arxiv-10200-1 | Cats & Co: Categorical Time Series Coclustering | http://arxiv.org/pdf/1505.01300v1.pdf | author:Dominique Gay, Romain Guigourès, Marc Boullé, Fabrice Clérot category:cs.DB stat.ML H.2.8 published:2015-05-06 summary:We suggest a novel method of clustering and exploratory analysis of temporalevent sequences data (also known as categorical time series) based onthree-dimensional data grid models. A data set of temporal event sequences canbe represented as a data set of three-dimensional points, each point is definedby three variables: a sequence identifier, a time value and an event value.Instantiating data grid models to the 3D-points turns the problem into3D-coclustering. The sequences are partitioned into clusters, the time variable is discretizedinto intervals and the events are partitioned into clusters. The cross-productof the univariate partitions forms a multivariate partition of therepresentation space, i.e., a grid of cells and it also represents anonparametric estimator of the joint distribution of the sequences, time andevents dimensions. Thus, the sequences are grouped together because they havesimilar joint distribution of time and events, i.e., similar distribution ofevents along the time dimension. The best data grid is computed using aparameter-free Bayesian model selection approach. We also suggest severalcriteria for exploiting the resulting grid through agglomerative hierarchies,for interpreting the clusters of sequences and characterizing their componentsthrough insightful visualizations. Extensive experiments on both synthetic andreal-world data sets demonstrate that data grid models are efficient, effectiveand discover meaningful underlying patterns of categorical time series data.
arxiv-10200-2 | A Deeper Look at Dataset Bias | http://arxiv.org/pdf/1505.01257v1.pdf | author:Tatiana Tommasi, Novi Patricia, Barbara Caputo, Tinne Tuytelaars category:cs.CV published:2015-05-06 summary:The presence of a bias in each image data collection has recently attracted alot of attention in the computer vision community showing the limits ingeneralization of any learning method trained on a specific dataset. At thesame time, with the rapid development of deep learning architectures, theactivation values of Convolutional Neural Networks (CNN) are emerging asreliable and robust image descriptors. In this paper we propose to verify thepotential of the DeCAF features when facing the dataset bias problem. Weconduct a series of analyses looking at how existing datasets differ among eachother and verifying the performance of existing debiasing methods underdifferent representations. We learn important lessons on which part of thedataset bias problem can be considered solved and which open questions stillneed to be tackled.
arxiv-10200-3 | On Pairwise Costs for Network Flow Multi-Object Tracking | http://arxiv.org/pdf/1408.3304v2.pdf | author:Visesh Chari, Simon Lacoste-Julien, Ivan Laptev, Josef Sivic category:cs.CV math.OC published:2014-08-14 summary:Multi-object tracking has been recently approached with the min-cost networkflow optimization techniques. Such methods simultaneously resolve multipleobject tracks in a video and enable modeling of dependencies among tracks.Min-cost network flow methods also fit well within the "tracking-by-detection"paradigm where object trajectories are obtained by connecting per-frame outputsof an object detector. Object detectors, however, often fail due to occlusionsand clutter in the video. To cope with such situations, we propose to addpairwise costs to the min-cost network flow framework. While integer solutionsto such a problem become NP-hard, we design a convex relaxation solution withan efficient rounding heuristic which empirically gives certificates of smallsuboptimality. We evaluate two particular types of pairwise costs anddemonstrate improvements over recent tracking methods in real-world videosequences.
arxiv-10200-4 | The Configurable SAT Solver Challenge (CSSC) | http://arxiv.org/pdf/1505.01221v1.pdf | author:Frank Hutter, Marius Lindauer, Adrian Balint, Sam Bayless, Holger Hoos, Kevin Leyton-Brown category:cs.AI cs.LG published:2015-05-05 summary:It is well known that different solution strategies work well for differenttypes of instances of hard combinatorial problems. As a consequence, mostsolvers for the propositional satisfiability problem (SAT) expose parametersthat allow them to be customized to a particular family of instances. In theinternational SAT competition series, these parameters are ignored: solvers arerun using a single default parameter setting (supplied by the authors) for allbenchmark instances in a given track. While this competition format rewardssolvers with robust default settings, it does not reflect the situation facedby a practitioner who only cares about performance on one particularapplication and can invest some time into tuning solver parameters for thisapplication. The new Configurable SAT Solver Competition (CSSC) comparessolvers in this latter setting, scoring each solver by the performance itachieved after a fully automated configuration step. This article describes theCSSC in more detail, and reports the results obtained in its two instantiationsso far, CSSC 2013 and 2014.
arxiv-10200-5 | Learning Style Similarity for Searching Infographics | http://arxiv.org/pdf/1505.01214v1.pdf | author:Babak Saleh, Mira Dontcheva, Aaron Hertzmann, Zhicheng Liu category:cs.GR cs.CV cs.HC cs.IR cs.MM published:2015-05-05 summary:Infographics are complex graphic designs integrating text, images, charts andsketches. Despite the increasing popularity of infographics and the rapidgrowth of online design portfolios, little research investigates how we cantake advantage of these design resources. In this paper we present a method formeasuring the style similarity between infographics. Based on human perceptiondata collected from crowdsourced experiments, we use computer vision andmachine learning algorithms to learn a style similarity metric for infographicdesigns. We evaluate different visual features and learning algorithms and findthat a combination of color histograms and Histograms-of-Gradients (HoG)features is most effective in characterizing the style of infographics. Wedemonstrate our similarity metric on a preliminary image retrieval test.
arxiv-10200-6 | Trees Assembling Mann Whitney Approach for Detecting Genome-wide Joint Association among Low Marginal Effect loci | http://arxiv.org/pdf/1505.01206v1.pdf | author:Changshuai Wei, Daniel J. Schaid, Qing Lu category:q-bio.QM stat.CO stat.ML published:2015-05-05 summary:Common complex diseases are likely influenced by the interplay of hundreds,or even thousands, of genetic variants. Converging evidence shows that geneticvariants with low marginal effects (LME) play an important role in diseasedevelopment. Despite their potential significance, discovering LME geneticvariants and assessing their joint association on high dimensional data (e.g.,genome wide association studies) remain a great challenge. To facilitate jointassociation analysis among a large ensemble of LME genetic variants, weproposed a computationally efficient and powerful approach, which we call TreesAssembling Mann whitney (TAMW). Through simulation studies and an empiricaldata application, we found that TAMW outperformed multifactor dimensionalityreduction (MDR) and the likelihood ratio based Mann whitney approach (LRMW)when the underlying complex disease involves multiple LME loci and theirinteractions. For instance, in a simulation with 20 interacting LME loci, TAMWattained a higher power (power=0.931) than both MDR (power=0.599) and LRMW(power=0.704). In an empirical study of 29 known Crohn's disease (CD) loci,TAMW also identified a stronger joint association with CD than those detectedby MDR and LRMW. Finally, we applied TAMW to Wellcome Trust CD GWAS to conducta genome wide analysis. The analysis of 459K single nucleotide polymorphismswas completed in 40 hours using parallel computing, and revealed a jointassociation predisposing to CD (p-value=2.763e-19). Further analysis of thenewly discovered association suggested that 13 genes, such as ATG16L1 andLACC1, may play an important role in CD pathophysiological and etiologicalprocesses.
arxiv-10200-7 | Output-Sensitive Adaptive Metropolis-Hastings for Probabilistic Programs | http://arxiv.org/pdf/1501.05677v2.pdf | author:David Tolpin, Jan Willem van de Meent, Brooks Paige, Frank Wood category:cs.AI stat.ML published:2015-01-22 summary:We introduce an adaptive output-sensitive Metropolis-Hastings algorithm forprobabilistic models expressed as programs, Adaptive LightweightMetropolis-Hastings (AdLMH). The algorithm extends LightweightMetropolis-Hastings (LMH) by adjusting the probabilities of proposing randomvariables for modification to improve convergence of the program output. Weshow that AdLMH converges to the correct equilibrium distribution and compareconvergence of AdLMH to that of LMH on several test problems to highlightdifferent aspects of the adaptation scheme. We observe consistent improvementin convergence on the test problems.
arxiv-10200-8 | Actions and Attributes from Wholes and Parts | http://arxiv.org/pdf/1412.2604v2.pdf | author:Georgia Gkioxari, Ross Girshick, Jitendra Malik category:cs.CV published:2014-12-08 summary:We investigate the importance of parts for the tasks of action and attributeclassification. We develop a part-based approach by leveraging convolutionalnetwork features inspired by recent advances in computer vision. Our partdetectors are a deep version of poselets and capture parts of the human bodyunder a distinct set of poses. For the tasks of action and attributeclassification, we train holistic convolutional neural networks and show thatadding parts leads to top-performing results for both tasks. In addition, wedemonstrate the effectiveness of our approach when we replace an oracle persondetector, as is the default in the current evaluation protocol for both tasks,with a state-of-the-art person detection system.
arxiv-10200-9 | An Extreme Learning Machine Approach to Predicting Near Chaotic HCCI Combustion Phasing in Real-Time | http://arxiv.org/pdf/1310.3567v3.pdf | author:Adam Vaughan, Stanislav V. Bohac category:cs.LG cs.CE published:2013-10-14 summary:Fuel efficient Homogeneous Charge Compression Ignition (HCCI) enginecombustion timing predictions must contend with non-linear chemistry,non-linear physics, period doubling bifurcation(s), turbulent mixing, modelparameters that can drift day-to-day, and air-fuel mixture state informationthat cannot typically be resolved on a cycle-to-cycle basis, especially duringtransients. In previous work, an abstract cycle-to-cycle mapping functioncoupled with $\epsilon$-Support Vector Regression was shown to predictexperimentally observed cycle-to-cycle combustion timing over a wide range ofengine conditions, despite some of the aforementioned difficulties. The mainlimitation of the previous approach was that a partially acausual randomlysampled training dataset was used to train proof of concept offlinepredictions. The objective of this paper is to address this limitation byproposing a new online adaptive Extreme Learning Machine (ELM) extension namedWeighted Ring-ELM. This extension enables fully causal combustion timingpredictions at randomly chosen engine set points, and is shown to achieveresults that are as good as or better than the previous offline method. Thebroader objective of this approach is to enable a new class of real-time modelpredictive control strategies for high variability HCCI and, ultimately, tobring HCCI's low engine-out NOx and reduced CO2 emissions to productionengines.
arxiv-10200-10 | Deep Learning for Object Saliency Detection and Image Segmentation | http://arxiv.org/pdf/1505.01173v1.pdf | author:Hengyue Pan, Bo Wang, Hui Jiang category:cs.CV published:2015-05-05 summary:In this paper, we propose several novel deep learning methods for objectsaliency detection based on the powerful convolutional neural networks. In ourapproach, we use a gradient descent method to iteratively modify an input imagebased on the pixel-wise gradients to reduce a cost function measuring theclass-specific objectness of the image. The pixel-wise gradients can beefficiently computed using the back-propagation algorithm. The discrepancybetween the modified image and the original one may be used as a saliency mapfor the image. Moreover, we have further proposed several new training methodsto learn saliency-specific convolutional nets for object saliency detection, inorder to leverage the available pixel-wise segmentation information. Ourmethods are extremely computationally efficient (processing 20-40 images persecond in one GPU). In this work, we use the computed saliency maps for imagesegmentation. Experimental results on two benchmark tasks, namely MicrosoftCOCO and Pascal VOC 2012, have shown that our proposed methods can generatehigh-quality salience maps, clearly outperforming many existing methods. Inparticular, our approaches excel in handling many difficult images, whichcontain complex background, highly-variable salient objects, multiple objects,and/or very small salient objects.
arxiv-10200-11 | Achieving a Hyperlocal Housing Price Index: Overcoming Data Sparsity by Bayesian Dynamical Modeling of Multiple Data Streams | http://arxiv.org/pdf/1505.01164v1.pdf | author:You Ren, Emily B. Fox, Andrew Bruce category:stat.AP stat.ME stat.ML published:2015-05-05 summary:Understanding how housing values evolve over time is important to policymakers, consumers and real estate professionals. Existing methods forconstructing housing indices are computed at a coarse spatial granularity, suchas metropolitan regions, which can mask or distort price dynamics apparent inlocal markets, such as neighborhoods and census tracts. A challenge in movingto estimates at, for example, the census tract level is the sparsity ofspatiotemporally localized house sales observations. Our work aims ataddressing this challenge by leveraging observations from multiple censustracts discovered to have correlated valuation dynamics. Our proposed Bayesiannonparametric approach builds on the framework of latent factor models toenable a flexible, data-driven method for inferring the clustering ofcorrelated census tracts. We explore methods for scalability andparallelizability of computations, yielding a housing valuation index at thelevel of census tract rather than zip code, and on a monthly basis rather thanquarterly. Our analysis is provided on a large Seattle metropolitan housingdataset.
arxiv-10200-12 | Generalized Low Rank Models | http://arxiv.org/pdf/1410.0342v4.pdf | author:Madeleine Udell, Corinne Horn, Reza Zadeh, Stephen Boyd category:stat.ML cs.LG math.OC published:2014-10-01 summary:Principal components analysis (PCA) is a well-known technique forapproximating a tabular data set by a low rank matrix. Here, we extend the ideaof PCA to handle arbitrary data sets consisting of numerical, Boolean,categorical, ordinal, and other data types. This framework encompasses manywell known techniques in data analysis, such as nonnegative matrixfactorization, matrix completion, sparse and robust PCA, $k$-means, $k$-SVD,and maximum margin matrix factorization. The method handles heterogeneous datasets, and leads to coherent schemes for compressing, denoising, and imputingmissing entries across all data types simultaneously. It also admits a numberof interesting interpretations of the low rank factors, which allow clusteringof examples or of features. We propose several parallel algorithms for fittinggeneralized low rank models, and describe implementations and numericalresults.
arxiv-10200-13 | fastFM: A Library for Factorization Machines | http://arxiv.org/pdf/1505.00641v2.pdf | author:Immanuel Bayer category:cs.LG cs.IR published:2015-05-04 summary:Factorization Machines (FM) are only used in a narrow range of applicationsand are not part of the standard toolbox of machine learning models. This is apity, because even though FMs are recognized as being very successful forrecommender system type applications they are a general model to deal withsparse and high dimensional features. Our Factorization Machine implementationprovides easy access to many solvers and supports regression, classificationand ranking tasks. Such an implementation simplifies the use of FM's for a widefield of applications. This implementation has the potential to improve ourunderstanding of the FM model and drive new development.
arxiv-10200-14 | Learnable Pooling Regions for Image Classification | http://arxiv.org/pdf/1301.3516v3.pdf | author:Mateusz Malinowski, Mario Fritz category:cs.CV cs.LG published:2013-01-15 summary:Biologically inspired, from the early HMAX model to Spatial Pyramid Matching,pooling has played an important role in visual recognition pipelines. Spatialpooling, by grouping of local codes, equips these methods with a certain degreeof robustness to translation and deformation yet preserving important spatialinformation. Despite the predominance of this approach in current recognitionsystems, we have seen little progress to fully adapt the pooling strategy tothe task at hand. This paper proposes a model for learning task dependentpooling scheme -- including previously proposed hand-crafted pooling schemes asa particular instantiation. In our work, we investigate the role of differentregularization terms showing that the smooth regularization term is crucial toachieve strong performance using the presented architecture. Finally, wepropose an efficient and parallel method to train the model. Our experimentsshow improved performance over hand-crafted pooling schemes on the CIFAR-10 andCIFAR-100 datasets -- in particular improving the state-of-the-art to 56.29% onthe latter.
arxiv-10200-15 | Towards a Visual Turing Challenge | http://arxiv.org/pdf/1410.8027v3.pdf | author:Mateusz Malinowski, Mario Fritz category:cs.AI cs.CL cs.CV cs.GL cs.LG published:2014-10-29 summary:As language and visual understanding by machines progresses rapidly, we areobserving an increasing interest in holistic architectures that tightlyinterlink both modalities in a joint learning and inference process. This trendhas allowed the community to progress towards more challenging and open tasksand refueled the hope at achieving the old AI dream of building machines thatcould pass a turing test in open domains. In order to steadily make progresstowards this goal, we realize that quantifying performance becomes increasinglydifficult. Therefore we ask how we can precisely define such challenges and howwe can evaluate different algorithms on this open tasks? In this paper, wesummarize and discuss such challenges as well as try to give answers whereappropriate options are available in the literature. We exemplify some of thesolutions on a recently presented dataset of question-answering task based onreal-world indoor images that establishes a visual turing challenge. Finally,we argue despite the success of unique ground-truth annotation, we likely haveto step away from carefully curated dataset and rather rely on 'socialconsensus' as the main driving force to create suitable benchmarks. Providingcoverage in this inherently ambiguous output space is an emerging challengethat we face in order to make quantifiable progress in this area.
arxiv-10200-16 | A Pooling Approach to Modelling Spatial Relations for Image Retrieval and Annotation | http://arxiv.org/pdf/1411.5190v2.pdf | author:Mateusz Malinowski, Mario Fritz category:cs.CV published:2014-11-19 summary:Over the last two decades we have witnessed strong progress on modelingvisual object classes, scenes and attributes that have significantlycontributed to automated image understanding. On the other hand, surprisinglylittle progress has been made on incorporating a spatial representation andreasoning in the inference process. In this work, we propose a poolinginterpretation of spatial relations and show how it improves image retrievaland annotations tasks involving spatial language. Due to the complexity of thespatial language, we argue for a learning-based approach that acquires arepresentation of spatial relations by learning parameters of the poolingoperator. We show improvements on previous work on two datasets and twodifferent tasks as well as provide additional insights on a new dataset with anexplicit focus on spatial relations.
arxiv-10200-17 | Variation of word frequencies in Russian literary texts | http://arxiv.org/pdf/1503.00339v2.pdf | author:Vladislav Kargin category:cs.CL physics.soc-ph stat.AP published:2015-03-01 summary:We study the variation of word frequencies in Russian literary texts. Ourfindings indicate that the standard deviation of a word's frequency acrosstexts depends on its average frequency according to a power law with exponent$0.62,$ showing that the rarer words have a relatively larger degree offrequency volatility (i.e., "burstiness"). Several latent factors models have been estimated to investigate thestructure of the word frequency distribution. The dependence of a word'sfrequency volatility on its average frequency can be explained by the asymmetryin the distribution of latent factors.
arxiv-10200-18 | A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input | http://arxiv.org/pdf/1410.0210v4.pdf | author:Mateusz Malinowski, Mario Fritz category:cs.AI cs.CL cs.CV cs.LG published:2014-10-01 summary:We propose a method for automatically answering questions about images bybringing together recent advances from natural language processing and computervision. We combine discrete reasoning with uncertain predictions by amulti-world approach that represents uncertainty about the perceived world in abayesian framework. Our approach can handle human questions of high complexityabout realistic scenes and replies with range of answer like counts, objectclasses, instances and lists of them. The system is directly trained fromquestion-answer pairs. We establish a first benchmark for this task that can beseen as a modern attempt at a visual turing test.
arxiv-10200-19 | In Defense of the Direct Perception of Affordances | http://arxiv.org/pdf/1505.01085v1.pdf | author:David F. Fouhey, Xiaolong Wang, Abhinav Gupta category:cs.CV published:2015-05-05 summary:The field of functional recognition or affordance estimation from images hasseen a revival in recent years. As originally proposed by Gibson, theaffordances of a scene were directly perceived from the ambient light: in otherwords, functional properties like sittable were estimated directly fromincoming pixels. Recent work, however, has taken a mediated approach in whichaffordances are derived by first estimating semantics or geometry and thenreasoning about the affordances. In a tribute to Gibson, this paper exploreshis theory of affordances as originally proposed. We propose two approaches fordirect perception of affordances and show that they obtain good results and canout-perform mediated approaches. We hope this paper can rekindle discussionaround direct perception and its implications in the long term.
arxiv-10200-20 | Mining Measured Information from Text | http://arxiv.org/pdf/1505.01072v1.pdf | author:Arun S. Maiya, Dale Visser, Andrew Wan category:cs.CL cs.IR I.2.7; H.3.3 published:2015-05-05 summary:We present an approach to extract measured information from text (e.g., a1370 degrees C melting point, a BMI greater than 29.9 kg/m^2 ). Suchextractions are critically important across a wide range of domains -especially those involving search and exploration of scientific and technicaldocuments. We first propose a rule-based entity extractor to mine measuredquantities (i.e., a numeric value paired with a measurement unit), whichsupports a vast and comprehensive set of both common and obscure measurementunits. Our method is highly robust and can correctly recover valid measuredquantities even when significant errors are introduced through the process ofconverting document formats like PDF to plain text. Next, we describe anapproach to extracting the properties being measured (e.g., the property "pixelpitch" in the phrase "a pixel pitch as high as 352 {\mu}m"). Finally, wepresent MQSearch: the realization of a search engine with full support formeasured information.
arxiv-10200-21 | Fast Guided Filter | http://arxiv.org/pdf/1505.00996v1.pdf | author:Kaiming He, Jian Sun category:cs.CV published:2015-05-05 summary:The guided filter is a technique for edge-aware image filtering. Because ofits nice visual quality, fast speed, and ease of implementation, the guidedfilter has witnessed various applications in real products, such as imageediting apps in phones and stereo reconstruction, and has been included inofficial MATLAB and OpenCV. In this note, we remind that the guided filter canbe simply sped up from O(N) time to O(N/s^2) time for a subsampling ratio s. Ina variety of applications, this leads to a speedup of >10x with almost novisible degradation. We hope this acceleration will improve performance ofcurrent applications and further popularize this filter. Code is released.
arxiv-10200-22 | Stochastic Local Interaction (SLI) Model: Interfacing Machine Learning and Geostatistics | http://arxiv.org/pdf/1501.04053v2.pdf | author:Dionissios T. Hristopulos category:cs.LG stat.ML published:2015-01-16 summary:Machine learning and geostatistics are powerful mathematical frameworks formodeling spatial data. Both approaches, however, suffer from poor scaling ofthe required computational resources for large data applications. We presentthe Stochastic Local Interaction (SLI) model, which employs a localrepresentation to improve computational efficiency. SLI combines geostatisticsand machine learning with ideas from statistical physics and computationalgeometry. It is based on a joint probability density function defined by anenergy functional which involves local interactions implemented by means ofkernel functions with adaptive local kernel bandwidths. SLI is expressed interms of an explicit, typically sparse, precision (inverse covariance) matrix.This representation leads to a semi-analytical expression for interpolation(prediction), which is valid in any number of dimensions and avoids thecomputationally costly covariance matrix inversion.
arxiv-10200-23 | Support Vector Machines for Current Status Data | http://arxiv.org/pdf/1505.00991v1.pdf | author:Yael Travis-Lumer, Yair Goldberg category:math.ST stat.ML stat.TH published:2015-05-05 summary:Current status data is a data format where the time to event is restricted toknowledge of whether or not the failure time exceeds a random monitoring time.We develop a support vector machine learning method for current status datathat estimates the failure time expectation as a function of the covariates. Inorder to obtain the support vector machine decision function, we minimize aregularized version of the empirical risk with respect to a data-dependentloss. We show that the decision function has a closed form. Using finite samplebounds and novel oracle inequalities, we prove that the obtained decisionfunction converges to the true conditional expectation for a large family ofprobability measures and study the associated learning rates. Finally wepresent a simulation study that compares the performance of the proposedapproach to current state of the art.
arxiv-10200-24 | Incorporating Road Networks into Territory Design | http://arxiv.org/pdf/1504.07846v2.pdf | author:Nitin Ahuja, Matthias Bender, Peter Sanders, Christian Schulz, Andreas Wagner category:math.OC cs.DS cs.NE published:2015-04-29 summary:Given a set of basic areas, the territory design problem asks to create apredefined number of territories, each containing at least one basic area, suchthat an objective function is optimized. Desired properties of territoriesoften include a reasonable balance, compact form, contiguity and small averagejourney times which are usually encoded in the objective function or formulatedas constraints. We address the territory design problem by developing graphtheoretic models that also consider the underlying road network. The derivedgraph models enable us to tackle the territory design problem by modifyinggraph partitioning algorithms and mixed integer programming formulations sothat the objective of the planning problem is taken into account. We test andcompare the algorithms on several real world instances.
arxiv-10200-25 | Autoencoding Time Series for Visualisation | http://arxiv.org/pdf/1505.00936v1.pdf | author:Nikolaos Gianniotis, Dennis Kügler, Peter Tino, Kai Polsterer, Ranjeev Misra category:astro-ph.IM cs.NE published:2015-05-05 summary:We present an algorithm for the visualisation of time series. To that end weemploy echo state networks to convert time series into a suitable vectorrepresentation which is capable of capturing the latent dynamics of the timeseries. Subsequently, the obtained vector representations are put through anautoencoder and the visualisation is constructed using the activations of thebottleneck. The crux of the work lies with defining an objective function thatquantifies the reconstruction error of these representations in a principledmanner. We demonstrate the method on synthetic and real data.
arxiv-10200-26 | Reinforced Decision Trees | http://arxiv.org/pdf/1505.00908v1.pdf | author:Aurélia Léon, Ludovic Denoyer category:cs.LG published:2015-05-05 summary:In order to speed-up classification models when facing a large number ofcategories, one usual approach consists in organizing the categories in aparticular structure, this structure being then used as a way to speed-up theprediction computation. This is for example the case when usingerror-correcting codes or even hierarchies of categories. But in the majorityof approaches, this structure is chosen \textit{by hand}, or during apreliminary step, and not integrated in the learning process. We propose a newmodel called Reinforced Decision Tree which simultaneously learns how toorganize categories in a tree structure and how to classify any input based onthis structure. This approach keeps the advantages of existing techniques (lowinference complexity) but allows one to build efficient classifiers in onelearning step. The learning algorithm is inspired by reinforcement learning andpolicy-gradient techniques which allows us to integrate the two steps (buildingthe tree, and learning the classifier) in one single algorithm.
arxiv-10200-27 | Domain-Size Pooling in Local Descriptors: DSP-SIFT | http://arxiv.org/pdf/1412.8556v3.pdf | author:Jingming Dong, Stefano Soatto category:cs.CV published:2014-12-30 summary:We introduce a simple modification of local image descriptors, such as SIFT,based on pooling gradient orientations across different domain sizes, inaddition to spatial locations. The resulting descriptor, which we callDSP-SIFT, outperforms other methods in wide-baseline matching benchmarks,including those based on convolutional neural networks, despite having the samedimension of SIFT and requiring no training.
arxiv-10200-28 | On the Feasibility of Distributed Kernel Regression for Big Data | http://arxiv.org/pdf/1505.00869v1.pdf | author:Chen Xu, Yongquan Zhang, Runze Li category:stat.ML published:2015-05-05 summary:In modern scientific research, massive datasets with huge numbers ofobservations are frequently encountered. To facilitate the computationalprocess, a divide-and-conquer scheme is often used for the analysis of bigdata. In such a strategy, a full dataset is first split into several manageablesegments; the final output is then averaged from the individual outputs of thesegments. Despite its popularity in practice, it remains largely unknown thatwhether such a distributive strategy provides valid theoretical inferences tothe original data. In this paper, we address this fundamental issue for thedistributed kernel regression (DKR), where the algorithmic feasibility ismeasured by the generalization performance of the resulting estimator. Tojustify DKR, a uniform convergence rate is needed for bounding thegeneralization error over the individual outputs, which brings new andchallenging issues in the big data setup. Under mild conditions, we show that,with a proper number of segments, DKR leads to an estimator that isgeneralization consistent to the unknown regression function. The obtainedresults justify the method of DKR and shed light on the feasibility of usingother distributed algorithms for processing big data. The promising preferenceof the method is supported by both simulation and real data examples.
arxiv-10200-29 | Adaptive diffusion constrained total variation scheme with application to `cartoon + texture + edge' image decomposition | http://arxiv.org/pdf/1505.00866v1.pdf | author:Juan C. Moreno, V. B. Surya Prasath, D. Vorotnikov, H. Proenca, K. Palaniappan category:cs.CV 68U10 published:2015-05-05 summary:We consider an image decomposition model involving a variational(minimization) problem and an evolutionary partial differential equation (PDE).We utilize a linear inhomogenuous diffusion constrained and weighted totalvariation (TV) scheme for image adaptive decomposition. An adaptive weightalong with TV regularization splits a given image into three componentsrepresenting the geometrical (cartoon), textural (small scale - microtextures),and edges (big scale - macrotextures). We study the wellposedness of thecoupled variational-PDE scheme along with an efficient numerical scheme basedon Chambolle's dual minimization method. We provide extensive experimentalresults in cartoon-texture-edges decomposition, and denoising as well comparewith other related variational, coupled anisotropic diffusion PDE basedmethods.
arxiv-10200-30 | A Feature-based Classification Technique for Answering Multi-choice World History Questions | http://arxiv.org/pdf/1505.00863v1.pdf | author:Shuangyong Song, Yao Meng, Zhongguang Zheng, Jun Sun category:cs.IR cs.AI cs.CL 68T50 H.3.4 published:2015-05-05 summary:Our FRDC_QA team participated in the QA-Lab English subtask of the NTCIR-11.In this paper, we describe our system for solving real-world universityentrance exam questions, which are related to world history. Wikipedia is usedas the main external resource for our system. Since problems with choosingright/wrong sentence from multiple sentence choices account for abouttwo-thirds of the total, we individually design a classification based modelfor solving this type of questions. For other types of questions, we alsodesign some simple methods.
arxiv-10200-31 | Large-scale Classification of Fine-Art Paintings: Learning The Right Metric on The Right Feature | http://arxiv.org/pdf/1505.00855v1.pdf | author:Babak Saleh, Ahmed Elgammal category:cs.CV cs.IR cs.LG cs.MM published:2015-05-05 summary:In the past few years, the number of fine-art collections that are digitizedand publicly available has been growing rapidly. With the availability of suchlarge collections of digitized artworks comes the need to develop multimediasystems to archive and retrieve this pool of data. Measuring the visualsimilarity between artistic items is an essential step for such multimediasystems, which can benefit more high-level multimedia tasks. In order to modelthis similarity between paintings, we should extract the appropriate visualfeatures for paintings and find out the best approach to learn the similaritymetric based on these features. We investigate a comprehensive list of visualfeatures and metric learning approaches to learn an optimized similaritymeasure between paintings. We develop a machine that is able to makeaesthetic-related semantic-level judgments, such as predicting a painting'sstyle, genre, and artist, as well as providing similarity measures optimizedbased on the knowledge available in the domain of art historicalinterpretation. Our experiments show the value of using this similarity measurefor the aforementioned prediction tasks.
arxiv-10200-32 | Locally Non-rigid Registration for Mobile HDR Photography | http://arxiv.org/pdf/1504.01441v3.pdf | author:Orazio Gallo, Alejandro Troccoli, Jun Hu, Kari Pulli, Jan Kautz category:cs.CV published:2015-04-07 summary:Image registration for stack-based HDR photography is challenging. If notproperly accounted for, camera motion and scene changes result in artifacts inthe composite image. Unfortunately, existing methods to address this problemare either accurate, but too slow for mobile devices, or fast, but prone tofailing. We propose a method that fills this void: our approach is extremelyfast---under 700ms on a commercial tablet for a pair of 5MP images---andprevents the artifacts that arise from insufficient registration quality.
arxiv-10200-33 | A novel plasticity rule can explain the development of sensorimotor intelligence | http://arxiv.org/pdf/1505.00835v1.pdf | author:Ralf Der, Georg Martius category:cs.RO cs.LG q-bio.NC I.2.9; I.2.6 published:2015-05-04 summary:Grounding autonomous behavior in the nervous system is a fundamentalchallenge for neuroscience. In particular, the self-organized behavioraldevelopment provides more questions than answers. Are there special functionalunits for curiosity, motivation, and creativity? This paper argues that thesefeatures can be grounded in synaptic plasticity itself, without requiring anyhigher level constructs. We propose differential extrinsic plasticity (DEP) asa new synaptic rule for self-learning systems and apply it to a number ofcomplex robotic systems as a test case. Without specifying any purpose or goal,seemingly purposeful and adaptive behavior is developed, displaying a certainlevel of sensorimotor intelligence. These surprising results require no systemspecific modifications of the DEP rule but arise rather from the underlyingmechanism of spontaneous symmetry breaking due to the tightbrain-body-environment coupling. The new synaptic rule is biologicallyplausible and it would be an interesting target for a neurobiolocalinvestigation. We also argue that this neuronal mechanism may have been acatalyst in natural evolution.
arxiv-10200-34 | Pattern Recognition in Narrative: Tracking Emotional Expression in Context | http://arxiv.org/pdf/1405.3539v3.pdf | author:Fionn Murtagh, Adam Ganz category:cs.AI cs.CL published:2014-05-14 summary:Using geometric data analysis, our objective is the analysis of narrative,with narrative of emotion being the focus in this work. The following twoprinciples for analysis of emotion inform our work. Firstly, emotion isrevealed not as a quality in its own right but rather through interaction. Westudy the 2-way relationship of Ilsa and Rick in the movie Casablanca, and the3-way relationship of Emma, Charles and Rodolphe in the novel {\em MadameBovary}. Secondly, emotion, that is expression of states of mind of subjects,is formed and evolves within the narrative that expresses external events and(personal, social, physical) context. In addition to the analysis methodologywith key aspects that are innovative, the input data used is crucial. We use,firstly, dialogue, and secondly, broad and general description thatincorporates dialogue. In a follow-on study, we apply our unsupervisednarrative mapping to data streams with very low emotional expression. We mapthe narrative of Twitter streams. Thus we demonstrate map analysis of generalnarratives.
arxiv-10200-35 | Self-Expressive Decompositions for Matrix Approximation and Clustering | http://arxiv.org/pdf/1505.00824v1.pdf | author:Eva L. Dyer, Tom A. Goldstein, Raajen Patel, Konrad P. Kording, Richard G. Baraniuk category:cs.IT cs.CV cs.LG math.IT stat.ML published:2015-05-04 summary:Data-aware methods for dimensionality reduction and matrix decomposition aimto find low-dimensional structure in a collection of data. Classical approachesdiscover such structure by learning a basis that can efficiently express thecollection. Recently, "self expression", the idea of using a small subset ofdata vectors to represent the full collection, has been developed as analternative to learning. Here, we introduce a scalable method for computingsparse SElf-Expressive Decompositions (SEED). SEED is a greedy method thatconstructs a basis by sequentially selecting incoherent vectors from thedataset. After forming a basis from a subset of vectors in the dataset, SEEDthen computes a sparse representation of the dataset with respect to thisbasis. We develop sufficient conditions under which SEED exactly represents lowrank matrices and vectors sampled from a unions of independent subspaces. Weshow how SEED can be used in applications ranging from matrix approximation anddenoising to clustering, and apply it to numerous real-world datasets. Ourresults demonstrate that SEED is an attractive low-complexity alternative toother sparse matrix factorization approaches such as sparse PCA andself-expressive methods for clustering.
arxiv-10200-36 | A Gaussian Scale Space Approach For Exudates Detection, Classification And Severity Prediction | http://arxiv.org/pdf/1505.00737v1.pdf | author:Mrinal Haloi, Samarendra Dandapat, Rohit Sinha category:cs.CV 68T45 published:2015-05-04 summary:In the context of Computer Aided Diagnosis system for diabetic retinopathy,we present a novel method for detection of exudates and their classificationfor disease severity prediction. The method is based on Gaussian scale spacebased interest map and mathematical morphology. It makes use of support vectormachine for classification and location information of the optic disc and themacula region for severity prediction. It can efficiently handle luminancevariation and it is suitable for varied sized exudates. The method has beenprobed in publicly available DIARETDB1V2 and e-ophthaEX databases. For exudatedetection the proposed method achieved a sensitivity of 96.54% and predictionof 98.35% in DIARETDB1V2 database.
arxiv-10200-37 | Unsupervised Object Discovery and Localization in the Wild: Part-based Matching with Bottom-up Region Proposals | http://arxiv.org/pdf/1501.06170v3.pdf | author:Minsu Cho, Suha Kwak, Cordelia Schmid, Jean Ponce category:cs.CV published:2015-01-25 summary:This paper addresses unsupervised discovery and localization of dominantobjects from a noisy image collection with multiple object classes. The settingof this problem is fully unsupervised, without even image-level annotations orany assumption of a single dominant class. This is far more general thantypical colocalization, cosegmentation, or weakly-supervised localizationtasks. We tackle the discovery and localization problem using a part-basedregion matching approach: We use off-the-shelf region proposals to form a setof candidate bounding boxes for objects and object parts. These regions areefficiently matched across images using a probabilistic Hough transform thatevaluates the confidence for each candidate correspondence considering bothappearance and spatial consistency. Dominant objects are discovered andlocalized by comparing the scores of candidate regions and selecting those thatstand out over other regions containing them. Extensive experimentalevaluations on standard benchmarks demonstrate that the proposed approachsignificantly outperforms the current state of the art in colocalization, andachieves robust object discovery in challenging mixed-class datasets.
arxiv-10200-38 | Penalized versus constrained generalized eigenvalue problems | http://arxiv.org/pdf/1410.6131v3.pdf | author:Irina Gaynanova, James Booth, Martin T. Wells category:stat.CO stat.ML published:2014-10-22 summary:We investigate the difference between using an $\ell_1$ penalty versus an$\ell_1$ constraint in generalized eigenvalue problems, such as principalcomponent analysis and discriminant analysis. Our main finding is that an$\ell_1$ penalty may fail to provide very sparse solutions; a severedisadvantage for variable selection that can be remedied by using an $\ell_1$constraint. Our claims are supported both by empirical evidence and theoreticalanalysis. Finally, we illustrate the advantages of an $\ell_1$ constraint inthe context of discriminant analysis and principal component analysis.
arxiv-10200-39 | Interleaved Text/Image Deep Mining on a Large-Scale Radiology Database for Automated Image Interpretation | http://arxiv.org/pdf/1505.00670v1.pdf | author:Hoo-Chang Shin, Le Lu, Lauren Kim, Ari Seff, Jianhua Yao, Ronald M. Summers category:cs.CV cs.LG published:2015-05-04 summary:Despite tremendous progress in computer vision, there has not been an attemptfor machine learning on very large-scale medical image databases. We present aninterleaved text/image deep learning system to extract and mine the semanticinteractions of radiology images and reports from a national researchhospital's Picture Archiving and Communication System. With natural languageprocessing, we mine a collection of representative ~216K two-dimensional keyimages selected by clinicians for diagnostic reference, and match the imageswith their descriptions in an automated manner. Our system interleaves betweenunsupervised learning and supervised learning on document- and sentence-leveltext collections, to generate semantic labels and to predict them given animage. Given an image of a patient scan, semantic topics in radiology levelsare predicted, and associated key-words are generated. Also, a number offrequent disease types are detected as present or absent, to provide morespecific interpretation of a patient scan. This shows the potential oflarge-scale learning and prediction in electronic patient records available inmost modern clinical institutions.
arxiv-10200-40 | Model Selection and Overfitting in Genetic Programming: Empirical Study [Extended Version] | http://arxiv.org/pdf/1504.08168v2.pdf | author:Jan Žegklitz, Petr Pošík category:cs.NE cs.LG published:2015-04-30 summary:Genetic Programming has been very successful in solving a large area ofproblems but its use as a machine learning algorithm has been limited so far.One of the reasons is the problem of overfitting which cannot be solved orsuppresed as easily as in more traditional approaches. Another problem, closelyrelated to overfitting, is the selection of the final model from thepopulation. In this article we present our research that addresses both problems:overfitting and model selection. We compare several ways of dealing withovefitting, based on Random Sampling Technique (RST) and on using a validationset, all with an emphasis on model selection. We subject each approach to athorough testing on artificial and real--world datasets and compare them withthe standard approach, which uses the full training data, as a baseline.
arxiv-10200-41 | Activity recognition from videos with parallel hypergraph matching on GPUs | http://arxiv.org/pdf/1505.00581v1.pdf | author:Eric Lombardi, Christian Wolf, Oya Celiktutan, Bülent Sankur category:cs.CV published:2015-05-04 summary:In this paper, we propose a method for activity recognition from videos basedon sparse local features and hypergraph matching. We benefit from specialproperties of the temporal domain in the data to derive a sequential and fastgraph matching algorithm for GPUs. Traditionally, graphs and hypergraphs are frequently used to recognizecomplex and often non-rigid patterns in computer vision, either through graphmatching or point-set matching with graphs. Most formulations resort to theminimization of a difficult discrete energy function mixing geometric orstructural terms with data attached terms involving appearance features.Traditional methods solve this minimization problem approximately, for instancewith spectral techniques. In this work, instead of solving the problem approximatively, the exactsolution for the optimal assignment is calculated in parallel on GPUs. Thegraphical structure is simplified and regularized, which allows to derive anefficient recursive minimization algorithm. The algorithm distributessubproblems over the calculation units of a GPU, which solves them in parallel,allowing the system to run faster than real-time on medium-end GPUs.
arxiv-10200-42 | Higher Order Maximum Persistency and Comparison Theorems | http://arxiv.org/pdf/1505.00571v1.pdf | author:Alexander Shekhovtsov category:cs.CV cs.DM math.CO published:2015-05-04 summary:We address combinatorial problems that can be formulated as minimization of apartially separable function of discrete variables (energy minimization ingraphical models, weighted constraint satisfaction, pseudo-Booleanoptimization, 0-1 polynomial programming). For polyhedral relaxations of suchproblems it is generally not true that variables integer in the relaxedsolution will retain the same values in the optimal discrete solution. Thosewhich do are called persistent. Such persistent variables define a part of aglobally optimal solution. Once identified, they can be excluded from theproblem, reducing its size. To any polyhedral relaxation we associate a sufficient condition provingpersistency of a subset of variables. We set up a specially constructed linearprogram which determines the set of persistent variables maximal with respectto the relaxation. The condition improves as the relaxation is tightened andpossesses all its invariances. The proposed framework explains a variety ofexisting methods originating from different areas of research and based ondifferent principles. A theoretical comparison is established that relatesthese methods to the standard linear relaxation and proves that the proposedtechnique identifies same or larger set of persistent variables.
arxiv-10200-43 | FlowNet: Learning Optical Flow with Convolutional Networks | http://arxiv.org/pdf/1504.06852v2.pdf | author:Philipp Fischer, Alexey Dosovitskiy, Eddy Ilg, Philip Häusser, Caner Hazırbaş, Vladimir Golkov, Patrick van der Smagt, Daniel Cremers, Thomas Brox category:cs.CV cs.LG I.2.6; I.4.8 published:2015-04-26 summary:Convolutional neural networks (CNNs) have recently been very successful in avariety of computer vision tasks, especially on those linked to recognition.Optical flow estimation has not been among the tasks where CNNs weresuccessful. In this paper we construct appropriate CNNs which are capable ofsolving the optical flow estimation problem as a supervised learning task. Wepropose and compare two architectures: a generic architecture and another oneincluding a layer that correlates feature vectors at different image locations. Since existing ground truth data sets are not sufficiently large to train aCNN, we generate a synthetic Flying Chairs dataset. We show that networkstrained on this unrealistic data still generalize very well to existingdatasets such as Sintel and KITTI, achieving competitive accuracy at framerates of 5 to 10 fps.
arxiv-10200-44 | On Regret-Optimal Learning in Decentralized Multi-player Multi-armed Bandits | http://arxiv.org/pdf/1505.00553v1.pdf | author:Naumaan Nayyar, Dileep Kalathil, Rahul Jain category:stat.ML cs.LG published:2015-05-04 summary:We consider the problem of learning in single-player and multiplayermultiarmed bandit models. Bandit problems are classes of online learningproblems that capture exploration versus exploitation tradeoffs. In amultiarmed bandit model, players can pick among many arms, and each play of anarm generates an i.i.d. reward from an unknown distribution. The objective isto design a policy that maximizes the expected reward over a time horizon for asingle player setting and the sum of expected rewards for the multiplayersetting. In the multiplayer setting, arms may give different rewards todifferent players. There is no separate channel for coordination among theplayers. Any attempt at communication is costly and adds to regret. We proposetwo decentralizable policies, $\tt E^3$ ($\tt E$-$\tt cubed$) and $\ttE^3$-$\tt TS$, that can be used in both single player and multiplayer settings.These policies are shown to yield expected regret that grows at most asO($\log^{1+\epsilon} T$). It is well known that $\log T$ is the lower bound onthe rate of growth of regret even in a centralized case. The proposedalgorithms improve on prior work where regret grew at O($\log^2 T$). Morefundamentally, these policies address the question of additional cost incurredin decentralized online learning, suggesting that there is at most an$\epsilon$-factor cost in terms of order of regret. This solves a problem ofrelevance in many domains and had been open for a while.
arxiv-10200-45 | Learning Document Image Binarization from Data | http://arxiv.org/pdf/1505.00529v1.pdf | author:Yue Wu, Stephen Rawls, Wael AbdAlmageed, Premkumar Natarajan category:cs.CV published:2015-05-04 summary:In this paper we present a fully trainable binarization solution for degradeddocument images. Unlike previous attempts that often used simple features witha series of pre- and post-processing, our solution encodes all heuristics aboutwhether or not a pixel is foreground text into a high-dimensional featurevector and learns a more complicated decision function. In particular, weprepare features of three types: 1) existing features for binarization such asintensity [1], contrast [2], [3], and Laplacian [4], [5]; 2) reformulatedfeatures from existing binarization decision functions such those in [6] and[7]; and 3) our newly developed features, namely the Logarithm IntensityPercentile (LIP) and the Relative Darkness Index (RDI). Our initialexperimental results show that using only selected samples (about 1.5% of allavailable training data), we can achieve a binarization performance comparableto those fine-tuned (typically by hand), state-of-the-art methods.Additionally, the trained document binarization classifier shows goodgeneralization capabilities on out-of-domain data.
arxiv-10200-46 | An Explicit Sampling Dependent Spectral Error Bound for Column Subset Selection | http://arxiv.org/pdf/1505.00526v1.pdf | author:Tianbao Yang, Lijun Zhang, Rong Jin, Shenghuo Zhu category:math.NA stat.ML published:2015-05-04 summary:In this paper, we consider the problem of column subset selection. We presenta novel analysis of the spectral norm reconstruction for a simple randomizedalgorithm and establish a new bound that depends explicitly on the samplingprobabilities. The sampling dependent error bound (i) allows us to betterunderstand the tradeoff in the reconstruction error due to samplingprobabilities, (ii) exhibits more insights than existing error bounds thatexploit specific probability distributions, and (iii) implies better samplingdistributions. In particular, we show that a sampling distribution withprobabilities proportional to the square root of the statistical leveragescores is always better than uniform sampling and is better than leverage-basedsampling when the statistical leverage scores are very nonuniform. And bysolving a constrained optimization problem related to the error bound with anefficient bisection search we are able to achieve better performance than usingeither the leverage-based distribution or that proportional to the square rootof the statistical leverage scores. Numerical simulations demonstrate thebenefits of the new sampling distributions for low-rank matrix approximationand least square approximation compared to state-of-the art algorithms.
arxiv-10200-47 | Modeling Representation of Videos for Anomaly Detection using Deep Learning: A Review | http://arxiv.org/pdf/1505.00523v1.pdf | author:Yong Shean Chong, Yong Haur Tay category:cs.CV published:2015-05-04 summary:This review article surveys the current progresses made toward video-basedanomaly detection. We address the most fundamental aspect for video anomalydetection, that is, video feature representation. Much research works have beendone in finding the right representation to perform anomaly detection in videostreams accurately with an acceptable false alarm rate. However, this is verychallenging due to large variations in environment and human movement, and highspace-time complexity due to huge dimensionality of video data. The weaklysupervised nature of deep learning algorithms can help in learningrepresentations from the video data itself instead of manually designing theright feature for specific scenes. In this paper, we would like to review theexisting methods of modeling video representations using deep learningtechniques for the task of anomaly detection and action recognition.
arxiv-10200-48 | Computational Baby Learning | http://arxiv.org/pdf/1411.2861v3.pdf | author:Xiaodan Liang, Si Liu, Yunchao Wei, Luoqi Liu, Liang Lin, Shuicheng Yan category:cs.CV published:2014-11-11 summary:Intuitive observations show that a baby may inherently possess the capabilityof recognizing a new visual concept (e.g., chair, dog) by learning from onlyvery few positive instances taught by parent(s) or others, and this recognitioncapability can be gradually further improved by exploring and/or interactingwith the real instances in the physical world. Inspired by these observations,we propose a computational model for slightly-supervised object detection,based on prior knowledge modelling, exemplar learning and learning with videocontexts. The prior knowledge is modeled with a pre-trained ConvolutionalNeural Network (CNN). When very few instances of a new concept are given, aninitial concept detector is built by exemplar learning over the deep featuresfrom the pre-trained CNN. Simulating the baby's interaction with physicalworld, the well-designed tracking solution is then used to discover morediverse instances from the massive online unlabeled videos. Once a positiveinstance is detected/identified with high score in each video, more variableinstances possibly from different view-angles and/or different distances aretracked and accumulated. Then the concept detector can be fine-tuned based onthese new instances. This process can be repeated again and again till weobtain a very mature concept detector. Extensive experiments on PascalVOC-07/10/12 object detection datasets well demonstrate the effectiveness ofour framework. It can beat the state-of-the-art full-training basedperformances by learning from very few samples for each object category, alongwith about 20,000 unlabeled videos.
arxiv-10200-49 | Learning the Structure and Parameters of Large-Population Graphical Games from Behavioral Data | http://arxiv.org/pdf/1206.3713v4.pdf | author:Jean Honorio, Luis Ortiz category:cs.LG cs.GT stat.ML published:2012-06-16 summary:We consider learning, from strictly behavioral data, the structure andparameters of linear influence games (LIGs), a class of parametric graphicalgames introduced by Irfan and Ortiz (2014). LIGs facilitate causal strategicinference (CSI): Making inferences from causal interventions on stable behaviorin strategic settings. Applications include the identification of the mostinfluential individuals in large (social) networks. Such tasks can also supportpolicy-making analysis. Motivated by the computational work on LIGs, we castthe learning problem as maximum-likelihood estimation (MLE) of a generativemodel defined by pure-strategy Nash equilibria (PSNE). Our simple formulationuncovers the fundamental interplay between goodness-of-fit and modelcomplexity: good models capture equilibrium behavior within the data whilecontrolling the true number of equilibria, including those unobserved. Weprovide a generalization bound establishing the sample complexity for MLE inour framework. We propose several algorithms including convex loss minimization(CLM) and sigmoidal approximations. We prove that the number of exact PSNE inLIGs is small, with high probability; thus, CLM is sound. We illustrate ourapproach on synthetic data and real-world U.S. congressional voting records. Webriefly discuss our learning framework's generality and potential applicabilityto general graphical games.
arxiv-10200-50 | Sequential Labeling with online Deep Learning | http://arxiv.org/pdf/1412.3397v3.pdf | author:Gang Chen, Ran Xu, Sargur Srihari category:cs.LG 68T10 I.2.6 published:2014-12-10 summary:Deep learning has attracted great attention recently and yielded the state ofthe art performance in dimension reduction and classification problems.However, it cannot effectively handle the structured output prediction, e.g.sequential labeling. In this paper, we propose a deep learning structure, whichcan learn discriminative features for sequential labeling problems. Morespecifically, we add the inter-relationship between labels in our deep learningstructure, in order to incorporate the context information from the sequentialdata. Thus, our model is more powerful than linear Conditional Random Fields(CRFs) because the objective function learns latent non-linear features so thattarget labeling can be better predicted. We pretrain the deep structure withstacked restricted Boltzmann machines (RBMs) for feature learning and optimizeour objective function with online learning algorithm, a mixture of perceptrontraining and stochastic gradient descent. We test our model on differentchallenge tasks, and show that our model outperforms significantly over thecompletive baselines.
arxiv-10200-51 | Concept Drift Detection for Streaming Data | http://arxiv.org/pdf/1504.01044v2.pdf | author:Heng Wang, Zubin Abraham category:stat.ML cs.LG published:2015-04-04 summary:Common statistical prediction models often require and assume stationarity inthe data. However, in many practical applications, changes in the relationshipof the response and predictor variables are regularly observed over time,resulting in the deterioration of the predictive performance of these models.This paper presents Linear Four Rates (LFR), a framework for detecting theseconcept drifts and subsequently identifying the data points that belong to thenew concept (for relearning the model). Unlike conventional concept driftdetection approaches, LFR can be applied to both batch and stream data; is notlimited by the distribution properties of the response variable (e.g., datasetswith imbalanced labels); is independent of the underlying statistical-model;and uses user-specified parameters that are intuitively comprehensible. Theperformance of LFR is compared to benchmark approaches using both simulated andcommonly used public datasets that span the gamut of concept drift types. Theresults show LFR significantly outperforms benchmark approaches in terms ofrecall, accuracy and delay in detection of concept drifts across datasets.
arxiv-10200-52 | Random Subspace Learning Approach to High-Dimensional Outliers Detection | http://arxiv.org/pdf/1502.04416v5.pdf | author:Bohan Liu, Ernest Fokoue category:stat.ML 62H25, 62H30 published:2015-02-16 summary:We introduce and develop a novel approach to outlier detection based onadaptation of random subspace learning. Our proposed method handles bothhigh-dimension low-sample size and traditional low-dimensional high-sample sizedatasets. Essentially, we avoid the computational bottleneck of techniques likeminimum covariance determinant (MCD) by computing the needed determinants andassociated measures in much lower dimensional subspaces. Both theoretical andcomputational development of our approach reveal that it is computationallymore efficient than the regularized methods in high-dimensional low-samplesize, and often competes favorably with existing methods as far as thepercentage of correct outlier detection is concerned.
arxiv-10200-53 | Risk Bounds For Mode Clustering | http://arxiv.org/pdf/1505.00482v1.pdf | author:Martin Azizyan, Yen-Chi Chen, Aarti Singh, Larry Wasserman category:math.ST cs.LG stat.ML stat.TH published:2015-05-03 summary:Density mode clustering is a nonparametric clustering method. The clustersare the basins of attraction of the modes of a density estimator. We study therisk of mode-based clustering. We show that the clustering risk over thecluster cores --- the regions where the density is high --- is very small evenin high dimensions. And under a low noise condition, the overall cluster riskis small even beyond the cores, in high dimensions.
arxiv-10200-54 | Kernel Spectral Clustering and applications | http://arxiv.org/pdf/1505.00477v1.pdf | author:Rocco Langone, Raghvendra Mall, Carlos Alzate, Johan A. K. Suykens category:cs.LG stat.ML published:2015-05-03 summary:In this chapter we review the main literature related to kernel spectralclustering (KSC), an approach to clustering cast within a kernel-basedoptimization setting. KSC represents a least-squares support vector machinebased formulation of spectral clustering described by a weighted kernel PCAobjective. Just as in the classifier case, the binary clustering model isexpressed by a hyperplane in a high dimensional space induced by a kernel. Inaddition, the multi-way clustering can be obtained by combining a set of binarydecision functions via an Error Correcting Output Codes (ECOC) encoding scheme.Because of its model-based nature, the KSC method encompasses three main steps:training, validation, testing. In the validation stage model selection isperformed to obtain tuning parameters, like the number of clusters present inthe data. This is a major advantage compared to classical spectral clusteringwhere the determination of the clustering parameters is unclear and relies onheuristics. Once a KSC model is trained on a small subset of the entire data,it is able to generalize well to unseen test points. Beyond the basicformulation, sparse KSC algorithms based on the Incomplete CholeskyDecomposition (ICD) and $L_0$, $L_1, L_0 + L_1$, Group Lasso regularization arereviewed. In that respect, we show how it is possible to handle large scaledata. Also, two possible ways to perform hierarchical clustering and a softclustering method are presented. Finally, real-world applications such as imagesegmentation, power load time-series clustering, document clustering and bigdata learning are considered.
arxiv-10200-55 | When Darwin meets Lorenz: Evolving new chaotic attractors through genetic programming | http://arxiv.org/pdf/1409.7842v3.pdf | author:Indranil Pan, Saptarshi Das category:nlin.CD cs.NE math.DS published:2014-09-27 summary:In this paper, we propose a novel methodology for automatically finding newchaotic attractors through a computational intelligence technique known asmulti-gene genetic programming (MGGP). We apply this technique to the case ofthe Lorenz attractor and evolve several new chaotic attractors based on thebasic Lorenz template. The MGGP algorithm automatically finds new nonlinearexpressions for the different state variables starting from the original Lorenzsystem. The Lyapunov exponents of each of the attractors are calculatednumerically based on the time series of the state variables using time delayembedding techniques. The MGGP algorithm tries to search the functional spaceof the attractors by aiming to maximise the largest Lyapunov exponent (LLE) ofthe evolved attractors. To demonstrate the potential of the proposedmethodology, we report over one hundred new chaotic attractor structures alongwith their parameters, which are evolved from just the Lorenz system alone.
arxiv-10200-56 | Some Theoretical Properties of a Network of Discretely Firing Neurons | http://arxiv.org/pdf/1505.00444v1.pdf | author:Stephen Luttrell category:cs.NE I.2.6; I.5.1 published:2015-05-03 summary:The problem of optimising a network of discretely firing neurons isaddressed. An objective function is introduced which measures the averagenumber of bits that are needed for the network to encode its state. When thisis minimised, it is shown that this leads to a number of results, such astopographic mappings, piecewise linear dependence on the input of theprobability of a neuron firing, and factorial encoder networks.
arxiv-10200-57 | Object Class Detection and Classification using Multi Scale Gradient and Corner Point based Shape Descriptors | http://arxiv.org/pdf/1505.00432v1.pdf | author:Basura Fernando, Sezer Karaoglu, Sajib Kumar Saha category:cs.CV published:2015-05-03 summary:This paper presents a novel multi scale gradient and a corner point basedshape descriptors. The novel multi scale gradient based shape descriptor iscombined with generic Fourier descriptors to extract contour and region basedshape information. Shape information based object class detection andclassification technique with a random forest classifier has been optimized.Proposed integrated descriptor in this paper is robust to rotation, scale,translation, affine deformations, noisy contours and noisy shapes. The newcorner point based interpolated shape descriptor has been exploited for fastobject detection and classification with higher accuracy.
arxiv-10200-58 | Electron Neutrino Classification in Liquid Argon Time Projection Chamber Detector | http://arxiv.org/pdf/1505.00424v1.pdf | author:Piotr Płoński, Dorota Stefan, Robert Sulej, Krzysztof Zaremba category:cs.CV published:2015-05-03 summary:Neutrinos are one of the least known elementary particles. The detection ofneutrinos is an extremely difficult task since they are affected only by weaksub-atomic force or gravity. Therefore large detectors are constructed toreveal neutrino's properties. Among them the Liquid Argon Time ProjectionChamber (LAr-TPC) detectors provide excellent imaging and particleidentification ability for studying neutrinos. The computerized methods forautomatic reconstruction and identification of particles are needed to fullyexploit the potential of the LAr-TPC technique. Herein, the novel method forelectron neutrino classification is presented. The method constructs a featuredescriptor from images of observed event. It characterizes the signaldistribution propagated from vertex of interest, where the particle interactswith the detector medium. The classifier is learned with a constructed featuredescriptor to decide whether the images represent the electron neutrino orcascade produced by photons. The proposed approach assumes that the position ofprimary interaction vertex is known. The method's performance in dependency tothe noise in a primary vertex position and deposited energy of particles isstudied.
arxiv-10200-59 | Bio-inspired Unsupervised Learning of Visual Features Leads to Robust Invariant Object Recognition | http://arxiv.org/pdf/1504.03871v2.pdf | author:Saeed Reza Kheradpisheh, Mohammad Ganjtabesh, Timothée Masquelier category:cs.CV q-bio.NC published:2015-04-15 summary:Retinal image of surrounding objects varies tremendously due to the changesin position, size, pose, illumination condition, background context, occlusion,noise, and nonrigid deformations. But despite these huge variations, our visualsystem is able to invariantly recognize any object in just a fraction of asecond. To date, various computational models have been proposed to mimic thehierarchical processing of the ventral visual pathway, with limited success.Here, we show that combining a biologically inspired network architecture witha biologically inspired learning rule significantly improves the models'performance when facing challenging object recognition problems. Our model isan asynchronous feedforward spiking neural network. When the network ispresented with natural images, the neurons in the entry layers detect edges,and the most activated ones fire first, while neurons in higher layers areequipped with spike timing-dependent plasticity. These neurons progressivelybecome selective to intermediate complexity visual features appropriate forobject categorization, as demonstrated using the 3D Object dataset provided bySavarese et al. at CVGLab, Stanford University. The model reached 96%categorization accuracy, which corresponds to two to three times fewer errorsthan the previous state-of-the-art, demonstrating that it is able to accuratelyrecognize different instances of multiple object classes in various appearanceconditions (different views, scales, tilts, and backgrounds). Severalstatistical analysis techniques are used to show that our model extracts classspecific and highly informative features.
arxiv-10200-60 | Optimal Time-Series Motifs | http://arxiv.org/pdf/1505.00423v1.pdf | author:Josif Grabocka, Nicolas Schilling, Lars Schmidt-Thieme category:cs.AI cs.LG published:2015-05-03 summary:Motifs are the most repetitive/frequent patterns of a time-series. Thediscovery of motifs is crucial for practitioners in order to understand andinterpret the phenomena occurring in sequential data. Currently, motifs aresearched among series sub-sequences, aiming at selecting the most frequentlyoccurring ones. Search-based methods, which try out series sub-sequence asmotif candidates, are currently believed to be the best methods in finding themost frequent patterns. However, this paper proposes an entirely new perspective in finding motifs.We demonstrate that searching is non-optimal since the domain of motifs isrestricted, and instead we propose a principled optimization approach able tofind optimal motifs. We treat the occurrence frequency as a function andtime-series motifs as its parameters, therefore we \textit{learn} the optimalmotifs that maximize the frequency function. In contrast to searching, ourmethod is able to discover the most repetitive patterns (hence optimal), evenin cases where they do not explicitly occur as sub-sequences. Experiments onseveral real-life time-series datasets show that the motifs found by our methodare highly more frequent than the ones found through searching, for exactly thesame distance threshold.
arxiv-10200-61 | Permutohedral Lattice CNNs | http://arxiv.org/pdf/1412.6618v3.pdf | author:Martin Kiefel, Varun Jampani, Peter V. Gehler category:cs.CV cs.LG cs.NE published:2014-12-20 summary:This paper presents a convolutional layer that is able to process sparseinput features. As an example, for image recognition problems this allows anefficient filtering of signals that do not lie on a dense grid (like pixelposition), but of more general features (such as color values). The presentedalgorithm makes use of the permutohedral lattice data structure. Thepermutohedral lattice was introduced to efficiently implement a bilateralfilter, a commonly used image processing operation. Its use allows for ageneralization of the convolution type found in current (spatial) convolutionalnetwork architectures.
arxiv-10200-62 | On a fast bilateral filtering formulation using functional rearrangements | http://arxiv.org/pdf/1505.00412v1.pdf | author:Gonzalo Galiano, Julián Velasco category:cs.CV 68U10 published:2015-05-03 summary:We introduce an exact reformulation of a broad class of neighborhood filters,among which the bilateral filters, in terms of two functional rearrangements:the decreasing and the relative rearrangements. Independently of the image spatial dimension (one-dimensional signal, image,volume of images, etc.), we reformulate these filters as integral operatorsdefined in a one-dimensional space corresponding to the level sets measures. We prove the equivalence between the usual pixel-based version and therearranged version of the filter. When restricted to the discrete setting, ourreformulation of bilateral filters extends previous results for the so-calledfast bilateral filtering. We, in addition, prove that the solution of thediscrete setting, understood as constant-wise interpolators, converges to thesolution of the continuous setting. Finally, we numerically illustrate computational aspects concerning qualityapproximation and execution time provided by the rearranged formulation.
arxiv-10200-63 | Sample Size Planning for Classification Models | http://arxiv.org/pdf/1211.1323v3.pdf | author:Claudia Beleites, Ute Neugebauer, Thomas Bocklitz, Christoph Krafft, Jürgen Popp category:stat.AP stat.ME stat.ML G.3 published:2012-11-06 summary:In biospectroscopy, suitably annotated and statistically independent samples(e. g. patients, batches, etc.) for classifier training and testing are scarceand costly. Learning curves show the model performance as function of thetraining sample size and can help to determine the sample size needed to traingood classifiers. However, building a good model is actually not enough: theperformance must also be proven. We discuss learning curves for typical smallsample size situations with 5 - 25 independent samples per class. Although theclassification models achieve acceptable performance, the learning curve can becompletely masked by the random testing uncertainty due to the equally limitedtest sample size. In consequence, we determine test sample sizes necessary toachieve reasonable precision in the validation and find that 75 - 100 sampleswill usually be needed to test a good but not perfect classifier. Such a dataset will then allow refined sample size planning on the basis of the achievedperformance. We also demonstrate how to calculate necessary sample sizes inorder to show the superiority of one classifier over another: this oftenrequires hundreds of statistically independent test samples or is eventheoretically impossible. We demonstrate our findings with a data set of ca.2550 Raman spectra of single cells (five classes: erythrocytes, leukocytes andthree tumour cell lines BT-20, MCF-7 and OCI-AML3) as well as by an extensivesimulation that allows precise determination of the actual performance of themodels in question.
arxiv-10200-64 | LABR: A Large Scale Arabic Sentiment Analysis Benchmark | http://arxiv.org/pdf/1411.6718v2.pdf | author:Mahmoud Nabil, Mohamed Aly, Amir Atiya category:cs.CL cs.LG published:2014-11-25 summary:We introduce LABR, the largest sentiment analysis dataset to-date for theArabic language. It consists of over 63,000 book reviews, each rated on a scaleof 1 to 5 stars. We investigate the properties of the dataset, and present itsstatistics. We explore using the dataset for two tasks: (1) sentiment polarityclassification; and (2) ratings classification. Moreover, we provide standardsplits of the dataset into training, validation and testing, for both polarityand ratings classification, in both balanced and unbalanced settings. We extendour previous work by performing a comprehensive analysis on the dataset. Inparticular, we perform an extended survey of the different classifierstypically used for the sentiment polarity classification problem. We alsoconstruct a sentiment lexicon from the dataset that contains both single andcompound sentiment words and we explore its effectiveness. We make the datasetand experimental details publicly available.
arxiv-10200-65 | Visualization of Tradeoff in Evaluation: from Precision-Recall & PN to LIFT, ROC & BIRD | http://arxiv.org/pdf/1505.00401v1.pdf | author:David M. W. Powers category:cs.LG cs.AI cs.IR stat.ME stat.ML published:2015-05-03 summary:Evaluation often aims to reduce the correctness or error characteristics of asystem down to a single number, but that always involves trade-offs. Anotherway of dealing with this is to quote two numbers, such as Recall and Precision,or Sensitivity and Specificity. But it can also be useful to see more thanthis, and a graphical approach can explore sensitivity to cost, prevalence,bias, noise, parameters and hyper-parameters. Moreover, most techniques are implicitly based on two balanced classes, andour ability to visualize graphically is intrinsically two dimensional, but weoften want to visualize in a multiclass context. We review the dichotomousapproaches relating to Precision, Recall, and ROC as well as the related LIFTchart, exploring how they handle unbalanced and multiclass data, and derivingnew probabilistic and information theoretic variants of LIFT that help dealwith the issues associated with the handling of multiple and unbalancedclasses.
arxiv-10200-66 | Structured Block Basis Factorization for Scalable Kernel Matrix Evaluation | http://arxiv.org/pdf/1505.00398v1.pdf | author:Ruoxi Wang, Yingzhou Li, Michael W. Mahoney, Eric Darve category:stat.ML cs.LG cs.NA published:2015-05-03 summary:Kernel matrices are popular in machine learning and scientific computing, butthey are limited by their quadratic complexity in both construction andstorage. It is well-known that as one varies the kernel parameter, e.g., thewidth parameter in radial basis function kernels, the kernel matrix changesfrom a smooth low-rank kernel to a diagonally-dominant and then fully-diagonalkernel. Low-rank approximation methods have been widely-studied, mostly in thefirst case, to reduce the memory storage and the cost of computingmatrix-vector products. Here, we use ideas from scientific computing to proposean extension of these methods to situations where the matrix is notwell-approximated by a low-rank matrix. In particular, we construct anefficient block low-rank approximation method---which we call the Block BasisFactorization---and we show that it has $\mathcal{O}(n)$ complexity in bothtime and memory. Our method works for a wide range of kernel parameters,extending the domain of applicability of low-rank approximation methods, andour empirical results demonstrate the stability (small standard deviation inerror) and superiority over current state-of-art kernel approximationalgorithms.
arxiv-10200-67 | Detail-preserving and Content-aware Variational Multi-view Stereo Reconstruction | http://arxiv.org/pdf/1505.00389v1.pdf | author:Zhaoxin Li, Kuanquan Wang, Wangmeng Zuo, Deyu Meng, Lei Zhang category:cs.CV published:2015-05-03 summary:Accurate recovery of 3D geometrical surfaces from calibrated 2D multi-viewimages is a fundamental yet active research area in computer vision. Despitethe steady progress in multi-view stereo reconstruction, most existing methodsare still limited in recovering fine-scale details and sharp features whilesuppressing noises, and may fail in reconstructing regions with few textures.To address these limitations, this paper presents a Detail-preserving andContent-aware Variational (DCV) multi-view stereo method, which reconstructsthe 3D surface by alternating between reprojection error minimization and meshdenoising. In reprojection error minimization, we propose a novel inter-imagesimilarity measure, which is effective to preserve fine-scale details of thereconstructed surface and builds a connection between guided image filteringand image registration. In mesh denoising, we propose a content-aware$\ell_{p}$-minimization algorithm by adaptively estimating the $p$ value andregularization parameters based on the current input. It is much more promisingin suppressing noise while preserving sharp features than conventionalisotropic mesh smoothing. Experimental results on benchmark datasetsdemonstrate that our DCV method is capable of recovering more surface details,and obtains cleaner and more accurate reconstructions than state-of-the-artmethods. In particular, our method achieves the best results among allpublished methods on the Middlebury dino ring and dino sparse ring datasets interms of both completeness and accuracy.
arxiv-10200-68 | Order-Revealing Encryption and the Hardness of Private Learning | http://arxiv.org/pdf/1505.00388v1.pdf | author:Mark Bun, Mark Zhandry category:cs.CR cs.CC cs.LG published:2015-05-03 summary:An order-revealing encryption scheme gives a public procedure by which twociphertexts can be compared to reveal the ordering of their underlyingplaintexts. We show how to use order-revealing encryption to separatecomputationally efficient PAC learning from efficient $(\epsilon,\delta)$-differentially private PAC learning. That is, we construct a conceptclass that is efficiently PAC learnable, but for which every efficient learnerfails to be differentially private. This answers a question of Kasiviswanathanet al. (FOCS '08, SIAM J. Comput. '11). To prove our result, we give a generic transformation from an order-revealingencryption scheme into one with strongly correct comparison, which enables theconsistent comparison of ciphertexts that are not obtained as the validencryption of any message. We believe this construction may be of independentinterest.
arxiv-10200-69 | Making Sense of Hidden Layer Information in Deep Networks by Learning Hierarchical Targets | http://arxiv.org/pdf/1505.00384v1.pdf | author:Abhinav Tushar category:cs.NE cs.LG published:2015-05-03 summary:This paper proposes an architecture for deep neural networks with hiddenlayer branches that learn targets of lower hierarchy than final layer targets.The branches provide a channel for enforcing useful information in hidden layerwhich helps in attaining better accuracy, both for the final layer and hiddenlayers. The shared layers modify their weights using the gradients of all costfunctions higher than the branching layer. This model provides a flexibleinference system with many levels of targets which is modular and can be usedefficiently in situations requiring different levels of results according tocomplexity. This paper applies the idea to a text classification task on 20Newsgroups data set with two level of hierarchical targets and a comparison ismade with training without the use of hidden layer branches.
arxiv-10200-70 | Modeling Compositionality with Multiplicative Recurrent Neural Networks | http://arxiv.org/pdf/1412.6577v3.pdf | author:Ozan İrsoy, Claire Cardie category:cs.LG cs.CL stat.ML published:2014-12-20 summary:We present the multiplicative recurrent neural network as a general model forcompositional meaning in language, and evaluate it on the task of fine-grainedsentiment analysis. We establish a connection to the previously investigatedmatrix-space models for compositionality, and show they are special cases ofthe multiplicative recurrent net. Our experiments show that these modelsperform comparably or better than Elman-type additive recurrent neural networksand outperform matrix-space models on a standard fine-grained sentimentanalysis corpus. Furthermore, they yield comparable results to structural deepmodels on the recently published Stanford Sentiment Treebank without the needfor generating parse trees.
arxiv-10200-71 | Joint Multi-Leaf Segmentation, Alignment and Tracking from Fluorescence Plant Videos | http://arxiv.org/pdf/1505.00353v1.pdf | author:Xi Yin, Xiaoming Liu, Jin Chen, David M. Kramer category:cs.CV published:2015-05-02 summary:This paper proposes a novel framework for fluorescence plant videoprocessing. Biologists are interested in the leaf level photosynthetic analysiswithin a plant. A prerequisite for such analysis is to segment all leaves,estimate their structures and track them over time. We treat this as a jointmulti-leaf segmentation, alignment, and tracking problem. First, leafsegmentation and alignment are applied on the last frame of a plant video tofind a number of well-aligned leaf candidates. Second, leaf tracking is appliedon the remaining frames with leaf candidate transformation from the previousframe. We form two optimization problems with shared terms in their objectivefunctions for leaf alignment and tracking respectively. Gradient descent isused to solve the proposed optimization problems. A quantitative evaluationframework is formulated to evaluate the performance of our algorithm with threemetrics. Two models are learned to predict the alignment accuracy and detecttracking failure respectively. We also study the limitation of our proposedalignment and tracking framework. Experimental results show the effectiveness,efficiency, and robustness of the proposed method.
arxiv-10200-72 | Learning Temporal Embeddings for Complex Video Analysis | http://arxiv.org/pdf/1505.00315v1.pdf | author:Vignesh Ramanathan, Kevin Tang, Greg Mori, Li Fei-Fei category:cs.CV published:2015-05-02 summary:In this paper, we propose to learn temporal embeddings of video frames forcomplex video analysis. Large quantities of unlabeled video data can be easilyobtained from the Internet. These videos possess the implicit weak label thatthey are sequences of temporally and semantically coherent images. We leveragethis information to learn temporal embeddings for video frames by associatingframes with the temporal context that they appear in. To do this, we propose ascheme for incorporating temporal context based on past and future frames invideos, and compare this to other contextual representations. In addition, weshow how data augmentation using multi-resolution samples and hard negativeshelps to significantly improve the quality of the learned embeddings. Weevaluate various design decisions for learning temporal embeddings, and showthat our embeddings can improve performance for multiple video tasks such asretrieval, classification, and temporal order recovery in unconstrainedInternet video.
arxiv-10200-73 | Deconstructing Principal Component Analysis Using a Data Reconciliation Perspective | http://arxiv.org/pdf/1505.00314v1.pdf | author:Shankar Narasimhan, Nirav Bhatt category:cs.LG cs.SY stat.ME I.2 published:2015-05-02 summary:Data reconciliation (DR) and Principal Component Analysis (PCA) are twopopular data analysis techniques in process industries. Data reconciliation isused to obtain accurate and consistent estimates of variables and parametersfrom erroneous measurements. PCA is primarily used as a method for reducing thedimensionality of high dimensional data and as a preprocessing technique fordenoising measurements. These techniques have been developed and deployedindependently of each other. The primary purpose of this article is toelucidate the close relationship between these two seemingly disparatetechniques. This leads to a unified framework for applying PCA and DR. Further,we show how the two techniques can be deployed together in a collaborative andconsistent manner to process data. The framework has been extended to deal withpartially measured systems and to incorporate partial knowledge available aboutthe process model.
arxiv-10200-74 | Advanced Mean Field Theory of Restricted Boltzmann Machine | http://arxiv.org/pdf/1502.00186v3.pdf | author:Haiping Huang, Taro Toyoizumi category:cs.LG q-bio.NC stat.ML published:2015-02-01 summary:Learning in restricted Boltzmann machine is typically hard due to thecomputation of gradients of log-likelihood function. To describe the networkstate statistics of the restricted Boltzmann machine, we develop an advancedmean field theory based on the Bethe approximation. Our theory provides anefficient message passing based method that evaluates not only the partitionfunction (free energy) but also its gradients without requiring statisticalsampling. The results are compared with those obtained by the computationallyexpensive sampling based method.
arxiv-10200-75 | Multi-Object Classification and Unsupervised Scene Understanding Using Deep Learning Features and Latent Tree Probabilistic Models | http://arxiv.org/pdf/1505.00308v1.pdf | author:Tejaswi Nimmagadda, Anima Anandkumar category:cs.CV cs.LG published:2015-05-02 summary:Deep learning has shown state-of-art classification performance on datasetssuch as ImageNet, which contain a single object in each image. However,multi-object classification is far more challenging. We present a unifiedframework which leverages the strengths of multiple machine learning methods,viz deep learning, probabilistic models and kernel methods to obtainstate-of-art performance on Microsoft COCO, consisting of non-iconic images. Weincorporate contextual information in natural images through a conditionallatent tree probabilistic model (CLTM), where the object co-occurrences areconditioned on the extracted fc7 features from pre-trained Imagenet CNN asinput. We learn the CLTM tree structure using conditional pairwiseprobabilities for object co-occurrences, estimated through kernel methods, andwe learn its node and edge potentials by training a new 3-layer neural network,which takes fc7 features as input. Object classification is carried out viainference on the learnt conditional tree model, and we obtain significant gainin precision-recall and F-measures on MS-COCO, especially for difficult objectcategories. Moreover, the latent variables in the CLTM capture sceneinformation: the images with top activations for a latent node have commonthemes such as being a grasslands or a food scene, and on on. In addition, weshow that a simple k-means clustering of the inferred latent nodes alonesignificantly improves scene classification performance on the MIT-Indoordataset, without the need for any retraining, and without using scene labelsduring training. Thus, we present a unified framework for multi-objectclassification and unsupervised scene understanding.
arxiv-10200-76 | Object-Scene Convolutional Neural Networks for Event Recognition in Images | http://arxiv.org/pdf/1505.00296v1.pdf | author:Limin Wang, Zhe Wang, Wenbin Du, Yu Qiao category:cs.CV published:2015-05-02 summary:Event recognition from still images is of great importance for imageunderstanding. However, compared with event recognition in videos, there aremuch fewer research works on event recognition in images. This paper addressesthe issue of event recognition from images and proposes an effective methodwith deep neural networks. Specifically, we design a new architecture, calledObject-Scene Convolutional Neural Network (OS-CNN). This architecture isdecomposed into object net and scene net, which extract useful information forevent understanding from the perspective of objects and scene context,respectively. Meanwhile, we investigate different network architectures forOS-CNN design, and adapt the deep (AlexNet) and very-deep (GoogLeNet) networksto the task of event recognition. Furthermore, we find that the deep andvery-deep networks are complementary to each other. Finally, based on theproposed OS-CNN and comparative study of different network architectures, wecome up with a solution of five-stream CNN for the track of cultural eventrecognition at the ChaLearn Looking at People (LAP) challenge 2015. Our methodobtains the performance of 85.5% and ranks the $1^{st}$ place in thischallenge.
arxiv-10200-77 | Monotonous (Semi-)Nonnegative Matrix Factorization | http://arxiv.org/pdf/1505.00294v1.pdf | author:Nirav Bhatt, Arun Ayyar category:cs.LG stat.ML I.2 published:2015-05-01 summary:Nonnegative matrix factorization (NMF) factorizes a non-negative matrix intoproduct of two non-negative matrices, namely a signal matrix and a mixingmatrix. NMF suffers from the scale and ordering ambiguities. Often, the sourcesignals can be monotonous in nature. For example, in source separation problem,the source signals can be monotonously increasing or decreasing while themixing matrix can have nonnegative entries. NMF methods may not be effectivefor such cases as it suffers from the ordering ambiguity. This paper proposesan approach to incorporate notion of monotonicity in NMF, labeled as monotonousNMF. An algorithm based on alternating least-squares is proposed for recoveringmonotonous signals from a data matrix. Further, the assumption on mixing matrixis relaxed to extend monotonous NMF for data matrix with real numbers asentries. The approach is illustrated using synthetic noisy data. The resultsobtained by monotonous NMF are compared with standard NMF algorithms in theliterature, and it is shown that monotonous NMF estimates source signals wellin comparison to standard NMF algorithms when the underlying sources signalsare monotonous.
arxiv-10200-78 | Grounded Discovery of Coordinate Term Relationships between Software Entities | http://arxiv.org/pdf/1505.00277v1.pdf | author:Dana Movshovitz-Attias, William W. Cohen category:cs.CL cs.AI cs.LG cs.SE published:2015-05-01 summary:We present an approach for the detection of coordinate-term relationshipsbetween entities from the software domain, that refer to Java classes. Usually,relations are found by examining corpus statistics associated with textentities. In some technical domains, however, we have access to additionalinformation about the real-world objects named by the entities, suggesting thatcoupling information about the "grounded" entities with corpus statistics mightlead to improved methods for relation discovery. To this end, we develop asimilarity measure for Java classes using distributional information about howthey are used in software, which we combine with corpus statistics on thedistribution of contexts in which the classes appear in text. Using ourapproach, cross-validation accuracy on this dataset can be improveddramatically, from around 60% to 88%. Human labeling results show that ourclassifier has an F1 score of 86% over the top 1000 predicted pairs.
arxiv-10200-79 | Joint Object and Part Segmentation using Deep Learned Potentials | http://arxiv.org/pdf/1505.00276v1.pdf | author:Peng Wang, Xiaohui Shen, Zhe Lin, Scott Cohen, Brian Price, Alan Yuille category:cs.CV published:2015-05-01 summary:Segmenting semantic objects from images and parsing them into theirrespective semantic parts are fundamental steps towards detailed objectunderstanding in computer vision. In this paper, we propose a joint solutionthat tackles semantic object and part segmentation simultaneously, in whichhigher object-level context is provided to guide part segmentation, and moredetailed part-level localization is utilized to refine object segmentation.Specifically, we first introduce the concept of semantic compositional parts(SCP) in which similar semantic parts are grouped and shared among differentobjects. A two-channel fully convolutional network (FCN) is then trained toprovide the SCP and object potentials at each pixel. At the same time, acompact set of segments can also be obtained from the SCP predictions of thenetwork. Given the potentials and the generated segments, in order to explorelong-range context, we finally construct an efficient fully connectedconditional random field (FCRF) to jointly predict the final object and partlabels. Extensive evaluation on three different datasets shows that ourapproach can mutually enhance the performance of object and part segmentation,and outperforms the current state-of-the-art on both tasks.
arxiv-10200-80 | Image Segmentation by Size-Dependent Single Linkage Clustering of a Watershed Basin Graph | http://arxiv.org/pdf/1505.00249v1.pdf | author:Aleksandar Zlateski, H. Sebastian Seung category:cs.CV published:2015-05-01 summary:We present a method for hierarchical image segmentation that defines adisaffinity graph on the image, over-segments it into watershed basins, definesa new graph on the basins, and then merges basins with a modified,size-dependent version of single linkage clustering. The quasilinear runtime ofthe method makes it suitable for segmenting large images. We illustrate themethod on the challenging problem of segmenting 3D electron microscopic brainimages.
arxiv-10200-81 | Probabilistic Depth Image Registration incorporating Nonvisual Information | http://arxiv.org/pdf/1504.07857v2.pdf | author:Manuel Wüthrich, Peter Pastor, Ludovic Righetti, Aude Billard, Stefan Schaal category:cs.RO cs.CV published:2015-04-29 summary:In this paper, we derive a probabilistic registration algorithm for objectmodeling and tracking. In many robotics applications, such as manipulationtasks, nonvisual information about the movement of the object is available,which we will combine with the visual information. Furthermore we do not onlyconsider observations of the object, but we also take space into account whichhas been observed to not be part of the object. Furthermore we are computing aposterior distribution over the relative alignment and not a point estimate astypically done in for example Iterative Closest Point (ICP). To our knowledgeno existing algorithm meets these three conditions and we thus derive a novelregistration algorithm in a Bayesian framework. Experimental results suggestthat the proposed methods perform favorably in comparison to PCLimplementations of feature mapping and ICP, especially if nonvisual informationis available.
arxiv-10200-82 | Volumetric Bias in Segmentation and Reconstruction: Secrets and Solutions | http://arxiv.org/pdf/1505.00218v1.pdf | author:Yuri Boykov, Hossam Isack, Carl Olsson, Ismail Ben Ayed category:cs.CV published:2015-05-01 summary:Many standard optimization methods for segmentation and reconstructioncompute ML model estimates for appearance or geometry of segments, e.g.Zhu-Yuille 1996, Torr 1998, Chan-Vese 2001, GrabCut 2004, Delong et al. 2012.We observe that the standard likelihood term in these formulations correspondsto a generalized probabilistic K-means energy. In learning it is well knownthat this energy has a strong bias to clusters of equal size, which can beexpressed as a penalty for KL divergence from a uniform distribution ofcardinalities. However, this volumetric bias has been mostly ignored incomputer vision. We demonstrate significant artifacts in standard segmentationand reconstruction methods due to this bias. Moreover, we propose binary andmulti-label optimization techniques that either (a) remove this bias or (b)replace it by a KL divergence term for any given target volume distribution.Our general ideas apply to many continuous or discrete energy formulations insegmentation, stereo, and other reconstruction problems.
arxiv-10200-83 | Topic Extraction and Bundling of Related Scientific Articles | http://arxiv.org/pdf/1212.5423v2.pdf | author:Shameem A Puthiya Parambath category:cs.IR cs.DL stat.ML published:2012-12-21 summary:Automatic classification of scientific articles based on commoncharacteristics is an interesting problem with many applications in digitallibrary and information retrieval systems. Properly organized articles can beuseful for automatic generation of taxonomies in scientific writings, textualsummarization, efficient information retrieval etc. Generating article bundlesfrom a large number of input articles, based on the associated features of thearticles is tedious and computationally expensive task. In this report wepropose an automatic two-step approach for topic extraction and bundling ofrelated articles from a set of scientific articles in real-time. For topicextraction, we make use of Latent Dirichlet Allocation (LDA) topic modelingtechniques and for bundling, we make use of hierarchical agglomerativeclustering techniques. We run experiments to validate our bundling semantics and compare it withexisting models in use. We make use of an online crowdsourcing marketplaceprovided by Amazon called Amazon Mechanical Turk to carry out experiments. Weexplain our experimental setup and empirical results in detail and show thatour method is advantageous over existing ones.
arxiv-10200-84 | Segmentation and Restoration of Images on Surfaces by Parametric Active Contours with Topology Changes | http://arxiv.org/pdf/1505.00193v1.pdf | author:Heike Benninghoff, Harald Garcke category:cs.CV math.AP math.NA published:2015-05-01 summary:In this article, a new method for segmentation and restoration of images ontwo-dimensional surfaces is given. Active contour models for image segmentationare extended to images on surfaces. The evolving curves on the surfaces aremathematically described using a parametric approach. For image restoration, adiffusion equation with Neumann boundary conditions is solved in apostprocessing step in the individual regions. Numerical schemes are presentedwhich allow to efficiently compute segmentations and denoised versions ofimages on surfaces. Also topology changes of the evolving curves are detectedand performed using a fast sub-routine. Finally, several experiments arepresented where the developed methods are applied on different artificial andreal images defined on different surfaces.
arxiv-10200-85 | SynthCam3D: Semantic Understanding With Synthetic Indoor Scenes | http://arxiv.org/pdf/1505.00171v1.pdf | author:Ankur Handa, Viorica Patraucean, Vijay Badrinarayanan, Simon Stent, Roberto Cipolla category:cs.CV published:2015-05-01 summary:We are interested in automatic scene understanding from geometric cues. Tothis end, we aim to bring semantic segmentation in the loop of real-timereconstruction. Our semantic segmentation is built on a deep autoencoder stacktrained exclusively on synthetic depth data generated from our novel 3D scenelibrary, SynthCam3D. Importantly, our network is able to segment real worldscenes without any noise modelling. We present encouraging preliminary results.
arxiv-10200-86 | Embedding Semantic Relations into Word Representations | http://arxiv.org/pdf/1505.00161v1.pdf | author:Danushka Bollegala, Takanori Maehara, Ken-ichi Kawarabayashi category:cs.CL published:2015-05-01 summary:Learning representations for semantic relations is important for varioustasks such as analogy detection, relational search, and relationclassification. Although there have been several proposals for learningrepresentations for individual words, learning word representations thatexplicitly capture the semantic relations between words remains underdeveloped. We propose an unsupervised method for learning vectorrepresentations for words such that the learnt representations are sensitive tothe semantic relations that exist between two words. First, we extract lexicalpatterns from the co-occurrence contexts of two words in a corpus to representthe semantic relations that exist between those two words. Second, we representa lexical pattern as the weighted sum of the representations of the words thatco-occur with that lexical pattern. Third, we train a binary classifier todetect relationally similar vs. non-similar lexical pattern pairs. The proposedmethod is unsupervised in the sense that the lexical pattern pairs we use astrain data are automatically sampled from a corpus, without requiring anymanual intervention. Our proposed method statistically significantlyoutperforms the current state-of-the-art word representations on threebenchmark datasets for proportional analogy detection, demonstrating itsability to accurately capture the semantic relations among words.
arxiv-10200-87 | Thompson Sampling for Budgeted Multi-armed Bandits | http://arxiv.org/pdf/1505.00146v1.pdf | author:Yingce Xia, Haifang Li, Tao Qin, Nenghai Yu, Tie-Yan Liu category:cs.LG published:2015-05-01 summary:Thompson sampling is one of the earliest randomized algorithms formulti-armed bandits (MAB). In this paper, we extend the Thompson sampling toBudgeted MAB, where there is random cost for pulling an arm and the total costis constrained by a budget. We start with the case of Bernoulli bandits, inwhich the random rewards (costs) of an arm are independently sampled from aBernoulli distribution. To implement the Thompson sampling algorithm in thiscase, at each round, we sample two numbers from the posterior distributions ofthe reward and cost for each arm, obtain their ratio, select the arm with themaximum ratio, and then update the posterior distributions. We prove that thedistribution-dependent regret bound of this algorithm is $O(\ln B)$, where $B$denotes the budget. By introducing a Bernoulli trial, we further extend thisalgorithm to the setting that the rewards (costs) are drawn from generaldistributions, and prove that its regret bound remains almost the same. Oursimulation results demonstrate the effectiveness of the proposed algorithm.
arxiv-10200-88 | Quality Control in Crowdsourced Object Segmentation | http://arxiv.org/pdf/1505.00145v1.pdf | author:Ferran Cabezas, Axel Carlier, Amaia Salvador, Xavier Giró-i-Nieto, Vincent Charvillat category:cs.CV cs.HC published:2015-05-01 summary:This paper explores processing techniques to deal with noisy data incrowdsourced object segmentation tasks. We use the data collected with"Click'n'Cut", an online interactive segmentation tool, and we perform severalexperiments towards improving the segmentation results. First, we introducedifferent superpixel-based techniques to filter users' traces, and assess theirimpact on the segmentation result. Second, we present different criteria todetect and discard the traces from potential bad users, resulting in aremarkable increase in performance. Finally, we show a novel superpixel-basedsegmentation algorithm which does not require any prior filtering and is basedon weighting each user's contribution according to his/her level of expertise.
arxiv-10200-89 | Word Representations via Gaussian Embedding | http://arxiv.org/pdf/1412.6623v4.pdf | author:Luke Vilnis, Andrew McCallum category:cs.CL cs.LG published:2014-12-20 summary:Current work in lexical distributed representations maps each word to a pointvector in low-dimensional space. Mapping instead to a density provides manyinteresting advantages, including better capturing uncertainty about arepresentation and its relationships, expressing asymmetries more naturallythan dot product or cosine similarity, and enabling more expressiveparameterization of decision boundaries. This paper advocates for density-baseddistributed embeddings and presents a method for learning representations inthe space of Gaussian distributions. We compare performance on various wordembedding benchmarks, investigate the ability of these embeddings to modelentailment and other asymmetric relationships, and explore novel properties ofthe representation.
arxiv-10200-90 | Compositional Distributional Semantics with Compact Closed Categories and Frobenius Algebras | http://arxiv.org/pdf/1505.00138v1.pdf | author:Dimitri Kartsaklis category:cs.CL cs.AI math.CT math.QA quant-ph published:2015-05-01 summary:This thesis contributes to ongoing research related to the categoricalcompositional model for natural language of Coecke, Sadrzadeh and Clark inthree ways: Firstly, I propose a concrete instantiation of the abstractframework based on Frobenius algebras (joint work with Sadrzadeh). The theoryimproves shortcomings of previous proposals, extends the coverage of thelanguage, and is supported by experimental work that improves existing results.The proposed framework describes a new class of compositional models that findintuitive interpretations for a number of linguistic phenomena. Secondly, Ipropose and evaluate in practice a new compositional methodology whichexplicitly deals with the different levels of lexical ambiguity (joint workwith Pulman). A concrete algorithm is presented, based on the separation ofvector disambiguation from composition in an explicit prior step. Extensiveexperimental work shows that the proposed methodology indeed results in moreaccurate composite representations for the framework of Coecke et al. inparticular and every other class of compositional models in general. As a lastcontribution, I formalize the explicit treatment of lexical ambiguity in thecontext of the categorical framework by resorting to categorical quantummechanics (joint work with Coecke). In the proposed extension, the concept of adistributional vector is replaced with that of a density matrix, whichcompactly represents a probability distribution over the potential differentmeanings of the specific word. Composition takes the form of quantummeasurements, leading to interesting analogies between quantum physics andlinguistics.
arxiv-10200-91 | The Cross-Depiction Problem: Computer Vision Algorithms for Recognising Objects in Artwork and in Photographs | http://arxiv.org/pdf/1505.00110v1.pdf | author:Hongping Cai, Qi Wu, Tadeo Corradi, Peter Hall category:cs.CV 68745 I.2.10 published:2015-05-01 summary:The cross-depiction problem is that of recognising visual objects regardlessof whether they are photographed, painted, drawn, etc. It is a potentiallysignificant yet under-researched problem. Emulating the remarkable humanability to recognise objects in an astonishingly wide variety of depictiveforms is likely to advance both the foundations and the applications ofComputer Vision. In this paper we benchmark classification, domain adaptation, and deeplearning methods; demonstrating that none perform consistently well in thecross-depiction problem. Given the current interest in deep learning, the factsuch methods exhibit the same behaviour as all but one other method: they showa significant fall in performance over inhomogeneous databases compared totheir peak performance, which is always over data comprising photographs only.Rather, we find the methods that have strong models of spatial relationsbetween parts tend to be more robust and therefore conclude that suchinformation is important in modelling object classes regardless of appearancedetails.
arxiv-10200-92 | A Cooperative Framework for Fireworks Algorithm | http://arxiv.org/pdf/1505.00075v1.pdf | author:Shaoqiu Zheng, Junzhi Li, Andreas Janecek, Ying Tan category:cs.NE published:2015-05-01 summary:This paper presents a cooperative framework for fireworks algorithm (CoFFWA).A detailed analysis of existing fireworks algorithm (FWA) and its recentlydeveloped variants has revealed that (i) the selection strategy lead to thecontribution of the firework with the best fitness (core firework) for theoptimization overwhelms the contributions of the rest of fireworks (non-corefireworks) in the explosion operator, (ii) the Gaussian mutation operator isnot as effective as it is designed to be. To overcome these limitations, theCoFFWA is proposed, which can greatly enhance the exploitation ability ofnon-core fireworks by using independent selection operator and increase theexploration capacity by crowdness-avoiding cooperative strategy among thefireworks. Experimental results on the CEC2013 benchmark functions suggest thatCoFFWA outperforms the state-of-the-art FWA variants, artificial bee colony,differential evolution, the standard particle swarm optimization (SPSO) in 2007and the most recent SPSO in 2011 in term of convergence performance.
arxiv-10200-93 | Overlapping and Non-overlapping Camera Layouts for Robot Pose Estimation | http://arxiv.org/pdf/1505.00040v1.pdf | author:Mohammad Ehab Ragab category:cs.CV published:2015-04-30 summary:We study the use of overlapping and non-overlapping camera layouts inestimating the ego-motion of a moving robot. To estimate the location andorientation of the robot, we investigate using four cameras as non-overlappingindividuals, and as two stereo pairs. The pros and cons of the two approachesare elucidated. The cameras work independently and can have larger field ofview in the non-overlapping layout. However, a scale factor ambiguity should bedealt with. On the other hand, stereo systems provide more accuracy but requireestablishing feature correspondence with more computational demand. For bothapproaches, the extended Kalman filter is used as a real-time recursiveestimator. The approaches studied are verified with synthetic and realexperiments alike.
arxiv-10200-94 | A Flexible Tensor Block Coordinate Ascent Scheme for Hypergraph Matching | http://arxiv.org/pdf/1504.07907v2.pdf | author:Quynh Nguyen, Antoine Gautier, Matthias Hein category:cs.CV published:2015-04-29 summary:The estimation of correspondences between two images resp. point sets is acore problem in computer vision. One way to formulate the problem is graphmatching leading to the quadratic assignment problem which is NP-hard. Severalso called second order methods have been proposed to solve this problem. Inrecent years hypergraph matching leading to a third order problem becamepopular as it allows for better integration of geometric information. For mostof these third order algorithms no theoretical guarantees are known. In thispaper we propose a general framework for tensor block coordinate ascent methodsfor hypergraph matching. We propose two algorithms which both come along withthe guarantee of monotonic ascent in the matching score on the set of discreteassignment matrices. In the experiments we show that our new algorithmsoutperform previous work both in terms of achieving better matching scores andmatching accuracy. This holds in particular for very challenging settings whereone has a high number of outliers and other forms of noise.
arxiv-10200-95 | Simultaneous sparse estimation of canonical vectors in the p>>N setting | http://arxiv.org/pdf/1403.6095v4.pdf | author:Irina Gaynanova, James G. Booth, Martin T. Wells category:stat.ME stat.ML published:2014-03-24 summary:This article considers the problem of sparse estimation of canonical vectorsin linear discriminant analysis when $p\gg N$. Several methods have beenproposed in the literature that estimate one canonical vector in the two-groupcase. However, $G-1$ canonical vectors can be considered if the number ofgroups is $G$. In the multi-group context, it is common to estimate canonicalvectors in a sequential fashion. Moreover, separate prior estimation of thecovariance structure is often required. We propose a novel methodology fordirect estimation of canonical vectors. In contrast to existing techniques, theproposed method estimates all canonical vectors at once, performs variableselection across all the vectors and comes with theoretical guarantees on thevariable selection and classification consistency. First, we highlight the factthat in the $N>p$ setting the canonical vectors can be expressed in a closedform up to an orthogonal transformation. Secondly, we propose an extension ofthis form to the $p\gg N$ setting and achieve feature selection by using agroup penalty. The resulting optimization problem is convex and can be solvedusing a block-coordinate descent algorithm. The practical performance of themethod is evaluated through simulation studies as well as real dataapplications.
arxiv-10200-96 | On the Relationship between Sum-Product Networks and Bayesian Networks | http://arxiv.org/pdf/1501.01239v2.pdf | author:Han Zhao, Mazen Melibari, Pascal Poupart category:cs.AI stat.ML published:2015-01-06 summary:In this paper, we establish some theoretical connections between Sum-ProductNetworks (SPNs) and Bayesian Networks (BNs). We prove that every SPN can beconverted into a BN in linear time and space in terms of the network size. Thekey insight is to use Algebraic Decision Diagrams (ADDs) to compactly representthe local conditional probability distributions at each node in the resultingBN by exploiting context-specific independence (CSI). The generated BN has asimple directed bipartite graphical structure. We show that by applying theVariable Elimination algorithm (VE) to the generated BN with ADDrepresentations, we can recover the original SPN where the SPN can be viewed asa history record or caching of the VE inference process. To help state theproof clearly, we introduce the notion of {\em normal} SPN and present atheoretical analysis of the consistency and decomposability properties. Weconclude the paper with some discussion of the implications of the proof andestablish a connection between the depth of an SPN and a lower bound of thetree-width of its corresponding BN.
arxiv-10200-97 | Application of S-Transform on Hyper kurtosis based Modified Duo Histogram Equalized DIC images for Pre-cancer Detection | http://arxiv.org/pdf/1505.00192v1.pdf | author:Sabyasachi Mukhopadhyay, Soham Mandal, Sawon Pratiher, Ritwik Barman, M. Venkatesh, Nirmalya Ghosh, Prasanta K. Panigrahi category:cs.CV published:2015-04-30 summary:Our proposed hyper kurtosis based histogram equalized DIC images enhances thecontrast by preserving the brightness. The evolution and development ofprecancerous activity among tissues are studied through S-transform (ST). Thesignificant variations of amplitude spectra can be observed due to increasedmedium roughness from normal tissue were observed in time-frequency domain. Therandomness and inhomogeneity of the tissue structures among human normal anddifferent grades of DIC tissues is recognized by ST based timefrequencyanalysis. This study offers a simpler and better way to recognize thesubstantial changes among different stages of DIC tissues, which are reflectedby spatial information containing within the inhomogeneity structures ofdifferent types of tissue.
arxiv-10200-98 | Hierarchical Subquery Evaluation for Active Learning on a Graph | http://arxiv.org/pdf/1504.08219v1.pdf | author:Oisin Mac Aodha, Neill D. F. Campbell, Jan Kautz, Gabriel J. Brostow category:cs.CV cs.LG stat.ML published:2015-04-30 summary:To train good supervised and semi-supervised object classifiers, it iscritical that we not waste the time of the human experts who are providing thetraining labels. Existing active learning strategies can have unevenperformance, being efficient on some datasets but wasteful on others, orinconsistent just between runs on the same dataset. We propose perplexity basedgraph construction and a new hierarchical subquery evaluation algorithm tocombat this variability, and to release the potential of Expected ErrorReduction. Under some specific circumstances, Expected Error Reduction has been one ofthe strongest-performing informativeness criteria for active learning. Untilnow, it has also been prohibitively costly to compute for sizeable datasets. Wedemonstrate our highly practical algorithm, comparing it to other activelearning measures on classification datasets that vary in sparsity,dimensionality, and size. Our algorithm is consistent over multiple runs andachieves high accuracy, while querying the human expert for labels at afrequency that matches their desired time budget.
arxiv-10200-99 | Lateral Connections in Denoising Autoencoders Support Supervised Learning | http://arxiv.org/pdf/1504.08215v1.pdf | author:Antti Rasmus, Harri Valpola, Tapani Raiko category:cs.LG cs.NE stat.ML published:2015-04-30 summary:We show how a deep denoising autoencoder with lateral connections can be usedas an auxiliary unsupervised learning task to support supervised learning. Theproposed model is trained to minimize simultaneously the sum of supervised andunsupervised cost functions by back-propagation, avoiding the need forlayer-wise pretraining. It improves the state of the art significantly in thepermutation-invariant MNIST classification task.
arxiv-10200-100 | Texts in, meaning out: neural language models in semantic similarity task for Russian | http://arxiv.org/pdf/1504.08183v1.pdf | author:Andrey Kutuzov, Igor Andreev category:cs.CL published:2015-04-30 summary:Distributed vector representations for natural language vocabulary get a lotof attention in contemporary computational linguistics. This paper summarizesthe experience of applying neural network language models to the task ofcalculating semantic similarity for Russian. The experiments were performed inthe course of Russian Semantic Similarity Evaluation track, where our modelstook from the 2nd to the 5th position, depending on the task. We introduce the tools and corpora used, comment on the nature of the sharedtask and describe the achieved results. It was found out that ContinuousSkip-gram and Continuous Bag-of-words models, previously successfully appliedto English material, can be used for semantic modeling of Russian as well.Moreover, we show that texts in Russian National Corpus (RNC) provide anexcellent training material for such models, outperforming other, much largercorpora. It is especially true for semantic relatedness tasks (althoughstacking models trained on larger corpora on top of RNC models improvesperformance even more). High-quality semantic vectors learned in such a way can be used in a varietyof linguistic tasks and promise an exciting field for further study.
arxiv-10200-101 | Proceedings of The 39th Annual Workshop of the Austrian Association for Pattern Recognition (OAGM), 2015 | http://arxiv.org/pdf/1505.01065v1.pdf | author:Sebastian Hegenbart, Roland Kwitt, Andreas Uhl category:cs.CV published:2015-04-30 summary:The 39th annual workshop of the Austrian Association for Pattern Recognition(OAGM/AAPR) provides a platform for presentation and discussion of researchprogress as well as research projects within the OAGM/AAPR community.
arxiv-10200-102 | Detecting and ordering adjectival scalemates | http://arxiv.org/pdf/1504.08102v1.pdf | author:Emiel van Miltenburg category:cs.CL published:2015-04-30 summary:This paper presents a pattern-based method that can be used to inferadjectival scales, such as <lukewarm, warm, hot>, from a corpus. Specifically,the proposed method uses lexical patterns to automatically identify and orderpairs of scalemates, followed by a filtering phase in which unrelated pairs arediscarded. For the filtering phase, several different similarity measures areimplemented and compared. The model presented in this paper is evaluated usingthe current standard, along with a novel evaluation set, and shown to be atleast as good as the current state-of-the-art.
arxiv-10200-103 | Marginal multi-Bernoulli filters: RFS derivation of MHT, JIPDA and association-based MeMBer | http://arxiv.org/pdf/1203.2995v5.pdf | author:Jason L. Williams category:cs.SY cs.CV published:2012-03-14 summary:Recent developments in random finite sets (RFSs) have yielded a variety oftracking methods that avoid data association. This paper derives a form of thefull Bayes RFS filter and observes that data association is implicitly present,in a data structure similar to MHT. Subsequently, algorithms are obtained byapproximating the distribution of associations. Two algorithms result: onenearly identical to JIPDA, and another related to the MeMBer filter. Bothimprove performance in challenging environments.
arxiv-10200-104 | An Automated Images-to-Graphs Framework for High Resolution Connectomics | http://arxiv.org/pdf/1411.6880v2.pdf | author:William Gray Roncal, Dean M. Kleissas, Joshua T. Vogelstein, Priya Manavalan, Kunal Lillaney, Michael Pekala, Randal Burns, R. Jacob Vogelstein, Carey E. Priebe, Mark A. Chevillet, Gregory D. Hager category:q-bio.QM cs.CV published:2014-11-25 summary:Reconstructing a map of neuronal connectivity is a critical challenge incontemporary neuroscience. Recent advances in high-throughput serial sectionelectron microscopy (EM) have produced massive 3D image volumes of nanoscalebrain tissue for the first time. The resolution of EM allows for individualneurons and their synaptic connections to be directly observed. Recoveringneuronal networks by manually tracing each neuronal process at this scale isunmanageable, and therefore researchers are developing automated imageprocessing modules. Thus far, state-of-the-art algorithms focus only on thesolution to a particular task (e.g., neuron segmentation or synapseidentification). In this manuscript we present the first fully automated images-to-graphspipeline (i.e., a pipeline that begins with an imaged volume of neural tissueand produces a brain graph without any human interaction). To evaluate overallperformance and select the best parameters and methods, we also develop ametric to assess the quality of the output graphs. We evaluate a set ofalgorithms and parameters, searching possible operating points to identify thebest available brain graph for our assessment metric. Finally, we deploy areference end-to-end version of the pipeline on a large, publicly availabledata set. This provides a baseline result and framework for community analysisand future algorithm development and testing. All code and data derivativeshave been made publicly available toward eventually unlocking new biofideliccomputational primitives and understanding of neuropathologies.
arxiv-10200-105 | Translating Videos to Natural Language Using Deep Recurrent Neural Networks | http://arxiv.org/pdf/1412.4729v3.pdf | author:Subhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond Mooney, Kate Saenko category:cs.CV cs.CL published:2014-12-15 summary:Solving the visual symbol grounding problem has long been a goal ofartificial intelligence. The field appears to be advancing closer to this goalwith recent breakthroughs in deep learning for natural language grounding instatic images. In this paper, we propose to translate videos directly tosentences using a unified deep neural network with both convolutional andrecurrent structure. Described video datasets are scarce, and most existingmethods have been applied to toy domains with a small vocabulary of possiblewords. By transferring knowledge from 1.2M+ images with category labels and100,000+ images with captions, our method is able to create sentencedescriptions of open-domain videos with large vocabularies. We compare ourapproach with recent work using language generation metrics, subject, verb, andobject prediction accuracy, and a human evaluation.
arxiv-10200-106 | Exploiting Local Features from Deep Networks for Image Retrieval | http://arxiv.org/pdf/1504.05133v2.pdf | author:Joe Yue-Hei Ng, Fan Yang, Larry S. Davis category:cs.CV published:2015-04-20 summary:Deep convolutional neural networks have been successfully applied to imageclassification tasks. When these same networks have been applied to imageretrieval, the assumption has been made that the last layers would give thebest performance, as they do in classification. We show that for instance-levelimage retrieval, lower layers often perform better than the last layers inconvolutional neural networks. We present an approach for extractingconvolutional features from different layers of the networks, and adopt VLADencoding to encode features into a single vector for each image. We investigatethe effect of different layers and scales of input images on the performance ofconvolutional features using the recent deep networks OxfordNet and GoogLeNet.Experiments demonstrate that intermediate layers or higher layers with finerscales produce better results for image retrieval, compared to the last layer.When using compressed 128-D VLAD descriptors, our method obtainsstate-of-the-art results and outperforms other VLAD and CNN based approaches ontwo out of three test datasets. Our work provides guidance for transferringdeep networks trained on image classification to image retrieval tasks.
arxiv-10200-107 | Detecting Concept-level Emotion Cause in Microblogging | http://arxiv.org/pdf/1504.08050v1.pdf | author:Shuangyong Song, Yao Meng category:cs.CL cs.AI 68P20 H.2.8 published:2015-04-30 summary:In this paper, we propose a Concept-level Emotion Cause Model (CECM), insteadof the mere word-level models, to discover causes of microblogging users'diversified emotions on specific hot event. A modified topic-supervised bitermtopic model is utilized in CECM to detect emotion topics' in event-relatedtweets, and then context-sensitive topical PageRank is utilized to detectmeaningful multiword expressions as emotion causes. Experimental results on adataset from Sina Weibo, one of the largest microblogging websites in China,show CECM can better detect emotion causes than baseline methods.
arxiv-10200-108 | Toward a multilevel representation of protein molecules: comparative approaches to the aggregation/folding propensity problem | http://arxiv.org/pdf/1407.7559v3.pdf | author:Lorenzo Livi, Alessandro Giuliani, Antonello Rizzi category:cs.CE cs.LG q-bio.BM q-bio.MN I.2.6; K.3.2 published:2014-07-28 summary:This paper builds upon the fundamental work of Niwa et al. [34], whichprovides the unique possibility to analyze the relative aggregation/foldingpropensity of the elements of the entire Escherichia coli (E. coli) proteome ina cell-free standardized microenvironment. The hardness of the problem comesfrom the superposition between the driving forces of intra- and inter-moleculeinteractions and it is mirrored by the evidences of shift from folding toaggregation phenotypes by single-point mutations [10]. Here we apply severalstate-of-the-art classification methods coming from the field of structuralpattern recognition, with the aim to compare different representations of thesame proteins gathered from the Niwa et al. data base; such representationsinclude sequences and labeled (contact) graphs enriched with chemico-physicalattributes. By this comparison, we are able to identify also some interestinggeneral properties of proteins. Notably, (i) we suggest a threshold around 250residues discriminating "easily foldable" from "hardly foldable" moleculesconsistent with other independent experiments, and (ii) we highlight therelevance of contact graph spectra for folding behavior discrimination andcharacterization of the E. coli solubility data. The soundness of theexperimental results presented in this paper is proved by the statisticallyrelevant relationships discovered among the chemico-physical description ofproteins and the developed cost matrix of substitution used in the variousdiscrimination systems.
arxiv-10200-109 | Technical Note on Equivalence Between Recurrent Neural Network Time Series Models and Variational Bayesian Models | http://arxiv.org/pdf/1504.08025v1.pdf | author:Jascha Sohl-Dickstein, Diederik P. Kingma category:cs.LG published:2015-04-29 summary:We observe that the standard log likelihood training objective for aRecurrent Neural Network (RNN) model of time series data is equivalent to avariational Bayesian training objective, given the proper choice of generativeand inference models. This perspective may motivate extensions to both RNNs andvariational Bayesian models. We propose one such extension, where multipleparticles are used for the hidden state of an RNN, allowing a naturalrepresentation of uncertainty or multimodality.
arxiv-10200-110 | Anticipating the future by watching unlabeled video | http://arxiv.org/pdf/1504.08023v1.pdf | author:Carl Vondrick, Hamed Pirsiavash, Antonio Torralba category:cs.CV published:2015-04-29 summary:In many computer vision applications, machines will need to reason beyond thepresent, and predict the future. This task is challenging because it requiresleveraging extensive commonsense knowledge of the world that is difficult towrite down. We believe that a promising resource for efficiently obtaining thisknowledge is through the massive amounts of readily available unlabeled video.In this paper, we present a large scale framework that capitalizes on temporalstructure in unlabeled video to learn to anticipate both actions and objects inthe future. The key idea behind our approach is that we can train deep networksto predict the visual representation of images in the future. We experimentallyvalidate this idea on two challenging "in the wild" video datasets, and ourresults suggest that learning with unlabeled videos significantly helpsforecast actions and anticipate objects.
arxiv-10200-111 | A Deep Learning Model for Structured Outputs with High-order Interaction | http://arxiv.org/pdf/1504.08022v1.pdf | author:Hongyu Guo, Xiaodan Zhu, Martin Renqiang Min category:cs.LG cs.NE published:2015-04-29 summary:Many real-world applications are associated with structured data, where notonly input but also output has interplay. However, typical classification andregression models often lack the ability of simultaneously exploring high-orderinteraction within input and that within output. In this paper, we present adeep learning model aiming to generate a powerful nonlinear functional mappingfrom structured input to structured output. More specifically, we propose tointegrate high-order hidden units, guided discriminative pretraining, andhigh-order auto-encoders for this purpose. We evaluate the model with threedatasets, and obtain state-of-the-art performances among competitive methods.Our current work focuses on structured output regression, which is a lessexplored area, although the model can be extended to handle structured labelclassification.
arxiv-10200-112 | Who Spoke What? A Latent Variable Framework for the Joint Decoding of Multiple Speakers and their Keywords | http://arxiv.org/pdf/1504.08021v1.pdf | author:Harshavardhan Sundar, Thippur V. Sreenivas category:cs.SD cs.LG published:2015-04-29 summary:In this paper, we present a latent variable (LV) framework to identify allthe speakers and their keywords given a multi-speaker mixture signal. Weintroduce two separate LVs to denote active speakers and the keywords uttered.The dependency of a spoken keyword on the speaker is modeled through aconditional probability mass function. The distribution of the mixture signalis expressed in terms of the LV mass functions and speaker-specific-keywordmodels. The proposed framework admits stochastic models, representing theprobability density function of the observation vectors given that a particularspeaker uttered a specific keyword, as speaker-specific-keyword models. The LVmass functions are estimated in a Maximum Likelihood framework using theExpectation Maximization (EM) algorithm. The active speakers and their keywordsare detected as modes of the joint distribution of the two LVs. In mixturesignals, containing two speakers uttering the keywords simultaneously, theproposed framework achieves an accuracy of 82% for detecting both the speakersand their respective keywords, using Student's-t mixture models asspeaker-specific-keyword models.
arxiv-10200-113 | Learning Contextualized Music Semantics from Tags via a Siamese Network | http://arxiv.org/pdf/1504.07968v1.pdf | author:Ubai Sandouk, Ke Chen category:cs.LG I.2.6 published:2015-04-29 summary:Automatic annotation of music with tags is a promising methodology for theacquisition of semantics that facilitates music information retrieval andunderstanding. One of the biggest challenges for this methodology is modelingconcept semantics in context. Moreover, the out of vocabulary (OOV) problemexacerbates its difficulty and has yet to be addressed so far. In this paper,we propose a novel Siamese network to fight off the challenge. By means of tagfeatures and a probabilistic topic model, our Siamese network capturescontextualized music semantics from tags via unsupervised learning, which leadsto a contextualized music semantic space and a potential solution to the OOV.We have conducted simulations on two public tag collections, CAL500 andMagTag5K, and compared our approach to a number of the state-of-the-artmethods. Comparative results suggest that our approach outperforms thestate-of-the-art methods in terms of semantic priming measures.
arxiv-10200-114 | Improved repeatability measures for evaluating performance of feature detectors | http://arxiv.org/pdf/1504.07967v1.pdf | author:Shoaib Ehsan, Nadia Kanwal, Adrian F. Clark, Klaus D. McDonald-Maier category:cs.CV cs.PF published:2015-04-29 summary:The most frequently employed measure for performance characterisation oflocal feature detectors is repeatability, but it has been observed that thisdoes not necessarily mirror actual performance. Presented are improvedrepeatability formulations which correlate much better with the trueperformance of feature detectors. Comparative results for severalstate-of-the-art feature detectors are presented using these measures; it isfound that Hessian-based detectors are generally superior at identifyingfeatures when images are subject to various geometric and photometrictransformations.
arxiv-10200-115 | Hardware based Scale- and Rotation-Invariant Feature Extraction: A Retrospective Analysis and Future Directions | http://arxiv.org/pdf/1504.07962v1.pdf | author:Shoaib Ehsan, Adrian F. Clark, Klaus D. McDonald-Maier category:cs.CV published:2015-04-29 summary:Computer Vision techniques represent a class of algorithms that are highlycomputation and data intensive in nature. Generally, performance of thesealgorithms in terms of execution speed on desktop computers is far fromreal-time. Since real-time performance is desirable in many applications,special-purpose hardware is required in most cases to achieve this goal. Scale-and rotation-invariant local feature extraction is a low level computer visiontask with very high computational complexity. The state-of-the-art algorithmsthat currently exist in this domain, like SIFT and SURF, suffer from slowexecution speeds and at best can only achieve rates of 2-3 Hz on modern desktopcomputers. Hardware-based scale- and rotation-invariant local featureextraction is an emerging trend enabling real-time performance for thesecomputationally complex algorithms. This paper takes a retrospective look atthe advances made so far in this field, discusses the hardware designstrategies employed and results achieved, identifies current research gaps andsuggests future research directions.
arxiv-10200-116 | Exploring Integral Image Word Length Reduction Techniques for SURF Detector | http://arxiv.org/pdf/1504.07958v1.pdf | author:Shoaib Ehsan, Klaus D. McDonald-Maier category:cs.CV published:2015-04-29 summary:Speeded Up Robust Features (SURF) is a state of the art computer visionalgorithm that relies on integral image representation for performing fastdetection and description of image features that are scale and rotationinvariant. Integral image representation, however, has major draw back of largebinary word length that leads to substantial increase in memory size. Whendesigning a dedicated hardware to achieve real-time performance for the SURFalgorithm, it is imperative to consider the adverse effects of integral imageon memory size, bus width and computational resources. With the objective ofminimizing hardware resources, this paper presents a novel implementationconcept of a reduced word length integral image based SURF detector. Itevaluates two existing word length reduction techniques for the particular caseof SURF detector and extends one of these to achieve more reduction in wordlength. This paper also introduces a novel method to achieve integral imageword length reduction for SURF detector.
arxiv-10200-117 | Designing Optimal Mortality Risk Prediction Scores that Preserve Clinical Knowledge | http://arxiv.org/pdf/1411.5086v2.pdf | author:Natalia M. Arzeno, Karla A. Lawson, Sarah V. Duzinski, Haris Vikalo category:stat.ML stat.AP published:2014-11-19 summary:Many in-hospital mortality risk prediction scores dichotomize predictivevariables to simplify the score calculation. However, hard thresholding inthese additive stepwise scores of the form "add x points if variable v isabove/below threshold t" may lead to critical failures. In this paper, we seekto develop risk prediction scores that preserve clinical knowledge embedded infeatures and structure of the existing additive stepwise scores whileaddressing limitations caused by variable dichotomization. To this end, wepropose a novel score structure that relies on a transformation of predictivevariables by means of nonlinear logistic functions facilitating smoothdifferentiation between critical and normal values of the variables. We developan optimization framework for inferring parameters of the logistic functionsfor a given patient population via cyclic block coordinate descent. Theparameters may readily be updated as the patient population and standards ofcare evolve. We tested the proposed methodology on two populations: (1) braintrauma patients admitted to the intensive care unit of the Dell Children'sMedical Center of Central Texas between 2007 and 2012, and (2) adult ICUpatient data from the MIMIC II database. The results are compared with thoseobtained by the widely used PRISM III and SOFA scores. The prediction power ofa score is evaluated using area under ROC curve, Youden's index, andprecision-recall balance in a cross-validation study. The results demonstratethat the new framework enables significant performance improvements over PRISMIII and SOFA in terms of all three criteria.
arxiv-10200-118 | Robust hyperspectral image classification with rejection fields | http://arxiv.org/pdf/1504.07918v1.pdf | author:Filipe Condessa, Jose Bioucas-Dias, Jelena Kovacevic category:cs.CV 68 published:2015-04-29 summary:In this paper we present a novel method for robust hyperspectral imageclassification using context and rejection. Hyperspectral image classificationis generally an ill-posed image problem where pixels may belong to unknownclasses, and obtaining representative and complete training sets is costly.Furthermore, the need for high classification accuracies is frequently greaterthan the need to classify the entire image. We approach this problem with a robust classification method that combinesclassification with context with classification with rejection. A rejectionfield that will guide the rejection is derived from the classification withcontextual information obtained by using the SegSALSA algorithm. We validateour method in real hyperspectral data and show that the performance gainsobtained from the rejection fields are equivalent to an increase the dimensionof the training sets.
arxiv-10200-119 | Comparative study of image registration techniques for bladder video-endoscopy | http://arxiv.org/pdf/1504.07901v1.pdf | author:Achraf Ben-Hamadou, Charles Soussen, Walter Blondel, Christian Daul, Didier Wolf category:cs.CV published:2015-04-29 summary:Bladder cancer is widely spread in the world. Many adequate diagnosistechniques exist. Video-endoscopy remains the standard clinical procedure forvisual exploration of the bladder internal surface. However, video-endoscopypresents the limit that the imaged area for each image is about nearly 1cm2.And, lesions are, typically, spread over several images. The aim of thiscontribution is to assess the performance of two mosaicing algorithms leadingto the construction of panoramic maps (one unique image) of bladder walls. Thequantitative comparison study is performed on a set of real endoscopic examdata and on simulated data relative to bladder phantom.
arxiv-10200-120 | Visual Information Retrieval in Endoscopic Video Archives | http://arxiv.org/pdf/1504.07874v1.pdf | author:Jennifer Roldan-Carlos, Mathias Lux, Xavier Giró-i-Nieto, Pia Muñoz, Nektarios Anagnostopoulos category:cs.IR cs.CV cs.MM published:2015-04-29 summary:In endoscopic procedures, surgeons work with live video streams from theinside of their subjects. A main source for documentation of procedures arestill frames from the video, identified and taken during the surgery. However,with growing demands and technical means, the streams are saved to storageservers and the surgeons need to retrieve parts of the videos on demand. Inthis submission we present a demo application allowing for video retrievalbased on visual features and late fusion, which allows surgeons to re-findshots taken during the procedure.
arxiv-10200-121 | ASTROMLSKIT: A New Statistical Machine Learning Toolkit: A Platform for Data Analytics in Astronomy | http://arxiv.org/pdf/1504.07865v1.pdf | author:Snehanshu Saha, Surbhi Agrawal, Manikandan. R, Kakoli Bora, Swati Routh, Anand Narasimhamurthy category:cs.CE astro-ph.IM cs.LG published:2015-04-29 summary:Astroinformatics is a new impact area in the world of astronomy, occasionallycalled the final frontier, where several astrophysicists, statisticians andcomputer scientists work together to tackle various data intensive astronomicalproblems. Exponential growth in the data volume and increased complexity of thedata augments difficult questions to the existing challenges. Classicalproblems in Astronomy are compounded by accumulation of astronomical volume ofcomplex data, rendering the task of classification and interpretationincredibly laborious. The presence of noise in the data makes analysis andinterpretation even more arduous. Machine learning algorithms and data analytictechniques provide the right platform for the challenges posed by theseproblems. A diverse range of open problem like star-galaxy separation,detection and classification of exoplanets, classification of supernovae isdiscussed. The focus of the paper is the applicability and efficacy of variousmachine learning algorithms like K Nearest Neighbor (KNN), random forest (RF),decision tree (DT), Support Vector Machine (SVM), Na\"ive Bayes and LinearDiscriminant Analysis (LDA) in analysis and inference of the decision theoreticproblems in Astronomy. The machine learning algorithms, integrated intoASTROMLSKIT, a toolkit developed in the course of the work, have been used toanalyze HabCat data and supernovae data. Accuracy has been found to beappreciably good.
arxiv-10200-122 | Intelligent Health Recommendation System for Computer Users | http://arxiv.org/pdf/1504.07858v1.pdf | author:Qi Guo, Zixuan Wang, Ming Li, Hamid Aghajan category:cs.CV published:2015-04-29 summary:The time people spend in front of computers has been increasing steadily dueto the role computers play in modern society. Individuals who sit in front ofcomputers for an extended period of time, specifically with improper posturesmay incur various health issues. In this work, individuals' behaviors in frontof computers are studied using web cameras. By means of non-rigid face trackingsystem, data are analyzed to determine the 3D head pose, blink rate and yawnfrequency of computer users. When combining these visual cues, a system ofintelligent personal assistants for computer users is proposed.
arxiv-10200-123 | On the universal structure of human lexical semantics | http://arxiv.org/pdf/1504.07843v1.pdf | author:Hyejin Youn, Logan Sutton, Eric Smith, Cristopher Moore, Jon F. Wilkins, Ian Maddieson, William Croft, Tanmoy Bhattacharya category:physics.soc-ph cs.CL published:2015-04-29 summary:How universal is human conceptual structure? The way concepts are organizedin the human brain may reflect distinct features of cultural, historical, andenvironmental background in addition to properties universal to humancognition. Semantics, or meaning expressed through language, provides directaccess to the underlying conceptual structure, but meaning is notoriouslydifficult to measure, let alone parameterize. Here we provide an empiricalmeasure of semantic proximity between concepts using cross-linguisticdictionaries. Across languages carefully selected from a phylogenetically andgeographically stratified sample of genera, translations of words reveal caseswhere a particular language uses a single polysemous word to express conceptsrepresented by distinct words in another. We use the frequency of polysemieslinking two concepts as a measure of their semantic proximity, and representthe pattern of such linkages by a weighted network. This network is highlyuneven and fragmented: certain concepts are far more prone to polysemy thanothers, and there emerge naturally interpretable clusters loosely connected toeach other. Statistical analysis shows such structural properties areconsistent across different language groups, largely independent of geography,environment, and literacy. It is therefore possible to conclude the conceptualstructure connecting basic vocabulary studied is primarily due to universalfeatures of human cognition and language use.
arxiv-10200-124 | Learning to Recognize Pedestrian Attribute | http://arxiv.org/pdf/1501.00901v2.pdf | author:Yubin Deng, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV published:2015-01-05 summary:Learning to recognize pedestrian attributes at far distance is a challengingproblem in visual surveillance since face and body close-shots are hardlyavailable; instead, only far-view image frames of pedestrian are given. In thisstudy, we present an alternative approach that exploits the context ofneighboring pedestrian images for improved attribute inference compared to theconventional SVM-based method. In addition, we conduct extensive experiments toevaluate the informativeness of background and foreground features forattribute recognition. Experiments are based on our newly released pedestrianattribute dataset, which is by far the largest and most diverse of its kind.
arxiv-10200-125 | Dual Averaging on Compactly-Supported Distributions And Application to No-Regret Learning on a Continuum | http://arxiv.org/pdf/1504.07720v1.pdf | author:Walid Krichene category:cs.LG math.OC published:2015-04-29 summary:We consider an online learning problem on a continuum. A decision maker isgiven a compact feasible set $S$, and is faced with the following sequentialproblem: at iteration~$t$, the decision maker chooses a distribution $x^{(t)}\in \Delta(S)$, then a loss function $\ell^{(t)} : S \to \mathbb{R}_+$ isrevealed, and the decision maker incurs expected loss $\langle \ell^{(t)},x^{(t)} \rangle = \mathbb{E}_{s \sim x^{(t)}} \ell^{(t)}(s)$. We view theproblem as an online convex optimization problem on the space $\Delta(S)$ ofLebesgue-continnuous distributions on $S$. We prove a general regret bound forthe Dual Averaging method on $L^2(S)$, then prove that dual averaging with$\omega$-potentials (a class of strongly convex regularizers) achievessublinear regret when $S$ is uniformly fat (a condition weaker than convexity).
arxiv-10200-126 | Heterogeneous Tensor Decomposition for Clustering via Manifold Optimization | http://arxiv.org/pdf/1504.01777v2.pdf | author:Yanfeng Sun, Junbin Gao, Xia Hong, Bamdev Mishra, Baocai Yin category:cs.CV published:2015-04-07 summary:Tensors or multiarray data are generalizations of matrices. Tensor clusteringhas become a very important research topic due to the intrinsically richstructures in real-world multiarray datasets. Subspace clustering based onvectorizing multiarray data has been extensively researched. However,vectorization of tensorial data does not exploit complete structureinformation. In this paper, we propose a subspace clustering algorithm withoutadopting any vectorization process. Our approach is based on a novelheterogeneous Tucker decomposition model. In contrast to existing techniques,we propose a new clustering algorithm that alternates between different modesof the proposed heterogeneous tensor model. All but the last mode haveclosed-form updates. Updating the last mode reduces to optimizing over theso-called multinomial manifold, for which we investigate second orderRiemannian geometry and propose a trust-region algorithm. Numerical experimentsshow that our proposed algorithm compete effectively with state-of-the-artclustering algorithms that are based on tensor factorization.
arxiv-10200-127 | Joint cross-domain classification and subspace learning for unsupervised adaptation | http://arxiv.org/pdf/1411.4491v3.pdf | author:Basura Fernando, Tatiana Tommasi, Tinne Tuytelaars category:cs.CV cs.LG published:2014-11-17 summary:Domain adaptation aims at adapting the knowledge acquired on a source domainto a new different but related target domain. Several approaches havebeenproposed for classification tasks in the unsupervised scenario, where nolabeled target data are available. Most of the attention has been dedicated tosearching a new domain-invariant representation, leaving the definition of theprediction function to a second stage. Here we propose to learn both jointly.Specifically we learn the source subspace that best matches the target subspacewhile at the same time minimizing a regularized misclassification loss. Weprovide an alternating optimization technique based on stochastic sub-gradientdescent to solve the learning problem and we demonstrate its performance onseveral domain adaptation tasks.
arxiv-10200-128 | Leveraging Deep Neural Networks and Knowledge Graphs for Entity Disambiguation | http://arxiv.org/pdf/1504.07678v1.pdf | author:Hongzhao Huang, Larry Heck, Heng Ji category:cs.CL published:2015-04-28 summary:Entity Disambiguation aims to link mentions of ambiguous entities to aknowledge base (e.g., Wikipedia). Modeling topical coherence is crucial forthis task based on the assumption that information from the same semanticcontext tends to belong to the same topic. This paper presents a novel deepsemantic relatedness model (DSRM) based on deep neural networks (DNN) andsemantic knowledge graphs (KGs) to measure entity semantic relatedness fortopical coherence modeling. The DSRM is directly trained on large-scale KGs andit maps heterogeneous types of knowledge of an entity from KGs to numericalfeature vectors in a latent space such that the distance between twosemantically-related entities is minimized. Compared with the state-of-the-artrelatedness approach proposed by (Milne and Witten, 2008a), the DSRM obtains19.4% and 24.5% reductions in entity disambiguation errors on two publiclyavailable datasets respectively.
arxiv-10200-129 | Explaining the Success of AdaBoost and Random Forests as Interpolating Classifiers | http://arxiv.org/pdf/1504.07676v1.pdf | author:Abraham J. Wyner, Matthew Olson, Justin Bleich, David Mease category:stat.ML cs.LG stat.ME published:2015-04-28 summary:There is a large literature explaining why AdaBoost is a successfulclassifier. The literature on AdaBoost focuses on classifier margins andboosting's interpretation as the optimization of an exponential likelihoodfunction. These existing explanations, however, have been pointed out to beincomplete. A random forest is another popular ensemble method for which thereis substantially less explanation in the literature. We introduce a novelperspective on AdaBoost and random forests that proposes that the twoalgorithms work for similar reasons. While both classifiers achieve similarpredictive accuracy, random forests cannot be conceived as a directoptimization procedure. Rather, random forests is a self-averaging,interpolating algorithm which creates what we denote as a "spikey-smooth"classifier, and we view AdaBoost in the same light. We conjecture that bothAdaBoost and random forests succeed because of this mechanism. We provide anumber of examples and some theoretical justification to support thisexplanation. In the process, we question the conventional wisdom that suggeststhat boosting algorithms for classification require regularization or earlystopping and should be limited to low complexity classes of learners, such asdecision stumps. We conclude that boosting should be used like random forests:with large decision trees and without direct regularization or early stopping.
arxiv-10200-130 | Evaluation of Explore-Exploit Policies in Multi-result Ranking Systems | http://arxiv.org/pdf/1504.07662v1.pdf | author:Dragomir Yankov, Pavel Berkhin, Lihong Li category:cs.LG published:2015-04-28 summary:We analyze the problem of using Explore-Exploit techniques to improveprecision in multi-result ranking systems such as web search, queryautocompletion and news recommendation. Adopting an exploration policy directlyonline, without understanding its impact on the production system, may haveunwanted consequences - the system may sustain large losses, create userdissatisfaction, or collect exploration data which does not help improveranking quality. An offline framework is thus necessary to let us decide whatpolicy and how we should apply in a production environment to ensure positiveoutcome. Here, we describe such an offline framework. Using the framework, we study a popular exploration policy - Thompsonsampling. We show that there are different ways of implementing it inmulti-result ranking systems, each having different semantic interpretation andleading to different results in terms of sustained click-through-rate (CTR)loss and expected model improvement. In particular, we demonstrate thatThompson sampling can act as an online learner optimizing CTR, which in somecases can lead to an interesting outcome: lift in CTR during exploration. Theobservation is important for production systems as it suggests that one can getboth valuable exploration data to improve ranking performance on the long run,and at the same time increase CTR while exploration lasts.
arxiv-10200-131 | Nearly Optimal Deterministic Algorithm for Sparse Walsh-Hadamard Transform | http://arxiv.org/pdf/1504.07648v1.pdf | author:Mahdi Cheraghchi, Piotr Indyk category:cs.IT cs.CC cs.LG math.FA math.IT published:2015-04-28 summary:For every fixed constant $\alpha > 0$, we design an algorithm for computingthe $k$-sparse Walsh-Hadamard transform of an $N$-dimensional vector $x \in\mathbb{R}^N$ in time $k^{1+\alpha} (\log N)^{O(1)}$. Specifically, thealgorithm is given query access to $x$ and computes a $k$-sparse $\tilde{x} \in\mathbb{R}^N$ satisfying $\\tilde{x} - \hat{x}\_1 \leq c \\hat{x} -H_k(\hat{x})\_1$, for an absolute constant $c > 0$, where $\hat{x}$ is thetransform of $x$ and $H_k(\hat{x})$ is its best $k$-sparse approximation. Ouralgorithm is fully deterministic and only uses non-adaptive queries to $x$(i.e., all queries are determined and performed in parallel when the algorithmstarts). An important technical tool that we use is a construction of nearly optimaland linear lossless condensers which is a careful instantiation of the GUVcondenser (Guruswami, Umans, Vadhan, JACM 2009). Moreover, we design adeterministic and non-adaptive $\ell_1/\ell_1$ compressed sensing scheme basedon general lossless condensers that is equipped with a fast reconstructionalgorithm running in time $k^{1+\alpha} (\log N)^{O(1)}$ (for the GUV-basedcondenser) and is of independent interest. Our scheme significantly simplifiesand improves an earlier expander-based construction due to Berinde, Gilbert,Indyk, Karloff, Strauss (Allerton 2008). Our methods use linear lossless condensers in a black box fashion; therefore,any future improvement on explicit constructions of such condensers wouldimmediately translate to improved parameters in our framework (potentiallyleading to $k (\log N)^{O(1)}$ reconstruction time with a reduced exponent inthe poly-logarithmic factor, and eliminating the extra parameter $\alpha$). Finally, by allowing the algorithm to use randomness, while still usingnon-adaptive queries, the running time of the algorithm can be improved to$\tilde{O}(k \log^3 N)$.
arxiv-10200-132 | A novel variational model for image registration using Gaussian curvature | http://arxiv.org/pdf/1504.07643v1.pdf | author:Mazlinda Ibrahim, Ke Chen, Carlos Brito-Loeza category:math.NA cs.CV published:2015-04-28 summary:Image registration is one important task in many image processingapplications. It aims to align two or more images so that useful informationcan be extracted through comparison, combination or superposition. This isachieved by constructing an optimal trans- formation which ensures that thetemplate image becomes similar to a given reference image. Although many modelsexist, designing a model capable of modelling large and smooth deformationfield continues to pose a challenge. This paper proposes a novel variationalmodel for image registration using the Gaussian curvature as a regulariser. Themodel is motivated by the surface restoration work in geometric processing[Elsey and Esedoglu, Multiscale Model. Simul., (2009), pp. 1549-1573]. Aneffective numerical solver is provided for the model using an augmentedLagrangian method. Numerical experiments can show that the new modeloutperforms three competing models based on, respectively, a linear curvature[Fischer and Modersitzki, J. Math. Imaging Vis., (2003), pp. 81- 85], the meancurvature [Chumchob, Chen and Brito, Multiscale Model. Simul., (2011), pp.89-128] and the diffeomorphic demon model [Vercauteren at al., NeuroImage,(2009), pp. 61-72] in terms of robustness and accuracy.
arxiv-10200-133 | Or's of And's for Interpretable Classification, with Application to Context-Aware Recommender Systems | http://arxiv.org/pdf/1504.07614v1.pdf | author:Tong Wang, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, Perry MacNeille category:cs.LG published:2015-04-28 summary:We present a machine learning algorithm for building classifiers that arecomprised of a small number of disjunctions of conjunctions (or's of and's). Anexample of a classifier of this form is as follows: If X satisfies (x1 = 'blue'AND x3 = 'middle') OR (x1 = 'blue' AND x2 = '<15') OR (x1 = 'yellow'), then wepredict that Y=1, ELSE predict Y=0. An attribute-value pair is called a literaland a conjunction of literals is called a pattern. Models of this form have theadvantage of being interpretable to human experts, since they produce a set ofconditions that concisely describe a specific class. We present twoprobabilistic models for forming a pattern set, one with a Beta-Binomial prior,and the other with Poisson priors. In both cases, there are prior parametersthat the user can set to encourage the model to have a desired size and shape,to conform with a domain-specific definition of interpretability. We providetwo scalable MAP inference approaches: a pattern level search, which involvesassociation rule mining, and a literal level search. We show stronger priorsreduce computation. We apply the Bayesian Or's of And's (BOA) model to predictuser behavior with respect to in-vehicle context-aware personalized recommendersystems.
arxiv-10200-134 | Fast Iteratively Reweighted Least Squares Algorithms for Analysis-Based Sparsity Reconstruction | http://arxiv.org/pdf/1411.5057v3.pdf | author:Chen Chen, Junzhou Huang, Lei He, Hongsheng Li category:cs.CV published:2014-11-18 summary:In this paper, we propose a novel algorithm for analysis-based sparsityreconstruction. It can solve the generalized problem by structured sparsityregularization with an orthogonal basis and total variation regularization. Theproposed algorithm is based on the iterative reweighted least squares (IRLS)model, which is further accelerated by the preconditioned conjugate gradientmethod. The convergence rate of the proposed algorithm is almost the same asthat of the traditional IRLS algorithms, that is, exponentially fast. Moreover,with the specifically devised preconditioner, the computational cost for eachiteration is significantly less than that of traditional IRLS algorithms, whichenables our approach to handle large scale problems. In addition to the fastconvergence, it is straightforward to apply our method to standard sparsity,group sparsity, overlapping group sparsity and TV based problems. Experimentsare conducted on a practical application: compressive sensing magneticresonance imaging. Extensive results demonstrate that the proposed algorithmachieves superior performance over 14 state-of-the-art algorithms in terms ofboth accuracy and computational cost.
arxiv-10200-135 | A Robust Lane Detection and Departure Warning System | http://arxiv.org/pdf/1504.07590v1.pdf | author:Mrinal Haloi, Dinesh Babu Jayagopi category:cs.CV 68T45 published:2015-04-28 summary:In this work, we have developed a robust lane detection and departure warningtechnique. Our system is based on single camera sensor. For lane detection amodified Inverse Perspective Mapping using only a few extrinsic cameraparameters and illuminant Invariant techniques is used. Lane markings arerepresented using a combination of 2nd and 4th order steerable filters, robustto shadowing. Effect of shadowing and extra sun light are removed using Labcolor space, and illuminant invariant representation. Lanes are assumed to becubic curves and fitted using robust RANSAC. This method can reliably detectlanes of the road and its boundary. This method has been experimented in Indianroad conditions under different challenging situations and the result obtainedwere very good. For lane departure angle an optical flow based method wereused.
arxiv-10200-136 | Joint Learning of Distributed Representations for Images and Texts | http://arxiv.org/pdf/1504.03083v2.pdf | author:Xiaodong He, Rupesh Srivastava, Jianfeng Gao, Li Deng category:cs.CV published:2015-04-13 summary:This technical report provides extra details of the deep multimodalsimilarity model (DMSM) which was proposed in (Fang et al. 2015,arXiv:1411.4952). The model is trained via maximizing global semanticsimilarity between images and their captions in natural language using thepublic Microsoft COCO database, which consists of a large set of images andtheir corresponding captions. The learned representations attempt to capturethe combination of various visual concepts and cues.
arxiv-10200-137 | Becoming the Expert - Interactive Multi-Class Machine Teaching | http://arxiv.org/pdf/1504.07575v1.pdf | author:Edward Johns, Oisin Mac Aodha, Gabriel J. Brostow category:cs.CV cs.LG stat.ML published:2015-04-28 summary:Compared to machines, humans are extremely good at classifying images intocategories, especially when they possess prior knowledge of the categories athand. If this prior information is not available, supervision in the form ofteaching images is required. To learn categories more quickly, people shouldsee important and representative images first, followed by less importantimages later - or not at all. However, image-importance is individual-specific,i.e. a teaching image is important to a student if it changes their overallability to discriminate between classes. Further, students keep learning, sowhile image-importance depends on their current knowledge, it also varies withtime. In this work we propose an Interactive Machine Teaching algorithm thatenables a computer to teach challenging visual concepts to a human. Ouradaptive algorithm chooses, online, which labeled images from a teaching setshould be shown to the student as they learn. We show that a teaching strategythat probabilistically models the student's ability and progress, based ontheir correct and incorrect answers, produces better 'experts'. We presentresults using real human participants across several varied and challengingreal-world datasets.
arxiv-10200-138 | Can Machines Truly Think | http://arxiv.org/pdf/1504.07571v1.pdf | author:Murat Okandan category:cs.AI cs.NE published:2015-04-28 summary:Can machines truly think? This question and its answer have many implicationsthat depend, in large part, on any number of assumptions underlying how theissue has been addressed or considered previously. A crucial question, and onethat is almost taken for granted, is the starting point for this discussion:Can "thought" be achieved or emulated by algorithmic procedures?
arxiv-10200-139 | Using Syntax-Based Machine Translation to Parse English into Abstract Meaning Representation | http://arxiv.org/pdf/1504.06665v2.pdf | author:Michael Pust, Ulf Hermjakob, Kevin Knight, Daniel Marcu, Jonathan May category:cs.CL cs.AI I.2.7 published:2015-04-24 summary:We present a parser for Abstract Meaning Representation (AMR). We treatEnglish-to-AMR conversion within the framework of string-to-tree, syntax-basedmachine translation (SBMT). To make this work, we transform the AMR structureinto a form suitable for the mechanics of SBMT and useful for modeling. Weintroduce an AMR-specific language model and add data and features drawn fromsemantic resources. Our resulting AMR parser improves upon state-of-the-artresults by 7 Smatch points.
arxiv-10200-140 | Differentially Private Release and Learning of Threshold Functions | http://arxiv.org/pdf/1504.07553v1.pdf | author:Mark Bun, Kobbi Nissim, Uri Stemmer, Salil Vadhan category:cs.CR cs.LG published:2015-04-28 summary:We prove new upper and lower bounds on the sample complexity of $(\epsilon,\delta)$ differentially private algorithms for releasing approximate answers tothreshold functions. A threshold function $c_x$ over a totally ordered domain$X$ evaluates to $c_x(y) = 1$ if $y \le x$, and evaluates to $0$ otherwise. Wegive the first nontrivial lower bound for releasing thresholds with$(\epsilon,\delta)$ differential privacy, showing that the task is impossibleover an infinite domain $X$, and moreover requires sample complexity $n \ge\Omega(\log^*X)$, which grows with the size of the domain. Inspired by thetechniques used to prove this lower bound, we give an algorithm for releasingthresholds with $n \le 2^{(1+ o(1))\log^*X}$ samples. This improves theprevious best upper bound of $8^{(1 + o(1))\log^*X}$ (Beimel et al., RANDOM'13). Our sample complexity upper and lower bounds also apply to the tasks oflearning distributions with respect to Kolmogorov distance and of properly PAClearning thresholds with differential privacy. The lower bound gives the firstseparation between the sample complexity of properly learning a concept classwith $(\epsilon,\delta)$ differential privacy and learning without privacy. Forproperly learning thresholds in $\ell$ dimensions, this lower bound extends to$n \ge \Omega(\ell \cdot \log^*X)$. To obtain our results, we give reductions in both directions from releasingand properly learning thresholds and the simpler interior point problem. Givena database $D$ of elements from $X$, the interior point problem asks for anelement between the smallest and largest elements in $D$. We introduce newrecursive constructions for bounding the sample complexity of the interiorpoint problem, as well as further reductions and techniques for provingimpossibility results for other basic problems in differential privacy.
arxiv-10200-141 | Speeding Up Neural Networks for Large Scale Classification using WTA Hashing | http://arxiv.org/pdf/1504.07488v1.pdf | author:Amir H. Bakhtiary, Agata Lapedriza, David Masip category:cs.CV published:2015-04-28 summary:In this paper we propose to use the Winner Takes All hashing technique tospeed up forward propagation and backward propagation in fully connected layersin convolutional neural networks. The proposed technique reduces significantlythe computational complexity, which in turn, allows us to train layers with alarge number of kernels with out the associated time penalty. As a consequence we are able to train convolutional neural network on a verylarge number of output classes with only a small increase in the computationalcost. To show the effectiveness of the technique we train a new output layer ona pretrained network using both the regular multiplicative approach and ourproposed hashing methodology. Our results showed no drop in performance anddemonstrate, with our implementation, a 7 fold speed up during the training.
arxiv-10200-142 | Entity-Augmented Distributional Semantics for Discourse Relations | http://arxiv.org/pdf/1412.5673v3.pdf | author:Yangfeng Ji, Jacob Eisenstein category:cs.CL cs.LG published:2014-12-17 summary:Discourse relations bind smaller linguistic elements into coherent texts.However, automatically identifying discourse relations is difficult, because itrequires understanding the semantics of the linked sentences. A more subtlechallenge is that it is not enough to represent the meaning of each sentence ofa discourse relation, because the relation may depend on links betweenlower-level elements, such as entity mentions. Our solution computesdistributional meaning representations by composition up the syntactic parsetree. A key difference from previous work on compositional distributionalsemantics is that we also compute representations for entity mentions, using anovel downward compositional pass. Discourse relations are predicted not onlyfrom the distributional representations of the sentences, but also of theircoreferent entity mentions. The resulting system obtains substantialimprovements over the previous state-of-the-art in predicting implicitdiscourse relations in the Penn Discourse Treebank.
arxiv-10200-143 | Identifying Reliable Annotations for Large Scale Image Segmentation | http://arxiv.org/pdf/1504.07460v1.pdf | author:Alexander Kolesnikov, Christoph H. Lampert category:cs.CV published:2015-04-28 summary:Challenging computer vision tasks, in particular semantic image segmentation,require large training sets of annotated images. While obtaining the actualimages is often unproblematic, creating the necessary annotation is a tediousand costly process. Therefore, one often has to work with unreliable annotationsources, such as Amazon Mechanical Turk or (semi-)automatic algorithmictechniques. In this work, we present a Gaussian process (GP) based techniquefor simultaneously identifying which images of a training set have unreliableannotation and learning a segmentation model in which the negative effect ofthese images is suppressed. Alternatively, the model can also just be used toidentify the most reliably annotated images from the training set, which canthen be used for training any other segmentation method. By relying on "deepfeatures" in combination with a linear covariance function, our GP can belearned and its hyperparameter determined efficiently using only matrixoperations and gradient-based optimization. This makes our method scalable evento large datasets with several million training instances.
arxiv-10200-144 | CommentWatcher: An Open Source Web-based platform for analyzing discussions on web forums | http://arxiv.org/pdf/1504.07459v1.pdf | author:Marian-Andrei Rizoiu, Adrien Guille, Julien Velcin category:cs.CL cs.SI published:2015-04-28 summary:We present CommentWatcher, an open source tool aimed at analyzing discussionson web forums. Constructed as a web platform, CommentWatcher features automaticmass fetching of user posts from forum on multiple sites, extracting topics,visualizing the topics as an expression cloud and exploring their temporalevolution. The underlying social network of users is simultaneously constructedusing the citation relations between users and visualized as a graph structure.Our platform addresses the issues of the diversity and dynamics of structuresof webpages hosting the forums by implementing a parser architecture that isindependent of the HTML structure of webpages. This allows easy on-the-flyadding of new websites. Two types of users are targeted: end users who seek tostudy the discussed topics and their temporal evolution, and researchers inneed of establishing a forum benchmark dataset and comparing the performancesof analysis tools.
arxiv-10200-145 | Embedded Platforms for Computer Vision-based Advanced Driver Assistance Systems: a Survey | http://arxiv.org/pdf/1504.07442v1.pdf | author:Gorka Velez, Oihana Otaegui category:cs.CV published:2015-04-28 summary:Computer Vision, either alone or combined with other technologies such asradar or Lidar, is one of the key technologies used in Advanced DriverAssistance Systems (ADAS). Its role understanding and analysing the drivingscene is of great importance as it can be noted by the number of ADASapplications that use this technology. However, porting a vision algorithm toan embedded automotive system is still very challenging, as there must be atrade-off between several design requisites. Furthermore, there is not astandard implementation platform, so different alternatives have been proposedby both the scientific community and the industry. This paper aims to reviewthe requisites and the different embedded implementation platforms that can beused for Computer Vision-based ADAS, with a critical analysis and an outlook tofuture trends.
arxiv-10200-146 | Provable Methods for Training Neural Networks with Sparse Connectivity | http://arxiv.org/pdf/1412.2693v4.pdf | author:Hanie Sedghi, Anima Anandkumar category:cs.LG cs.NE stat.ML published:2014-12-08 summary:We provide novel guaranteed approaches for training feedforward neuralnetworks with sparse connectivity. We leverage on the techniques developedpreviously for learning linear networks and show that they can also beeffectively adopted to learn non-linear networks. We operate on the momentsinvolving label and the score function of the input, and show that theirfactorization provably yields the weight matrix of the first layer of a deepnetwork under mild conditions. In practice, the output of our method can beemployed as effective initializers for gradient descent.
arxiv-10200-147 | Lexical Translation Model Using a Deep Neural Network Architecture | http://arxiv.org/pdf/1504.07395v1.pdf | author:Thanh-Le Ha, Jan Niehues, Alex Waibel category:cs.CL cs.LG cs.NE published:2015-04-28 summary:In this paper we combine the advantages of a model using global sourcesentence contexts, the Discriminative Word Lexicon, and neural networks. Byusing deep neural networks instead of the linear maximum entropy model in theDiscriminative Word Lexicon models, we are able to leverage dependenciesbetween different source words due to the non-linearity. Furthermore, themodels for different target words can share parameters and therefore datasparsity problems are effectively reduced. By using this approach in a state-of-the-art translation system, we canimprove the performance by up to 0.5 BLEU points for three different languagepairs on the TED translation task.
arxiv-10200-148 | Building Classifiers to Predict the Start of Glucose-Lowering Pharmacotherapy Using Belgian Health Expenditure Data | http://arxiv.org/pdf/1504.07389v1.pdf | author:Marc Claesen, Frank De Smet, Pieter Gillard, Chantal Mathieu, Bart De Moor category:stat.ML cs.IR I.5.4; J.3 published:2015-04-28 summary:Early diagnosis is important for type 2 diabetes (T2D) to improve patientprognosis, prevent complications and reduce long-term treatment costs. Wepresent a novel risk profiling approach based exclusively on health expendituredata that is available to Belgian mutual health insurers. We used expendituredata related to drug purchases and medical provisions to construct models thatpredict whether a patient will start glucose-lowering pharmacotherapy in thecoming years, based on that patient's recent medical expenditure history. Thedesign and implementation of the modeling strategy are discussed in detail andseveral learning methods are benchmarked for our application. Our bestperforming model obtains between 74.9% and 76.8% area under the ROC curve,which is comparable to state-of-the-art risk prediction approaches for T2Dbased on questionnaires. In contrast to other methods, our approach can beimplemented on a population-wide scale at virtually no extra operational cost.Possibly, our approach can be further improved by additional information aboutsome risk factors of T2D that is unavailable in health expenditure data.
arxiv-10200-149 | Audio Source Separation with Discriminative Scattering Networks | http://arxiv.org/pdf/1412.7022v3.pdf | author:Pablo Sprechmann, Joan Bruna, Yann LeCun category:cs.SD cs.LG published:2014-12-22 summary:In this report we describe an ongoing line of research for solvingsingle-channel source separation problems. Many monaural signal decompositiontechniques proposed in the literature operate on a feature space consisting ofa time-frequency representation of the input data. A challenge faced by theseapproaches is to effectively exploit the temporal dependencies of the signalsat scales larger than the duration of a time-frame. In this work we propose totackle this problem by modeling the signals using a time-frequencyrepresentation with multiple temporal resolutions. The proposed representationconsists of a pyramid of wavelet scattering operators, which generalizesConstant Q Transforms (CQT) with extra layers of convolution and complexmodulus. We first show that learning standard models with this multi-resolutionsetting improves source separation results over fixed-resolution methods. Asstudy case, we use Non-Negative Matrix Factorizations (NMF) that has beenwidely considered in many audio application. Then, we investigate the inclusionof the proposed multi-resolution setting into a discriminative training regime.We discuss several alternatives using different deep neural networkarchitectures.
arxiv-10200-150 | Combined A*-Ants Algorithm: A New Multi-Parameter Vehicle Navigation Scheme | http://arxiv.org/pdf/1504.07329v1.pdf | author:Hojjat Salehinejad, Hossein Nezamabadi-pour, Saeid Saryazdi, Fereydoun Farrahi-Moghaddam category:cs.NE published:2015-04-28 summary:In this paper a multi-parameter A*(A- star)-ants based algorithm is proposedin order to find the best optimized multi-parameter path between two desiredpoints in regions. This algorithm recognizes paths, according to user desiredparameters using electronic maps. The proposed algorithm is a combination of A*and ants algorithm in which the proposed A* algorithm is the prologue to thesuggested ant based algorithm .In fact, this A* algorithm invigorates somepaths pheromones in ants algorithm. As one of implementations of this method,this algorithm was applied on a part of Kerman city, Iran as a multi-parametervehicle navigator. It finds the best optimized multi-parameter directionbetween two desired junctions based on city traveler parameters. Comparisonresults between the proposed method and ants algorithm demonstrates efficiencyand lower cost function results of the proposed method versus ants algorithm.
arxiv-10200-151 | Toward Smart Power Grids: Communication Network Design for Power Grids Synchronization | http://arxiv.org/pdf/1504.07327v1.pdf | author:Hojjat Salehinejad, Farhad Pouladi, Siamak Talebi category:cs.NE published:2015-04-28 summary:In smart power grids, keeping the synchronicity of generators and thecorresponding controls is of great importance. To do so, a simple model isemployed in terms of swing equation to represent the interactions amongdynamics of generators and feedback control. In case of having a communicationnetwork available, the control can be done based on the transmittedmeasurements by the communication network. The stability of system is denotedby the largest eigenvalue of the weighted sum of the Laplacian matrices of thecommunication infrastructure and power network. In this work, we use graphtheory to model the communication network as a graph problem. Then, Ant ColonySystem (ACS) is employed for optimum design of above graph for synchronizationof power grids. Performance evaluation of the proposed method for the 39-busNew England power system versus methods such as exhaustive search and Rayleighquotient approximation indicates feasibility and effectiveness of our methodfor even large scale smart power grids.
arxiv-10200-152 | Reader-Aware Multi-Document Summarization via Sparse Coding | http://arxiv.org/pdf/1504.07324v1.pdf | author:Piji Li, Lidong Bing, Wai Lam, Hang Li, Yi Liao category:cs.CL cs.AI published:2015-04-28 summary:We propose a new MDS paradigm called reader-aware multi-documentsummarization (RA-MDS). Specifically, a set of reader comments associated withthe news reports are also collected. The generated summaries from the reportsfor the event should be salient according to not only the reports but also thereader comments. To tackle this RA-MDS problem, we propose asparse-coding-based method that is able to calculate the salience of the textunits by jointly considering news reports and reader comments. Anotherreader-aware characteristic of our framework is to improve linguistic qualityvia entity rewriting. The rewriting consideration is jointly assessed togetherwith other summarization requirements under a unified optimization model. Tosupport the generation of compressive summaries via optimization, we explore afiner syntactic unit, namely, noun/verb phrase. In this work, we also generatea data set for conducting RA-MDS. Extensive experiments on this data set andsome classical data sets demonstrate the effectiveness of our proposedapproach.
arxiv-10200-153 | Private Disclosure of Information in Health Tele-monitoring | http://arxiv.org/pdf/1504.07313v1.pdf | author:Daniel Aranki, Ruzena Bajcsy category:cs.CR cs.AI cs.IT cs.LG math.IT published:2015-04-28 summary:We present a novel framework, called Private Disclosure of Information (PDI),which is aimed to prevent an adversary from inferring certain sensitiveinformation about subjects using the data that they disclosed duringcommunication with an intended recipient. We show cases where it is possible toachieve perfect privacy regardless of the adversary's auxiliary knowledge whilepreserving full utility of the information to the intended recipient andprovide sufficient conditions for such cases. We also demonstrate theapplicability of PDI on a real-world data set that simulates a healthtele-monitoring scenario.
arxiv-10200-154 | Mid-level Elements for Object Detection | http://arxiv.org/pdf/1504.07284v1.pdf | author:Aayush Bansal, Abhinav Shrivastava, Carl Doersch, Abhinav Gupta category:cs.CV published:2015-04-27 summary:Building on the success of recent discriminative mid-level elements, wepropose a surprisingly simple approach for object detection which performscomparable to the current state-of-the-art approaches on PASCAL VOC comp-3detection challenge (no external data). Through extensive experiments andablation analysis, we show how our approach effectively improves upon theHOG-based pipelines by adding an intermediate mid-level representation for thetask of object detection. This representation is easily interpretable andallows us to visualize what our object detector "sees". We also discuss theinsights our approach shares with CNN-based methods, such as sharingrepresentation between categories helps.
arxiv-10200-155 | EgoSampling: Fast-Forward and Stereo for Egocentric Videos | http://arxiv.org/pdf/1412.3596v2.pdf | author:Yair Poleg, Tavi Halperin, Chetan Arora, Shmuel Peleg category:cs.CV cs.MM published:2014-12-11 summary:While egocentric cameras like GoPro are gaining popularity, the videos theycapture are long, boring, and difficult to watch from start to end. Fastforwarding (i.e. frame sampling) is a natural choice for faster video browsing.However, this accentuates the shake caused by natural head motion, making thefast forwarded video useless. We propose EgoSampling, an adaptive frame sampling that gives more stablefast forwarded videos. Adaptive frame sampling is formulated as energyminimization, whose optimal solution can be found in polynomial time. In addition, egocentric video taken while walking suffers from the left-rightmovement of the head as the body weight shifts from one leg to another. We turnthis drawback into a feature: Stereo video can be created by sampling theframes from the left most and right most head positions of each step, formingapproximate stereo-pairs.
arxiv-10200-156 | Learning Deep Structured Models | http://arxiv.org/pdf/1407.2538v3.pdf | author:Liang-Chieh Chen, Alexander G. Schwing, Alan L. Yuille, Raquel Urtasun category:cs.LG published:2014-07-09 summary:Many problems in real-world applications involve predicting several randomvariables which are statistically related. Markov random fields (MRFs) are agreat mathematical tool to encode such relationships. The goal of this paper isto combine MRFs with deep learning algorithms to estimate complexrepresentations while taking into account the dependencies between the outputrandom variables. Towards this goal, we propose a training algorithm that isable to learn structured models jointly with deep features that form the MRFpotentials. Our approach is efficient as it blends learning and inference andmakes use of GPU acceleration. We demonstrate the effectiveness of ouralgorithm in the tasks of predicting words from noisy images, as well asmulti-class classification of Flickr photographs. We show that joint learningof the deep features and the MRF parameters results in significant performancegains.
arxiv-10200-157 | Optimal Convergence Rate in Feed Forward Neural Networks using HJB Equation | http://arxiv.org/pdf/1504.07278v1.pdf | author:Vipul Arora, Laxmidhar Behera, Ajay Pratap Yadav category:cs.NE published:2015-04-27 summary:A control theoretic approach is presented in this paper for both batch andinstantaneous updates of weights in feed-forward neural networks. The popularHamilton-Jacobi-Bellman (HJB) equation has been used to generate an optimalweight update law. The remarkable contribution in this paper is that closedform solutions for both optimal cost and weight update can be achieved for anyfeed-forward network using HJB equation in a simple yet elegant manner. Theproposed approach has been compared with some of the existing best performinglearning algorithms. It is found as expected that the proposed approach isfaster in convergence in terms of computational time. Some of the benchmarktest data such as 8-bit parity, breast cancer and credit approval, as well as2D Gabor function have been used to validate our claims. The paper alsodiscusses issues related to global optimization. The limitations of populardeterministic weight update laws are critiqued and the possibility of globaloptimization using HJB formulation is discussed. It is hoped that the proposedalgorithm will bring in a lot of interest in researchers working in developingfast learning algorithms and global optimization.
arxiv-10200-158 | Surrogate regret bounds for generalized classification performance metrics | http://arxiv.org/pdf/1504.07272v1.pdf | author:Wojciech Kotłowski, Krzysztof Dembczyński category:cs.LG published:2015-04-27 summary:We consider optimization of generalized performance metrics for binaryclassification by means of surrogate loss. We focus on a class of metrics,which are linear-fractional functions of the false positive and false negativerates (examples of which include $F_{\beta}$-measure, Jaccard similaritycoefficient, AM measure, and many others). Our analysis concerns the followingtwo-step procedure. First, a real-valued function $f$ is learned by minimizinga surrogate loss for binary classification on the training sample. It isassumed that the surrogate loss is a strongly proper composite loss function(examples of which include logistic loss, squared-error loss, exponential loss,etc.). Then, given $f$, a threshold $\hat{\theta}$ is tuned on a separatevalidation sample, by direct optimization of the target performance measure. Weshow that the regret of the resulting classifier (obtained from thresholding$f$ on $\hat{\theta}$) measured with respect to the target metric isupperbounded by the regret of $f$ measured with respect to the surrogate loss.Our finding is further analyzed in a computational study on both synthetic andreal data sets.
arxiv-10200-159 | Dynamic Body VSLAM with Semantic Constraints | http://arxiv.org/pdf/1504.07269v1.pdf | author:N. Dinesh Reddy, Prateek Singhal, Visesh Chari, K. Madhava Krishna category:cs.CV published:2015-04-27 summary:Image based reconstruction of urban environments is a challenging problemthat deals with optimization of large number of variables, and has severalsources of errors like the presence of dynamic objects. Since most large scaleapproaches make the assumption of observing static scenes, dynamic objects arerelegated to the noise modeling section of such systems. This is an approach ofconvenience since the RANSAC based framework used to compute most multiviewgeometric quantities for static scenes naturally confine dynamic objects to theclass of outlier measurements. However, reconstructing dynamic objects alongwith the static environment helps us get a complete picture of an urbanenvironment. Such understanding can then be used for important robotic taskslike path planning for autonomous navigation, obstacle tracking and avoidance,and other areas. In this paper, we propose a system for robust SLAM that worksin both static and dynamic environments. To overcome the challenge of dynamicobjects in the scene, we propose a new model to incorporate semanticconstraints into the reconstruction algorithm. While some of these constraintsare based on multi-layered dense CRFs trained over appearance as well as motioncues, other proposed constraints can be expressed as additional terms in thebundle adjustment optimization process that does iterative refinement of 3Dstructure and camera / object motion trajectories. We show results on thechallenging KITTI urban dataset for accuracy of motion segmentation andreconstruction of the trajectory and shape of moving objects relative to groundtruth. We are able to show average relative error reduction by a significantamount for moving object trajectory reconstruction relative to state-of-the-artmethods like VISO 2, as well as standard bundle adjustment algorithms.
arxiv-10200-160 | Image Segmentation and Restoration Using Parametric Contours With Free Endpoints | http://arxiv.org/pdf/1504.07259v1.pdf | author:Heike Benninghoff, Harald Garcke category:cs.CV math.AP math.NA published:2015-04-27 summary:In this paper, we introduce a novel approach for active contours with freeendpoints. A scheme is presented for image segmentation and restoration basedon a discrete version of the Mumford-Shah functional where the contours can beboth closed and open curves. Additional to a flow of the curves in normaldirection, evolution laws for the tangential flow of the endpoints are derived.Using a parametric approach to describe the evolving contours together with anedge-preserving denoising, we obtain a fast method for image segmentation andrestoration. The analytical and numerical schemes are presented followed bynumerical experiments with artificial test images and with a real medicalimage.
arxiv-10200-161 | Sign Stable Random Projections for Large-Scale Learning | http://arxiv.org/pdf/1504.07235v1.pdf | author:Ping Li category:stat.ML cs.LG stat.CO published:2015-04-27 summary:We study the use of "sign $\alpha$-stable random projections" (where$0<\alpha\leq 2$) for building basic data processing tools in the context oflarge-scale machine learning applications (e.g., classification, regression,clustering, and near-neighbor search). After the processing by sign stablerandom projections, the inner products of the processed data approximatevarious types of nonlinear kernels depending on the value of $\alpha$. Thus,this approach provides an effective strategy for approximating nonlinearlearning algorithms essentially at the cost of linear learning. When $\alpha=2$, it is known that the corresponding nonlinear kernel is the arc-cosinekernel. When $\alpha=1$, the procedure approximates the arc-cos-$\chi^2$ kernel(under certain condition). When $\alpha\rightarrow0+$, it corresponds to theresemblance kernel. From practitioners' perspective, the method of sign $\alpha$-stable randomprojections is ready to be tested for large-scale learning applications, where$\alpha$ can be simply viewed as a tuning parameter. What is missing in theliterature is an extensive empirical study to show the effectiveness of signstable random projections, especially for $\alpha\neq 2$ or 1. The papersupplies such a study on a wide variety of classification datasets. Inparticular, we compare shoulder-by-shoulder sign stable random projections withthe recently proposed "0-bit consistent weighted sampling (CWS)" (Li 2015).
arxiv-10200-162 | Self-Adaptive Hierarchical Sentence Model | http://arxiv.org/pdf/1504.05070v2.pdf | author:Han Zhao, Zhengdong Lu, Pascal Poupart category:cs.CL cs.LG cs.NE published:2015-04-20 summary:The ability to accurately model a sentence at varying stages (e.g.,word-phrase-sentence) plays a central role in natural language processing. Asan effort towards this goal we propose a self-adaptive hierarchical sentencemodel (AdaSent). AdaSent effectively forms a hierarchy of representations fromwords to phrases and then to sentences through recursive gated localcomposition of adjacent segments. We design a competitive mechanism (throughgating networks) to allow the representations of the same sentence to beengaged in a particular learning task (e.g., classification), thereforeeffectively mitigating the gradient vanishing problem persistent in otherrecursive models. Both qualitative and quantitative analysis shows that AdaSentcan automatically form and select the representations suitable for the task athand during training, yielding superior classification performance overcompetitor models on 5 benchmark data sets.
arxiv-10200-163 | Combining Local Appearance and Holistic View: Dual-Source Deep Neural Networks for Human Pose Estimation | http://arxiv.org/pdf/1504.07159v1.pdf | author:Xiaochuan Fan, Kang Zheng, Yuewei Lin, Song Wang category:cs.CV published:2015-04-27 summary:We propose a new learning-based method for estimating 2D human pose from asingle image, using Dual-Source Deep Convolutional Neural Networks (DS-CNN).Recently, many methods have been developed to estimate human pose by using posepriors that are estimated from physiologically inspired graphical models orlearned from a holistic perspective. In this paper, we propose to integrateboth the local (body) part appearance and the holistic view of each local partfor more accurate human pose estimation. Specifically, the proposed DS-CNNtakes a set of image patches (category-independent object proposals fortraining and multi-scale sliding windows for testing) as the input and thenlearns the appearance of each local part by considering their holistic views inthe full body. Using DS-CNN, we achieve both joint detection, which determineswhether an image patch contains a body joint, and joint localization, whichfinds the exact location of the joint in the image patch. Finally, we developan algorithm to combine these joint detection/localization results from all theimage patches for estimating the human pose. The experimental results show theeffectiveness of the proposed method by comparing to the state-of-the-arthuman-pose estimation methods based on pose priors that are estimated fromphysiologically inspired graphical models or learned from a holisticperspective.
arxiv-10200-164 | Stochastic Descent Analysis of Representation Learning Algorithms | http://arxiv.org/pdf/1412.5744v6.pdf | author:Richard M. Golden category:stat.ML cs.LG published:2014-12-18 summary:Although stochastic approximation learning methods have been widely used inthe machine learning literature for over 50 years, formal theoretical analysesof specific machine learning algorithms are less common because stochasticapproximation theorems typically possess assumptions which are difficult tocommunicate and verify. This paper presents a new stochastic approximationtheorem for state-dependent noise with easily verifiable assumptions applicableto the analysis and design of important deep learning algorithms including:adaptive learning, contrastive divergence learning, stochastic descentexpectation maximization, and active learning.
arxiv-10200-165 | Shape Representation and Classification through Pattern Spectrum and Local Binary Pattern - A Decision Level Fusion Approach | http://arxiv.org/pdf/1504.07082v1.pdf | author:B. H. Shekar, Bharathi Pilar category:cs.CV published:2015-04-27 summary:In this paper, we present a decision level fused local Morphological PatternSpectrum(PS) and Local Binary Pattern (LBP) approach for an efficient shaperepresentation and classification. This method makes use of Earth MoversDistance(EMD) as the measure in feature matching and shape retrieval process.The proposed approach has three major phases : Feature Extraction, Constructionof hybrid spectrum knowledge base and Classification. In the first phase,feature extraction of the shape is done using pattern spectrum and local binarypattern method. In the second phase, the histograms of both pattern spectrumand local binary pattern are fused and stored in the knowledge base. In thethird phase, the comparison and matching of the features, which are representedin the form of histograms, is done using Earth Movers Distance(EMD) as metric.The top-n shapes are retrieved for each query shape. The accuracy is tested bymeans of standard Bulls eye score method. The experiments are conducted onpublicly available shape datasets like Kimia-99, Kimia-216 and MPEG-7. Thecomparative study is also provided with the well known approaches to exhibitthe retrieval accuracy of the proposed approach.
arxiv-10200-166 | Exploring semantically-related concepts from Wikipedia: the case of SeRE | http://arxiv.org/pdf/1504.07071v1.pdf | author:Daniel Hienert, Dennis Wegener, Siegfried Schomisch category:cs.CL cs.IR published:2015-04-27 summary:In this paper we present our web application SeRE designed to exploresemantically related concepts. Wikipedia and DBpedia are rich data sources toextract related entities for a given topic, like in- and out-links, broader andnarrower terms, categorisation information etc. We use the Wikipedia full textbody to compute the semantic relatedness for extracted terms, which results ina list of entities that are most relevant for a topic. For any given query, theuser interface of SeRE visualizes these related concepts, ordered by semanticrelatedness; with snippets from Wikipedia articles that explain the connectionbetween those two entities. In a user study we examine how SeRE can be used tofind important entities and their relationships for a given topic and to answerthe question of how the classification system can be used for filtering.
arxiv-10200-167 | Attentive monitoring of multiple video streams driven by a Bayesian foraging strategy | http://arxiv.org/pdf/1410.5605v3.pdf | author:Paolo Napoletano, Giuseppe Boccignone, Francesco Tisato category:cs.CV published:2014-10-21 summary:In this paper we shall consider the problem of deploying attention to subsetsof the video streams for collating the most relevant data and information ofinterest related to a given task. We formalize this monitoring problem as aforaging problem. We propose a probabilistic framework to model observer'sattentive behavior as the behavior of a forager. The forager, moment to moment,focuses its attention on the most informative stream/camera, detectsinteresting objects or activities, or switches to a more profitable stream. Theapproach proposed here is suitable to be exploited for multi-stream videosummarization. Meanwhile, it can serve as a preliminary step for moresophisticated video surveillance, e.g. activity and behavior analysis.Experimental results achieved on the UCR Videoweb Activities Dataset, apublicly available dataset, are presented to illustrate the utility of theproposed technique.
arxiv-10200-168 | SegSALSA-STR: A convex formulation to supervised hyperspectral image segmentation using hidden fields and structure tensor regularization | http://arxiv.org/pdf/1504.07028v1.pdf | author:Filipe Condessa, Jose Bioucas-Dias, Jelena Kovacevic category:cs.CV 68 published:2015-04-27 summary:We present a supervised hyperspectral image segmentation algorithm based on aconvex formulation of a marginal maximum a posteriori segmentation with hiddenfields and structure tensor regularization: Segmentation via the ConstraintSplit Augmented Lagrangian Shrinkage by Structure Tensor Regularization(SegSALSA-STR). This formulation avoids the generally discrete nature ofsegmentation problems and the inherent NP-hardness of the integer optimizationassociated. We extend the Segmentation via the Constraint Split Augmented LagrangianShrinkage (SegSALSA) algorithm by generalizing the vectorial total variationprior using a structure tensor prior constructed from a patch-based Jacobian.The resulting algorithm is convex, time-efficient and highly parallelizable.This shows the potential of combining hidden fields with convex optimizationthrough the inclusion of different regularizers. The SegSALSA-STR algorithm isvalidated in the segmentation of real hyperspectral images.
arxiv-10200-169 | On-Board Vision Processing For Small UAVs: Time to Rethink Strategy | http://arxiv.org/pdf/1504.07021v1.pdf | author:Shoaib Ehsan, Klaus D. McDonald-Maier category:cs.CV cs.RO published:2015-04-27 summary:The ultimate research goal for unmanned aerial vehicles (UAVs) is tofacilitate autonomy of operation. Research in the last decade has highlightedthe potential of vision sensing in this regard. Although vital foraccomplishment of missions assigned to any type of unmanned aerial vehicles,vision sensing is more critical for small aerial vehicles due to lack of highprecision inertial sensors. In addition, uncertainty of GPS signal in indoorand urban environments calls for more reliance on vision sensing for such smallvehicles. With off-line processing does not offer an attractive option in termsof autonomy, these vehicles have been challenging platforms to implement visionprocessing onboard due to their strict payload capacity and power budget. Thestrict constraints drive the need for new vision processing architectures forsmall unmanned aerial vehicles. Recent research has shown encouraging resultswith FPGA based hardware architectures. This paper reviews the bottle necksinvolved in implementing vision processing on-board, advocates the potential ofhardware based solutions to tackle strict constraints of small unmanned aerialvehicles and finally analyzes feasibility of ASICs, Structured ASICs and FPGAsfor use on future systems.
arxiv-10200-170 | An Active Learning Based Approach For Effective Video Annotation And Retrieval | http://arxiv.org/pdf/1504.07004v1.pdf | author:Moitreya Chatterjee, Anton Leuski category:cs.MM cs.IR cs.LG H.3.3; H.5.1 published:2015-04-27 summary:Conventional multimedia annotation/retrieval systems such as NormalizedContinuous Relevance Model (NormCRM) [16] require a fully labeled training datafor a good performance. Active Learning, by determining an order for labelingthe training data, allows for a good performance even before the training datais fully annotated. In this work we propose an active learning algorithm, whichcombines a novel measure of sample uncertainty with a novel clustering-basedapproach for determining sample density and diversity and integrate it withNormCRM. The clusters are also iteratively refined to ensure both feature andlabel-level agreement among samples. We show that our approach outperformsmultiple baselines both on a recent, open character animation dataset and onthe popular TRECVID corpus at both the tasks of annotation and text-basedretrieval of videos.
arxiv-10200-171 | Accelerated nonlinear discriminant analysis | http://arxiv.org/pdf/1504.07000v1.pdf | author:Nikolaos Gkalelis, Vasileios Mezaris category:cs.LG published:2015-04-27 summary:In this paper, a novel nonlinear discriminant analysis is proposed.Experimental results show that the new method provides state of the artperformance when combined with LSVM in terms of training time and accuracy.
arxiv-10200-172 | Compression Artifacts Reduction by a Deep Convolutional Network | http://arxiv.org/pdf/1504.06993v1.pdf | author:Chao Dong, Yubin Deng, Chen Change Loy, Xiaoou Tang category:cs.CV I.4.5; I.2.6 published:2015-04-27 summary:Lossy compression introduces complex compression artifacts, particularly theblocking artifacts, ringing effects and blurring. Existing algorithms eitherfocus on removing blocking artifacts and produce blurred output, or restoressharpened images that are accompanied with ringing effects. Inspired by thedeep convolutional networks (DCN) on super-resolution, we formulate a compactand efficient network for seamless attenuation of different compressionartifacts. We also demonstrate that a deeper model can be effectively trainedwith the features learned in a shallow network. Following a similar "easy tohard" idea, we systematically investigate several practical transfer settingsand show the effectiveness of transfer learning in low-level vision problems.Our method shows superior performance than the state-of-the-arts both on thebenchmark datasets and the real-world use case (i.e. Twitter). In addition, weshow that our method can be applied as pre-processing to facilitate otherlow-level vision routines when they take compressed images as input.
arxiv-10200-173 | Modeling Recovery Curves With Application to Prostatectomy | http://arxiv.org/pdf/1504.06964v1.pdf | author:Fulton Wang, Tyler H. McCormick, Cynthia Rudin, John Gore category:stat.ME stat.AP stat.ML published:2015-04-27 summary:We propose a Bayesian model that predicts recovery curves based oninformation available before the disruptive event. A recovery curve of interestis the quantified sexual function of prostate cancer patients afterprostatectomy surgery. We illustrate the utility of our model as apre-treatment medical decision aid, producing personalized predictions that areboth interpretable and accurate. We uncover covariate relationships that agreewith and supplement that in existing medical literature.
arxiv-10200-174 | Concept Extraction to Identify Adverse Drug Reactions in Medical Forums: A Comparison of Algorithms | http://arxiv.org/pdf/1504.06936v1.pdf | author:Alejandro Metke-Jimenez, Sarvnaz Karimi category:cs.AI cs.CL cs.IR published:2015-04-27 summary:Social media is becoming an increasingly important source of information tocomplement traditional pharmacovigilance methods. In order to identify signalsof potential adverse drug reactions, it is necessary to first identify medicalconcepts in the social media text. Most of the existing studies usedictionary-based methods which are not evaluated independently from the overallsignal detection task. We compare different approaches to automatically identify and normalisemedical concepts in consumer reviews in medical forums. Specifically, weimplement several dictionary-based methods popular in the relevant literature,as well as a method we suggest based on a state-of-the-art machine learningmethod for entity recognition. MetaMap, a popular biomedical concept extractiontool, is used as a baseline. Our evaluations were performed in a controlledsetting on a common corpus which is a collection of medical forum postsannotated with concepts and linked to controlled vocabularies such as MedDRAand SNOMED CT. To our knowledge, our study is the first to systematically examine the effectof popular concept extraction methods in the area of signal detection foradverse reactions. We show that the choice of algorithm or controlledvocabulary has a significant impact on concept extraction, which will impactthe overall signal detection process. We also show that our proposed machinelearning approach significantly outperforms all the other methods inidentification of both adverse reactions and drugs, even when trained with arelatively small set of annotated text.
arxiv-10200-175 | Detection and Recognition of Malaysian Special License Plate Based On SIFT Features | http://arxiv.org/pdf/1504.06921v1.pdf | author:Hooi Sin Ng, Yong Haur Tay, Kim Meng Liang, Hamam Mokayed, Hock Woon Hon category:cs.CV published:2015-04-27 summary:Automated car license plate recognition systems are developed and applied forpurpose of facilitating the surveillance, law enforcement, access control andintelligent transportation monitoring with least human intervention. In thispaper, an algorithm based on SIFT feature points clustering and matching isproposed to address the issue of recognizing Malaysian special plates. Thesespecial plates do not follow the format of standard car plates as they maycontain italic, cursive, connected and small letters. The algorithm is testedwith 150 Malaysian special plate images under different environment and thepromising experimental results demonstrate that the proposed algorithm isrelatively robust.
arxiv-10200-176 | Neural Responding Machine for Short-Text Conversation | http://arxiv.org/pdf/1503.02364v2.pdf | author:Lifeng Shang, Zhengdong Lu, Hang Li category:cs.CL cs.AI cs.NE published:2015-03-09 summary:We propose Neural Responding Machine (NRM), a neural network-based responsegenerator for Short-Text Conversation. NRM takes the general encoder-decoderframework: it formalizes the generation of response as a decoding process basedon the latent representation of the input text, while both encoding anddecoding are realized with recurrent neural networks (RNN). The NRM is trainedwith a large amount of one-round conversation data collected from amicroblogging service. Empirical study shows that NRM can generategrammatically correct and content-wise appropriate responses to over 75% of theinput text, outperforming state-of-the-arts in the same setting, includingretrieval-based and SMT-based models.
arxiv-10200-177 | Linear Spatial Pyramid Matching Using Non-convex and non-negative Sparse Coding for Image Classification | http://arxiv.org/pdf/1504.06897v1.pdf | author:Chengqiang Bao, Liangtian He, Yilun Wang category:cs.CV cs.LG 68T45 I.5.2 published:2015-04-27 summary:Recently sparse coding have been highly successful in image classificationmainly due to its capability of incorporating the sparsity of imagerepresentation. In this paper, we propose an improved sparse coding model basedon linear spatial pyramid matching(SPM) and Scale Invariant Feature Transform(SIFT ) descriptors. The novelty is the simultaneous non-convex andnon-negative characters added to the sparse coding model. Our numericalexperiments show that the improved approach using non-convex and non-negativesparse coding is superior than the original ScSPM[1] on several typicaldatabases.
arxiv-10200-178 | Bayesian kernel-based system identification with quantized output data | http://arxiv.org/pdf/1504.06877v1.pdf | author:Giulio Bottegal, Gianluigi Pillonetto, Håkan Hjalmarsson category:cs.SY stat.ML published:2015-04-26 summary:In this paper we introduce a novel method for linear system identificationwith quantized output data. We model the impulse response as a zero-meanGaussian process whose covariance (kernel) is given by the recently proposedstable spline kernel, which encodes information on regularity and exponentialstability. This serves as a starting point to cast our system identificationproblem into a Bayesian framework. We employ Markov Chain Monte Carlo (MCMC)methods to provide an estimate of the system. In particular, we show how todesign a Gibbs sampler which quickly converges to the target distribution.Numerical simulations show a substantial improvement in the accuracy of theestimates over state-of-the-art kernel-based methods when employed inidentification of systems with quantized data.
arxiv-10200-179 | Autonomy and Reliability of Continuous Active Learning for Technology-Assisted Review | http://arxiv.org/pdf/1504.06868v1.pdf | author:Gordon V. Cormack, Maura R. Grossman category:cs.IR cs.LG published:2015-04-26 summary:We enhance the autonomy of the continuous active learning method shown byCormack and Grossman (SIGIR 2014) to be effective for technology-assistedreview, in which documents from a collection are retrieved and reviewed, usingrelevance feedback, until substantially all of the relevant documents have beenreviewed. Autonomy is enhanced through the elimination of topic-specific anddataset-specific tuning parameters, so that the sole input required by the useris, at the outset, a short query, topic description, or single relevantdocument; and, throughout the review, ongoing relevance assessments of theretrieved documents. We show that our enhancements consistently yield superiorresults to Cormack and Grossman's version of continuous active learning, andother methods, not only on average, but on the vast majority of topics fromfour separate sets of tasks: the legal datasets examined by Cormack andGrossman, the Reuters RCV1-v2 subject categories, the TREC 6 AdHoc task, andthe construction of the TREC 2002 filtering test collection.
arxiv-10200-180 | Fast Dictionary Matching for Content-based Image Retrieval | http://arxiv.org/pdf/1504.06864v1.pdf | author:Patryk Najgebauer, Janusz Rygal, Tomasz Nowak, Jakub Romanowski, Leszek Rutkowski, Sviatoslav Voloshynovskiy, Rafal Scherer category:cs.CV published:2015-04-26 summary:This paper describes a method for searching for common sets of descriptorsbetween collections of images. The presented method operates on local interestkeypoints, which are generated using the SURF algorithm. The use of adictionary of descriptors allowed achieving good performance of thecontent-based image retrieval. The method can be used to initially determine aset of similar pairs of keypoints between images. For this purpose, we use acertain level of tolerance between values of descriptors, as values of featuredescriptors are almost never equal but similar between different images. Afterthat, the method compares the structure of rotation and location of interestpoints in one image with the point structure in other images. Thus, we wereable to find similar areas in images and determine the level of similaritybetween them, even when images contain different scenes.
arxiv-10200-181 | When Hillclimbers Beat Genetic Algorithms in Multimodal Optimization | http://arxiv.org/pdf/1504.06859v1.pdf | author:Fernando G. Lobo, Mosab Bazargani category:cs.NE published:2015-04-26 summary:It has been shown in the past that a multistart hillclimbing strategycompares favourably to a standard genetic algorithm with respect to solvinginstances of the multimodal problem generator. We extend that work and verifyif the utilization of diversity preservation techniques in the geneticalgorithm changes the outcome of the comparison. We do so under two scenarios:(1) when the goal is to find the global optimum, (2) when the goal is to findall optima. A mathematical analysis is performed for the multistart hillclimbingalgorithm and a through empirical study is conducted for solving instances ofthe multimodal problem generator with increasing number of optima, both withthe hillclimbing strategy as well as with genetic algorithms with niching.Although niching improves the performance of the genetic algorithm, it is stillinferior to the multistart hillclimbing strategy on this class of problems. An idealized niching strategy is also presented and it is argued that itsperformance should be close to a lower bound of what any evolutionary algorithmcan do on this class of problems.
arxiv-10200-182 | Unregularized Online Learning Algorithms with General Loss Functions | http://arxiv.org/pdf/1503.00623v2.pdf | author:Yiming Ying, Ding-Xuan Zhou category:cs.LG stat.ML published:2015-03-02 summary:In this paper, we consider unregularized online learning algorithms in aReproducing Kernel Hilbert Spaces (RKHS). Firstly, we derive explicitconvergence rates of the unregularized online learning algorithms forclassification associated with a general gamma-activating loss (see Definition1 in the paper). Our results extend and refine the results in Ying and Pontil(2008) for the least-square loss and the recent result in Bach and Moulines(2011) for the loss function with a Lipschitz-continuous gradient. Moreover, weestablish a very general condition on the step sizes which guarantees theconvergence of the last iterate of such algorithms. Secondly, we establish, forthe first time, the convergence of the unregularized pairwise learningalgorithm with a general loss function and derive explicit rates under theassumption of polynomially decaying step sizes. Concrete examples are used toillustrate our main results. The main techniques are tools from convexanalysis, refined inequalities of Gaussian averages, and an induction approach.
arxiv-10200-183 | Maximum a Posteriori Estimation by Search in Probabilistic Programs | http://arxiv.org/pdf/1504.06848v1.pdf | author:David Tolpin, Frank Wood category:cs.AI stat.ML published:2015-04-26 summary:We introduce an approximate search algorithm for fast maximum a posterioriprobability estimation in probabilistic programs, which we call Bayesian ascentMonte Carlo (BaMC). Probabilistic programs represent probabilistic models withvarying number of mutually dependent finite, countable, and continuous randomvariables. BaMC is an anytime MAP search algorithm applicable to anycombination of random variables and dependencies. We compare BaMC to other MAPestimation algorithms and show that BaMC is faster and more robust on a rangeof probabilistic models.
arxiv-10200-184 | Comparison of Training Methods for Deep Neural Networks | http://arxiv.org/pdf/1504.06825v1.pdf | author:Patrick O. Glauner category:cs.LG cs.AI published:2015-04-26 summary:This report describes the difficulties of training neural networks and inparticular deep neural networks. It then provides a literature review oftraining methods for deep neural networks, with a focus on pre-training. Itfocuses on Deep Belief Networks composed of Restricted Boltzmann Machines andStacked Autoencoders and provides an outreach on further and alternativeapproaches. It also includes related practical recommendations from theliterature on training them. In the second part, initial experiments using someof the covered methods are performed on two databases. In particular,experiments are performed on the MNIST hand-written digit dataset and on facialemotion data from a Kaggle competition. The results are discussed in thecontext of results reported in other research papers. An error rate lower thanthe best contribution to the Kaggle competition is achieved using an optimizedStacked Autoencoder.
arxiv-10200-185 | Analysis of Nuclear Norm Regularization for Full-rank Matrix Completion | http://arxiv.org/pdf/1504.06817v1.pdf | author:Lijun Zhang, Tianbao Yang, Rong Jin, Zhi-Hua Zhou category:cs.LG stat.ML published:2015-04-26 summary:In this paper, we provide a theoretical analysis of the nuclear-normregularized least squares for full-rank matrix completion. Although similarformulations have been examined by previous studies, their results areunsatisfactory because only additive upper bounds are provided. Under theassumption that the top eigenspaces of the target matrix are incoherent, wederive a relative upper bound for recovering the best low-rank approximation ofthe unknown matrix. Our relative upper bound is tighter than previous additivebounds of other methods if the mass of the target matrix is concentrated on itstop eigenspaces, and also implies perfect recovery if it is low-rank. Theanalysis is built upon the optimality condition of the regularized formulationand existing guarantees for low-rank matrix completion. To the best of ourknowledge, this is first time such a relative bound is proved for theregularized formulation of matrix completion.
arxiv-10200-186 | Overlapping Community Detection by Online Cluster Aggregation | http://arxiv.org/pdf/1504.06798v1.pdf | author:Mark Kozdoba, Shie Mannor category:cs.LG cs.SI physics.soc-ph published:2015-04-26 summary:We present a new online algorithm for detecting overlapping communities. Themain ingredients are a modification of an online k-means algorithm and a newapproach to modelling overlap in communities. An evaluation on large benchmarkgraphs shows that the quality of discovered communities compares favorably toseveral methods in the recent literature, while the running time issignificantly improved.
arxiv-10200-187 | Viewpoints and Keypoints | http://arxiv.org/pdf/1411.6067v2.pdf | author:Shubham Tulsiani, Jitendra Malik category:cs.CV published:2014-11-22 summary:We characterize the problem of pose estimation for rigid objects in terms ofdetermining viewpoint to explain coarse pose and keypoint prediction to capturethe finer details. We address both these tasks in two different settings - theconstrained setting with known bounding boxes and the more challengingdetection setting where the aim is to simultaneously detect and correctlyestimate pose of objects. We present Convolutional Neural Network basedarchitectures for these and demonstrate that leveraging viewpoint estimates cansubstantially improve local appearance based keypoint predictions. In additionto achieving significant improvements over state-of-the-art in the above tasks,we analyze the error modes and effect of object characteristics on performanceto guide future efforts towards this goal.
arxiv-10200-188 | Spy vs. Spy: Rumor Source Obfuscation | http://arxiv.org/pdf/1412.8439v3.pdf | author:Giulia Fanti, Peter Kairouz, Sewoong Oh, Pramod Viswanath category:cs.SI cs.LG published:2014-12-29 summary:Anonymous messaging platforms, such as Secret and Whisper, have emerged asimportant social media for sharing one's thoughts without the fear of beingjudged by friends, family, or the public. Further, such anonymous platforms arecrucial in nations with authoritarian governments; the right to free expressionand sometimes the personal safety of the author of the message depend onanonymity. Whether for fear of judgment or personal endangerment, it is crucialto keep anonymous the identity of the user who initially posted a sensitivemessage. In this paper, we consider an adversary who observes a snapshot of thespread of a message at a certain time. Recent advances in rumor sourcedetection shows that the existing messaging protocols are vulnerable againstsuch an adversary. We introduce a novel messaging protocol, which we calladaptive diffusion, and show that it spreads the messages fast and achieves aperfect obfuscation of the source when the underlying contact network is aninfinite regular tree: all users with the message are nearly equally likely tohave been the origin of the message. Experiments on a sampled Facebook networkshow that it effectively hides the location of the source even when the graphis finite, irregular and has cycles. We further consider a stronger adversarialmodel where a subset of colluding users track the reception of messages. Weshow that the adaptive diffusion provides a strong protection of the anonymityof the source even under this scenario.
arxiv-10200-189 | Exploring Transfer Function Nonlinearity in Echo State Networks | http://arxiv.org/pdf/1502.04423v2.pdf | author:Alireza Goudarzi, Alireza Shabani, Darko Stefanovic category:cs.NE published:2015-02-16 summary:Supralinear and sublinear pre-synaptic and dendritic integration isconsidered to be responsible for nonlinear computation power of biologicalneurons, emphasizing the role of nonlinear integration as opposed to nonlinearoutput thresholding. How, why, and to what degree the transfer functionnonlinearity helps biologically inspired neural network models is not fullyunderstood. Here, we study these questions in the context of echo statenetworks (ESN). ESN is a simple neural network architecture in which a fixedrecurrent network is driven with an input signal, and the output is generatedby a readout layer from the measurements of the network states. ESNarchitecture enjoys efficient training and good performance on certainsignal-processing tasks, such as system identification and time seriesprediction. ESN performance has been analyzed with respect to the connectivitypattern in the network structure and the input bias. However, the effects ofthe transfer function in the network have not been studied systematically.Here, we use an approach tanh on the Taylor expansion of a frequently usedtransfer function, the hyperbolic tangent function, to systematically study theeffect of increasing nonlinearity of the transfer function on the memory,nonlinear capacity, and signal processing performance of ESN. Interestingly, wefind that a quadratic approximation is enough to capture the computationalpower of ESN with tanh function. The results of this study apply to bothsoftware and hardware implementation of ESN.
arxiv-10200-190 | Hierarchical Composition of Memristive Networks for Real-Time Computing | http://arxiv.org/pdf/1504.02833v2.pdf | author:Jens Bürger, Alireza Goudarzi, Darko Stefanovic, Christof Teuscher category:cs.ET cs.NE published:2015-04-11 summary:Advances in materials science have led to physical instantiations ofself-assembled networks of memristive devices and demonstrations of theircomputational capability through reservoir computing. Reservoir computing is anapproach that takes advantage of collective system dynamics for real-timecomputing. A dynamical system, called a reservoir, is excited with atime-varying signal and observations of its states are used to reconstruct adesired output signal. However, such a monolithic assembly limits thecomputational power due to signal interdependency and the resulting correlatedreadouts. Here, we introduce an approach that hierarchically composes a set ofinterconnected memristive networks into a larger reservoir. We use signalamplification and restoration to reduce reservoir state correlation, whichimproves the feature extraction from the input signals. Using the same numberof output signals, such a hierarchical composition of heterogeneous smallnetworks outperforms monolithic memristive networks by at least 20% on waveformgeneration tasks. On the NARMA-10 task, we reduce the error by up to a factorof 2 compared to homogeneous reservoirs with sigmoidal neurons, whereas singlememristive networks are unable to produce the correct result. Hierarchicalcomposition is key for solving more complex tasks with such novel nano-scalehardware.
arxiv-10200-191 | Product Reservoir Computing: Time-Series Computation with Multiplicative Neurons | http://arxiv.org/pdf/1502.00718v2.pdf | author:Alireza Goudarzi, Alireza Shabani, Darko Stefanovic category:cs.NE published:2015-02-03 summary:Echo state networks (ESN), a type of reservoir computing (RC) architecture,are efficient and accurate artificial neural systems for time series processingand learning. An ESN consists of a core of recurrent neural networks, called areservoir, with a small number of tunable parameters to generate ahigh-dimensional representation of an input, and a readout layer which iseasily trained using regression to produce a desired output from the reservoirstates. Certain computational tasks involve real-time calculation of high-ordertime correlations, which requires nonlinear transformation either in thereservoir or the readout layer. Traditional ESN employs a reservoir withsigmoid or tanh function neurons. In contrast, some types of biological neuronsobey response curves that can be described as a product unit rather than a sumand threshold. Inspired by this class of neurons, we introduce a RCarchitecture with a reservoir of product nodes for time series computation. Wefind that the product RC shows many properties of standard ESN such asshort-term memory and nonlinear capacity. On standard benchmarks for chaoticprediction tasks, the product RC maintains the performance of a standardnonlinear ESN while being more amenable to mathematical analysis. Our studyprovides evidence that such networks are powerful in highly nonlinear tasksowing to high-order statistics generated by the recurrent product nodereservoir.
arxiv-10200-192 | Hypercolumns for Object Segmentation and Fine-grained Localization | http://arxiv.org/pdf/1411.5752v2.pdf | author:Bharath Hariharan, Pablo Arbeláez, Ross Girshick, Jitendra Malik category:cs.CV published:2014-11-21 summary:Recognition algorithms based on convolutional networks (CNNs) typically usethe output of the last layer as feature representation. However, theinformation in this layer may be too coarse to allow precise localization. Onthe contrary, earlier layers may be precise in localization but will notcapture semantics. To get the best of both worlds, we define the hypercolumn ata pixel as the vector of activations of all CNN units above that pixel. Usinghypercolumns as pixel descriptors, we show results on three fine-grainedlocalization tasks: simultaneous detection and segmentation[22], where weimprove state-of-the-art from 49.7[22] mean AP^r to 60.0, keypointlocalization, where we get a 3.3 point boost over[20] and part labeling, wherewe show a 6.6 point gain over a strong baseline.
arxiv-10200-193 | SIFT Vs SURF: Quantifying the Variation in Transformations | http://arxiv.org/pdf/1504.06740v1.pdf | author:Siddharth Srivastava category:cs.CV published:2015-04-25 summary:This paper studies the robustness of SIFT and SURF against different imagetransforms (rigid body, similarity, affine and projective) by quantitativelyanalyzing the variations in the extent of transformations. Previous studieshave been comparing the two techniques on absolute transformations rather thanthe specific amount of deformation caused by the transformation. The paperestablishes an exhaustive empirical analysis of such deformations and matchingcapability of SIFT and SURF with variations in matching parameters and theamount of tolerance. This is helpful in choosing the specific use case forapplying these techniques.
arxiv-10200-194 | Adaptive Locally Affine-Invariant Shape Matching | http://arxiv.org/pdf/1504.06719v1.pdf | author:Smit Marvaniya, Raj Gupta, Anurag Mittal category:cs.CV published:2015-04-25 summary:Matching deformable objects using their shapes is an important problem incomputer vision since shape is perhaps the most distinguishable characteristicof an object. The problem is difficult due to many factors such as intra-classvariations, local deformations, articulations, viewpoint changes and missed andextraneous contour portions due to errors in shape extraction. While smalllocal deformations has been handled in the literature by allowing some leewayin the matching of individual contour points via methods such as Chamferdistance and Hausdorff distance, handling more severe deformations andarticulations has been done by applying local geometric corrections such assimilarity or affine. However, determining which portions of the shape shouldbe used for the geometric corrections is very hard, although some methods havebeen tried. In this paper, we address this problem by an efficient search forthe group of contour segments to be clustered together for a geometriccorrection using Dynamic Programming by essentially searching for thesegmentations of two shapes that lead to the best matching between them. At thesame time, we allow portions of the contours to remain unmatched to handlemissing and extraneous contour portions. Experiments indicate that our methodoutperforms other algorithms, especially when the shapes to be matched are morecomplex.
arxiv-10200-195 | A Prior Distribution over Directed Acyclic Graphs for Sparse Bayesian Networks | http://arxiv.org/pdf/1504.06701v1.pdf | author:Felix L. Rios, John M. Noble, Timo J. T. Koski category:stat.ML published:2015-04-25 summary:The main contribution of this article is a new prior distribution overdirected acyclic graphs, which gives larger weight to sparse graphs. Thisdistribution is intended for structured Bayesian networks, where the structureis given by an ordered block model. That is, the nodes of the graph are objectswhich fall into categories (or blocks); the blocks have a natural ordering. Thepresence of a relationship between two objects is denoted by an arrow, from theobject of lower category to the object of higher category. The modelsconsidered here were introduced in Kemp et al. (2004) for relational data andextended to multivariate data in Mansinghka et al. (2006). The prior over graphstructures presented here has an explicit formula. The number of nodes in eachlayer of the graph follow a Hoppe Ewens urn model. We consider the situation where the nodes of the graph represent randomvariables, whose joint probability distribution factorises along the DAG. Wedescribe Monte Carlo schemes for finding the optimal aposteriori structuregiven a data matrix and compare the performance with Mansinghka et al. (2006)and also with the uniform prior.
arxiv-10200-196 | Online Convex Optimization Using Predictions | http://arxiv.org/pdf/1504.06681v1.pdf | author:Niangjun Chen, Anish Agarwal, Adam Wierman, Siddharth Barman, Lachlan L. H. Andrew category:cs.LG published:2015-04-25 summary:Making use of predictions is a crucial, but under-explored, area of onlinealgorithms. This paper studies a class of online optimization problems where wehave external noisy predictions available. We propose a stochastic predictionerror model that generalizes prior models in the learning and stochasticcontrol communities, incorporates correlation among prediction errors, andcaptures the fact that predictions improve as time passes. We prove thatachieving sublinear regret and constant competitive ratio for online algorithmsrequires the use of an unbounded prediction window in adversarial settings, butthat under more realistic stochastic prediction error models it is possible touse Averaging Fixed Horizon Control (AFHC) to simultaneously achieve sublinearregret and constant competitive ratio in expectation using only aconstant-sized prediction window. Furthermore, we show that the performance ofAFHC is tightly concentrated around its mean.
arxiv-10200-197 | Differential Recurrent Neural Networks for Action Recognition | http://arxiv.org/pdf/1504.06678v1.pdf | author:Vivek Veeriah, Naifan Zhuang, Guo-Jun Qi category:cs.CV published:2015-04-25 summary:The long short-term memory (LSTM) neural network is capable of processingcomplex sequential information since it utilizes special gating schemes forlearning representations from long input sequences. It has the potential tomodel any sequential time-series data, where the current hidden state has to beconsidered in the context of the past hidden states. This property makes LSTMan ideal choice to learn the complex dynamics of various actions.Unfortunately, the conventional LSTMs do not consider the impact ofspatio-temporal dynamics corresponding to the given salient motion patterns,when they gate the information that ought to be memorized through time. Toaddress this problem, we propose a differential gating scheme for the LSTMneural network, which emphasizes on the change in information gain caused bythe salient motions between the successive frames. This change in informationgain is quantified by Derivative of States (DoS), and thus the proposed LSTMmodel is termed as differential Recurrent Neural Network (dRNN). We demonstratethe effectiveness of the proposed model by automatically recognizing actionsfrom the real-world 2D and 3D human action datasets. Our study is one of thefirst works towards demonstrating the potential of learning complex time-seriesrepresentations via high-order derivatives of states.
arxiv-10200-198 | Recovering Spatiotemporal Correspondence between Deformable Objects by Exploiting Consistent Foreground Motion in Video | http://arxiv.org/pdf/1412.0477v2.pdf | author:Luca Del Pero, Susanna Ricco, Rahul Sukthankar, Vittorio Ferrari category:cs.CV published:2014-12-01 summary:Given unstructured videos of deformable objects, we automatically recoverspatiotemporal correspondences to map one object to another (such as animals inthe wild). While traditional methods based on appearance fail in suchchallenging conditions, we exploit consistency in object motion betweeninstances. Our approach discovers pairs of short video intervals where theobject moves in a consistent manner and uses these candidates as seeds forspatial alignment. We model the spatial correspondence between the pointtrajectories on the object in one interval to those in the other using atime-varying Thin Plate Spline deformation model. On a large dataset of tigerand horse videos, our method automatically aligns thousands of pairs of framesto a high accuracy, and outperforms the popular SIFT Flow algorithm.
arxiv-10200-199 | Inferring Missing Entity Type Instances for Knowledge Base Completion: New Dataset and Methods | http://arxiv.org/pdf/1504.06658v1.pdf | author:Arvind Neelakantan, Ming-Wei Chang category:cs.CL stat.ML published:2015-04-24 summary:Most of previous work in knowledge base (KB) completion has focused on theproblem of relation extraction. In this work, we focus on the task of inferringmissing entity type instances in a KB, a fundamental task for KB competitionyet receives little attention. Due to the novelty of this task, we construct alarge-scale dataset and design an automatic evaluation methodology. Ourknowledge base completion method uses information within the existing KB andexternal information from Wikipedia. We show that individual methods trainedwith a global objective that considers unobserved cells from both the entityand the type side gives consistently higher quality predictions compared tobaseline methods. We also perform manual evaluation on a small subset of thedata to verify the effectiveness of our knowledge base completion methods andthe correctness of our proposed automatic evaluation method.
arxiv-10200-200 | Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space | http://arxiv.org/pdf/1504.06654v1.pdf | author:Arvind Neelakantan, Jeevan Shankar, Alexandre Passos, Andrew McCallum category:cs.CL stat.ML published:2015-04-24 summary:There is rising interest in vector-space word embeddings and their use inNLP, especially given recent methods for their fast estimation at very largescale. Nearly all this work, however, assumes a single vector per word typeignoring polysemy and thus jeopardizing their usefulness for downstream tasks.We present an extension to the Skip-gram model that efficiently learns multipleembeddings per word type. It differs from recent related work by jointlyperforming word sense discrimination and embedding learning, bynon-parametrically estimating the number of senses per word type, and by itsefficiency and scalability. We present new state-of-the-art results in the wordsimilarity in context task and demonstrate its scalability by training with onemachine on a corpus of nearly 1 billion tokens in less than 6 hours.
arxiv-10200-201 | Learning Dictionaries for Named Entity Recognition using Minimal Supervision | http://arxiv.org/pdf/1504.06650v1.pdf | author:Arvind Neelakantan, Michael Collins category:cs.CL stat.ML published:2015-04-24 summary:This paper describes an approach for automatic construction of dictionariesfor Named Entity Recognition (NER) using large amounts of unlabeled data and afew seed examples. We use Canonical Correlation Analysis (CCA) to obtain lowerdimensional embeddings (representations) for candidate phrases and classifythese phrases using a small number of labeled examples. Our method achieves16.5% and 11.3% F-1 score improvement over co-training on disease and virus NERrespectively. We also show that by adding candidate phrase embeddings asfeatures in a sequence tagger gives better performance compared to using wordembeddings.
arxiv-10200-202 | Subjectivity, Bayesianism, and Causality | http://arxiv.org/pdf/1407.4139v4.pdf | author:Pedro A. Ortega category:cs.AI stat.ME stat.ML published:2014-07-15 summary:Bayesian probability theory is one of the most successful frameworks to modelreasoning under uncertainty. Its defining property is the interpretation ofprobabilities as degrees of belief in propositions about the state of the worldrelative to an inquiring subject. This essay examines the notion ofsubjectivity by drawing parallels between Lacanian theory and Bayesianprobability theory, and concludes that the latter must be enriched with causalinterventions to model agency. The central contribution of this work is anabstract model of the subject that accommodates causal interventions in ameasure-theoretic formalisation. This formalisation is obtained through agame-theoretic Ansatz based on modelling the inside and outside of the subjectas an extensive-form game with imperfect information between two players.Finally, I illustrate the expressiveness of this model with an example ofcausal induction.
arxiv-10200-203 | Object Level Deep Feature Pooling for Compact Image Representation | http://arxiv.org/pdf/1504.06591v1.pdf | author:Konda Reddy Mopuri, R. Venkatesh Babu category:cs.CV published:2015-04-24 summary:Convolutional Neural Network (CNN) features have been successfully employedin recent works as an image descriptor for various vision tasks. But theinability of the deep CNN features to exhibit invariance to geometrictransformations and object compositions poses a great challenge for imagesearch. In this work, we demonstrate the effectiveness of the objectness priorover the deep CNN features of image regions for obtaining an invariant imagerepresentation. The proposed approach represents the image as a vector ofpooled CNN features describing the underlying objects. This representationprovides robustness to spatial layout of the objects in the scene and achievesinvariance to general geometric transformations, such as translation, rotationand scaling. The proposed approach also leads to a compact representation ofthe scene, making each image occupy a smaller memory footprint. Experimentsshow that the proposed representation achieves state of the art retrievalresults on a set of challenging benchmark image datasets, while maintaining acompact representation.
arxiv-10200-204 | Semantic Motion Segmentation Using Dense CRF Formulation | http://arxiv.org/pdf/1504.06587v1.pdf | author:N. Dinesh Reddy, Prateek Singhal, K. Madhava Krishna category:cs.CV published:2015-04-24 summary:While the literature has been fairly dense in the areas of sceneunderstanding and semantic labeling there have been few works that make use ofmotion cues to embellish semantic performance and vice versa. In this paper, weaddress the problem of semantic motion segmentation, and show how semantic andmotion priors augments performance. We pro- pose an algorithm that jointlyinfers the semantic class and motion labels of an object. Integrating semantic,geometric and optical ow based constraints into a dense CRF-model we infer boththe object class as well as motion class, for each pixel. We found improvementin performance using a fully connected CRF as compared to a standardclique-based CRFs. For inference, we use a Mean Field approximation basedalgorithm. Our method outperforms recently pro- posed motion detectionalgorithms and also improves the semantic labeling compared to thestate-of-the-art Automatic Labeling Environment algorithm on the challengingKITTI dataset especially for object classes such as pedestrians and cars thatare critical to an outdoor robotic navigation scenario.
arxiv-10200-205 | Cultural Event Recognition with Visual ConvNets and Temporal Models | http://arxiv.org/pdf/1504.06567v1.pdf | author:Amaia Salvador, Matthias Zeppelzauer, Daniel Manchon-Vizuete, Andrea Calafell, Xavier Giro-i-Nieto category:cs.CV cs.CY published:2015-04-24 summary:This paper presents our contribution to the ChaLearn Challenge 2015 onCultural Event Classification. The challenge in this task is to automaticallyclassify images from 50 different cultural events. Our solution is based on thecombination of visual features extracted from convolutional neural networkswith temporal information using a hierarchical classifier scheme. We extractvisual features from the last three fully connected layers of both CaffeNet(pretrained with ImageNet) and our fine tuned version for the ChaLearnchallenge. We propose a late fusion strategy that trains a separate low-levelSVM on each of the extracted neural codes. The class predictions of thelow-level SVMs form the input to a higher level SVM, which gives the finalevent scores. We achieve our best result by adding a temporal refinement stepinto our classification scheme, which is applied directly to the output of eachlow-level SVM. Our approach penalizes high classification scores based onvisual features when their time stamp does not match well an event-specifictemporal distribution learned from the training and validation data. Our systemachieved the second best result in the ChaLearn Challenge 2015 on CulturalEvent Classification with a mean average precision of 0.767 on the test set.
arxiv-10200-206 | Joint calibration of Ensemble of Exemplar SVMs | http://arxiv.org/pdf/1503.00783v2.pdf | author:Davide Modolo, Alexander Vezhnevets, Olga Russakovsky, Vittorio Ferrari category:cs.CV published:2015-03-02 summary:We present a method for calibrating the Ensemble of Exemplar SVMs model.Unlike the standard approach, which calibrates each SVM independently, ourmethod optimizes their joint performance as an ensemble. We formulate jointcalibration as a constrained optimization problem and devise an efficientoptimization algorithm to find its global optimum. The algorithm dynamicallydiscards parts of the solution space that cannot contain the optimum early on,making the optimization computationally feasible. We experiment with EE-SVMtrained on state-of-the-art CNN descriptors. Results on the ILSVRC 2014 andPASCAL VOC 2007 datasets show that (i) our joint calibration procedureoutperforms independent calibration on the task of classifying windows asbelonging to an object class or not; and (ii) this improved window classifierleads to better performance on the object detection task.
arxiv-10200-207 | Optimum Statistical Estimation with Strategic Data Sources | http://arxiv.org/pdf/1408.2539v2.pdf | author:Yang Cai, Constantinos Daskalakis, Christos H. Papadimitriou category:stat.ML cs.GT cs.LG published:2014-08-11 summary:We propose an optimum mechanism for providing monetary incentives to the datasources of a statistical estimator such as linear regression, so that highquality data is provided at low cost, in the sense that the sum of payments andestimation error is minimized. The mechanism applies to a broad range ofestimators, including linear and polynomial regression, kernel regression, and,under some additional assumptions, ridge regression. It also generalizes toseveral objectives, including minimizing estimation error subject to budgetconstraints. Besides our concrete results for regression problems, wecontribute a mechanism design framework through which to design and analyzestatistical estimators whose examples are supplied by workers with cost forlabeling said examples.
arxiv-10200-208 | A Bayesian approach for structure learning in oscillating regulatory networks | http://arxiv.org/pdf/1504.06553v1.pdf | author:D Trejo, AJ Millar, G Sanguinetti category:stat.ML q-bio.QM published:2015-04-24 summary:Oscillations lie at the core of many biological processes, from the cellcycle, to circadian oscillations and developmental processes. Time-keepingmechanisms are essential to enable organisms to adapt to varying conditions inenvironmental cycles, from day/night to seasonal. Transcriptional regulatorynetworks are one of the mechanisms behind these biological oscillations.However, while identifying cyclically expressed genes from time seriesmeasurements is relatively easy, determining the structure of the interactionnetwork underpinning the oscillation is a far more challenging problem. Here,we explicitly leverage the oscillatory nature of the transcriptional signalsand present a method for reconstructing network interactions tailored to thisspecial but important class of genetic circuits. Our method is based onprojecting the signal onto a set of oscillatory basis functions using aDiscrete Fourier Transform. We build a Bayesian Hierarchical model within afrequency domain linear model in order to enforce sparsity and incorporateprior knowledge about the network structure. Experiments on real and simulateddata show that the method can lead to substantial improvements over competingapproaches if the oscillatory assumption is met, and remains competitive alsoin cases it is not.
arxiv-10200-209 | Sampling Correctors | http://arxiv.org/pdf/1504.06544v1.pdf | author:Clément Canonne, Themis Gouleakis, Ronitt Rubinfeld category:cs.DS cs.LG math.PR published:2015-04-24 summary:In many situations, sample data is obtained from a noisy or imperfect source.In order to address such corruptions, this paper introduces the concept of asampling corrector. Such algorithms use structure that the distribution ispurported to have, in order to allow one to make "on-the-fly" corrections tosamples drawn from probability distributions. These algorithms then act asfilters between the noisy data and the end user. We show connections between sampling correctors, distribution learningalgorithms, and distribution property testing algorithms. We show that theseconnections can be utilized to expand the applicability of known distributionlearning and property testing algorithms as well as to achieve improvedalgorithms for those tasks. As a first step, we show how to design sampling correctors using properlearning algorithms. We then focus on the question of whether algorithms forsampling correctors can be more efficient in terms of sample complexity thanlearning algorithms for the analogous families of distributions. Whencorrecting monotonicity, we show that this is indeed the case when also grantedquery access to the cumulative distribution function. We also obtain samplingcorrectors for monotonicity without this stronger type of access, provided thatthe distribution be originally very close to monotone (namely, at a distance$O(1/\log^2 n)$). In addition to that, we consider a restricted error modelthat aims at capturing "missing data" corruptions. In this model, we show thatdistributions that are close to monotone have sampling correctors that aresignificantly more efficient than achievable by the learning approach. We also consider the question of whether an additional source of independentrandom bits is required by sampling correctors to implement the correctionprocess.
arxiv-10200-210 | Articulated motion discovery using pairs of trajectories | http://arxiv.org/pdf/1411.7883v3.pdf | author:Luca Del Pero, Susanna Ricco, Rahul Sukthankar, Vittorio Ferrari category:cs.CV published:2014-11-28 summary:We propose an unsupervised approach for discovering characteristic motionpatterns in videos of highly articulated objects performing natural, unscriptedbehaviors, such as tigers in the wild. We discover consistent patterns in abottom-up manner by analyzing the relative displacements of large numbers ofordered trajectory pairs through time, such that each trajectory is attached toa different moving part on the object. The pairs of trajectories descriptorrelies entirely on motion and is more discriminative than state-of-the-artfeatures that employ single trajectories. Our method generates temporal videointervals, each automatically trimmed to one instance of the discoveredbehavior, and clusters them by type (e.g., running, turning head, drinkingwater). We present experiments on two datasets: dogs from YouTube-Objects and anew dataset of National Geographic tiger videos. Results confirm that ourproposed descriptor outperforms existing appearance- and trajectory-baseddescriptors (e.g., HOG and DTFs) on both datasets and enables us to segmentunconstrained animal video into intervals containing single behaviors.
arxiv-10200-211 | Local Variation as a Statistical Hypothesis Test | http://arxiv.org/pdf/1504.06507v1.pdf | author:Michael Baltaxe, Peter Meer, Michael Lindenbaum category:cs.CV published:2015-04-24 summary:The goal of image oversegmentation is to divide an image into several pieces,each of which should ideally be part of an object. One of the simplest and yetmost effective oversegmentation algorithms is known as local variation (LV)(Felzenszwalb and Huttenlocher 2004). In this work, we study this algorithm andshow that algorithms similar to LV can be devised by applying differentstatistical models and decisions, thus providing further theoreticaljustification and a well-founded explanation for the unexpected highperformance of the LV approach. Some of these algorithms are based onstatistics of natural images and on a hypothesis testing decision; we denotethese algorithms probabilistic local variation (pLV). The best pLV algorithm,which relies on censored estimation, presents state-of-the-art results whilekeeping the same computational complexity of the LV algorithm.
arxiv-10200-212 | Discriminative Switching Linear Dynamical Systems applied to Physiological Condition Monitoring | http://arxiv.org/pdf/1504.06494v1.pdf | author:Konstantinos Georgatzis, Christopher K. I. Williams category:cs.LG published:2015-04-24 summary:We present a Discriminative Switching Linear Dynamical System (DSLDS) appliedto patient monitoring in Intensive Care Units (ICUs). Our approach is based onidentifying the state-of-health of a patient given their observed vital signsusing a discriminative classifier, and then inferring their underlyingphysiological values conditioned on this status. The work builds on theFactorial Switching Linear Dynamical System (FSLDS) (Quinn et al., 2009) whichhas been previously used in a similar setting. The FSLDS is a generative model,whereas the DSLDS is a discriminative model. We demonstrate on two real-worlddatasets that the DSLDS is able to outperform the FSLDS in most cases ofinterest, and that an $\alpha$-mixture of the two models achieves higherperformance than either of the two models separately.
arxiv-10200-213 | Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition | http://arxiv.org/pdf/1412.6553v3.pdf | author:Vadim Lebedev, Yaroslav Ganin, Maksim Rakhuba, Ivan Oseledets, Victor Lempitsky category:cs.CV cs.LG published:2014-12-19 summary:We propose a simple two-step approach for speeding up convolution layerswithin large convolutional neural networks based on tensor decomposition anddiscriminative fine-tuning. Given a layer, we use non-linear least squares tocompute a low-rank CP-decomposition of the 4D convolution kernel tensor into asum of a small number of rank-one tensors. At the second step, thisdecomposition is used to replace the original convolutional layer with asequence of four convolutional layers with small kernels. After suchreplacement, the entire network is fine-tuned on the training data usingstandard backpropagation process. We evaluate this approach on two CNNs and show that it is competitive withprevious approaches, leading to higher obtained CPU speedups at the cost oflower accuracy drops for the smaller of the two networks. Thus, for the36-class character classification CNN, our approach obtains a 8.5x CPU speedupof the whole network with only minor accuracy drop (1% from 91% to 90%). Forthe standard ImageNet architecture (AlexNet), the approach speeds up the secondconvolution layer by a factor of 4x at the cost of $1\%$ increase of theoverall top-5 classification error.
arxiv-10200-214 | Image Denoising Using Low Rank Minimization With Modified Noise Estimation | http://arxiv.org/pdf/1504.03439v2.pdf | author:Zahid Hussain Shamsi, Hyun Sook Oh, Dai-Gyoung Kim category:cs.CV published:2015-04-14 summary:Recently, the application of low rank minimization to image denoising hasshown remarkable denoising results which are equivalent or better than those ofthe existing state-of-the-art algorithms. However, due to iterative nature oflow rank optimization, estimation of residual noise is an essential requirementafter each iteration. Currently, this noise is estimated by using the filterednoise in the previous iteration without considering the geometric structure ofthe given image. This estimate may be affected in the presence of moderate andsevere levels of noise. To obtain a more reliable estimate of residual noise,we propose a modified algorithm (GWNNM) which includes the contribution of thegeometric structure of an image to the existing noise estimation. Furthermore,the proposed algorithm exploits the difference of large and small singularvalues to enhance the edges and textures during the denoising process.Consequently, the proposed modifications achieve significant improvements inthe denoising results of the existing low rank optimization algorithms.
arxiv-10200-215 | Situational Object Boundary Detection | http://arxiv.org/pdf/1504.06434v1.pdf | author:Jasper Uijlings, Vittorio Ferrari category:cs.CV published:2015-04-24 summary:Intuitively, the appearance of true object boundaries varies from image toimage. Hence the usual monolithic approach of training a single boundarypredictor and applying it to all images regardless of their content is bound tobe suboptimal. In this paper we therefore propose situational object boundarydetection: We first define a variety of situations and train a specializedobject boundary detector for each of them using [Dollar and Zitnick 2013]. Thengiven a test image, we classify it into these situations using its context,which we model by global image appearance. We apply the correspondingsituational object boundary detectors, and fuse them based on theclassification probabilities. In experiments on ImageNet, Microsoft COCO, andPascal VOC 2012 segmentation we show that our situational object boundarydetection gives significant improvements over a monolithic approach.Additionally, our method substantially outperforms [Hariharan et al. 2011] onsemantic contour detection on their SBD dataset.
arxiv-10200-216 | $gen$CNN: A Convolutional Architecture for Word Sequence Prediction | http://arxiv.org/pdf/1503.05034v2.pdf | author:Mingxuan Wang, Zhengdong Lu, Hang Li, Wenbin Jiang, Qun Liu category:cs.CL published:2015-03-17 summary:We propose a novel convolutional architecture, named $gen$CNN, for wordsequence prediction. Different from previous work on neural network-basedlanguage modeling and generation (e.g., RNN or LSTM), we choose not to greedilysummarize the history of words as a fixed length vector. Instead, we use aconvolutional neural network to predict the next word with the history of wordsof variable length. Also different from the existing feedforward networks forlanguage modeling, our model can effectively fuse the local correlation andglobal correlation in the word sequence, with a convolution-gating strategyspecifically designed for the task. We argue that our model can give adequaterepresentation of the history, and therefore can naturally exploit both theshort and long range dependencies. Our model is fast, easy to train, andreadily parallelized. Our extensive experiments on text generation and $n$-bestre-ranking in machine translation show that $gen$CNN outperforms thestate-of-the-arts with big margins.
arxiv-10200-217 | From Image-level to Pixel-level Labeling with Convolutional Networks | http://arxiv.org/pdf/1411.6228v3.pdf | author:Pedro O. Pinheiro, Ronan Collobert category:cs.CV published:2014-11-23 summary:We are interested in inferring object segmentation by leveraging only objectclass information, and by considering only minimal priors on the objectsegmentation task. This problem could be viewed as a kind of weakly supervisedsegmentation task, and naturally fits the Multiple Instance Learning (MIL)framework: every training image is known to have (or not) at least one pixelcorresponding to the image class label, and the segmentation task can berewritten as inferring the pixels belonging to the class of the object (givenone image, and its object class). We propose a Convolutional NeuralNetwork-based model, which is constrained during training to put more weight onpixels which are important for classifying the image. We show that at testtime, the model has learned to discriminate the right pixels well enough, suchthat it performs very well on an existing segmentation benchmark, by addingonly few smoothing priors. Our system is trained using a subset of the Imagenetdataset and the segmentation experiments are performed on the challengingPascal VOC dataset (with no fine-tuning of the model on Pascal VOC). Our modelbeats the state of the art results in weakly supervised object segmentationtask by a large margin. We also compare the performance of our model with stateof the art fully-supervised segmentation approaches.
arxiv-10200-218 | Social Trust Prediction via Max-norm Constrained 1-bit Matrix Completion | http://arxiv.org/pdf/1504.06394v1.pdf | author:Jing Wang, Jie Shen, Huan Xu category:cs.SI cs.LG stat.ML published:2015-04-24 summary:Social trust prediction addresses the significant problem of exploringinteractions among users in social networks. Naturally, this problem can beformulated in the matrix completion framework, with each entry indicating thetrustness or distrustness. However, there are two challenges for the socialtrust problem: 1) the observed data are with sign (1-bit) measurements; 2) theyare typically sampled non-uniformly. Most of the previous matrix completionmethods do not well handle the two issues. Motivated by the recent progress ofmax-norm, we propose to solve the problem with a 1-bit max-norm constrainedformulation. Since max-norm is not easy to optimize, we utilize a reformulationof max-norm which facilitates an efficient projected gradient decent algorithm.We demonstrate the superiority of our formulation on two benchmark datasets.
arxiv-10200-219 | On the Stability of Online Language Features: How Much Text do you Need to know a Person? | http://arxiv.org/pdf/1504.06391v1.pdf | author:Eben M. Haber category:cs.CL published:2015-04-24 summary:In recent years, numerous studies have inferred personality and other traitsfrom people's online writing. While these studies are encouraging, moreinformation is needed in order to use these techniques with confidence. How dolinguistic features vary across different online media, and how much text isrequired to have a representative sample for a person? In this paper, weexamine several large sets of online, user-generated text, drawn from Twitter,email, blogs, and online discussion forums. We examine and comparepopulation-wide results for the linguistic measure LIWC, and the inferredtraits of Big5 Personality and Basic Human Values. We also empirically measurethe stability of these traits across different sized samples for eachindividual. Our results highlight the importance of tuning models to eachonline medium, and include guidelines for the minimum amount of text requiredfor a representative result.
arxiv-10200-220 | Visual Recognition Using Directional Distribution Distance | http://arxiv.org/pdf/1504.04792v2.pdf | author:Jianxin Wu, Bin-Bin Gao, Guoqing Liu category:cs.CV published:2015-04-19 summary:In computer vision, an entity such as an image or video is often representedas a set of instance vectors, which can be SIFT, motion, or deep learningfeature vectors extracted from different parts of that entity. Thus, it isessential to design efficient and effective methods to compare two sets ofinstance vectors. Existing methods such as FV, VLAD or Super Vectors haveachieved excellent results. However, this paper shows that these methods aredesigned based on a generative perspective, and a discriminative method can bemore effective in categorizing images or videos. The proposed D3(discriminative distribution distance) method effectively compares two sets astwo distributions, and proposes a directional total variation distance (DTVD)to measure how separated are they. Furthermore, a robust classifier-basedmethod is proposed to estimate DTVD robustly. The D3 method is evaluated inaction and image recognition tasks and has achieved excellent accuracy andspeed. D3 also has a synergy with FV. The combination of D3 and FV hasadvantages over D3, FV, and VLAD.
arxiv-10200-221 | Unsupervised learning of clutter-resistant visual representations from natural videos | http://arxiv.org/pdf/1409.3879v2.pdf | author:Qianli Liao, Joel Z. Leibo, Tomaso Poggio category:cs.CV cs.LG published:2014-09-12 summary:Populations of neurons in inferotemporal cortex (IT) maintain an explicitcode for object identity that also tolerates transformations of objectappearance e.g., position, scale, viewing angle [1, 2, 3]. Though the learningrules are not known, recent results [4, 5, 6] suggest the operation of anunsupervised temporal-association-based method e.g., Foldiak's trace rule [7].Such methods exploit the temporal continuity of the visual world by assumingthat visual experience over short timescales will tend to have invariantidentity content. Thus, by associating representations of frames from nearbytimes, a representation that tolerates whatever transformations occurred in thevideo may be achieved. Many previous studies verified that such rules can workin simple situations without background clutter, but the presence of visualclutter has remained problematic for this approach. Here we show that temporalassociation based on large class-specific filters (templates) avoids theproblem of clutter. Our system learns in an unsupervised way from naturalvideos gathered from the internet, and is able to perform a difficultunconstrained face recognition task on natural images: Labeled Faces in theWild [8].
arxiv-10200-222 | Use of Ensembles of Fourier Spectra in Capturing Recurrent Concepts in Data Streams | http://arxiv.org/pdf/1504.06366v1.pdf | author:Sripirakas Sakthithasan, Russel Pears, Albert Bifet, Bernhard Pfahringer category:cs.AI cs.LG published:2015-04-23 summary:In this research, we apply ensembles of Fourier encoded spectra to captureand mine recurring concepts in a data stream environment. Previous researchshowed that compact versions of Decision Trees can be obtained by applying theDiscrete Fourier Transform to accurately capture recurrent concepts in a datastream. However, in highly volatile environments where new concepts emergeoften, the approach of encoding each concept in a separate spectrum is nolonger viable due to memory overload and thus in this research we present anensemble approach that addresses this problem. Our empirical results on realworld data and synthetic data exhibiting varying degrees of recurrence revealthat the ensemble approach outperforms the single spectrum approach in terms ofclassification accuracy, memory and execution time.
arxiv-10200-223 | On the Runtime of Randomized Local Search and Simple Evolutionary Algorithms for Dynamic Makespan Scheduling | http://arxiv.org/pdf/1504.06363v1.pdf | author:Frank Neumann, Carsten Witt category:cs.DS cs.NE published:2015-04-23 summary:Evolutionary algorithms have been frequently used for dynamic optimizationproblems. With this paper, we contribute to the theoretical understanding ofthis research area. We present the first computational complexity analysis ofevolutionary algorithms for a dynamic variant of a classical combinatorialoptimization problem, namely makespan scheduling. We study the model of astrong adversary which is allowed to change one job at regular intervals.Furthermore, we investigate the setting of random changes. Our results showthat randomized local search and a simple evolutionary algorithm are veryeffective in dynamically tracking changes made to the problem instance.
arxiv-10200-224 | Strategic Teaching and Learning in Games | http://arxiv.org/pdf/1504.06341v1.pdf | author:Burkhard C. Schipper category:cs.GT cs.AI cs.LG published:2015-04-23 summary:It is known that there are uncoupled learning heuristics leading to Nashequilibrium in all finite games. Why should players use such learningheuristics and where could they come from? We show that there is no uncoupledlearning heuristic leading to Nash equilibrium in all finite games that aplayer has an incentive to adopt, that would be evolutionary stable or thatcould "learn itself". Rather, a player has an incentive to strategically teachsuch a learning opponent in order secure at least the Stackelberg leaderpayoff. The impossibility result remains intact when restricted to the classesof generic games, two-player games, potential games, games with strategiccomplements or 2x2 games, in which learning is known to be "nice". Moregenerally, it also applies to uncoupled learning heuristics leading tocorrelated equilibria, rationalizable outcomes, iterated admissible outcomes,or minimal curb sets. A possibility result restricted to "strategicallytrivial" games fails if some generic games outside this class are considered aswell.
arxiv-10200-225 | Analysis of Stopping Active Learning based on Stabilizing Predictions | http://arxiv.org/pdf/1504.06329v1.pdf | author:Michael Bloodgood, John Grothendieck category:cs.LG cs.CL stat.ML published:2015-04-23 summary:Within the natural language processing (NLP) community, active learning hasbeen widely investigated and applied in order to alleviate the annotationbottleneck faced by developers of new NLP systems and technologies. This paperpresents the first theoretical analysis of stopping active learning based onstabilizing predictions (SP). The analysis has revealed three elements that arecentral to the success of the SP method: (1) bounds on Cohen's Kappa agreementbetween successively trained models impose bounds on differences in F-measureperformance of the models; (2) since the stop set does not have to be labeled,it can be made large in practice, helping to guarantee that the resultstransfer to previously unseen streams of examples at test/application time; and(3) good (low variance) sample estimates of Kappa between successive models canbe obtained. Proofs of relationships between the level of Kappa agreement andthe difference in performance between consecutive models are presented.Specifically, if the Kappa agreement between two models exceeds a threshold T(where $T>0$), then the difference in F-measure performance between thosemodels is bounded above by $\frac{4(1-T)}{T}$ in all cases. If precision of thepositive conjunction of the models is assumed to be $p$, then the bound can betightened to $\frac{4(1-T)}{(p+1)T}$.
arxiv-10200-226 | Regularization-free estimation in trace regression with symmetric positive semidefinite matrices | http://arxiv.org/pdf/1504.06305v1.pdf | author:Martin Slawski, Ping Li, Matthias Hein category:stat.ML cs.LG stat.ME published:2015-04-23 summary:Over the past few years, trace regression models have received considerableattention in the context of matrix completion, quantum state tomography, andcompressed sensing. Estimation of the underlying matrix fromregularization-based approaches promoting low-rankedness, notably nuclear normregularization, have enjoyed great popularity. In the present paper, we arguethat such regularization may no longer be necessary if the underlying matrix issymmetric positive semidefinite (\textsf{spd}) and the design satisfies certainconditions. In this situation, simple least squares estimation subject to an\textsf{spd} constraint may perform as well as regularization-based approacheswith a proper choice of the regularization parameter, which entails knowledgeof the noise level and/or tuning. By contrast, constrained least squaresestimation comes without any tuning parameter and may hence be preferred due toits simplicity.
arxiv-10200-227 | A new approach for physiological time series | http://arxiv.org/pdf/1504.06274v1.pdf | author:Dong Mao, Yang Wang, Qiang Wu category:cs.LG stat.ML published:2015-04-23 summary:We developed a new approach for the analysis of physiological time series. Aniterative convolution filter is used to decompose the time series into variouscomponents. Statistics of these components are extracted as features tocharacterize the mechanisms underlying the time series. Motivated by thestudies that show many normal physiological systems involve irregularity whilethe decrease of irregularity usually implies the abnormality, the statisticsfor "outliers" in the components are used as features measuring irregularity.Support vector machines are used to select the most relevant features that areable to differentiate the time series from normal and abnormal systems. Thisnew approach is successfully used in the study of congestive heart failure byheart beat interval time series.
arxiv-10200-228 | Evolving Fuzzy Image Segmentation with Self-Configuration | http://arxiv.org/pdf/1504.06266v1.pdf | author:Ahmed Othman, Hamid R. Tizhoosh, Farzad Khalvati category:cs.CV published:2015-04-23 summary:Current image segmentation techniques usually require that the user tuneseveral parameters in order to obtain maximum segmentation accuracy, acomputationally inefficient approach, especially when a large number of imagesmust be processed sequentially in daily practice. The use of evolving fuzzysystems for designing a method that automatically adjusts parameters to segmentmedical images according to the quality expectation of expert users has beenproposed recently (Evolving fuzzy image segmentation EFIS). However, EFISsuffers from a few limitations when used in practice mainly due to some fixedparameters. For instance, EFIS depends on auto-detection of the object ofinterest for feature calculation, a task that is highly application-dependent.This shortcoming limits the applicability of EFIS, which was proposed with theultimate goal of offering a generic but adjustable segmentation scheme. In thispaper, a new version of EFIS is proposed to overcome these limitations. The newEFIS, called self-configuring EFIS (SC-EFIS), uses available training data toself-estimate the parameters that are fixed in EFIS. As well, the proposedSC-EFIS relies on a feature selection process that does not requireauto-detection of an ROI. The proposed SC-EFIS was evaluated using the samesegmentation algorithms and the same dataset as for EFIS. The results show thatSC-EFIS can provide the same results as EFIS but with a higher level ofautomation.
arxiv-10200-229 | Multiple Object Recognition with Visual Attention | http://arxiv.org/pdf/1412.7755v2.pdf | author:Jimmy Ba, Volodymyr Mnih, Koray Kavukcuoglu category:cs.LG cs.CV cs.NE published:2014-12-24 summary:We present an attention-based model for recognizing multiple objects inimages. The proposed model is a deep recurrent neural network trained withreinforcement learning to attend to the most relevant regions of the inputimage. We show that the model learns to both localize and recognize multipleobjects despite being given only class labels during training. We evaluate themodel on the challenging task of transcribing house number sequences fromGoogle Street View images and show that it is both more accurate than thestate-of-the-art convolutional networks and uses fewer parameters and lesscomputation.
arxiv-10200-230 | Person Re-identification with Correspondence Structure Learning | http://arxiv.org/pdf/1504.06243v1.pdf | author:Yang Shen, Weiyao Lin, Junchi Yan, Mingliang Xu, Jianxin Wu, Jingdong Wang category:cs.CV published:2015-04-23 summary:This paper addresses the problem of handling spatial misalignments due tocamera-view changes or human-pose variations in person re-identification. Wefirst introduce a boosting-based approach to learn a correspondence structurewhich indicates the patch-wise matching probabilities between images from atarget camera pair. The learned correspondence structure can not only capturethe spatial correspondence pattern between cameras but also handle theviewpoint or human-pose variation in individual images. We further introduce aglobal-based matching process. It integrates a global matching constraint overthe learned correspondence structure to exclude cross-view misalignments duringthe image patch matching process, hence achieving a more reliable matchingscore between images. Experimental results on various datasets demonstrate theeffectiveness of our approach.
arxiv-10200-231 | An Elastic Image Registration Approach for Wireless Capsule Endoscope Localization | http://arxiv.org/pdf/1504.06206v1.pdf | author:Isabel N. Figueiredo, Carlos Leal, Luís Pinto, Pedro N. Figueiredo, Richard Tsai category:cs.CV published:2015-04-23 summary:Wireless Capsule Endoscope (WCE) is an innovative imaging device that permitsphysicians to examine all the areas of the Gastrointestinal (GI) tract. It isespecially important for the small intestine, where traditional invasiveendoscopies cannot reach. Although WCE represents an extremely importantadvance in medical imaging, a major drawback that remains unsolved is the WCEprecise location in the human body during its operating time. This is mainlydue to the complex physiological environment and the inherent capsule effectsduring its movement. When an abnormality is detected, in the WCE images,medical doctors do not know precisely where this abnormality is locatedrelative to the intestine and therefore they can not proceed efficiently withthe appropriate therapy. The primary objective of the present paper is to givea contribution to WCE localization, using image-based methods. The main focusof this work is on the description of a multiscale elastic image registrationapproach, its experimental application on WCE videos, and comparison with amultiscale affine registration. The proposed approach includes registrationsthat capture both rigid-like and non-rigid deformations, due respectively tothe rigid-like WCE movement and the elastic deformation of the small intestineoriginated by the GI peristaltic movement. Under this approach a qualitativeinformation about the WCE speed can be obtained, as well as the WCE locationand orientation via projective geometry. The results of the experimental testswith real WCE video frames show the good performance of the proposed approach,when elastic deformations of the small intestine are involved in successiveframes, and its superiority with respect to a multiscale affine imageregistration, which accounts for rigid-like deformations only and discardselastic deformations.
arxiv-10200-232 | DeepEdge: A Multi-Scale Bifurcated Deep Network for Top-Down Contour Detection | http://arxiv.org/pdf/1412.1123v3.pdf | author:Gedas Bertasius, Jianbo Shi, Lorenzo Torresani category:cs.CV published:2014-12-02 summary:Contour detection has been a fundamental component in many image segmentationand object detection systems. Most previous work utilizes low-level featuressuch as texture or saliency to detect contours and then use them as cues for ahigher-level task such as object detection. However, we claim that recognizingobjects and predicting contours are two mutually related tasks. Contrary totraditional approaches, we show that we can invert the commonly establishedpipeline: instead of detecting contours with low-level cues for a higher-levelrecognition task, we exploit object-related features as high-level cues forcontour detection. We achieve this goal by means of a multi-scale deep network that consists offive convolutional layers and a bifurcated fully-connected sub-network. Thesection from the input layer to the fifth convolutional layer is fixed anddirectly lifted from a pre-trained network optimized over a large-scale objectclassification task. This section of the network is applied to four differentscales of the image input. These four parallel and identical streams are thenattached to a bifurcated sub-network consisting of two independently-trainedbranches. One branch learns to predict the contour likelihood (with aclassification objective) whereas the other branch is trained to learn thefraction of human labelers agreeing about the contour presence at a given point(with a regression criterion). We show that without any feature engineering our multi-scale deep learningapproach achieves state-of-the-art results in contour detection.
arxiv-10200-233 | Collectively Embedding Multi-Relational Data for Predicting User Preferences | http://arxiv.org/pdf/1504.06165v1.pdf | author:Nitish Gupta, Sameer Singh category:cs.LG cs.IR published:2015-04-23 summary:Matrix factorization has found incredible success and widespread applicationas a collaborative filtering based approach to recommendations. Unfortunately,incorporating additional sources of evidence, especially ones that areincomplete and noisy, is quite difficult to achieve in such models, however, isoften crucial for obtaining further gains in accuracy. For example, additionalinformation about businesses from reviews, categories, and attributes should beleveraged for predicting user preferences, even though this information isoften inaccurate and partially-observed. Instead of creating customized methodsthat are specific to each type of evidences, in this paper we present a genericapproach to factorization of relational data that collectively models all therelations in the database. By learning a set of embeddings that are sharedacross all the relations, the model is able to incorporate observed informationfrom all the relations, while also predicting all the relations of interest.Our evaluation on multiple Amazon and Yelp datasets demonstrates effectiveutilization of additional information for held-out preference prediction, butfurther, we present accurate models even for the cold-starting businesses andproducts for which we do not observe any ratings or reviews. We also illustratethe capability of the model in imputing missing information and jointlyvisualizing words, categories, and attribute factors.
arxiv-10200-234 | Robust Principal Component Analysis on Graphs | http://arxiv.org/pdf/1504.06151v1.pdf | author:Nauman Shahid, Vassilis Kalofolias, Xavier Bresson, Michael Bronstein, Pierre Vandergheynst category:cs.CV published:2015-04-23 summary:Principal Component Analysis (PCA) is the most widely used tool for lineardimensionality reduction and clustering. Still it is highly sensitive tooutliers and does not scale well with respect to the number of data samples.Robust PCA solves the first issue with a sparse penalty term. The second issuecan be handled with the matrix factorization model, which is howevernon-convex. Besides, PCA based clustering can also be enhanced by using a graphof data similarity. In this article, we introduce a new model called "RobustPCA on Graphs" which incorporates spectral graph regularization into the RobustPCA framework. Our proposed model benefits from 1) the robustness of principalcomponents to occlusions and missing values, 2) enhanced low-rank recovery, 3)improved clustering property due to the graph smoothness assumption on thelow-rank matrix, and 4) convexity of the resulting optimization problem.Extensive experiments on 8 benchmark, 3 video and 2 artificial datasets withcorruptions clearly reveal that our model outperforms 10 other state-of-the-artmodels in its clustering and low-rank recovery tasks.
arxiv-10200-235 | Sparse Radial Sampling LBP for Writer Identification | http://arxiv.org/pdf/1504.06133v1.pdf | author:Anguelos Nicolaou, Andrew D. Bagdanov, Marcus Liwicki, Dimosthenis Karatzas category:cs.CV published:2015-04-23 summary:In this paper we present the use of Sparse Radial Sampling Local BinaryPatterns, a variant of Local Binary Patterns (LBP) for text-as-textureclassification. By adapting and extending the standard LBP operator to theparticularities of text we get a generic text-as-texture classification schemeand apply it to writer identification. In experiments on CVL and ICDAR 2013datasets, the proposed feature-set demonstrates State-Of-the-Art (SOA)performance. Among the SOA, the proposed method is the only one that is basedon dense extraction of a single local feature descriptor. This makes it fastand applicable at the earliest stages in a DIA pipeline without the need forsegmentation, binarization, or extraction of multiple features.
arxiv-10200-236 | Unsupervised Feature Learning for Dense Correspondences across Scenes | http://arxiv.org/pdf/1501.00642v2.pdf | author:Chao Zhang, Chunhua Shen, Tingzhi Shen category:cs.CV published:2015-01-04 summary:We propose a fast, accurate matching method for estimating dense pixelcorrespondences across scenes. It is a challenging problem to estimate densepixel correspondences between images depicting different scenes or instances ofthe same object category. While most such matching methods rely on hand-craftedfeatures such as SIFT, we learn features from a large amount of unlabeled imagepatches using unsupervised learning. Pixel-layer features are obtained byencoding over the dictionary, followed by spatial pooling to obtain patch-layerfeatures. The learned features are then seamlessly embedded into a multi-layermatch- ing framework. We experimentally demonstrate that the learned features,together with our matching model, outperforms state-of-the-art methods such asthe SIFT flow, coherency sensitive hashing and the recent deformable spatialpyramid matching methods both in terms of accuracy and computation efficiency.Furthermore, we evaluate the performance of a few different dictionary learningand feature encoding methods in the proposed pixel correspondences estimationframework, and analyse the impact of dictionary learning and feature encodingwith respect to the final matching performance.
arxiv-10200-237 | svcR: An R Package for Support Vector Clustering improved with Geometric Hashing applied to Lexical Pattern Discovery | http://arxiv.org/pdf/1504.06080v1.pdf | author:Nicolas Turenne category:cs.LG cs.CL published:2015-04-23 summary:We present a new R package which takes a numerical matrix format as datainput, and computes clusters using a support vector clustering method (SVC). Wehave implemented an original 2D-grid labeling approach to speed up clusterextraction. In this sense, SVC can be seen as an efficient cluster extractionif clusters are separable in a 2-D map. Secondly we showed that this SVCapproach using a Jaccard-Radial base kernel can help to classify well enough aset of terms into ontological classes and help to define regular expressionrules for information extraction in documents; our case study concerns a set ofterms and documents about developmental and molecular biology.
arxiv-10200-238 | x.ent: R Package for Entities and Relations Extraction based on Unsupervised Learning and Document Structure | http://arxiv.org/pdf/1504.06078v1.pdf | author:Nicolas Turenne, Tien Phan category:cs.CL cs.AI published:2015-04-23 summary:Relation extraction with accurate precision is still a challenge whenprocessing full text databases. We propose an approach based on cooccurrenceanalysis in each document for which we used document organization to improveaccuracy of relation extraction. This approach is implemented in a R packagecalled \emph{x.ent}. Another facet of extraction relies on use of extractedrelation into a querying system for expert end-users. Two datasets had beenused. One of them gets interest from specialists of epidemiology in planthealth. For this dataset usage is dedicated to plant-disease explorationthrough agricultural information news. An open-data platform exploits exportsfrom \emph{x.ent} and is publicly available.
arxiv-10200-239 | Open Data Platform for Knowledge Access in Plant Health Domain : VESPA Mining | http://arxiv.org/pdf/1504.06077v1.pdf | author:Nicolas Turenne, Mathieu Andro, Roselyne Corbière, Tien T. Phan category:cs.IR cs.CL published:2015-04-23 summary:Important data are locked in ancient literature. It would be uneconomic toproduce these data again and today or to extract them without the help of textmining technologies. Vespa is a text mining project whose aim is to extractdata on pest and crops interactions, to model and predict attacks on crops, andto reduce the use of pesticides. A few attempts proposed an agriculturalinformation access. Another originality of our work is to parse documents witha dependency of the document architecture.
arxiv-10200-240 | Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition | http://arxiv.org/pdf/1406.4729v4.pdf | author:Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun category:cs.CV published:2014-06-18 summary:Existing deep convolutional neural networks (CNNs) require a fixed-size(e.g., 224x224) input image. This requirement is "artificial" and may reducethe recognition accuracy for the images or sub-images of an arbitrarysize/scale. In this work, we equip the networks with another pooling strategy,"spatial pyramid pooling", to eliminate the above requirement. The new networkstructure, called SPP-net, can generate a fixed-length representationregardless of image size/scale. Pyramid pooling is also robust to objectdeformations. With these advantages, SPP-net should in general improve allCNN-based image classification methods. On the ImageNet 2012 dataset, wedemonstrate that SPP-net boosts the accuracy of a variety of CNN architecturesdespite their different designs. On the Pascal VOC 2007 and Caltech101datasets, SPP-net achieves state-of-the-art classification results using asingle full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net,we compute the feature maps from the entire image only once, and then poolfeatures in arbitrary regions (sub-images) to generate fixed-lengthrepresentations for training the detectors. This method avoids repeatedlycomputing the convolutional features. In processing test images, our method is24-102x faster than the R-CNN method, while achieving better or comparableaccuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, ourmethods rank #2 in object detection and #3 in image classification among all 38teams. This manuscript also introduces the improvement made for thiscompetition.
arxiv-10200-241 | Object Detection Networks on Convolutional Feature Maps | http://arxiv.org/pdf/1504.06066v1.pdf | author:Shaoqing Ren, Kaiming He, Ross Girshick, Xiangyu Zhang, Jian Sun category:cs.CV published:2015-04-23 summary:Most object detectors contain two important components: a feature extractorand an object classifier. The feature extractor has rapidly evolved withsignificant research efforts leading to better deep ConvNet architectures. Theobject classifier, however, has not received much attention and moststate-of-the-art systems (like R-CNN) use simple multi-layer perceptrons. Thispaper demonstrates that carefully designing deep networks for objectclassification is just as important. We take inspiration from traditionalobject classifiers, such as DPM, and experiment with deep networks that havepart-like filters and reason over latent variables. We discover that onpre-trained convolutional feature maps, even randomly initialized deepclassifiers produce excellent results, while the improvement due to fine-tuningis secondary; on HOG features, deep classifiers outperform DPMs and produce thebest HOG-only results without external data. We believe these findings providenew insight for developing object detection systems. Our framework, calledNetworks on Convolutional feature maps (NoC), achieves outstanding results onthe PASCAL VOC 2007 (73.3% mAP) and 2012 (68.8% mAP) benchmarks.
arxiv-10200-242 | Understanding and Diagnosing Visual Tracking Systems | http://arxiv.org/pdf/1504.06055v1.pdf | author:Naiyan Wang, Jianping Shi, Dit-Yan Yeung, Jiaya Jia category:cs.CV published:2015-04-23 summary:Several benchmark datasets for visual tracking research have been proposed inrecent years. Despite their usefulness, whether they are sufficient forunderstanding and diagnosing the strengths and weaknesses of different trackersremains questionable. To address this issue, we propose a framework by breakinga tracker down into five constituent parts, namely, motion model, featureextractor, observation model, model updater, and ensemble post-processor. Wethen conduct ablative experiments on each component to study how it affects theoverall result. Surprisingly, our findings are discrepant with some commonbeliefs in the visual tracking research community. We find that the featureextractor plays the most important role in a tracker. On the other hand,although the observation model is the focus of many studies, we find that itoften brings no significant improvement. Moreover, the motion model and modelupdater contain many details that could affect the result. Also, the ensemblepost-processor can improve the result substantially when the constituenttrackers have high diversity. Based on our findings, we put together some veryelementary building blocks to give a basic tracker which is competitive inperformance to the state-of-the-art trackers. We believe our framework canprovide a solid baseline when conducting controlled experiments for visualtracking research.
arxiv-10200-243 | Transferring Rich Feature Hierarchies for Robust Visual Tracking | http://arxiv.org/pdf/1501.04587v2.pdf | author:Naiyan Wang, Siyi Li, Abhinav Gupta, Dit-Yan Yeung category:cs.CV cs.NE published:2015-01-19 summary:Convolutional neural network (CNN) models have demonstrated great success invarious computer vision tasks including image classification and objectdetection. However, some equally important tasks such as visual tracking remainrelatively unexplored. We believe that a major hurdle that hinders theapplication of CNN to visual tracking is the lack of properly labeled trainingdata. While existing applications that liberate the power of CNN often need anenormous amount of training data in the order of millions, visual trackingapplications typically have only one labeled example in the first frame of eachvideo. We address this research issue here by pre-training a CNN offline andthen transferring the rich feature hierarchies learned to online tracking. TheCNN is also fine-tuned during online tracking to adapt to the appearance of thetracked target specified in the first video frame. To fit the characteristicsof object tracking, we first pre-train the CNN to recognize what is an object,and then propose to generate a probability map instead of producing a simpleclass label. Using two challenging open benchmarks for performance evaluation,our proposed tracker has demonstrated substantial improvement over otherstate-of-the-art trackers.
arxiv-10200-244 | Stability of Stochastic Approximations with `Controlled Markov' Noise and Temporal Difference Learning | http://arxiv.org/pdf/1504.06043v1.pdf | author:Arunselvan Ramaswamy, Shalabh Bhatnagar category:cs.SY stat.ML published:2015-04-23 summary:In this paper we present a `stability theorem' for stochastic approximation(SA) algorithms with `controlled Markov' noise. Such algorithms were firststudied by Borkar in 2006. Specifically, sufficient conditions are presentedwhich guarantee the stability of the iterates. Further, under these conditionsthe iterates are shown to track a solution to the differential inclusiondefined in terms of the ergodic occupation measures associated with the`controlled Markov' process. As an application to our main result we present animprovement to a general form of temporal difference learning algorithms.Specifically, we present sufficient conditions for their stability andconvergence using our framework. This paper builds on the works of Borkar aswell as Benveniste, Metivier and Priouret.
arxiv-10200-245 | Edge Detection Based on Global and Local Parameters of the Image | http://arxiv.org/pdf/1504.06036v1.pdf | author:Andrew F. C. Brustolin category:cs.CV I.4.6 published:2015-04-23 summary:This paper presents an edge detection method based on global and localparameters of the image, which produces satisfactory results on the edgedetection of complex images and has a simple structure for execution. The localand global parameters of the image are arithmetic means and standarddeviations, the former acquired from a three sized window representing fivepixels, the latter acquired from the entire row or column. We obtain thedifferences of grayscale intensities between two adjacent pixels and the sum ofthe modulus of these differences from the horizontal and vertical scans of theimage. Using these obtained values, we calculate the local and globalparameters. After the gathering of the local and global parameters, we compareeach sum of the modulus of differences with its own local and global parameter.In the case of the comparison is true, the consecutive pixel to the modulus sumof differences index is marked as an edge. We present the results of the testswith grayscale images using different parameters and discuss the advantages anddisadvantages of each parameter value and algorithm structure chosen on theedge processing. There is a comparison of results between this papers detectorand Canny, where we evaluate the quality of the presented detector.
arxiv-10200-246 | Review Mining for Feature Based Opinion Summarization and Visualization | http://arxiv.org/pdf/1504.03068v2.pdf | author:Ahmad Kamal category:cs.IR cs.CL published:2015-04-13 summary:The application and usage of opinion mining, especially for businessintelligence, product recommendation, targeted marketing etc. have fascinatedmany research attentions around the globe. Various research efforts attemptedto mine opinions from customer reviews at different levels of granularity,including word-, sentence-, and document-level. However, development of a fullyautomatic opinion mining and sentiment analysis system is still elusive. Thoughthe development of opinion mining and sentiment analysis systems are gettingmomentum, most of them attempt to perform document-level sentiment analysis,classifying a review document as positive, negative, or neutral. Suchdocument-level opinion mining approaches fail to provide insight about userssentiment on individual features of a product or service. Therefore, it seemsto be a great help for both customers and manufacturers, if the reviews couldbe processed at a finer-grained level and presented in a summarized formthrough some visual means, highlighting individual features of a product andusers sentiment expressed over them. In this paper, the design of a unifiedopinion mining and sentiment analysis framework is presented at theintersection of both machine learning and natural language processingapproaches. Also, design of a novel feature-level review summarization schemeis proposed to visualize mined features, opinions and their polarity values ina comprehendible way.
arxiv-10200-247 | Graphical Fermat's Principle and Triangle-Free Graph Estimation | http://arxiv.org/pdf/1504.06026v1.pdf | author:Junwei Lu, Han Liu category:stat.ML published:2015-04-23 summary:We consider the problem of estimating undirected triangle-free graphs of highdimensional distributions. Triangle-free graphs form a rich graph family whichallows arbitrary loopy structures but 3-cliques. For inferential tractability,we propose a graphical Fermat's principle to regularize the distributionfamily. Such principle enforces the existence of a distribution-dependentpseudo-metric such that any two nodes have a smaller distance than that of twoother nodes who have a geodesic path include these two nodes. Guided by thisprinciple, we show that a greedy strategy is able to recover the true graph.The resulting algorithm only requires a pairwise distance matrix as input andis computationally even more efficient than calculating the minimum spanningtree. We consider graph estimation problems under different settings, includingdiscrete and nonparametric distribution families. Thorough numerical resultsare provided to illustrate the usefulness of the proposed method.
arxiv-10200-248 | Deep Spatial Pyramid: The Devil is Once Again in the Details | http://arxiv.org/pdf/1504.05277v2.pdf | author:Bin-Bin Gao, Xiu-Shen Wei, Jianxin Wu, Weiyao Lin category:cs.CV published:2015-04-21 summary:In this paper we show that by carefully making good choices for variousdetailed but important factors in a visual recognition framework using deeplearning features, one can achieve a simple, efficient, yet highly accurateimage classification system. We first list 5 important factors, based on bothexisting researches and ideas proposed in this paper. These important detailedfactors include: 1) $\ell_2$ matrix normalization is more effective thanunnormalized or $\ell_2$ vector normalization, 2) the proposed natural deepspatial pyramid is very effective, and 3) a very small $K$ in Fisher Vectorssurprisingly achieves higher accuracy than normally used large $K$ values.Along with other choices (convolutional activations and multiple scales), theproposed DSP framework is not only intuitive and efficient, but also achievesexcellent classification accuracy on many benchmark datasets. For example,DSP's accuracy on SUN397 is 59.78%, significantly higher than previousstate-of-the-art (53.86%).
arxiv-10200-249 | On the relation between Gaussian process quadratures and sigma-point methods | http://arxiv.org/pdf/1504.05994v1.pdf | author:Simo Särkkä, Jouni Hartikainen, Lennart Svensson, Fredrik Sandblom category:stat.ME math.DS stat.ML published:2015-04-22 summary:This article is concerned with Gaussian process quadratures, which arenumerical integration methods based on Gaussian process regression methods, andsigma-point methods, which are used in advanced non-linear Kalman filtering andsmoothing algorithms. We show that many sigma-point methods can be interpretedas Gaussian quadrature based methods with suitably selected covariancefunctions. We show that this interpretation also extends to more generalmultivariate Gauss--Hermite integration methods and related spherical cubaturerules. Additionally, we discuss different criteria for selecting thesigma-point locations: exactness for multivariate polynomials up to a givenorder, minimum average error, and quasi-random point sets. The performance ofthe different methods is tested in numerical experiments.
arxiv-10200-250 | Learning Mixed Membership Community Models in Social Tagging Networks through Tensor Methods | http://arxiv.org/pdf/1503.04567v2.pdf | author:Anima Anandkumar, Hanie Sedghi category:cs.LG cs.SI stat.ML published:2015-03-16 summary:Community detection in graphs has been extensively studied both in theory andin applications. However, detecting communities in hypergraphs is morechallenging. In this paper, we propose a tensor decomposition approach forguaranteed learning of communities in a special class of hypergraphs modelingsocial tagging systems or folksonomies. A folksonomy is a tripartite 3-uniformhypergraph consisting of (user, tag, resource) hyperedges. We posit aprobabilistic mixed membership community model, and prove that the tensormethod consistently learns the communities under efficient sample complexityand separation requirements.
arxiv-10200-251 | A review of "Mem-computing NP-complete problems in polynomial time using polynomial resources" (arXiv:1411.4798) | http://arxiv.org/pdf/1412.0650v3.pdf | author:Igor L. Markov category:cs.ET cs.NE published:2014-11-29 summary:The reviewed paper describes an analog device that empirically solves smallinstances of the NP-complete Subset Sum Problem (SSP). The authors claim thatthis device can solve the SSP in polynomial time using polynomial space, inprinciple, and observe no exponential scaling in resource requirements. Wepoint out that (a) the properties ascribed by the authors to their device areinsufficient to solve NP-complete problems in poly-time, (b) runtime analysisoffered does not cover the spectral measurement step, (c) the overall techniquerequires exponentially increasing resources when scaled up because of thespectral measurement step.
arxiv-10200-252 | Robust Vertex Classification | http://arxiv.org/pdf/1311.5954v2.pdf | author:Li Chen, Cencheng Shen, Joshua Vogelstein, Carey Priebe category:stat.ML published:2013-11-23 summary:For random graphs distributed according to stochastic blockmodels, a specialcase of latent position graphs, adjacency spectral embedding followed byappropriate vertex classification is asymptotically Bayes optimal; but thisapproach requires knowledge of and critically depends on the model dimension.In this paper, we propose a sparse representation vertex classifier which doesnot require information about the model dimension. This classifier represents atest vertex as a sparse combination of the vertices in the training set anduses the recovered coefficients to classify the test vertex. We proveconsistency of our proposed classifier for stochastic blockmodels, anddemonstrate that the sparse representation classifier can predict vertex labelswith higher accuracy than adjacency spectral embedding approaches via bothsimulation studies and real data experiments. Our results demonstrate therobustness and effectiveness of our proposed vertex classifier when the modeldimension is unknown.
arxiv-10200-253 | The Power of Randomization: Distributed Submodular Maximization on Massive Datasets | http://arxiv.org/pdf/1502.02606v2.pdf | author:Rafael da Ponte Barbosa, Alina Ene, Huy L. Nguyen, Justin Ward category:cs.LG cs.AI cs.DC published:2015-02-09 summary:A wide variety of problems in machine learning, including exemplarclustering, document summarization, and sensor placement, can be cast asconstrained submodular maximization problems. Unfortunately, the resultingsubmodular optimization problems are often too large to be solved on a singlemachine. We develop a simple distributed algorithm that is embarrassinglyparallel and it achieves provable, constant factor, worst-case approximationguarantees. In our experiments, we demonstrate its efficiency in large problemswith different kinds of constraints with objective values always close to whatis achievable in the centralized setting.
arxiv-10200-254 | Convergence results for projected line-search methods on varieties of low-rank matrices via Łojasiewicz inequality | http://arxiv.org/pdf/1402.5284v3.pdf | author:Reinhold Schneider, André Uschmajew category:math.OC cs.LG math.NA published:2014-02-21 summary:The aim of this paper is to derive convergence results for projectedline-search methods on the real-algebraic variety $\mathcal{M}_{\le k}$ of real$m \times n$ matrices of rank at most $k$. Such methods extend Riemannianoptimization methods, which are successfully used on the smooth manifold$\mathcal{M}_k$ of rank-$k$ matrices, to its closure by taking steps alonggradient-related directions in the tangent cone, and afterwards projecting backto $\mathcal{M}_{\le k}$. Considering such a method circumvents thedifficulties which arise from the nonclosedness and the unbounded curvature of$\mathcal{M}_k$. The pointwise convergence is obtained for real-analyticfunctions on the basis of a \L{}ojasiewicz inequality for the projection of theantigradient to the tangent cone. If the derived limit point lies on the smoothpart of $\mathcal{M}_{\le k}$, i.e. in $\mathcal{M}_k$, this boils down to moreor less known results, but with the benefit that asymptotic convergence rateestimates (for specific step-sizes) can be obtained without an a prioricurvature bound, simply from the fact that the limit lies on a smooth manifold.At the same time, one can give a convincing justification for assuming criticalpoints to lie in $\mathcal{M}_k$: if $X$ is a critical point of $f$ on$\mathcal{M}_{\le k}$, then either $X$ has rank $k$, or $\nabla f(X) = 0$.
arxiv-10200-255 | Spectral Norm of Random Kernel Matrices with Applications to Privacy | http://arxiv.org/pdf/1504.05880v1.pdf | author:Shiva Prasad Kasiviswanathan, Mark Rudelson category:stat.ML cs.CR cs.LG F.2.1 published:2015-04-22 summary:Kernel methods are an extremely popular set of techniques used for manyimportant machine learning and data analysis applications. In addition tohaving good practical performances, these methods are supported by awell-developed theory. Kernel methods use an implicit mapping of the input datainto a high dimensional feature space defined by a kernel function, i.e., afunction returning the inner product between the images of two data points inthe feature space. Central to any kernel method is the kernel matrix, which isbuilt by evaluating the kernel function on a given sample dataset. In this paper, we initiate the study of non-asymptotic spectral theory ofrandom kernel matrices. These are n x n random matrices whose (i,j)th entry isobtained by evaluating the kernel function on $x_i$ and $x_j$, where$x_1,...,x_n$ are a set of n independent random high-dimensional vectors. Ourmain contribution is to obtain tight upper bounds on the spectral norm (largesteigenvalue) of random kernel matrices constructed by commonly used kernelfunctions based on polynomials and Gaussian radial basis. As an application of these results, we provide lower bounds on the distortionneeded for releasing the coefficients of kernel ridge regression underattribute privacy, a general privacy notion which captures a large class ofprivacy definitions. Kernel ridge regression is standard method for performingnon-parametric regression that regularly outperforms traditional regressionapproaches in various domains. Our privacy distortion lower bounds are thefirst for any kernel technique, and our analysis assumes realistic scenariosfor the input, unlike all previous lower bounds for other release problemswhich only hold under very restrictive input settings.
arxiv-10200-256 | On-the-fly Approximation of Multivariate Total Variation Minimization | http://arxiv.org/pdf/1504.05854v1.pdf | author:Jordan Frecon, Nelly Pustelnik, Patrice Abry, Laurent Condat category:cs.LG cs.NA math.OC published:2015-04-22 summary:In the context of change-point detection, addressed by Total Variationminimization strategies, an efficient on-the-fly algorithm has been designedleading to exact solutions for univariate data. In this contribution, anextension of such an on-the-fly strategy to multivariate data is investigated.The proposed algorithm relies on the local validation of the Karush-Kuhn-Tuckerconditions on the dual problem. Showing that the non-local nature of themultivariate setting precludes to obtain an exact on-the-fly solution, wedevise an on-the-fly algorithm delivering an approximate solution, whosequality is controlled by a practitioner-tunable parameter, acting as atrade-off between quality and computational cost. Performance assessment showsthat high quality solutions are obtained on-the-fly while benefiting ofcomputational costs several orders of magnitude lower than standard iterativeprocedures. The proposed algorithm thus provides practitioners with anefficient multivariate change-point detection on-the-fly procedure.
arxiv-10200-257 | Can Partial Strong Labels Boost Multi-label Object Recognition? | http://arxiv.org/pdf/1504.05843v1.pdf | author:Hao Yang, Joey Tianyi Zhou, Yu Zhang, Bin-Bin Gao, Jianxin Wu, Jianfei Cai category:cs.CV cs.LG published:2015-04-22 summary:Convolutional neural networks (CNN) have shown great performance as a globalrepresentation for object recognition. However, for multi-label images thatcontain multiple objects from different categories, scales and locations,single CNN features might not be be optimal. To enhance the robustness anddiscriminative power of CNN features for multi-label object recognitionproblem, we propose a multi-view multi-instance framework. This frameworktransforms the multi-label classification problem into a multi-classmulti-instance learning problem by extracting object proposals from images. Amulti-view pipeline is then applied to generate a two-view representation ofeach proposal by exploiting two levels of labels in multi-label recognitionproblem. The proposed framework not only has the flexibility of utilizing bothweak and strong labels or just weak labels, but also holds the generalizationability to boost the performance of unseen categories by available stronglabels. Our framework is extensively compared with state-of-the-arthand-crafted feature based and CNN based methods on two multi-label benchmarkdatasets. The experimental results validate the discriminative power andgeneralization ability of the proposed framework. When combined with avery-deep network, we can achieve state-of-the-art results in both datasets.
arxiv-10200-258 | Learning of Behavior Trees for Autonomous Agents | http://arxiv.org/pdf/1504.05811v1.pdf | author:Michele Colledanchise, Ramviyas Parasuraman, Petter Ögren category:cs.RO cs.AI cs.LG published:2015-04-22 summary:Definition of an accurate system model for Automated Planner (AP) is oftenimpractical, especially for real-world problems. Conversely, off-the-shelfplanners fail to scale up and are domain dependent. These drawbacks areinherited from conventional transition systems such as Finite State Machines(FSMs) that describes the action-plan execution generated by the AP. On theother hand, Behavior Trees (BTs) represent a valid alternative to FSMspresenting many advantages in terms of modularity, reactiveness, scalabilityand domain-independence. In this paper, we propose a model-free AP frameworkusing Genetic Programming (GP) to derive an optimal BT for an autonomous agentto achieve a given goal in unknown (but fully observable) environments. Weillustrate the proposed framework using experiments conducted with an opensource benchmark Mario AI for automated generation of BTs that can play thegame character Mario to complete a certain level at various levels ofdifficulty to include enemies and obstacles.
arxiv-10200-259 | LOAD: Local Orientation Adaptive Descriptor for Texture and Material Classification | http://arxiv.org/pdf/1504.05809v1.pdf | author:Xianbiao Qi, Guoying Zhao, Linlin Shen, Qingquan Li, Matti Pietikainen category:cs.CV published:2015-04-22 summary:In this paper, we propose a novel local feature, called Local OrientationAdaptive Descriptor (LOAD), to capture regional texture in an image. In LOAD,we proposed to define point description on an Adaptive Coordinate System (ACS),adopt a binary sequence descriptor to capture relationships between one pointand its neighbors and use multi-scale strategy to enhance the discriminativepower of the descriptor. The proposed LOAD enjoys not only discriminative powerto capture the texture information, but also has strong robustness toillumination variation and image rotation. Extensive experiments on benchmarkdata sets of texture classification and real-world material recognition showthat the proposed LOAD yields the state-of-the-art performance. It is worth tomention that we achieve a 65.4\% classification accuracy-- which is, to thebest of our knowledge, the highest record by far --on Flickr Material Databaseby using a single feature. Moreover, by combining LOAD with the featureextracted by Convolutional Neural Networks (CNN), we obtain significantlybetter performance than both the LOAD and CNN. This result confirms that theLOAD is complementary to the learning-based features.
arxiv-10200-260 | Rounding Methods for Neural Networks with Low Resolution Synaptic Weights | http://arxiv.org/pdf/1504.05767v1.pdf | author:Lorenz K. Muller, Giacomo Indiveri category:cs.NE published:2015-04-22 summary:Neural network algorithms simulated on standard computing platforms typicallymake use of high resolution weights, with floating-point notation. However, fordedicated hardware implementations of such algorithms, fixed-point synapticweights with low resolution are preferable. The basic approach of reducing theresolution of the weights in these algorithms by standard rounding methodsincurs drastic losses in performance. To reduce the resolution further, in theextreme case even to binary weights, more advanced techniques are necessary. Tothis end, we propose two methods for mapping neural network algorithms withhigh resolution weights to corresponding algorithms that work with lowresolution weights and demonstrate that their performance is substantiallybetter than standard rounding. We further use these methods to investigate theperformance of three common neural network algorithms under fixed memory sizeof the weight matrix with different weight resolutions. We show that dedicatedhardware systems, whose technology dictates very low weight resolutions (bethey electronic or biological) could in principle implement the algorithms westudy.
arxiv-10200-261 | Honeybees-inspired heuristic algorithms for numerical optimisation | http://arxiv.org/pdf/1504.05766v1.pdf | author:Muharrem Düğenci category:cs.NE published:2015-04-22 summary:Swarm intelligence is all about developing collective behaviours to solvecomplex, ill-structured and large-scale problems. Efficiency in collectivebehaviours depends on how to harmonise the individual contributions so that acomplementary collective effort can be achieved to offer a useful solution. Themain points in organising the harmony remains as managing the diversificationand intensification actions appropriately, where the efficiency of collectivebehaviours depends on blending these two actions appropriately. In this study,two swarm intelligence algorithms inspired of natural honeybee colonies havebeen overviewed with many respects and two new revisions and a hybrid versionhave been studied to improve the efficiencies in solving numerical optimisationproblems, which are well-known hard benchmarks. Consequently, the revisions andespecially the hybrid algorithm proposed have outperformed the two original beealgorithms in solving these very hard numerical optimisation benchmarks.
arxiv-10200-262 | Learning Non-deterministic Representations with Energy-based Ensembles | http://arxiv.org/pdf/1412.7272v2.pdf | author:Maruan Al-Shedivat, Emre Neftci, Gert Cauwenberghs category:cs.LG cs.NE published:2014-12-23 summary:The goal of a generative model is to capture the distribution underlying thedata, typically through latent variables. After training, these variables areoften used as a new representation, more effective than the original featuresin a variety of learning tasks. However, the representations constructed bycontemporary generative models are usually point-wise deterministic mappingsfrom the original feature space. Thus, even with representations robust toclass-specific transformations, statistically driven models trained on themwould not be able to generalize when the labeled data is scarce. Inspired bythe stochasticity of the synaptic connections in the brain, we introduceEnergy-based Stochastic Ensembles. These ensembles can learn non-deterministicrepresentations, i.e., mappings from the feature space to a family ofdistributions in the latent space. These mappings are encoded in a distributionover a (possibly infinite) collection of models. By conditionally samplingmodels from the ensemble, we obtain multiple representations for every inputexample and effectively augment the data. We propose an algorithm similar tocontrastive divergence for training restricted Boltzmann stochastic ensembles.Finally, we demonstrate the concept of the stochastic representations on asynthetic dataset as well as test them in the one-shot learning scenario onMNIST.
arxiv-10200-263 | Rebuilding Factorized Information Criterion: Asymptotically Accurate Marginal Likelihood | http://arxiv.org/pdf/1504.05665v1.pdf | author:Kohei Hayashi, Shin-ichi Maeda, Ryohei Fujimaki category:cs.LG stat.ML published:2015-04-22 summary:Factorized information criterion (FIC) is a recently developed approximationtechnique for the marginal log-likelihood, which provides an automatic modelselection framework for a few latent variable models (LVMs) with tractableinference algorithms. This paper reconsiders FIC and fills theoretical gaps ofprevious FIC studies. First, we reveal the core idea of FIC that allowsgeneralization for a broader class of LVMs, including continuous LVMs, incontrast to previous FICs, which are applicable only to binary LVMs. Second, weinvestigate the model selection mechanism of the generalized FIC. Our analysisprovides a formal justification of FIC as a model selection criterion for LVMsand also a systematic procedure for pruning redundant latent variables thathave been removed heuristically in previous studies. Third, we provide aninterpretation of FIC as a variational free energy and uncover a fewpreviously-unknown their relationships. A demonstrative study on Bayesianprincipal component analysis is provided and numerical experiments support ourtheoretical results.
arxiv-10200-264 | Self-Tuned Deep Super Resolution | http://arxiv.org/pdf/1504.05632v1.pdf | author:Zhangyang Wang, Yingzhen Yang, Zhaowen Wang, Shiyu Chang, Wei Han, Jianchao Yang, Thomas S. Huang category:cs.LG cs.CV published:2015-04-22 summary:Deep learning has been successfully applied to image super resolution (SR).In this paper, we propose a deep joint super resolution (DJSR) model to exploitboth external and self similarities for SR. A Stacked Denoising ConvolutionalAuto Encoder (SDCAE) is first pre-trained on external examples with proper dataaugmentations. It is then fine-tuned with multi-scale self examples from eachinput, where the reliability of self examples is explicitly taken into account.We also enhance the model performance by sub-model training and selection. TheDJSR model is extensively evaluated and compared with state-of-the-arts, andshow noticeable performance improvements both quantitatively and perceptuallyon a wide range of images.
arxiv-10200-265 | Adaptive Compressive Tracking via Online Vector Boosting Feature Selection | http://arxiv.org/pdf/1504.05451v2.pdf | author:Qingshan Liu, Jing Yang, Kaihua Zhang, Yi Wu category:cs.CV published:2015-04-21 summary:Recently, the compressive tracking (CT) method has attracted much attentiondue to its high efficiency, but it cannot well deal with the large scale targetappearance variations due to its data-independent random projection matrix thatresults in less discriminative features. To address this issue, in this paperwe propose an adaptive CT approach, which selects the most discriminativefeatures to design an effective appearance model. Our method significantlyimproves CT in three aspects: Firstly, the most discriminative features areselected via an online vector boosting method. Secondly, the objectrepresentation is updated in an effective online manner, which preserves thestable features while filtering out the noisy ones. Finally, a simple andeffective trajectory rectification approach is adopted that can make theestimated location more accurate. Extensive experiments on the CVPR2013tracking benchmark demonstrate the superior performance of our algorithmcompared over state-of-the-art tracking algorithms.
arxiv-10200-266 | Median and Mode Ellipse Parameterization for Robust Contour Fitting | http://arxiv.org/pdf/1504.05623v1.pdf | author:Michael A. Greminger category:cs.CV published:2015-04-22 summary:Problems that require the parameterization of closed contours arisefrequently in computer vision applications. This article introduces a new curveparameterization algorithm that is able to fit a closed curve to a set ofpoints while being robust to the presence of outliers and occlusions in thedata. This robustness property makes this algorithm applicable to computervision applications where misclassification of features may lead to outliers.The algorithm starts by fitting ellipses to numerous five point subsets fromthe source data. The closed curve is parameterized by determining the medianperimeter of the set of ellipses. The resulting curve is not an ellipse,allowing arbitrary closed contours to be parameterized. The use of the modalperimeter rather than the median perimeter is also explored. A detailedcomparison is made between the proposed curve fitting algorithm and existingrobust ellipse fitting algorithms. Finally, the utility of the algorithm forcomputer vision applications is demonstrated through the parameterization ofthe boundary of fuel droplets during combustion. The performance of theproposed algorithm and the performance of existing algorithms are compared to aground truth segmentation of the fuel droplet images, which demonstratesimproved performance for both area quantification and edge deviation.
arxiv-10200-267 | Learning Opposites with Evolving Rules | http://arxiv.org/pdf/1504.05619v1.pdf | author:Hamid R. Tizhoosh, Shahryar Rahnamayan category:cs.NE cs.LG published:2015-04-21 summary:The idea of opposition-based learning was introduced 10 years ago. Since thena noteworthy group of researchers has used some notions of oppositeness toimprove existing optimization and learning algorithms. Among others,evolutionary algorithms, reinforcement agents, and neural networks have beenreportedly extended into their opposition-based version to become faster and/ormore accurate. However, most works still use a simple notion of opposites,namely linear (or type- I) opposition, that for each $x\in[a,b]$ assigns itsopposite as $\breve{x}_I=a+b-x$. This, of course, is a very naive estimate ofthe actual or true (non-linear) opposite $\breve{x}_{II}$, which has beencalled type-II opposite in literature. In absence of any knowledge about afunction $y=f(\mathbf{x})$ that we need to approximate, there seems to be noalternative to the naivety of type-I opposition if one intents to utilizeoppositional concepts. But the question is if we can receive some level ofaccuracy increase and time savings by using the naive opposite estimate$\breve{x}_I$ according to all reports in literature, what would we be able togain, in terms of even higher accuracies and more reduction in computationalcomplexity, if we would generate and employ true opposites? This workintroduces an approach to approximate type-II opposites using evolving fuzzyrules when we first perform opposition mining. We show with multiple examplesthat learning true opposites is possible when we mine the opposites from thetraining data to subsequently approximate $\breve{x}_{II}=f(\mathbf{x},y)$.
arxiv-10200-268 | Temporal-Difference Networks | http://arxiv.org/pdf/1504.05539v1.pdf | author:Richard S. Sutton, Brian Tanner category:cs.LG published:2015-04-21 summary:We introduce a generalization of temporal-difference (TD) learning tonetworks of interrelated predictions. Rather than relating a single predictionto itself at a later time, as in conventional TD methods, a TD network relateseach prediction in a set of predictions to other predictions in the set at alater time. TD networks can represent and apply TD learning to a much widerclass of predictions than has previously been possible. Using a random-walkexample, we show that these networks can be used to learn to predict by a fixedinterval, which is not possible with conventional TD methods. Secondly, we showthat if the inter-predictive relationships are made conditional on action, thenthe usual learning-efficiency advantage of TD methods over Monte Carlo(supervised learning) methods becomes particularly pronounced. Thirdly, wedemonstrate that TD networks can learn predictive state representations thatenable exact solution of a non-Markov problem. A very broad range ofinter-predictive temporal relationships can be expressed in these networks.Overall we argue that TD networks represent a substantial extension of theabilities of TD methods and bring us closer to the goal of representing worldknowledge in entirely predictive, grounded terms.
arxiv-10200-269 | A robust and efficient video representation for action recognition | http://arxiv.org/pdf/1504.05524v1.pdf | author:Heng Wang, Dan Oneata, Jakob Verbeek, Cordelia Schmid category:cs.CV published:2015-04-21 summary:This paper introduces a state-of-the-art video representation and applies itto efficient action recognition and detection. We first propose to improve thepopular dense trajectory features by explicit camera motion estimation. Morespecifically, we extract feature point matches between frames using SURFdescriptors and dense optical flow. The matches are used to estimate ahomography with RANSAC. To improve the robustness of homography estimation, ahuman detector is employed to remove outlier matches from the human body ashuman motion is not constrained by the camera. Trajectories consistent with thehomography are considered as due to camera motion, and thus removed. We alsouse the homography to cancel out camera motion from the optical flow. Thisresults in significant improvement on motion-based HOF and MBH descriptors. Wefurther explore the recent Fisher vector as an alternative feature encodingapproach to the standard bag-of-words histogram, and consider different ways toinclude spatial layout information in these encodings. We present a large andvaried set of evaluations, considering (i) classification of short basicactions on six datasets, (ii) localization of such actions in feature-lengthmovies, and (iii) large-scale recognition of complex events. We find that ourimproved trajectory features significantly outperform previous densetrajectories, and that Fisher vectors are superior to bag-of-words encodingsfor video recognition tasks. In all three tasks, we show substantialimprovements over the state-of-the-art results.
arxiv-10200-270 | Online Learning Algorithm for Time Series Forecasting Suitable for Low Cost Wireless Sensor Networks Nodes | http://arxiv.org/pdf/1504.05517v1.pdf | author:Juan Pardo, Francisco Zamora-Martinez, Paloma Botella-Rocamora category:cs.NI cs.LG cs.SY published:2015-04-21 summary:Time series forecasting is an important predictive methodology which can beapplied to a wide range of problems. Particularly, forecasting the indoortemperature permits an improved utilization of the HVAC (Heating, Ventilatingand Air Conditioning) systems in a home and thus a better energy efficiency.With such purpose the paper describes how to implement an Artificial NeuralNetwork (ANN) algorithm in a low cost system-on-chip to develop an autonomousintelligent wireless sensor network. The present paper uses a Wireless SensorNetworks (WSN) to monitor and forecast the indoor temperature in a smart home,based on low resources and cost microcontroller technology as the 8051MCU. Anon-line learning approach, based on Back-Propagation (BP) algorithm for ANNs,has been developed for real-time time series learning. It performs the modeltraining with every new data that arrive to the system, without saving enormousquantities of data to create a historical database as usual, i.e., withoutprevious knowledge. Consequently to validate the approach a simulation studythrough a Bayesian baseline model have been tested in order to compare with adatabase of a real application aiming to see the performance and accuracy. Thecore of the paper is a new algorithm, based on the BP one, which has beendescribed in detail, and the challenge was how to implement a computationaldemanding algorithm in a simple architecture with very few hardware resources.
arxiv-10200-271 | Deep Convolutional Neural Networks Based on Semi-Discrete Frames | http://arxiv.org/pdf/1504.05487v1.pdf | author:Thomas Wiatowski, Helmut Bölcskei category:cs.LG cs.IT math.FA math.IT stat.ML published:2015-04-21 summary:Deep convolutional neural networks have led to breakthrough results inpractical feature extraction applications. The mathematical analysis of thesenetworks was pioneered by Mallat, 2012. Specifically, Mallat consideredso-called scattering networks based on identical semi-discrete wavelet framesin each network layer, and proved translation-invariance as well as deformationstability of the resulting feature extractor. The purpose of this paper is todevelop Mallat's theory further by allowing for different and, mostimportantly, general semi-discrete frames (such as, e.g., Gabor frames,wavelets, curvelets, shearlets, ridgelets) in distinct network layers. Thisallows to extract wider classes of features than point singularities resolvedby the wavelet transform. Our generalized feature extractor is proven to betranslation-invariant, and we develop deformation stability results for alarger class of deformations than those considered by Mallat. For Mallat'swavelet-based feature extractor, we get rid of a number of technicalconditions. The mathematical engine behind our results is continuous frametheory, which allows us to completely detach the invariance and deformationstability proofs from the particular algebraic structure of the underlyingframes.
arxiv-10200-272 | Can FCA-based Recommender System Suggest a Proper Classifier? | http://arxiv.org/pdf/1504.05473v1.pdf | author:Yury Kashnitsky, Dmitry I. Ignatov category:cs.IR cs.LG stat.ML 62-07 published:2015-04-21 summary:The paper briefly introduces multiple classifier systems and describes a newalgorithm, which improves classification accuracy by means of recommendation ofa proper algorithm to an object classification. This recommendation is doneassuming that a classifier is likely to predict the label of the objectcorrectly if it has correctly classified its neighbors. The process ofassigning a classifier to each object is based on Formal Concept Analysis. Weexplain the idea of the algorithm with a toy example and describe our firstexperiments with real-world datasets.
arxiv-10200-273 | Detecting Epileptic Seizures from EEG Data using Neural Networks | http://arxiv.org/pdf/1412.6502v4.pdf | author:Siddharth Pramod, Adam Page, Tinoosh Mohsenin, Tim Oates category:cs.LG cs.NE q-bio.NC published:2014-12-19 summary:We explore the use of neural networks trained with dropout in predictingepileptic seizures from electroencephalographic data (scalp EEG). The input tothe neural network is a 126 feature vector containing 9 features for each ofthe 14 EEG channels obtained over 1-second, non-overlapping windows. The modelsin our experiments achieved high sensitivity and specificity on patient recordsnot used in the training process. This is demonstrated usingleave-one-out-cross-validation across patient records, where we hold out onepatient's record as the test set and use all other patients' records fortraining; repeating this procedure for all patients in the database.
arxiv-10200-274 | A local approach to estimation in discrete loglinear models | http://arxiv.org/pdf/1504.05434v1.pdf | author:Helene Massam, Nanwei Wang category:stat.ML 62H17, 62M40 published:2015-04-21 summary:We consider two connected aspects of maximum likelihood estimation of theparameter for high-dimensional discrete graphical models: the existence of themaximum likelihood estimate (mle) and its computation. When the data is sparse, there are many zeros in the contingency table andthe maximum likelihood estimate of the parameter may not exist. Fienberg andRinaldo (2012) have shown that the mle does not exists iff the data vectorbelongs to a face of the so-called marginal cone spanned by the rows of thedesign matrix of the model. Identifying these faces in high-dimension ischallenging. In this paper, we take a local approach : we show that one suchface, albeit possibly not the smallest one, can be identified by looking at acollection of marginal graphical models generated by induced subgraphs$G_i,i=1,\ldots,k$ of $G$. This is our first contribution. Our second contribution concerns the composite maximum likelihood estimate.When the dimension of the problem is large, estimating the parameters of agiven graphical model through maximum likelihood is challenging, if notimpossible. The traditional approach to this problem has been local with theuse of composite likelihood based on local conditional likelihoods. A more recent development is to have the components of the compositelikelihood be marginal likelihoods centred around each $v$. We first show thatthe estimates obtained by consensus through local conditional and marginallikelihoods are identical. We then study the asymptotic properties of thecomposite maximum likelihood estimate when both the dimension of the model andthe sample size $N$ go to infinity.
arxiv-10200-275 | Effective Discriminative Feature Selection with Non-trivial Solutions | http://arxiv.org/pdf/1504.05408v1.pdf | author:Hong Tao, Chenping Hou, Feiping Nie, Yuanyuan Jiao, Dongyun Yi category:cs.LG published:2015-04-21 summary:Feature selection and feature transformation, the two main ways to reducedimensionality, are often presented separately. In this paper, a featureselection method is proposed by combining the popular transformation baseddimensionality reduction method Linear Discriminant Analysis (LDA) and sparsityregularization. We impose row sparsity on the transformation matrix of LDAthrough ${\ell}_{2,1}$-norm regularization to achieve feature selection, andthe resultant formulation optimizes for selecting the most discriminativefeatures and removing the redundant ones simultaneously. The formulation isextended to the ${\ell}_{2,p}$-norm regularized case: which is more likely tooffer better sparsity when $0<p<1$. Thus the formulation is a betterapproximation to the feature selection problem. An efficient algorithm isdeveloped to solve the ${\ell}_{2,p}$-norm based optimization problem and it isproved that the algorithm converges when $0<p\le 2$. Systematical experimentsare conducted to understand the work of the proposed method. Promisingexperimental results on various types of real-world data sets demonstrate theeffectiveness of our algorithm.
arxiv-10200-276 | Nonparametric Testing for Heterogeneous Correlation | http://arxiv.org/pdf/1504.05392v1.pdf | author:Stephen Bamattre, Rex Hu, Joseph S. Verducci category:stat.ML published:2015-04-21 summary:In the presence of weak overall correlation, it may be useful to investigateif the correlation is significantly and substantially more pronounced over asubpopulation. Two different testing procedures are compared. Both are based onthe rankings of the values of two variables from a data set with a large numbern of observations. The first maintains its level against Gaussian copulas; thesecond adapts to general alternatives in the sense that that the number ofparameters used in the test grows with n. An analysis of wine qualityillustrates how the methods detect heterogeneity of association betweenchemical properties of the wine, which are attributable to a mix of differentcultivars.
arxiv-10200-277 | Key-Pose Prediction in Cyclic Human Motion | http://arxiv.org/pdf/1504.05369v1.pdf | author:Dan Zecha, Rainer Lienhart category:cs.CV published:2015-04-21 summary:In this paper we study the problem of estimating innercyclic time intervalswithin repetitive motion sequences of top-class swimmers in a swimming channel.Interval limits are given by temporal occurrences of key-poses, i.e.distinctive postures of the body. A key-pose is defined by means of only one ortwo specific features of the complete posture. It is often difficult to detectsuch subtle features directly. We therefore propose the following method: Giventhat we observe the swimmer from the side, we build a pictorial structure ofposelets to robustly identify random support poses within the regular motion ofa swimmer. We formulate a maximum likelihood model which predicts a key-posegiven the occurrences of multiple support poses within one stroke. The maximumlikelihood can be extended with prior knowledge about the temporal location ofa key-pose in order to improve the prediction recall. We experimentally showthat our models reliably and robustly detect key-poses with a high precisionand that their performance can be improved by extending the framework withadditional camera views.
arxiv-10200-278 | Learning Activation Functions to Improve Deep Neural Networks | http://arxiv.org/pdf/1412.6830v3.pdf | author:Forest Agostinelli, Matthew Hoffman, Peter Sadowski, Pierre Baldi category:cs.NE cs.CV cs.LG stat.ML published:2014-12-21 summary:Artificial neural networks typically have a fixed, non-linear activationfunction at each neuron. We have designed a novel form of piecewise linearactivation function that is learned independently for each neuron usinggradient descent. With this adaptive activation function, we are able toimprove upon deep neural network architectures composed of static rectifiedlinear units, achieving state-of-the-art performance on CIFAR-10 (7.51%),CIFAR-100 (30.83%), and a benchmark from high-energy physics involving Higgsboson decay modes.
arxiv-10200-279 | A Group Theoretic Perspective on Unsupervised Deep Learning | http://arxiv.org/pdf/1504.02462v3.pdf | author:Arnab Paul, Suresh Venkatasubramanian category:cs.LG cs.NE stat.ML published:2015-04-08 summary:Why does Deep Learning work? What representations does it capture? How dohigher-order representations emerge? We study these questions from theperspective of group theory, thereby opening a new approach towards a theory ofDeep learning. One factor behind the recent resurgence of the subject is a key algorithmicstep called {\em pretraining}: first search for a good generative model for theinput samples, and repeat the process one layer at a time. We show deeperimplications of this simple principle, by establishing a connection with theinterplay of orbits and stabilizers of group actions. Although the neuralnetworks themselves may not form groups, we show the existence of {\em shadow}groups whose elements serve as close approximations. Over the shadow groups, the pre-training step, originally introduced as amechanism to better initialize a network, becomes equivalent to a search forfeatures with minimal orbits. Intuitively, these features are in a way the {\emsimplest}. Which explains why a deep learning network learns simple featuresfirst. Next, we show how the same principle, when repeated in the deeperlayers, can capture higher order representations, and why representationcomplexity increases as the layers get deeper.
arxiv-10200-280 | Streaming Variational Inference for Bayesian Nonparametric Mixture Models | http://arxiv.org/pdf/1412.0694v3.pdf | author:Alex Tank, Nicholas J. Foti, Emily B. Fox category:stat.ML published:2014-12-01 summary:In theory, Bayesian nonparametric (BNP) models are well suited to streamingdata scenarios due to their ability to adapt model complexity with the observeddata. Unfortunately, such benefits have not been fully realized in practice;existing inference algorithms are either not applicable to streamingapplications or not extensible to BNP models. For the special case of Dirichletprocesses, streaming inference has been considered. However, there is growinginterest in more flexible BNP models building on the class of normalized randommeasures (NRMs). We work within this general framework and present a streamingvariational inference algorithm for NRM mixture models. Our algorithm is basedon assumed density filtering (ADF), leading straightforwardly to expectationpropagation (EP) for large-scale batch inference as well. We demonstrate theefficacy of the algorithm on clustering documents in large, streaming textcorpora.
arxiv-10200-281 | Automatic Face Recognition from Video | http://arxiv.org/pdf/1504.05308v1.pdf | author:Ognjen Arandjelovic category:cs.CV published:2015-04-21 summary:The objective of this work is to automatically recognize faces from videosequences in a realistic, unconstrained setup in which illumination conditionsare extreme and greatly changing, viewpoint and user motion pattern have a widevariability, and video input is of low quality. At the centre of focus are faceappearance manifolds: this thesis presents a significant advance of theirunderstanding and application in the sphere of face recognition. The two maincontributions are the Generic Shape-Illumination Manifold recognition algorithmand the Anisotropic Manifold Space clustering. The Generic Shape-IlluminationManifold is evaluated on a large data corpus acquired in real-world conditionsand its performance is shown to greatly exceed that of state-of-the-art methodsin the literature and the best performing commercial software. Empiricalevaluation of the Anisotropic Manifold Space clustering on a popular situationcomedy is also described with excellent preliminary results.
arxiv-10200-282 | The adaptable buffer algorithm for high quantile estimation in non-stationary data streams | http://arxiv.org/pdf/1504.05302v1.pdf | author:Ognjen Arandjelovic, Duc-Son Pham, Svetha Venkatesh category:cs.CV published:2015-04-21 summary:The need to estimate a particular quantile of a distribution is an importantproblem which frequently arises in many computer vision and signal processingapplications. For example, our work was motivated by the requirements of manysemi-automatic surveillance analytics systems which detect abnormalities inclose-circuit television (CCTV) footage using statistical models of low-levelmotion features. In this paper we specifically address the problem ofestimating the running quantile of a data stream with non-stationarystochasticity when the memory for storing observations is limited. We makeseveral major contributions: (i) we derive an important theoretical resultwhich shows that the change in the quantile of a stream is constrainedregardless of the stochastic properties of data, (ii) we describe a set ofhigh-level design goals for an effective estimation algorithm that emerge as aconsequence of our theoretical findings, (iii) we introduce a novel algorithmwhich implements the aforementioned design goals by retaining a sample of datavalues in a manner adaptive to changes in the distribution of data andprogressively narrowing down its focus in the periods of quasi-stationarystochasticity, and (iv) we present a comprehensive evaluation of the proposedalgorithm and compare it with the existing methods in the literature on bothsynthetic data sets and three large `real-world' streams acquired in the courseof operation of an existing commercial surveillance system. Our findingsconvincingly demonstrate that the proposed method is highly successful andvastly outperforms the existing alternatives, especially when the targetquantile is high valued and the available buffer capacity severely limited.
arxiv-10200-283 | Groupwise registration of aerial images | http://arxiv.org/pdf/1504.05299v1.pdf | author:Ognjen Arandjelovic, Duc-Son Pham, Svetha Venkatesh category:cs.CV published:2015-04-21 summary:This paper addresses the task of time separated aerial image registration.The ability to solve this problem accurately and reliably is important for avariety of subsequent image understanding applications. The principal challengelies in the extent and nature of transient appearance variation that a landarea can undergo, such as that caused by the change in illumination conditions,seasonal variations, or the occlusion by non-persistent objects (people, cars).Our work introduces several novelties: (i) unlike all previous work on aerialimage registration, we approach the problem using a set-based paradigm; (ii) weshow how local, pair-wise constraints can be used to enforce a globally goodregistration using a constraints graph structure; (iii) we show how a simpleholistic representation derived from raw aerial images can be used as a basicbuilding block of the constraints graph in a manner which achieves both highregistration accuracy and speed. We demonstrate: (i) that the proposed methodoutperforms the state-of-the-art for pair-wise registration already, achievinggreater accuracy and reliability, while at the same time reducing thecomputational cost of the task; and (ii) that the increase in the number ofavailable images in a set consistently reduces the average registration error.
arxiv-10200-284 | Viewpoint distortion compensation in practical surveillance systems | http://arxiv.org/pdf/1504.05298v1.pdf | author:Ognjen Arandjelovic, Duc-Son Pham, Svetha Venkatesh category:cs.CV published:2015-04-21 summary:Our aim is to estimate the perspective-effected geometric distortion of ascene from a video feed. In contrast to all previous work we wish to achievethis using from low-level, spatio-temporally local motion features used incommercial semi-automatic surveillance systems. We: (i) describe a densealgorithm which uses motion features to estimate the perspective distortion ateach image locus and then polls all such local estimates to arrive at theglobally best estimate, (ii) present an alternative coarse algorithm whichsubdivides the image frame into blocks, and uses motion features to deriveblock-specific motion characteristics and constrain the relationships betweenthese characteristics, with the perspective estimate emerging as a result of aglobal optimization scheme, and (iii) report the results of an evaluation usingnine large sets acquired using existing close-circuit television (CCTV)cameras. Our findings demonstrate that both of the proposed methods aresuccessful, their accuracy matching that of human labelling using completevisual data.
arxiv-10200-285 | Distance-based species tree estimation: information-theoretic trade-off between number of loci and sequence length under the coalescent | http://arxiv.org/pdf/1504.05289v1.pdf | author:Elchanan Mossel, Sebastien Roch category:math.PR cs.LG math.ST q-bio.PE stat.TH published:2015-04-21 summary:We consider the reconstruction of a phylogeny from multiple genes under themultispecies coalescent. We establish a connection with the sparse signaldetection problem, where one seeks to distinguish between a distribution and amixture of the distribution and a sparse signal. Using this connection, wederive an information-theoretic trade-off between the number of genes, $m$,needed for an accurate reconstruction and the sequence length, $k$, of thegenes. Specifically, we show that to detect a branch of length $f$, one needs$m = \Theta(1/[f^{2} \sqrt{k}])$.
arxiv-10200-286 | Decomposing Overcomplete 3rd Order Tensors using Sum-of-Squares Algorithms | http://arxiv.org/pdf/1504.05287v1.pdf | author:Rong Ge, Tengyu Ma category:cs.DS cs.LG stat.ML published:2015-04-21 summary:Tensor rank and low-rank tensor decompositions have many applications inlearning and complexity theory. Most known algorithms use unfoldings of tensorsand can only handle rank up to $n^{\lfloor p/2 \rfloor}$ for a $p$-th ordertensor in $\mathbb{R}^{n^p}$. Previously no efficient algorithm can decompose3rd order tensors when the rank is super-linear in the dimension. Using ideasfrom sum-of-squares hierarchy, we give the first quasi-polynomial timealgorithm that can decompose a random 3rd order tensor decomposition when therank is as large as $n^{3/2}/\textrm{polylog} n$. We also give a polynomial time algorithm for certifying the injective norm ofrandom low rank tensors. Our tensor decomposition algorithm exploits therelationship between injective norm and the tensor components. The proof relieson interesting tools for decoupling random variables to prove better matrixconcentration bounds, which can be useful in other settings.
arxiv-10200-287 | An Emphatic Approach to the Problem of Off-policy Temporal-Difference Learning | http://arxiv.org/pdf/1503.04269v2.pdf | author:Richard S. Sutton, A. Rupam Mahmood, Martha White category:cs.LG published:2015-03-14 summary:In this paper we introduce the idea of improving the performance ofparametric temporal-difference (TD) learning algorithms by selectivelyemphasizing or de-emphasizing their updates on different time steps. Inparticular, we show that varying the emphasis of linear TD($\lambda$)'s updatesin a particular way causes its expected update to become stable underoff-policy training. The only prior model-free TD methods to achieve this withper-step computation linear in the number of function approximation parametersare the gradient-TD family of methods including TDC, GTD($\lambda$), andGQ($\lambda$). Compared to these methods, our _emphatic TD($\lambda$)_ issimpler and easier to use; it has only one learned parameter vector and onestep-size parameter. Our treatment includes general state-dependent discountingand bootstrapping functions, and a way of specifying varying degrees ofinterest in accurately valuing different states.
arxiv-10200-288 | Show and Tell: A Neural Image Caption Generator | http://arxiv.org/pdf/1411.4555v2.pdf | author:Oriol Vinyals, Alexander Toshev, Samy Bengio, Dumitru Erhan category:cs.CV published:2014-11-17 summary:Automatically describing the content of an image is a fundamental problem inartificial intelligence that connects computer vision and natural languageprocessing. In this paper, we present a generative model based on a deeprecurrent architecture that combines recent advances in computer vision andmachine translation and that can be used to generate natural sentencesdescribing an image. The model is trained to maximize the likelihood of thetarget description sentence given the training image. Experiments on severaldatasets show the accuracy of the model and the fluency of the language itlearns solely from image descriptions. Our model is often quite accurate, whichwe verify both qualitatively and quantitatively. For instance, while thecurrent state-of-the-art BLEU-1 score (the higher the better) on the Pascaldataset is 25, our approach yields 59, to be compared to human performancearound 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66,and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, weachieve a BLEU-4 of 27.7, which is the current state-of-the-art.
arxiv-10200-289 | Convolutional Neural Network-Based Image Representation for Visual Loop Closure Detection | http://arxiv.org/pdf/1504.05241v1.pdf | author:Yi Hou, Hong Zhang, Shilin Zhou category:cs.RO cs.CV published:2015-04-20 summary:Deep convolutional neural networks (CNN) have recently been shown in manycomputer vision and pattern recog- nition applications to outperform by asignificant margin state- of-the-art solutions that use traditionalhand-crafted features. However, this impressive performance is yet to be fullyexploited in robotics. In this paper, we focus one specific problem that canbenefit from the recent development of the CNN technology, i.e., we focus onusing a pre-trained CNN model as a method of generating an image representationappropriate for visual loop closure detection in SLAM (simultaneouslocalization and mapping). We perform a comprehensive evaluation of the outputsat the intermediate layers of a CNN as image descriptors, in comparison withstate-of-the-art image descriptors, in terms of their ability to match imagesfor detecting loop closures. The main conclusions of our study include: (a)CNN-based image representations perform comparably to state-of-the-art hand-crafted competitors in environments without significant lighting change, (b)they outperform state-of-the-art competitors when lighting changessignificantly, and (c) they are also significantly faster to extract than thestate-of-the-art hand-crafted features even on a conventional CPU and are twoorders of magnitude faster on an entry-level GPU.
arxiv-10200-290 | Scalable Multilabel Prediction via Randomized Methods | http://arxiv.org/pdf/1502.02710v2.pdf | author:Nikos Karampatziakis, Paul Mineiro category:cs.LG published:2015-02-09 summary:Modeling the dependence between outputs is a fundamental challenge inmultilabel classification. In this work we show that a generic regularizednonlinearity mapping independent predictions to joint predictions is sufficientto achieve state-of-the-art performance on a variety of benchmark problems.Crucially, we compute the joint predictions without ever obtaining anyindependent predictions, while incorporating low-rank and smoothnessregularization. We achieve this by leveraging randomized algorithms for matrixdecomposition and kernel approximation. Furthermore, our techniques areapplicable to the multiclass setting. We apply our method to a variety ofmulticlass and multilabel data sets, obtaining state-of-the-art results.
arxiv-10200-291 | Multi-view Face Detection Using Deep Convolutional Neural Networks | http://arxiv.org/pdf/1502.02766v3.pdf | author:Sachin Sudhakar Farfade, Mohammad Saberian, Li-Jia Li category:cs.CV I.4 published:2015-02-10 summary:In this paper we consider the problem of multi-view face detection. Whilethere has been significant research on this problem, current state-of-the-artapproaches for this task require annotation of facial landmarks, e.g. TSM [25],or annotation of face poses [28, 22]. They also require training dozens ofmodels to fully capture faces in all orientations, e.g. 22 models in HeadHuntermethod [22]. In this paper we propose Deep Dense Face Detector (DDFD), a methodthat does not require pose/landmark annotation and is able to detect faces in awide range of orientations using a single model based on deep convolutionalneural networks. The proposed method has minimal complexity; unlike otherrecent deep learning object detection methods [9], it does not requireadditional components such as segmentation, bounding-box regression, or SVMclassifiers. Furthermore, we analyzed scores of the proposed face detector forfaces in different orientations and found that 1) the proposed method is ableto detect faces from different angles and can handle occlusion to some extent,2) there seems to be a correlation between dis- tribution of positive examplesin the training set and scores of the proposed face detector. The lattersuggests that the proposed methods performance can be further improved by usingbetter sampling strategies and more sophisticated data augmentation techniques.Evaluations on popular face detection benchmark datasets show that oursingle-model face detector algorithm has similar or better performance comparedto the previous methods, which are more complex and require annotations ofeither different poses or facial landmarks.
arxiv-10200-292 | Multi-swarm PSO algorithm for the Quadratic Assignment Problem: a massive parallel implementation on the OpenCL platform | http://arxiv.org/pdf/1504.05158v1.pdf | author:Piotr Szwed, Wojciech Chmiel category:cs.NE published:2015-04-20 summary:This paper presents a multi-swarm PSO algorithm for the Quadratic AssignmentProblem (QAP) implemented on OpenCL platform. Our work was motivated by resultsof time efficiency tests performed for single-swarm algorithm implementationthat showed clearly that the benefits of a parallel execution platform can befully exploited, if the processed population is large. The described algorithmcan be executed in two modes: with independent swarms or with migration. Wediscuss the algorithm construction, as well as we report results of testsperformed on several problem instances from the QAPLIB library. During theexperiments the algorithm was configured to process large populations. Thisallowed us to collect statistical data related to values of goal functionreached by individual particles. We use them to demonstrate on two test casesthat although single particles seem to behave chaotically during theoptimization process, when the whole population is analyzed, the probabilitythat a particle will select a near-optimal solution grows.
arxiv-10200-293 | Restricted Boltzmann Machine for Classification with Hierarchical Correlated Prior | http://arxiv.org/pdf/1406.3407v2.pdf | author:Gang Chen, Sargur H. Srihari category:cs.LG 68T10 I.2.6 published:2014-06-13 summary:Restricted Boltzmann machines (RBM) and its variants have become hot researchtopics recently, and widely applied to many classification problems, such ascharacter recognition and document categorization. Often, classification RBMignores the interclass relationship or prior knowledge of sharing informationamong classes. In this paper, we are interested in RBM with the hierarchicalprior over classes. We assume parameters for nearby nodes are correlated in thehierarchical tree, and further the parameters at each node of the tree beorthogonal to those at its ancestors. We propose a hierarchical correlated RBMfor classification problem, which generalizes the classification RBM withsharing information among different classes. In order to reduce the redundancybetween node parameters in the hierarchy, we also introduce orthogonalrestrictions to our objective function. We test our method on challengedatasets, and show promising results compared to competitive baselines.
arxiv-10200-294 | Network Plasticity as Bayesian Inference | http://arxiv.org/pdf/1504.05143v1.pdf | author:David Kappel, Stefan Habenschuss, Robert Legenstein, Wolfgang Maass category:cs.NE q-bio.NC published:2015-04-20 summary:General results from statistical learning theory suggest to understand notonly brain computations, but also brain plasticity as probabilistic inference.But a model for that has been missing. We propose that inherently stochasticfeatures of synaptic plasticity and spine motility enable cortical networks ofneurons to carry out probabilistic inference by sampling from a posteriordistribution of network configurations. This model provides a viablealternative to existing models that propose convergence of parameters tomaximum likelihood values. It explains how priors on weight distributions andconnection probabilities can be merged optimally with learned experience, howcortical networks can generalize learned information so well to novelexperiences, and how they can compensate continuously for unforeseendisturbances of the network. The resulting new theory of network plasticityexplains from a functional perspective a number of experimental data onstochastic aspects of synaptic plasticity that previously appeared to be quitepuzzling.
arxiv-10200-295 | Optimal Nudging: Solving Average-Reward Semi-Markov Decision Processes as a Minimal Sequence of Cumulative Tasks | http://arxiv.org/pdf/1504.05122v1.pdf | author:Reinaldo Uribe Muriel, Fernando Lozando, Charles Anderson category:cs.LG cs.AI published:2015-04-20 summary:This paper describes a novel method to solve average-reward semi-Markovdecision processes, by reducing them to a minimal sequence of cumulative rewardproblems. The usual solution methods for this type of problems update the gain(optimal average reward) immediately after observing the result of taking anaction. The alternative introduced, optimal nudging, relies instead on settingthe gain to some fixed value, which transitorily makes the problem acumulative-reward task, solving it by any standard reinforcement learningmethod, and only then updating the gain in a way that minimizes uncertainty ina minmax sense. The rule for optimal gain update is derived by exploiting thegeometric features of the w-l space, a simple mapping of the space of policies.The total number of cumulative reward tasks that need to be solved is shown tobe small. Some experiments are presented to explore the features of thealgorithm and to compare its performance with other approaches.
arxiv-10200-296 | Hybrid Genetic Algorithm and Lasso Test Approach for Inferring Well Supported Phylogenetic Trees based on Subsets of Chloroplastic Core Genes | http://arxiv.org/pdf/1504.05095v1.pdf | author:Bassam AlKindy, Christophe Guyeux, Jean-François Couchot, Michel Salomon, Christian Parisod, Jacques M. Bahi category:cs.AI cs.NE q-bio.PE q-bio.QM published:2015-04-20 summary:The amount of completely sequenced chloroplast genomes increases rapidlyevery day, leading to the possibility to build large scale phylogenetic treesof plant species. Considering a subset of close plant species defined accordingto their chloroplasts, the phylogenetic tree that can be inferred by their coregenes is not necessarily well supported, due to the possible occurrence of"problematic" genes (i.e., homoplasy, incomplete lineage sorting, horizontalgene transfers, etc.) which may blur phylogenetic signal. However, atrustworthy phylogenetic tree can still be obtained if the number ofproblematic genes is low, the problem being to determine the largest subset ofcore genes that produces the best supported tree. To discard problematic genesand due to the overwhelming number of possible combinations, we propose anhybrid approach that embeds both genetic algorithms and statistical tests.Given a set of organisms, the result is a pipeline of many stages for theproduction of well supported phylogenetic trees. The proposal has been appliedto different cases of plant families, leading to encouraging results for thesefamilies.
arxiv-10200-297 | Nonparametric Nearest Neighbor Random Process Clustering | http://arxiv.org/pdf/1504.05059v1.pdf | author:Michael Tschannen, Helmut Bölcskei category:stat.ML cs.IT cs.LG math.IT published:2015-04-20 summary:We consider the problem of clustering noisy finite-length observations ofstationary ergodic random processes according to their nonparametric generativemodels without prior knowledge of the model statistics and the number ofgenerative models. Two algorithms, both using the L1-distance between estimatedpower spectral densities (PSDs) as a measure of dissimilarity, are analyzed.The first algorithm, termed nearest neighbor process clustering (NNPC), to thebest of our knowledge, is new and relies on partitioning the nearest neighborgraph of the observations via spectral clustering. The second algorithm, simplyreferred to as k-means (KM), consists of a single k-means iteration withfarthest point initialization and was considered before in the literature,albeit with a different measure of dissimilarity and with asymptoticperformance results only. We show that both NNPC and KM succeed with highprobability under noise and even when the generative process PSDs overlapsignificantly, all provided that the observation length is sufficiently large.Our results quantify the tradeoff between the overlap of the generative processPSDs, the noise variance, and the observation length. Finally, we presentnumerical performance results for synthetic and real data.
arxiv-10200-298 | F-SVM: Combination of Feature Transformation and SVM Learning via Convex Relaxation | http://arxiv.org/pdf/1504.05035v1.pdf | author:Xiaohe Wu, Wangmeng Zuo, Yuanyuan Zhu, Liang Lin category:cs.LG cs.CV published:2015-04-20 summary:The generalization error bound of support vector machine (SVM) depends on theratio of radius and margin, while standard SVM only considers the maximizationof the margin but ignores the minimization of the radius. Several approacheshave been proposed to integrate radius and margin for joint learning of featuretransformation and SVM classifier. However, most of them either require theform of the transformation matrix to be diagonal, or are non-convex andcomputationally expensive. In this paper, we suggest a novel approximation forthe radius of minimum enclosing ball (MEB) in feature space, and then propose aconvex radius-margin based SVM model for joint learning of featuretransformation and SVM classifier, i.e., F-SVM. An alternating minimizationmethod is adopted to solve the F-SVM model, where the feature transformation isupdatedvia gradient descent and the classifier is updated by employing theexisting SVM solver. By incorporating with kernel principal component analysis,F-SVM is further extended for joint learning of nonlinear transformation andclassifier. Experimental results on the UCI machine learning datasets and theLFW face datasets show that F-SVM outperforms the standard SVM and the existingradius-margin based SVMs, e.g., RMM, R-SVM+ and R-SVM+{\mu}.
arxiv-10200-299 | Weakly Supervised Multi-Embeddings Learning of Acoustic Models | http://arxiv.org/pdf/1412.6645v3.pdf | author:Gabriel Synnaeve, Emmanuel Dupoux category:cs.SD cs.CL cs.LG published:2014-12-20 summary:We trained a Siamese network with multi-task same/different information on aspeech dataset, and found that it was possible to share a network for bothtasks without a loss in performance. The first task was to discriminate betweentwo same or different words, and the second was to discriminate between twosame or different talkers.
arxiv-10200-300 | Multi-Level Anomaly Detection on Time-Varying Graph Data | http://arxiv.org/pdf/1410.4355v4.pdf | author:Robert A. Bridges, John Collins, Erik M. Ferragut, Jason Laska, Blair D. Sullivan category:cs.SI cs.LG stat.ML published:2014-10-16 summary:This work presents a novel modeling and analysis framework for graphsequences which addresses the challenge of detecting and contextualizinganomalies in labelled, streaming graph data. We introduce a generalization ofthe BTER model of Seshadhri et al. by adding flexibility to communitystructure, and use this model to perform multi-scale graph anomaly detection.Specifically, probability models describing coarse subgraphs are built byaggregating probabilities at finer levels, and these closely relatedhierarchical models simultaneously detect deviations from expectation. Thistechnique provides insight into a graph's structure and internal context thatmay shed light on a detected event. Additionally, this multi-scale analysisfacilitates intuitive visualizations by allowing users to narrow focus from ananomalous graph to particular subgraphs or nodes causing the anomaly. For evaluation, two hierarchical anomaly detectors are tested against abaseline Gaussian method on a series of sampled graphs. We demonstrate that ourgraph statistics-based approach outperforms both a distribution-based detectorand the baseline in a labeled setting with community structure, and itaccurately detects anomalies in synthetic and real-world datasets at the node,subgraph, and graph levels. To illustrate the accessibility of information madepossible via this technique, the anomaly detector and an associated interactivevisualization tool are tested on NCAA football data, where teams andconferences that moved within the league are identified with perfect recall,and precision greater than 0.786.
