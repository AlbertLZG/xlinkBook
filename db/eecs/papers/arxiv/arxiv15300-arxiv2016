arxiv-15300-1 | Convexified Modularity Maximization for Degree-corrected Stochastic Block Models | http://arxiv.org/pdf/1512.08425v2.pdf | author:Yudong Chen, Xiaodong Li, Jiaming Xu category:math.ST cs.LG cs.SI stat.ML stat.TH published:2015-12-28 summary:The stochastic block model (SBM) is a popular framework for studyingcommunity detection in networks. This model is limited by the assumption thatall nodes in the same community are statistically equivalent and have equalexpected degrees. The degree-corrected stochastic block model (DCSBM) is anatural extension of SBM that allows for degree heterogeneity withincommunities. This paper proposes a convexified modularity maximization approachfor estimating the hidden communities under DCSBM. Our approach is based on aconvex programming relaxation of the classical (generalized) modularitymaximization formulation, followed by a novel doubly-weighted $ \ell_1 $-norm $k $-median procedure. We establish non-asymptotic theoretical guarantees forboth approximate clustering and perfect clustering. Our approximate clusteringresults are insensitive to the minimum degree, and hold even in sparse regimewith bounded average degrees. In the special case of SBM, these theoreticalresults match the best-known performance guarantees of computationally feasiblealgorithms. Numerically, we provide an efficient implementation of ouralgorithm, which is applied to both synthetic and real-world networks.Experiment results show that our method enjoys competitive performance comparedto the state of the art in the literature.
arxiv-15300-2 | A Simple Baseline for Travel Time Estimation using Large-Scale Trip Data | http://arxiv.org/pdf/1512.08580v1.pdf | author:Hongjian Wang, Zhenhui Li, Yu-Hsuan Kuo, Dan Kifer category:cs.LG cs.CY H.2.8; I.2.6 published:2015-12-28 summary:The increased availability of large-scale trajectory data around the worldprovides rich information for the study of urban dynamics. For example, NewYork City Taxi Limousine Commission regularly releases source-destinationinformation about trips in the taxis they regulate. Taxi data provideinformation about traffic patterns, and thus enable the study of urban flow --what will traffic between two locations look like at a certain date and time inthe future? Existing big data methods try to outdo each other in terms ofcomplexity and algorithmic sophistication. In the spirit of "big data beatsalgorithms", we present a very simple baseline which outperformsstate-of-the-art approaches, including Bing Maps and Baidu Maps (whose APIspermit large scale experimentation). Such a travel time estimation baseline hasseveral important uses, such as navigation (fast travel time estimates canserve as approximate heuristics for A search variants for path finding) andtrip planning (which uses operating hours for popular destinations along withtravel time estimates to create an itinerary).
arxiv-15300-3 | Natural Language Inference by Tree-Based Convolution and Heuristic Matching | http://arxiv.org/pdf/1512.08422v3.pdf | author:Lili Mou, Rui Men, Ge Li, Yan Xu, Lu Zhang, Rui Yan, Zhi Jin category:cs.CL cs.LG published:2015-12-28 summary:In this paper, we propose the TBCNN-pair model to recognize entailment andcontradiction between two sentences. In our model, a tree-based convolutionalneural network (TBCNN) captures sentence-level semantics; then heuristicmatching layers like concatenation, element-wise product/difference combine theinformation in individual sentences. Experimental results show that our modeloutperforms existing sentence encoding-based approaches by a large margin.
arxiv-15300-4 | MRF-based multispectral image fusion using an adaptive approach based on edge-guided interpolation | http://arxiv.org/pdf/1512.08475v1.pdf | author:Mohammad Reza Khosravi, Suleiman Mansouri, Ahmad Keshavarz, Habib Rostami category:cs.CV published:2015-12-28 summary:In interpretation of remote sensing images, it is possible that the imageswhich are supplied by different sensors wouldn't be understandable or we couldnot get vital information from them. For better visual perception of images, itis essential to operate series of pre-processing and elementary corrections andthen operate a series of main processing for more precise analysis on theimage. There are several approaches for processing which depend on type ofremote sensing image. The discussed approach in this article, i.e. imagefusion, is using natural colors of an optical image for adding color togray-scale satellite image which gives us the ability to better observe the HRimage of the OLI sensor of Landsat. This process previously with emphasis ondetails of fusion technique was performed, but we are going to relieve conceptof interpolation process that did not have suitable attentions in past. In factwe see many important software tools such as ENVI and ERDAS as most famousremote sensing image processing software tools have only classicalinterpolation techniques (such as BL and CC). Therefore ENVI-based andERDAS-based researches in image fusion area and even other fusion researchesoften do not use new and better interpolations and only are concentrating onfusion details for achievement of better quality, so we only focus oninterpolation impact in fusion quality in a specific application, i.e. Landsatmulti-spectral images. The important feature of this approach is using astatistical, adaptive, edge-guided and MRF-based interpolation method forimproving color quality in MRF-based images with maintenance of high resolutionin practice. Numerical Simulations show selection of suitable interpolationtechnique in MRF-based images creates better quality rather than classicalinterpolations.
arxiv-15300-5 | Visually Indicated Sounds | http://arxiv.org/pdf/1512.08512v2.pdf | author:Andrew Owens, Phillip Isola, Josh McDermott, Antonio Torralba, Edward H. Adelson, William T. Freeman category:cs.CV cs.LG cs.SD published:2015-12-28 summary:Objects make distinctive sounds when they are hit or scratched. These soundsreveal aspects of an object's material properties, as well as the actions thatproduced them. In this paper, we propose the task of predicting what sound anobject makes when struck as a way of studying physical interactions within avisual scene. We present an algorithm that synthesizes sound from silent videosof people hitting and scratching objects with a drumstick. This algorithm usesa recurrent neural network to predict sound features from videos and thenproduces a waveform from these features with an example-based synthesisprocedure. We show that the sounds predicted by our model are realistic enoughto fool participants in a "real or fake" psychophysical experiment, and thatthey convey significant information about material properties and physicalinteractions.
arxiv-15300-6 | Approximate Hubel-Wiesel Modules and the Data Structures of Neural Computation | http://arxiv.org/pdf/1512.08457v1.pdf | author:Joel Z. Leibo, Julien Cornebise, Sergio GÃ³mez, Demis Hassabis category:cs.NE q-bio.NC published:2015-12-28 summary:This paper describes a framework for modeling the interface betweenperception and memory on the algorithmic level of analysis. It is consistentwith phenomena associated with many different brain regions. These includeview-dependence (and invariance) effects in visual psychophysics andinferotemporal cortex physiology, as well as episodic memory recallinterference effects associated with the medial temporal lobe. The perspectivedeveloped here relies on a novel interpretation of Hubel and Wiesel'sconjecture for how receptive fields tuned to complex objects, and invariant todetails, could be achieved. It complements existing accounts of two-speedlearning systems in neocortex and hippocampus (e.g., McClelland et al. 1995)while significantly expanding their scope to encompass a unified view of theentire pathway from V1 to hippocampus.
arxiv-15300-7 | Robust Semi-supervised Least Squares Classification by Implicit Constraints | http://arxiv.org/pdf/1512.08240v1.pdf | author:Jesse H. Krijthe, Marco Loog category:stat.ML cs.LG published:2015-12-27 summary:We introduce the implicitly constrained least squares (ICLS) classifier, anovel semi-supervised version of the least squares classifier. This classifierminimizes the squared loss on the labeled data among the set of parametersimplied by all possible labelings of the unlabeled data. Unlike otherdiscriminative semi-supervised methods, this approach does not introduceexplicit additional assumptions into the objective function, but leveragesimplicit assumptions already present in the choice of the supervised leastsquares classifier. This method can be formulated as a quadratic programmingproblem and its solution can be found using a simple gradient descentprocedure. We prove that, in a limited 1-dimensional setting, this approachnever leads to performance worse than the supervised classifier. Experimentalresults show that also in the general multidimensional case performanceimprovements can be expected, both in terms of the squared loss that isintrinsic to the classifier, as well as in terms of the expected classificationerror.
arxiv-15300-8 | Improving Facial Analysis and Performance Driven Animation through Disentangling Identity and Expression | http://arxiv.org/pdf/1512.08212v1.pdf | author:David Rim, Sina Honari, Md Kamrul Hasan, Chris Pal category:cs.CV published:2015-12-27 summary:We present techniques for improving performance driven facial animation,emotion recognition, and facial key-point or landmark prediction techniquesusing learned identity invariant representations. Established approaches tothese problems can work well if sufficient examples and labels for a particularidentity are available and factors of variation are highly controlled. However,labeled examples of facial expressions, emotions and key-points for newindividuals are difficult and costly to obtain. In this paper we improve theability of techniques to generalize to new and unseen individuals by explicitlymodeling previously seen variations related to identity and expression. We usea weakly-supervised approach in which identity labels are used to learn thedifferent factors of variation linked to identity separately from factorsrelated to expression. We show how probabilistic modeling of these sources ofvariation allows one to learn identity-invariant representations forexpressions which can then used to identity-normalize various procedures forfacial expression analysis and animation control. We also show how to extendthe widely used techniques of active appearance models and constrained localmodels through replacing the underlying point distribution models which aretypically constructed using principal component analysis withidentity-expression factorized representations. We present a wide variety ofexperiments in which we consistently improve performance on emotionrecognition, markerless performance-driven facial animation and facialkey-point tracking.
arxiv-15300-9 | New Perspectives on $k$-Support and Cluster Norms | http://arxiv.org/pdf/1512.08204v1.pdf | author:Andrew M. McDonald, Massimiliano Pontil, Dimitris Stamos category:cs.LG stat.ML published:2015-12-27 summary:We study a regularizer which is defined as a parameterized infimum ofquadratics, and which we call the box-norm. We show that the k-support norm, aregularizer proposed by [Argyriou et al, 2012] for sparse vector predictionproblems, belongs to this family, and the box-norm can be generated as aperturbation of the former. We derive an improved algorithm to compute theproximity operator of the squared box-norm, and we provide a method to computethe norm. We extend the norms to matrices, introducing the spectral k-supportnorm and spectral box-norm. We note that the spectral box-norm is essentiallyequivalent to the cluster norm, a multitask learning regularizer introduced by[Jacob et al. 2009a], and which in turn can be interpreted as a perturbation ofthe spectral k-support norm. Centering the norm is important for multitasklearning and we also provide a method to use centered versions of the norms asregularizers. Numerical experiments indicate that the spectral k-support andbox-norms and their centered variants provide state of the art performance inmatrix completion and multitask learning problems respectively.
arxiv-15300-10 | Electricity Demand Forecasting by Multi-Task Learning | http://arxiv.org/pdf/1512.08178v1.pdf | author:Jean-Baptiste Fiot, Francesco Dinuzzo category:cs.LG published:2015-12-27 summary:We explore the application of kernel-based multi-task learning techniques toforecast the demand of electricity in multiple nodes of a distribution network.We show that recently developed output kernel learning techniques areparticularly well suited to solve this problem, as they allow to flexibly modelthe complex seasonal effects that characterize electricity demand data, whilelearning and exploiting correlations between multiple demand profiles. We alsodemonstrate that kernels with a multiplicative structure yield superiorpredictive performance with respect to the widely adopted (generalized)additive models. Our study is based on residential and industrial smart meterdata provided by the Irish Commission for Energy Regulation (CER).
arxiv-15300-11 | Self-Excitation: An Enabler for Online Thermal Estimation and Model Predictive Control of Buildings | http://arxiv.org/pdf/1512.08169v1.pdf | author:Peter Radecki, Brandon Hencey category:cs.SY cs.LG published:2015-12-27 summary:This paper investigates a method to improve buildings' thermal predictivecontrol performance via online identification and excitation (active learningprocess) that minimally disrupts normal operations. In previous studies we havedemonstrated scalable methods to acquire multi-zone thermal models of passivebuildings using a gray-box approach that leverages building topology andmeasurement data. Here we extend the method to multi-zone actively controlledbuildings and examine how to improve the thermal model estimation by using thecontroller to excite unknown portions of the building's dynamics. Comparingagainst a baseline thermostat controller, we demonstrate the utility of boththe initially acquired and improved thermal models within a Model PredictiveControl (MPC) framework, which anticipates weather uncertainty and time-varyingtemperature set-points. A simulation study demonstrates self-excitationimproves model estimation, which corresponds to improved MPC energy savings andoccupant comfort. By coupling building topology, estimation, and controlroutines into a single online framework, we have demonstrated the potential forlow-cost scalable methods to actively learn and control buildings to ensureoccupant comfort and minimize energy usage, all while using the existingbuilding's HVAC sensors and hardware.
arxiv-15300-12 | Learning Document Embeddings by Predicting N-grams for Sentiment Classification of Long Movie Reviews | http://arxiv.org/pdf/1512.08183v5.pdf | author:Bofang Li, Tao Liu, Xiaoyong Du, Deyuan Zhang, Zhe Zhao category:cs.CL published:2015-12-27 summary:Despite the loss of semantic information, bag-of-ngram based methods stillachieve state-of-the-art results for tasks such as sentiment classification oflong movie reviews. Many document embeddings methods have been proposed tocapture semantics, but they still can't outperform bag-of-ngram based methodson this task. In this paper, we modify the architecture of the recentlyproposed Paragraph Vector, allowing it to learn document vectors by predictingnot only words, but n-gram features as well. Our model is able to capture bothsemantics and word order in documents while keeping the expressive power oflearned vectors. Experimental results on IMDB movie review dataset shows thatour model outperforms previous deep learning models and bag-of-ngram basedmodels due to the above advantages. More robust results are also obtained whenour model is combined with other models. The source code of our model will bealso published together with this paper.
arxiv-15300-13 | Statistical and Computational Guarantees for the Baum-Welch Algorithm | http://arxiv.org/pdf/1512.08269v1.pdf | author:Fanny Yang, Sivaraman Balakrishnan, Martin J. Wainwright category:stat.ML cs.IT math.IT math.ST stat.TH published:2015-12-27 summary:The Hidden Markov Model (HMM) is one of the mainstays of statistical modelingof discrete time series, with applications including speech recognition,computational biology, computer vision and econometrics. Estimating an HMM fromits observation process is often addressed via the Baum-Welch algorithm, whichis known to be susceptible to local optima. In this paper, we first give ageneral characterization of the basin of attraction associated with any globaloptimum of the population likelihood. By exploiting this characterization, weprovide non-asymptotic finite sample guarantees on the Baum-Welch updates,guaranteeing geometric convergence to a small ball of radius on the order ofthe minimax rate around a global optimum. As a concrete example, we prove alinear rate of convergence for a hidden Markov mixture of two isotropicGaussians given a suitable mean separation and an initialization within a ballof large radius around (one of) the true parameters. To our knowledge, theseare the first rigorous local convergence guarantees to global optima for theBaum-Welch algorithm in a setting where the likelihood function is nonconvex.We complement our theoretical results with thorough numerical simulationsstudying the convergence of the Baum-Welch algorithm and illustrating theaccuracy of our predictions.
arxiv-15300-14 | Online Model Estimation for Predictive Thermal Control of Buildings | http://arxiv.org/pdf/1601.02947v1.pdf | author:Peter Radecki, Brandon Hencey category:cs.SY cs.LG published:2015-12-27 summary:This study proposes a general, scalable method to learn control-orientedthermal models of buildings that could enable wide-scale deployment ofcost-effective predictive controls. An Unscented Kalman Filter augmented forparameter and disturbance estimation is shown to accurately learn and predict abuilding's thermal response. Recent studies of heating, ventilating, and airconditioning (HVAC) systems have shown significant energy savings with advancedmodel predictive control (MPC). A scalable cost-effective method to readilyacquire accurate, robust models of individual buildings' unique thermalenvelopes has historically been elusive and hindered the widespread deploymentof prediction-based control systems. Continuous commissioning and lifetimeperformance of these thermal models requires deployment of on-line data-drivensystem identification and parameter estimation routines. We propose a novelgray-box approach using an Unscented Kalman Filter based on a multi-zonethermal network and validate it with EnergyPlus simulation data. The filterquickly learns parameters of a thermal network during periods of known orconstrained loads and then characterizes unknown loads in order to provideaccurate 24+ hour energy predictions. This study extends our initialinvestigation by formalizing parameter and disturbance estimation routines anddemonstrating results across a year-long study.
arxiv-15300-15 | Using Causal Discovery to Track Information Flow in Spatio-Temporal Data - A Testbed and Experimental Results Using Advection-Diffusion Simulations | http://arxiv.org/pdf/1512.08279v1.pdf | author:Imme Ebert-Uphoff, Yi Deng category:cs.LG published:2015-12-27 summary:Causal discovery algorithms based on probabilistic graphical models haveemerged in geoscience applications for the identification and visualization ofdynamical processes. The key idea is to learn the structure of a graphicalmodel from observed spatio-temporal data, which indicates information flow,thus pathways of interactions, in the observed physical system. Studying thosepathways allows geoscientists to learn subtle details about the underlyingdynamical mechanisms governing our planet. Initial studies using this approachon real-world atmospheric data have shown great potential for scientificdiscovery. However, in these initial studies no ground truth was available, sothat the resulting graphs have been evaluated only by whether a domain expertthinks they seemed physically plausible. This paper seeks to fill this gap. Wedevelop a testbed that emulates two dynamical processes dominant in manygeoscience applications, namely advection and diffusion, in a 2D grid. Then weapply the causal discovery based information tracking algorithms to thesimulation data to study how well the algorithms work for different scenariosand to gain a better understanding of the physical meaning of the graphresults, in particular of instantaneous connections. We make all data sets usedin this study available to the community as a benchmark. Keywords: Information flow, graphical model, structure learning, causaldiscovery, geoscience.
arxiv-15300-16 | Inverse Reinforcement Learning via Deep Gaussian Process | http://arxiv.org/pdf/1512.08065v1.pdf | author:Ming Jin, Costas Spanos category:cs.LG cs.RO stat.ML published:2015-12-26 summary:The report proposes a new approach for inverse reinforcement learning basedon deep Gaussian process (GP), which is capable of learning complicated rewardstructures with few demonstrations. The model stacks multiple latent GP layersto learn abstract representations of the state feature space, which is linkedto the demonstrations through the Maximum Entropy learning framework. Asanalytic derivation of the model evidence is prohibitive due to thenonlinearity of latent variables, variational inference is employed forapproximate inference, based on a special choice of variational distributions.This guards the model from over training, achieving the Automatic Occam'sRazor. Experiments on the benchmark test, i.e., object world, as well as a newsetup, i.e., binary world, are performed, where the proposed method outperformsstate-of-the-art approaches.
arxiv-15300-17 | Statistical Learning under Nonstationary Mixing Processes | http://arxiv.org/pdf/1512.08064v1.pdf | author:Steve Hanneke, Tommi Jaakkola, Liu Yang category:cs.LG stat.ML published:2015-12-26 summary:We study a special case of the problem of statistical learning without thei.i.d. assumption. Specifically, we suppose a learning method is presented witha sequence of data points, and required to make a prediction (e.g., aclassification) for each one, and can then observe the loss incurred by thisprediction. We go beyond traditional analyses, which have focused on stationarymixing processes or nonstationary product processes, by combining these tworelaxations to allow nonstationary mixing processes. We are particularlyinterested in the case of $\beta$-mixing processes, with the sum of changes inmarginal distributions growing sublinearly in the number of samples. Underthese conditions, we propose a learning method, and establish that for boundedVC subgraph classes, the cumulative excess risk grows sublinearly in the numberof predictions, at a quantified rate.
arxiv-15300-18 | The Utility of Abstaining in Binary Classification | http://arxiv.org/pdf/1512.08133v1.pdf | author:Akshay Balsubramani category:cs.LG published:2015-12-26 summary:We explore the problem of binary classification in machine learning, with atwist - the classifier is allowed to abstain on any datum, professing ignoranceabout the true class label without committing to any prediction. This isdirectly motivated by applications like medical diagnosis and fraud riskassessment, in which incorrect predictions have potentially calamitousconsequences. We focus on a recent spate of theoretically driven work in thisarea that characterizes how allowing abstentions can lead to fewer errors invery general settings. Two areas are highlighted: the surprising possibility ofzero-error learning, and the fundamental tradeoff between predictingsufficiently often and avoiding incorrect predictions. We review efficientalgorithms with provable guarantees for each of these areas. We also discussconnections to other scenarios, notably active learning, as they suggestpromising directions of further inquiry in this emerging field.
arxiv-15300-19 | Data Driven Robust Image Guided Depth Map Restoration | http://arxiv.org/pdf/1512.08103v1.pdf | author:Wei Liu, Yun Gu, Chunhua Shen, Xiaogang Chen, Qiang Wu, Jie Yang category:cs.CV published:2015-12-26 summary:Depth maps captured by modern depth cameras such as Kinect and Time-of-Flight(ToF) are usually contaminated by missing data, noises and suffer from being oflow resolution. In this paper, we present a robust method for high-qualityrestoration of a degraded depth map with the guidance of the correspondingcolor image. We solve the problem in an energy optimization framework thatconsists of a novel robust data term and smoothness term. To accommodate notonly the noise but also the inconsistency between depth discontinuities and thecolor edges, we model both the data term and smoothness term with a robustexponential error norm function. We propose to use Iteratively Re-weightedLeast Squares (IRLS) methods for efficiently solving the resulting highlynon-convex optimization problem. More importantly, we further develop adata-driven adaptive parameter selection scheme to properly determine theparameter in the model. We show that the proposed approach can preserve finedetails and sharp depth discontinuities even for a large upsampling factor($8\times$ for example). Experimental results on both simulated and realdatasets demonstrate that the proposed method outperforms recentstate-of-the-art methods in coping with the heavy noise, preserving sharp depthdiscontinuities and suppressing the texture copy artifacts.
arxiv-15300-20 | Part-Stacked CNN for Fine-Grained Visual Categorization | http://arxiv.org/pdf/1512.08086v1.pdf | author:Shaoli Huang, Zhe Xu, Dacheng Tao, Ya Zhang category:cs.CV published:2015-12-26 summary:In the context of fine-grained visual categorization, the ability tointerpret models as human-understandable visual manuals is sometimes asimportant as achieving high classification accuracy. In this paper, we proposea novel Part-Stacked CNN architecture that explicitly explains the fine-grainedrecognition process by modeling subtle differences from object parts. Based onmanually-labeled strong part annotations, the proposed architecture consists ofa fully convolutional network to locate multiple object parts and a two-streamclassification network that en- codes object-level and part-level cuessimultaneously. By adopting a set of sharing strategies between the computationof multiple object parts, the proposed architecture is very efficient runningat 20 frames/sec during inference. Experimental results on the CUB-200-2011dataset reveal the effectiveness of the proposed architecture, from both theperspective of classification accuracy and model interpretability.
arxiv-15300-21 | The Improvement of Negative Sentences Translation in English-to-Korean Machine Translation | http://arxiv.org/pdf/1512.08066v1.pdf | author:Chung-Hyok Jang, Kwang-Hyok Kim category:cs.CL published:2015-12-26 summary:This paper describes the algorithm for translating English negative sentencesinto Korean in English-Korean Machine Translation (EKMT). The proposedalgorithm is based on the comparative study of English and Korean negativesentences. The earlier translation software cannot translate English negativesentences into accurate Korean equivalents. We established a new algorithm forthe negative sentence translation and evaluated it.
arxiv-15300-22 | Regularized Orthogonal Tensor Decompositions for Multi-Relational Learning | http://arxiv.org/pdf/1512.08120v2.pdf | author:Fanhua Shang, James Cheng, Hong Cheng category:cs.LG cs.AI published:2015-12-26 summary:Multi-relational learning has received lots of attention from researchers invarious research communities. Most existing methods either suffer fromsuperlinear per-iteration cost, or are sensitive to the given ranks. To addressboth issues, we propose a scalable core tensor trace norm RegularizedOrthogonal Iteration Decomposition (ROID) method for full or incomplete tensoranalytics, which can be generalized as a graph Laplacian regularized version byusing auxiliary information or a sparse higher-order orthogonal iteration(SHOOI) version. We first induce the equivalence relation of the Schattenp-norm (0<p<\infty) of a low multi-linear rank tensor and its core tensor. Thenwe achieve a much smaller matrix trace norm minimization problem. Finally, wedevelop two efficient augmented Lagrange multiplier algorithms to solve ourproblems with convergence guarantees. Extensive experiments using both real andsynthetic datasets, even though with only a few observations, verified both theefficiency and effectiveness of our methods.
arxiv-15300-23 | Bridging the Gap between Stochastic Gradient MCMC and Stochastic Optimization | http://arxiv.org/pdf/1512.07962v2.pdf | author:Changyou Chen, David Carlson, Zhe Gan, Chunyuan Li, Lawrence Carin category:stat.ML cs.LG published:2015-12-25 summary:Stochastic gradient Markov chain Monte Carlo (SG-MCMC) methods are Bayesiananalogs to popular stochastic optimization methods; however, this connection isnot well studied. We explore this relationship by applying simulated annealingto an SGMCMC algorithm. Furthermore, we extend recent SG-MCMC methods with twokey components: i) adaptive preconditioners (as in ADAgrad or RMSprop), and ii)adaptive element-wise momentum weights. The zero-temperature limit gives anovel stochastic optimization method with adaptive element-wise momentumweights, while conventional optimization methods only have a shared, staticmomentum weight. Under certain assumptions, our theoretical analysis suggeststhe proposed simulated annealing approach converges close to the global optima.Experiments on several deep neural network models show state-of-the-art resultscompared to related stochastic optimization algorithms.
arxiv-15300-24 | Texture measures combination for improved meningioma classification of histopathological images | http://arxiv.org/pdf/1512.08049v1.pdf | author:Omar S. Al-Kadi category:cs.CV published:2015-12-25 summary:Providing an improved technique which can assist pathologists in correctlyclassifying meningioma tumours with a significant accuracy is our mainobjective. The proposed technique, which is based on optimum texture measurecombination, inspects the separability of the RGB colour channels and selectsthe channel which best segments the cell nuclei of the histopathologicalimages. The morphological gradient was applied to extract the region ofinterest for each subtype and for elimination of possible noise (e.g. cracks)which might occur during biopsy preparation. Meningioma texture features areextracted by four different texture measures (two model-based and twostatistical-based) and then corresponding features are fused together indifferent combinations after excluding highly correlated features, and aBayesian classifier was used for meningioma subtype discrimination. Thecombined Gaussian Markov random field and run-length matrix texture measuresoutperformed all other combinations in terms of quantitatively characterisingthe meningioma tissue, achieving an overall classification accuracy of 92.50%,improving from 83.75% which is the best accuracy achieved if the texturemeasures are used individually.
arxiv-15300-25 | Inducing Generalized Multi-Label Rules with Learning Classifier Systems | http://arxiv.org/pdf/1512.07982v1.pdf | author:Fani A. Tzima, Miltiadis Allamanis, Alexandros Filotheou, Pericles A. Mitkas category:cs.NE cs.LG published:2015-12-25 summary:In recent years, multi-label classification has attracted a significant bodyof research, motivated by real-life applications, such as text classificationand medical diagnoses. Although sparsely studied in this context, LearningClassifier Systems are naturally well-suited to multi-label classificationproblems, whose search space typically involves multiple highly specificniches. This is the motivation behind our current work that introduces ageneralized multi-label rule format -- allowing for flexible label-dependencymodeling, with no need for explicit knowledge of which correlations to searchfor -- and uses it as a guide for further adapting the general Michigan-stylesupervised Learning Classifier System framework. The integration of theaforementioned rule format and framework adaptations results in a novelalgorithm for multi-label classification whose behavior is studied through aset of properly defined artificial problems. The proposed algorithm is alsothoroughly evaluated on a set of multi-label datasets and found competitive toother state-of-the-art multi-label classification methods.
arxiv-15300-26 | Device and System Level Design Considerations for Analog-Non-Volatile-Memory Based Neuromorphic Architectures | http://arxiv.org/pdf/1512.08030v2.pdf | author:Sukru Burc Eryilmaz, Duygu Kuzum, Shimeng Yu, H. -S. Philip Wong category:cs.NE cs.AI published:2015-12-25 summary:This paper gives an overview of recent progress in the brain inspiredcomputing field with a focus on implementation using emerging memories aselectronic synapses. Design considerations and challenges such as requirementsand design targets on multilevel states, device variability, programmingenergy, array-level connectivity, fan-in/fanout, wire energy, and IR drop arepresented. Wires are increasingly important in design decisions, especially forlarge systems, and cycle-to-cycle variations have large impact on learningperformance.
arxiv-15300-27 | A Multiresolution Clinical Decision Support System Based on Fractal Model Design for Classification of Histological Brain Tumours | http://arxiv.org/pdf/1512.08051v1.pdf | author:Omar S. Al-Kadi category:cs.CV published:2015-12-25 summary:Tissue texture is known to exhibit a heterogeneous or non-stationary nature,therefore using a single resolution approach for optimum classification mightnot suffice. A clinical decision support system that exploits the subbandtextural fractal characteristics for best bases selection of meningioma brainhistopathological image classification is proposed. Each subband is analysedusing its fractal dimension instead of energy, which has the advantage of beingless sensitive to image intensity and abrupt changes in tissue texture. Themost significant subband that best identifies texture discontinuities will bechosen for further decomposition, and its fractal characteristics wouldrepresent the optimal feature vector for classification. The performance wastested using the support vector machine (SVM), Bayesian and k-nearest neighbour(kNN) classifiers and a leave-one-patient-out method was employed forvalidation. Our method outperformed the classical energy based selectionapproaches, achieving for SVM, Bayesian and kNN classifiers an overallclassification accuracy of 94.12%, 92.50% and 79.70%, as compared to 86.31%,83.19% and 51.63% for the co-occurrence matrix, and 76.01%, 73.50% and 50.69%for the energy texture signatures, respectively. These results indicate thepotential usefulness as a decision support system that could complementradiologists diagnostic capability to discriminate higher order statisticaltextural information, for which it would be otherwise difficult via ordinaryhuman vision.
arxiv-15300-28 | Micro-Differential Evolution: Diversity Enhancement and Comparative Study | http://arxiv.org/pdf/1512.07980v1.pdf | author:Hojjat Salehinejad, Shahryar Rahnamayan, Hamid R. Tizhoosh category:cs.NE published:2015-12-25 summary:The differential evolution (DE) algorithm suffers from high computationaltime due to slow nature of evaluation. In contrast, micro-DE (MDE) algorithmsemploy a very small population size, which can converge faster to a reasonablesolution. However, these algorithms are vulnerable to a premature convergenceas well as to high risk of stagnation. In this paper, MDE algorithm withvectorized random mutation factor (MDEVM) is proposed, which utilizes the smallsize population benefit while empowers the exploration ability of mutationfactor through randomizing it in the decision variable level. The idea issupported by analyzing mutation factor using Monte-Carlo based simulations. Tofacilitate the usage of MDE algorithms with very-small population sizes, newmutation schemes for population sizes less than four are also proposed.Furthermore, comprehensive comparative simulations and analysis on performanceof the MDE algorithms over various mutation schemes, population sizes, problemtypes (i.e. uni-modal, multi-modal, and composite), problem dimensionalities,and mutation factor ranges are conducted by considering population diversityanalysis for stagnation and trapping in local optimum situations. The studiesare conducted on 28 benchmark functions provided for the IEEE CEC-2013competition. Experimental results demonstrate high performance and convergencespeed of the proposed MDEVM algorithm.
arxiv-15300-29 | Sparse Reconstruction of Compressive Sensing MRI using Cross-Domain Stochastically Fully Connected Conditional Random Fields | http://arxiv.org/pdf/1512.07947v1.pdf | author:Edward Li, Farzad Khalvati, Mohammad Javad Shafiee, Masoom A. Haider, Alexander Wong category:cs.CV physics.med-ph stat.ME published:2015-12-25 summary:Magnetic Resonance Imaging (MRI) is a crucial medical imaging technology forthe screening and diagnosis of frequently occurring cancers. However imagequality may suffer by long acquisition times for MRIs due to patient motion, aswell as result in great patient discomfort. Reducing MRI acquisition time canreduce patient discomfort and as a result reduces motion artifacts from theacquisition process. Compressive sensing strategies, when applied to MRI, havebeen demonstrated to be effective at decreasing acquisition times significantlyby sparsely sampling the \emph{k}-space during the acquisition process.However, such a strategy requires advanced reconstruction algorithms to producehigh quality and reliable images from compressive sensing MRI. This paperproposes a new reconstruction approach based on cross-domain stochasticallyfully connected conditional random fields (CD-SFCRF) for compressive sensingMRI. The CD-SFCRF introduces constraints in both \emph{k}-space and spatialdomains within a stochastically fully connected graphical model to produceimproved MRI reconstruction. Experimental results using T2-weighted (T2w)imaging and diffusion-weighted imaging (DWI) of the prostate show strongperformance in preserving fine details and tissue structures in thereconstructed images when compared to other tested methods even at low samplingrates.
arxiv-15300-30 | Discovering topic structures of a temporally evolving document corpus | http://arxiv.org/pdf/1512.08008v1.pdf | author:Adham Beykikhoshk, Ognjen Arandjelovic, Dinh Phung, Svetha Venkatesh category:cs.IR cs.LG published:2015-12-25 summary:In this paper we describe a novel framework for the discovery of the topicalcontent of a data corpus, and the tracking of its complex structural changesacross the temporal dimension. In contrast to previous work our model does notimpose a prior on the rate at which documents are added to the corpus nor doesit adopt the Markovian assumption which overly restricts the type of changesthat the model can capture. Our key technical contribution is a framework basedon (i) discretization of time into epochs, (ii) epoch-wise topic discoveryusing a hierarchical Dirichlet process-based model, and (iii) a temporalsimilarity graph which allows for the modelling of complex topic changes:emergence and disappearance, evolution, splitting, and merging. The power ofthe proposed framework is demonstrated on two medical literature corporaconcerned with the autism spectrum disorder (ASD) and the metabolic syndrome(MetS) -- both increasingly important research subjects with significant socialand healthcare consequences. In addition to the collected ASD and metabolicsyndrome literature corpora which we made freely available, our contributionalso includes an extensive empirical analysis of the proposed framework. Wedescribe a detailed and careful examination of the effects that ouralgorithms's free parameters have on its output, and discuss the significanceof the findings both in the context of the practical application of ouralgorithm as well as in the context of the existing body of work on temporaltopic analysis. Our quantitative analysis is followed by several qualitativecase studies highly relevant to the current research on ASD and MetS, on whichour algorithm is shown to capture well the actual developments in these fields.
arxiv-15300-31 | Multi-Level Cause-Effect Systems | http://arxiv.org/pdf/1512.07942v1.pdf | author:Krzysztof Chalupka, Pietro Perona, Frederick Eberhardt category:stat.ML cs.AI published:2015-12-25 summary:We present a domain-general account of causation that applies to settings inwhich macro-level causal relations between two systems are of interest, but therelevant causal features are poorly understood and have to be aggregated fromvast arrays of micro-measurements. Our approach generalizes that of Chalupka etal. (2015) to the setting in which the macro-level effect is not specified. Weformalize the connection between micro- and macro-variables in such situationsand provide a coherent framework describing causal relations at multiple levelsof analysis. We present an algorithm that discovers macro-variable causes andeffects from micro-level measurements obtained from an experiment. We furthershow how to design experiments to discover macro-variables from observationalmicro-variable data. Finally, we show that under specific conditions, one canidentify multiple levels of causal structure. Throughout the article, we use asimulated neuroscience multi-unit recording experiment to illustrate the ideasand the algorithms.
arxiv-15300-32 | Histogram Meets Topic Model: Density Estimation by Mixture of Histograms | http://arxiv.org/pdf/1512.07960v1.pdf | author:Hideaki Kim, Hiroshi Sawada category:stat.ML published:2015-12-25 summary:The histogram method is a powerful non-parametric approach for estimating theprobability density function of a continuous variable. But the construction ofa histogram, compared to the parametric approaches, demands a large number ofobservations to capture the underlying density function. Thus it is notsuitable for analyzing a sparse data set, a collection of units with a smallsize of data. In this paper, by employing the probabilistic topic model, wedevelop a novel Bayesian approach to alleviating the sparsity problem in theconventional histogram estimation. Our method estimates a unit's densityfunction as a mixture of basis histograms, in which the number of bins for eachbasis, as well as their heights, is determined automatically. The estimationprocedure is performed by using the fast and easy-to-implement collapsed Gibbssampling. We apply the proposed method to synthetic data, showing that itperforms well.
arxiv-15300-33 | Assessment of texture measures susceptibility to noise in conventional and contrast enhanced computed tomography lung tumour images | http://arxiv.org/pdf/1512.08047v1.pdf | author:Omar Sultan Al-Kadi category:cs.CV published:2015-12-25 summary:Noise is one of the major problems that hinder an effective texture analysisof disease in medical images, which may cause variability in the reporteddiagnosis. In this paper seven texture measurement methods (two wavelet, twomodel and three statistical based) were applied to investigate theirsusceptibility to subtle noise caused by acquisition and reconstructiondeficiencies in computed tomography (CT) images. Features of lung tumours wereextracted from two different conventional and contrast enhanced CT imagedata-sets under filtered and noisy conditions. When measuring the noise in thebackground open-air region of the analysed CT images, noise of Gaussian andRayleigh distributions with varying mean and variance was encountered, andFisher distance was used to differentiate between an original extracted lungtumour region of interest (ROI) with the filtered and noisy reconstructedversions. It was determined that the wavelet packet (WP) and fractal dimensionmeasures were the least affected, while the Gaussian Markov random field,run-length and co-occurrence matrices were the most affected by noise.Depending on the selected ROI size, it was concluded that texture measures withfewer extracted features can decrease susceptibility to noise, with the WP andthe Gabor filter having a stable performance in both filtered and noisy CTversions and for both data-sets. Knowing how robust each texture measure undernoise presence is can assist physicians using an automated lung textureclassification system in choosing the appropriate feature extraction algorithmfor a more accurate diagnosis.
arxiv-15300-34 | A Combined Deep-Learning and Deformable-Model Approach to Fully Automatic Segmentation of the Left Ventricle in Cardiac MRI | http://arxiv.org/pdf/1512.07951v1.pdf | author:M. R. Avendi, A. Kheradvar, H. Jafarkhani category:cs.CV published:2015-12-25 summary:Segmentation of the left ventricle (LV) from cardiac magnetic resonanceimaging (MRI) datasets is an essential step for calculation of clinical indicessuch as ventricular volume and ejection fraction. In this work, we employ deeplearning algorithms combined with deformable models to develop and evaluate afully automatic segmentation tool for the LV from short-axis cardiac MRIdatasets. The method employs deep learning algorithms to learn the segmentationtask from the ground true data. Convolutional networks are employed toautomatically detect the LV chamber in MRI dataset. Stacked autoencoders areutilized to infer the shape of the LV. The inferred shape is incorporated intodeformable models to improve the accuracy and robustness of the segmentation.We validated our method using 45 cardiac MR datasets taken from the MICCAI 2009LV segmentation challenge and showed that it outperforms the state-of-the artmethods. Excellent agreement with the ground truth was achieved. Validationmetrics, percentage of good contours, Dice metric, average perpendiculardistance and conformity, were computed as 96.69%, 0.94, 1.81mm and 0.86, versusthose of 79.2%-95.62%, 0.87-0.9, 1.76-2.97mm and 0.67-0.78, obtained by othermethods, respectively.
arxiv-15300-35 | Real-Time Audio-to-Score Alignment of Music Performances Containing Errors and Arbitrary Repeats and Skips | http://arxiv.org/pdf/1512.07748v1.pdf | author:Tomohiko Nakamura, Eita Nakamura, Shigeki Sagayama category:cs.SD cs.LG cs.MM published:2015-12-24 summary:This paper discusses real-time alignment of audio signals of musicperformance to the corresponding score (a.k.a. score following) which canhandle tempo changes, errors and arbitrary repeats and/or skips (repeats/skips)in performances. This type of score following is particularly useful inautomatic accompaniment for practices and rehearsals, where errors andrepeats/skips are often made. Simple extensions of the algorithms previouslyproposed in the literature are not applicable in these situations for scores ofpractical length due to the problem of large computational complexity. To copewith this problem, we present two hidden Markov models of monophonicperformance with errors and arbitrary repeats/skips, and derive efficientscore-following algorithms with an assumption that the prior probabilitydistributions of score positions before and after repeats/skips are independentfrom each other. We confirmed real-time operation of the algorithms with musicscores of practical length (around 10000 notes) on a modern laptop and theirtracking ability to the input performance within 0.7 s on average afterrepeats/skips in clarinet performance data. Further improvements and extensionfor polyphonic signals are also discussed.
arxiv-15300-36 | Deep Reinforcement Learning in Large Discrete Action Spaces | http://arxiv.org/pdf/1512.07679v2.pdf | author:Gabriel Dulac-Arnold, Richard Evans, Hado van Hasselt, Peter Sunehag, Timothy Lillicrap, Jonathan Hunt, Timothy Mann, Theophane Weber, Thomas Degris, Ben Coppin category:cs.AI cs.LG cs.NE stat.ML published:2015-12-24 summary:Being able to reason in an environment with a large number of discreteactions is essential to bringing reinforcement learning to a larger class ofproblems. Recommender systems, industrial plants and language models are onlysome of the many real-world tasks involving large numbers of discrete actionsfor which current methods are difficult or even often impossible to apply. Anability to generalize over the set of actions as well as sub-linear complexityrelative to the size of the set are both necessary to handle such tasks.Current approaches are not able to provide both of these, which motivates thework in this paper. Our proposed approach leverages prior information about theactions to embed them in a continuous space upon which it can generalize.Additionally, approximate nearest-neighbor methods allow for logarithmic-timelookup complexity relative to the number of actions, which is necessary fortime-wise tractable training. This combined approach allows reinforcementlearning methods to be applied to large-scale learning problems previouslyintractable with current methods. We demonstrate our algorithm's abilities on aseries of tasks having up to one million actions.
arxiv-15300-37 | Visualizations Relevant to The User By Multi-View Latent Variable Factorization | http://arxiv.org/pdf/1512.07807v2.pdf | author:Seppo Virtanen, Homayun Afrabandpey, Samuel Kaski category:cs.LG cs.IR published:2015-12-24 summary:A main goal of data visualization is to find, from among all the availablealternatives, mappings to the 2D/3D display which are relevant to the user.Assuming user interaction data, or other auxiliary data about the items ortheir relationships, the goal is to identify which aspects in the primary datasupport the user\'s input and, equally importantly, which aspects of theuser\'s potentially noisy input have support in the primary data. For solvingthe problem, we introduce a multi-view embedding in which a latentfactorization identifies which aspects in the two data views (primary data anduser data) are related and which are specific to only one of them. Thefactorization is a generative model in which the display is parameterized as apart of the factorization and the other factors explain away the aspects notexpressible in a two-dimensional display. Functioning of the model isdemonstrated on several data sets.
arxiv-15300-38 | Context-Based Prediction of App Usage | http://arxiv.org/pdf/1512.07851v2.pdf | author:Joseph Keshet, Adam Kariv, Arnon Dagan, Dvir Volk, Joey Simhon category:cs.LG published:2015-12-24 summary:There are around a hundred installed apps on an average smartphone. The highnumber of apps and the limited number of app icons that can be displayed on thedevice's screen requires a new paradigm to address their visibility to theuser. In this paper we propose a new online algorithm for dynamicallypredicting a set of apps that the user is likely to use. The algorithm runs onthe user's device and constantly learns the user's habits at a given time,location, and device state. It is designed to actively help the user tonavigate to the desired app as well as to provide a personalized feeling, andhence is aimed at maximizing the AUC. We show both theoretically andempirically that the algorithm maximizes the AUC, and yields good results on aset of 1,000 devices.
arxiv-15300-39 | The LovÃ¡sz Hinge: A Convex Surrogate for Submodular Losses | http://arxiv.org/pdf/1512.07797v1.pdf | author:Jiaqian Yu, Matthew Blaschko category:stat.ML cs.LG published:2015-12-24 summary:Learning with non-modular losses is an important problem when sets ofpredictions are made simultaneously. The main tools for constructing convexsurrogate loss functions for set prediction are margin rescaling and slackrescaling. In this work, we show that these strategies lead to tight convexsurrogates iff the underlying loss function is increasing in the number ofincorrect predictions. However, gradient or cutting-plane computation for thesefunctions is NP-hard for non-supermodular loss functions. We propose instead anovel surrogate loss function for submodular losses, the Lov{\'a}sz hinge,which leads to O(p log p) complexity with O(p) oracle accesses to the lossfunction to compute a gradient or cutting-plane. We prove that the Lov{\'a}szhinge is convex and yields an extension. As a result, we have developed thefirst tractable convex surrogates in the literature for submodular losses. Wedemonstrate the utility of this novel convex surrogate through several setprediction tasks, including on the PASCAL VOC and Microsoft COCO datasets.
arxiv-15300-40 | Fast Parallel SVM using Data Augmentation | http://arxiv.org/pdf/1512.07716v1.pdf | author:Hugh Perkins, Minjie Xu, Jun Zhu, Bo Zhang category:cs.LG published:2015-12-24 summary:As one of the most popular classifiers, linear SVMs still have challenges indealing with very large-scale problems, even though linear or sub-linearalgorithms have been developed recently on single machines. Parallel computingmethods have been developed for learning large-scale SVMs. However, existingmethods rely on solving local sub-optimization problems. In this paper, wedevelop a novel parallel algorithm for learning large-scale linear SVM. Ourapproach is based on a data augmentation equivalent formulation, which caststhe problem of learning SVM as a Bayesian inference problem, for which we candevelop very efficient parallel sampling methods. We provide empirical resultsfor this parallel sampling SVM, and provide extensions for SVR, non-linearkernels, and provide a parallel implementation of the Crammer and Singer model.This approach is very promising in its own right, and further is a very usefultechnique to parallelize a broader family of general maximum-margin models.
arxiv-15300-41 | Fast Acquisition for Quantitative MRI Maps: Sparse Recovery from Non-linear Measurements | http://arxiv.org/pdf/1512.07712v1.pdf | author:Anupriya Gogna, Angshul Majumdar category:cs.CV published:2015-12-24 summary:This work addresses the problem of estimating proton density and T1 maps fromtwo partially sampled K-space scans such that the total acquisition timeremains approximately the same as a single scan. Existing multi parametric nonlinear curve fitting techniques require a large number (8 or more) of echoes toestimate the maps resulting in prolonged (clinically infeasible) acquisitiontimes. Our simulation results show that our method yields very accurate androbust results from only two partially sampled scans (total scan time being thesame as a single echo MRI). We model PD and T1 maps to be sparse in sometransform domain. The PD map is recovered via standard Compressed Sensing basedrecovery technique. Estimating the T1 map requires solving an analysis priorsparse recovery problem from non linear measurements, since the relationshipbetween T1 values and intensity values or K space samples is not linear. Forthe first time in this work, we propose an algorithm for analysis prior sparserecovery for non linear measurements. We have compared our approach with theonly existing technique based on matrix factorization from non linearmeasurements; our method yields considerably superior results.
arxiv-15300-42 | Truncated Max-of-Convex Models | http://arxiv.org/pdf/1512.07815v1.pdf | author:Pankaj Pansari, M. Pawan Kumar category:cs.CV published:2015-12-24 summary:Truncated convex models (TCM) are special cases of pairwise random fieldsthat have been widely used in computer vision. However, by restricting theorder of the potentials to be at most two, they fail to capture useful imagestatistics. We propose a natural generalization of TCM to high-order randomfields, which we call truncated max-of-convex models (TMCM). The energyfunction of TMCM consists of two types of potentials: (i) unary potentials,which have no restriction on their form; and (ii) high-order potentials, whichare the sum of the truncation of the m largest convex distances over disjointpairs of random variables in an arbitrary size clique. The use of a convexdistance function encourages smoothness, while truncation allows fordiscontinuities in the labeling. By using m > 1, TMCM provides robustnesstowards errors in the clique definition. In order to minimize the energyfunction of a TMCM over all possible labelings, we design an efficientst-mincut based range expansion algorithm. We prove the accuracy of ouralgorithm by establishing strong multiplicative bounds for several specialcases of interest.
arxiv-15300-43 | Service Choreography, SBVR, and Time | http://arxiv.org/pdf/1512.07685v1.pdf | author:Nurulhuda A. Manaf, Sotiris Moschoyiannis, Paul Krause category:cs.SE cs.CL published:2015-12-24 summary:We propose the use of structured natural language (English) in specifyingservice choreographies, focusing on the what rather than the how of therequired coordination of participant services in realising a businessapplication scenario. The declarative approach we propose uses the OMG standardSemantics of Business Vocabulary and Rules (SBVR) as a modelling language. Theservice choreography approach has been proposed for describing the globalorderings of the invocations on interfaces of participant services. Wetherefore extend SBVR with a notion of time which can capture the coordinationof the participant services, in terms of the observable message exchangesbetween them. The extension is done using existing modelling constructs inSBVR, and hence respects the standard specification. The idea is that users -domain specialists rather than implementation specialists - can verify therequested service composition by directly reading the structured English usedby SBVR. At the same time, the SBVR model can be represented in formal logic soit can be parsed and executed by a machine.
arxiv-15300-44 | Learning Transferrable Knowledge for Semantic Segmentation with Deep Convolutional Neural Network | http://arxiv.org/pdf/1512.07928v1.pdf | author:Seunghoon Hong, Junhyuk Oh, Bohyung Han, Honglak Lee category:cs.CV published:2015-12-24 summary:We propose a novel weakly-supervised semantic segmentation algorithm based onDeep Convolutional Neural Network (DCNN). Contrary to existingweakly-supervised approaches, our algorithm exploits auxiliary segmentationannotations available for different categories to guide segmentations on imageswith only image-level class labels. To make the segmentation knowledgetransferrable across categories, we design a decoupled encoder-decoderarchitecture with attention model. In this architecture, the model generatesspatial highlights of each category presented in an image using an attentionmodel, and subsequently generates foreground segmentation for each highlightedregion using decoder. Combining attention model, we show that the decodertrained with segmentation annotations in different categories can boost theperformance of weakly-supervised semantic segmentation. The proposed algorithmdemonstrates substantially improved performance compared to thestate-of-the-art weakly-supervised techniques in challenging PASCAL VOC 2012dataset when our model is trained with the annotations in 60 exclusivecategories in Microsoft COCO dataset.
arxiv-15300-45 | An unsupervised spatiotemporal graphical modeling approach to anomaly detection in distributed CPS | http://arxiv.org/pdf/1512.07876v2.pdf | author:Chao Liu, Sambuddha Ghosal, Zhanhong Jiang, Soumik Sarkar category:cs.LG published:2015-12-24 summary:Modern distributed cyber-physical systems (CPSs) encounter a large variety ofphysical faults and cyber anomalies and in many cases, they are vulnerable tocatastrophic fault propagation scenarios due to strong connectivity among thesub-systems. This paper presents a new data-driven framework for system-wideanomaly detection for addressing such issues. The framework is based on aspatiotemporal feature extraction scheme built on the concept of symbolicdynamics for discovering and representing causal interactions among thesubsystems of a CPS. The extracted spatiotemporal features are then used tolearn system-wide patterns via a Restricted Boltzmann Machine (RBM). Theresults show that: (1) the RBM free energy in the off-nominal conditions isdifferent from that in the nominal conditions and can be used for anomalydetection; (2) the framework can capture multiple nominal modes with onegraphical model; (3) the case studies with simulated data and an integratedbuilding system validate the proposed approach.
arxiv-15300-46 | Hardware Architecture for Large Parallel Array of Random Feature Extractors applied to Image Recognition | http://arxiv.org/pdf/1512.07783v1.pdf | author:Aakash Patil, Shanlan Shen, Enyi Yao, Arindam Basu category:cs.ET cs.NE published:2015-12-24 summary:We demonstrate a low-power and compact hardware implementation of RandomFeature Extractor (RFE) core. With complex tasks like Image Recognitionrequiring a large set of features, we show how weight reuse technique can allowto virtually expand the random features available from RFE core. Further, weshow how to avoid computation cost wasted for propagating "incognizant" orredundant random features. For proof of concept, we validated our approach byusing our RFE core as the first stage of Extreme Learning Machine (ELM)--a twolayer neural network--and were able to achieve $>97\%$ accuracy on MNISTdatabase of handwritten digits. ELM's first stage of RFE is done on an analogASIC occupying $5$mm$\times5$mm area in $0.35\mu$m CMOS and consuming $5.95$$\mu$J/classify while using $\approx 5000$ effective hidden neurons. The ELMsecond stage consisting of just adders can be implemented as digital circuitwith estimated power consumption of $20.9$ nJ/classify. With a total energyconsumption of only $5.97$ $\mu$J/classify, this low-power mixed signal ASICcan act as a co-processor in portable electronic gadgets with cameras.
arxiv-15300-47 | Adaptive Object Detection Using Adjacency and Zoom Prediction | http://arxiv.org/pdf/1512.07711v2.pdf | author:Yongxi Lu, Tara Javidi, Svetlana Lazebnik category:cs.CV published:2015-12-24 summary:State-of-the-art object detection systems rely on an accurate set of regionproposals. Several recent methods use a neural network architecture tohypothesize promising object locations. While these approaches arecomputationally efficient, they rely on fixed image regions as anchors forpredictions. In this paper we propose to use a search strategy that adaptivelydirects computational resources to sub-regions likely to contain objects.Compared to methods based on fixed anchor locations, our approach naturallyadapts to cases where object instances are sparse and small. Our approach iscomparable in terms of accuracy to the state-of-the-art Faster R-CNN approachwhile using two orders of magnitude fewer anchors on average. Code is publiclyavailable.
arxiv-15300-48 | G-CNN: an Iterative Grid Based Object Detector | http://arxiv.org/pdf/1512.07729v2.pdf | author:Mahyar Najibi, Mohammad Rastegari, Larry S. Davis category:cs.CV published:2015-12-24 summary:We introduce G-CNN, an object detection technique based on CNNs which workswithout proposal algorithms. G-CNN starts with a multi-scale grid of fixedbounding boxes. We train a regressor to move and scale elements of the gridtowards objects iteratively. G-CNN models the problem of object detection asfinding a path from a fixed grid to boxes tightly surrounding the objects.G-CNN with around 180 boxes in a multi-scale grid performs comparably to FastR-CNN which uses around 2K bounding boxes generated with a proposal technique.This strategy makes detection faster by removing the object proposal stage aswell as reducing the number of boxes to be processed.
arxiv-15300-49 | Convolutional Architecture Exploration for Action Recognition and Image Classification | http://arxiv.org/pdf/1512.07502v1.pdf | author:J. T. Turner, David Aha, Leslie Smith, Kalyan Moy Gupta category:cs.CV published:2015-12-23 summary:Convolutional Architecture for Fast Feature Encoding (CAFFE) [11] is asoftware package for the training, classifying, and feature extraction ofimages. The UCF Sports Action dataset is a widely used machine learning datasetthat has 200 videos taken in 720x480 resolution of 9 different sportingactivities: diving, golf, swinging, kicking, lifting, horseback riding,running, skateboarding, swinging (various gymnastics), and walking. In thisreport we report on a caffe feature extraction pipeline of images taken fromthe videos of the UCF Sports Action dataset. A similar test was performed onoverfeat, and results were inferior to caffe. This study is intended to explorethe architecture and hyper parameters needed for effective static analysis ofaction in videos and classification over a variety of image datasets.
arxiv-15300-50 | A Deep Generative Deconvolutional Image Model | http://arxiv.org/pdf/1512.07344v1.pdf | author:Yunchen Pu, Xin Yuan, Andrew Stevens, Chunyuan Li, Lawrence Carin category:cs.CV cs.LG stat.ML published:2015-12-23 summary:A deep generative model is developed for representation and analysis ofimages, based on a hierarchical convolutional dictionary-learning framework.Stochastic {\em unpooling} is employed to link consecutive layers in the model,yielding top-down image generation. A Bayesian support vector machine is linkedto the top-layer features, yielding max-margin discrimination. Deepdeconvolutional inference is employed when testing, to infer the latentfeatures, and the top-layer features are connected with the max-marginclassifier for discrimination tasks. The model is efficiently trained using aMonte Carlo expectation-maximization (MCEM) algorithm, with implementation ongraphical processor units (GPUs) for efficient large-scale learning, and fasttesting. Excellent results are obtained on several benchmark datasets,including ImageNet, demonstrating that the proposed model achieves results thatare highly competitive with similarly sized convolutional neural networks.
arxiv-15300-51 | Homology Computation of Large Point Clouds using Quantum Annealing | http://arxiv.org/pdf/1512.09328v2.pdf | author:Raouf Dridi, Hedayat Alghassi category:quant-ph cs.LG published:2015-12-23 summary:Homology is a tool in topological data analysis which measures the shape ofthe data. In many cases, these measurements translate into new insights whichare not readily available by other means. To compute homology, we rely onmathematical constructions which scale exponentially with the size of the data.Therefore, for large point clouds, the computation is infeasible usingclassical computers. In this paper, we present a quantum annealing pipeline forcomputation of homology of large point clouds. It is designed to workconcurrently with resizable cloud computing platforms. The pipeline takes asinput a witness graph approximating the given point cloud. It uses quantumannealing to compute a clique covering of the graph and then uses this cover toconstruct a Mayer-Vietoris complex. The pipeline terminates by performing asimplified homology computation of the Mayer-Vietoris complex in parallel. Wehave designed three different clique coverings and their quantum annealingformulation with which our algorithm exhibits an exponential speed-up overclassical implementations. In fact, not only the computation is simplified butalso the simplicial complex construction itself is greatly simplified. We havealso included tests using D-Wave 2X quantum processor.
arxiv-15300-52 | k-Means Clustering Is Matrix Factorization | http://arxiv.org/pdf/1512.07548v1.pdf | author:Christian Bauckhage category:stat.ML published:2015-12-23 summary:We show that the objective function of conventional k-means clustering can beexpressed as the Frobenius norm of the difference of a data matrix and a lowrank approximation of that data matrix. In short, we show that k-meansclustering is a matrix factorization problem. These notes are meant as areference and intended to provide a guided tour towards a result that is oftenmentioned but seldom made explicit in the literature.
arxiv-15300-53 | Recovering 6D Object Pose and Predicting Next-Best-View in the Crowd | http://arxiv.org/pdf/1512.07506v2.pdf | author:Andreas Doumanoglou, Rigas Kouskouridas, Sotiris Malassiotis, Tae-Kyun Kim category:cs.CV published:2015-12-23 summary:Object detection and 6D pose estimation in the crowd (scenes with multipleobject instances, severe foreground occlusions and background distractors), hasbecome an important problem in many rapidly evolving technological areas suchas robotics and augmented reality. Single shot-based 6D pose estimators withmanually designed features are still unable to tackle the above challenges,motivating the research towards unsupervised feature learning andnext-best-view estimation. In this work, we present a complete framework forboth single shot-based 6D object pose estimation and next-best-view predictionbased on Hough Forests, the state of the art object pose estimator thatperforms classification and regression jointly. Rather than using manuallydesigned features we a) propose an unsupervised feature learnt fromdepth-invariant patches using a Sparse Autoencoder and b) offer an extensiveevaluation of various state of the art features. Furthermore, taking advantageof the clustering performed in the leaf nodes of Hough Forests, we learn toestimate the reduction of uncertainty in other views, formulating the problemof selecting the next-best-view. To further improve pose estimation, we proposean improved joint registration and hypotheses verification module as a finalrefinement step to reject false detections. We provide two additionalchallenging datasets inspired from realistic scenarios to extensively evaluatethe state of the art and our framework. One is related to domestic environmentsand the other depicts a bin-picking scenario mostly found in industrialsettings. We show that our framework significantly outperforms state of the artboth on public and on our datasets.
arxiv-15300-54 | Satisficing in multi-armed bandit problems | http://arxiv.org/pdf/1512.07638v1.pdf | author:Paul Reverdy, Vaibhav Srivastava, Naomi Ehrich Leonard category:cs.LG math.OC stat.ML published:2015-12-23 summary:Satisficing is a relaxation of maximizing and allows for less riskydecision-making in the face of uncertainty. We propose two sets of satisficingobjectives for the multi-armed bandit problem, where the objective is toachieve reward-based decision-making performance above a given threshold. Weshow that these new problems are equivalent to various standard multi-armedbandit problems with maximizing objectives and use the equivalence to findbounds on performance. The different objectives can result in qualitativelydifferent behavior; for example, agents explore their options continually inone case and only a finite number of times in another. For the case of Gaussianrewards we show an additional equivalence between the two sets of satisficingobjectives that allows algorithms developed for one set to be applied to theother. We then develop variants of the Upper Credible Limit (UCL) algorithmthat solve the problems with satisficing objectives and show that thesemodified UCL algorithms achieve efficient satisficing performance.
arxiv-15300-55 | Latent Variable Modeling with Diversity-Inducing Mutual Angular Regularization | http://arxiv.org/pdf/1512.07336v1.pdf | author:Pengtao Xie, Yuntian Deng, Eric Xing category:cs.LG stat.ML published:2015-12-23 summary:Latent Variable Models (LVMs) are a large family of machine learning modelsproviding a principled and effective way to extract underlying patterns,structure and knowledge from observed data. Due to the dramatic growth ofvolume and complexity of data, several new challenges have emerged and cannotbe effectively addressed by existing LVMs: (1) How to capture long-tailpatterns that carry crucial information when the popularity of patterns isdistributed in a power-law fashion? (2) How to reduce model complexity andcomputational cost without compromising the modeling power of LVMs? (3) How toimprove the interpretability and reduce the redundancy of discovered patterns?To addresses the three challenges discussed above, we develop a novelregularization technique for LVMs, which controls the geometry of the latentspace during learning to enable the learned latent components of LVMs to bediverse in the sense that they are favored to be mutually different from eachother, to accomplish long-tail coverage, low redundancy, and betterinterpretability. We propose a mutual angular regularizer (MAR) to encouragethe components in LVMs to have larger mutual angles. The MAR is non-convex andnon-smooth, entailing great challenges for optimization. To cope with thisissue, we derive a smooth lower bound of the MAR and optimize the lower boundinstead. We show that the monotonicity of the lower bound is closely alignedwith the MAR to qualify the lower bound as a desirable surrogate of the MAR.Using neural network (NN) as an instance, we analyze how the MAR affects thegeneralization performance of NN. On two popular latent variable models ---restricted Boltzmann machine and distance metric learning, we demonstrate thatMAR can effectively capture long-tail patterns, reduce model complexity withoutsacrificing expressivity and improve interpretability.
arxiv-15300-56 | Incremental Method for Spectral Clustering of Increasing Orders | http://arxiv.org/pdf/1512.07349v2.pdf | author:Pin-Yu Chen, Baichuan Zhang, Mohammad Al Hasan, Alfred O. Hero category:cs.SI cs.NA stat.ML published:2015-12-23 summary:The smallest eigenvalues and the associated eigenvectors (i.e., eigenpairs)of a graph Laplacian matrix have been widely used for spectral clustering andcommunity detection. However, in real-life applications the number of clustersor communities (say, K) is generally unknown a-priori. Consequently, themajority of the existing methods either choose K heuristically or they repeatthe clustering method with different choices of K and accept the bestclustering result. The first option, more often, yield suboptimal result, whilethe second option is computationally expensive. In this work, we propose anincremental method for constructing the eigenspectrum of the graph Laplacianmatrix. This method leverages the eigenstructure of graph Laplacian matrix toobtain the K-th eigenpairs of the Laplacian matrix given a collection of allthe K-1 smallest eigenpairs. Our proposed method adapts the Laplacian matrixsuch that the batch eigenvalue decomposition problem transforms into anefficient sequential leading eigenpair computation problem. As a practicalapplication, we consider user-guided spectral clustering. Specifically, wedemonstrate that users can utilize the proposed incremental method foreffective eigenpair computation and determining the desired number of clustersbased on multiple clustering metrics.
arxiv-15300-57 | Adaptive Algorithms for Online Convex Optimization with Long-term Constraints | http://arxiv.org/pdf/1512.07422v1.pdf | author:Rodolphe Jenatton, Jim Huang, CÃ©dric Archambeau category:stat.ML cs.LG math.OC published:2015-12-23 summary:We present an adaptive online gradient descent algorithm to solve onlineconvex optimization problems with long-term constraints , which are constraintsthat need to be satisfied when accumulated over a finite number of rounds T ,but can be violated in intermediate rounds. For some user-defined trade-offparameter $\beta$ $\in$ (0, 1), the proposed algorithm achieves cumulativeregret bounds of O(T^max{$\beta$,1--$\beta$}) and O(T^(1--$\beta$/2)) for theloss and the constraint violations respectively. Our results hold for convexlosses and can handle arbitrary convex constraints without requiring knowledgeof the number of rounds in advance. Our contributions improve over the bestknown cumulative regret bounds by Mahdavi, et al. (2012) that are respectivelyO(T^1/2) and O(T^3/4) for general convex domains, and respectively O(T^2/3) andO(T^2/3) when further restricting to polyhedral domains. We supplement theanalysis with experiments validating the performance of our algorithm inpractice.
arxiv-15300-58 | Adaptive Ensemble Learning with Confidence Bounds | http://arxiv.org/pdf/1512.07446v1.pdf | author:Cem Tekin, Jinsung Yoon. Mihael category:cs.LG stat.ML published:2015-12-23 summary:Extracting actionable intelligence from distributed, heterogeneous,correlated and high-dimensional data sources requires run-time processing andlearning both locally and globally. In the last decade, a large number ofmeta-learning techniques have been proposed in which local learners make onlinepredictions based on their locally-collected data instances, and feed thesepredictions to an ensemble learner, which fuses them and issues a globalprediction. However, most of these works do not provide performance guaranteesor, when they do, these guarantees are asymptotic. None of these existing worksprovide confidence estimates about the issued predictions or rate of learningguarantees for the ensemble learner. In this paper, we provide a systematicensemble learning method called Hedged Bandits, which comes with both long run(asymptotic) and short run (rate of learning) performance guarantees. Moreover,we show that our proposed method outperforms all existing ensemble learningtechniques, even in the presence of concept drift. We illustrate theperformance of Hedged Bandits in the context of medical informatics. However,the proposed methods have numerous other applications, including networkmonitoring and security, online recommendation systems, social networks, smartcities, etc.
arxiv-15300-59 | A Latent-Variable Lattice Model | http://arxiv.org/pdf/1512.07587v5.pdf | author:Rajasekaran Masatran category:cs.LG cs.CV stat.ML published:2015-12-23 summary:The MRF is frequently used in computer vision, but MRF approximationalgorithms are computationally expensive. Since only a small subset of MRF isused in computer vision, we characterize this subset with three concepts: (1)Lattice, (2) Homogenity, and (3) Inertia. We design a non-markov high-biaslow-variance model as an alternative to this subclass of MRF. Our goal isrobust learning, from small datasets. Our learning algorithm uses vectorquantization and, at time complexity O(T^d log T^d) for a hypercube of sizeT^d, is much faster than that of MRF.
arxiv-15300-60 | The Max $K$-Armed Bandit: PAC Lower Bounds and Efficient Algorithms | http://arxiv.org/pdf/1512.07650v1.pdf | author:Yahel David, Nahum Shimkin category:stat.ML cs.AI cs.LG published:2015-12-23 summary:We consider the Max $K$-Armed Bandit problem, where a learning agent is facedwith several stochastic arms, each a source of i.i.d. rewards of unknowndistribution. At each time step the agent chooses an arm, and observes thereward of the obtained sample. Each sample is considered here as a separateitem with the reward designating its value, and the goal is to find an itemwith the highest possible value. Our basic assumption is a known lower bound onthe {\em tail function} of the reward distributions. Under the PAC framework,we provide a lower bound on the sample complexity of any$(\epsilon,\delta)$-correct algorithm, and propose an algorithm that attainsthis bound up to logarithmic factors. We analyze the robustness of the proposedalgorithm and in addition, we compare the performance of this algorithm to thevariant in which the arms are not distinguishable by the agent and are chosenrandomly at each stage. Interestingly, when the maximal rewards of the armshappen to be similar, the latter approach may provide better performance.
arxiv-15300-61 | Multi-centrality Graph Spectral Decompositions and their Application to Cyber Intrusion Detection | http://arxiv.org/pdf/1512.07372v2.pdf | author:Pin-Yu Chen, Sutanay Choudhury, Alfred O. Hero category:cs.SI cs.CR stat.ML published:2015-12-23 summary:Many modern datasets can be represented as graphs and hence spectraldecompositions such as graph principal component analysis (PCA) can be useful.Distinct from previous graph decomposition approaches based on subspaceprojection of a single topological feature, e.g., the Fiedler vector ofcentered graph adjacency matrix (graph Laplacian), we propose spectraldecomposition approaches to graph PCA and graph dictionary learning thatintegrate multiple features, including graph walk statistics, centralitymeasures and graph distances to reference nodes. In this paper we propose a newPCA method for single graph analysis, called multi-centrality graph PCA(MC-GPCA), and a new dictionary learning method for ensembles of graphs, calledmulti-centrality graph dictionary learning (MC-GDL), both based on spectraldecomposition of multi-centrality matrices. As an application to cyberintrusion detection, MC-GPCA can be an effective indicator of anomalousconnectivity pattern and MC-GDL can provide discriminative basis for attackclassification.
arxiv-15300-62 | Plug-and-Play Priors for Bright Field Electron Tomography and Sparse Interpolation | http://arxiv.org/pdf/1512.07331v1.pdf | author:Suhas Sreehari, S. V. Venkatakrishnan, Brendt Wohlberg, Lawrence F. Drummy, Jeffrey P. Simmons, Charles A. Bouman category:cs.CV published:2015-12-23 summary:Many material and biological samples in scientific imaging are characterizedby non-local repeating structures. These are studied using scanning electronmicroscopy and electron tomography. Sparse sampling of individual pixels in a2D image acquisition geometry, or sparse sampling of projection images withlarge tilt increments in a tomography experiment, can enable high speed dataacquisition and minimize sample damage caused by the electron beam. In this paper, we present an algorithm for electron tomographicreconstruction and sparse image interpolation that exploits the non-localredundancy in images. We adapt a framework, termed plug-and-play (P&P) priors,to solve these imaging problems in a regularized inversion setting. The powerof the P&P approach is that it allows a wide array of modern denoisingalgorithms to be used as a "prior model" for tomography and imageinterpolation. We also present sufficient mathematical conditions that ensureconvergence of the P&P approach, and we use these insights to design a newnon-local means denoising algorithm. Finally, we demonstrate that the algorithmproduces higher quality reconstructions on both simulated and real electronmicroscope data, along with improved convergence properties compared to othermethods.
arxiv-15300-63 | Interacting Behavior and Emerging Complexity | http://arxiv.org/pdf/1512.07450v3.pdf | author:Alyssa Adams, Hector Zenil, Eduardo Hermo Reyes, Joost Joosten category:cs.NE cs.CC nlin.CG q-bio.PE published:2015-12-23 summary:Can we quantify the change of complexity throughout evolutionary processes?We attempt to address this question through an empirical approach. In verygeneral terms, we simulate two simple organisms on a computer that compete overlimited available resources. We implement Global Rules that determine theinteraction between two Elementary Cellular Automata on the same grid. GlobalRules change the complexity of the state evolution output which suggests thatsome complexity is intrinsic to the interaction rules themselves. The largestincreases in complexity occurred when the interacting elementary rules had verylittle complexity, suggesting that they are able to accept complexity throughinteraction only. We also found that some Class 3 or 4 CA rules are morefragile than others to Global Rules, while others are more robust, hencesuggesting some intrinsic properties of the rules independent of the GlobalRule choice. We provide statistical mappings of Elementary Cellular Automataexposed to Global Rules and different initial conditions onto differentcomplexity classes.
arxiv-15300-64 | Preconditioned Stochastic Gradient Langevin Dynamics for Deep Neural Networks | http://arxiv.org/pdf/1512.07666v1.pdf | author:Chunyuan Li, Changyou Chen, David Carlson, Lawrence Carin category:stat.ML published:2015-12-23 summary:Effective training of deep neural networks suffers from two main issues. Thefirst is that the parameter spaces of these models exhibit pathologicalcurvature. Recent methods address this problem by using adaptivepreconditioning for Stochastic Gradient Descent (SGD). These methods improveconvergence by adapting to the local geometry of parameter space. A secondissue is overfitting, which is typically addressed by early stopping. However,recent work has demonstrated that Bayesian model averaging mitigates thisproblem. The posterior can be sampled by using Stochastic Gradient LangevinDynamics (SGLD). However, the rapidly changing curvature renders default SGLDmethods inefficient. Here, we propose combining adaptive preconditioners withSGLD. In support of this idea, we give theoretical properties on asymptoticconvergence and predictive risk. We also provide empirical results for LogisticRegression, Feedforward Neural Nets, and Convolutional Neural Nets,demonstrating that our preconditioned SGLD method gives state-of-the-artperformance on these models.
arxiv-15300-65 | Mid-level Representation for Visual Recognition | http://arxiv.org/pdf/1512.07314v1.pdf | author:Moin Nabi category:cs.CV published:2015-12-23 summary:Visual Recognition is one of the fundamental challenges in AI, where the goalis to understand the semantics of visual data. Employing mid-levelrepresentation, in particular, shifted the paradigm in visual recognition. Themid-level image/video representation involves discovering and training a set ofmid-level visual patterns (e.g., parts and attributes) and represent a givenimage/video utilizing them. The mid-level patterns can be extracted from imagesand videos using the motion and appearance information of visual phenomenas.This thesis targets employing mid-level representations for differenthigh-level visual recognition tasks, namely (i)image understanding and(ii)video understanding. In the case of image understanding, we focus on object detection/recognitiontask. We investigate on discovering and learning a set of mid-level patches tobe used for representing the images of an object category. We specificallyemploy the discriminative patches in a subcategory-aware webly-supervisedfashion. We, additionally, study the outcomes provided by employing thesubcategory-based models for undoing dataset bias.
arxiv-15300-66 | High-Order Stochastic Gradient Thermostats for Bayesian Learning of Deep Models | http://arxiv.org/pdf/1512.07662v1.pdf | author:Chunyuan Li, Changyou Chen, Kai Fan, Lawrence Carin category:stat.ML published:2015-12-23 summary:Learning in deep models using Bayesian methods has generated significantattention recently. This is largely because of the feasibility of modernBayesian methods to yield scalable learning and inference, while maintaining ameasure of uncertainty in the model parameters. Stochastic gradient MCMCalgorithms (SG-MCMC) are a family of diffusion-based sampling methods forlarge-scale Bayesian learning. In SG-MCMC, multivariate stochastic gradientthermostats (mSGNHT) augment each parameter of interest, with a momentum and athermostat variable to maintain stationary distributions as target posteriordistributions. As the number of variables in a continuous-time diffusionincreases, its numerical approximation error becomes a practical bottleneck, sobetter use of a numerical integrator is desirable. To this end, we propose useof an efficient symmetric splitting integrator in mSGNHT, instead of thetraditional Euler integrator. We demonstrate that the proposed scheme is moreaccurate, robust, and converges faster. These properties are demonstrated to bedesirable in Bayesian deep learning. Extensive experiments on two canonicalmodels and their deep extensions demonstrate that the proposed scheme improvesgeneral Bayesian posterior sampling, particularly for deep models.
arxiv-15300-67 | Implementing a Bayes Filter in a Neural Circuit: The Case of Unknown, Nonlinear Stimulus Dynamics | http://arxiv.org/pdf/1512.07839v2.pdf | author:Sacha Sokoloski category:cs.LG stat.ML published:2015-12-22 summary:In order to interact intelligently with objects in the world, animals mustfirst transform neural population responses into estimates of the unknownstimuli which caused them. The Bayesian solution to this problem is known as aBayes filter, and previous work has shown how to exactly implement a Bayesfilter in a theoretical neural circuit when the stimulus dynamics are known andlinear. In this paper we develop a method for approximating a Bayes filter whenthe stimulus dynamics are unknown and nonlinear, by training a recurrent neuralnetwork to approximate the predictions of the Bayes filter. To train thenetwork, we use a combination of contrastive divergence minimization andbackpropagation, in order to maximize the likelihood of the parameters of thenetwork given the population responses. We demonstrate this method on a problemwhere the stimulus is a stochastic pendulum, and show how the learned networkdisplays many of the characteristic properties found in research on populationsof neurons.
arxiv-15300-68 | A C++ library for Multimodal Deep Learning | http://arxiv.org/pdf/1512.06927v4.pdf | author:Jian Jin category:cs.LG published:2015-12-22 summary:MDL, Multimodal Deep Learning Library, is a deep learning framework thatsupports multiple models, and this document explains its philosophy andfunctionality. MDL runs on Linux, Mac, and Unix platforms. It depends onOpenCV.
arxiv-15300-69 | Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels | http://arxiv.org/pdf/1512.06974v2.pdf | author:Ishan Misra, C. Lawrence Zitnick, Margaret Mitchell, Ross Girshick category:cs.CV published:2015-12-22 summary:When human annotators are given a choice about what to label in an image,they apply their own subjective judgments on what to ignore and what tomention. We refer to these noisy "human-centric" annotations as exhibitinghuman reporting bias. Examples of such annotations include image tags andkeywords found on photo sharing sites, or in datasets containing imagecaptions. In this paper, we use these noisy annotations for learning visuallycorrect image classifiers. Such annotations do not use consistent vocabulary,and miss a significant amount of the information present in an image; however,we demonstrate that the noise in these annotations exhibits structure and canbe modeled. We propose an algorithm to decouple the human reporting bias fromthe correct visually grounded labels. Our results are highly interpretable forreporting "what's in the image" versus "what's worth saying." We demonstratethe algorithm's efficacy along a variety of metrics and datasets, including MSCOCO and Yahoo Flickr 100M. We show significant improvements over traditionalalgorithms for both image classification and image captioning, doubling theperformance of existing methods in some cases.
arxiv-15300-70 | Topical differences between Chinese language Twitter and Sina Weibo | http://arxiv.org/pdf/1512.07281v1.pdf | author:Qian Zhang, Bruno GonÃ§alves category:cs.SI cs.CL physics.soc-ph published:2015-12-22 summary:Sina Weibo, China's most popular microblogging platform, is currently used byover $500M$ users and is considered to be a proxy of Chinese social life. Inthis study, we contrast the discussions occurring on Sina Weibo and on Chineselanguage Twitter in order to observe two different strands of Chinese culture:people within China who use Sina Weibo with its government imposed restrictionsand those outside that are free to speak completely anonymously. We firstpropose a simple ad-hoc algorithm to identify topics of Tweets and Weibo.Different from previous works on micro-message topic detection, our algorithmconsiders topics of the same contents but with different \#tags. Our algorithmcan also detect topics for Tweets and Weibos without any \#tags. Using a largecorpus of Weibo and Chinese language tweets, covering the period from January$1$ to December $31$, $2012$, we obtain a list of topics using clustered \#tagsthat we can then use to compare the two platforms. Surprisingly, we find thatthere are no common entries among the Top $100$ most popular topics.Furthermore, only $9.2\%$ of tweets correspond to the Top $1000$ topics on SinaWeibo platform, and conversely only $4.4\%$ of weibos were found to discuss themost popular Twitter topics. Our results reveal significant differences insocial attention on the two platforms, with most popular topics on Sina Weiborelating to entertainment while most tweets corresponded to cultural orpolitical contents that is practically non existent in Sina Weibo.
arxiv-15300-71 | Do Less and Achieve More: Training CNNs for Action Recognition Utilizing Action Images from the Web | http://arxiv.org/pdf/1512.07155v1.pdf | author:Shugao Ma, Sarah Adel Bargal, Jianming Zhang, Leonid Sigal, Stan Sclaroff category:cs.CV published:2015-12-22 summary:Recently, attempts have been made to collect millions of videos to train CNNmodels for action recognition in videos. However, curating such large-scalevideo datasets requires immense human labor, and training CNNs on millions ofvideos demands huge computational resources. In contrast, collecting actionimages from the Web is much easier and training on images requires much lesscomputation. In addition, labeled web images tend to contain discriminativeaction poses, which highlight discriminative portions of a video's temporalprogression. We explore the question of whether we can utilize web actionimages to train better CNN models for action recognition in videos. We collect23.8K manually filtered images from the Web that depict the 101 actions in theUCF101 action video dataset. We show that by utilizing web action images alongwith videos in training, significant performance boosts of CNN models can beachieved. We then investigate the scalability of the process by leveragingcrawled web images (unfiltered) for UCF101 and ActivityNet. We replace 16.2Mvideo frames by 393K unfiltered images and get comparable performance.
arxiv-15300-72 | Feature Selection for Classification under Anonymity Constraint | http://arxiv.org/pdf/1512.07158v4.pdf | author:Baichuan Zhang, Vachik Dave, Noman Mohammed, Mohammad Al Hasan category:cs.LG cs.CR published:2015-12-22 summary:Over the last decade, proliferation of various online platforms and theirincreasing adoption by billions of users have heightened the privacy risk of auser enormously. In fact, security researchers have shown that sparse microdatacontaining information about online activities of a user although anonymous,can still be used to disclose the identity of the user by cross-referencing thedata with other data sources. To preserve the privacy of a user, in existingworks several methods (k-anonymity, l-diversity, differential privacy) areproposed that ensure a dataset which is meant to share or publish bears smallidentity disclosure risk. However, the majority of these methods modify thedata in isolation, without considering their utility in subsequent knowledgediscovery tasks, which makes these datasets less informative. In this work, weconsider labeled data that are generally used for classification, and proposetwo methods for feature selection considering two goals: first, on the reducedfeature set the data has small disclosure risk, and second, the utility of thedata is preserved for performing a classification task. Experimental results onvarious real-world datasets show that the method is effective and useful inpractice.
arxiv-15300-73 | Transformed Residual Quantization for Approximate Nearest Neighbor Search | http://arxiv.org/pdf/1512.06925v1.pdf | author:Jiangbo Yuan, Xiuwen Liu category:cs.CV published:2015-12-22 summary:The success of product quantization (PQ) for fast nearest neighbor searchdepends on the exponentially reduced complexities of both storage andcomputation with respect to the codebook size. Recent efforts have been focusedon employing sophisticated optimization strategies, or seeking more effectivemodels. Residual quantization (RQ) is such an alternative that holds the sameproperty as PQ in terms of the aforementioned complexities. In addition tobeing a direct replacement of PQ, hybrids of PQ and RQ can yield more gains forapproximate nearest neighbor search. This motivated us to propose a novelapproach to optimizing RQ and the related hybrid models. With an observation ofthe general randomness increase in a residual space, we propose a new strategythat jointly learns a local transformation per residual cluster with anultimate goal to reduce overall quantization errors. We have shown that ourapproach can achieve significantly better accuracy on nearest neighbor searchthan both the original and the optimized PQ on several very large scalebenchmarks.
arxiv-15300-74 | Facility Deployment Decisions through Warp Optimizaton of Regressed Gaussian Processes | http://arxiv.org/pdf/1512.06929v1.pdf | author:Anthony Scopatz category:math.OC stat.ML published:2015-12-22 summary:A method for quickly determining deployment schedules that meet a given fuelcycle demand is presented here. This algorithm is fast enough to perform insitu within low-fidelity fuel cycle simulators. It uses Gaussian processregression models to predict the production curve as a function of time and thenumber of deployed facilities. Each of these predictions is measured againstthe demand curve using the dynamic time warping distance. The minimum distancedeployment schedule is evaluated in a full fuel cycle simulation, whosegenerated production curve then informs the model on the next optimizationiteration. The method converges within five to ten iterations to a distancethat is less than one percent of the total deployable production. Arepresentative once-through fuel cycle is used to demonstrate the methodologyfor reactor deployment.
arxiv-15300-75 | Refined Error Bounds for Several Learning Algorithms | http://arxiv.org/pdf/1512.07146v1.pdf | author:Steve Hanneke category:cs.LG math.ST stat.ML stat.TH published:2015-12-22 summary:This article studies the achievable guarantees on the error rates of certainlearning algorithms, with particular focus on refining logarithmic factors.Many of the results are based on a general technique for obtaining bounds onthe error rates of sample-consistent classifiers with monotonic error regions,in the realizable case. We prove bounds of this type expressed in terms ofeither the VC dimension or the sample compression size. This general techniquealso enables us to derive several new bounds on the error rates of generalsample-consistent learning algorithms, as well as refined bounds on the labelcomplexity of the CAL active learning algorithm. Additionally, we establish asimple necessary and sufficient condition for the existence of adistribution-free bound on the error rates of all sample-consistent learningrules, converging at a rate inversely proportional to the sample size. We alsostudy learning in the presence of classification noise, deriving a new excesserror rate guarantee for general VC classes under Tsybakov's noise condition,and establishing a simple and general necessary and sufficient condition forthe minimax excess risk under bounded noise to converge at a rate inverselyproportional to the sample size.
arxiv-15300-76 | Multi-Instance Visual-Semantic Embedding | http://arxiv.org/pdf/1512.06963v1.pdf | author:Zhou Ren, Hailin Jin, Zhe Lin, Chen Fang, Alan Yuille category:cs.CV published:2015-12-22 summary:Visual-semantic embedding models have been recently proposed and shown to beeffective for image classification and zero-shot learning, by mapping imagesinto a continuous semantic label space. Although several approaches have beenproposed for single-label embedding tasks, handling images with multiple labels(which is a more general setting) still remains an open problem, mainly due tothe complex underlying corresponding relationship between image and its labels.In this work, we present Multi-Instance visual-semantic Embedding model (MIE)for embedding images associated with either single or multiple labels. Ourmodel discovers and maps semantically-meaningful image subregions to theircorresponding labels. And we demonstrate the superiority of our method over thestate-of-the-art on two tasks, including multi-label image annotation andzero-shot learning.
arxiv-15300-77 | On the Differential Privacy of Bayesian Inference | http://arxiv.org/pdf/1512.06992v1.pdf | author:Zuhe Zhang, Benjamin Rubinstein, Christos Dimitrakakis category:cs.AI cs.CR cs.LG math.ST stat.ML stat.TH published:2015-12-22 summary:We study how to communicate findings of Bayesian inference to third parties,while preserving the strong guarantee of differential privacy. Our maincontributions are four different algorithms for private Bayesian inference onproba-bilistic graphical models. These include two mechanisms for adding noiseto the Bayesian updates, either directly to the posterior parameters, or totheir Fourier transform so as to preserve update consistency. We also utilise arecently introduced posterior sampling mechanism, for which we prove bounds forthe specific but general case of discrete Bayesian networks; and we introduce amaximum-a-posteriori private mechanism. Our analysis includes utility andprivacy bounds, with a novel focus on the influence of graph structure onprivacy. Worked examples and experiments with Bayesian na{\"i}ve Bayes andBayesian linear regression illustrate the application of our mechanisms.
arxiv-15300-78 | SR-Clustering: Semantic Regularized Clustering for Egocentric Photo Streams Segmentation | http://arxiv.org/pdf/1512.07143v1.pdf | author:Mariella Dimiccoli, Marc BolaÃ±os, Estefania Talavera, Maedeh Aghaei, Stavri G. Nikolov, Petia Radeva category:cs.AI cs.CV published:2015-12-22 summary:While wearable cameras are becoming increasingly popular, locating relevantinformation in large unstructured collections of egocentric images is still atedious and time consuming processes. This paper addresses the problem oforganizing egocentric photo streams acquired by a wearable camera intosemantically meaningful segments. First, contextual and semantic information isextracted for each image by employing a Convolutional Neural Networks approach.Later, by integrating language processing, a vocabulary of concepts is definedin a semantic space. Finally, by exploiting the temporal coherence in photostreams, images which share contextual and semantic attributes are groupedtogether. The resulting temporal segmentation is particularly suited forfurther analysis, ranging from activity and event recognition to semanticindexing and summarization. Experiments over egocentric sets of nearly 17,000images, show that the proposed approach outperforms state-of-the-art methods.
arxiv-15300-79 | FAASTA: A fast solver for total-variation regularization of ill-conditioned problems with application to brain imaging | http://arxiv.org/pdf/1512.06999v1.pdf | author:GaÃ«l Varoquaux, Michael Eickenberg, Elvis Dohmatob, Bertand Thirion category:q-bio.NC cs.LG stat.CO stat.ML published:2015-12-22 summary:The total variation (TV) penalty, as many other analysis-sparsity problems,does not lead to separable factors or a proximal operatorwith a closed-formexpression, such as soft thresholding for the $\ell\_1$ penalty. As a result,in a variational formulation of an inverse problem or statisticallearningestimation, it leads to challenging non-smooth optimization problemsthat areoften solved with elaborate single-step first-order methods. When thedata-fitterm arises from empirical measurements, as in brain imaging, it isoften veryill-conditioned and without simple structure. In this situation, in proximalsplitting methods, the computation cost of thegradient step can easily dominateeach iteration. Thus it is beneficialto minimize the number of gradientsteps.We present fAASTA, a variant of FISTA, that relies on an internal solverforthe TV proximal operator, and refines its tolerance to balancecomputationalcost of the gradient and the proximal steps. We give benchmarksandillustrations on "brain decoding": recovering brain maps fromnoisymeasurements to predict observed behavior. The algorithm as well astheempirical study of convergence speed are valuable for any non-exactproximaloperator, in particular analysis-sparsity problems.
arxiv-15300-80 | Recent Advances in Convolutional Neural Networks | http://arxiv.org/pdf/1512.07108v1.pdf | author:Jiuxiang Gu, Zhenhua Wang, Jason Kuen, Lianyang Ma, Amir Shahroudy, Bing Shuai, Ting Liu, Xingxing Wang, Gang Wang category:cs.CV cs.LG cs.NE published:2015-12-22 summary:In the last few years, deep learning has lead to very good performance on avariety of problems, such as object recognition, speech recognition and naturallanguage processing. Among different types of deep neural networks,convolutional neural networks have been most extensively studied. Due to thelack of training data and computing power in early days, it is hard to train alarge high-capacity convolutional neural network without overfitting. Recently,with the rapid growth of data size and the increasing power of graphicsprocessor unit, many researchers have improved the convolutional neuralnetworks and achieved state-of-the-art results on various tasks. In this paper,we provide a broad survey of the recent advances in convolutional neuralnetworks. Besides, we also introduce some applications of convolutional neuralnetworks in computer vision.
arxiv-15300-81 | Cost-based Feature Transfer for Vehicle Occupant Classification | http://arxiv.org/pdf/1512.07080v1.pdf | author:Toby Perrett, Majid Mirmehdi, Eduardo Dias category:cs.CV I.4.9 published:2015-12-22 summary:Knowledge of human presence and interaction in a vehicle is of growinginterest to vehicle manufacturers for design and safety purposes. We present aframework to perform the tasks of occupant detection and occupantclassification for automatic child locks and airbag suppression. It operatesfor all passenger seats, using a single overhead camera. A transfer learningtechnique is introduced to make full use of training data from all seats whilststill maintaining some control over the bias, necessary for a system designedto penalize certain misclassifications more than others. An evaluation isperformed on a challenging dataset with both weighted and unweightedclassifiers, demonstrating the effectiveness of the transfer process.
arxiv-15300-82 | Move from Perturbed scheme to exponential weighting average | http://arxiv.org/pdf/1512.07074v1.pdf | author:Chunyang Xiao category:cs.LG published:2015-12-22 summary:In an online decision problem, one makes decisions often with a pool ofdecision sequence called experts but without knowledge of the future. Aftereach step, one pays a cost based on the decision and observed rate. Onereasonal goal would be to perform as well as the best expert in the pool. Themodern and well-known way to attain this goal is the algorithm of exponentialweighting. However, recently, another algorithm called follow the perturbedleader is developed and achieved about the same performance. In our work, wefirst show the properties shared in common by the two algorithms which explainthe similarities on the performance. Next we will show that for a specificperturbation, the two algorithms are identical. Finally, we show with someexamples that follow-the-leader style algorithms extend naturally to a largeclass of structured online problems for which the exponential algorithms areinefficient.
arxiv-15300-83 | News Across Languages - Cross-Lingual Document Similarity and Event Tracking | http://arxiv.org/pdf/1512.07046v1.pdf | author:Jan Rupnik, Andrej Muhic, Gregor Leban, Primoz Skraba, Blaz Fortuna, Marko Grobelnik category:cs.IR cs.CL published:2015-12-22 summary:In today's world, we follow news which is distributed globally. Significantevents are reported by different sources and in different languages. In thiswork, we address the problem of tracking of events in a large multilingualstream. Within a recently developed system Event Registry we examine twoaspects of this problem: how to compare articles in different languages and howto link collections of articles in different languages which refer to the sameevent. Taking a multilingual stream and clusters of articles from eachlanguage, we compare different cross-lingual document similarity measures basedon Wikipedia. This allows us to compute the similarity of any two articlesregardless of language. Building on previous work, we show there are methodswhich scale well and can compute a meaningful similarity between articles fromlanguages with little or no direct overlap in the training data. Using thiscapability, we then propose an approach to link clusters of articles acrosslanguages which represent the same event. We provide an extensive evaluation ofthe system as a whole, as well as an evaluation of the quality and robustnessof the similarity measure and the linking algorithm.
arxiv-15300-84 | Implementation of deep learning algorithm for automatic detection of brain tumors using intraoperative IR-thermal mapping data | http://arxiv.org/pdf/1512.07041v1.pdf | author:A. V. Makarenko, M. G. Volovik category:cs.CV cs.LG q-bio.QM stat.ML published:2015-12-22 summary:The efficiency of deep machine learning for automatic delineation of tumorareas has been demonstrated for intraoperative neuronavigation using activeIR-mapping with the use of the cold test. The proposed approach employs amatrix IR-imager to remotely register the space-time distribution of surfacetemperature pattern, which is determined by the dynamics of local cerebralblood flow. The advantages of this technique are non-invasiveness, zero risksfor the health of patients and medical staff, low implementation andoperational costs, ease and speed of use. Traditional IR-diagnostic techniquehas a crucial limitation - it involves a diagnostician who determines theboundaries of tumor areas, which gives rise to considerable uncertainty, whichcan lead to diagnosis errors that are difficult to control. The current studydemonstrates that implementing deep learning algorithms allows to eliminate theexplained drawback.
arxiv-15300-85 | Deep Learning with S-shaped Rectified Linear Activation Units | http://arxiv.org/pdf/1512.07030v1.pdf | author:Xiaojie Jin, Chunyan Xu, Jiashi Feng, Yunchao Wei, Junjun Xiong, Shuicheng Yan category:cs.CV published:2015-12-22 summary:Rectified linear activation units are important components forstate-of-the-art deep convolutional networks. In this paper, we propose a novelS-shaped rectified linear activation unit (SReLU) to learn both convex andnon-convex functions, imitating the multiple function forms given by the twofundamental laws, namely the Webner-Fechner law and the Stevens law, inpsychophysics and neural sciences. Specifically, SReLU consists of threepiecewise linear functions, which are formulated by four learnable parameters.The SReLU is learned jointly with the training of the whole deep networkthrough back propagation. During the training phase, to initialize SReLU indifferent layers, we propose a "freezing" method to degenerate SReLU into apredefined leaky rectified linear unit in the initial several training epochsand then adaptively learn the good initial values. SReLU can be universallyused in the existing deep networks with negligible additional parameters andcomputation cost. Experiments with two popular CNN architectures, Network inNetwork and GoogLeNet on scale-various benchmarks including CIFAR10, CIFAR100,MNIST and ImageNet demonstrate that SReLU achieves remarkable improvementcompared to other activation functions.
arxiv-15300-86 | Deep Learning for Surface Material Classification Using Haptic And Visual Information | http://arxiv.org/pdf/1512.06658v2.pdf | author:Haitian Zheng, Lu Fang, Mengqi Ji, Matti Strese, Yigitcan Ozer, Eckehard Steinbach category:cs.RO cs.CV cs.LG published:2015-12-21 summary:When a user scratches a hand-held rigid tool across an object surface, anacceleration signal can be captured, which carries relevant information aboutthe surface. More importantly, such a haptic signal is complementary to thevisual appearance of the surface, which suggests the combination of bothmodalities for the recognition of the surface material. In this paper, wepresent a novel deep learning method dealing with the surface materialclassification problem based on a Fully Convolutional Network (FCN), whichtakes as input the aforementioned acceleration signal and a corresponding imageof the surface texture. Compared to previous surface material classificationsolutions, which rely on a careful design of hand-crafted domain-specificfeatures, our method automatically extracts discriminative features utilizingthe advanced deep learning methodologies. Experiments performed on the TUMsurface material database demonstrate that our method achieves state-of-the-artclassification accuracy robustly and efficiently.
arxiv-15300-87 | Harnessing the Deep Net Object Models for Enhancing Human Action Recognition | http://arxiv.org/pdf/1512.06498v2.pdf | author:O. V. Ramana Murthy, Roland Goecke category:cs.CV published:2015-12-21 summary:In this study, the influence of objects is investigated in the scenario ofhuman action recognition with large number of classes. We hypothesize that theobjects the humans are interacting will have good say in determining the actionbeing performed. Especially, if the objects are non-moving, such as objectsappearing in the background, features such as spatio-temporal interest points,dense trajectories may fail to detect them. Hence we propose to detect objectsusing pre-trained object detectors in every frame statically. Trained Deepnetwork models are used as object detectors. Information from different layersin conjunction with different encoding techniques is extensively studied toobtain the richest feature vectors. This technique is observed to yieldstate-of-the-art performance on HMDB51 and UCF101 datasets.
arxiv-15300-88 | GraphConnect: A Regularization Framework for Neural Networks | http://arxiv.org/pdf/1512.06757v2.pdf | author:Jiaji Huang, Qiang Qiu, Robert Calderbank, Guillermo Sapiro category:cs.CV cs.LG cs.NE published:2015-12-21 summary:Deep neural networks have proved very successful in domains where largetraining sets are available, but when the number of training samples is small,their performance suffers from overfitting. Prior methods of reducingoverfitting such as weight decay, Dropout and DropConnect are data-independent.This paper proposes a new method, GraphConnect, that is data-dependent, and ismotivated by the observation that data of interest lie close to a manifold. Thenew method encourages the relationships between the learned decisions toresemble a graph representing the manifold structure. Essentially GraphConnectis designed to learn attributes that are present in data samples in contrast toweight decay, Dropout and DropConnect which are simply designed to make it moredifficult to fit to random error or noise. Empirical Rademacher complexity isused to connect the generalization error of the neural network to spectralproperties of the graph learned from the input data. This framework is used toshow that GraphConnect is superior to weight decay. Experimental results onseveral benchmark datasets validate the theoretical analysis, and show thatwhen the number of training samples is small, GraphConnect is able tosignificantly improve performance over weight decay.
arxiv-15300-89 | On Distributed Cooperative Decision-Making in Multiarmed Bandits | http://arxiv.org/pdf/1512.06888v2.pdf | author:Peter Landgren, Vaibhav Srivastava, Naomi Ehrich Leonard category:cs.SY cs.MA math.OC stat.ML published:2015-12-21 summary:We study the explore-exploit tradeoff in distributed cooperativedecision-making using the context of the multiarmed bandit (MAB) problem. Forthe distributed cooperative MAB problem, we design the cooperative UCBalgorithm that comprises two interleaved distributed processes: (i) runningconsensus algorithms for estimation of rewards, and (ii)upper-confidence-bound-based heuristics for selection of arms. We rigorouslyanalyze the performance of the cooperative UCB algorithm and characterize theinfluence of communication graph structure on the decision-making performanceof the group.
arxiv-15300-90 | Spatial Phase-Sweep: Increasing temporal resolution of transient imaging using a light source array | http://arxiv.org/pdf/1512.06539v1.pdf | author:Ryuichi Tadano, Adithya Kumar Pediredla, Kaushik Mitra, Ashok Veeraraghavan category:cs.CV published:2015-12-21 summary:Transient imaging or light-in-flight techniques capture the propagation of anultra-short pulse of light through a scene, which in effect captures theoptical impulse response of the scene. Recently, it has been shown that we cancapture transient images using commercially available Time-of-Flight (ToF)systems such as Photonic Mixer Devices (PMD). In this paper, we propose`spatial phase-sweep', a technique that exploits the speed of light to increasethe temporal resolution beyond the 100 picosecond limit imposed by currentelectronics. Spatial phase-sweep uses a linear array of light sources withspatial separation of about 3 mm between them, thereby resulting in a timeshift of about 10 picoseconds, which translates into 100 Gfps of transientimaging in theory. We demonstrate a prototype and transient imaging resultsusing spatial phase-sweep.
arxiv-15300-91 | The 2015 Sheffield System for Transcription of Multi-Genre Broadcast Media | http://arxiv.org/pdf/1512.06643v1.pdf | author:Oscar Saz, Mortaza Doulaty, Salil Deena, Rosanna Milner, Raymond W. M. Ng, Madina Hasan, Yulan Liu, Thomas Hain category:cs.CL published:2015-12-21 summary:We describe the University of Sheffield system for participation in the 2015Multi-Genre Broadcast (MGB) challenge task of transcribing multi-genrebroadcast shows. Transcription was one of four tasks proposed in the MGBchallenge, with the aim of advancing the state of the art of automatic speechrecognition, speaker diarisation and automatic alignment of subtitles forbroadcast media. Four topics are investigated in this work: Data selectiontechniques for training with unreliable data, automatic speech segmentation ofbroadcast media shows, acoustic modelling and adaptation in highly variableenvironments, and language modelling of multi-genre shows. The final systemoperates in multiple passes, using an initial unadapted decoding stage torefine segmentation, followed by three adapted passes: a hybrid DNN pass withinput features normalised by speaker-based cepstral normalisation, anotherhybrid stage with input features normalised by speaker feature-MLLRtransformations, and finally a bottleneck-based tandem stage with noise andspeaker factorisation. The combination of these three system outputs provides afinal error rate of 27.5% on the official development set, consisting of 47multi-genre shows.
arxiv-15300-92 | Remote Health Coaching System and Human Motion Data Analysis for Physical Therapy with Microsoft Kinect | http://arxiv.org/pdf/1512.06492v1.pdf | author:Qifei Wang, Gregorij Kurillo, Ferda Ofli, Ruzena Bajcsy category:cs.CV cs.AI published:2015-12-21 summary:This paper summarizes the recent progress we have made for the computervision technologies in physical therapy with the accessible and affordabledevices. We first introduce the remote health coaching system we build withMicrosoft Kinect. Since the motion data captured by Kinect is noisy, weinvestigate the data accuracy of Kinect with respect to the high accuracymotion capture system. We also propose an outlier data removal algorithm basedon the data distribution. In order to generate the kinematic parameter from thenoisy data captured by Kinect, we propose a kinematic filtering algorithm basedon Unscented Kalman Filter and the kinematic model of human skeleton. Theproposed algorithm can obtain smooth kinematic parameter with reduced noisecompared to the kinematic parameter generated from the raw motion data fromKinect.
arxiv-15300-93 | Backward and Forward Language Modeling for Constrained Sentence Generation | http://arxiv.org/pdf/1512.06612v2.pdf | author:Lili Mou, Rui Yan, Ge Li, Lu Zhang, Zhi Jin category:cs.CL cs.LG cs.NE published:2015-12-21 summary:Recent language models, especially those based on recurrent neural networks(RNNs), make it possible to generate natural language from a learnedprobability. Language generation has wide applications including machinetranslation, summarization, question answering, conversation systems, etc.Existing methods typically learn a joint probability of words conditioned onadditional information, which is (either statically or dynamically) fed toRNN's hidden layer. In many applications, we are likely to impose hardconstraints on the generated texts, i.e., a particular word must appear in thesentence. Unfortunately, existing approaches could not solve this problem. Inthis paper, we propose a novel backward and forward language model. Provided aspecific word, we use RNNs to generate previous words and future words, eithersimultaneously or asynchronously, resulting in two model variants. In this way,the given word could appear at any position in the sentence. Experimentalresults show that the generated texts are comparable to sequential LMs inquality.
arxiv-15300-94 | Sparse Coding with Fast Image Alignment via Large Displacement Optical Flow | http://arxiv.org/pdf/1512.06709v1.pdf | author:Xiaoxia Sun, Nasser M. Nasrabadi, Trac D. Tran category:cs.CV published:2015-12-21 summary:Sparse representation-based classifiers have shown outstanding accuracy androbustness in image classification tasks even with the presence of intensenoise and occlusion. However, it has been discovered that the performancedegrades significantly either when test image is not aligned with thedictionary atoms or the dictionary atoms themselves are not aligned with eachother, in which cases the sparse linear representation assumption fails. Inthis paper, having both training and test images misaligned, we introduce anovel sparse coding framework that is able to efficiently adapt the dictionaryatoms to the test image via large displacement optical flow. In the proposedalgorithm, every dictionary atom is automatically aligned with the input imageand the sparse code is then recovered using the adapted dictionary atoms. Acorresponding supervised dictionary learning algorithm is also developed forthe proposed framework. Experimental results on digit datasets recognitionverify the efficacy and robustness of the proposed algorithm.
arxiv-15300-95 | Beyond Classification: Latent User Interests Profiling from Visual Contents Analysis | http://arxiv.org/pdf/1512.06785v1.pdf | author:Longqi Yang, Cheng-Kang Hsieh, Deborah Estrin category:cs.IR cs.CV cs.SI published:2015-12-21 summary:User preference profiling is an important task in modern online socialnetworks (OSN). With the proliferation of image-centric social platforms, suchas Pinterest, visual contents have become one of the most informative datastreams for understanding user preferences. Traditional approaches usuallytreat visual content analysis as a general classification problem where one ormore labels are assigned to each image. Although such an approach simplifiesthe process of image analysis, it misses the rich context and visual cues thatplay an important role in people's perception of images. In this paper, weexplore the possibilities of learning a user's latent visual preferencesdirectly from image contents. We propose a distance metric learning methodbased on Deep Convolutional Neural Networks (CNN) to directly extractsimilarity information from visual contents and use the derived distance metricto mine individual users' fine-grained visual preferences. Through ourpreliminary experiments using data from 5,790 Pinterest users, we show thateven for the images within the same category, each user possesses distinct andindividually-identifiable visual preferences that are consistent over theirlifetime. Our results underscore the untapped potential of finer-grained visualpreference profiling in understanding users' preferences.
arxiv-15300-96 | Information-Theoretic Bounded Rationality | http://arxiv.org/pdf/1512.06789v1.pdf | author:Pedro A. Ortega, Daniel A. Braun, Justin Dyer, Kee-Eung Kim, Naftali Tishby category:stat.ML cs.AI cs.SY math.OC published:2015-12-21 summary:Bounded rationality, that is, decision-making and planning under resourcelimitations, is widely regarded as an important open problem in artificialintelligence, reinforcement learning, computational neuroscience and economics.This paper offers a consolidated presentation of a theory of boundedrationality based on information-theoretic ideas. We provide a conceptualjustification for using the free energy functional as the objective functionfor characterizing bounded-rational decisions. This functional possesses threecrucial properties: it controls the size of the solution space; it has MonteCarlo planners that are exact, yet bypass the need for exhaustive search; andit captures model uncertainty arising from lack of evidence or from interactingwith other agents having unknown intentions. We discuss the single-stepdecision-making case, and show how to extend it to sequential decisions usingequivalence transformations. This extension yields a very general class ofdecision problems that encompass classical decision rules (e.g. EXPECTIMAX andMINIMAX) as limit cases, as well as trust- and risk-sensitive planning.
arxiv-15300-97 | Multilinear Subspace Clustering | http://arxiv.org/pdf/1512.06730v1.pdf | author:Eric Kernfeld, Nathan Majumder, Shuchin Aeron, Misha Kilmer category:cs.IT cs.CV cs.LG math.IT stat.ML published:2015-12-21 summary:In this paper we present a new model and an algorithm for unsupervisedclustering of 2-D data such as images. We assume that the data comes from aunion of multilinear subspaces (UOMS) model, which is a specific structuredcase of the much studied union of subspaces (UOS) model. For segmentation underthis model, we develop Multilinear Subspace Clustering (MSC) algorithm andevaluate its performance on the YaleB and Olivietti image data sets. We showthat MSC is highly competitive with existing algorithms employing the UOS modelin terms of clustering performance while enjoying improvement in computationalcomplexity.
arxiv-15300-98 | Quantized Convolutional Neural Networks for Mobile Devices | http://arxiv.org/pdf/1512.06473v3.pdf | author:Jiaxiang Wu, Cong Leng, Yuhang Wang, Qinghao Hu, Jian Cheng category:cs.CV published:2015-12-21 summary:Recently, convolutional neural networks (CNN) have demonstrated impressiveperformance in various computer vision tasks. However, high performancehardware is typically indispensable for the application of CNN models due tothe high computation complexity, which prohibits their further extensions. Inthis paper, we propose an efficient framework, namely Quantized CNN, tosimultaneously speed-up the computation and reduce the storage and memoryoverhead of CNN models. Both filter kernels in convolutional layers andweighting matrices in fully-connected layers are quantized, aiming atminimizing the estimation error of each layer's response. Extensive experimentson the ILSVRC-12 benchmark demonstrate 4~6x speed-up and 15~20x compressionwith merely one percentage loss of classification accuracy. With our quantizedCNN model, even mobile devices can accurately classify images within onesecond.
arxiv-15300-99 | Local and global gestalt laws: A neurally based spectral approach | http://arxiv.org/pdf/1512.06566v1.pdf | author:Marta Favali, Giovanna Citti, Alessandro Sarti category:cs.CV published:2015-12-21 summary:A mathematical model of figure-ground articulation is presented, taking intoaccount both local and global gestalt laws. The model is compatible with thefunctional architecture of the primary visual cortex (V1). Particularly thelocal gestalt law of good continuity is described by means of suitableconnectivity kernels, that are derived from Lie group theory and are neurallyimplemented in long range connectivity in V1. Different kernels are compatiblewith the geometric structure of cortical connectivity and they are derived asthe fundamental solutions of the Fokker Planck, the Sub-Riemannian Laplacianand the isotropic Laplacian equations. The kernels are used to constructmatrices of connectivity among the features present in a visual stimulus.Global gestalt constraints are then introduced in terms of spectral analysis ofthe connectivity matrix, showing that this processing can be corticallyimplemented in V1 by mean field neural equations. This analysis performsgrouping of local features and individuates perceptual units with the highestsaliency. Numerical simulations are performed and results are obtained applyingthe technique to a number of stimuli.
arxiv-15300-100 | Predicting the Co-Evolution of Event and Knowledge Graphs | http://arxiv.org/pdf/1512.06900v1.pdf | author:CristÃ³bal Esteban, Volker Tresp, Yinchong Yang, Stephan Baier, Denis KrompaÃ category:cs.LG published:2015-12-21 summary:Embedding learning, a.k.a. representation learning, has been shown to be ableto model large-scale semantic knowledge graphs. A key concept is a mapping ofthe knowledge graph to a tensor representation whose entries are predicted bymodels using latent representations of generalized entities. Knowledge graphsare typically treated as static: A knowledge graph grows more links when morefacts become available but the ground truth values associated with links isconsidered time invariant. In this paper we address the issue of knowledgegraphs where triple states depend on time. We assume that changes in theknowledge graph always arrive in form of events, in the sense that the eventsare the gateway to the knowledge graph. We train an event prediction modelwhich uses both knowledge graph background information and information onrecent events. By predicting future events, we also predict likely changes inthe knowledge graph and thus obtain a model for the evolution of the knowledgegraph as well. Our experiments demonstrate that our approach performs well in aclinical application, a recommendation engine and a sensor network application.
arxiv-15300-101 | Analysis of Vessel Connectivities in Retinal Images by Cortically Inspired Spectral Clustering | http://arxiv.org/pdf/1512.06559v1.pdf | author:Marta Favali, Samaneh Abbasi-Sureshjani, Bart ter Haar Romeny, Alessandro Sarti category:cs.CV published:2015-12-21 summary:Retinal images provide early signs of diabetic retinopathy, glaucoma andhypertension. These signs can be investigated based on microaneurysms orsmaller vessels. The diagnostic biomarkers are the change of vessel widths andangles especially at junctions, which are investigated using the vesselsegmentation or tracking. Vessel paths may also be interrupted, crossings andbifurcations may be disconnected. This paper addresses a novel contextualmethod based on the geometry of the primary visual cortex (V1) to study thesedifficulties. We have analysed the specific problems at junctions with aconnectivity kernel obtained as the fundamental solution of the Fokker-Planckequation, which is usually used to represent the geometrical structure ofmulti-orientation cortical connectivity. By using the spectral clustering on alarge local affinity matrix constructed by both the connectivity kernel and thefeature of intensity, the vessels are identified successfully in a hierarchicaltopology each representing an individual perceptual unit.
arxiv-15300-102 | Instance-Level Segmentation for Autonomous Driving with Deep Densely Connected MRFs | http://arxiv.org/pdf/1512.06735v2.pdf | author:Ziyu Zhang, Sanja Fidler, Raquel Urtasun category:cs.CV published:2015-12-21 summary:Our aim is to provide a pixel-wise instance-level labeling of a monocularimage in the context of autonomous driving. We build on recent work [Zhang etal., ICCV15] that trained a convolutional neural net to predict instancelabeling in local image patches, extracted exhaustively in a stride from animage. A simple Markov random field model using several heuristics was thenproposed in [Zhang et al., ICCV15] to derive a globally consistent instancelabeling of the image. In this paper, we formulate the global labeling problemwith a novel densely connected Markov random field and show how to encodevarious intuitive potentials in a way that is amenable to efficient mean fieldinference [Kr\"ahenb\"uhl et al., NIPS11]. Our potentials encode thecompatibility between the global labeling and the patch-level predictions,contrast-sensitive smoothness as well as the fact that separate regions formdifferent instances. Our experiments on the challenging KITTI benchmark [Geigeret al., CVPR12] demonstrate that our method achieves a significant performanceboost over the baseline [Zhang et al., ICCV15].
arxiv-15300-103 | Car Segmentation and Pose Estimation using 3D Object Models | http://arxiv.org/pdf/1512.06790v1.pdf | author:Siddharth Mahendran, RenÃ© Vidal category:cs.CV published:2015-12-21 summary:Image segmentation and 3D pose estimation are two key cogs in any algorithmfor scene understanding. However, state-of-the-art CRF-based models for imagesegmentation rely mostly on 2D object models to construct top-down high-orderpotentials. In this paper, we propose new top-down potentials for imagesegmentation and pose estimation based on the shape and volume of a 3D objectmodel. We show that these complex top-down potentials can be easily decomposedinto standard forms for efficient inference in both the segmentation and poseestimation tasks. Experiments on a car dataset show that knowledge ofsegmentation helps perform pose estimation better and vice versa.
arxiv-15300-104 | ATD: Anomalous Topic Discovery in High Dimensional Discrete Data | http://arxiv.org/pdf/1512.06452v2.pdf | author:Hossein Soleimani, David J. Miller category:stat.ML cs.LG published:2015-12-20 summary:We propose an algorithm for detecting patterns exhibited by anomalousclusters in high dimensional discrete data. Unlike most anomaly detection (AD)methods, which detect individual anomalies, our proposed method detects groups(clusters) of anomalies; i.e. sets of points which collectively exhibitabnormal patterns. In many applications this can lead to better understandingof the nature of the atypical behavior and to identifying the sources of theanomalies. Moreover, we consider the case where the atypical patterns exhibiton only a small (salient) subset of the very high dimensional feature space.Individual AD techniques and techniques that detect anomalies using all thefeatures typically fail to detect such anomalies, but our method can detectsuch instances collectively, discover the shared anomalous patterns exhibitedby them, and identify the subsets of salient features. In this paper, we focuson detecting anomalous topics in a batch of text documents, developing ouralgorithm based on topic models. Results of our experiments show that ourmethod can accurately detect anomalous topics and salient features (words)under each such topic in a synthetic data set and two real-world text corporaand achieves better performance compared to both standard group AD andindividual AD techniques. All required code to reproduce our experiments isavailable from https://github.com/hsoleimani/ATD
arxiv-15300-105 | Kernel principal component analysis network for image classification | http://arxiv.org/pdf/1512.06337v1.pdf | author:Dan Wu, Jiasong Wu, Rui Zeng, Longyu Jiang, Lotfi Senhadji, Huazhong Shu category:cs.LG cs.CV published:2015-12-20 summary:In order to classify the nonlinear feature with linear classifier and improvethe classification accuracy, a deep learning network named kernel principalcomponent analysis network (KPCANet) is proposed. First, mapping the data intohigher space with kernel principal component analysis to make the data linearlyseparable. Then building a two-layer KPCANet to obtain the principal componentsof image. Finally, classifying the principal components with linearlyclassifier. Experimental results show that the proposed KPCANet is effective inface recognition, object recognition and hand-writing digits recognition, italso outperforms principal component analysis network (PCANet) generally aswell. Besides, KPCANet is invariant to illumination and stable to occlusion andslight deformation.
arxiv-15300-106 | Revisiting Differentially Private Regression: Lessons From Learning Theory and their Consequences | http://arxiv.org/pdf/1512.06388v1.pdf | author:Xi Wu, Matthew Fredrikson, Wentao Wu, Somesh Jha, Jeffrey F. Naughton category:cs.CR cs.DB cs.LG published:2015-12-20 summary:Private regression has received attention from both database and securitycommunities. Recent work by Fredrikson et al. (USENIX Security 2014) analyzedthe functional mechanism (Zhang et al. VLDB 2012) for training linearregression models over medical data. Unfortunately, they found that modelaccuracy is already unacceptable with differential privacy when $\varepsilon =5$. We address this issue, presenting an explicit connection betweendifferential privacy and stable learning theory through which a substantiallybetter privacy/utility tradeoff can be obtained. Perhaps more importantly, ourtheory reveals that the most basic mechanism in differential privacy, outputperturbation, can be used to obtain a better tradeoff for allconvex-Lipschitz-bounded learning tasks. Since output perturbation is simple toimplement, it means that our approach is potentially widely applicable inpractice. We go on to apply it on the same medical data as used by Fredriksonet al. Encouragingly, we achieve accurate models even for $\varepsilon = 0.1$.In the last part of this paper, we study the impact of our improveddifferentially private mechanisms on model inversion attacks, a privacy attackintroduced by Fredrikson et al. We observe that the improved tradeoff makes theresulting differentially private model more susceptible to inversion attacks.We analyze this phenomenon formally.
arxiv-15300-107 | Behavioral Modeling for Churn Prediction: Early Indicators and Accurate Predictors of Custom Defection and Loyalty | http://arxiv.org/pdf/1512.06430v1.pdf | author:Muhammad R. Khan, Johua Manoj, Anikate Singh, Joshua Blumenstock category:cs.LG published:2015-12-20 summary:Churn prediction, or the task of identifying customers who are likely todiscontinue use of a service, is an important and lucrative concern of firms inmany different industries. As these firms collect an increasing amount oflarge-scale, heterogeneous data on the characteristics and behaviors ofcustomers, new methods become possible for predicting churn. In this paper, wepresent a unified analytic framework for detecting the early warning signs ofchurn, and assigning a "Churn Score" to each customer that indicates thelikelihood that the particular individual will churn within a predefined amountof time. This framework employs a brute force approach to feature engineering,then winnows the set of relevant attributes via feature selection, beforefeeding the final feature-set into a suite of supervised learning algorithms.Using several terabytes of data from a large mobile phone network, our methodidentifies several intuitive - and a few surprising - early warning signs ofchurn, and our best model predicts whether a subscriber will churn with 89.4%accuracy.
arxiv-15300-108 | Discriminative Subnetworks with Regularized Spectral Learning for Global-state Network Data | http://arxiv.org/pdf/1512.06173v1.pdf | author:Xuan Hong Dang, Ambuj K. Singh, Petko Bogdanov, Hongyuan You, Bayyuan Hsu category:cs.LG published:2015-12-19 summary:Data mining practitioners are facing challenges from data with networkstructure. In this paper, we address a specific class of global-state networkswhich comprises of a set of network instances sharing a similar structure yethaving different values at local nodes. Each instance is associated with aglobal state which indicates the occurrence of an event. The objective is touncover a small set of discriminative subnetworks that can optimally classifyglobal network values. Unlike most existing studies which explore anexponential subnetwork space, we address this difficult problem by adopting aspace transformation approach. Specifically, we present an algorithm thatoptimizes a constrained dual-objective function to learn a low-dimensionalsubspace that is capable of discriminating networks labelled by differentglobal states, while reconciling with common network topology sharing acrossinstances. Our algorithm takes an appealing approach from spectral graphlearning and we show that the globally optimum solution can be achieved viamatrix eigen-decomposition.
arxiv-15300-109 | Poseidon: A System Architecture for Efficient GPU-based Deep Learning on Multiple Machines | http://arxiv.org/pdf/1512.06216v1.pdf | author:Hao Zhang, Zhiting Hu, Jinliang Wei, Pengtao Xie, Gunhee Kim, Qirong Ho, Eric Xing category:cs.LG cs.CV cs.DC published:2015-12-19 summary:Deep learning (DL) has achieved notable successes in many machine learningtasks. A number of frameworks have been developed to expedite the process ofdesigning and training deep neural networks (DNNs), such as Caffe, Torch andTheano. Currently they can harness multiple GPUs on a single machine, but areunable to use GPUs that are distributed across multiple machines; as evenaverage-sized DNNs can take days to train on a single GPU with 100s of GBs toTBs of data, distributed GPUs present a prime opportunity for scaling up DL.However, the limited bandwidth available on commodity Ethernet networkspresents a bottleneck to distributed GPU training, and prevents its trivialrealization. To investigate how to adapt existing frameworks to efficiently supportdistributed GPUs, we propose Poseidon, a scalable system architecture fordistributed inter-machine communication in existing DL frameworks. We integratePoseidon with Caffe and evaluate its performance at training DNNs for objectrecognition. Poseidon features three key contributions that accelerate DNNtraining on clusters: (1) a three-level hybrid architecture that allowsPoseidon to support both CPU-only and GPU-equipped clusters, (2) a distributedwait-free backpropagation (DWBP) algorithm to improve GPU utilization and tobalance communication, and (3) a structure-aware communication protocol (SACP)to minimize communication overheads. We empirically show that Poseidonconverges to same objectives as a single machine, and achieves state-of-arttraining speedup across multiple models and well-established datasets using acommodity GPU cluster of 8 nodes (e.g. 4.5x speedup on AlexNet, 4x onGoogLeNet, 4x on CIFAR-10). On the much larger ImageNet22K dataset, Poseidonwith 8 nodes achieves better speedup and competitive accuracy to recentCPU-based distributed systems such as Adam and Le et al., which use 10s to1000s of nodes.
arxiv-15300-110 | Regularized Estimation of Piecewise Constant Gaussian Graphical Models: The Group-Fused Graphical Lasso | http://arxiv.org/pdf/1512.06171v1.pdf | author:Alexander J. Gibberd, James D. B. Nelson category:stat.ME stat.CO stat.ML published:2015-12-19 summary:The time-evolving precision matrix of a piecewise-constant Gaussian graphicalmodel encodes the dynamic conditional dependency structure of a multivariatetime-series. Traditionally, graphical models are estimated under the assumptionthat data is drawn identically from a generating distribution. Introducingsparsity and sparse-difference inducing priors we relax these assumptions andpropose a novel regularized M-estimator to jointly estimate both the graph andchangepoint structure. The resulting estimator possesses the ability totherefore favor sparse dependency structures and/or smoothly evolving graphstructures, as required. Moreover, our approach extends current methods toallow estimation of changepoints that are grouped across multiple dependenciesin a system. An efficient algorithm for estimating structure is proposed. Westudy the empirical recovery properties in a synthetic setting. The qualitativeeffect of grouped changepoint estimation is then demonstrated by applying themethod on two real-world data-sets.
arxiv-15300-111 | A new robust adaptive algorithm for underwater acoustic channel equalization | http://arxiv.org/pdf/1512.06222v1.pdf | author:Dariush Kari, Muhammed Omer Sayin, Suleyman Serdar Kozat category:cs.SD cs.IT cs.LG math.IT published:2015-12-19 summary:We introduce a novel family of adaptive robust equalizers for highlychallenging underwater acoustic (UWA) channel equalization. Since theunderwater environment is highly non-stationary and subjected to impulsivenoise, we use adaptive filtering techniques based on a relative logarithmiccost function inspired by the competitive methods from the online learningliterature. To improve the convergence performance of the conventional linearequalization methods, while mitigating the stability issues, we intrinsicallycombine different norms of the error in the cost function, using logarithmicfunctions. Hence, we achieve a comparable convergence performance to least meanfourth (LMF) equalizer, while significantly enhancing the stability performancein such an adverse communication medium. We demonstrate the performance of ouralgorithms through highly realistic experiments performed on accuratelysimulated underwater acoustic channels.
arxiv-15300-112 | Neutro-Connectedness Cut | http://arxiv.org/pdf/1512.06285v1.pdf | author:Min Xian, Yingtao Zhang, H. D. Cheng, Fei Xu, Jianrui Ding category:cs.CV published:2015-12-19 summary:Interactive image segmentation is a challenging task and received increasingattention recently; however, two major drawbacks exist in interactivesegmentation approaches. First, the segmentation performance of ROI-basedmethods is sensitive to the initial ROI: different ROIs may produce resultswith great difference. Second, most seed-based methods need intenseinteractions, and are not applicable in many cases. In this work, we generalizethe Neutro-Connectedness (NC) to be independent of top-down priors of objectsand to model image topology with indeterminacy measurement on image regions,propose a novel method for determining object and background regions, which isapplied to exclude isolated background regions and enforce label consistency,and put forward a hybrid interactive segmentation method, Neutro-ConnectednessCut (NC-Cut), which can overcome the above two problems by utilizing bothpixel-wise appearance information and region-based NC properties. We evaluatethe proposed NC-Cut by employing two image datasets (265 images), anddemonstrate that the proposed approach outperforms state-of-the-art interactiveimage segmentation methods (Grabcut, MILCut, One-Cut, {{GC}_max}^sum and pPBC).
arxiv-15300-113 | Combining patch-based strategies and non-rigid registration-based label fusion methods | http://arxiv.org/pdf/1512.06223v1.pdf | author:Carlos Platero, M. Carmen Tobar category:cs.CV published:2015-12-19 summary:The objective of this study is to develop a patch-based labeling method thatcooperates with a label fusion using non-rigid registrations. We present anovel patch-based label fusion method, whose selected patches and their weightsare calculated from a combination of similarity measures between patches usingintensity-based distances and labeling-based distances, where a previouslabeling of the target image is inferred through a label fusion method usingnon-rigid registrations. These combined similarity measures result in betterselection of the patches, and their weights are more robust, which improves thesegmentation results compared to other label fusion methods, including theconventional patch-based labeling method. To evaluate the performance and therobustness of the proposed label fusion method, we employ two availabledatabases of T1-weighted (T1W) magnetic resonance imaging (MRI) of humanbrains. We compare our approach with other label fusion methods in theautomatic hippocampal segmentation from T1W-MRI. Our label fusion method yields mean Dice coefficients of 0.847 and 0.798 forthe two databases used with mean times of approximately 180 and 320 seconds,respectively. The collaboration between the patch-based labeling method and thelabel fusion using non-rigid registrations is given in the several levels: (a)The pre-selection of the patches in the atlases are improved, (b) The weightsof our selected patches are also more robust, (c) our approach imposesgeometrical restrictions, such as shape priors, and (d) the work-flow is veryefficient. We show that the proposed approach is very competitive with respectto recently reported methods.
arxiv-15300-114 | A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction | http://arxiv.org/pdf/1512.06293v1.pdf | author:Thomas Wiatowski, Helmut BÃ¶lcskei category:cs.IT cs.AI cs.LG math.FA math.IT stat.ML published:2015-12-19 summary:Deep convolutional neural networks have led to breakthrough results inpractical feature extraction applications. The mathematical analysis of suchnetworks was initiated by Mallat, 2012. Specifically, Mallat consideredso-called scattering networks based on semi-discrete shift-invariant waveletframes and modulus non-linearities in each network layer, and provedtranslation invariance (asymptotically in the wavelet scale parameter) anddeformation stability of the corresponding feature extractor. The purpose ofthis paper is to develop Mallat's theory further by allowing for generalconvolution kernels, or in more technical parlance, general semi-discreteshift-invariant frames (including Weyl-Heisenberg, curvelet, shearlet,ridgelet, and wavelet frames) and general Lipschitz-continuous non-linearities(e.g., rectified linear units, shifted logistic sigmoids, hyperbolic tangents,and modulus functions), as well as pooling through sub-sampling, all of whichcan be different in different network layers. The resulting generalized networkenables extraction of significantly wider classes of features than thoseresolved by Mallat's wavelet-modulus scattering network. We prove deformationstability for a larger class of deformations than those considered by Mallat,and we establish a new translation invariance result which is of verticalnature in the sense of the network depth determining the amount of invariance.Moreover, our results establish that deformation stability and verticaltranslation invariance are guaranteed by the network structure per se ratherthan the specific convolution kernels and non-linearities. This offers anexplanation for the tremendous success of deep convolutional neural networks ina wide variety of practical feature extraction applications. The mathematicaltechniques we employ are based on continuous frame theory.
arxiv-15300-115 | Multistage SFM: A Coarse-to-Fine Approach for 3D Reconstruction | http://arxiv.org/pdf/1512.06235v1.pdf | author:Rajvi Shah, Aditya Deshpande, P J Narayanan category:cs.CV published:2015-12-19 summary:Several methods have been proposed for large-scale 3D reconstruction fromlarge, unorganized image collections. A large reconstruction problem istypically divided into multiple components which are reconstructedindependently using structure from motion (SFM) and later merged together.Incremental SFM methods are most popular for the basic structure recovery of asingle component. They are robust and effective but are strictly sequential innature. We present a multistage approach for SFM reconstruction of a singlecomponent that breaks the sequential nature of the incremental SFM methods. Ourapproach begins with quickly building a coarse 3D model using only a fractionof features from given images. The coarse model is then enriched by localizingremaining images and matching and triangulating remaining features insubsequent stages. These stages are made efficient and highly parallel byleveraging the geometry of the coarse model. Our method produces similarquality models as compared to incremental SFM methods while being notably fastand parallel.
arxiv-15300-116 | The Limitations of Optimization from Samples | http://arxiv.org/pdf/1512.06238v2.pdf | author:Eric Balkanski, Aviad Rubinstein, Yaron Singer category:cs.DS cs.DM cs.LG published:2015-12-19 summary:In this paper we consider the following question: can we optimize decisionson models learned from data and be guaranteed that we achieve desirableoutcomes? We formalize this question through a novel framework calledoptimization from samples (OPS). In the OPS framework, we are given sampledvalues of a function drawn from some distribution and the objective is tooptimize the function under some constraint. We show that there are classes of functions which have desirable learnabilityand optimizability guarantees and for which no reasonable approximation foroptimization from samples is achievable. In particular, our main result showsthat even for maximization of coverage functions under a cardinality constraint$k$, there exists a hypothesis class of functions that cannot be approximatedwithin a factor of $n^{-1/4 + \epsilon}$ (for any constant $\epsilon > 0$) ofthe optimal solution, from samples drawn from the uniform distribution over allsets of size at most $k$. In the general case of monotone submodular functions,we show an $n^{-1/3 + \epsilon}$ lower bound and an almost matching$\tilde{\Omega}(n^{-1/3})$-optimization from samples algorithm. On the positiveside, if a monotone subadditive function has bounded curvature we obtaindesirable guarantees. We also show that additive and unit-demand functions canbe optimized from samples to within arbitrarily good precision, and that budgetadditive functions can be optimized from samples to a factor of 1/2.
arxiv-15300-117 | Using machine learning for medium frequency derivative portfolio trading | http://arxiv.org/pdf/1512.06228v1.pdf | author:Abhijit Sharang, Chetan Rao category:q-fin.TR cs.LG stat.ML published:2015-12-19 summary:We use machine learning for designing a medium frequency trading strategy fora portfolio of 5 year and 10 year US Treasury note futures. We formulate thisas a classification problem where we predict the weekly direction of movementof the portfolio using features extracted from a deep belief network trained ontechnical indicators of the portfolio constituents. The experimentation showsthat the resulting pipeline is effective in making a profitable trade.
arxiv-15300-118 | Deformable Distributed Multiple Detector Fusion for Multi-Person Tracking | http://arxiv.org/pdf/1512.05990v1.pdf | author:Andy J Ma, Pong C Yuen, Suchi Saria category:cs.CV published:2015-12-18 summary:This paper addresses fully automated multi-person tracking in complexenvironments with challenging occlusion and extensive pose variations. Oursolution combines multiple detectors for a set of different regions of interest(e.g., full-body and head) for multi-person tracking. The use of multipledetectors leads to fewer miss detections as it is able to exploit thecomplementary strengths of the individual detectors. While the number of falsepositives may increase with the increased number of bounding boxes detectedfrom multiple detectors, we propose to group the detection outputs by boundingbox location and depth information. For robustness to significant posevariations, deformable spatial relationship between detectors are learnt in ourmulti-person tracking system. On RGBD data from a live Intensive Care Unit(ICU), we show that the proposed method significantly improves multi-persontracking performance over state-of-the-art methods.
arxiv-15300-119 | Face Hallucination using Linear Models of Coupled Sparse Support | http://arxiv.org/pdf/1512.06009v1.pdf | author:Reuben Farrugia, Christine Guillemot category:cs.CV published:2015-12-18 summary:Most face super-resolution methods assume that low-resolution andhigh-resolution manifolds have similar local geometrical structure, hence learnlocal models on the lowresolution manifolds (e.g. sparse or locally linearembedding models), which are then applied on the high-resolution manifold.However, the low-resolution manifold is distorted by the oneto-manyrelationship between low- and high- resolution patches. This paper presents amethod which learns linear models based on the local geometrical structure onthe high-resolution manifold rather than on the low-resolution manifold. Forthis, in a first step, the low-resolution patch is used to derive a globallyoptimal estimate of the high-resolution patch. The approximated solution isshown to be close in Euclidean space to the ground-truth but is generallysmooth and lacks the texture details needed by state-ofthe-art facerecognizers. This first estimate allows us to find the support of thehigh-resolution manifold using sparse coding (SC), which are then used assupport for learning a local projection (or upscaling) model between thelow-resolution and the highresolution manifolds using Multivariate RidgeRegression (MRR). Experimental results show that the proposed methodoutperforms six face super-resolution methods in terms of both recognition andquality. These results also reveal that the recognition and quality aresignificantly affected by the method used for stitching all super-resolvedpatches together, where quilting was found to better preserve the texturedetails which helps to achieve higher recognition rates.
arxiv-15300-120 | Can Pretrained Neural Networks Detect Anatomy? | http://arxiv.org/pdf/1512.05986v1.pdf | author:Vlado Menkovski, Zharko Aleksovski, Axel Saalbach, Hannes Nickisch category:cs.CV cs.AI cs.NE published:2015-12-18 summary:Convolutional neural networks demonstrated outstanding empirical results incomputer vision and speech recognition tasks where labeled training data isabundant. In medical imaging, there is a huge variety of possible imagingmodalities and contrasts, where annotated data is usually very scarce. Wepresent two approaches to deal with this challenge. A network pretrained in adifferent domain with abundant data is used as a feature extractor, while asubsequent classifier is trained on a small target dataset; and a deeparchitecture trained with heavy augmentation and equipped with sophisticatedregularization methods. We test the approaches on a corpus of X-ray images todesign an anatomy detection system.
arxiv-15300-121 | Complexity and Approximation of the Fuzzy K-Means Problem | http://arxiv.org/pdf/1512.05947v1.pdf | author:Johannes BlÃ¶mer, Sascha Brauer, Kathrin Bujna category:cs.LG cs.DS published:2015-12-18 summary:The fuzzy $K$-means problem is a generalization of the classical $K$-meansproblem to soft clusterings, i.e. clusterings where each points belongs to eachcluster to some degree. Although popular in practice, prior to this work thefuzzy $K$-means problem has not been studied from a complexity theoretic oralgorithmic perspective. We show that optimal solutions for fuzzy $K$-meanscannot, in general, be expressed by radicals over the input points.Surprisingly, this already holds for very simple inputs in one-dimensionalspace. Hence, one cannot expect to compute optimal solutions exactly. We givethe first $(1+\epsilon)$-approximation algorithms for the fuzzy $K$-meansproblem. First, we present a deterministic approximation algorithm whoseruntime is polynomial in $N$ and linear in the dimension $D$ of the input set,given that $K$ is constant, i.e. a polynomial time approximation algorithmgiven a fixed $K$. We achieve this result by showing that for each softclustering there exists a hard clustering with comparable properties. Second,by using techniques known from coreset constructions for the $K$-means problem,we develop a deterministic approximation algorithm that runs in time almostlinear in $N$ but exponential in the dimension $D$. We complement these resultswith a randomized algorithm which imposes some natural restrictions on theinput set and whose runtime is comparable to some of the most efficientapproximation algorithms for $K$-means, i.e. linear in the number of points andthe dimension, but exponential in the number of clusters.
arxiv-15300-122 | Multiclass Classification of Cervical Cancer Tissues by Hidden Markov Model | http://arxiv.org/pdf/1512.06014v1.pdf | author:Sabyasachi Mukhopadhyay, Sanket Nandan, Indrajit Kurmi category:cs.CV published:2015-12-18 summary:In this paper, we report a hidden Markov model based multiclassclassification of cervical cancer tissues. This model has been validateddirectly over time series generated by the medium refractive index fluctuationsextracted from differential interference contrast images of healthy anddifferent stages of cancer tissues. The method shows promising results formulticlass classification with higher accuracy.
arxiv-15300-123 | Asymptotic Behavior of Mean Partitions in Consensus Clustering | http://arxiv.org/pdf/1512.06061v1.pdf | author:Brijnesh Jain category:cs.LG stat.ML published:2015-12-18 summary:Although consistency is a minimum requirement of any estimator, little isknown about consistency of the mean partition approach in consensus clustering.This contribution studies the asymptotic behavior of mean partitions. We showthat under normal assumptions, the mean partition approach is consistent andasymptotic normal. To derive both results, we represent partitions as points ofsome geometric space, called orbit space. Then we draw on results from thetheory of Fr\'echet means and stochastic programming. The asymptotic propertieshold for continuous extensions of standard cluster criteria (indices). Theresults justify consensus clustering using finite but sufficiently large samplesizes. Furthermore, the orbit space framework provides a mathematicalfoundation for studying further statistical, geometrical, and analyticalproperties of sets of partitions.
arxiv-15300-124 | Morphological Inflection Generation Using Character Sequence to Sequence Learning | http://arxiv.org/pdf/1512.06110v3.pdf | author:Manaal Faruqui, Yulia Tsvetkov, Graham Neubig, Chris Dyer category:cs.CL published:2015-12-18 summary:Morphological inflection generation is the task of generating the inflectedform of a given lemma corresponding to a particular linguistic transformation.We model the problem of inflection generation as a character sequence tosequence learning problem and present a variant of the neural encoder-decodermodel for solving it. Our model is language independent and can be trained inboth supervised and semi-supervised settings. We evaluate our system on sevendatasets of morphologically rich languages and achieve either better orcomparable results to existing state-of-the-art models of inflectiongeneration.
arxiv-15300-125 | Domain Adaptation and Transfer Learning in StochasticNets | http://arxiv.org/pdf/1512.05844v1.pdf | author:Mohammad Javad Shafiee, Parthipan Siva, Paul Fieguth, Alexander Wong category:cs.CV stat.ML published:2015-12-18 summary:Transfer learning is a recent field of machine learning research that aims toresolve the challenge of dealing with insufficient training data in the domainof interest. This is a particular issue with traditional deep neural networkswhere a large amount of training data is needed. Recently, StochasticNets wasproposed to take advantage of sparse connectivity in order to decrease thenumber of parameters that needs to be learned, which in turn may relax trainingdata size requirements. In this paper, we study the efficacy of transferlearning on StochasticNet frameworks. Experimental results show ~7% improvementon StochasticNet performance when the transfer learning is applied in trainingstep.
arxiv-15300-126 | Modeling Colors of Single Attribute Variations with Application to Food Appearance | http://arxiv.org/pdf/1512.06075v1.pdf | author:Yaser Yacoob category:cs.CV published:2015-12-18 summary:This paper considers the intra-image color-space of an object or a scene whenthese are subject to a dominant single-source of variation. The source ofvariation can be intrinsic or extrinsic (i.e., imaging conditions) to theobject. We observe that the quantized colors for such objects typically lie ona planar subspace of RGB, and in some cases linear or polynomial curves on thisplane are effective in capturing these color variations. We also observe thatthe inter-image color sub-spaces are robust as long as drastic illuminationchange is not involved. We illustrate the use of this analysis for: discriminating betweenshading-change and reflectance-change for patches, and object detection,segmentation and recognition based on a single exemplar. We focus on images offood items to illustrate the effectiveness of the proposed approach.
arxiv-15300-127 | Bayesian anti-sparse coding | http://arxiv.org/pdf/1512.06086v1.pdf | author:ClÃ©ment Elvira, Pierre Chainais, Nicolas Dobigeon category:stat.ML stat.ME published:2015-12-18 summary:Sparse representations have proven their efficiency in solving a wide classof inverse problems encountered in signal and image processing. Conversely,enforcing the information to be spread uniformly over representationcoefficients exhibits relevant properties in various applications such asdigital communications. Anti-sparse regularization can be naturally expressedthrough an $\ell_{\infty}$-norm penalty. This paper derives a probabilisticformulation of such representations. A new probability distribution, referredto as the democratic prior, is first introduced. Its main properties as well asthree random variate generators for this distribution are derived. Then thisprobability distribution is used as a prior to promote anti-sparsity in aGaussian linear inverse problem, yielding a fully Bayesian formulation ofanti-sparse coding. Two Markov chain Monte Carlo (MCMC) algorithms are proposedto generate samples according to the posterior distribution. The first one is astandard Gibbs sampler. The second one uses Metropolis-Hastings moves thatexploit the proximity mapping of the log-posterior distribution. These samplesare used to approximate maximum a posteriori and minimum mean square errorestimators of both parameters and hyperparameters. Simulations on syntheticdata illustrate the performances of the two proposed samplers, for bothcomplete and over-complete dictionaries. All results are compared to the recentdeterministic variational FITRA algorithm.
arxiv-15300-128 | A Planning based Framework for Essay Generation | http://arxiv.org/pdf/1512.05919v2.pdf | author:Bing Qin, Duyu Tang, Xinwei Geng, Dandan Ning, Jiahao Liu, Ting Liu category:cs.CL published:2015-12-18 summary:Generating an article automatically with computer program is a challengingtask in artificial intelligence and natural language processing. In this paper,we target at essay generation, which takes as input a topic word in mind andgenerates an organized article under the theme of the topic. We follow the ideaof text planning \cite{Reiter1997} and develop an essay generation framework.The framework consists of three components, including topic understanding,sentence extraction and sentence reordering. For each component, we studiedseveral statistical algorithms and empirically compared between them in termsof qualitative or quantitative analysis. Although we run experiments on Chinesecorpus, the method is language independent and can be easily adapted to otherlanguage. We lay out the remaining challenges and suggest avenues for futureresearch.
arxiv-15300-129 | Expectation propagation for diffusion processes by moment closure approximations | http://arxiv.org/pdf/1512.06098v1.pdf | author:Botond Cseke, David Schnoerr, Manfred Opper, Guido Sanguinetti category:stat.ML published:2015-12-18 summary:We consider the inverse problem of reconstructing the trajectory of adiffusion process from discrete and continuous time (soft) observations. Wecast the problem in a Bayesian framework and derive approximations to theposterior distributions of state space marginals using variational approximateinference. The resulting optimisation algorithm is a hybrid expectationpropagation/variational message passing algorithm. We then show how theapproximation can be extended to a wide class of discrete-state Markovian jumpprocesses by making use of the chemical Langevin equation. Our empiricalresults show that this is a computationally feasible and accurate method toapproach these intractable classes of inverse problems.
arxiv-15300-130 | Deep Poisson Factorization Machines: factor analysis for mapping behaviors in journalist ecosystem | http://arxiv.org/pdf/1512.05840v1.pdf | author:Pau Perng-Hwa Kung category:cs.CY cs.LG stat.ML published:2015-12-18 summary:Newsroom in online ecosystem is difficult to untangle. With prevalence ofsocial media, interactions between journalists and individuals become visible,but lack of understanding to inner processing of information feedback loop inpublic sphere leave most journalists baffled. Can we provide an organized viewto characterize journalist behaviors on individual level to know better of theecosystem? To this end, I propose Poisson Factorization Machine (PFM), aBayesian analogue to matrix factorization that assumes Poisson distribution forgenerative process. The model generalizes recent studies on Poisson MatrixFactorization to account temporal interaction which involves tensor-likestructure, and label information. Two inference procedures are designed, onebased on batch variational EM and another stochastic variational inferencescheme that efficiently scales with data size. An important novelty in thisnote is that I show how to stack layers of PFM to introduce a deeparchitecture. This work discusses some potential results applying the model andexplains how such latent factors may be useful for analyzing latent behaviorsfor data exploration.
arxiv-15300-131 | Relay Backpropagation for Effective Learning of Deep Convolutional Neural Networks | http://arxiv.org/pdf/1512.05830v2.pdf | author:Li Shen, Zhouchen Lin, Qingming Huang category:cs.CV cs.LG published:2015-12-18 summary:Learning deeper convolutional neural networks becomes a tendency in recentyears. However, many empirical evidences suggest that performance improvementcannot be gained by simply stacking more layers. In this paper, we consider theissue from an information theoretical perspective, and propose a novel methodRelay Backpropagation, that encourages the propagation of effective informationthrough the network in training stage. By virtue of the method, we achieved thefirst place in ILSVRC 2015 Scene Classification Challenge. Extensiveexperiments on two challenging large scale datasets demonstrate theeffectiveness of our method is not restricted to a specific dataset or networkarchitecture. Our models will be available to the research community later.
arxiv-15300-132 | Unsupervised Feature Construction for Improving Data Representation and Semantics | http://arxiv.org/pdf/1512.05467v1.pdf | author:Marian-Andrei Rizoiu, Julien Velcin, StÃ©phane Lallich category:cs.AI cs.LG published:2015-12-17 summary:Feature-based format is the main data representation format used by machinelearning algorithms. When the features do not properly describe the initialdata, performance starts to degrade. Some algorithms address this problem byinternally changing the representation space, but the newly-constructedfeatures are rarely comprehensible. We seek to construct, in an unsupervisedway, new features that are more appropriate for describing a given dataset and,at the same time, comprehensible for a human user. We propose two algorithmsthat construct the new features as conjunctions of the initial primitivefeatures or their negations. The generated feature sets have reducedcorrelations between features and succeed in catching some of the hiddenrelations between individuals in a dataset. For example, a feature like $sky\wedge \neg building \wedge panorama$ would be true for non-urban images and ismore informative than simple features expressing the presence or the absence ofan object. The notion of Pareto optimality is used to evaluate feature sets andto obtain a balance between total correlation and the complexity of theresulted feature set. Statistical hypothesis testing is used in order toautomatically determine the values of the parameters used for constructing adata-dependent feature set. We experimentally show that our approaches achievethe construction of informative feature sets for multiple datasets.
arxiv-15300-133 | Towards automating the generation of derivative nouns in Sanskrit by simulating Panini | http://arxiv.org/pdf/1512.05670v2.pdf | author:Amrith Krishna, Pawan Goyal category:cs.CL published:2015-12-17 summary:About 1115 rules in Astadhyayi from A.4.1.76 to A.5.4.160 deal withgeneration of derivative nouns, making it one of the largest topical sectionsin Astadhyayi, called as the Taddhita section owing to the head rule A.4.1.76.This section is a systematic arrangement of rules that enumerates variousaffixes that are used in the derivation under specific semantic relations. Wepropose a system that automates the process of generation of derivative nounsas per the rules in Astadhyayi. The proposed system follows a completely objectoriented approach, that models each rule as a class of its own and then groupsthem as rule groups. The rule groups are decided on the basis of selectivegrouping of rules by virtue of anuvrtti. The grouping of rules results in aninheritance network of rules which is a directed acyclic graph. Every rulegroup has a head rule and the head rule notifies all the direct member rules ofthe group about the environment which contains all the details about dataentities, participating in the derivation process. The system implements thismechanism using multilevel inheritance and observer design patterns. The systemfocuses not only on generation of the desired final form, but also on thecorrectness of sequence of rules applied to make sure that the derivation hastaken place in strict adherence to Astadhyayi. The proposed system's designallows to incorporate various conflict resolution methods mentioned inauthentic texts and hence the effectiveness of those rules can be validatedwith the results from the system. We also present cases where we have checkedthe applicability of the system with the rules which are not specificallyapplicable to derivation of derivative nouns, in order to see the effectivenessof the proposed schema as a generic system for modeling Astadhyayi.
arxiv-15300-134 | Numerical Demultiplexing of Color Image Sensor Measurements via Non-linear Random Forest Modeling | http://arxiv.org/pdf/1512.05421v1.pdf | author:Jason Deglint, Farnoud Kazemzadeh, Daniel Cho, David A. Clausi, Alexander Wong category:cs.CV published:2015-12-17 summary:The simultaneous capture of imaging data at multiple wavelengths across theelectromagnetic spectrum is highly challenging, requiring complex and costlymultispectral image sensors. In this study, we introduce a comprehensiveframework for performing simultaneous multispectral imaging using conventionalimage sensors with color filter arrays via numerical demultiplexing of thecolor image sensor measurements. A numerical forward model characterizing theformation of sensor measurements from light spectra hitting the sensor isconstructed based on a comprehensive spectral characterization of the sensor. Anumerical demultiplexer is then learned via non-linear random forest modelingbased on the forward model. Given the learned numerical demultiplexer, one canthen demultiplex simultaneously-acquired measurements made by the image sensorinto reflectance intensities at discrete selectable wavelengths, resulting in ahigher resolution reflectance spectrum. Simulation and real-world experimentalresults demonstrate the efficacy of such a method for simultaneousmultispectral imaging.
arxiv-15300-135 | Inferring the Causal Direction Privately | http://arxiv.org/pdf/1512.05469v1.pdf | author:Matt J. Kusner, Yu Sun, Karthik Sridharan, Kilian Q. Weinberger category:stat.ML published:2015-12-17 summary:Causal inference deals with identifying which random variables "cause" orcontrol other random variables. Recent advances on the topic of causalinference based on tools from statistical estimation and machine learning haveresulted in practical algorithms for causal inference. Causal inference has thepotential to have significant impact on medical research, prevention andcontrol of diseases and identifying influential factors that impact society toname just a few. However, these promising applications for causal inference areoften ones that involve sensitive or personal data of users that need to bekept private (e.g. medical records, personal finances). Therefore, there is aneed for the development of causal inference methods that preserve dataprivacy. We study the problem of inferring causality using the current, popularcausal inference framework, the additive noise model (ANM) while simultaneouslyensuring privacy of the users. We derive a framework that provides differentialprivacy guarantees for a variety of ANM variants. We run extensive experiments,and demonstrate that our techniques are practical and easy to implement.
arxiv-15300-136 | An Empirical Comparison of Neural Architectures for Reinforcement Learning in Partially Observable Environments | http://arxiv.org/pdf/1512.05509v1.pdf | author:Denis Steckelmacher, Peter Vrancx category:cs.NE cs.AI cs.LG published:2015-12-17 summary:This paper explores the performance of fitted neural Q iteration forreinforcement learning in several partially observable environments, usingthree recurrent neural network architectures: Long Short-Term Memory, GatedRecurrent Unit and MUT1, a recurrent neural architecture evolved from a pool ofseveral thousands candidate architectures. A variant of fitted Q iteration,based on Advantage values instead of Q values, is also explored. The resultsshow that GRU performs significantly better than LSTM and MUT1 for most of theproblems considered, requiring less training episodes and less CPU time beforelearning a very good policy. Advantage learning also tends to produce betterresults.
arxiv-15300-137 | A Survey of Available Corpora for Building Data-Driven Dialogue Systems | http://arxiv.org/pdf/1512.05742v2.pdf | author:Iulian Vlad Serban, Ryan Lowe, Laurent Charlin, Joelle Pineau category:cs.CL cs.AI cs.HC cs.LG stat.ML published:2015-12-17 summary:During the past decade, several areas of speech and language understandinghave witnessed substantial breakthroughs from the use of data-driven models. Inthe area of dialogue systems, the trend is less obvious, and most practicalsystems are still built through significant engineering and expert knowledge.Nevertheless, several recent results suggest that data-driven approaches arefeasible and quite promising. To facilitate research in this area, we havecarried out a wide survey of publicly available datasets suitable fordata-driven learning of dialogue systems. We discuss important characteristicsof these datasets and how they can be used to learn diverse dialoguestrategies. We also describe other potential uses of these datasets, such asmethods for transfer learning between datasets and the use of externalknowledge, and discuss appropriate choice of evaluation metrics for thelearning objective.
arxiv-15300-138 | Reconstruction of Enhanced Ultrasound Images From Compressed Measurements Using Simultaneous Direction Method of Multipliers | http://arxiv.org/pdf/1512.05586v1.pdf | author:Zhouye Chen, Adrian Basarab, Denis KouamÃ© category:cs.CV published:2015-12-17 summary:High resolution ultrasound image reconstruction from a reduced number ofmeasurements is of great interest in ultrasound imaging, since it could enhanceboth the frame rate and image resolution. Compressive deconvolution, combiningcompressed sensing and image deconvolution, represents an interestingpossibility to consider this challenging task. The model of compressivedeconvolution includes, in addition to the compressive sampling matrix, a 2Dconvolution operator carrying the information on the system point spreadfunction. Through this model, the resolution of reconstructed ultrasound imagesfrom compressed measurements mainly depends on three aspects: the acquisitionsetup, i.e. the incoherence of the sampling matrix, the image regularization,i.e. the sparsity prior, and the optimization technique. In this paper, wemainly focused on the last two aspects. We proposed a novel simultaneousdirection method of multipliers-based optimization scheme to invert the linearmodel, including two regularization terms expressing the sparsity of the RFimages in a given basis and the generalized Gaussian statistical assumption ontissue reflectivity functions. The performance of the method is evaluated onboth simulated and in vivo data.
arxiv-15300-139 | Large Scale Business Discovery from Street Level Imagery | http://arxiv.org/pdf/1512.05430v2.pdf | author:Qian Yu, Christian Szegedy, Martin C. Stumpe, Liron Yatziv, Vinay Shet, Julian Ibarz, Sacha Arnoud category:cs.CV published:2015-12-17 summary:Search with local intent is becoming increasingly useful due to thepopularity of the mobile device. The creation and maintenance of accuratelistings of local businesses worldwide is time consuming and expensive. In thispaper, we propose an approach to automatically discover businesses that arevisible on street level imagery. Precise business store front detection enablesaccurate geo-location of businesses, and further provides input for businesscategorization, listing generation, etc. The large variety of businesscategories in different countries makes this a very challenging problem.Moreover, manual annotation is prohibitive due to the scale of this problem. Wepropose the use of a MultiBox based approach that takes input image pixels anddirectly outputs store front bounding boxes. This end-to-end learning approachinstead preempts the need for hand modeling either the proposal generationphase or the post-processing phase, leveraging large labelled trainingdatasets. We demonstrate our approach outperforms the state of the artdetection techniques with a large margin in terms of performance and run-timeefficiency. In the evaluation, we show this approach achieves human accuracy inthe low-recall settings. We also provide an end-to-end evaluation of businessdiscovery in the real world.
arxiv-15300-140 | Classification of weak multi-view signals by sharing factors in a mixture of Bayesian group factor analyzers | http://arxiv.org/pdf/1512.05610v1.pdf | author:Sami Remes, Tommi Mononen, Samuel Kaski category:stat.ML published:2015-12-17 summary:We propose a novel classification model for weak signal data, building upon arecent model for Bayesian multi-view learning, Group Factor Analysis (GFA).Instead of assuming all data to come from a single GFA model, we allow latentclusters, each having a different GFA model and producing a different classdistribution. We show that sharing information across the clusters, by sharingfactors, increases the classification accuracy considerably; the shared factorsessentially form a flexible noise model that explains away the part of data notrelated to classification. Motivation for the setting comes from single-trialfunctional brain imaging data, having a very low signal-to-noise ratio and anatural multi-view setting, with the different sensors, measurement modalities(EEG, MEG, fMRI) and possible auxiliary information as views. We demonstrateour model on a MEG dataset.
arxiv-15300-141 | Deep-Spying: Spying using Smartwatch and Deep Learning | http://arxiv.org/pdf/1512.05616v1.pdf | author:Tony Beltramelli, Sebastian Risi category:cs.CR cs.CY cs.LG published:2015-12-17 summary:Wearable technologies are today on the rise, becoming more common and broadlyavailable to mainstream users. In fact, wristband and armband devices such assmartwatches and fitness trackers already took an important place in theconsumer electronics market and are becoming ubiquitous. By their very natureof being wearable, these devices, however, provide a new pervasive attacksurface threatening users privacy, among others. In the meantime, advances in machine learning are providing unprecedentedpossibilities to process complex data efficiently. Allowing patterns to emergefrom high dimensional unavoidably noisy data. The goal of this work is to raise awareness about the potential risks relatedto motion sensors built-in wearable devices and to demonstrate abuseopportunities leveraged by advanced neural network architectures. The LSTM-based implementation presented in this research can performtouchlogging and keylogging on 12-keys keypads with above-average accuracy evenwhen confronted with raw unprocessed data. Thus demonstrating that deep neuralnetworks are capable of making keystroke inference attacks based on motionsensors easier to achieve by removing the need for non-trivial pre-processingpipelines and carefully engineered feature extraction strategies. Our resultssuggest that the complete technological ecosystem of a user can be compromisedwhen a wearable wristband device is worn.
arxiv-15300-142 | Semi-supervised Question Retrieval with Gated Convolutions | http://arxiv.org/pdf/1512.05726v2.pdf | author:Tao Lei, Hrishikesh Joshi, Regina Barzilay, Tommi Jaakkola, Katerina Tymoshenko, Alessandro Moschitti, Lluis Marquez category:cs.CL cs.NE published:2015-12-17 summary:Question answering forums are rapidly growing in size with no effectiveautomated ability to refer to and reuse answers already available for previousposted questions. In this paper, we develop a methodology for findingsemantically related questions. The task is difficult since 1) key pieces ofinformation are often buried in extraneous details in the question body and 2)available annotations on similar questions are scarce and fragmented. We designa recurrent and convolutional model (gated convolution) to effectively mapquestions to their semantic representations. The models are pre-trained withinan encoder-decoder framework (from body to title) on the basis of the entireraw corpus, and fine-tuned discriminatively from limited annotations. Ourevaluation demonstrates that our model yields substantial gains over a standardIR baseline and various neural network architectures (including CNNs, LSTMs andGRUs).
arxiv-15300-143 | Successive Ray Refinement and Its Application to Coordinate Descent for LASSO | http://arxiv.org/pdf/1512.05808v1.pdf | author:Jun Liu, Zheng Zhao, Ruiwen Zhang category:cs.LG published:2015-12-17 summary:Coordinate descent is one of the most popular approaches for solving Lassoand its extensions due to its simplicity and efficiency. When applyingcoordinate descent to solving Lasso, we update one coordinate at a time whilefixing the remaining coordinates. Such an update, which is usually easy tocompute, greedily decreases the objective function value. In this paper, we aimto improve its computational efficiency by reducing the number of coordinatedescent iterations. To this end, we propose a novel technique called SuccessiveRay Refinement (SRR). SRR makes use of the following ray continuation propertyon the successive iterations: for a particular coordinate, the value obtainedin the next iteration almost always lies on a ray that starts at its previousiteration and passes through the current iteration. Motivated by thisray-continuation property, we propose that coordinate descent be performed notdirectly on the previous iteration but on a refined search point that has thefollowing properties: on one hand, it lies on a ray that starts at a historysolution and passes through the previous iteration, and on the other hand, itachieves the minimum objective function value among all the points on the ray.We propose two schemes for defining the search point and show that the refinedsearch point can be efficiently obtained. Empirical results for real andsynthetic data sets show that the proposed SRR can significantly reduce thenumber of coordinate descent iterations, especially for small Lassoregularization parameters.
arxiv-15300-144 | Continuous online sequence learning with an unsupervised neural network model | http://arxiv.org/pdf/1512.05463v2.pdf | author:Yuwei Cui, Subutai Ahmad, Jeff Hawkins category:cs.NE q-bio.NC published:2015-12-17 summary:The ability to recognize and predict temporal sequences of sensory inputs isvital for survival in natural environments. Based on many known properties ofcortical neurons, hierarchical temporal memory (HTM) sequence memory isrecently proposed as a theoretical framework for sequence learning in thecortex. In this paper, we analyze properties of HTM sequence memory and applyit to sequence learning and prediction problems with streaming data. We showthe model is able to continuously learn a large number of variable-ordertemporal sequences using an unsupervised Hebbian-like learning rule. The sparsetemporal codes formed by the model can robustly handle branching temporalsequences by maintaining multiple predictions until there is sufficientdisambiguating evidence. We compare the HTM sequence memory with other sequencelearning algorithms, including statistical methods: autoregressive integratedmoving average (ARIMA), feedforward neural networks: online sequential extremelearning machine (ELM), and recurrent neural networks: long short-term memory(LSTM) and echo-state networks (ESN), on sequence prediction problems with bothartificial and real-world data. The HTM model achieves comparable accuracy toother state-of-the-art algorithms. The model also exhibits properties that arecritical for sequence learning, including continuous online learning, theability to handle multiple predictions and branching sequences with high orderstatistics, robustness to sensor noise and fault tolerance, and goodperformance without task-specific hyper- parameters tuning. Therefore the HTMsequence memory not only advances our understanding of how the brain may solvethe sequence learning problem, but is also applicable to a wide range ofreal-world problems such as discrete and continuous sequence prediction,anomaly detection, and sequence classification.
arxiv-15300-145 | Synthesis of recurrent neural networks for dynamical system simulation | http://arxiv.org/pdf/1512.05702v1.pdf | author:Adam P Trischler, Gabriele MT D'Eleuterio category:cs.NE 68T01 published:2015-12-17 summary:We review several of the most widely used techniques for training recurrentneural networks to approximate dynamical systems, then describe a novelalgorithm for this task. The algorithm is based on an earlier theoreticalresult that guarantees the quality of the network approximation. We show that afeedforward neural network can be trained on the vector field representation ofa given dynamical system using backpropagation, then recast, using matrixmanipulations, as a recurrent network that replicates the original system'sdynamics. After detailing this algorithm and its relation to earlierapproaches, we present numerical examples that demonstrate its capabilities.One of the distinguishing features of our approach is that both the originaldynamical systems and the recurrent networks that simulate them operate incontinuous time.
arxiv-15300-146 | Kauffman's adjacent possible in word order evolution | http://arxiv.org/pdf/1512.05582v2.pdf | author:Ramon Ferrer-i-Cancho category:cs.CL cs.IT math.IT physics.soc-ph published:2015-12-17 summary:Word order evolution has been hypothesized to be constrained by a word orderpermutation ring: transitions involving orders that are closer in thepermutation ring are more likely. The hypothesis can be seen as a particularcase of Kauffman's adjacent possible in word order evolution. Here we considerthe problem of the association of the six possible orders of S, V and O toyield a couple of primary alternating orders as a window to word orderevolution. We evaluate the suitability of various competing hypotheses topredict one member of the couple from the other with the help of informationtheoretic model selection. Our ensemble of models includes a six-way model thatis based on the word order permutation ring (Kauffman's adjacent possible) andanother model based on the dual two-way of standard typology, that reduces wordorder to basic orders preferences (e.g., a preference for SV over VS andanother for SO over OS). Our analysis indicates that the permutation ringyields the best model when favoring parsimony strongly, providing support forKauffman's general view and a six-way typology.
arxiv-15300-147 | Probabilistic Programming with Gaussian Process Memoization | http://arxiv.org/pdf/1512.05665v2.pdf | author:Ulrich Schaechtle, Ben Zinberg, Alexey Radul, Kostas Stathis, Vikash K. Mansinghka category:cs.LG cs.AI stat.ML published:2015-12-17 summary:Gaussian Processes (GPs) are widely used tools in statistics, machinelearning, robotics, computer vision, and scientific computation. However,despite their popularity, they can be difficult to apply; all but the simplestclassification or regression applications require specification and inferenceover complex covariance functions that do not admit simple analyticalposteriors. This paper shows how to embed Gaussian processes in anyhigher-order probabilistic programming language, using an idiom based onmemoization, and demonstrates its utility by implementing and extending classicand state-of-the-art GP applications. The interface to Gaussian processes,called gpmem, takes an arbitrary real-valued computational process as input andreturns a statistical emulator that automatically improve as the originalprocess is invoked and its input-output behavior is recorded. The flexibilityof gpmem is illustrated via three applications: (i) robust GP regression withhierarchical hyper-parameter learning, (ii) discovering symbolic expressionsfrom time-series data by fully Bayesian structure learning over kernelsgenerated by a stochastic grammar, and (iii) a bandit formulation of Bayesianoptimization with automatic inference and action selection. All applicationsshare a single 50-line Python library and require fewer than 20 lines ofprobabilistic code each.
arxiv-15300-148 | Oracle inequalities for ranking and U-processes with Lasso penalty | http://arxiv.org/pdf/1512.05698v1.pdf | author:Wojciech Rejchel category:stat.ML published:2015-12-17 summary:We investigate properties of estimators obtained by minimization ofU-processes with the Lasso penalty in high-dimensional settings. Our attentionis focused on the ranking problem that is popular in machine learning. It isrelated to guessing the ordering between objects on the basis of their observedpredictors. We prove the oracle inequality for the excess risk of theconsidered estimator as well as the bound for the l1 distance between theestimator and the oracle.
arxiv-15300-149 | Differential Evolution with Event-Triggered Impulsive Control | http://arxiv.org/pdf/1512.05449v2.pdf | author:Wei Du, Sunney Yung Sun Leung, Yang Tang, Athanasios V. Vasilakos category:cs.NE cs.SY math.OC published:2015-12-17 summary:Differential evolution (DE) is a simple but powerful evolutionary algorithm,which has been widely and successfully used in various areas. In this paper, anevent-triggered impulsive control scheme (ETI) is introduced to improve theperformance of DE. Impulsive control, the concept of which derives from controltheory, aims at regulating the states of a network by instantly adjusting thestates of a fraction of nodes at certain instants, and these instants aredetermined by event-triggered mechanism (ETM). By introducing impulsive controland ETM into DE, we hope to change the search performance of the population ina positive way after revising the positions of some individuals at certainmoments. At the end of each generation, the impulsive control operation istriggered when the update rate of the population declines or equals to zero. Indetail, inspired by the concepts of impulsive control, two types of impulsesare presented within the framework of DE in this paper: stabilizing impulsesand destabilizing impulses. Stabilizing impulses help the individuals withlower rankings instantly move to a desired state determined by the individualswith better fitness values. Destabilizing impulses randomly alter the positionsof inferior individuals within the range of the current population. By means ofintelligently modifying the positions of a part of individuals with these twokinds of impulses, both exploitation and exploration abilities of the wholepopulation can be meliorated. In addition, the proposed ETI is flexible to beincorporated into several state-of-the-art DE variants. Experimental resultsover the CEC 2014 benchmark functions exhibit that the developed scheme issimple yet effective, which significantly improves the performance of theconsidered DE algorithms.
arxiv-15300-150 | Symphony from Synapses: Neocortex as a Universal Dynamical Systems Modeller using Hierarchical Temporal Memory | http://arxiv.org/pdf/1512.05245v1.pdf | author:Fergal Byrne category:cs.NE cs.AI q-bio.NC published:2015-12-16 summary:Reverse engineering the brain is proving difficult, perhaps impossible. Whilemany believe that this is just a matter of time and effort, a differentapproach might help. Here, we describe a very simple idea which explains thepower of the brain as well as its structure, exploiting complex dynamics ratherthan abstracting it away. Just as a Turing Machine is a Universal DigitalComputer operating in a world of symbols, we propose that the brain is aUniversal Dynamical Systems Modeller, evolved bottom-up (itself using nestednetworks of interconnected, self-organised dynamical systems) to prosper in aworld of dynamical systems. Recent progress in Applied Mathematics has produced startling evidence ofwhat happens when abstract Dynamical Systems interact. Key latent informationdescribing system A can be extracted by system B from very simple signals, andsignals can be used by one system to control and manipulate others. Using thesefacts, we show how a region of the neocortex uses its dynamics to intrinsically"compute" about the external and internal world. Building on an existing "static" model of cortical computation (Hawkins'Hierarchical Temporal Memory - HTM), we describe how a region of neocortex canbe viewed as a network of components which together form a Dynamical Systemsmodelling module, connected via sensory and motor pathways to the externalworld, and forming part of a larger dynamical network in the brain. Empirical modelling and simulations of Dynamical HTM are possible with simpleextensions and combinations of currently existing open source software. We lista number of relevant projects.
arxiv-15300-151 | Learning a Hybrid Architecture for Sequence Regression and Annotation | http://arxiv.org/pdf/1512.05219v1.pdf | author:Yizhe Zhang, Ricardo Henao, Lawrence Carin, Jianling Zhong, Alexander J. Hartemink category:stat.ML published:2015-12-16 summary:When learning a hidden Markov model (HMM), sequen- tial observations canoften be complemented by real-valued summary response variables generated fromthe path of hid- den states. Such settings arise in numerous domains, includ-ing many applications in biology, like motif discovery and genome annotation.In this paper, we present a flexible frame- work for jointly modeling bothlatent sequence features and the functional mapping that relates the summaryresponse variables to the hidden state sequence. The algorithm is com- patiblewith a rich set of mapping functions. Results show that the availability ofadditional continuous response vari- ables can simultaneously improve theannotation of the se- quential observations and yield good predictionperformance in both synthetic data and real-world datasets.
arxiv-15300-152 | Blockout: Dynamic Model Selection for Hierarchical Deep Networks | http://arxiv.org/pdf/1512.05246v1.pdf | author:Calvin Murdock, Zhen Li, Howard Zhou, Tom Duerig category:cs.CV cs.LG published:2015-12-16 summary:Most deep architectures for image classification--even those that are trainedto classify a large number of diverse categories--learn shared imagerepresentations with a single model. Intuitively, however, categories that aremore similar should share more information than those that are very different.While hierarchical deep networks address this problem by learning separatefeatures for subsets of related categories, current implementations requiresimplified models using fixed architectures specified via heuristic clusteringmethods. Instead, we propose Blockout, a method for regularization and modelselection that simultaneously learns both the model architecture andparameters. A generalization of Dropout, our approach gives a novelparametrization of hierarchical architectures that allows for structurelearning via back-propagation. To demonstrate its utility, we evaluate Blockouton the CIFAR and ImageNet datasets, demonstrating improved classificationaccuracy, better regularization performance, faster training, and the clearemergence of hierarchical network structures.
arxiv-15300-153 | DNA-Level Splice Junction Prediction using Deep Recurrent Neural Networks | http://arxiv.org/pdf/1512.05135v1.pdf | author:Byunghan Lee, Taehoon Lee, Byunggook Na, Sungroh Yoon category:cs.LG q-bio.GN published:2015-12-16 summary:A eukaryotic gene consists of multiple exons (protein coding regions) andintrons (non-coding regions), and a splice junction refers to the boundarybetween a pair of exon and intron. Precise identification of spice junctions ona gene is important for deciphering its primary structure, function, andinteraction. Experimental techniques for determining exon/intron boundariesinclude RNA-seq, which is often accompanied by computational approaches.Canonical splicing signals are known, but computational junction predictionstill remains challenging because of a large number of false positives andother complications. In this paper, we exploit deep recurrent neural networks(RNNs) to model DNA sequences and to detect splice junctions thereon. We testvarious RNN units and architectures including long short-term memory units,gated recurrent units, and recently proposed iRNN for in-depth design spaceexploration. According to our experimental results, the proposed approachsignificantly outperforms not only conventional machine learning-based methodsbut also a recent state-of-the-art deep belief network-based technique in termsof prediction accuracy.
arxiv-15300-154 | Effects of GIMP Retinex Filtering Evaluated by the Image Entropy | http://arxiv.org/pdf/1512.05653v1.pdf | author:A. C. Sparavigna, R. Marazzato category:cs.CV published:2015-12-16 summary:A GIMP Retinex filtering can be used for enhancing images, with good resultson foggy images, as recently discussed. Since this filter has some parametersthat can be adjusted to optimize the output image, several approaches can bedecided according to desired results. Here, as a criterion for optimizing thefiltering parameters, we consider the maximization of the image entropy. Weuse, besides the Shannon entropy, also a generalized entropy.
arxiv-15300-155 | A Theoretically Grounded Application of Dropout in Recurrent Neural Networks | http://arxiv.org/pdf/1512.05287v2.pdf | author:Yarin Gal category:stat.ML published:2015-12-16 summary:Recurrent neural networks (RNNs) stand at the forefront of many recentdevelopments in deep learning. Yet a major difficulty with these models istheir tendency to overfit. Dropout is a widely used tool for regularisation indeep models, but a long strand of empirical research has claimed that it cannotbe applied between the recurrent connections of an RNN. The argument is thatnoise hinders the network's ability to model sequences and therefore dropoutshould be applied to the RNN's inputs and outputs alone. But withoutregularisation in recurrent layers, existing techniques overfit quickly. Inthis paper we make use of a recently developed theoretical framework castingdropout as approximate variational inference. Based on the framework we derivemathematically grounded tools to apply dropout within the recurrent layers ofRNNs, eliminating model overfitting. We apply our new variational inferencebased dropout technique in LSTM and GRU networks, evaluating the techniqueempirically. We show that the new approach outperforms existing techniques onsentiment analysis and language modelling tasks, extending our arsenal ofvariational tools in deep learning.
arxiv-15300-156 | Learning Games and Rademacher Observations Losses | http://arxiv.org/pdf/1512.05244v2.pdf | author:Richard Nock category:cs.LG I.2.6 published:2015-12-16 summary:It has recently been shown that supervised learning with the popular logisticloss is equivalent to optimizing the exponential loss over sufficientstatistics about the class: Rademacher observations (rados). We first show thatthis unexpected equivalence can actually be generalized to other example / radolosses, with necessary and sufficient conditions for the equivalence,exemplified on four losses that bear popular names in various fields:exponential (boosting), mean-variance (finance), Linear Hinge (on-linelearning), ReLU (deep learning), and unhinged (statistics). Second, we showthat the generalization unveils a surprising new connection to regularizedlearning, and in particular a sufficient condition under which regularizing theloss over examples is equivalent to regularizing the rados (with Minkowskisums) in the equivalent rado loss. This brings simple and powerful rado-basedlearning algorithms for sparsity-controlling regularization, that we exemplifyon a boosting algorithm for the regularized exponential rado-loss, whichformally boosts over four types of regularization, including the popular ridgeand lasso, and the recently coined slope --- we obtain the first provenboosting algorithm for this last regularization. Through our first contributionon the equivalence of rado and example-based losses, Omega-R.AdaBoost~appearsto be an efficient proxy to boost the regularized logistic loss over examplesusing whichever of the four regularizers. Experiments display thatregularization consistently improves performances of rado-based learning, andmay challenge or beat the state of the art of example-based learning even whenlearning over small sets of rados. Finally, we connect regularization todifferential privacy, and display how tiny budgets can be afforded on bigdomains while beating (protected) example-based learning.
arxiv-15300-157 | Shape and Spatially-Varying Reflectance Estimation From Virtual Exemplars | http://arxiv.org/pdf/1512.05278v1.pdf | author:Zhuo Hui, Aswin C Sankaranarayanan category:cs.CV published:2015-12-16 summary:This paper addresses the problem of estimating the shape of objects thatexhibit spatially-varying reflectance. We assume that multiple images of theobject are obtained under a fixed view-point and varying illumination, i.e.,the setting of photometric stereo. At the core of our techniques is theassumption that the BRDF at each pixel lies in the non-negative span of a knownBRDF dictionary.This assumption enables a per-pixel surface normal and BRDFestimation framework that is computationally tractable and requires noinitialization in spite of the underlying problem being non-convex. Ourestimation framework first solves for the surface normal at each pixel using avariant of example-based photometric stereo. We design an efficient multi-scalesearch strategy for estimating the surface normal and subsequently, refine thisestimate using a gradient descent procedure. Given the surface normal estimate,we solve for the spatially-varying BRDF by constraining the BRDF at each pixelto be in the span of the BRDF dictionary, here, we use additional priors tofurther regularize the solution. A hallmark of our approach is that it does notrequire iterative optimization techniques nor the need for carefulinitialization, both of which are endemic to most state-of-the-art techniques.We showcase the performance of our technique on a wide range of simulated andreal scenes where we outperform competing methods.
arxiv-15300-158 | A Novel Minimum Divergence Approach to Robust Speaker Identification | http://arxiv.org/pdf/1512.05073v1.pdf | author:Ayanendranath Basu, Smarajit Bose, Amita Pal, Anish Mukherjee, Debasmita Das category:stat.ML cs.SD stat.AP published:2015-12-16 summary:In this work, a novel solution to the speaker identification problem isproposed through minimization of statistical divergences between theprobability distribution (g). of feature vectors from the test utterance andthe probability distributions of the feature vector corresponding to thespeaker classes. This approach is made more robust to the presence of outliers,through the use of suitably modified versions of the standard divergencemeasures. The relevant solutions to the minimum distance methods are referredto as the minimum rescaled modified distance estimators (MRMDEs). Threemeasures were considered - the likelihood disparity, the Hellinger distance andPearson's chi-square distance. The proposed approach is motivated by theobservation that, in the case of the likelihood disparity, when the empiricaldistribution function is used to estimate g, it becomes equivalent to maximumlikelihood classification with Gaussian Mixture Models (GMMs) for speakerclasses, a highly effective approach used, for example, by Reynolds [22] basedon Mel Frequency Cepstral Coefficients (MFCCs) as features. Significantimprovement in classification accuracy is observed under this approach on thebenchmark speech corpus NTIMIT and a new bilingual speech corpus NISIS, withMFCC features, both in isolation and in combination with delta MFCC features.Moreover, the ubiquitous principal component transformation, by itself and inconjunction with the principle of classifier combination, is found to furtherenhance the performance.
arxiv-15300-159 | Streaming Kernel Principal Component Analysis | http://arxiv.org/pdf/1512.05059v1.pdf | author:Mina Ghashami, Daniel Perry, Jeff M. Phillips category:cs.DS cs.LG stat.ML published:2015-12-16 summary:Kernel principal component analysis (KPCA) provides a concise set of basisvectors which capture non-linear structures within large data sets, and is acentral tool in data analysis and learning. To allow for non-linear relations,typically a full $n \times n$ kernel matrix is constructed over $n$ datapoints, but this requires too much space and time for large values of $n$.Techniques such as the Nystr\"om method and random feature maps can helptowards this goal, but they do not explicitly maintain the basis vectors in astream and take more space than desired. We propose a new approach forstreaming KPCA which maintains a small set of basis elements in a stream,requiring space only logarithmic in $n$, and also improves the dependence onthe error parameter. Our technique combines together random feature maps withrecent advances in matrix sketching, it has guaranteed spectral norm errorbounds with respect to the original kernel matrix, and it compares favorably inpractice to state-of-the-art approaches.
arxiv-15300-160 | Inferring Gene Regulatory Network Using An Evolutionary Multi-Objective Method | http://arxiv.org/pdf/1512.05055v1.pdf | author:Yu Chen, Xiufen Zou category:cs.CE cs.NE q-bio.QM 92B99 published:2015-12-16 summary:Inference of gene regulatory networks (GRNs) based on experimental data is achallenging task in bioinformatics. In this paper, we present a bi-objectiveminimization model (BoMM) for inference of GRNs, where one objective is thefitting error of derivatives, and the other is the number of connections in thenetwork. To solve the BoMM efficiently, we propose a multi-objectiveevolutionary algorithm (MOEA), and utilize the separable parameter estimationmethod (SPEM) decoupling the ordinary differential equation (ODE) system. Then,the Akaike Information Criterion (AIC) is employed to select one inferenceresult from the obtained Pareto set. Taking the S-system as the investigatedGRN model, our method can properly identify the topologies and parameter valuesof benchmark systems. There is no need to preset problem-dependent parametervalues to obtain appropriate results, and thus, our method could be applicableto inference of various GRNs models.
arxiv-15300-161 | ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs | http://arxiv.org/pdf/1512.05193v3.pdf | author:Wenpeng Yin, Hinrich SchÃ¼tze, Bing Xiang, Bowen Zhou category:cs.CL published:2015-12-16 summary:How to model a pair of sentences is a critical issue in many NLP tasks suchas answer selection (AS), paraphrase identification (PI) and textual entailment(TE). Most prior work (i) deals with one individual task by fine-tuning aspecific system; (ii) models each sentence's representation separately, rarelyconsidering the impact of the other sentence; or (iii) relies fully on manuallydesigned, task-specific linguistic features. This work presents a generalAttention Based Convolutional Neural Network (ABCNN) for modeling a pair ofsentences. We make three contributions. (i) ABCNN can be applied to a widevariety of tasks that require modeling of sentence pairs. (ii) We propose threeattention schemes that integrate mutual influence between sentences into CNN;thus, the representation of each sentence takes into consideration itscounterpart. These interdependent sentence pair representations are morepowerful than isolated sentence representations. (iii) ABCNN achievesstate-of-the-art performance on AS, PI and TE tasks.
arxiv-15300-162 | Multiregion Bilinear Convolutional Neural Networks for Person Re-Identification | http://arxiv.org/pdf/1512.05300v2.pdf | author:Evgeniya Ustinova, Yaroslav Ganin, Victor Lempitsky category:cs.CV published:2015-12-16 summary:In this work we explore the applicability of the recently proposed CNNarchitecture, called Bilinear CNN, and its new modification that we callmulti-region Bilinear CNN to the person re-identification problem. Originally,Bilinear CNNs were introduced for fine-grained classification and proved to beboth simple and high-performing architectures. Bilinear CNN allows to build anorderless descriptor for an image using outer product of features outputtedfrom two separate feature extractors. Based on this approach, MultiregionBilinear CNN, apply bilinear pooling over multiple regions for extracting richand useful descriptors that retain some spatial information. We show than when embedded into a standard "siamese" type learning, bilinearCNNs and in particular their multi-region variants can improvere-identification performance compared to standard CNNs and achievestate-of-the-art accuracy on the largest person re-identification datasetsavailable at the moment, namely CUHK03 and Market-1501.
arxiv-15300-163 | Fine-grained Categorization and Dataset Bootstrapping using Deep Metric Learning with Humans in the Loop | http://arxiv.org/pdf/1512.05227v2.pdf | author:Yin Cui, Feng Zhou, Yuanqing Lin, Serge Belongie category:cs.CV published:2015-12-16 summary:Existing fine-grained visual categorization methods often suffer from threechallenges: lack of training data, large number of fine-grained categories, andhigh intraclass vs. low inter-class variance. In this work we propose a genericiterative framework for fine-grained categorization and dataset bootstrappingthat handles these three challenges. Using deep metric learning with humans inthe loop, we learn a low dimensional feature embedding with anchor points onmanifolds for each category. These anchor points capture intra-class variancesand remain discriminative between classes. In each round, images with highconfidence scores from our model are sent to humans for labeling. By comparingwith exemplar images, labelers mark each candidate image as either a "truepositive" or a "false positive". True positives are added into our currentdataset and false positives are regarded as "hard negatives" for our metriclearning model. Then the model is retrained with an expanded dataset and hardnegatives for the next round. To demonstrate the effectiveness of the proposedframework, we bootstrap a fine-grained flower dataset with 620 categories fromInstagram images. The proposed deep metric learning scheme is evaluated on bothour dataset and the CUB-200-2001 Birds dataset. Experimental evaluations showsignificant performance gain using dataset bootstrapping and demonstratestate-of-the-art results achieved by the proposed deep metric learning methods.
arxiv-15300-164 | Morpho-syntactic Lexicon Generation Using Graph-based Semi-supervised Learning | http://arxiv.org/pdf/1512.05030v3.pdf | author:Manaal Faruqui, Ryan McDonald, Radu Soricut category:cs.CL published:2015-12-16 summary:Morpho-syntactic lexicons provide information about the morphological andsyntactic roles of words in a language. Such lexicons are not available for alllanguages and even when available, their coverage can be limited. We present agraph-based semi-supervised learning method that uses the morphological,syntactic and semantic relations between words to automatically construct widecoverage lexicons from small seed sets. Our method is language-independent, andwe show that we can expand a 1000 word seed lexicon to more than 100 times itssize with high quality for 11 languages. In addition, the automatically createdlexicons provide features that improve performance in two downstream tasks:morphological tagging and dependency parsing.
arxiv-15300-165 | Feature Representation for ICU Mortality | http://arxiv.org/pdf/1512.05294v2.pdf | author:Harini Suresh category:cs.AI cs.LG stat.ML published:2015-12-16 summary:Good predictors of ICU Mortality have the potential to identify high-riskpatients earlier, improve ICU resource allocation, or create more accuratepopulation-level risk models. Machine learning practitioners typically makechoices about how to represent features in a particular model, but thesechoices are seldom evaluated quantitatively. This study compares theperformance of different representations of clinical event data from MIMIC IIin a logistic regression model to predict 36-hour ICU mortality. The mostcommon representations are linear (normalized counts) and binary (yes/no).These, along with a new representation termed "hill", are compared using bothL1 and L2 regularization. Results indicate that the introduced "hill"representation outperforms both the binary and linear representations, the hillrepresentation thus has the potential to improve existing models of ICUmortality.
arxiv-15300-166 | Context Driven Label Fusion for segmentation of Subcutaneous and Visceral Fat in CT Volumes | http://arxiv.org/pdf/1512.04958v1.pdf | author:Sarfaraz Hussein, Aileen Green, Arjun Watane, Georgios Papadakis, Medhat Osman, Ulas Bagci category:cs.CV published:2015-12-15 summary:Quantification of adipose tissue (fat) from computed tomography (CT) scans isconducted mostly through manual or semi-automated image segmentation algorithmswith limited efficacy. In this work, we propose a completely unsupervised andautomatic method to identify adipose tissue, and then separate SubcutaneousAdipose Tissue (SAT) from Visceral Adipose Tissue (VAT) at the abdominalregion. We offer a three-phase pipeline consisting of (1) Initial boundaryestimation using gradient points, (2) boundary refinement using GeometricMedian Absolute Deviation and Appearance based Local Outlier Scores (3) Contextdriven label fusion using Conditional Random Fields (CRF) to obtain the finalboundary between SAT and VAT. We evaluate the proposed method on 151 abdominalCT scans and obtain state-of-the-art 94% and 91% dice similarity scores for SATand VAT segmentation, as well as significant reduction in fat quantificationerror measure.
arxiv-15300-167 | Relative Density and Exact Recovery in Heterogeneous Stochastic Block Models | http://arxiv.org/pdf/1512.04937v1.pdf | author:Amin Jalali, Qiyang Han, Ioana Dumitriu, Maryam Fazel category:stat.ML published:2015-12-15 summary:The Stochastic Block Model (SBM) is a widely used random graph model fornetworks with communities. Despite the recent burst of interest in recoveringcommunities in the SBM from statistical and computational points of view, thereare still gaps in understanding the fundamental information theoretic andcomputational limits of recovery. In this paper, we consider the SBM in itsfull generality, where there is no restriction on the number and sizes ofcommunities or how they grow with the number of nodes, as well as on theconnection probabilities inside or across communities. This generality allowsus to move past the artifacts of homogenous SBM, and understand the rightparameters (such as the relative densities of communities) that define thevarious recovery thresholds. We outline the implications of our generalizationsvia a set of illustrative examples. For instance, $\log n$ is considered to bethe standard lower bound on the cluster size for exact recovery via convexmethods, for homogenous SBM. We show that it is possible, in the rightcircumstances (when sizes are spread and the smaller the cluster, the denser),to recover very small clusters (up to $\sqrt{\log n}$ size), if there are justa few of them (at most polylogarithmic in $n$).
arxiv-15300-168 | Strategies for Training Large Vocabulary Neural Language Models | http://arxiv.org/pdf/1512.04906v1.pdf | author:Welin Chen, David Grangier, Michael Auli category:cs.CL cs.LG published:2015-12-15 summary:Training neural network language models over large vocabularies is stillcomputationally very costly compared to count-based models such as Kneser-Ney.At the same time, neural language models are gaining popularity for manyapplications such as speech recognition and machine translation whose successdepends on scalability. We present a systematic comparison of strategies torepresent and train large vocabularies, including softmax, hierarchicalsoftmax, target sampling, noise contrastive estimation and self normalization.We further extend self normalization to be a proper estimator of likelihood andintroduce an efficient variant of softmax. We evaluate each method on threepopular benchmarks, examining performance on rare words, the speed/accuracytrade-off and complementarity to Kneser-Ney.
arxiv-15300-169 | A Light Touch for Heavily Constrained SGD | http://arxiv.org/pdf/1512.04960v1.pdf | author:Andrew Cotter, Maya Gupta, Jan Pfeifer category:cs.LG published:2015-12-15 summary:Projected stochastic gradient descent (SGD) is often the default choice forlarge-scale optimization in machine learning, but requires a projection aftereach update. For heavily-constrained objectives, we propose an efficientextension of SGD that stays close to the feasible region while only applyingconstraints probabilistically at each iteration. Theoretical analysis shows agood trade-off between per-iteration work and the number of iterations needed,indicating compelling advantages on problems with a large number of constraintsonto which projecting is expensive. In MATLAB experiments, our algorithmsuccessfully handles a large-scale real-world video ranking problem with tensof thousands of linear inequality constraints that was too large for projectedSGD and stochastic Frank-Wolfe.
arxiv-15300-170 | An Operator for Entity Extraction in MapReduce | http://arxiv.org/pdf/1512.04973v1.pdf | author:Ndapandula Nakashole category:cs.DB cs.CL 68T50 published:2015-12-15 summary:Dictionary-based entity extraction involves finding mentions of dictionaryentities in text. Text mentions are often noisy, containing spurious or missingwords. Efficient algorithms for detecting approximate entity mentions followone of two general techniques. The first approach is to build an index on theentities and perform index lookups of document substrings. The second approachrecognizes that the number of substrings generated from documents can explodeto large numbers, to get around this, they use a filter to prune many suchsubstrings which do not match any dictionary entity and then only verify theremaining substrings if they are entity mentions of dictionary entities, bymeans of a text join. The choice between the index-based approach and thefilter & verification-based approach is a case-to-case decision as the bestapproach depends on the characteristics of the input entity dictionary, forexample frequency of entity mentions. Choosing the right approach for thesetting can make a substantial difference in execution time. Making this choiceis however non-trivial as there are parameters within each of the approachesthat make the space of possible approaches very large. In this paper, wepresent a cost-based operator for making the choice among execution plans forentity extraction. Since we need to deal with large dictionaries and evenlarger large datasets, our operator is developed for implementations ofMapReduce distributed algorithms.
arxiv-15300-171 | Multiple penalized principal curves: analysis and computation | http://arxiv.org/pdf/1512.05010v1.pdf | author:Slav Kirov, Dejan SlepÄev category:math.AP cs.CV stat.ML published:2015-12-15 summary:We study the problem of finding the one-dimensional structure in a given dataset. In other words we consider ways to approximate a given measure (data) bycurves. We consider an objective functional whose minimizers are aregularization of principal curves and introduce a new functional which allowsfor multiple curves. We prove the existence of minimizers and establish theirbasic properties. We develop an efficient algorithm for obtaining (near)minimizers of the functional. While both of the functionals used are nonconvex,we argue that enlarging the configuration space to allow for multiple curvesleads to a simpler energy landscape with fewer undesirable (high-energy) localminima. Furthermore we note that the approach proposed is able to find theone-dimensional structure even for data with considerable amount of noise.
arxiv-15300-172 | Increasing the Action Gap: New Operators for Reinforcement Learning | http://arxiv.org/pdf/1512.04860v1.pdf | author:Marc G. Bellemare, Georg Ostrovski, Arthur Guez, Philip S. Thomas, RÃ©mi Munos category:cs.AI cs.LG published:2015-12-15 summary:This paper introduces new optimality-preserving operators on Q-functions. Wefirst describe an operator for tabular representations, the consistent Bellmanoperator, which incorporates a notion of local policy consistency. We show thatthis local consistency leads to an increase in the action gap at each state;increasing this gap, we argue, mitigates the undesirable effects ofapproximation and estimation errors on the induced greedy policies. Thisoperator can also be applied to discretized continuous space and time problems,and we provide empirical results evidencing superior performance in thiscontext. Extending the idea of a locally consistent operator, we then derivesufficient conditions for an operator to preserve optimality, leading to afamily of operators which includes our consistent Bellman operator. Ascorollaries we provide a proof of optimality for Baird's advantage learningalgorithm and derive other gap-increasing operators with interestingproperties. We conclude with an empirical study on 60 Atari 2600 gamesillustrating the strong potential of these new operators.
arxiv-15300-173 | Energy-Efficient Classification for Anomaly Detection: The Wireless Channel as a Helper | http://arxiv.org/pdf/1512.04857v1.pdf | author:Kiril Ralinovski, Mario Goldenbaum, SÅawomir StaÅczak category:cs.IT cs.LG math.IT published:2015-12-15 summary:Anomaly detection has various applications including condition monitoring andfault diagnosis. The objective is to sense the environment, learn the normalsystem state, and then periodically classify whether the instantaneous statedeviates from the normal one or not. A flexible and cost-effective way ofmonitoring a system state is to use a wireless sensor network. In thetraditional approach, the sensors encode their observations and transmit themto a fusion center by means of some interference avoiding channel accessmethod. The fusion center then decodes all the data and classifies thecorresponding system state. As this approach can be highly inefficient in termsof energy consumption, in this paper we propose a transmission scheme thatexploits interference for carrying out the anomaly detection directly in theair. In other words, the wireless channel helps the fusion center to retrievethe sought classification outcome immediately from the channel output. Toachieve this, the chosen learning model is linear support vector machines.After discussing the proposed scheme and proving its reliability, we presentnumerical examples demonstrating that the scheme reduces the energy consumptionfor anomaly detection by up to 53% compared to a strategy that uses timedivision multiple-access.
arxiv-15300-174 | Data Driven Resource Allocation for Distributed Learning | http://arxiv.org/pdf/1512.04848v1.pdf | author:Travis Dick, Mu Li, Venkata Krishna Pillutla, Colin White, Maria Florina Balcan, Alex Smola category:cs.LG cs.DS stat.ML published:2015-12-15 summary:In distributed machine learning, data is dispatched to multiple machines forprocessing. Motivated by the fact that similar data points are often belongingto the same or similar classes, and more generally, classification rules ofhigh accuracy tend to be "locally simple but globally complex", we propose datadependent dispatching that takes advantage of such structures. Our maintechnical contribution is to provide algorithms with provable guarantees fordata-dependent dispatching, that partition the data in a way that satisfiesimportant conditions for accurate distributed learning, including faulttolerance and balancedness. We show the effectiveness of our method over thewidely used random partitioning scheme in several real world image andadvertising datasets.
arxiv-15300-175 | Noise-Compensated, Bias-Corrected Diffusion Weighted Endorectal Magnetic Resonance Imaging via a Stochastically Fully-Connected Joint Conditional Random Field Model | http://arxiv.org/pdf/1512.04636v1.pdf | author:Ameneh Boroomand, Mohammad Javad Shafiee, Farzad Khalvati, Masoom A. Haider, Alexander Wong category:stat.ME cs.CV physics.med-ph stat.AP published:2015-12-15 summary:Diffusion weighted magnetic resonance imaging (DW-MRI) is a powerful tool inimaging-based prostate cancer (PCa) screening and detection. Endorectal coilsare commonly used in DW-MRI to improve the signal-to-noise ratio (SNR) of theacquisition, at the expense of significant intensity inhomogeneities (biasfield) that worsens as we move away from the endorectal coil. The presence ofbias field can have a significant negative impact on the accuracy of differentimage analysis tasks, as well as the accuracy of PCa tumor localization, thusleading to increased inter- and intra-observer variability. The previouslyproposed bias field correction methods often suffer from undesired noiseamplification that can reduce the image quality of the resulting bias-correctedDW-MRI data. Here, we propose a unified data reconstruction approach thatenables joint compensation of bias field as well as data noise in diffusionweighted endorectal magnetic resonance (DW-EMR) imaging. The proposednoise-compensated, bias-corrected (NCBC) data reconstruction method takesadvantage of a novel stochastically fully connected joint conditional randomfield (SFC-JCRF) model to mitigate the effects of data noise and bias field inthe reconstructed DW-EMR prostate imaging data. The proposed NCBCreconstruction method was tested on synthetic DW-EMR data, physical DW-EMRphantom, as well as real DW-EMR imaging data. Both qualitative and quantitativeanalysis illustrated that the proposed NCBC method can achieve improved imagequality when compared to other tested bias correction methods. As such, theproposed NCBC method can have strong potential for improving the consistency ofimage interpretations, thus leading to more accurate PCa diagnosis.
arxiv-15300-176 | From One Point to A Manifold: Knowledge Graph Embedding For Precise Link Prediction | http://arxiv.org/pdf/1512.04792v3.pdf | author:Han Xiao, Minlie Huang, Xiaoyan Zhu category:cs.AI cs.LG published:2015-12-15 summary:Knowledge graph embedding aims at offering a numerical knowledgerepresentation paradigm by transforming the entities and relations intocontinuous vector space. However, existing methods could not characterize theknowledge graph in a fine degree to make a precise prediction. There are tworeasons: being an ill-posed algebraic system and applying an overstrictgeometric form. As precise prediction is critical, we propose an manifold-basedembedding principle (\textbf{ManifoldE}) which could be treated as a well-posedalgebraic system that expands the position of golden triples from one point incurrent models to a manifold in ours. Extensive experiments show that theproposed models achieve substantial improvements against the state-of-the-artbaselines especially for the precise prediction task, and yet maintain highefficiency.
arxiv-15300-177 | Towards Cultural-Scale Models of Full Text | http://arxiv.org/pdf/1512.05004v2.pdf | author:Jaimie Murdock, Jiaan Zeng, Colin Allen category:cs.DL cs.CL cs.IR published:2015-12-15 summary:This technical report consists of two components: an administrative reportfor the HathiTrust Research Center (HTRC) Advanced Collaborative Support (ACS)program and a research report on the variance of topic models trained overrandom samples of books in the Hathi Trust. Cultural-scale models of full textdocuments are prone to over-interpretation by researchers makingunintentionally strong socio-linguistic claims without recognizing that evenlarge digital libraries are merely samples of all the books ever produced. Inthis study, we test the sensitivity of the topic models to the sampling processby taking random samples of books in the Hathi Trust Digital Library withindifferent Library of Congress Classification (LCC) areas. For eachclassification area, we train several topic models over the entire class withdifferent random seeds, generating a set of spanning models. Then, we traintopic models on random samples of books from the classification area,generating a set of sample models. Finally, we align topics from the samplemodels to the spanning models and measure the alignment distance and topicoverlap. We find that sample models with a large sample size typically have analignment distance that falls in the range of the alignment distance betweenspanning models. Unsurprisingly, as sample size increases, alignment distancedecreases. We also find that the topic overlap increases as sample sizeincreases. However, the decomposition of these measures by sample size differsby field and by number of topics. We speculate that these measures could beused to find classes which have a common "canon" discussed among all books inthe area, as shown by high topic overlap and low alignment distance even insmall sample sizes.
arxiv-15300-178 | Feature-Level Domain Adaptation | http://arxiv.org/pdf/1512.04829v1.pdf | author:Wouter M. Kouw, Jesse H. Krijthe, Marco Loog, Laurens J. P. van der Maaten category:stat.ML cs.LG published:2015-12-15 summary:Domain adaptation is the supervised learning setting in which the trainingand test data originate from different domains: the so-called source and targetdomains. In this paper, we propose and study a domain adaption approach, calledfeature-level domain adaptation (flda), that models the dependence between twodomains by means of a feature-level transfer distribution. The domain adaptedclassifier is trained by minimizing the expected loss under this transferdistribution. Our empirical evaluation of flda focuses on problems with binaryand count features in which the domain adaptation can be naturally modeled viaa dropout distribution, which allows the final classifier to adapt to theimportance of specific features in the target data. Our experimental evaluationsuggests that under certain conditions, flda converges to the classifiertrained on the target distribution. Experiments with our domain adaptationapproach on several real-world problems show that flda performs on par withstate-of-the-art techniques in domain adaptation.
arxiv-15300-179 | Linear Models of Computation and Program Learning | http://arxiv.org/pdf/1512.04639v1.pdf | author:Michael Bukatin, Steve Matthews category:cs.LO cs.NE published:2015-12-15 summary:We consider two classes of computations which admit taking linearcombinations of execution runs: probabilistic sampling and generalizedanimation. We argue that the task of program learning should be more tractablefor these architectures than for conventional deterministic programs. We lookat the recent advances in the "sampling the samplers" paradigm in higher-orderprobabilistic programming. We also discuss connections between partialinconsistency, non-monotonic inference, and vector semantics.
arxiv-15300-180 | Joint Image-Text News Topic Detection and Tracking with And-Or Graph Representation | http://arxiv.org/pdf/1512.04701v1.pdf | author:Weixin Li, Jungseock Joo, Hang Qi, Song-Chun Zhu category:cs.IR cs.CL cs.SI published:2015-12-15 summary:In this paper, we aim to develop a method for automatically detecting andtracking topics in broadcast news. We present a hierarchical And-Or graph (AOG)to jointly represent the latent structure of both texts and visuals. The AOGembeds a context sensitive grammar that can describe the hierarchicalcomposition of news topics by semantic elements about people involved, relatedplaces and what happened, and model contextual relationships between elementsin the hierarchy. We detect news topics through a cluster sampling processwhich groups stories about closely related events. Swendsen-Wang Cuts (SWC), aneffective cluster sampling algorithm, is adopted for traversing the solutionspace and obtaining optimal clustering solutions by maximizing a Bayesianposterior probability. Topics are tracked to deal with the continuously updatednews streams. We generate topic trajectories to show how topics emerge, evolveand disappear over time. The experimental results show that our method canexplicitly describe the textual and visual data in news videos and producemeaningful topic trajectories. Our method achieves superior performancecompared to state-of-the-art methods on both a public dataset Reuters-21578 anda self-collected dataset named UCLA Broadcast News Dataset.
arxiv-15300-181 | Learning optimal nonlinearities for iterative thresholding algorithms | http://arxiv.org/pdf/1512.04754v1.pdf | author:Ulugbek S. Kamilov, Hassan Mansour category:cs.LG stat.ML published:2015-12-15 summary:Iterative shrinkage/thresholding algorithm (ISTA) is a well-studied methodfor finding sparse solutions to ill-posed inverse problems. In this letter, wepresent a data-driven scheme for learning optimal thresholding functions forISTA. The proposed scheme is obtained by relating iterations of ISTA to layersof a simple deep neural network (DNN) and developing a corresponding errorbackpropagation algorithm that allows to fine-tune the thresholding functions.Simulations on sparse statistical signals illustrate potential gains inestimation quality due to the proposed data adaptive ISTA.
arxiv-15300-182 | Causal and anti-causal learning in pattern recognition for neuroimaging | http://arxiv.org/pdf/1512.04808v1.pdf | author:Sebastian Weichwald, Bernhard SchÃ¶lkopf, Tonio Ball, Moritz Grosse-Wentrup category:stat.ML cs.LG q-bio.NC stat.ME published:2015-12-15 summary:Pattern recognition in neuroimaging distinguishes between two types ofmodels: encoding- and decoding models. This distinction is based on the insightthat brain state features, that are found to be relevant in an experimentalparadigm, carry a different meaning in encoding- than in decoding models. Inthis paper, we argue that this distinction is not sufficient: Relevant featuresin encoding- and decoding models carry a different meaning depending on whetherthey represent causal- or anti-causal relations. We provide a theoreticaljustification for this argument and conclude that causal inference is essentialfor interpretation in neuroimaging.
arxiv-15300-183 | Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation | http://arxiv.org/pdf/1512.04650v2.pdf | author:Yong Cheng, Shiqi Shen, Zhongjun He, Wei He, Hua Wu, Maosong Sun, Yang Liu category:cs.CL published:2015-12-15 summary:The attentional mechanism has proven to be effective in improving end-to-endneural machine translation. However, due to the intricate structural divergencebetween natural languages, unidirectional attention-based models might onlycapture partial aspects of attentional regularities. We propose agreement-basedjoint training for bidirectional attention-based end-to-end neural machinetranslation. Instead of training source-to-target and target-to-sourcetranslation models independently,our approach encourages the two complementarymodels to agree on word alignment matrices on the same training data.Experiments on Chinese-English and English-French translation tasks show thatagreement-based joint training significantly improves both alignment andtranslation quality over independent training.
arxiv-15300-184 | On Deep Representation Learning from Noisy Web Images | http://arxiv.org/pdf/1512.04785v1.pdf | author:Phong D. Vo, Alexandru Ginsca, HervÃ© Le Borgne, Adrian Popescu category:cs.CV cs.MM published:2015-12-15 summary:The keep-growing content of Web images may be the next important data sourceto scale up deep neural networks, which recently obtained a great success inthe ImageNet classification challenge and related tasks. This prospect,however, has not been validated on convolutional networks (convnet) -- one ofbest performing deep models -- because of their supervised regime. Whileunsupervised alternatives are not so good as convnet in generalizing thelearned model to new domains, we use convnet to leverage semi-supervisedrepresentation learning. Our approach is to use massive amounts of unlabeledand noisy Web images to train convnets as general feature detectors despitechallenges coming from data such as high level of mislabeled data, outliers,and data biases. Extensive experiments are conducted at several data scales,different network architectures, and data reranking techniques. The learnedrepresentations are evaluated on nine public datasets of various topics. Thebest results obtained by our convnets, trained on 3.14 million Web images,outperform AlexNet trained on 1.2 million clean images of ILSVRC 2012 and isclosing the gap with VGG-16. These prominent results suggest a budget solutionto use deep learning in practice and motivate more research in semi-supervisedrepresentation learning.
arxiv-15300-185 | On the Relation between two Rotation Metrics | http://arxiv.org/pdf/1512.04219v1.pdf | author:Thomas Ruland category:cs.CV published:2015-12-14 summary:In their work "Global Optimization through Rotation Space Search", RichardHartley and Fredrik Kahl introduce a global optimization strategy for problemsin geometric computer vision, based on rotation space search using abranch-and-bound algorithm. In its core, Lemma 2 of their publication is theimportant foundation for a class of global optimization algorithms, which isadopted over a wide range of problems in subsequent publications. This lemmarelates a metric on rotations represented by rotation matrices with a metric onrotations in axis-angle representation. This work focuses on a proof for thisrelationship, which is based on Rodrigues' Rotation Theorem for the compositionof rotations in axis-angle representation.
arxiv-15300-186 | Watch-Bot: Unsupervised Learning for Reminding Humans of Forgotten Actions | http://arxiv.org/pdf/1512.04208v1.pdf | author:Chenxia Wu, Jiemi Zhang, Bart Selman, Silvio Savarese, Ashutosh Saxena category:cs.RO cs.CV published:2015-12-14 summary:We present a robotic system that watches a human using a Kinect v2 RGB-Dsensor, detects what he forgot to do while performing an activity, and ifnecessary reminds the person using a laser pointer to point out the relatedobject. Our simple setup can be easily deployed on any assistive robot. Our approach is based on a learning algorithm trained in a purelyunsupervised setting, which does not require any human annotations. This makesour approach scalable and applicable to variant scenarios. Our model learns theaction/object co-occurrence and action temporal relations in the activity, anduses the learned rich relationships to infer the forgotten action and therelated object. We show that our approach not only improves the unsupervisedaction segmentation and action cluster assignment performance, but alsoeffectively detects the forgotten actions on a challenging human activity RGB-Dvideo dataset. In robotic experiments, we show that our robot is able to remindpeople of forgotten actions successfully.
arxiv-15300-187 | Data-driven Sequential Monte Carlo in Probabilistic Programming | http://arxiv.org/pdf/1512.04387v2.pdf | author:Yura N Perov, Tuan Anh Le, Frank Wood category:cs.AI stat.AP stat.ML published:2015-12-14 summary:Most of Markov Chain Monte Carlo (MCMC) and sequential Monte Carlo (SMC)algorithms in existing probabilistic programming systems suboptimally use onlymodel priors as proposal distributions. In this work, we describe an approachfor training a discriminative model, namely a neural network, in order toapproximate the optimal proposal by using posterior estimates from previousruns of inference. We show an example that incorporates a data-driven proposalfor use in a non-parametric model in the Anglican probabilistic programmingsystem. Our results show that data-driven proposals can significantly improveinference performance so that considerably fewer particles are necessary toperform a good posterior estimation.
arxiv-15300-188 | Decoding index finger position from EEG using random forests | http://arxiv.org/pdf/1512.04274v1.pdf | author:Sebastian Weichwald, Timm Meyer, Bernhard SchÃ¶lkopf, Tonio Ball, Moritz Grosse-Wentrup category:stat.ML q-bio.NC q-bio.QM published:2015-12-14 summary:While invasively recorded brain activity is known to provide detailedinformation on motor commands, it is an open question at what level of detailinformation about positions of body parts can be decoded from non-invasivelyacquired signals. In this work it is shown that index finger positions can bedifferentiated from non-invasive electroencephalographic (EEG) recordings inhealthy human subjects. Using a leave-one-subject-out cross-validationprocedure, a random forest distinguished different index finger positions on anumerical keyboard above chance-level accuracy. Among the different spectralfeatures investigated, high $\beta$-power (20-30 Hz) over contralateralsensorimotor cortex carried most information about finger position. Thus, thesefindings indicate that finger position is in principle decodable fromnon-invasive features of brain activity that generalize across individuals.
arxiv-15300-189 | Compressed Dynamic Mode Decomposition for Real-Time Object Detection | http://arxiv.org/pdf/1512.04205v1.pdf | author:N. Benjamin Erichson, Steven L. Brunton, J. Nathan Kutz category:cs.CV published:2015-12-14 summary:We introduce the method of compressive dynamic mode decomposition (cDMD) forrobustly performing real-time foreground/background separation inhigh-definition video. The DMD method provides a regression technique forleast-square fitting of video snapshots to a linear dynamical system. Themethod integrates two of the leading data analysis methods in use today:Fourier transforms and Principal Components. DMD modes with temporal Fourierfrequencies near the origin (zero-modes) are interpreted as background(low-rank) portions of the given video frames, and the terms with Fourierfrequencies bounded away from the origin are their foreground (sparse)counterparts. When combined with compression techniques, the resulting cDMD canprocess full HD video feeds in real-time on CPU computing platforms while stillmaintaining competitive video decomposition quality, quantified by F-measure,Recall and Precision. On a GPU architecture, the method is significantly fasterthan real-time, allowing for further video processing to improve the separationquality and/or enacting further computer vision processes such as objectrecognition.
arxiv-15300-190 | Learning Deep Features for Discriminative Localization | http://arxiv.org/pdf/1512.04150v1.pdf | author:Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba category:cs.CV published:2015-12-14 summary:In this work, we revisit the global average pooling layer proposed in [13],and shed light on how it explicitly enables the convolutional neural network tohave remarkable localization ability despite being trained on image-levellabels. While this technique was previously proposed as a means forregularizing training, we find that it actually builds a generic localizabledeep representation that can be applied to a variety of tasks. Despite theapparent simplicity of global average pooling, we are able to achieve 37.1%top-5 error for object localization on ILSVRC 2014, which is remarkably closeto the 34.2% top-5 error achieved by a fully supervised CNN approach. Wedemonstrate that our network is able to localize the discriminative imageregions on a variety of tasks despite not being trained for them
arxiv-15300-191 | Instance-aware Semantic Segmentation via Multi-task Network Cascades | http://arxiv.org/pdf/1512.04412v1.pdf | author:Jifeng Dai, Kaiming He, Jian Sun category:cs.CV published:2015-12-14 summary:Semantic segmentation research has recently witnessed rapid progress, butmany leading methods are unable to identify object instances. In this paper, wepresent Multi-task Network Cascades for instance-aware semantic segmentation.Our model consists of three networks, respectively differentiating instances,estimating masks, and categorizing objects. These networks form a cascadedstructure, and are designed to share their convolutional features. We developan algorithm for the nontrivial end-to-end training of this causal, cascadedstructure. Our solution is a clean, single-step training framework and can begeneralized to cascades that have more stages. We demonstrate state-of-the-artinstance-aware semantic segmentation accuracy on PASCAL VOC. Meanwhile, ourmethod takes only 360ms testing an image using VGG-16, which is two orders ofmagnitude faster than previous systems for this challenging problem. As a byproduct, our method also achieves compelling object detection results whichsurpass the competitive Fast/Faster R-CNN systems. The method described in this paper is the foundation of our submissions tothe MS COCO 2015 segmentation competition, where we won the 1st place.
arxiv-15300-192 | Sparse Representation of a Blur Kernel for Blind Image Restoration | http://arxiv.org/pdf/1512.04418v1.pdf | author:Chia-Chen Lee, Wen-Liang Hwang category:cs.CV published:2015-12-14 summary:Blind image restoration is a non-convex problem which involves restoration ofimages from an unknown blur kernel. The factors affecting the performance ofthis restoration are how much prior information about an image and a blurkernel are provided and what algorithm is used to perform the restoration task.Prior information on images is often employed to restore the sharpness of theedges of an image. By contrast, no consensus is still present regarding whatprior information to use in restoring from a blur kernel due to complex imageblurring processes. In this paper, we propose modelling of a blur kernel as asparse linear combinations of basic 2-D patterns. Our approach has acompetitive edge over the existing blur kernel modelling methods because ourmethod has the flexibility to customize the dictionary design, which makes itwell-adaptive to a variety of applications. As a demonstration, we construct adictionary formed by basic patterns derived from the Kronecker product ofGaussian sequences. We also compare our results with those derived by otherstate-of-the-art methods, in terms of peak signal to noise ratio (PSNR).
arxiv-15300-193 | Sentence Entailment in Compositional Distributional Semantics | http://arxiv.org/pdf/1512.04419v1.pdf | author:Esma Balkir, Dimitri Kartsaklis, Mehrnoosh Sadrzadeh category:cs.CL cs.AI math.CT I.2.7 published:2015-12-14 summary:Distributional semantic models provide vector representations for words bygathering co-occurrence frequencies from corpora of text. Compositionaldistributional models extend these representations from words to phrases andsentences. In categorical compositional distributional semantics theserepresentations are built in such a manner that meanings of phrases andsentences are functions of their grammatical structure and the meanings of thewords therein. These models have been applied to reasoning about phrase andsentence level similarity. In this paper, we argue for and prove that thesemodels can also be used to reason about phrase and sentence level entailment.We provide preliminary experimental results on a toy entailment dataset.
arxiv-15300-194 | Near-Optimal Bounds for Binary Embeddings of Arbitrary Sets | http://arxiv.org/pdf/1512.04433v1.pdf | author:Samet Oymak, Ben Recht category:cs.LG cs.DS math.FA published:2015-12-14 summary:We study embedding a subset $K$ of the unit sphere to the Hamming cube$\{-1,+1\}^m$. We characterize the tradeoff between distortion and samplecomplexity $m$ in terms of the Gaussian width $\omega(K)$ of the set. Forsubspaces and several structured sets we show that Gaussian maps provide theoptimal tradeoff $m\sim \delta^{-2}\omega^2(K)$, in particular for $\delta$distortion one needs $m\approx\delta^{-2}{d}$ where $d$ is the subspacedimension. For general sets, we provide sharp characterizations which reducesto $m\approx{\delta^{-4}}{\omega^2(K)}$ after simplification. We provideimproved results for local embedding of points that are in close proximity ofeach other which is related to locality sensitive hashing. We also discussfaster binary embedding where one takes advantage of an initial sketchingprocedure based on Fast Johnson-Lindenstauss Transform. Finally, we listseveral numerical observations and discuss open problems.
arxiv-15300-195 | Memory-based control with recurrent neural networks | http://arxiv.org/pdf/1512.04455v1.pdf | author:Nicolas Heess, Jonathan J Hunt, Timothy P Lillicrap, David Silver category:cs.LG published:2015-12-14 summary:Partially observed control problems are a challenging aspect of reinforcementlearning. We extend two related, model-free algorithms for continuous control-- deterministic policy gradient and stochastic value gradient -- to solvepartially observed domains using recurrent neural networks trained withbackpropagation through time. We demonstrate that this approach, coupled with long-short term memory isable to solve a variety of physical control problems exhibiting an assortmentof memory requirements. These include the short-term integration of informationfrom noisy sensors and the identification of system parameters, as well aslong-term memory problems that require preserving information over many timesteps. We also demonstrate success on a combined exploration and memory problemin the form of a simplified version of the well-known Morris water maze task.Finally, we show that our approach can deal with high-dimensional observationsby learning directly from pixels. We find that recurrent deterministic and stochastic policies are able tolearn similarly good solutions to these tasks, including the water maze wherethe agent must learn effective search strategies.
arxiv-15300-196 | Fighting Bandits with a New Kind of Smoothness | http://arxiv.org/pdf/1512.04152v1.pdf | author:Jacob Abernethy, Chansoo Lee, Ambuj Tewari category:cs.LG cs.GT stat.ML published:2015-12-14 summary:We define a novel family of algorithms for the adversarial multi-armed banditproblem, and provide a simple analysis technique based on convex smoothing. Weprove two main results. First, we show that regularization via the\emph{Tsallis entropy}, which includes EXP3 as a special case, achieves the$\Theta(\sqrt{TN})$ minimax regret. Second, we show that a wide class ofperturbation methods achieve a near-optimal regret as low as $O(\sqrt{TN \logN})$ if the perturbation distribution has a bounded hazard rate. For example,the Gumbel, Weibull, Frechet, Pareto, and Gamma distributions all satisfy thiskey property.
arxiv-15300-197 | On non-iterative training of a neural classifier | http://arxiv.org/pdf/1512.04509v2.pdf | author:K. Eswaran, K. Damodhar Rao category:cs.CV cs.LG cs.NE 62M45 published:2015-12-14 summary:Recently an algorithm, was discovered, which separates points in n-dimensionby planes in such a manner that no two points are left un-separated by at leastone plane{[}1-3{]}. By using this new algorithm we show that there are two waysof classification by a neural network, for a large dimension feature space,both of which are non-iterative and deterministic. To demonstrate the power ofboth these methods we apply them exhaustively to the classical patternrecognition problem: The Fisher-Anderson's, IRIS flower data set and presentthe results. It is expected these methods will now be widely used for the training ofneural networks for Deep Learning not only because of their non-iterative anddeterministic nature but also because of their efficiency and speed and willsupersede other classification methods which are iterative in nature and relyon error minimization.
arxiv-15300-198 | Semisupervised Autoencoder for Sentiment Analysis | http://arxiv.org/pdf/1512.04466v1.pdf | author:Shuangfei Zhai, Zhongfei Zhang category:cs.LG published:2015-12-14 summary:In this paper, we investigate the usage of autoencoders in modeling textualdata. Traditional autoencoders suffer from at least two aspects: scalabilitywith the high dimensionality of vocabulary size and dealing withtask-irrelevant words. We address this problem by introducing supervision viathe loss function of autoencoders. In particular, we first train a linearclassifier on the labeled data, then define a loss for the autoencoder with theweights learned from the linear classifier. To reduce the bias brought by onesingle classifier, we define a posterior probability distribution on theweights of the classifier, and derive the marginalized loss of the autoencoderwith Laplace approximation. We show that our choice of loss function can berationalized from the perspective of Bregman Divergence, which justifies thesoundness of our model. We evaluate the effectiveness of our model on sixsentiment analysis datasets, and show that our model significantly outperformsall the competing methods with respect to classification accuracy. We also showthat our model is able to take advantage of unlabeled dataset and get improvedperformance. We further show that our model successfully learns highlydiscriminative feature maps, which explains its superior performance.
arxiv-15300-199 | Dropout Training of Matrix Factorization and Autoencoder for Link Prediction in Sparse Graphs | http://arxiv.org/pdf/1512.04483v1.pdf | author:Shuangfei Zhai, Zhongfei Zhang category:cs.LG published:2015-12-14 summary:Matrix factorization (MF) and Autoencoder (AE) are among the most successfulapproaches of unsupervised learning. While MF based models have beenextensively exploited in the graph modeling and link prediction literature, theAE family has not gained much attention. In this paper we investigate both MFand AE's application to the link prediction problem in sparse graphs. We showthe connection between AE and MF from the perspective of multiview learning,and further propose MF+AE: a model training MF and AE jointly with sharedparameters. We apply dropout to training both the MF and AE parts, and showthat it can significantly prevent overfitting by acting as an adaptiveregularization. We conduct experiments on six real world sparse graph datasets,and show that MF+AE consistently outperforms the competing methods, especiallyon datasets that demonstrate strong non-cohesive structures.
arxiv-15300-200 | Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks | http://arxiv.org/pdf/1512.04143v1.pdf | author:Sean Bell, C. Lawrence Zitnick, Kavita Bala, Ross Girshick category:cs.CV published:2015-12-14 summary:It is well known that contextual and multi-scale representations areimportant for accurate visual recognition. In this paper we present theInside-Outside Net (ION), an object detector that exploits information bothinside and outside the region of interest. Contextual information outside theregion of interest is integrated using spatial recurrent neural networks.Inside, we use skip pooling to extract information at multiple scales andlevels of abstraction. Through extensive experiments we evaluate the designspace and provide readers with an overview of what tricks of the trade areimportant. ION improves state-of-the-art on PASCAL VOC 2012 object detectionfrom 73.9% to 76.4% mAP. On the new and more challenging MS COCO dataset, weimprove state-of-art-the from 19.7% to 33.1% mAP. In the 2015 MS COCO DetectionChallenge, our ION model won the Best Student Entry and finished 3rd placeoverall. As intuition suggests, our detection results provide strong evidencethat context and multi-scale representations improve small object detection.
arxiv-15300-201 | Preconditioned Stochastic Gradient Descent | http://arxiv.org/pdf/1512.04202v1.pdf | author:Xi-Lin Li category:stat.ML cs.LG published:2015-12-14 summary:Stochastic gradient descent (SGD) still is the workhorse for many practicalproblems. However, it converges slow, and can be difficult to tune. It ispossible to precondition SGD to accelerate its convergence remarkably. But manyattempts in this direction either aim at solving specialized problems, orresult in significantly more complicated methods than SGD. This paper proposesa new way to estimate a preconditioner by equalizing the amplitudes ofparameter changes and the amplitudes of associated gradient changes. Unlike theHessian inverse like preconditioners based on secant equation fitting as donein deterministic quasi-Newton methods, which work the best when the Hessian ispositive definite, the new preconditioner works equally well for both convexand non-convex optimizations. When stochastic gradient is used, it cannaturally damp the gradient noise to stabilize SGD. Efficient preconditionerestimation methods are developed, and with reasonable simplifications, they areapplicable to large scaled problems. Experimental results demonstrate thatequipped with the new preconditioner, without any tuning effort, preconditionedSGD can efficiently solve many challenging problems like the training of a deepneural network or a recurrent neural network requiring extremely long termmemories.
arxiv-15300-202 | Origami: A 803 GOp/s/W Convolutional Network Accelerator | http://arxiv.org/pdf/1512.04295v2.pdf | author:Lukas Cavigelli, Luca Benini category:cs.CV cs.AI cs.LG cs.NE B.7.1; I.2.6 published:2015-12-14 summary:An ever increasing number of computer vision and image/video processingchallenges are being approached using deep convolutional neural networks,obtaining state-of-the-art results in object recognition and detection,semantic segmentation, action recognition, optical flow and superresolution.Hardware acceleration of these algorithms is essential to adopt theseimprovements in embedded and mobile computer vision systems. We present a newarchitecture, design and implementation as well as the first reported siliconmeasurements of such an accelerator, outperforming previous work in terms ofpower-, area- and I/O-efficiency. The manufactured device provides up to 196GOp/s on 3.09 mm^2 of silicon in UMC 65nm technology and can achieve a powerefficiency of 803 GOp/s/W. The massively reduced bandwidth requirements make itthe first architecture scalable to TOp/s performance.
arxiv-15300-203 | Understanding Human-Centric Images: From Geometry to Fashion | http://arxiv.org/pdf/1604.08164v1.pdf | author:Edgar Simo-Serra category:cs.CV published:2015-12-14 summary:Understanding humans from photographs has always been a fundamental goal ofcomputer vision. In this thesis we have developed a hierarchy of tools thatcover a wide range of topics with the objective of understanding humans frommonocular RGB image: from low level feature point descriptors to high levelfashion-aware conditional random fields models. In order to build these highlevel models it is paramount to have a battery of robust and reliable low andmid level cues. Along these lines, we have proposed two low-level keypointdescriptors: one based on the theory of the heat diffusion on images, and theother that uses a convolutional neural network to learn discriminative imagepatch representations. We also introduce distinct low-level generative modelsfor representing human pose: in particular we present a discrete model based ona directed acyclic graph and a continuous model that consists of posesclustered on a Riemannian manifold. As mid level cues we propose two 3D humanpose estimation algorithms: one that estimates the 3D pose given a noisy 2Destimation, and an approach that simultaneously estimates both the 2D and 3Dpose. Finally, we formulate higher level models built upon low and mid levelcues for understanding humans from single images. Concretely, we focus on twodifferent tasks in the context of fashion: semantic segmentation of clothing,and predicting the fashionability from images with metadata to ultimatelyprovide fashion advice to the user. For all presented approaches we presentextensive results and comparisons against the state-of-the-art and showsignificant improvements on the entire variety of tasks we tackle.
arxiv-15300-204 | We Are Humor Beings: Understanding and Predicting Visual Humor | http://arxiv.org/pdf/1512.04407v4.pdf | author:Arjun Chandrasekaran, Ashwin K. Vijayakumar, Stanislaw Antol, Mohit Bansal, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh category:cs.CV cs.CL cs.LG published:2015-12-14 summary:Humor is an integral part of human lives. Despite being tremendouslyimpactful, it is perhaps surprising that we do not have a detailedunderstanding of humor yet. As interactions between humans and AI systemsincrease, it is imperative that these systems are taught to understandsubtleties of human expressions such as humor. In this work, we are interestedin the question - what content in a scene causes it to be funny? As a firststep towards understanding visual humor, we analyze the humor manifested inabstract scenes and design computational models for them. We collect twodatasets of abstract scenes that facilitate the study of humor at both thescene-level and the object-level. We analyze the funny scenes and explore thedifferent types of humor depicted in them via human studies. We model two tasksthat we believe demonstrate an understanding of some aspects of visual humor.The tasks involve predicting the funniness of a scene and altering thefunniness of a scene. We show that our models perform well quantitatively, andqualitatively through human studies. Our datasets are publicly available.
arxiv-15300-205 | Small-footprint Deep Neural Networks with Highway Connections for Speech Recognition | http://arxiv.org/pdf/1512.04280v2.pdf | author:Liang Lu, Steve Renals category:cs.CL cs.LG cs.NE published:2015-12-14 summary:For speech recognition, deep neural networks (DNNs) have significantlyimproved the recognition accuracy in most of benchmark datasets and applicationdomains. However, compared to the conventional Gaussian mixture models,DNN-based acoustic models usually have much larger number of model parameters,making it challenging for their applications in resource constrained platforms,e.g., mobile devices. In this paper, we study the application of the recentlyproposed highway network to train small-footprint DNNs, which are {\it thinner}and {\it deeper}, and have significantly smaller number of model parameterscompared to conventional DNNs. We investigated this approach on the AMI meetingspeech transcription corpus which has around 70 hours of audio data. Thehighway neural networks constantly outperformed their plain DNN counterparts,and the number of model parameters can be reduced significantly withoutsacrificing the recognition accuracy.
arxiv-15300-206 | Automatic Incident Classification for Big Traffic Data by Adaptive Boosting SVM | http://arxiv.org/pdf/1512.04392v2.pdf | author:Li-Li Wang, Henry Y. T. Ngan, Nelson H. C. Yung category:cs.LG published:2015-12-14 summary:Modern cities experience heavy traffic flows and congestions regularly acrossspace and time. Monitoring traffic situations becomes an important challengefor the Traffic Control and Surveillance Systems (TCSS). In advanced TCSS, itis helpful to automatically detect and classify different traffic incidentssuch as severity of congestion, abnormal driving pattern, abrupt or illegalstop on road, etc. Although most TCSS are equipped with basic incidentdetection algorithms, they are however crude to be really useful as anautomated tool for further classification. In literature, there is a lack ofresearch for Automated Incident Classification (AIC). Therefore, a novel AICmethod is proposed in this paper to tackle such challenges. In the proposedmethod, traffic signals are firstly extracted from captured videos andconverted as spatial-temporal (ST) signals. Based on the characteristics of theST signals, a set of realistic simulation data are generated to construct anextended big traffic database to cover a variety of traffic situations. Next, aMean-Shift filter is introduced to suppress the effect of noise and extractsignificant features from the ST signals. The extracted features are thenassociated with various types of traffic data: one normal type (inliers) andmultiple abnormal types (outliers). For the classification, an adaptiveboosting classifier is trained to detect outliers in traffic dataautomatically. Further, a Support Vector Machine (SVM) based method is adoptedto train the model for identifying the categories of outliers. In short, thishybrid approach is called an Adaptive Boosting Support Vector Machines (AB-SVM)method. Experimental results show that the proposed AB-SVM method achieves asatisfied result with more than 92% classification accuracy on average.
arxiv-15300-207 | Relaxed Linearized Algorithms for Faster X-Ray CT Image Reconstruction | http://arxiv.org/pdf/1512.04564v1.pdf | author:Hung Nien, Jeffrey A. Fessler category:math.OC cs.LG stat.ML published:2015-12-14 summary:Statistical image reconstruction (SIR) methods are studied extensively forX-ray computed tomography (CT) due to the potential of acquiring CT scans withreduced X-ray dose while maintaining image quality. However, the longerreconstruction time of SIR methods hinders their use in X-ray CT in practice.To accelerate statistical methods, many optimization techniques have beeninvestigated. Over-relaxation is a common technique to speed up convergence ofiterative algorithms. For instance, using a relaxation parameter that is closeto two in alternating direction method of multipliers (ADMM) has been shown tospeed up convergence significantly. This paper proposes a relaxed linearizedaugmented Lagrangian (AL) method that shows theoretical faster convergence ratewith over-relaxation and applies the proposed relaxed linearized AL method toX-ray CT image reconstruction problems. Experimental results with bothsimulated and real CT scan data show that the proposed relaxed algorithm (withordered-subsets [OS] acceleration) is about twice as fast as the existingunrelaxed fast algorithms, with negligible computation and memory overhead.
arxiv-15300-208 | Semantic-enriched Visual Vocabulary Construction in a Weakly Supervised Context | http://arxiv.org/pdf/1512.04605v1.pdf | author:Marian-Andrei Rizoiu, Julien Velcin, StÃ©phane Lallich category:cs.CV published:2015-12-14 summary:One of the prevalent learning tasks involving images is content-based imageclassification. This is a difficult task especially because the low-levelfeatures used to digitally describe images usually capture little informationabout the semantics of the images. In this paper, we tackle this difficulty byenriching the semantic content of the image representation by using externalknowledge. The underlying hypothesis of our work is that creating a moresemantically rich representation for images would yield higher machine learningperformances, without the need to modify the learning algorithms themselves.The external semantic information is presented under the form of non-positionalimage labels, therefore positioning our work in a weakly supervised context.Two approaches are proposed: the first one leverages the labels into the visualvocabulary construction algorithm, the result being dedicated visualvocabularies. The second approach adds a filtering phase as a pre-processing ofthe vocabulary construction. Known positive and known negative sets areconstructed and features that are unlikely to be associated with the objectsdenoted by the labels are filtered. We apply our proposition to the task ofcontent-based image classification and we show that semantically enriching theimage representation yields higher classification performances than thebaseline representation.
arxiv-15300-209 | Multimodal, high-dimensional, model-based, Bayesian inverse problems with applications in biomechanics | http://arxiv.org/pdf/1512.04481v2.pdf | author:Isabell M. Franck, P. S. Koutsourelakis category:stat.CO stat.ML published:2015-12-14 summary:This paper is concerned with the numerical solution of model-based, Bayesianinverse problems. We are particularly interested in cases where the cost ofeach likelihood evaluation (forward-model call) is expensive and the number ofunknown (latent) variables is high. This is the setting of many problems incomputational physics where forward models with nonlinear PDEs are used and theparameters to be calibrated involve spatio-temporarily varying coefficients,which upon discretization give rise to a high-dimensional vector of unknowns. One of the consequences of the well-documented, ill-posedness of inverseproblems is the possibility of multiple solutions. While such information iscontained in the posterior density in Bayesian formulations, the discovery of asingle mode, let alone multiple, is a formidable task. The goal of the presentpaper is two-fold. On one hand, we propose approximate, adaptive inferencestrategies using mixture densities to capture multimodal posteriors, and on theother, to extend our work in \cite{franck_sparse_2015} with regards toeffective dimensionality reduction techniques that reveal low-dimensionalsubspaces where the posterior variance is mostly concentrated. We validate theproposed methodology in a problem in nonlinear elastography where theidentification of the mechanical properties of biological materials can informnon-invasive, medical diagnosis. The discovery of multiple modes (solutions) insuch problems is critical in achieving the diagnostic objectives.
arxiv-15300-210 | Big Data Scaling through Metric Mapping: Exploiting the Remarkable Simplicity of Very High Dimensional Spaces using Correspondence Analysis | http://arxiv.org/pdf/1512.04052v1.pdf | author:Fionn Murtagh category:stat.ML cs.LG 62H25 published:2015-12-13 summary:We present new findings in regard to data analysis in very high dimensionalspaces. We use dimensionalities up to around one million. A particular benefitof Correspondence Analysis is its suitability for carrying out an orthonormalmapping, or scaling, of power law distributed data. Power law distributed dataare found in many domains. Correspondence factor analysis provides a latentsemantic or principal axes mapping. Our experiments use data from digitalchemistry and finance, and other statistically generated data.
arxiv-15300-211 | Distributed Optimization with Arbitrary Local Solvers | http://arxiv.org/pdf/1512.04039v1.pdf | author:Chenxin Ma, Jakub KoneÄnÃ½, Martin Jaggi, Virginia Smith, Michael I. Jordan, Peter RichtÃ¡rik, Martin TakÃ¡Ä category:cs.LG math.OC published:2015-12-13 summary:With the growth of data and necessity for distributed optimization methods,solvers that work well on a single machine must be re-designed to leveragedistributed computation. Recent work in this area has been limited by focusingheavily on developing highly specific methods for the distributed environment.These special-purpose methods are often unable to fully leverage thecompetitive performance of their well-tuned and customized single machinecounterparts. Further, they are unable to easily integrate improvements thatcontinue to be made to single machine methods. To this end, we present aframework for distributed optimization that both allows the flexibility ofarbitrary solvers to be used on each (single) machine locally, and yetmaintains competitive performance against other state-of-the-artspecial-purpose distributed methods. We give strong primal-dual convergencerate guarantees for our framework that hold for arbitrary local solvers. Wedemonstrate the impact of local solver selection both theoretically and in anextensive experimental comparison. Finally, we provide thorough implementationdetails for our framework, highlighting areas for practical performance gains.
arxiv-15300-212 | Cross-dimensional Weighting for Aggregated Deep Convolutional Features | http://arxiv.org/pdf/1512.04065v1.pdf | author:Yannis Kalantidis, Clayton Mellina, Simon Osindero category:cs.CV published:2015-12-13 summary:We propose a simple and straightforward way of creating powerful imagerepresentations via cross-dimensional weighting and aggregation of deepconvolutional neural network layer outputs. We first present a generalizedframework that encompasses a broad family of approaches and includescross-dimensional pooling and weighting steps. We then propose specificnon-parametric schemes for both spatial- and channel-wise weighting, that boostthe effect of highly active spatial responses and at the same time regulateburstiness effects. We experiment on four public datasets for image search andunsupervised fine-grained classification and show that our approachconsistently outperforms the current state-of-the-art by a large margin.
arxiv-15300-213 | Tracking Idea Flows between Social Groups | http://arxiv.org/pdf/1512.04036v1.pdf | author:Yangxin Zhong, Shixia Liu, Xiting Wang, Jiannan Xiao, Yangqiu Song category:cs.SI cs.LG published:2015-12-13 summary:In many applications, ideas that are described by a set of words often flowbetween different groups. To facilitate users in analyzing the flow, we presenta method to model the flow behaviors that aims at identifying the lead-lagrelationships between word clusters of different user groups. In particular, animproved Bayesian conditional cointegration based on dynamic time warping isemployed to learn links between words in different groups. A tensor-basedtechnique is developed to cluster these linked words into different clusters(ideas) and track the flow of ideas. The main feature of the tensorrepresentation is that we introduce two additional dimensions to represent bothtime and lead-lag relationships. Experiments on both synthetic and realdatasets show that our method is more effective than methods based ontraditional clustering techniques and achieves better accuracy. A case studywas conducted to demonstrate the usefulness of our method in helping usersunderstand the flow of ideas between different user groups on social media
arxiv-15300-214 | Quantum Privacy-Preserving Data Mining | http://arxiv.org/pdf/1512.04009v2.pdf | author:Shenggang Ying, Mingsheng Ying, Yuan Feng category:quant-ph cs.CR cs.DB cs.LG published:2015-12-13 summary:Data mining is a key technology in big data analytics and it can discoverunderstandable knowledge (patterns) hidden in large data sets. Association ruleis one of the most useful knowledge patterns, and a large number of algorithmshave been developed in the data mining literature to generate association rulescorresponding to different problems and situations. Privacy becomes a vitalissue when data mining is used to sensitive data sets like medical records,commercial data sets and national security. In this Letter, we present aquantum protocol for mining association rules on vertically partitioneddatabases. The quantum protocol can improve the privacy level preserved byknown classical protocols and at the same time it can exponentially reduce thecomputational complexity and communication cost.
arxiv-15300-215 | True Online Temporal-Difference Learning | http://arxiv.org/pdf/1512.04087v1.pdf | author:Harm van Seijen, A. Rupam Mahmood, Patrick M. Pilarski, Marlos C. Machado, Richard S. Sutton category:cs.AI cs.LG published:2015-12-13 summary:The temporal-difference methods TD($\lambda$) and Sarsa($\lambda$) form acore part of modern reinforcement learning. Their appeal comes from their goodperformance, low computational cost, and their simple interpretation, given bytheir forward view. Recently, new versions of these methods were introduced,called true online TD($\lambda$) and true online Sarsa($\lambda$), respectively(van Seijen and Sutton, 2014). Algorithmically, these true online methods onlymake two small changes to the update rules of the regular methods, and theextra computational cost is negligible in most cases. However, they follow theideas underlying the forward view much more closely. In particular, theymaintain an exact equivalence with the forward view at all times, whereas thetraditional versions only approximate it for small step-sizes. We hypothesizethat these true online methods not only have better theoretical properties, butalso dominate the regular methods empirically. In this article, we put thishypothesis to the test by performing an extensive empirical comparison.Specifically, we compare the performance of true onlineTD($\lambda$)/Sarsa($\lambda$) with regular TD($\lambda$)/Sarsa($\lambda$) onrandom MRPs, a real-world myoelectric prosthetic arm, and a domain from theArcade Learning Environment. We use linear function approximation with tabular,binary, and non-binary features. Our results suggest that the true onlinemethods indeed dominate the regular methods. Across all domains/representationsthe learning speed of the true online methods are often better, but never worsethan that of the regular methods. An additional advantage is that no choicebetween traces has to be made for the true online methods. We show that newtrue online temporal-difference methods can be derived by making changes to thereal-time forward view and then rewriting the update equations.
arxiv-15300-216 | Stack Exchange Tagger | http://arxiv.org/pdf/1512.04092v1.pdf | author:Sanket Mehta, Shagun Sodhani category:cs.CL cs.LG published:2015-12-13 summary:The goal of our project is to develop an accurate tagger for questions postedon Stack Exchange. Our problem is an instance of the more general problem ofdeveloping accurate classifiers for large scale text datasets. We are tacklingthe multilabel classification problem where each item (in this case, question)can belong to multiple classes (in this case, tags). We are predicting the tags(or keywords) for a particular Stack Exchange post given only the question textand the title of the post. In the process, we compare the performance ofSupport Vector Classification (SVC) for different kernel functions, lossfunction, etc. We found linear SVC with Crammer Singer technique produces bestresults.
arxiv-15300-217 | Deep Relative Attributes | http://arxiv.org/pdf/1512.04103v1.pdf | author:Yaser Souri, Erfan Noury, Ehsan Adeli-Mosabbeb category:cs.CV published:2015-12-13 summary:Visual attributes are great means of describing images or scenes, in a wayboth humans and computers understand. In order to establish a correspondencebetween images and to be able to compare the strength of each property betweenimages, relative attributes were introduced. However, since their introduction,hand-crafted and engineered features were used to learn complex models for theproblem of relative attributes. This limits the applicability of those methodsfor more realistic cases. We introduce a two part deep learning architecturefor the task of relative attribute prediction. A convolutional neural network(ConvNet) architecture is adopted to learn the features with addition of anadditional layer (ranking layer) that learns to rank the images based on thesefeatures. Also an appropriate ranking loss is adapted to train the wholenetwork in an end-to-end fashion. Our proposed method outperforms the baselineand state-of-the-art methods in relative attribute prediction on variousdatasets. Our qualitative results also show that the network is able to learneffective features for the task. Furthermore, we use our trained models tovisualize saliency maps for each attribute.
arxiv-15300-218 | Policy Gradient Methods for Off-policy Control | http://arxiv.org/pdf/1512.04105v1.pdf | author:Lucas Lehnert, Doina Precup category:cs.AI cs.LG published:2015-12-13 summary:Off-policy learning refers to the problem of learning the value function of away of behaving, or policy, while following a different policy. Gradient-basedoff-policy learning algorithms, such as GTD and TDC/GQ, converge even whenusing function approximation and incremental updates. However, they have beendeveloped for the case of a fixed behavior policy. In control problems, onewould like to adapt the behavior policy over time to become more greedy withrespect to the existing value function. In this paper, we present the firstgradient-based learning algorithms for this problem, which rely on theframework of policy gradient in order to modify the behavior policy. We presentderivations of the algorithms, a convergence theorem, and empirical evidenceshowing that they compare favorably to existing approaches.
arxiv-15300-219 | L1-Regularized Distributed Optimization: A Communication-Efficient Primal-Dual Framework | http://arxiv.org/pdf/1512.04011v1.pdf | author:Virginia Smith, Simone Forte, Michael I. Jordan, Martin Jaggi category:cs.LG published:2015-12-13 summary:Despite the importance of sparsity in many big data applications, there arefew existing methods for efficient distributed optimization ofsparsely-regularized objectives. In this paper, we present acommunication-efficient framework for L1-regularized optimization indistributed environments. By taking a non-traditional view of classicalobjectives as part of a more general primal-dual setting, we obtain a new classof methods that can be efficiently distributed and is applicable to commonL1-regularized regression and classification objectives, such as Lasso, sparselogistic regression, and elastic net regression. We provide convergenceguarantees for this framework and demonstrate strong empirical performance ascompared to other state-of-the-art methods on several real-world distributeddatasets.
arxiv-15300-220 | Unsupervised Temporal Segmentation of Repetitive Human Actions Based on Kinematic Modeling and Frequency Analysis | http://arxiv.org/pdf/1512.04115v1.pdf | author:Qifei Wang, Gregorij Kurillo, Ferda Ofli, Ruzena Bajcsy category:cs.CV published:2015-12-13 summary:In this paper, we propose a method for temporal segmentation of humanrepetitive actions based on frequency analysis of kinematic parameters,zero-velocity crossing detection, and adaptive k-means clustering. Since thehuman motion data may be captured with different modalities which havedifferent temporal sampling rate and accuracy (e.g., optical motion capturesystems vs. Microsoft Kinect), we first apply a generic full-body kinematicmodel with an unscented Kalman filter to convert the motion data into a unifiedrepresentation that is robust to noise. Furthermore, we extract the mostrepresentative kinematic parameters via the primary frequency analysis. Thesequences are segmented based on zero-velocity crossing of the selectedparameters followed by an adaptive k-means clustering to identify therepetition segments. Experimental results demonstrate that for the motion datacaptured by both the motion capture system and the Microsoft Kinect, ourproposed algorithm obtains robust segmentation of repetitive action sequences.
arxiv-15300-221 | Action Recognition with Image Based CNN Features | http://arxiv.org/pdf/1512.03980v1.pdf | author:Mahdyar Ravanbakhsh, Hossein Mousavi, Mohammad Rastegari, Vittorio Murino, Larry S. Davis category:cs.CV published:2015-12-13 summary:Most of human actions consist of complex temporal compositions of more simpleactions. Action recognition tasks usually relies on complex handcraftedstructures as features to represent the human action model. ConvolutionalNeural Nets (CNN) have shown to be a powerful tool that eliminate the need fordesigning handcrafted features. Usually, the output of the last layer in CNN (alayer before the classification layer -known as fc7) is used as a genericfeature for images. In this paper, we show that fc7 features, per se, can notget a good performance for the task of action recognition, when the network istrained only on images. We present a feature structure on top of fc7 features,which can capture the temporal variation in a video. To represent the temporalcomponents, which is needed to capture motion information, we introduced ahierarchical structure. The hierarchical model enables to capture sub-actionsfrom a complex action. At the higher levels of the hierarchy, it represents acoarse capture of action sequence and lower levels represent fine actionelements. Furthermore, we introduce a method for extracting key-frames usingbinary coding of each frame in a video, which helps to improve the performanceof our hierarchical model. We experimented our method on several actiondatasets and show that our method achieves superior results compared to otherstate-of-the-arts methods.
arxiv-15300-222 | Evaluation of Pose Tracking Accuracy in the First and Second Generations of Microsoft Kinect | http://arxiv.org/pdf/1512.04134v1.pdf | author:Qifei Wang, Gregorij Kurillo, Ferda Ofli, Ruzena Bajcsy category:cs.CV cs.AI published:2015-12-13 summary:Microsoft Kinect camera and its skeletal tracking capabilities have beenembraced by many researchers and commercial developers in various applicationsof real-time human movement analysis. In this paper, we evaluate the accuracyof the human kinematic motion data in the first and second generation of theKinect system, and compare the results with an optical motion capture system.We collected motion data in 12 exercises for 10 different subjects and fromthree different viewpoints. We report on the accuracy of the joint localizationand bone length estimation of Kinect skeletons in comparison to the motioncapture. We also analyze the distribution of the joint localization offsets byfitting a mixture of Gaussian and uniform distribution models to determine theoutliers in the Kinect motion data. Our analysis shows that overall Kinect 2has more robust and more accurate tracking of human pose as compared to Kinect1.
arxiv-15300-223 | A Person Re-Identification System For Mobile Devices | http://arxiv.org/pdf/1512.04133v1.pdf | author:George Cushen category:cs.CV cs.CR cs.IR published:2015-12-13 summary:Person re-identification is a critical security task for recognizing a personacross spatially disjoint sensors. Previous work can be computationallyintensive and is mainly based on low-level cues extracted from RGB data andimplemented on a PC for a fixed sensor network (such as traditional CCTV). Wepresent a practical and efficient framework for mobile devices (such as smartphones and robots) where high-level semantic soft biometrics are extracted fromRGB and depth data. By combining these cues, our approach attempts to providerobustness to noise, illumination, and minor variations in clothing. Thismobile approach may be particularly useful for the identification of persons inareas ill-served by fixed sensors or for tasks where the sensor position anddirection need to dynamically adapt to a target. Results on the BIWI datasetare preliminary but encouraging. Further evaluation and demonstration of thesystem will be available on our website.
arxiv-15300-224 | Cloud-based Electronic Health Records for Real-time, Region-specific Influenza Surveillance | http://arxiv.org/pdf/1512.03990v1.pdf | author:Mauricio Santillana, Andre Nguyen, Tamara Louie, Anna Zink, Josh Gray, Iyue Sung, John S. Brownstein category:stat.AP stat.ML published:2015-12-13 summary:Accurate real-time monitoring systems of influenza outbreaks help publichealth officials make informed decisions that may help save lives. We show thatinformation extracted from cloud-based electronic health records databases, incombination with machine learning techniques and historical epidemiologicalinformation, have the potential to accurately and reliably provide nearreal-time regional predictions of flu outbreaks in the United States.
arxiv-15300-225 | Deep Tracking: Visual Tracking Using Deep Convolutional Networks | http://arxiv.org/pdf/1512.03993v1.pdf | author:Meera Hahn, Si Chen, Afshin Dehghan category:cs.CV published:2015-12-13 summary:In this paper, we study a discriminatively trained deep convolutional networkfor the task of visual tracking. Our tracker utilizes both motion andappearance features that are extracted from a pre-trained dual stream deepconvolution network. We show that the features extracted from our dual-streamnetwork can provide rich information about the target and this leads tocompetitive performance against state of the art tracking methods on a visualtracking benchmark.
arxiv-15300-226 | Learning the Correction for Multi-Path Deviations in Time-of-Flight Cameras | http://arxiv.org/pdf/1512.04077v2.pdf | author:Mojmir Mutny, Rahul Nair, Jens-Malte Gottfried category:cs.CV published:2015-12-13 summary:The Multipath effect in Time-of-Flight(ToF) cameras still remains to be achallenging problem that hinders further processing of 3D data information.Based on the evidence from previous literature, we explored the possibility ofusing machine learning techniques to correct this effect. Firstly, we createdtwo new datasets of of ToF images rendered via ToF simulator of LuxRender.These two datasets contain corners in multiple orientations and with differentmaterial properties. We chose scenes with corners as multipath effects are mostpronounced in corners. Secondly, we used this dataset to construct a learningmodel to predict real valued corrections to the ToF data using Random Forests.We found out that in our smaller dataset we were able to predict real valuedcorrection and improve the quality of depth images significantly by removingmultipath bias. With our algorithm, we improved relative per-pixel error fromaverage value of 19% to 3%. Additionally, variance of the error was lowered byan order of magnitude.
arxiv-15300-227 | Deep Learning-Based Image Kernel for Inductive Transfer | http://arxiv.org/pdf/1512.04086v3.pdf | author:Neeraj Kumar, Animesh Karmakar, Ranti Dev Sharma, Abhinav Mittal, Amit Sethi category:cs.CV published:2015-12-13 summary:We propose a method to classify images from target classes with a smallnumber of training examples based on transfer learning from non-target classes.Without using any more information than class labels for samples fromnon-target classes, we train a Siamese net to estimate the probability of twoimages to belong to the same class. With some post-processing, output of theSiamese net can be used to form a gram matrix of a Mercer kernel. Coupled witha support vector machine (SVM), such a kernel gave reasonable classificationaccuracy on target classes without any fine-tuning. When the Siamese net wasonly partially fine-tuned using a small number of samples from the targetclasses, the resulting classifier outperformed the state-of-the-art and otheralternatives. We share class separation capabilities and insights into thelearning process of such a kernel on MNIST, Dogs vs. Cats, and CIFAR-10datasets.
arxiv-15300-228 | Articulated Pose Estimation Using Hierarchical Exemplar-Based Models | http://arxiv.org/pdf/1512.04118v1.pdf | author:Jiongxin Liu, Yinxiao Li, Peter Allen, Peter Belhumeur category:cs.CV published:2015-12-13 summary:Exemplar-based models have achieved great success on localizing the parts ofsemi-rigid objects. However, their efficacy on highly articulated objects suchas humans is yet to be explored. Inspired by hierarchical object representationand recent application of Deep Convolutional Neural Networks (DCNNs) on humanpose estimation, we propose a novel formulation that incorporates bothhierarchical exemplar-based models and DCNNs in the spatial terms.Specifically, we obtain more expressive spatial models by assuming independencebetween exemplars at different levels in the hierarchy; we also obtain strongerspatial constraints by inferring the spatial relations between parts at thesame level. As our method strikes a good balance between expressiveness andstrength of spatial models, it is both effective and generalizable, achievingstate-of-the-art results on different benchmarks: Leeds Sports Dataset andCUB-200-2011.
arxiv-15300-229 | Active Distance-Based Clustering using K-medoids | http://arxiv.org/pdf/1512.03953v1.pdf | author:Mehrdad Ghadiri, Amin Aghaee, Mahdieh Soleymani Baghshah category:cs.LG published:2015-12-12 summary:k-medoids algorithm is a partitional, centroid-based clustering algorithmwhich uses pairwise distances of data points and tries to directly decomposethe dataset with $n$ points into a set of $k$ disjoint clusters. However,k-medoids itself requires all distances between data points that are not soeasy to get in many applications. In this paper, we introduce a new methodwhich requires only a small proportion of the whole set of distances and makesan effort to estimate an upper-bound for unknown distances using the inquiredones. This algorithm makes use of the triangle inequality to calculate anupper-bound estimation of the unknown distances. Our method is built upon arecursive approach to cluster objects and to choose some points actively fromeach bunch of data and acquire the distances between these prominent pointsfrom oracle. Experimental results show that the proposed method using only asmall subset of the distances can find proper clustering on many real-world andsynthetic datasets.
arxiv-15300-230 | A Hidden Markov Model Based System for Entity Extraction from Social Media English Text at FIRE 2015 | http://arxiv.org/pdf/1512.03950v1.pdf | author:Kamal Sarkar category:cs.CL 68T50 published:2015-12-12 summary:This paper presents the experiments carried out by us at Jadavpur Universityas part of the participation in FIRE 2015 task: Entity Extraction from SocialMedia Text - Indian Languages (ESM-IL). The tool that we have developed for thetask is based on Trigram Hidden Markov Model that utilizes information likegazetteer list, POS tag and some other word level features to enhance theobservation probabilities of the known tokens as well as unknown tokens. Wesubmitted runs for English only. A statistical HMM (Hidden Markov Models) basedmodel has been used to implement our system. The system has been trained andtested on the datasets released for FIRE 2015 task: Entity Extraction fromSocial Media Text - Indian Languages (ESM-IL). Our system is the best performerfor English language and it obtains precision, recall and F-measures of 61.96,39.46 and 48.21 respectively.
arxiv-15300-231 | Quantum assisted Gaussian process regression | http://arxiv.org/pdf/1512.03929v1.pdf | author:Zhikuan Zhao, Jack K. Fitzsimons, Joseph F. Fitzsimons category:quant-ph cs.LG stat.ML published:2015-12-12 summary:Gaussian processes (GP) are a widely used model for regression problems insupervised machine learning. Implementation of GP regression typically requires$O(n^3)$ logic gates. We show that the quantum linear systems algorithm [Harrowet al., Phys. Rev. Lett. 103, 150502 (2009)] can be applied to Gaussian processregression (GPR), leading to an exponential reduction in computation time insome instances. We show that even in some cases not ideally suited to thequantum linear systems algorithm, a polynomial increase in efficiency stilloccurs.
arxiv-15300-232 | RNN Fisher Vectors for Action Recognition and Image Annotation | http://arxiv.org/pdf/1512.03958v1.pdf | author:Guy Lev, Gil Sadeh, Benjamin Klein, Lior Wolf category:cs.CV published:2015-12-12 summary:Recurrent Neural Networks (RNNs) have had considerable success in classifyingand predicting sequences. We demonstrate that RNNs can be effectively used inorder to encode sequences and provide effective representations. Themethodology we use is based on Fisher Vectors, where the RNNs are thegenerative probabilistic models and the partial derivatives are computed usingbackpropagation. State of the art results are obtained in two central butdistant tasks, which both rely on sequences: video action recognition and imageannotation. We also show a surprising transfer learning result from the task ofimage annotation to the task of video action recognition.
arxiv-15300-233 | The Power of Depth for Feedforward Neural Networks | http://arxiv.org/pdf/1512.03965v4.pdf | author:Ronen Eldan, Ohad Shamir category:cs.LG cs.NE stat.ML published:2015-12-12 summary:We show that there is a simple (approximately radial) function on $\reals^d$,expressible by a small 3-layer feedforward neural networks, which cannot beapproximated by any 2-layer network, to more than a certain constant accuracy,unless its width is exponential in the dimension. The result holds forvirtually all known activation functions, including rectified linear units,sigmoids and thresholds, and formally demonstrates that depth -- even ifincreased by 1 -- can be exponentially more valuable than width for standardfeedforward neural networks. Moreover, compared to related results in thecontext of Boolean functions, our result requires fewer assumptions, and theproof techniques and construction are very different.
arxiv-15300-234 | Minimal Perceptrons for Memorizing Complex Patterns | http://arxiv.org/pdf/1512.03850v1.pdf | author:Marissa Pastor, Juyong Song, Danh-Tai Hoang, Junghyo Jo category:q-bio.NC cs.NE published:2015-12-12 summary:Feedforward neural networks have been investigated to understand learning andmemory, as well as applied to numerous practical problems in patternclassification. It is a rule of thumb that more complex tasks require largernetworks. However, the design of optimal network architectures for specifictasks is still an unsolved fundamental problem. In this study, we considerthree-layered neural networks for memorizing binary patterns. We developed anew complexity measure of binary patterns, and estimated the minimal networksize for memorizing them as a function of their complexity. We formulated theminimal network size for regular, random, and complex patterns. In particular,the minimal size for complex patterns, which are neither ordered nordisordered, was predicted by measuring their Hamming distances from knownordered patterns. Our predictions agreed with simulations based on theback-propagation algorithm.
arxiv-15300-235 | Active Sampler: Light-weight Accelerator for Complex Data Analytics at Scale | http://arxiv.org/pdf/1512.03880v1.pdf | author:Jinyang Gao, H. V. Jagadish, Beng Chin Ooi category:cs.DB cs.LG stat.ML published:2015-12-12 summary:Recent years have witnessed amazing outcomes from "Big Models" trained by"Big Data". Most popular algorithms for model training are iterative. Due tothe surging volumes of data, we can usually afford to process only a fractionof the training data in each iteration. Typically, the data are eitheruniformly sampled or sequentially accessed. In this paper, we study how the data access pattern can affect modeltraining. We propose an Active Sampler algorithm, where training data with more"learning value" to the model are sampled more frequently. The goal is to focustraining effort on valuable instances near the classification boundaries,rather than evident cases, noisy data or outliers. We show the correctness andoptimality of Active Sampler in theory, and then develop a light-weightvectorized implementation. Active Sampler is orthogonal to most approachesoptimizing the efficiency of large-scale data analytics, and can be applied tomost analytics models trained by stochastic gradient descent (SGD) algorithm.Extensive experimental evaluations demonstrate that Active Sampler can speed upthe training procedure of SVM, feature selection and deep learning, forcomparable training quality by 1.6-2.2x.
arxiv-15300-236 | Sparse Generalized Principal Component Analysis for Large-scale Applications beyond Gaussianity | http://arxiv.org/pdf/1512.03883v2.pdf | author:Qiaoya Zhang, Yiyuan She category:stat.CO stat.ML published:2015-12-12 summary:Principal Component Analysis (PCA) is a dimension reduction technique. Itproduces inconsistent estimators when the dimensionality is moderate to high,which is often the problem in modern large-scale applications where algorithmscalability and model interpretability are difficult to achieve, not to mentionthe prevalence of missing values. While existing sparse PCA methods alleviateinconsistency, they are constrained to the Gaussian assumption of classical PCAand fail to address algorithm scalability issues. We generalize sparse PCA tothe broad exponential family distributions under high-dimensional setup, withbuilt-in treatment for missing values. Meanwhile we propose a family ofiterative sparse generalized PCA (SG-PCA) algorithms such that despite thenon-convexity and non-smoothness of the optimization task, the loss functiondecreases in every iteration. In terms of ease and intuitive parameter tuning,our sparsity-inducing regularization is far superior to the popular Lasso.Furthermore, to promote overall scalability, accelerated gradient is integratedfor fast convergence, while a progressive screening technique graduallysqueezes out nuisance dimensions of a large-scale problem for feasibleoptimization. High-dimensional simulation and real data experiments demonstratethe efficiency and efficacy of SG-PCA.
arxiv-15300-237 | Improving Human Activity Recognition Through Ranking and Re-ranking | http://arxiv.org/pdf/1512.03740v1.pdf | author:Zhenzhong Lan, Shoou-I Yu, Alexander G. Hauptmann category:cs.CV published:2015-12-11 summary:We propose two well-motivated ranking-based methods to enhance theperformance of current state-of-the-art human activity recognition systems.First, as an improvement over the classic power normalization method, wepropose a parameter-free ranking technique called rank normalization (RaN). RaNnormalizes each dimension of the video features to address the sparse andbursty distribution problems of Fisher Vectors and VLAD. Second, inspired bycurriculum learning, we introduce a training-free re-ranking technique calledmulti-class iterative re-ranking (MIR). MIR captures relationships among actionclasses by separating easy and typical videos from difficult ones andre-ranking the prediction scores of classifiers accordingly. We demonstratethat our methods significantly improve the performance of state-of-the-artmotion features on six real-world datasets.
arxiv-15300-238 | A New Approach of Gray Images Binarization with Threshold Methods | http://arxiv.org/pdf/1512.03706v1.pdf | author:Andrei Hossu, Daniela Andone category:cs.CV published:2015-12-11 summary:The paper presents some aspects of the (gray level) image binarizationmethods used in artificial vision systems. It is introduced a new approach ofgray level image binarization for artificial vision systems dedicated toindustrial automation temporal thresholding. In the first part of the paper areextracted some limitations of using the global optimum thresholding in graylevel image binarization. In the second part of this paper are presented someaspects of the dynamic optimum thresholding method for gray level imagebinarization. Starting from classic methods of global and dynamic optimalthresholding of the gray level images in the next section are introduced theconcepts of temporal histogram and temporal thresholding. In the final sectionare presented some practical aspects of the temporal thresholding method inartificial vision applications form the moving scene in robotic automationclass; pointing out the influence of the acquisition frequency on the methodsresults.
arxiv-15300-239 | Deep Feature Learning with Relative Distance Comparison for Person Re-identification | http://arxiv.org/pdf/1512.03622v1.pdf | author:Shengyong Ding, Liang Lin, Guangrun Wang, Hongyang Chao category:cs.CV published:2015-12-11 summary:Identifying the same individual across different scenes is an important yetdifficult task in intelligent video surveillance. Its main difficulty lies inhow to preserve similarity of the same person against large appearance andstructure variation while discriminating different individuals. In this paper,we present a scalable distance driven feature learning framework based on thedeep neural network for person re-identification, and demonstrate itseffectiveness to handle the existing challenges. Specifically, given thetraining images with the class labels (person IDs), we first produce a largenumber of triplet units, each of which contains three images, i.e. one personwith a matched reference and a mismatched reference. Treating the units as theinput, we build the convolutional neural network to generate the layeredrepresentations, and follow with the $L2$ distance metric. By means ofparameter optimization, our framework tends to maximize the relative distancebetween the matched pair and the mismatched pair for each triplet unit.Moreover, a nontrivial issue arising with the framework is that the tripletorganization cubically enlarges the number of training triplets, as one imagecan be involved into several triplet units. To overcome this problem, wedevelop an effective triplet generation scheme and an optimized gradientdescent algorithm, making the computational load mainly depends on the numberof original images instead of the number of triplets. On several challengingdatabases, our approach achieves very promising results and outperforms otherstate-of-the-art approaches.
arxiv-15300-240 | Robust Dictionary based Data Representation | http://arxiv.org/pdf/1512.03617v1.pdf | author:Wei-Ya Ren category:cs.CV published:2015-12-11 summary:The robustness to noise and outliers is an important issue in linearrepresentation in real applications. We focus on the problem that samples aregrossly corrupted, which is also the 'sample specific' corruptions problem. Areasonable assumption is that corrupted samples cannot be represented by thedictionary while clean samples can be well represented. This assumption isenforced in this paper by investigating the coefficients of corrupted samples.Concretely, we require the coefficients of corrupted samples be zero. In thisway, the representation quality of clean data can be assured without the effectof corrupted data. At last, a robust dictionary based data representationapproach and its sparse representation version are proposed, which havedirective significance for future applications.
arxiv-15300-241 | Words are not Equal: Graded Weighting Model for building Composite Document Vectors | http://arxiv.org/pdf/1512.03549v1.pdf | author:Pranjal Singh, Amitabha Mukerjee category:cs.CL cs.LG cs.NE published:2015-12-11 summary:Despite the success of distributional semantics, composing phrases from wordvectors remains an important challenge. Several methods have been tried forbenchmark tasks such as sentiment classification, including word vectoraveraging, matrix-vector approaches based on parsing, and on-the-fly learningof paragraph vectors. Most models usually omit stop words from the composition.Instead of such an yes-no decision, we consider several graded schemes wherewords are weighted according to their discriminatory relevance with respect toits use in the document (e.g., idf). Some of these methods (particularlytf-idf) are seen to result in a significant improvement in performance overprior state of the art. Further, combining such approaches into an ensemblebased on alternate classifiers such as the RNN model, results in an 1.6%performance improvement on the standard IMDB movie review dataset, and a 7.01%improvement on Amazon product reviews. Since these are language free models andcan be obtained in an unsupervised manner, they are of interest also forunder-resourced languages such as Hindi as well and many more languages. Wedemonstrate the language free aspects by showing a gain of 12% for two reviewdatasets over earlier results, and also release a new larger dataset for futuretesting (Singh,2015).
arxiv-15300-242 | Efficient Deep Feature Learning and Extraction via StochasticNets | http://arxiv.org/pdf/1512.03844v1.pdf | author:Mohammad Javad Shafiee, Parthipan Siva, Paul Fieguth, Alexander Wong category:cs.LG stat.ML published:2015-12-11 summary:Deep neural networks are a powerful tool for feature learning and extractiongiven their ability to model high-level abstractions in highly complex data.One area worth exploring in feature learning and extraction using deep neuralnetworks is efficient neural connectivity formation for faster feature learningand extraction. Motivated by findings of stochastic synaptic connectivityformation in the brain as well as the brain's uncanny ability to efficientlyrepresent information, we propose the efficient learning and extraction offeatures via StochasticNets, where sparsely-connected deep neural networks canbe formed via stochastic connectivity between neurons. To evaluate thefeasibility of such a deep neural network architecture for feature learning andextraction, we train deep convolutional StochasticNets to learn abstractfeatures using the CIFAR-10 dataset, and extract the learned features fromimages to perform classification on the SVHN and STL-10 datasets. Experimentalresults show that features learned using deep convolutional StochasticNets,with fewer neural connections than conventional deep convolutional neuralnetworks, can allow for better or comparable classification accuracy thanconventional deep neural networks: relative test error decrease of ~4.5% forclassification on the STL-10 dataset and ~1% for classification on the SVHNdataset. Furthermore, it was shown that the deep features extracted using deepconvolutional StochasticNets can provide comparable classification accuracyeven when only 10% of the training data is used for feature learning. Finally,it was also shown that significant gains in feature extraction speed can beachieved in embedded applications using StochasticNets. As such, StochasticNetsallow for faster feature learning and extraction performance while facilitatefor better or comparable accuracy performances.
arxiv-15300-243 | Distilling Knowledge from Deep Networks with Applications to Healthcare Domain | http://arxiv.org/pdf/1512.03542v1.pdf | author:Zhengping Che, Sanjay Purushotham, Robinder Khemani, Yan Liu category:stat.ML cs.LG published:2015-12-11 summary:Exponential growth in Electronic Healthcare Records (EHR) has resulted in newopportunities and urgent needs for discovery of meaningful data-drivenrepresentations and patterns of diseases in Computational Phenotyping research.Deep Learning models have shown superior performance for robust prediction incomputational phenotyping tasks, but suffer from the issue of modelinterpretability which is crucial for clinicians involved in decision-making.In this paper, we introduce a novel knowledge-distillation approach calledInterpretable Mimic Learning, to learn interpretable phenotype features formaking robust prediction while mimicking the performance of deep learningmodels. Our framework uses Gradient Boosting Trees to learn interpretablefeatures from deep learning models such as Stacked Denoising Autoencoder andLong Short-Term Memory. Exhaustive experiments on a real-world clinicaltime-series dataset show that our method obtains similar or better performancethan the deep learning models, and it provides interpretable phenotypes forclinical decision making.
arxiv-15300-244 | Randomized Low-Rank Dynamic Mode Decomposition for Motion Detection | http://arxiv.org/pdf/1512.03526v1.pdf | author:N. Benjamin Erichson, Carl Donovan category:cs.CV published:2015-12-11 summary:This paper introduces a fast algorithm for randomized computation of alow-rank Dynamic Mode Decomposition (DMD) of a matrix. Here we consider thismatrix to represent the development of a spatial grid through time e.g. datafrom a static video source. DMD was originally introduced in the fluidmechanics community, but is also suitable for motion detection in video streamsand its use for background subtraction has received little previousinvestigation. In this study we present a comprehensive evaluation ofbackground subtraction, using the randomized DMD and compare the results withleading robust principal component analysis algorithms. The results areconvincing and show the random DMD is an efficient and powerful approach forbackground modeling, allowing processing of high resolution videos inreal-time. Supplementary materials include implementations of the algorithms inPython.
arxiv-15300-245 | A Unified Approach to Error Bounds for Structured Convex Optimization Problems | http://arxiv.org/pdf/1512.03518v1.pdf | author:Zirui Zhou, Anthony Man-Cho So category:math.OC cs.LG math.NA stat.ML published:2015-12-11 summary:Error bounds, which refer to inequalities that bound the distance of vectorsin a test set to a given set by a residual function, have proven to beextremely useful in analyzing the convergence rates of a host of iterativemethods for solving optimization problems. In this paper, we present a newframework for establishing error bounds for a class of structured convexoptimization problems, in which the objective function is the sum of a smoothconvex function and a general closed proper convex function. Such a classencapsulates not only fairly general constrained minimization problems but alsovarious regularized loss minimization formulations in machine learning, signalprocessing, and statistics. Using our framework, we show that a number ofexisting error bound results can be recovered in a unified and transparentmanner. To further demonstrate the power of our framework, we apply it to aclass of nuclear-norm regularized loss minimization problems and establish anew error bound for this class under a strict complementarity-type regularitycondition. We then complement this result by constructing an example to showthat the said error bound could fail to hold without the regularity condition.Consequently, we obtain a rather complete answer to a question raised by Tseng.We believe that our approach will find further applications in the study oferror bounds for structured convex optimization problems.
arxiv-15300-246 | Computing factorized approximations of Pareto-fronts using mNM-landscapes and Boltzmann distributions | http://arxiv.org/pdf/1512.03466v1.pdf | author:Roberto Santana, Alexander Mendiburu, Jose A. Lozano category:cs.NE published:2015-12-10 summary:NM-landscapes have been recently introduced as a class of tunable ruggedmodels. They are a subset of the general interaction models where all theinteractions are of order less or equal $M$. The Boltzmann distribution hasbeen extensively applied in single-objective evolutionary algorithms toimplement selection and study the theoretical properties of model-buildingalgorithms. In this paper we propose the combination of the multi-objectiveNM-landscape model and the Boltzmann distribution to obtain Pareto-frontapproximations. We investigate the joint effect of the parameters of theNM-landscapes and the probabilistic factorizations in the shape of the Paretofront approximations.
arxiv-15300-247 | Deep Residual Learning for Image Recognition | http://arxiv.org/pdf/1512.03385v1.pdf | author:Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun category:cs.CV published:2015-12-10 summary:Deeper neural networks are more difficult to train. We present a residuallearning framework to ease the training of networks that are substantiallydeeper than those used previously. We explicitly reformulate the layers aslearning residual functions with reference to the layer inputs, instead oflearning unreferenced functions. We provide comprehensive empirical evidenceshowing that these residual networks are easier to optimize, and can gainaccuracy from considerably increased depth. On the ImageNet dataset we evaluateresidual nets with a depth of up to 152 layers---8x deeper than VGG nets butstill having lower complexity. An ensemble of these residual nets achieves3.57% error on the ImageNet test set. This result won the 1st place on theILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100and 1000 layers. The depth of representations is of central importance for many visualrecognition tasks. Solely due to our extremely deep representations, we obtaina 28% relative improvement on the COCO object detection dataset. Deep residualnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,where we also won the 1st places on the tasks of ImageNet detection, ImageNetlocalization, COCO detection, and COCO segmentation.
arxiv-15300-248 | Deep Learning Algorithms with Applications to Video Analytics for A Smart City: A Survey | http://arxiv.org/pdf/1512.03131v1.pdf | author:Li Wang, Dennis Sng category:cs.CV published:2015-12-10 summary:Deep learning has recently achieved very promising results in a wide range ofareas such as computer vision, speech recognition and natural languageprocessing. It aims to learn hierarchical representations of data by using deeparchitecture models. In a smart city, a lot of data (e.g. videos captured frommany distributed sensors) need to be automatically processed and analyzed. Inthis paper, we review the deep learning algorithms applied to video analyticsof smart city in terms of different research topics: object detection, objecttracking, face recognition, image classification and scene labeling.
arxiv-15300-249 | Measuring Semantic Relatedness using Mined Semantic Analysis | http://arxiv.org/pdf/1512.03465v1.pdf | author:Walid Shalaby, Wlodek Zadrozny category:cs.CL H.3.1 published:2015-12-10 summary:Mined Semantic Analysis (MSA) is a novel distributional semantics approachwhich employs data mining techniques. MSA embraces knowledge-driven analysis ofnatural languages. It uncovers implicit relations between concepts by miningfor their associations in target encyclopedic corpora. MSA exploits not onlytarget corpus content but also its knowledge graph (e.g., "See also" link graphof Wikipedia). Empirical results show competitive performance of MSA comparedto prior state-of-the-art methods for measuring semantic relatedness onbenchmark data sets. Additionally, we introduce the first analytical study toexamine statistical significance of results reported by different semanticrelatedness methods. Our study shows that, top performing results could bestatistically equivalent though mathematically different. The study positionsMSA as one of state-of-the-art methods for measuring semantic relatedness.
arxiv-15300-250 | Convolutional Monte Carlo Rollouts in Go | http://arxiv.org/pdf/1512.03375v1.pdf | author:Peter H. Jin, Kurt Keutzer category:cs.LG cs.AI published:2015-12-10 summary:In this work, we present a MCTS-based Go-playing program which usesconvolutional networks in all parts. Our method performs MCTS in batches,explores the Monte Carlo search tree using Thompson sampling and aconvolutional network, and evaluates convnet-based rollouts on the GPU. Weachieve strong win rates against open source Go programs and attain competitiveresults against state of the art convolutional net-based Go-playing programs.
arxiv-15300-251 | Boosted Sparse Non-linear Distance Metric Learning | http://arxiv.org/pdf/1512.03396v1.pdf | author:Yuting Ma, Tian Zheng category:stat.ML cs.LG published:2015-12-10 summary:This paper proposes a boosting-based solution addressing metric learningproblems for high-dimensional data. Distance measures have been used as naturalmeasures of (dis)similarity and served as the foundation of various learningmethods. The efficiency of distance-based learning methods heavily depends onthe chosen distance metric. With increasing dimensionality and complexity ofdata, however, traditional metric learning methods suffer from poor scalabilityand the limitation due to linearity as the true signals are usually embeddedwithin a low-dimensional nonlinear subspace. In this paper, we propose anonlinear sparse metric learning algorithm via boosting. We restructure aglobal optimization problem into a forward stage-wise learning of weak learnersbased on a rank-one decomposition of the weight matrix in the Mahalanobisdistance metric. A gradient boosting algorithm is devised to obtain a sparserank-one update of the weight matrix at each step. Nonlinear features arelearned by a hierarchical expansion of interactions incorporated within theboosting algorithm. Meanwhile, an early stopping rule is imposed to control theoverall complexity of the learned metric. As a result, our approach guaranteesthree desirable properties of the final metric: positive semi-definiteness, lowrank and element-wise sparsity. Numerical experiments show that our learningmodel compares favorably with the state-of-the-art methods in the currentliterature of metric learning.
arxiv-15300-252 | Predicting proximity with ambient mobile sensors for non-invasive health diagnostics | http://arxiv.org/pdf/1512.03423v1.pdf | author:Sylvester Olubolu Orimaye, Foo Chuan Leong, Chen Hui Lee, Eddy Cheng Han Ng category:cs.CY cs.LG published:2015-12-10 summary:Modern smart phones are becoming helpful in the areas of Internet-Of-Things(IoT) and ambient health intelligence. By learning data from several mobilesensors, we detect nearness of the human body to a mobile device in athree-dimensional space with no physical contact with the device fornon-invasive health diagnostics. We show that the human body generates wavepatterns that interact with other naturally occurring ambient signals thatcould be measured by mobile sensors, such as, temperature, humidity, magneticfield, acceleration, gravity, and light. This interaction consequentiallyalters the patterns of the naturally occurring signals, and thus, exhibitscharacteristics that could be learned to predict the nearness of the human bodyto a mobile device, hence provide diagnostic information for medicalpractitioners. Our prediction technique achieved 88.75% accuracy and 88.3%specificity.
arxiv-15300-253 | Scalable Modeling of Conversational-role based Self-presentation Characteristics in Large Online Forums | http://arxiv.org/pdf/1512.03443v1.pdf | author:Abhimanu Kumar, Shriphani Palakodety, Chong Wang, Carolyn P. Rose, Eric P. Xing, Miaomiao Wen category:stat.ML cs.SI published:2015-12-10 summary:Online discussion forums are complex webs of overlapping subcommunities(macrolevel structure, across threads) in which users enact different rolesdepending on which subcommunity they are participating in within a particulartime point (microlevel structure, within threads). This sub-network structureis implicit in massive collections of threads. To uncover this structure, wedevelop a scalable algorithm based on stochastic variational inference andleverage topic models (LDA) along with mixed membership stochastic block (MMSB)models. We evaluate our model on three large-scale datasets,Cancer-ThreadStarter (22K users and 14.4K threads), Cancer-NameMention(15.1Kusers and 12.4K threads) and StackOverFlow (1.19 million users and 4.55 millionthreads). Qualitatively, we demonstrate that our model can provide usefulexplanations of microlevel and macrolevel user presentation characteristics indifferent communities using the topics discovered from posts. Quantitatively,we show that our model does better than MMSB and LDA in predicting user replystructure within threads. In addition, we demonstrate via synthetic dataexperiments that the proposed active sub-network discovery model is stable andrecovers the original parameters of the experimental setup with highprobability.
arxiv-15300-254 | Gated networks: an inventory | http://arxiv.org/pdf/1512.03201v1.pdf | author:Olivier Sigaud, ClÃ©ment Masson, David Filliat, Freek Stulp category:cs.LG published:2015-12-10 summary:Gated networks are networks that contain gating connections, in which theoutputs of at least two neurons are multiplied. Initially, gated networks wereused to learn relationships between two input sources, such as pixels from twoimages. More recently, they have been applied to learning activity recognitionor multi-modal representations. The aims of this paper are threefold: 1) toexplain the basic computations in gated networks to the non-expert, whileadopting a standpoint that insists on their symmetric nature. 2) to serve as aquick reference guide to the recent literature, by providing an inventory ofapplications of these networks, as well as recent extensions to the basicarchitecture. 3) to suggest future research directions and applications.
arxiv-15300-255 | Enhanced image feature coverage: Key-point selection using genetic algorithms | http://arxiv.org/pdf/1512.03155v1.pdf | author:Erkan Bostanci category:cs.CV published:2015-12-10 summary:Coverage of image features play an important role in many vision algorithmssince their distribution affect the estimated homography. This paper presents aGenetic Algorithm (GA) in order to select the optimal set of features yieldingmaximum coverage of the image which is measured by a robust method based onspatial statistics. It is shown with statistical tests on two datasets that themetric yields better coverage and this is also confirmed by an accuracy test onthe computed homography for the original set and the newly selected set offeatures. Results have demonstrated that the new set has similar performance interms of the accuracy of the computed homography with the original one with anextra benefit of using fewer number of features ultimately reducing the timerequired for descriptor calculation and matching.
arxiv-15300-256 | Norm-Free Radon-Nikodym Approach to Machine Learning | http://arxiv.org/pdf/1512.03219v2.pdf | author:Vladislav Gennadievich Malyshkin category:cs.LG stat.ML published:2015-12-10 summary:For Machine Learning (ML) classification problem, where a vector of$\mathbf{x}$--observations (values of attributes) is mapped to a single $y$value (class label), a generalized Radon--Nikodym type of solution is proposed.Quantum--mechanics --like probability states $\psi^2(\mathbf{x})$ areconsidered and "Cluster Centers", corresponding to the extremums of$<y\psi^2(\mathbf{x})>/<\psi^2(\mathbf{x})>$, are found from generalizedeigenvalues problem. The eigenvalues give possible $y^{[i]}$ outcomes andcorresponding to them eigenvectors $\psi^{[i]}(\mathbf{x})$ define "ClusterCenters". The projection of a $\psi$ state, localized at given $\mathbf{x}$ toclassify, on these eigenvectors define the probability of $y^{[i]}$ outcome,thus avoiding using a norm ($L^2$ or other types), required for "qualitycriteria" in a typical Machine Learning technique. A coverage of each `ClusterCenter" is calculated, what potentially allows to separate system properties(described by $y^{[i]}$ outcomes) and system testing conditions (described by$C^{[i]}$ coverage). As an example of such application $y$ distributionestimator is proposed in a form of pairs $(y^{[i]},C^{[i]})$, that can beconsidered as Gauss quadratures generalization. This estimator allows toperform $y$ probability distribution estimation in a strongly non--Gaussiancase.
arxiv-15300-257 | 3D Reconstruction of Crime Scenes and Design Considerations for an Interactive Investigation Tool | http://arxiv.org/pdf/1512.03156v1.pdf | author:Erkan Bostanci category:cs.CV published:2015-12-10 summary:Crime Scene Investigation (CSI) is a carefully planned systematic processwith the purpose of acquiring physical evidences to shed light upon thephysical reality of the crime and eventually detect the identity of thecriminal. Capturing images and videos of the crime scene is an important partof this process in order to conduct a deeper analysis on the digital evidencefor possible hints. This work brings this idea further to use the acquiredfootage for generating a 3D model of the crime scene. Results show thatrealistic reconstructions can be obtained using sophisticated computer visiontechniques. The paper also discusses a number of important designconsiderations describing key features that should be present in a powerfulinteractive CSI analysis tool.
arxiv-15300-258 | Cross-Validated Variable Selection in Tree-Based Methods Improves Predictive Performance | http://arxiv.org/pdf/1512.03444v1.pdf | author:Amichai Painsky, Saharon Rosset category:stat.ML published:2015-12-10 summary:Recursive partitioning approaches producing tree-like models are a longstanding staple of predictive modeling, in the last decade mostly as``sub-learners'' within state of the art ensemble methods like Boosting andRandom Forest. However, a fundamental flaw in the partitioning (or splitting)rule of commonly used tree building methods precludes them from treatingdifferent types of variables equally. This most clearly manifests in thesemethods' inability to properly utilize categorical variables with a largenumber of categories, which are ubiquitous in the new age of big data. Suchvariables can often be very informative, but current tree methods essentiallyleave us a choice of either not using them, or exposing our models to severeoverfitting. We propose a conceptual framework to splitting using leave-one-out(LOO) cross validation for selecting the splitting variable, then performing aregular split (in our case, following CART's approach) for the selectedvariable. The most important consequence of our approach is that categoricalvariables with many categories can be safely used in tree building and are onlychosen if they contribute to predictive power. We demonstrate in extensivesimulation and real data analysis that our novel splitting approachsignificantly improves the performance of both single tree models and ensemblemethods that utilize trees. Importantly, we design an algorithm for LOOsplitting variable selection which under reasonable assumptions does notincrease the overall computational complexity compared to CART for two-classclassification. For regression tasks, our approach carries an increasedcomputational burden, replacing a O(log(n)) factor in CART splitting rulesearch with an O(n) term.
arxiv-15300-259 | Neural Self Talk: Image Understanding via Continuous Questioning and Answering | http://arxiv.org/pdf/1512.03460v1.pdf | author:Yezhou Yang, Yi Li, Cornelia Fermuller, Yiannis Aloimonos category:cs.CV cs.CL cs.RO I.2.10 published:2015-12-10 summary:In this paper we consider the problem of continuously discovering imagecontents by actively asking image based questions and subsequently answeringthe questions being asked. The key components include a Visual QuestionGeneration (VQG) module and a Visual Question Answering module, in whichRecurrent Neural Networks (RNN) and Convolutional Neural Network (CNN) areused. Given a dataset that contains images, questions and their answers, bothmodules are trained at the same time, with the difference being VQG uses theimages as input and the corresponding questions as output, while VQA usesimages and questions as input and the corresponding answers as output. Weevaluate the self talk process subjectively using Amazon Mechanical Turk, whichshow effectiveness of the proposed method.
arxiv-15300-260 | The p-filter: multi-layer FDR control for grouped hypotheses | http://arxiv.org/pdf/1512.03397v2.pdf | author:Rina Foygel Barber, Aaditya Ramdas category:stat.ME stat.ML published:2015-12-10 summary:In many practical applications of multiple hypothesis testing using the FalseDiscovery Rate (FDR), the given hypotheses can be naturally partitioned intogroups, and one may not only want to control the number of false discoveries(wrongly rejected null hypotheses), but also the number of falsely discoveredgroups of hypotheses (we say a group is falsely discovered if at least onehypothesis within that group is rejected, when in reality the group containsonly nulls). In this paper, we introduce the p-filter, a procedure whichunifies and generalizes the standard FDR procedure by Benjamini and Hochbergand global null testing procedure by Simes. We first prove that our proposedmethod can simultaneously control the overall FDR at the finest level(individual hypotheses treated separately) and the group FDR at coarser levels(when such groups are user-specified). We then generalize the p-filterprocedure even further to handle multiple partitions of hypotheses, since thatmight be natural in many applications. For example, in neuroscienceexperiments, we may have a hypothesis for every (discretized) location in thebrain, and at every (discretized) timepoint: does the stimulus correlate withactivity in location x at time t after the stimulus was presented? In thissetting, one might want to group hypotheses by location and by time.Importantly, our procedure can handle multiple partitions which arenonhierarchical (i.e. one partition may arrange p-values by voxel, and anotherpartition arranges them by time point; neither one is nested inside the other).We prove that our procedure controls FDR simultaneously across these multiplelay- ers, under assumptions that are standard in the literature: we do not needthe hypotheses to be independent, but require a nonnegative dependencecondition known as PRDS.
arxiv-15300-261 | Guaranteed algorithms for inference in topic models | http://arxiv.org/pdf/1512.03308v1.pdf | author:Khoat Than, Tung Doan category:stat.ML published:2015-12-10 summary:One of the core problems in statistical models is the estimation of aposterior distribution. For topic models, the problem of posterior inferencefor individual texts is particularly important, especially when dealing withdata streams, but is often intractable in the worst case \citep{SontagR11}. Asa consequence, existing methods for posterior inference are approximate and donot have any guarantee on neither quality nor convergence rate. In this paper,we introduce a provably fast algorithm, namely \textit{Online Maximum aPosterior Estimation (OPE)}, for posterior inference in topic models. OPE hasmore attractive properties than existing inference approaches, includingtheoretical guarantees on quality and fast convergence rate. The discussionsabout OPE are very general and hence can be easily employed in a wide class ofprobabilistic models. Finally, we employ OPE to design three novel methods forlearning Latent Dirichlet allocation from text streams or large corpora.Extensive experiments demonstrate some superior behaviors of OPE and of our newlearning methods.
arxiv-15300-262 | Evaluation of Object Detection Proposals Under Condition Variations | http://arxiv.org/pdf/1512.03424v1.pdf | author:Fahimeh Rezazadegan, Sareh Shirazi, Michael Milford, Ben Upcroft category:cs.CV published:2015-12-10 summary:Object detection is a fundamental task in many computer vision applications,therefore the importance of evaluating the quality of object detection is wellacknowledged in this domain. This process gives insight into the capabilitiesof methods in handling environmental changes. In this paper, a new method forobject detection is introduced that combines the Selective Search andEdgeBoxes. We tested these three methods under environmental variations. Ourexperiments demonstrate the outperformance of the combination method underillumination and view point variations.
arxiv-15300-263 | Inference in topic models: sparsity and trade-off | http://arxiv.org/pdf/1512.03300v1.pdf | author:Khoat Than, Tu Bao Ho category:stat.ML published:2015-12-10 summary:Topic models are popular for modeling discrete data (e.g., texts, images,videos, links), and provide an efficient way to discover hiddenstructures/semantics in massive data. One of the core problems in this field isthe posterior inference for individual data instances. This problem isparticularly important in streaming environments, but is often intractable. Inthis paper, we investigate the use of the Frank-Wolfe algorithm (FW) forrecovering sparse solutions to posterior inference. From detailed elucidationof both theoretical and practical aspects, FW exhibits many interestingproperties which are beneficial to topic modeling. We then employ FW to designfast methods, including ML-FW, for learning latent Dirichlet allocation (LDA)at large scales. Extensive experiments show that to reach the samepredictiveness level, ML-FW can perform tens to thousand times faster thanexisting state-of-the-art methods for learning LDA from massive/streaming data.
arxiv-15300-264 | VRFP: On-the-fly Video Retrieval using Web Images and Fast Fisher Vector Products | http://arxiv.org/pdf/1512.03384v2.pdf | author:Xintong Han, Bharat Singh, Vlad I. Morariu, Larry S. Davis category:cs.CV published:2015-12-10 summary:VRFP is a real-time video retrieval framework based on short text inputqueries in which weakly labeled training samples from the web are obtained,after the query is known. Our experiments show that a Fisher Vector is robustto noise present in web-images and compares favorably in terms of accuracy toother standard representations. While a Fisher Vector for a new query can beconstructed efficiently, matching against the test set is slow due to its highdimensionality. To perform matching in real-time, we present a losslessalgorithm for accelerating the computation of dot product between highdimensional Fisher Vectors. We prove that the expected number ofmultiplications required is quadratic in terms of sparsity in Fisher Vectors.We are not only able to construct and apply query models in real-time, but withthe help of a simple re-ranking scheme, we also outperform state-of-the-artautomatic retrieval methods by a significant margin on TRECVID MED13 (3.5%),MED14 (1.3%) and CCV datasets (5.2%).
arxiv-15300-265 | Bigger Buffer k-d Trees on Multi-Many-Core Systems | http://arxiv.org/pdf/1512.02831v1.pdf | author:Fabian Gieseke, Cosmin Eugen Oancea, Ashish Mahabal, Christian Igel, Tom Heskes category:cs.DC cs.DS cs.LG published:2015-12-09 summary:A buffer k-d tree is a k-d tree variant for massively-parallel nearestneighbor search. While providing valuable speed-ups on modern many-core devicesin case both a large number of reference and query points are given, buffer k-dtrees are limited by the amount of points that can fit on a single device. Inthis work, we show how to modify the original data structure and the associatedworkflow to make the overall approach capable of dealing with massive datasets. We further provide a simple yet efficient way of using multiple devicesgiven in a single workstation. The applicability of the modified framework isdemonstrated in the context of astronomy, a field that is faced with hugeamounts of data.
arxiv-15300-266 | Multi-Player Bandits -- a Musical Chairs Approach | http://arxiv.org/pdf/1512.02866v1.pdf | author:Jonathan Rosenski, Ohad Shamir, Liran Szlak category:cs.LG stat.ML published:2015-12-09 summary:We consider a variant of the stochastic multi-armed bandit problem, wheremultiple players simultaneously choose from the same set of arms and maycollide, receiving no reward. This setting has been motivated by problemsarising in cognitive radio networks, and is especially challenging under therealistic assumption that communication between players is limited. We providea communication-free algorithm (Musical Chairs) which attains constant regretwith high probability, as well as a sublinear-regret, communication-freealgorithm (Dynamic Musical Chairs) for the more difficult setting of playersdynamically entering and leaving throughout the game. Moreover, both algorithmsdo not require prior knowledge of the number of players. To the best of ourknowledge, these are the first communication-free algorithms with these typesof formal guarantees. We also rigorously compare our algorithms to previousworks, and complement our theoretical findings with experiments.
arxiv-15300-267 | A Novel Regularized Principal Graph Learning Framework on Explicit Graph Representation | http://arxiv.org/pdf/1512.02752v2.pdf | author:Qi Mao, Li Wang, Ivor W. Tsang, Yijun Sun category:cs.AI cs.LG stat.ML published:2015-12-09 summary:Many scientific datasets are of high dimension, and the analysis usuallyrequires visual manipulation by retaining the most important structures ofdata. Principal curve is a widely used approach for this purpose. However, manyexisting methods work only for data with structures that are notself-intersected, which is quite restrictive for real applications. A fewmethods can overcome the above problem, but they either require complicatedhuman-made rules for a specific task with lack of convergence guarantee andadaption flexibility to different tasks, or cannot obtain explicit structuresof data. To address these issues, we develop a new regularized principal graphlearning framework that captures the local information of the underlying graphstructure based on reversed graph embedding. As showcases, models that canlearn a spanning tree or a weighted undirected $\ell_1$ graph are proposed, anda new learning algorithm is developed that learns a set of principal points anda graph structure from data, simultaneously. The new algorithm is simple withguaranteed convergence. We then extend the proposed framework to deal withlarge-scale data. Experimental results on various synthetic and six real worlddatasets show that the proposed method compares favorably with baselines andcan uncover the underlying structure correctly.
arxiv-15300-268 | Distributed Training of Deep Neural Networks with Theoretical Analysis: Under SSP Setting | http://arxiv.org/pdf/1512.02728v2.pdf | author:Abhimanu Kumar, Pengtao Xie, Junming Yin, Eric P. Xing category:stat.ML cs.LG math.OC published:2015-12-09 summary:We propose a distributed approach to train deep neural networks (DNNs), whichhas guaranteed convergence theoretically and great scalability empirically:close to 6 times faster on instance of ImageNet data set when run with 6machines. The proposed scheme is close to optimally scalable in terms of numberof machines, and guaranteed to converge to the same optima as the undistributedsetting. The convergence and scalability of the distributed setting is shownempirically across di?erent datasets (TIMIT and ImageNet) and machine learningtasks (image classi?cation and phoneme extraction). The convergence analysisprovides novel insights into this complex learning scheme, including: 1)layerwise convergence, and 2) convergence of the weights in probability.
arxiv-15300-269 | Where You Are Is Who You Are: User Identification by Matching Statistics | http://arxiv.org/pdf/1512.02896v1.pdf | author:Farid M. Naini, Jayakrishnan Unnikrishnan, Patrick Thiran, Martin Vetterli category:cs.LG cs.CR cs.SI stat.AP stat.ML published:2015-12-09 summary:Most users of online services have unique behavioral or usage patterns. Thesebehavioral patterns can be exploited to identify and track users by using onlythe observed patterns in the behavior. We study the task of identifying usersfrom statistics of their behavioral patterns. Specifically, we focus on thesetting in which we are given histograms of users' data collected during twodifferent experiments. We assume that, in the first dataset, the users'identities are anonymized or hidden and that, in the second dataset, theiridentities are known. We study the task of identifying the users by matchingthe histograms of their data in the first dataset with the histograms from thesecond dataset. In recent works, the optimal algorithm for this useridentification task is introduced. In this paper, we evaluate the effectivenessof this method on three different types of datasets and in multiple scenarios.Using datasets such as call data records, web browsing histories, and GPStrajectories, we show that a large fraction of users can be easily identifiedgiven only histograms of their data; hence these histograms can act as users'fingerprints. We also verify that simultaneous identification of users achievesbetter performance compared to one-by-one user identification. We show thatusing the optimal method for identification gives higher identificationaccuracy than heuristics-based approaches in practical scenarios. The accuracyobtained under this optimal method can thus be used to quantify the maximumlevel of user identification that is possible in such settings. We show thatthe key factors affecting the accuracy of the optimal identification algorithmare the duration of the data collection, the number of users in the anonymizeddataset, and the resolution of the dataset. We analyze the effectiveness ofk-anonymization in resisting user identification attacks on these datasets.
arxiv-15300-270 | MovieQA: Understanding Stories in Movies through Question-Answering | http://arxiv.org/pdf/1512.02902v1.pdf | author:Makarand Tapaswi, Yukun Zhu, Rainer Stiefelhagen, Antonio Torralba, Raquel Urtasun, Sanja Fidler category:cs.CV cs.CL published:2015-12-09 summary:We introduce the MovieQA dataset which aims to evaluate automatic storycomprehension from both video and text. The dataset consists of 7702 questionsabout 294 movies with high semantic diversity. The questions range from simpler"Who" did "What" to "Whom", to "Why" and "How" certain events occurred. Eachquestion comes with a set of five possible answers; a correct one and fourdeceiving answers provided by human annotators. Our dataset is unique in thatit contains multiple sources of information -- full-length movies, plots,subtitles, scripts and for a subset DVS. We analyze our data through variousstatistics and intelligent baselines. We further extend existing QA techniquesto show that question-answering with such open-ended semantics is hard. We planto create a benchmark with an active leader board, to encourage inspiring workin this challenging domain.
arxiv-15300-271 | Yet Another Statistical Analysis of Bob Ross Paintings | http://arxiv.org/pdf/1512.02914v1.pdf | author:Christopher Steven Marcum category:stat.AP cs.CV published:2015-12-09 summary:In this paper, we analyze a sample of clippings from paintings by the lateartist Bob Ross. Previous work focused on the qualitative themes of hispaintings (Hickey, 2014); here, we expand on that line of research byconsidering the colorspace and luminosity values as our data. Our resultsdemonstrate the subtle aesthetics of the average Ross painting, the commonvariation shared by his paintings, and the structure of the relationshipsbetween each painting in our sample. We reveal, for the first time, renderingsof the average paintings and introduce "eigenross" components to identify andevaluate shared variance. Additionally, all data and code are embedded in thisdocument to encourage future research, and, in the spirit of Bob Ross, to teachothers how to do so.
arxiv-15300-272 | Sensor Fusion of Camera, GPS and IMU using Fuzzy Adaptive Multiple Motion Models | http://arxiv.org/pdf/1512.02766v1.pdf | author:Erkan Bostanci, Betul Bostanci, Nadia Kanwal, Adrian F. Clark category:cs.RO cs.CV published:2015-12-09 summary:A tracking system that will be used for Augmented Reality (AR) applicationshas two main requirements: accuracy and frame rate. The first requirement isrelated to the performance of the pose estimation algorithm and how accuratelythe tracking system can find the position and orientation of the user in theenvironment. Accuracy problems of current tracking devices, considering thatthey are low-cost devices, cause static errors during this motion estimationprocess. The second requirement is related to dynamic errors (the end-to-endsystem delay; occurring because of the delay in estimating the motion of theuser and displaying images based on this estimate. This paper investigatescombining the vision-based estimates with measurements from other sensors, GPSand IMU, in order to improve the tracking accuracy in outdoor environments. Theidea of using Fuzzy Adaptive Multiple Models (FAMM) was investigated using anovel fuzzy rule-based approach to decide on the model that results in improvedaccuracy and faster convergence for the fusion filter. Results show that thedeveloped tracking system is more accurate than a conventional GPS-IMU fusionapproach due to additional estimates from a camera and fuzzy motion models. Thepaper also presents an application in cultural heritage context.
arxiv-15300-273 | Affinity CNN: Learning Pixel-Centric Pairwise Relations for Figure/Ground Embedding | http://arxiv.org/pdf/1512.02767v2.pdf | author:Michael Maire, Takuya Narihira, Stella X. Yu category:cs.CV cs.LG cs.NE published:2015-12-09 summary:Spectral embedding provides a framework for solving perceptual organizationproblems, including image segmentation and figure/ground organization. From anaffinity matrix describing pairwise relationships between pixels, it clusterspixels into regions, and, using a complex-valued extension, orders pixelsaccording to layer. We train a convolutional neural network (CNN) to directlypredict the pairwise relationships that define this affinity matrix. Spectralembedding then resolves these predictions into a globally-consistentsegmentation and figure/ground organization of the scene. Experimentsdemonstrate significant benefit to this direct coupling compared to prior workswhich use explicit intermediate stages, such as edge detection, on the pathwayfrom image to affinities. Our results suggest spectral embedding as a powerfulalternative to the conditional random field (CRF)-based globalization schemestypically coupled to deep neural networks.
arxiv-15300-274 | Perfect Recovery Conditions For Non-Negative Sparse Modeling | http://arxiv.org/pdf/1512.02743v2.pdf | author:Yuki Itoh, Marco F. Duarte, Mario Parente category:cs.IT cs.LG math.IT published:2015-12-09 summary:Sparse modeling has been widely and successfully used in many applicationssuch as computer vision, machine learning, and pattern recognition and,accompanied with those applications, significant research has studied thetheoretical limits and algorithm design for convex relaxations in sparsemodeling. However, only little has been done for theoretical limits ofnon-negative versions of sparse modeling. The behavior is expected to besimilar as the general sparse modeling, but a precise analysis has not beenexplored. This paper studies the performance of non-negative sparse modeling,especially for non-negativity constrained and $\ell_1$-penalized least squares,and gives an exact bound for which this problem can recover the correct signalelements. We pose two conditions to guarantee the correct signal recovery:minimum coefficient condition (MCC) and non-linearity vs. subset coherencecondition (NSCC). The former defines the minimum weight for each of the correctatoms present in the signal and the latter defines the tolerable deviation fromthe linear model relative to the positive subset coherence (PSC), a novel typeof "coherence" metric. We provide rigorous performance guarantees based onthese conditions and experimentally verify their precise predictive power in ahyperspectral data unmixing application.
arxiv-15300-275 | Embedding Label Structures for Fine-Grained Feature Representation | http://arxiv.org/pdf/1512.02895v2.pdf | author:Xiaofan Zhang, Feng Zhou, Yuanqing Lin, Shaoting Zhang category:cs.CV published:2015-12-09 summary:Recent algorithms in convolutional neural networks (CNN) considerably advancethe fine-grained image classification, which aims to differentiate subtledifferences among subordinate classes. However, previous studies have rarelyfocused on learning a fined-grained and structured feature representation thatis able to locate similar images at different levels of relevance, e.g.,discovering cars from the same make or the same model, both of which requirehigh precision. In this paper, we propose two main contributions to tackle thisproblem. 1) A multi-task learning framework is designed to effectively learnfine-grained feature representations by jointly optimizing both classificationand similarity constraints. 2) To model the multi-level relevance, labelstructures such as hierarchy or shared attributes are seamlessly embedded intothe framework by generalizing the triplet loss. Extensive and thoroughexperiments have been conducted on three fine-grained datasets, i.e., theStanford car, the car-333, and the food datasets, which contain eitherhierarchical labels or shared attributes. Our proposed method has achieved verycompetitive performance, i.e., among state-of-the-art classification accuracy.More importantly, it significantly outperforms previous fine-grained featurerepresentations for image retrieval at different levels of relevance.
arxiv-15300-276 | Window-Object Relationship Guided Representation Learning for Generic Object Detections | http://arxiv.org/pdf/1512.02736v1.pdf | author:Xingyu Zeng, Wanli Ouyang, Xiaogang Wang category:cs.CV cs.LG cs.MM published:2015-12-09 summary:In existing works that learn representation for object detection, therelationship between a candidate window and the ground truth bounding box of anobject is simplified by thresholding their overlap. This paper showsinformation loss in this simplification and picks up the relative location/sizeinformation discarded by thresholding. We propose a representation learningpipeline to use the relationship as supervision for improving the learnedrepresentation in object detection. Such relationship is not limited to objectof the target category, but also includes surrounding objects of othercategories. We show that image regions with multiple contexts and multiplerotations are effective in capturing such relationship during therepresentation learning process and in handling the semantic and visualvariation caused by different window-object configurations. Experimentalresults show that the representation learned by our approach can improve theobject detection accuracy by 6.4% in mean average precision (mAP) onILSVRC2014. On the challenging ILSVRC2014 test dataset, 48.6% mAP is achievedby our single model and it is the best among published results. On PASCAL VOC,it outperforms the state-of-the-art result of Fast RCNN by 3.3% in absolutemAP.
arxiv-15300-277 | Stochastic Interpretation of Quasi-periodic Event-based Systems | http://arxiv.org/pdf/1512.02930v1.pdf | author:Hesham Mostafa, Giacomo Indiveri category:cs.NE cs.ET q-bio.NC published:2015-12-09 summary:Many networks used in machine learning and as models of biological neuralnetworks make use of stochastic neurons or neuron-like units. We show thatstochastic artificial neurons can be realized on silicon chips by exploitingthe quasi-periodic behavior of mismatched analog oscillators to approximate theneuron's stochastic activation function. We represent neurons by finite statemachines (FSMs) that communicate using digital events and whose transitions areevent-triggered. The event generation times of each neuron are controlled by ananalog oscillator internal to that neuron/FSM and the frequencies of theoscillators in different FSMs are incommensurable. We show that within thisquasi-periodic system, the transition graph of a FSM can be interpreted as thetransition graph of a Markov chain and we show that by using different FSMs, wecan obtain approximations of different stochastic activation functions. Weinvestigate the quality of the stochastic interpretation of such adeterministic system and we use the system to realize and sample from arestricted Boltzmann machine. We implemented the quasi-periodic event-basedsystem on a custom silicon chip and we show that the chip behavior can be usedto closely approximate a stochastic sampling task.
arxiv-15300-278 | Video captioning with recurrent networks based on frame- and video-level features and visual content classification | http://arxiv.org/pdf/1512.02949v1.pdf | author:Rakshith Shetty, Jorma Laaksonen category:cs.CV published:2015-12-09 summary:In this paper, we describe the system for generating textual descriptions ofshort video clips using recurrent neural networks (RNN), which we used whileparticipating in the Large Scale Movie Description Challenge 2015 in ICCV 2015.Our work builds on static image captioning systems with RNN based languagemodels and extends this framework to videos utilizing both static imagefeatures and video-specific features. In addition, we study the usefulness ofvisual content classifiers as a source of additional information for captiongeneration. With experimental results we show that utilizing keyframe basedfeatures, dense trajectory video features and content classifier outputstogether gives better performance than any one of them individually.
arxiv-15300-279 | Scaling Up Distributed Stochastic Gradient Descent Using Variance Reduction | http://arxiv.org/pdf/1512.02970v1.pdf | author:Soham De, Gavin Taylor, Tom Goldstein category:cs.LG cs.DC math.OC stat.ML published:2015-12-09 summary:Variance reduction stochastic gradient descent methods enable minimization ofmodel fitting problems involving big datasets with low iteration complexity andfast asymptotic convergence rates. However, they scale poorly in distributedsettings. In this paper, we propose a highly parallel variance reductionmethod, CentralVR, with performance that scales linearly with the number ofworker nodes. We also propose distributed versions of popular variancereduction methods that support a high degree of parallelization. Unlikeexisting distributed stochastic gradient schemes, CentralVR exhibits linearperformance gains up to thousands of cores for massive datasets.
arxiv-15300-280 | Get More With Less: Near Real-Time Image Clustering on Mobile Phones | http://arxiv.org/pdf/1512.02972v1.pdf | author:Jorge Ortiz, Chien-Chin Huang, Supriyo Chakraborty category:cs.CV cs.DC cs.PF published:2015-12-09 summary:Machine learning algorithms, in conjunction with user data, hold the promiseof revolutionizing the way we interact with our phones, and indeed theirwidespread adoption in the design of apps bear testimony to this promise.However, currently, the computationally expensive segments of the learningpipeline, such as feature extraction and model training, are offloaded to thecloud, resulting in an over-reliance on the network and under-utilization ofcomputing resources available on mobile platforms. In this paper, we show thatby combining the computing power distributed over a number of phones, judiciousoptimization choices, and contextual information it is possible to execute theend-to-end pipeline entirely on the phones at the edge of the network,efficiently. We also show that by harnessing the power of this combination, itis possible to execute a computationally expensive pipeline at near real-time. To demonstrate our approach, we implement an end-to-end image-processingpipeline -- that includes feature extraction, vocabulary learning,vectorization, and image clustering -- on a set of mobile phones. Our resultsshow a 75% improvement over the standard, full pipeline implementation runningon the phones without modification -- reducing the time to one minute undercertain conditions. We believe that this result is a promising indication thatfully distributed, infrastructure-less computing is possible on networks ofmobile phones; enabling a new class of mobile applications that are lessreliant on the cloud.
arxiv-15300-281 | ShapeNet: An Information-Rich 3D Model Repository | http://arxiv.org/pdf/1512.03012v1.pdf | author:Angel X. Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, Jianxiong Xiao, Li Yi, Fisher Yu category:cs.GR cs.AI cs.CG cs.CV cs.RO published:2015-12-09 summary:We present ShapeNet: a richly-annotated, large-scale repository of shapesrepresented by 3D CAD models of objects. ShapeNet contains 3D models from amultitude of semantic categories and organizes them under the WordNet taxonomy.It is a collection of datasets providing many semantic annotations for each 3Dmodel such as consistent rigid alignments, parts and bilateral symmetry planes,physical sizes, keywords, as well as other planned annotations. Annotations aremade available through a public web-based interface to enable datavisualization of object attributes, promote data-driven geometric analysis, andprovide a large-scale quantitative benchmark for research in computer graphicsand vision. At the time of this technical report, ShapeNet has indexed morethan 3,000,000 models, 220,000 models out of which are classified into 3,135categories (WordNet synsets). In this report we describe the ShapeNet effort asa whole, provide details for all currently available datasets, and summarizefuture plans.
arxiv-15300-282 | Minimally Supervised Feature Selection for Classification (Master's Thesis, University Politehnica of Bucharest) | http://arxiv.org/pdf/1512.03019v1.pdf | author:Alexandra Maria Radu category:cs.CV published:2015-12-09 summary:In the context of the highly increasing number of features that are availablenowadays we design a robust and fast method for feature selection. The methodtries to select the most representative features that are independent from eachother, but are strong together. We propose an algorithm that requires verylimited labeled data (as few as one labeled frame per class) and canaccommodate as many unlabeled samples. We also present here the supervisedapproach from which we started. We compare our two formulations withestablished methods like AdaBoost, SVM, Lasso, Elastic Net and FoBa and showthat our method is much faster and it has constant training time. Moreover, theunsupervised approach outperforms all the methods with which we compared andthe difference might be quite prominent. The supervised approach is in mostcases better than the other methods, especially when the number of trainingshots is very limited. All that the algorithm needs is to choose from a pool ofpositively correlated features. The methods are evaluated on theYoutube-Objects dataset of videos and on MNIST digits dataset, while attraining time we also used features obtained on CIFAR10 dataset and otherspre-trained on ImageNet dataset. Thereby, we also proved that transfer learningis useful, even though the datasets differ very much: from low-resolutioncentered images from 10 classes, to high-resolution images with objects from1000 classes occurring in different regions of the images or to very difficultvideos with very high intraclass variance. 7
arxiv-15300-283 | Partial Reinitialisation for Optimisers | http://arxiv.org/pdf/1512.03025v1.pdf | author:Ilia Zintchenko, Matthew Hastings, Nathan Wiebe, Ethan Brown, Matthias Troyer category:stat.ML cs.LG cs.NE math.OC published:2015-12-09 summary:Heuristic optimisers which search for an optimal configuration of variablesrelative to an objective function often get stuck in local optima where thealgorithm is unable to find further improvement. The standard approach tocircumvent this problem involves periodically restarting the algorithm fromrandom initial configurations when no further improvement can be found. Wepropose a method of partial reinitialization, whereby, in an attempt to find abetter solution, only sub-sets of variables are re-initialised rather than thewhole configuration. Much of the information gained from previous runs is henceretained. This leads to significant improvements in the quality of the solutionfound in a given time for a variety of optimisation problems in machinelearning.
arxiv-15300-284 | Gamma Belief Networks | http://arxiv.org/pdf/1512.03081v1.pdf | author:Mingyuan Zhou, Yulai Cong, Bo Chen category:stat.ML stat.ME published:2015-12-09 summary:To infer multilayer deep representations of high-dimensional discrete andnonnegative real vectors, we propose the gamma belief network (GBN) thatfactorizes each of its hidden layers into the product of a sparse connectionweight matrix and the nonnegative real hidden units of the next layer. TheGBN's hidden layers are jointly trained with an upward-downward Gibbs samplerthat solves each layer with the same subroutine. The gamma-negative binomialprocess combined with a layer-wise training strategy allows inferring the widthof each layer given a fixed budget on the width of the first layer. Exampleresults illustrate interesting relationships between the width of the firstlayer and the inferred network structure, and demonstrate that the GBN can addmore layers to improve its performance in both unsupervisedly extractingfeatures and predicting heldout data. For exploratory data analysis, we extracttrees and subnetworks from the learned deep network to visualize how the veryspecific factors discovered at the first hidden layer and the increasingly moregeneral factors discovered at deeper hidden layers are related to each other,and we generate synthetic data by propagating random variables through the deepnetwork from the top hidden layer back to the bottom data layer.
arxiv-15300-285 | RSG: Beating SG without Smoothness and/or Strong Convexity | http://arxiv.org/pdf/1512.03107v9.pdf | author:Tianbao Yang, Qihang Lin category:math.OC stat.ML published:2015-12-09 summary:In this paper, we propose novel deterministic and stochastic {\bf R}estarted{\bf S}ub{\bf G}radient (RSG) methods that can find an $\epsilon$-optimalsolution for a broad class of non-smooth and/or non-strongly convexoptimization problems faster than the vanilla deterministic or stochasticsubgradient method (SG). We show that for non-smooth and non-strongly convexoptimization, RSG can reduce the dependence of SG's iteration complexity on thedistance to the optimal set of the initial solution to that of points on the$\epsilon$-level set. For a special family of non-smooth and non-stronglyconvex optimization problems whose epigraph is a polyhedron, we further showthat RSG could converge linearly. In addition, RSG has an$O(\frac{1}{\epsilon}\log(\frac{1}{\epsilon}))$ iteration complexity forproblems with a much weaker notion of strong convexity, namely locallysemi-strongly convexity. For a family of non-smooth optimization problems thatadmit a local Kurdyka-\L ojasiewicz property with a power constant of$\beta\in(0,1)$, RSG has an$O(\frac{1}{\epsilon^{2\beta}}\log(\frac{1}{\epsilon}))$ iteration complexity,which is better than that of SG for such optimization problems whose iterationcomplexity is $O(\frac{1}{\epsilon^2})$. The novelty of our analysis lies atexploiting the lower bound of the subgradient of the objective function at the$\epsilon$-level set. It is this novelty that allows us to explore the localproperties of functions (e.g., local semi-strong convexity, local Kurdyka-\Lojasiewicz property, more generally local error bounds) to develop improvedconvergence of RSG.
arxiv-15300-286 | Explaining NonLinear Classification Decisions with Deep Taylor Decomposition | http://arxiv.org/pdf/1512.02479v1.pdf | author:GrÃ©goire Montavon, Sebastian Bach, Alexander Binder, Wojciech Samek, Klaus-Robert MÃ¼ller category:cs.LG stat.ML published:2015-12-08 summary:Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standardfor various challenging machine learning problems, e.g., image classification,natural language processing or human action recognition. Although these methodsperform impressively well, they have a significant disadvantage, the lack oftransparency, limiting the interpretability of the solution and thus the scopeof application in practice. Especially DNNs act as black boxes due to theirmultilayer nonlinear structure. In this paper we introduce a novel methodologyfor interpreting generic multilayer neural networks by decomposing the networkclassification decision into contributions of its input elements. Although ourfocus is on image classification, the method is applicable to a broad set ofinput data, learning tasks and network architectures. Our method is based ondeep Taylor decomposition and efficiently utilizes the structure of the networkby backpropagating the explanations from the output to the input layer. Weevaluate the proposed method empirically on the MNIST and ILSVRC data sets.
arxiv-15300-287 | Tracking Objects with Higher Order Interactions using Delayed Column Generation | http://arxiv.org/pdf/1512.02413v2.pdf | author:Steffen Wolf, Fred A. Hamprecht, Julian Yarkony category:cs.CV published:2015-12-08 summary:We introduce a new approach to tracking a large number of objects.Specifically we consider tracking in the context of higher order Markovinteractions which can not be modeled using network flow techniques ascurrently developed. Our approach relies on delayed column generation and isinspired by the corresponding approach to the cutting stock problem. Columnscan be generated exactly using dynamic programming.
arxiv-15300-288 | Computational Models for Multiview Dense Depth Maps of Dynamic Scene | http://arxiv.org/pdf/1512.02329v2.pdf | author:Qifei Wang category:cs.CV published:2015-12-08 summary:This paper reviews the recent progresses of the depth map generation fordynamic scene and its corresponding computational models. This paper mainlycovers the homogeneous ambiguity models in depth sensing, resolution models indepth processing, and consistency models in depth optimization. We alsosummarize the future work in the depth map generation.
arxiv-15300-289 | Nonparametric Reduced-Rank Regression for Multi-SNP, Multi-Trait Association Mapping | http://arxiv.org/pdf/1512.02306v1.pdf | author:Ashlee Valente, Geoffrey Ginsburg, Barbara E Engelhardt category:stat.AP q-bio.GN stat.ML published:2015-12-08 summary:Genome-wide association studies have proven to be essential for understandingthe genetic basis of disease. However, many complex traits---personalitytraits, facial features, disease subtyping---are inherently high-dimensional,impeding simple approaches to association mapping. We developed a nonparametricBayesian reduced rank regression model for multi-SNP, multi-trait associationmapping that does not require the rank of the linear subspace to be specified.We show in simulations and real data that our model shares strength over SNPsand over correlated traits, improving statistical power to identify geneticassociations with an interpretable, SNP-supervised low-dimensional linearprojection of the high-dimensional phenotype. On the HapMap phase 3 geneexpression QTL study data, we identify pleiotropic expression QTLs thatclassical univariate tests are underpowered to find and that two stepapproaches cannot recover. Our Python software, BERRRI, is publicly availableat GitHub: https://github.com/ashlee1031/BERRRI.
arxiv-15300-290 | Reinforcement Control with Hierarchical Backpropagated Adaptive Critics | http://arxiv.org/pdf/1512.02693v1.pdf | author:John W. Jameson category:cs.NE cs.LG cs.SY I.2.6 published:2015-12-08 summary:Present incremental learning methods are limited in the ability to achievereliable credit assignment over a large number time steps (or events). However,this situation is typical for cases where the dynamical system to be controlledrequires relatively frequent control updates in order to maintain stability orrobustness yet has some action-consequences which must be established overrelatively long periods of time. To address this problem, the learningcapabilities of a control architecture comprised of two Backpropagated AdaptiveCritics (BACs) in a two-level hierarchy with continuous actions are explored.The high-level BAC updates less frequently than the low-level BAC and controlsthe latter to some degree. The response of the low-level to high-level signalscan either be determined a priori or it can emerge during learning. A generalapproach called Response Induction Learning is introduced to address the lattercase.
arxiv-15300-291 | Deep Speech 2: End-to-End Speech Recognition in English and Mandarin | http://arxiv.org/pdf/1512.02595v1.pdf | author:Dario Amodei, Rishita Anubhai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Jingdong Chen, Mike Chrzanowski, Adam Coates, Greg Diamos, Erich Elsen, Jesse Engel, Linxi Fan, Christopher Fougner, Tony Han, Awni Hannun, Billy Jun, Patrick LeGresley, Libby Lin, Sharan Narang, Andrew Ng, Sherjil Ozair, Ryan Prenger, Jonathan Raiman, Sanjeev Satheesh, David Seetapun, Shubho Sengupta, Yi Wang, Zhiqian Wang, Chong Wang, Bo Xiao, Dani Yogatama, Jun Zhan, Zhenyao Zhu category:cs.CL published:2015-12-08 summary:We show that an end-to-end deep learning approach can be used to recognizeeither English or Mandarin Chinese speech--two vastly different languages.Because it replaces entire pipelines of hand-engineered components with neuralnetworks, end-to-end learning allows us to handle a diverse variety of speechincluding noisy environments, accents and different languages. Key to ourapproach is our application of HPC techniques, resulting in a 7x speedup overour previous system. Because of this efficiency, experiments that previouslytook weeks now run in days. This enables us to iterate more quickly to identifysuperior architectures and algorithms. As a result, in several cases, oursystem is competitive with the transcription of human workers when benchmarkedon standard datasets. Finally, using a technique called Batch Dispatch withGPUs in the data center, we show that our system can be inexpensively deployedin an online setting, delivering low latency when serving users at scale.
arxiv-15300-292 | Learning Discrete Bayesian Networks from Continuous Data | http://arxiv.org/pdf/1512.02406v2.pdf | author:Yi-Chun Chen, Tim Allan Wheeler, Mykel John Kochenderfer category:cs.AI cs.LG published:2015-12-08 summary:Real data often contains a mixture of discrete and continuous variables, butmany Bayesian network structure learning and inference algorithms assume allrandom variables are discrete. Continuous variables are often discretized, butthe choice of discretization policy has significant impact on the accuracy,speed, and interpretability of the resulting models. This paper introduces aprincipled Bayesian discretization method for continuous variables in Bayesiannetworks with quadratic complexity instead of the cubic complexity of otherstandard techniques. Empirical demonstrations show that the proposed method issuperior to the state of the art. In addition, this paper shows how toincorporate existing methods into the structure learning process to discretizeall continuous variables and simultaneously learn Bayesian network structures.
arxiv-15300-293 | Distributed Adaptive LMF Algorithm for Sparse Parameter Estimation in Gaussian Mixture Noise | http://arxiv.org/pdf/1512.02567v1.pdf | author:Mojtaba Hajiabadi category:cs.IT cs.CL math.IT published:2015-12-08 summary:A distributed adaptive algorithm for estimation of sparse unknown parametersin the presence of nonGaussian noise is proposed in this paper based onnormalized least mean fourth (NLMF) criterion. At the first step, localadaptive NLMF algorithm is modified by zero norm in order to speed up theconvergence rate and also to reduce the steady state error power in sparseconditions. Then, the proposed algorithm is extended for distributed scenarioin which more improvement in estimation performance is achieved due tocooperation of local adaptive filters. Simulation results show the superiorityof the proposed algorithm in comparison with conventional NLMF algorithms.
arxiv-15300-294 | Selective Sequential Model Selection | http://arxiv.org/pdf/1512.02565v1.pdf | author:William Fithian, Jonathan Taylor, Robert Tibshirani, Ryan Tibshirani category:stat.ME stat.ML published:2015-12-08 summary:Many model selection algorithms produce a path of fits specifying a sequenceof increasingly complex models. Given such a sequence and the data used toproduce them, we consider the problem of choosing the least complex model thatis not falsified by the data. Extending the selected-model tests of Fithian etal. (2014), we construct p-values for each step in the path which account forthe adaptive selection of the model path using the data. In the case of linearregression, we propose two specific tests, the max-t test for forward stepwiseregression (generalizing a proposal of Buja and Brown (2014)), and thenext-entry test for the lasso. These tests improve on the power of thesaturated-model test of Tibshirani et al. (2014), sometimes dramatically. Inaddition, our framework extends beyond linear regression to a much more generalclass of parametric and nonparametric model selection problems. To select a model, we can feed our single-step p-values as inputs intosequential stopping rules such as those proposed by G'Sell et al. (2013) and Liand Barber (2015), achieving control of the familywise error rate or falsediscovery rate (FDR) as desired. The FDR-controlling rules require the nullp-values to be independent of each other and of the non-null p-values, acondition not satisfied by the saturated-model p-values of Tibshirani et al.(2014). We derive intuitive and general sufficient conditions for independence,and show that our proposed constructions yield independent p-values.
arxiv-15300-295 | Deep Learning for Single and Multi-Session i-Vector Speaker Recognition | http://arxiv.org/pdf/1512.02560v1.pdf | author:Omid Ghahabi, Javier Hernando category:cs.SD cs.LG published:2015-12-08 summary:The promising performance of Deep Learning (DL) in speech recognition hasmotivated the use of DL in other speech technology applications such as speakerrecognition. Given i-vectors as inputs, the authors proposed an impostorselection algorithm and a universal model adaptation process in a hybrid systembased on Deep Belief Networks (DBN) and Deep Neural Networks (DNN) todiscriminatively model each target speaker. In order to have more insight intothe behavior of DL techniques in both single and multi-session speakerenrollment tasks, some experiments have been carried out in this paper in bothscenarios. Additionally, the parameters of the global model, referred to asuniversal DBN (UDBN), are normalized before adaptation. UDBN normalizationfacilitates training DNNs specifically with more than one hidden layer.Experiments are performed on the NIST SRE 2006 corpus. It is shown that theproposed impostor selection algorithm and UDBN adaptation process enhance theperformance of conventional DNNs 8-20 % and 16-20 % in terms of EER for thesingle and multi-session tasks, respectively. In both scenarios, the proposedarchitectures outperform the baseline systems obtaining up to 17 % reduction inEER.
arxiv-15300-296 | Direct Intrinsics: Learning Albedo-Shading Decomposition by Convolutional Regression | http://arxiv.org/pdf/1512.02311v1.pdf | author:Takuya Narihira, Michael Maire, Stella X. Yu category:cs.CV published:2015-12-08 summary:We introduce a new approach to intrinsic image decomposition, the task ofdecomposing a single image into albedo and shading components. Our strategy,which we term direct intrinsics, is to learn a convolutional neural network(CNN) that directly predicts output albedo and shading channels from an inputRGB image patch. Direct intrinsics is a departure from classical techniques forintrinsic image decomposition, which typically rely on physically-motivatedpriors and graph-based inference algorithms. The large-scale synthetic ground-truth of the MPI Sintel dataset plays a keyrole in training direct intrinsics. We demonstrate results on both thesynthetic images of Sintel and the real images of the classic MIT intrinsicimage dataset. On Sintel, direct intrinsics, using only RGB input, outperformsall prior work, including methods that rely on RGB+Depth input. Directintrinsics also generalizes across modalities; it produces quite reasonabledecompositions on the real images of the MIT dataset. Our results indicate thatthe marriage of CNNs with synthetic training data may be a powerful newtechnique for tackling classic problems in computer vision.
arxiv-15300-297 | Minimum Risk Training for Neural Machine Translation | http://arxiv.org/pdf/1512.02433v2.pdf | author:Shiqi Shen, Yong Cheng, Zhongjun He, Wei He, Hua Wu, Maosong Sun, Yang Liu category:cs.CL published:2015-12-08 summary:We propose minimum risk training for end-to-end neural machine translation.Unlike conventional maximum likelihood estimation, minimum risk training iscapable of optimizing model parameters directly with respect to evaluationmetrics. Experiments on Chinese-English and English-French translation showthat our approach achieves significant improvements over maximum likelihoodestimation on a state-of-the-art neural machine translation system.
arxiv-15300-298 | Learning to Point and Count | http://arxiv.org/pdf/1512.02326v1.pdf | author:Jie Shao, Dequan Wang, Xiangyang Xue, Zheng Zhang category:cs.CV published:2015-12-08 summary:This paper proposes the problem of point-and-count as a test case to breakthe what-and-where deadlock. Different from the traditional detection problem,the goal is to discover key salient points as a way to localize and count thenumber of objects simultaneously. We propose two alternatives, one that countsfirst and then point, and another that works the other way around.Fundamentally, they pivot around whether we solve "what" or "where" first. Weevaluate their performance on dataset that contains multiple instances of thesame class, demonstrating the potentials and their synergies. The experiencesderive a few important insights that explains why this is a much harder problemthan classification, including strong data bias and the inability to deal withobject scales robustly in state-of-art convolutional neural networks.
arxiv-15300-299 | Online Gradient Descent in Function Space | http://arxiv.org/pdf/1512.02394v1.pdf | author:Changbo Zhu, Huan Xu category:cs.LG published:2015-12-08 summary:In many problems in machine learning and operations research, we need tooptimize a function whose input is a random variable or a probability densityfunction, i.e. to solve optimization problems in an in?nite dimensional space.On the other hand, online learning has the advantage of dealing with streamingexamples, and better model a changing environ- ment. In this paper, we extendthe celebrated online gradient descent algorithm to Hilbert spaces (functionspaces), and analyze the convergence guarantee of the algorithm. Finally, wedemonstrate that our algorithms can be useful in several important problems.
arxiv-15300-300 | Is Hamming distance the only way for matching binary image feature descriptors? | http://arxiv.org/pdf/1512.02355v1.pdf | author:Erkan Bostanci category:cs.CV published:2015-12-08 summary:Brute force matching of binary image feature descriptors is conventionallyperformed using the Hamming distance. This paper assesses the use ofalternative metrics in order to see whether they can produce featurecorrespondences that yield more accurate homography matrices. Two statisticaltests, namely ANOVA (Analysis of Variance) and McNemar's test were employed forevaluation. Results show that Jackard-Needham and Dice metrics can displaybetter performance for some descriptors. Yet, these performance differenceswere not found to be statistically significant.
