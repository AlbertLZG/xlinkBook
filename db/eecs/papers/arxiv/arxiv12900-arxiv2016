arxiv-12900-1 | Probabilistic Modelling of Morphologically Rich Languages | http://arxiv.org/abs/1508.04271 | author:Jan A. Botha category:cs.CL I.2.7; I.2.6 published:2015-08-18 summary:This thesis investigates how the sub-structure of words can be accounted forin probabilistic models of language. Such models play an important role innatural language processing tasks such as translation or speech recognition,but often rely on the simplistic assumption that words are opaque symbols. Thisassumption does not fit morphologically complex language well, where words canhave rich internal structure and sub-word elements are shared across distinctword forms. Our approach is to encode basic notions of morphology into the assumptions ofthree different types of language models, with the intention that leveragingshared sub-word structure can improve model performance and help overcome datasparsity that arises from morphological processes. In the context of n-gram language modelling, we formulate a new Bayesianmodel that relies on the decomposition of compound words to attain bettersmoothing, and we develop a new distributed language model that learns vectorrepresentations of morphemes and leverages them to link togethermorphologically related words. In both cases, we show that accounting for wordsub-structure improves the models' intrinsic performance and provides benefitswhen applied to other tasks, including machine translation. We then shift the focus beyond the modelling of word sequences and considermodels that automatically learn what the sub-word elements of a given languageare, given an unannotated list of words. We formulate a novel model that canlearn discontiguous morphemes in addition to the more conventional contiguousmorphemes that most previous models are limited to. This approach isdemonstrated on Semitic languages, and we find that modelling discontiguoussub-word structures leads to improvements in the task of segmenting words intotheir contiguous morphemes.
arxiv-12900-2 | Zero-Truncated Poisson Tensor Factorization for Massive Binary Tensors | http://arxiv.org/abs/1508.04210 | author:Changwei Hu, Piyush Rai, Lawrence Carin category:stat.ML cs.LG published:2015-08-18 summary:We present a scalable Bayesian model for low-rank factorization of massivetensors with binary observations. The proposed model has the following keyproperties: (1) in contrast to the models based on the logistic or probitlikelihood, using a zero-truncated Poisson likelihood for binary data allowsour model to scale up in the number of \emph{ones} in the tensor, which isespecially appealing for massive but sparse binary tensors; (2)side-information in form of binary pairwise relationships (e.g., an adjacencynetwork) between objects in any tensor mode can also be leveraged, which can beespecially useful in "cold-start" settings; and (3) the model admits simpleBayesian inference via batch, as well as \emph{online} MCMC; the latter allowsscaling up even for \emph{dense} binary data (i.e., when the number of ones inthe tensor/network is also massive). In addition, non-negative factor matricesin our model provide easy interpretability, and the tensor rank can be inferredfrom the data. We evaluate our model on several large-scale real-world binarytensors, achieving excellent computational scalability, and also demonstrateits usefulness in leveraging side-information provided in form ofmode-network(s).
arxiv-12900-3 | Scalable Out-of-Sample Extension of Graph Embeddings Using Deep Neural Networks | http://arxiv.org/abs/1508.04422 | author:Aren Jansen, Gregory Sell, Vince Lyzinski category:stat.ML cs.LG cs.NE stat.ME published:2015-08-18 summary:Several popular graph embedding techniques for representation learning anddimensionality reduction rely on performing computationally expensiveeigendecompositions to derive a nonlinear transformation of the input dataspace. The resulting eigenvectors encode the embedding coordinates for thetraining samples only, preventing the transformation of novel data sampleswithout recomputation. In this paper, we present a method for out-of sampleextension of graph embeddings that uses deep neural networks (DNN) toparametrically approximate these nonlinear maps. Compared with traditionalnonparametric out-of-sample extension methods, we demonstrate that the DNNs cangeneralize with equal or better fidelity and require orders of magnitude lesscomputation at test time. Moreover, we find that unsupervised pretraining ofthe DNNs improves optimization for larger network sizes, thus removingsensitivity to model selection.
arxiv-12900-4 | ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R | http://arxiv.org/abs/1508.04409 | author:Marvin N. Wright, Andreas Ziegler category:stat.ML stat.CO published:2015-08-18 summary:We introduce the C++ application and R package ranger. The software is a fastimplementation of random forests for high dimensional data. Ensembles ofclassification, regression and survival trees are supported. We describe theimplementation, provide examples, validate the package with a referenceimplementation, and compare runtime and memory usage with otherimplementations. The new software proves to scale best with the number offeatures, samples, trees, and features tried for splitting. Finally, we showthat ranger is the fastest and most memory efficient implementation of randomforests to analyze data on the scale of a genome-wide association study.
arxiv-12900-5 | Deep clustering: Discriminative embeddings for segmentation and separation | http://arxiv.org/abs/1508.04306 | author:John R. Hershey, Zhuo Chen, Jonathan Le Roux, Shinji Watanabe category:cs.NE cs.LG stat.ML published:2015-08-18 summary:We address the problem of acoustic source separation in a deep learningframework we call "deep clustering." Rather than directly estimating signals ormasking functions, we train a deep network to produce spectrogram embeddingsthat are discriminative for partition labels given in training data. Previousdeep network approaches provide great advantages in terms of learning power andspeed, but previously it has been unclear how to use them to separate signalsin a class-independent way. In contrast, spectral clustering approaches areflexible with respect to the classes and number of items to be segmented, butit has been unclear how to leverage the learning power and speed of deepnetworks. To obtain the best of both worlds, we use an objective function thatto train embeddings that yield a low-rank approximation to an ideal pairwiseaffinity matrix, in a class-independent way. This avoids the high cost ofspectral factorization and instead produces compact clusters that are amenableto simple clustering methods. The segmentations are therefore implicitlyencoded in the embeddings, and can be "decoded" by clustering. Preliminaryexperiments show that the proposed method can separate speech: when trained onspectrogram features containing mixtures of two speakers, and tested onmixtures of a held-out set of speakers, it can infer masking functions thatimprove signal quality by around 6dB. We show that the model can generalize tothree-speaker mixtures despite training only on two-speaker mixtures. Theframework can be used without class labels, and therefore has the potential tobe trained on a diverse set of sound types, and to generalize to novel sources.We hope that future work will lead to segmentation of arbitrary sounds, withextensions to microphone array methods as well as image segmentation and otherdomains.
arxiv-12900-6 | A Deep Pyramid Deformable Part Model for Face Detection | http://arxiv.org/abs/1508.04389 | author:Rajeev Ranjan, Vishal M. Patel, Rama Chellappa category:cs.CV published:2015-08-18 summary:We present a face detection algorithm based on Deformable Part Models anddeep pyramidal features. The proposed method called DP2MFD is able to detectfaces of various sizes and poses in unconstrained conditions. It reduces thegap in training and testing of DPM on deep features by adding a normalizationlayer to the deep convolutional neural network (CNN). Extensive experiments onfour publicly available unconstrained face detection datasets show that ourmethod is able to capture the meaningful structure of faces and performssignificantly better than many competitive face detection algorithms.
arxiv-12900-7 | Distributed Deep Q-Learning | http://arxiv.org/abs/1508.04186 | author:Hao Yi Ong, Kevin Chavez, Augustus Hong category:cs.LG cs.AI cs.DC cs.NE published:2015-08-18 summary:We propose a distributed deep learning model to successfully learn controlpolicies directly from high-dimensional sensory input using reinforcementlearning. The model is based on the deep Q-network, a convolutional neuralnetwork trained with a variant of Q-learning. Its input is raw pixels and itsoutput is a value function estimating future rewards from taking an actiongiven a system state. To distribute the deep Q-network training, we adapt theDistBelief software framework to the context of efficiently trainingreinforcement learning agents. As a result, the method is completelyasynchronous and scales well with the number of machines. We demonstrate thatthe deep Q-network agent, receiving only the pixels and the game score asinputs, was able to achieve reasonable success on a simple game with minimalparameter tuning.
arxiv-12900-8 | ESDF: Ensemble Selection using Diversity and Frequency | http://arxiv.org/abs/1508.04333 | author:Shouvick Mondal, Arko Banerjee category:cs.LG 62H30 published:2015-08-18 summary:Recently ensemble selection for consensus clustering has emerged as aresearch problem in Machine Intelligence. Normally consensus clusteringalgorithms take into account the entire ensemble of clustering, where there isa tendency of generating a very large size ensemble before computing itsconsensus. One can avoid considering the entire ensemble and can judiciouslyselect few partitions in the ensemble without compromising on the quality ofthe consensus. This may result in an efficient consensus computation techniqueand may save unnecessary computational overheads. The ensemble selectionproblem addresses this issue of consensus clustering. In this paper, we proposean efficient method of ensemble selection for a large ensemble. We prioritizethe partitions in the ensemble based on diversity and frequency. Our methodselects top K of the partitions in order of priority, where K is decided by theuser. We observe that considering jointly the diversity and frequency helps inidentifying few representative partitions whose consensus is qualitativelybetter than the consensus of the entire ensemble. Experimental analysis on alarge number of datasets shows our method gives better results than earlierensemble selection methods.
arxiv-12900-9 | Cascade Learning by Optimally Partitioning | http://arxiv.org/abs/1508.04326 | author:Yanwei Pang, Jiale Cao, Xuelong Li category:cs.CV cs.LG published:2015-08-18 summary:Cascaded AdaBoost classifier is a well-known efficient object detectionalgorithm. The cascade structure has many parameters to be determined. Most ofexisting cascade learning algorithms are designed by assigning detection rateand false positive rate to each stage either dynamically or statically. Theirobjective functions are not directly related to minimum computation cost. Thesealgorithms are not guaranteed to have optimal solution in the sense ofminimizing computation cost. On the assumption that a strong classifier isgiven, in this paper we propose an optimal cascade learning algorithm (we callit iCascade) which iteratively partitions the strong classifiers into two partsuntil predefined number of stages are generated. iCascade searches the optimalnumber ri of weak classifiers of each stage i by directly minimizing thecomputation cost of the cascade. Theorems are provided to guarantee theexistence of the unique optimal solution. Theorems are also given for theproposed efficient algorithm of searching optimal parameters ri. Once a newstage is added, the parameter ri for each stage decreases gradually asiteration proceeds, which we call decreasing phenomenon. Moreover, with thegoal of minimizing computation cost, we develop an effective algorithm forsetting the optimal threshold of each stage classifier. In addition, we provein theory why more new weak classifiers are required compared to the laststage. Experimental results on face detection demonstrate the effectiveness andefficiency of the proposed algorithm.
arxiv-12900-10 | Non-Stationary Gaussian Process Regression with Hamiltonian Monte Carlo | http://arxiv.org/abs/1508.04319 | author:Markus Heinonen, Henrik Mannerström, Juho Rousu, Samuel Kaski, Harri Lähdesmäki category:stat.ML published:2015-08-18 summary:We present a novel approach for fully non-stationary Gaussian processregression (GPR), where all three key parameters -- noise variance, signalvariance and lengthscale -- can be simultaneously input-dependent. We developgradient-based inference methods to learn the unknown function and thenon-stationary model parameters, without requiring any model approximations. Wepropose to infer full parameter posterior with Hamiltonian Monte Carlo (HMC),which conveniently extends the analytical gradient-based GPR learning byguiding the sampling with model gradients. We also learn the MAP solution fromthe posterior by gradient ascent. In experiments on several synthetic datasetsand in modelling of temporal gene expression, the nonstationary GPR is shown tobe necessary for modeling realistic input-dependent dynamics, while it performscomparably to conventional stationary or previous non-stationary GPR modelsotherwise.
arxiv-12900-11 | Low Rank Representation on Riemannian Manifold of Square Root Densities | http://arxiv.org/abs/1508.04198 | author:Yifan Fu, Junbin Gao, Xia Hong, David Tien category:cs.CV published:2015-08-18 summary:In this paper, we present a novel low rank representation (LRR) algorithm fordata lying on the manifold of square root densities. Unlike traditional LRRmethods which rely on the assumption that the data points are vectors in theEuclidean space, our new algorithm is designed to incorporate the intrinsicgeometric structure and geodesic distance of the manifold. Experiments onseveral computer vision datasets showcase its noise robustness and superiorperformance on classification and subspace clustering compared to otherstate-of-the-art approaches.
arxiv-12900-12 | Action Recognition based on Subdivision-Fusion Model | http://arxiv.org/abs/1508.04190 | author:Hao Zongbo, Lu Linlin, Zhang Qianni, Wu Jie, Izquierdo Ebroul, Yang Juanyu, Zhao Jun category:cs.CV published:2015-08-18 summary:This paper proposes a novel Subdivision-Fusion Model (SFM) to recognize humanactions. In most action recognition tasks, overlapping feature distribution isa common problem leading to overfitting. In the subdivision stage of theproposed SFM, samples in each category are clustered. Then, such samples aregrouped into multiple more concentrated subcategories. Boundaries for thesubcategories are easier to find and as consequence overfitting is avoided. Inthe subsequent fusion stage, the multi-subcategories classification results areconverted back to the original category recognition problem. Two methods todetermine the number of clusters are provided. The proposed model has beenthoroughly tested with four popular datasets. In the Hollywood2 dataset, anaccuracy of 79.4% is achieved, outperforming the state-of-the-art accuracy of64.3%. The performance on the YouTube Action dataset has been improved from75.8% to 82.5%, while considerably improvements are also observed on the KTHand UCF50 datasets.
arxiv-12900-13 | Effective Approaches to Attention-based Neural Machine Translation | http://arxiv.org/abs/1508.04025 | author:Minh-Thang Luong, Hieu Pham, Christopher D. Manning category:cs.CL published:2015-08-17 summary:An attentional mechanism has lately been used to improve neural machinetranslation (NMT) by selectively focusing on parts of the source sentenceduring translation. However, there has been little work exploring usefularchitectures for attention-based NMT. This paper examines two simple andeffective classes of attentional mechanism: a global approach which alwaysattends to all source words and a local one that only looks at a subset ofsource words at a time. We demonstrate the effectiveness of both approachesover the WMT translation tasks between English and German in both directions.With local attention, we achieve a significant gain of 5.0 BLEU points overnon-attentional systems which already incorporate known techniques such asdropout. Our ensemble model using different attention architectures hasestablished a new state-of-the-art result in the WMT'15 English to Germantranslation task with 25.9 BLEU points, an improvement of 1.0 BLEU points overthe existing best system backed by NMT and an n-gram reranker.
arxiv-12900-14 | Deep Networks Can Resemble Human Feed-forward Vision in Invariant Object Recognition | http://arxiv.org/abs/1508.03929 | author:Saeed Reza Kheradpisheh, Masoud Ghodrati, Mohammad Ganjtabesh, Timothée Masquelier category:cs.CV q-bio.NC published:2015-08-17 summary:Deep convolutional neural networks (DCNNs) have attracted much attentionrecently, and have shown to be able to recognize thousands of object categoriesin natural image databases. Their architecture is somewhat similar to that ofthe human visual system: both use restricted receptive fields, and a hierarchyof layers which progressively extract more and more abstracted features. Yet itis unknown whether DCNNs match human performance at the task of view-invariantobject recognition, whether they make similar errors and use similarrepresentations for this task, and whether the answers depend on the magnitudeof the viewpoint variations. To investigate these issues, we benchmarked eightstate-of-the-art DCNNs, the HMAX model, and a baseline shallow model andcompared their results to those of humans with backward masking. Unlike in allprevious DCNN studies, we carefully controlled the magnitude of the viewpointvariations to demonstrate that shallow nets can outperform deep nets and humanswhen variations are weak. When facing larger variations, however, more layerswere needed to match human performance and error distributions, and to haverepresentations that are consistent with human behavior. A very deep net with18 layers even outperformed humans at the highest variation level, using themost human-like representations.
arxiv-12900-15 | Using a Machine Learning Approach to Implement and Evaluate Product Line Features | http://arxiv.org/abs/1508.03906 | author:Davide Bacciu, Stefania Gnesi, Laura Semini category:cs.SE cs.LG published:2015-08-17 summary:Bike-sharing systems are a means of smart transportation in urbanenvironments with the benefit of a positive impact on urban mobility. In thispaper we are interested in studying and modeling the behavior of features thatpermit the end user to access, with her/his web browser, the status of theBike-Sharing system. In particular, we address features able to make aprediction on the system state. We propose to use a machine learning approachto analyze usage patterns and learn computational models of such features fromlogs of system usage. On the one hand, machine learning methodologies provide a powerful andgeneral means to implement a wide choice of predictive features. On the otherhand, trained machine learning models are provided with a measure of predictiveperformance that can be used as a metric to assess the cost-performancetrade-off of the feature. This provides a principled way to assess the runtimebehavior of different components before putting them into operation.
arxiv-12900-16 | LCNN: Low-level Feature Embedded CNN for Salient Object Detection | http://arxiv.org/abs/1508.03928 | author:Hongyang Li, Huchuan Lu, Zhe Lin, Xiaohui Shen, Brian Price category:cs.CV published:2015-08-17 summary:In this paper, we propose a novel deep neural network framework embedded withlow-level features (LCNN) for salient object detection in complex images. Weutilise the advantage of convolutional neural networks to automatically learnthe high-level features that capture the structured information and semanticcontext in the image. In order to better adapt a CNN model into the saliencytask, we redesign the network architecture based on the small-scale datasets.Several low-level features are extracted, which can effectively capturecontrast and spatial information in the salient regions, and incorporated tocompensate with the learned high-level features at the output of the last fullyconnected layer. The concatenated feature vector is further fed into ahinge-loss SVM detector in a joint discriminative learning manner and the finalsaliency score of each region within the bounding box is obtained by the linearcombination of the detector's weights. Experiments on three challengingbenchmark (MSRA-5000, PASCAL-S, ECCSD) demonstrate our algorithm to beeffective and superior than most low-level oriented state-of-the-arts in termsof P-R curves, F-measure and mean absolute errors.
arxiv-12900-17 | Sense Beyond Expressions: Cuteness | http://arxiv.org/abs/1508.03953 | author:Kang Wang, Tam V. Nguyen, Jiashi Feng, Jose Sepulveda category:cs.CV published:2015-08-17 summary:With the development of Internet culture, cuteness has become a popularconcept. Many people are curious about what factors making a person look cute.However, there is rare research to answer this interesting question. In thiswork, we construct a dataset of personal images with comprehensively annotatedcuteness scores and facial attributes to investigate this high-level concept indepth. Based on this dataset, through an automatic attributes mining process,we find several critical attributes determining the cuteness of a person. Wealso develop a novel Continuous Latent Support Vector Machine (C-LSVM) methodto predict the cuteness score of one person given only his image. Extensiveevaluations validate the effectiveness of the proposed method for cutenessprediction.
arxiv-12900-18 | Pose-Guided Human Parsing with Deep Learned Features | http://arxiv.org/abs/1508.03881 | author:Fangting Xia, Jun Zhu, Peng Wang, Alan Yuille category:cs.CV published:2015-08-17 summary:Parsing human body into semantic regions is crucial to human-centricanalysis. In this paper, we propose a segment-based parsing pipeline thatexplores human pose information, i.e. the joint location of a human model,which improves the part proposal, accelerates the inference and regularizes theparsing process at the same time. Specifically, we first generate part segmentproposals with respect to human joints predicted by a deep model, then part-specific ranking models are trained for segment selection using both pose-basedfeatures and deep-learned part potential features. Finally, the best ensembleof the proposed part segments are inferred though an And-Or Graph. We evaluate our approach on the popular Penn-Fudan pedestrian parsingdataset, and demonstrate the effectiveness of using the pose information foreach stage of the parsing pipeline. Finally, we show that our approach yieldssuperior part segmentation accuracy comparing to the state-of-the-art methods.
arxiv-12900-19 | "Owl" and "Lizard": Patterns of Head Pose and Eye Pose in Driver Gaze Classification | http://arxiv.org/abs/1508.04028 | author:Lex Fridman, Joonbum Lee, Bryan Reimer, Trent Victor category:cs.CV cs.HC cs.LG published:2015-08-17 summary:Accurate, robust, inexpensive gaze tracking in the car can help keep a driversafe by facilitating the more effective study of how to improve (1) vehicleinterfaces and (2) the design of future Advanced Driver Assistance Systems. Inthis paper, we estimate head pose and eye pose from monocular video usingmethods developed extensively in prior work and ask two new interestingquestions. First, how much better can we classify driver gaze using head andeye pose versus just using head pose? Second, are there individual-specificgaze strategies that strongly correlate with how much gaze classificationimproves with the addition of eye pose information? We answer these questionsby evaluating data drawn from an on-road study of 40 drivers. The main insightof the paper is conveyed through the analogy of an "owl" and "lizard" whichdescribes the degree to which the eyes and the head move when shifting gaze.When the head moves a lot ("owl"), not much classification improvement isattained by estimating eye pose on top of head pose. On the other hand, whenthe head stays still and only the eyes move ("lizard"), classification accuracyincreases significantly from adding in eye pose. We characterize how thataccuracy varies between people, gaze strategies, and gaze regions.
arxiv-12900-20 | Evaluating Classifiers in Detecting 419 Scams in Bilingual Cybercriminal Communities | http://arxiv.org/abs/1508.04123 | author:Alex V. Mbaziira, Ehab Abozinadah, James H. Jones Jr category:cs.SI cs.CY cs.LG published:2015-08-17 summary:Incidents of organized cybercrime are rising because of criminals are reapinghigh financial rewards while incurring low costs to commit crime. As thedigital landscape broadens to accommodate more internet-enabled devices andtechnologies like social media, more cybercriminals who are not native Englishspeakers are invading cyberspace to cash in on quick exploits. In this paper weevaluate the performance of three machine learning classifiers in detecting 419scams in a bilingual Nigerian cybercriminal community. We use three popularclassifiers in text processing namely: Na\"ive Bayes, k-nearest neighbors (IBK)and Support Vector Machines (SVM). The preliminary results on a real worlddataset reveal the SVM significantly outperforms Na\"ive Bayes and IBK at 95%confidence level.
arxiv-12900-21 | Molding CNNs for text: non-linear, non-consecutive convolutions | http://arxiv.org/abs/1508.04112 | author:Tao Lei, Regina Barzilay, Tommi Jaakkola category:cs.CL cs.AI published:2015-08-17 summary:The success of deep learning often derives from well-chosen operationalbuilding blocks. In this work, we revise the temporal convolution operation inCNNs to better adapt it to text processing. Instead of concatenating wordrepresentations, we appeal to tensor algebra and use low-rank n-gram tensors todirectly exploit interactions between words already at the convolution stage.Moreover, we extend the n-gram convolution to non-consecutive words torecognize patterns with intervening words. Through a combination of low-ranktensors, and pattern weighting, we can efficiently evaluate the resultingconvolution operation via dynamic programming. We test the resultingarchitecture on standard sentiment classification and news categorizationtasks. Our model achieves state-of-the-art performance both in terms ofaccuracy and training speed. For instance, we obtain 51.2% accuracy on thefine-grained sentiment classification task.
arxiv-12900-22 | A Deep Learning Approach to Structured Signal Recovery | http://arxiv.org/abs/1508.04065 | author:Ali Mousavi, Ankit B. Patel, Richard G. Baraniuk category:cs.LG stat.ML published:2015-08-17 summary:In this paper, we develop a new framework for sensing and recoveringstructured signals. In contrast to compressive sensing (CS) systems that employlinear measurements, sparse representations, and computationally complexconvex/greedy algorithms, we introduce a deep learning framework that supportsboth linear and mildly nonlinear measurements, that learns a structuredrepresentation from training data, and that efficiently computes a signalestimate. In particular, we apply a stacked denoising autoencoder (SDA), as anunsupervised feature learner. SDA enables us to capture statisticaldependencies between the different elements of certain signals and improvesignal recovery performance as compared to the CS approach.
arxiv-12900-23 | A Generative Model for Multi-Dialect Representation | http://arxiv.org/abs/1508.04035 | author:Emmanuel N. Osegi category:cs.CV cs.LG stat.ML published:2015-08-17 summary:In the era of deep learning several unsupervised models have been developedto capture the key features in unlabeled handwritten data. Popular among themis the Restricted Boltzmann Machines RBM. However, due to the novelty inhandwritten multidialect data, the RBM may fail to generate an efficientrepresentation. In this paper we propose a generative model, the ModeSynthesizing Machine MSM for on-line representation of real life handwrittenmultidialect language data. The MSM takes advantage of the hierarchicalrepresentation of the modes of a data distribution using a two-point errorupdate to learn a sequence of representative multidialects in a generative way.Experiments were performed to evaluate the performance of the MSM over the RBMwith the former attaining much lower error values than the latter on bothindependent and mixed data set.
arxiv-12900-24 | A Generative Word Embedding Model and its Low Rank Positive Semidefinite Solution | http://arxiv.org/abs/1508.03826 | author:Shaohua Li, Jun Zhu, Chunyan Miao category:cs.CL cs.LG stat.ML published:2015-08-16 summary:Most existing word embedding methods can be categorized into Neural EmbeddingModels and Matrix Factorization (MF)-based methods. However some models areopaque to probabilistic interpretation, and MF-based methods, typically solvedusing Singular Value Decomposition (SVD), may incur loss of corpus information.In addition, it is desirable to incorporate global latent factors, such astopics, sentiments or writing styles, into the word embedding model. Sincegenerative models provide a principled way to incorporate latent factors, wepropose a generative word embedding model, which is easy to interpret, and canserve as a basis of more sophisticated latent factor models. The modelinference reduces to a low rank weighted positive semidefinite approximationproblem. Its optimization is approached by eigendecomposition on a submatrix,followed by online blockwise regression, which is scalable and avoids theinformation loss in SVD. In experiments on 7 common benchmark datasets, ourvectors are competitive to word2vec, and better than other MF-based methods.
arxiv-12900-25 | Online Representation Learning in Recurrent Neural Language Models | http://arxiv.org/abs/1508.03854 | author:Marek Rei category:cs.CL cs.LG cs.NE published:2015-08-16 summary:We investigate an extension of continuous online learning in recurrent neuralnetwork language models. The model keeps a separate vector representation ofthe current unit of text being processed and adaptively adjusts it after eachprediction. The initial experiments give promising results, indicating that themethod is able to increase language modelling accuracy, while also decreasingthe parameters needed to store the model along with the computation required ateach step.
arxiv-12900-26 | Two-stage Cascaded Classifier for Purchase Prediction | http://arxiv.org/abs/1508.03856 | author:Sheikh Muhammad Sarwar, Mahamudul Hasan, Dmitry I. Ignatov category:cs.IR cs.LG published:2015-08-16 summary:In this paper we describe our machine learning solution for the RecSysChallenge, 2015. We have proposed a time efficient two-stage cascadedclassifier for the prediction of buy sessions and purchased items within suchsessions. Based on the model, several interesting features found, and formationof our own test bed, we have achieved a reasonable score. Usage of RandomForests helps us to cope with the effect of the multiplicity of good modelsdepending on varying subsets of features in the purchased items prediction and,in its turn, boosting is used as a suitable technique to overcome severe classimbalance of the buy-session prediction.
arxiv-12900-27 | Visual Affect Around the World: A Large-scale Multilingual Visual Sentiment Ontology | http://arxiv.org/abs/1508.03868 | author:Brendan Jou, Tao Chen, Nikolaos Pappas, Miriam Redi, Mercan Topkara, Shih-Fu Chang category:cs.MM cs.CL cs.CV cs.IR published:2015-08-16 summary:Every culture and language is unique. Our work expressly focuses on theuniqueness of culture and language in relation to human affect, specificallysentiment and emotion semantics, and how they manifest in social multimedia. Wedevelop sets of sentiment- and emotion-polarized visual concepts by adaptingsemantic structures called adjective-noun pairs, originally introduced by Borthet al. (2013), but in a multilingual context. We propose a newlanguage-dependent method for automatic discovery of these adjective-nounconstructs. We show how this pipeline can be applied on a social multimediaplatform for the creation of a large-scale multilingual visual sentimentconcept ontology (MVSO). Unlike the flat structure in Borth et al. (2013), ourunified ontology is organized hierarchically by multilingual clusters ofvisually detectable nouns and subclusters of emotionally biased versions ofthese nouns. In addition, we present an image-based prediction task to show howgeneralizable language-specific models are in a multilingual context. A new,publicly available dataset of >15.6K sentiment-biased visual concepts across 12languages with language-specific detector banks, >7.36M images and theirmetadata is also released.
arxiv-12900-28 | Predicting Grades | http://arxiv.org/abs/1508.03865 | author:Yannick Meier, Jie Xu, Onur Atan, Mihaela van der Schaar category:cs.LG published:2015-08-16 summary:To increase efficacy in traditional classroom courses as well as in MassiveOpen Online Courses (MOOCs), automated systems supporting the instructor areneeded. One important problem is to automatically detect students that aregoing to do poorly in a course early enough to be able to take remedialactions. Existing grade prediction systems focus on maximizing the accuracy ofthe prediction while overseeing the importance of issuing timely andpersonalized predictions. This paper proposes an algorithm that predicts thefinal grade of each student in a class. It issues a prediction for each studentindividually, when the expected accuracy of the prediction is sufficient. Thealgorithm learns online what is the optimal prediction and time to issue aprediction based on past history of students' performance in a course. Wederive a confidence estimate for the prediction accuracy and demonstrate theperformance of our algorithm on a dataset obtained based on the performance ofapproximately 700 UCLA undergraduate students who have taken an introductorydigital signal processing over the past 7 years. We demonstrate that for 85% ofthe students we can predict with 76% accuracy whether they are going do well orpoorly in the class after the 4th course week. Using data obtained from a pilotcourse, our methodology suggests that it is effective to perform early in-classassessments such as quizzes, which result in timely performance prediction foreach student, thereby enabling timely interventions by the instructor (at thestudent or class level) when necessary.
arxiv-12900-29 | Depth-Gated LSTM | http://arxiv.org/abs/1508.03790 | author:Kaisheng Yao, Trevor Cohn, Katerina Vylomova, Kevin Duh, Chris Dyer category:cs.NE cs.CL published:2015-08-16 summary:In this short note, we present an extension of long short-term memory (LSTM)neural networks to using a depth gate to connect memory cells of adjacentlayers. Doing so introduces a linear dependence between lower and upper layerrecurrent units. Importantly, the linear dependence is gated through a gatingfunction, which we call depth gate. This gate is a function of the lower layermemory cell, the input to and the past memory cell of this layer. We conductedexperiments and verified that this new architecture of LSTMs was able toimprove machine translation and language modeling performances.
arxiv-12900-30 | Schema Independent Relational Learning | http://arxiv.org/abs/1508.03846 | author:Jose Picado, Arash Termehchy, Alan Fern category:cs.DB cs.AI cs.LG cs.LO published:2015-08-16 summary:Learning novel and interesting concepts and relations from relationaldatabases is an important problem with many applications in database systemsand machine learning. Relational learning algorithms generally leverage theproperties of the database schema to find the definition of the target conceptin terms of the existing relations in the database. Nevertheless, it is wellestablished that the same data set may be represented under different schemasfor various reasons, such as efficiency, data quality, and usability.Unfortunately, many current learning algorithms tend to vary quitesubstantially over the choice of schema, both in terms of learning accuracy andefficiency, which complicates their off-the-shelf application. In this paper,we formalize the property of schema independence of relational learningalgorithms, and study both the theoretical and empirical dependence of existingalgorithms on the common class of vertical (de)composition schematransformations. We study both sample-based learning algorithms, which learnfrom sets of labeled examples, and query-based algorithms, which learn byasking queries to a user. For sample-based algorithms we consider the two mainalgorithm classes: top-down and bottom-up. We prove that practical top-downalgorithms are generally not schema independent, while, in contrast, twobottom-up algorithms Golem and ProGolem are schema independent with somemodifications. For query-based learning algorithms we show that the vertical(de)composition transformations influence their learning efficiency. We supportthe theoretical results with an empirical study that demonstrates the schemadependence/independence of several algorithms on existing benchmark data setsunder natural vertical (de)compositions.
arxiv-12900-31 | Beat-Event Detection in Action Movie Franchises | http://arxiv.org/abs/1508.03755 | author:Danila Potapov, Matthijs Douze, Jerome Revaud, Zaid Harchaoui, Cordelia Schmid category:cs.CV published:2015-08-15 summary:While important advances were recently made towards temporally localizing andrecognizing specific human actions or activities in videos, efficient detectionand classification of long video chunks belonging to semantically definedcategories such as "pursuit" or "romance" remains challenging.We introduce anew dataset, Action Movie Franchises, consisting of a collection of Hollywoodaction movie franchises. We define 11 non-exclusive semantic categories -called beat-categories - that are broad enough to cover most of the moviefootage. The corresponding beat-events are annotated as groups of video shots,possibly overlapping.We propose an approach for localizing beat-events based onclassifying shots into beat-categories and learning the temporal constraintsbetween shots. We show that temporal constraints significantly improve theclassification performance. We set up an evaluation protocol for beat-eventlocalization as well as for shot classification, depending on whether moviesfrom the same franchise are present or not in the training data.
arxiv-12900-32 | A Comparative Study on Regularization Strategies for Embedding-based Neural Networks | http://arxiv.org/abs/1508.03721 | author:Hao Peng, Lili Mou, Ge Li, Yunchuan Chen, Yangyang Lu, Zhi Jin category:cs.CL cs.LG published:2015-08-15 summary:This paper aims to compare different regularization strategies to address acommon phenomenon, severe overfitting, in embedding-based neural networks forNLP. We chose two widely studied neural models and tasks as our testbed. Wetried several frequently applied or newly proposed regularization strategies,including penalizing weights (embeddings excluded), penalizing embeddings,re-embedding words, and dropout. We also emphasized on incrementalhyperparameter tuning, and combining different regularizations. The resultsprovide a picture on tuning hyperparameters for neural NLP models.
arxiv-12900-33 | Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Path | http://arxiv.org/abs/1508.03720 | author:Xu Yan, Lili Mou, Ge Li, Yunchuan Chen, Hao Peng, Zhi Jin category:cs.CL cs.LG published:2015-08-15 summary:Relation classification is an important research arena in the field ofnatural language processing (NLP). In this paper, we present SDP-LSTM, a novelneural network to classify the relation of two entities in a sentence. Ourneural architecture leverages the shortest dependency path (SDP) between twoentities; multichannel recurrent neural networks, with long short term memory(LSTM) units, pick up heterogeneous information along the SDP. Our proposedmodel has several distinct features: (1) The shortest dependency paths retainmost relevant information (to relation classification), while eliminatingirrelevant words in the sentence. (2) The multichannel LSTM networks alloweffective information integration from heterogeneous sources over thedependency paths. (3) A customized dropout strategy regularizes the neuralnetwork to alleviate overfitting. We test our model on the SemEval 2010relation classification task, and achieve an $F_1$-score of 83.7\%, higher thancompeting methods in the literature.
arxiv-12900-34 | Towards an Axiomatic Approach to Hierarchical Clustering of Measures | http://arxiv.org/abs/1508.03712 | author:Philipp Thomann, Ingo Steinwart, Nico Schmid category:stat.ML cs.LG math.ST stat.ME stat.TH published:2015-08-15 summary:We propose some axioms for hierarchical clustering of probability measuresand investigate their ramifications. The basic idea is to let the userstipulate the clusters for some elementary measures. This is done without theneed of any notion of metric, similarity or dissimilarity. Our main resultsthen show that for each suitable choice of user-defined clustering onelementary measures we obtain a unique notion of clustering on a large set ofdistributions satisfying a set of additivity and continuity axioms. Weillustrate the developed theory by numerous examples including some with andsome without a density.
arxiv-12900-35 | A Novel Approach For Finger Vein Verification Based on Self-Taught Learning | http://arxiv.org/abs/1508.03710 | author:Mohsen Fayyaz, Masoud PourReza, Mohammad Hajizadeh Saffar, Mohammad Sabokrou, Mahmood Fathy category:cs.CV published:2015-08-15 summary:In this paper, we propose a method for user Finger Vein Authentication (FVA)as a biometric system. Using the discriminative features for classifying thesesfinger veins is one of the main tips that make difference in related works,Thus we propose to learn a set of representative features, based onautoencoders. We model the user finger vein using a Gaussian distribution.Experimental results show that our algorithm perform like a state-of-the-art onSDUMLA-HMT benchmark.
arxiv-12900-36 | Reward Shaping with Recurrent Neural Networks for Speeding up On-Line Policy Learning in Spoken Dialogue Systems | http://arxiv.org/abs/1508.03391 | author:Pei-Hao Su, David Vandyke, Milica Gasic, Nikola Mrksic, Tsung-Hsien Wen, Steve Young category:cs.LG cs.CL published:2015-08-14 summary:Statistical spoken dialogue systems have the attractive property of beingable to be optimised from data via interactions with real users. However in thereinforcement learning paradigm the dialogue manager (agent) often requiressignificant time to explore the state-action space to learn to behave in adesirable manner. This is a critical issue when the system is trained on-linewith real users where learning costs are expensive. Reward shaping is onepromising technique for addressing these concerns. Here we examine threerecurrent neural network (RNN) approaches for providing reward shapinginformation in addition to the primary (task-orientated) environmentalfeedback. These RNNs are trained on returns from dialogues generated by asimulated user and attempt to diffuse the overall evaluation of the dialogueback down to the turn level to guide the agent towards good behaviour faster.In both simulated and real user scenarios these RNNs are shown to increasepolicy learning speed. Importantly, they do not require prior knowledge of theuser's goal.
arxiv-12900-37 | Cost Sensitive Learning of Deep Feature Representations from Imbalanced Data | http://arxiv.org/abs/1508.03422 | author:Salman H. Khan, Mohammed Bennamoun, Ferdous Sohel, Roberto Togneri category:cs.CV published:2015-08-14 summary:Class imbalance is a common problem in the case of real-world objectdetection and classification tasks. Data of some classes is abundant makingthem an over-represented majority, and data of other classes is scarce, makingthem an under-represented minority. This imbalance makes it challenging for aclassifier to appropriately learn the discriminating boundaries of the majorityand minority classes. In this work, we propose a cost sensitive deep neuralnetwork which can automatically learn robust feature representations for boththe majority and minority classes. During training, our learning procedurejointly optimizes the class dependent costs and the neural network parameters.The proposed approach is applicable to both binary and multi-class problemswithout any modification. Moreover, as opposed to data level approaches, we donot alter the original data distribution which results in a lower computationalcost during the training process. We report the results of our experiments onsix major image classification datasets and show that the proposed approachsignificantly outperforms the baseline algorithms. Comparisons with populardata sampling techniques and cost sensitive classifiers demonstrate thesuperior performance of our proposed method.
arxiv-12900-38 | Doubly Stochastic Primal-Dual Coordinate Method for Empirical Risk Minimization and Bilinear Saddle-Point Problem | http://arxiv.org/abs/1508.03390 | author:Adams Wei Yu, Qihang Lin, Tianbao Yang category:cs.LG stat.ML published:2015-08-14 summary:We proposed a doubly stochastic primal-dual coordinate (DSPDC) optimizationalgorithm for empirical risk minimization, which can be formulated as abilinear saddle-point problem. In each iteration, our method randomly samples ablock of coordinates of the primal and dual solutions to update. Theconvergence of our method is established in both the distance from the currentiterate to the optimal solution and the primal-dual objective gap. We show thatthe proposed method has a lower overall complexity than existing coordinatemethods when either the data matrix has a factorized structure or the proximalmapping on each block is computationally expensive, e.g., involves aneigenvalue decomposition. Furthermore, we give a theoretical lower bound on theiteration complexity of a general family of primal-dual (block) coordinatemethods for bilinear saddle-point problems, which also includes DSPDC.
arxiv-12900-39 | Unbounded Bayesian Optimization via Regularization | http://arxiv.org/abs/1508.03666 | author:Bobak Shahriari, Alexandre Bouchard-Côté, Nando de Freitas category:stat.ML published:2015-08-14 summary:Bayesian optimization has recently emerged as a popular and efficient toolfor global optimization and hyperparameter tuning. Currently, the establishedBayesian optimization practice requires a user-defined bounding box which isassumed to contain the optimizer. However, when little is known about theprobed objective function, it can be difficult to prescribe such bounds. Inthis work we modify the standard Bayesian optimization framework in aprincipled way to allow automatic resizing of the search space. We introducetwo alternative methods and compare them on two common synthetic benchmarkingtest functions as well as the tasks of tuning the stochastic gradient descentoptimizer of a multi-layered perceptron and a convolutional neural network onMNIST.
arxiv-12900-40 | Oracle MCG: A first peek into COCO Detection Challenges | http://arxiv.org/abs/1509.03660 | author:Jordi Pont-Tuset, Pablo Arbeláez, Luc Van Gool category:cs.CV published:2015-08-14 summary:The recently presented COCO detection challenge will most probably be thereference benchmark in object detection in the next years. COCO is two ordersof magnitude larger than Pascal and has four times the number of categories; soin all likelihood researchers will be faced with a number of new challenges. Atthis point, without any finished round of the competition, it is difficult forresearchers to put their techniques in context, or in other words, to know howgood their results are. In order to give a little context, this note evaluatesa hypothetical object detector consisting in an oracle picking the best objectproposal from a state-of-the-art technique. This oracle achieves a AP=0.292 insegmented objects and AP=0.317 in bounding boxes, showing that indeed thedatabase is challenging, given that this value is the best one can expect ifworking on object proposals without refinement.
arxiv-12900-41 | Lensless Compressive Imaging | http://arxiv.org/abs/1508.03498 | author:Xin Yuan, Hong Jiang, Gang Huang, Paul Wilford category:cs.CV stat.AP stat.ME published:2015-08-14 summary:We develop a lensless compressive imaging architecture, which consists of anaperture assembly and a single sensor, without using any lens. An anytimealgorithm is proposed to reconstruct images from the compressive measurements;the algorithm produces a sequence of solutions that monotonically converge tothe true signal (thus, anytime). The algorithm is developed based on thesparsity of local overlapping patches (in the transformation domain) andstate-of-the-art results have been obtained. Experiments on real datademonstrate that encouraging results are obtained by measuring about 10% (ofthe image pixels) compressive measurements. The reconstruction results of theproposed algorithm are compared with the JPEG compression (based on file sizes)and the reconstructed image quality is close to the JPEG compression, inparticular at a high compression rate.
arxiv-12900-42 | End-to-end Learning of LDA by Mirror-Descent Back Propagation over a Deep Architecture | http://arxiv.org/abs/1508.03398 | author:Jianshu Chen, Ji He, Yelong Shen, Lin Xiao, Xiaodong He, Jianfeng Gao, Xinying Song, Li Deng category:cs.LG published:2015-08-14 summary:We develop a fully discriminative learning approach for supervised LatentDirichlet Allocation (LDA) model using Back Propagation (i.e., BP-sLDA), whichmaximizes the posterior probability of the prediction variable given the inputdocument. Different from traditional variational learning or Gibbs samplingapproaches, the proposed learning method applies (i) the mirror descentalgorithm for maximum a posterior inference and (ii) back propagation over adeep architecture together with stochastic gradient/mirror descent for modelparameter estimation, leading to scalable and end-to-end discriminativelearning of the model. As a byproduct, we also apply this technique to developa new learning method for the traditional unsupervised LDA model (i.e.,BP-LDA). Experimental results on three real-world regression and classificationtasks show that the proposed methods significantly outperform the previoussupervised topic models, neural networks, and is on par with deep neuralnetworks.
arxiv-12900-43 | Hierarchical Models as Marginals of Hierarchical Models | http://arxiv.org/abs/1508.03606 | author:Guido Montufar, Johannes Rauh category:math.PR cs.LG cs.NE math.ST stat.TH published:2015-08-14 summary:We investigate the representation of hierarchical models in terms ofmarginals of other hierarchical models with smaller interactions. We focus onbinary variables and marginals of pairwise interaction models whose hiddenvariables are conditionally independent given the visible variables. In thiscase the problem is equivalent to the representation of linear subspaces ofpolynomials by feedforward neural networks with soft-plus computational units.We show that every hidden variable can freely model multiple interactions amongthe visible variables, which allows us to generalize and improve previousresults. In particular, we show that a restricted Boltzmann machine with lessthan $[ 2(\log(v)+1) / (v+1) ] 2^v-1$ hidden binary variables can approximateevery distribution of $v$ visible binary variables arbitrarily well, comparedto $2^{v-1}-1$ from the best previously known result.
arxiv-12900-44 | Is Stack Overflow Overflowing With Questions and Tags | http://arxiv.org/abs/1508.03601 | author:Ranjitha R. K., Sanjay Singh category:cs.SI cs.CL published:2015-08-14 summary:Programming question and answer (Q & A) websites, such as Quora, StackOverflow, and Yahoo! Answer etc. helps us to understand the programmingconcepts easily and quickly in a way that has been tested and applied by manysoftware developers. Stack Overflow is one of the most frequently usedprogramming Q\&A website where the questions and answers posted are presentlyanalyzed manually, which requires a huge amount of time and resource. To savethe effort, we present a topic modeling based technique to analyze the words ofthe original texts to discover the themes that run through them. We alsopropose a method to automate the process of reviewing the quality of questionson Stack Overflow dataset in order to avoid ballooning the stack overflow withinsignificant questions. The proposed method also recommends the appropriatetags for the new post, which averts the creation of unnecessary tags on StackOverflow.
arxiv-12900-45 | Information-theoretic Bounds on Matrix Completion under Union of Subspaces Model | http://arxiv.org/abs/1508.03395 | author:Vaneet Aggarwal, Shuchin Aeron category:cs.IT math.IT stat.ML published:2015-08-14 summary:In this short note we extend some of the recent results on matrix completionunder the assumption that the columns of the matrix can be grouped (clustered)into subspaces (not necessarily disjoint or independent). This model deviatesfrom the typical assumption prevalent in the literature dealing withcompression and recovery for big-data applications. The results have a directbearing on the problem of subspace clustering under missing or incompleteinformation.
arxiv-12900-46 | Emphatic TD Bellman Operator is a Contraction | http://arxiv.org/abs/1508.03411 | author:Assaf Hallak, Aviv Tamar, Shie Mannor category:stat.ML cs.LG published:2015-08-14 summary:Recently, \citet{SuttonMW15} introduced the emphatic temporal differences(ETD) algorithm for off-policy evaluation in Markov decision processes. In thisshort note, we show that the projected fixed-point equation that underlies ETDinvolves a contraction operator, with a $\sqrt{\gamma}$-contraction modulus(where $\gamma$ is the discount factor). This allows us to provide error boundson the approximation error of ETD. To our knowledge, these are the first errorbounds for an off-policy evaluation algorithm under general target and behaviorpolicies.
arxiv-12900-47 | A Survey on Contextual Multi-armed Bandits | http://arxiv.org/abs/1508.03326 | author:Li Zhou category:cs.LG published:2015-08-13 summary:In this survey we cover a few stochastic and adversarial contextual banditalgorithms. We analyze each algorithm's assumption and regret bound.
arxiv-12900-48 | A Randomized Rounding Algorithm for Sparse PCA | http://arxiv.org/abs/1508.03337 | author:Kimon Fountoulakis, Abhisek Kundu, Eugenia-Maria Kontopoulou, Petros Drineas category:cs.DS cs.LG stat.ML published:2015-08-13 summary:We present and analyze a simple, two-step algorithm to approximate theoptimal solution of the sparse PCA problem. Our approach first solves a L1penalized version of the NP-hard sparse PCA optimization problem and then usesa randomized rounding strategy to sparsify the resulting dense solution. Ourmain theoretical result guarantees an additive error approximation and providesa tradeoff between sparsity and accuracy. Our experimental evaluation indicatesthat our approach is competitive in practice, even compared to state-of-the-arttoolboxes such as Spasm.
arxiv-12900-49 | Hash Function Learning via Codewords | http://arxiv.org/abs/1508.03285 | author:Yinjie Huang, Michael Georgiopoulos, Georgios C. Anagnostopoulos category:cs.LG published:2015-08-13 summary:In this paper we introduce a novel hash learning framework that has two maindistinguishing features, when compared to past approaches. First, it utilizescodewords in the Hamming space as ancillary means to accomplish its hashlearning task. These codewords, which are inferred from the data, attempt tocapture similarity aspects of the data's hash codes. Secondly and moreimportantly, the same framework is capable of addressing supervised,unsupervised and, even, semi-supervised hash learning tasks in a naturalmanner. A series of comparative experiments focused on content-based imageretrieval highlights its performance advantages.
arxiv-12900-50 | Logical N-AND Gate on a Molecular Turing Machine | http://arxiv.org/abs/1508.03174 | author:Victor Hernandez-Urbina category:cs.ET cs.NE published:2015-08-13 summary:In Boolean algebra, it is known that the logical function that corresponds tothe negation of the conjunction --NAND-- is universal in the sense that anyother logical function can be built based on it. This property makes itessential to modern digital electronics and computer processor design. Here, wedesign a molecular Turing machine that computes the NAND function over binarystrings of arbitrary length. For this purpose, we will perform a mathematicalabstraction of the kind of operations that can be done over a double-strandedDNA molecule, as well as presenting a molecular encoding of the input symbolsfor such a machine.
arxiv-12900-51 | Learning from Real Users: Rating Dialogue Success with Neural Networks for Reinforcement Learning in Spoken Dialogue Systems | http://arxiv.org/abs/1508.03386 | author:Pei-Hao Su, David Vandyke, Milica Gasic, Dongho Kim, Nikola Mrksic, Tsung-Hsien Wen, Steve Young category:cs.LG cs.CL published:2015-08-13 summary:To train a statistical spoken dialogue system (SDS) it is essential that anaccurate method for measuring task success is available. To date training hasrelied on presenting a task to either simulated or paid users and inferring thedialogue's success by observing whether this presented task was achieved ornot. Our aim however is to be able to learn from real users acting under theirown volition, in which case it is non-trivial to rate the success as any priorknowledge of the task is simply unavailable. User feedback may be utilised buthas been found to be inconsistent. Hence, here we present two neural networkmodels that evaluate a sequence of turn-level features to rate the success of adialogue. Importantly these models make no use of any prior knowledge of theuser's task. The models are trained on dialogues generated by a simulated userand the best model is then used to train a policy on-line which is shown toperform at least as well as a baseline system using prior knowledge of theuser's task. We note that the models should also be of interest for evaluatingSDS and for monitoring a dialogue in rule-based SDS.
arxiv-12900-52 | Multi-Task Learning with Group-Specific Feature Space Sharing | http://arxiv.org/abs/1508.03329 | author:Niloofar Yousefi, Michael Georgiopoulos, Georgios C. Anagnostopoulos category:cs.LG published:2015-08-13 summary:When faced with learning a set of inter-related tasks from a limited amountof usable data, learning each task independently may lead to poorgeneralization performance. Multi-Task Learning (MTL) exploits the latentrelations between tasks and overcomes data scarcity limitations by co-learningall these tasks simultaneously to offer improved performance. We propose anovel Multi-Task Multiple Kernel Learning framework based on Support VectorMachines for binary classification tasks. By considering pair-wise taskaffinity in terms of similarity between a pair's respective feature spaces, thenew framework, compared to other similar MTL approaches, offers a high degreeof flexibility in determining how similar feature spaces should be, as well aswhich pairs of tasks should share a common feature space in order to benefitoverall performance. The associated optimization problem is solved via a blockcoordinate descent, which employs a consensus-form Alternating Direction Methodof Multipliers algorithm to optimize the Multiple Kernel Learning weights and,hence, to determine task affinities. Empirical evaluation on seven data setsexhibits a statistically significant improvement of our framework's resultscompared to the ones of several other Clustered Multi-Task Learning methods.
arxiv-12900-53 | Talking about the Moving Image: A Declarative Model for Image Schema Based Embodied Perception Grounding and Language Generation | http://arxiv.org/abs/1508.03276 | author:Jakob Suchan, Mehul Bhatt, Harshita Jhavar category:cs.AI cs.CL cs.CV cs.HC published:2015-08-13 summary:We present a general theory and corresponding declarative model for theembodied grounding and natural language based analytical summarisation ofdynamic visuo-spatial imagery. The declarative model ---ecompassingspatio-linguistic abstractions, image schemas, and a spatio-temporal featurebased language generator--- is modularly implemented within Constraint LogicProgramming (CLP). The implemented model is such that primitives of the theory,e.g., pertaining to space and motion, image schemata, are available asfirst-class objects with `deep semantics' suited for inference and query. Wedemonstrate the model with select examples broadly motivated by areas such asfilm, design, geography, smart environments where analytical natural languagebased externalisations of the moving image are central from the viewpoint ofhuman interaction, evidence-based qualitative analysis, and sensemaking. Keywords: moving image, visual semantics and embodiment, visuo-spatialcognition and computation, cognitive vision, computational models of narrative,declarative spatial reasoning
arxiv-12900-54 | Generation of Multimedia Artifacts: An Extractive Summarization-based Approach | http://arxiv.org/abs/1508.03170 | author:Paulo Figueiredo, Marta Aparício, David Martins de Matos, Ricardo Ribeiro category:cs.AI cs.CL cs.MM I.2.7 published:2015-08-13 summary:We explore methods for content selection and address the issue of coherencein the context of the generation of multimedia artifacts. We use audio andvideo to present two case studies: generation of film tributes, andlecture-driven science talks. For content selection, we use centrality-basedand diversity-based summarization, along with topic analysis. To establishcoherence, we use the emotional content of music, for film tributes, and ensuretopic similarity between lectures and documentaries, for science talks.Composition techniques for the production of multimedia artifacts are addressedas a means of organizing content, in order to improve coherence. We discuss ourresults considering the above aspects.
arxiv-12900-55 | Neyman-Pearson Classification under High-Dimensional Settings | http://arxiv.org/abs/1508.03106 | author:Anqi Zhao, Yang Feng, Lie Wang, Xin Tong category:stat.ML published:2015-08-13 summary:Most existing binary classification methods target on the optimization of theoverall classification risk and may fail to serve some real-world applicationssuch as cancer diagnosis, where users are more concerned with the risk ofmisclassifying one specific class than the other. Neyman-Pearson (NP) paradigmwas introduced in this context as a novel statistical framework for handlingasymmetric type I/II error priorities. It seeks classifiers with a minimal typeII error and a constrained type I error under a user specified level. Thisarticle is the first attempt to construct classifiers with guaranteedtheoretical performance under the NP paradigm in high-dimensional settings.Based on the fundamental Neyman-Pearson Lemma, we used a plug-in approach toconstruct NP-type classifiers for Naive Bayes models. The proposed classifierssatisfy the NP oracle inequalities, which are natural NP paradigm counterpartsof the oracle inequalities in classical binary classification. Besides theirdesirable theoretical properties, we also demonstrated their numericaladvantages in prioritized error control via both simulation and real datastudies.
arxiv-12900-56 | Probabilistic Dependency Networks for Prediction and Diagnostics | http://arxiv.org/abs/1508.03130 | author:Narayanan U. Edakunni, Aditi Raghunathan, Abhishek Tripathi, John Handley, Fredric Roulland category:cs.LG published:2015-08-13 summary:Research in transportation frequently involve modelling and predictingattributes of events that occur at regular intervals. The event could bearrival of a bus at a bus stop, the volume of a traffic at a particular point,the demand at a particular bus stop etc. In this work, we propose a specificimplementation of probabilistic graphical models to learn the probabilisticdependency between the events that occur in a network. A dependency graph isbuilt from the past observed instances of the event and we use the graph tounderstand the causal effects of some events on others in the system. Thedependency graph is also used to predict the attributes of future events and isshown to have a good prediction accuracy compared to the state of the art.
arxiv-12900-57 | Optimized Projections for Compressed Sensing via Direct Mutual Coherence Minimization | http://arxiv.org/abs/1508.03117 | author:Zhouchen Lin, Canyi Lu, Huan Li category:cs.IT cs.LG math.IT published:2015-08-13 summary:Compressed Sensing (CS) is a novel technique for simultaneous signal samplingand compression based on the existence of a sparse representation of signal anda projected dictionary $\PP\D$, where $\PP\in\mathbb{R}^{m\times d}$ is theprojection matrix and $\D\in\mathbb{R}^{d\times n}$ is the dictionary. Toexactly recover the signal with a small number of measurements $m$, theprojected dictionary $\PP\D$ is expected to be of low mutual coherence. Severalprevious methods attempt to find the projection $\PP$ such that the mutualcoherence of $\PP\D$ can be as low as possible. However, they do not minimizethe mutual coherence directly and thus their methods are far from optimal. Alsothe solvers they used lack of the convergence guarantee and thus there has noguarantee on the quality of their obtained solutions. This work aims to addressthese issues. We propose to find an optimal projection by minimizing the mutualcoherence of $\PP\D$ directly. This leads to a nonconvex nonsmooth minimizationproblem. We then approximate it by smoothing and solve it by alternateminimization. We further prove the convergence of our algorithm. To the best ofour knowledge, this is the first work which directly minimizes the mutualcoherence of the projected dictionary with a convergence guarantee. Numericalexperiments demonstrate that the proposed method can recover sparse signalsbetter than existing methods.
arxiv-12900-58 | Borobudur was Built Algorithmically | http://arxiv.org/abs/1508.03649 | author:Hokky Situngkir category:cs.CY cs.CV cs.GR published:2015-08-13 summary:The self-similarity of Indonesian Borobudur Temple is observed through thedimensionality of stupa that is hypothetically closely related to wholearchitectural body. Fractal dimension is calculated by using the cube countingmethod and found that the dimension is 2.325, which is laid between thetwo-dimensional plane and three dimensional space. The applied fractal geometryand self-similarity of the building is emerged as the building processimplement the metric rules, since there is no universal metric standard knownin ancient traditional Javanese culture thus the architecture is not based onfinal master plan. The paper also proposes how the hypothetical algorithmicarchitecture might be applied computationally in order to see some experimentalgenerations of similar building. The paper ends with some conjectures forfurther challenge and insights related to fractal geometry in Javanesetraditional cultural heritages.
arxiv-12900-59 | A New Approach to an Old Problem: The Reconstruction of a Go Game through a Series of Photographs | http://arxiv.org/abs/1508.03269 | author:Mario Corsolini, Andrea Carta category:cs.CV published:2015-08-13 summary:Given a series of photographs taken during a Go game, we describe thetechniques we successfully employ for pinpointing the grid lines of the Goboard and for tracking their small movements between consecutive photographs;then we discuss how to approximate the location and orientation of theobserver's point of view, in order to compensate for projection effects.Finally we describe the different criteria that jointly form the algorithm forstones' detection, thus enabling us to automatically reconstruct the whole movesequence.
arxiv-12900-60 | From Cutting Planes Algorithms to Compression Schemes and Active Learning | http://arxiv.org/abs/1508.02986 | author:Liva Ralaivola, Ugo Louche category:cs.LG published:2015-08-12 summary:Cutting-plane methods are well-studied localization(and optimization)algorithms. We show that they provide a natural framework to performmachinelearning ---and not just to solve optimization problems posed bymachinelearning--- in addition to their intended optimization use. Inparticular, theyallow one to learn sparse classifiers and provide goodcompression schemes.Moreover, we show that very little effort is required toturn them intoeffective active learning methods. This last property provides ageneric way todesign a whole family of active learning algorithms from existingpassivemethods. We present numerical simulations testifying of the relevanceofcutting-plane methods for passive and active learning tasks.
arxiv-12900-61 | Syntax Evolution: Problems and Recursion | http://arxiv.org/abs/1508.03040 | author:Ramón Casares category:cs.CL I.2.7; I.2.8 published:2015-08-12 summary:We are Turing complete, and natural language parsing is decidable, so oursyntactic abilities are in excess to those needed to speak a natural language.This is an anomaly, because evolution would not keep an overqualified featurefor long. We solve this anomaly by using a coincidence, both syntax and problemsolving are computing, and a difference, Turing completeness is not arequirement of syntax, but of problem solving. Then computing should have beenshaped by evolutionary requirements coming from both syntax and problemsolving, but the last one, Turing completeness, only from problem solving. Sowe propose and analyze a hypothesis: syntax and problem solving co-evolved inhumans towards Turing completeness. Finally, we argue that Turing completeness,also known as recursion, is our most singular feature.
arxiv-12900-62 | Learning to Hire Teams | http://arxiv.org/abs/1508.02823 | author:Adish Singla, Eric Horvitz, Pushmeet Kohli, Andreas Krause category:cs.HC cs.CY cs.LG published:2015-08-12 summary:Crowdsourcing and human computation has been employed in increasinglysophisticated projects that require the solution of a heterogeneous set oftasks. We explore the challenge of building or hiring an effective team, forperforming tasks required for such projects on an ongoing basis, from anavailable pool of applicants or workers who have bid for the tasks. Therecruiter needs to learn workers' skills and expertise by performing onlinetests and interviews, and would like to minimize the amount of budget or timespent in this process before committing to hiring the team. How can oneoptimally spend budget to learn the expertise of workers as part of recruitinga team? How can one exploit the similarities among tasks as well as underlyingsocial ties or commonalities among the workers for faster learning? We tacklethese decision-theoretic challenges by casting them as an instance of onlinelearning for best action selection. We present algorithms with PAC bounds onthe required budget to hire a near-optimal team with high confidence.Furthermore, we consider an embedding of the tasks and workers in an underlyinggraph that may arise from task similarities or social ties, and that canprovide additional side-observations for faster learning. We then quantify theimprovement in the bounds that we can achieve depending on the characteristicproperties of this graph structure. We evaluate our methodology on simulatedproblem instances as well as on real-world crowdsourcing data collected fromthe oDesk platform. Our methodology and results present an interestingdirection of research to tackle the challenges faced by a recruiter forcontract-based crowdsourcing.
arxiv-12900-63 | Possible Mechanisms for Neural Reconfigurability and their Implications | http://arxiv.org/abs/1508.02792 | author:Thomas M. Breuel category:cs.NE q-bio.NC K.3.2 published:2015-08-12 summary:The paper introduces a biologically and evolutionarily plausible neuralarchitecture that allows a single group of neurons, or an entire corticalpathway, to be dynamically reconfigured to perform multiple, potentially verydifferent computations. The paper shows that reconfigurability can account forthe observed stochastic and distributed coding behavior of neurons and providesa parsimonious explanation for timing phenomena in psychophysical experiments.It also shows that reconfigurable pathways correspond to classes of statisticalclassifiers that include decision lists, decision trees, and hierarchicalBayesian methods. Implications for the interpretation of neurophysiological andpsychophysical results are discussed, and future experiments for testing thereconfigurability hypothesis are explored.
arxiv-12900-64 | On the Convergence of SGD Training of Neural Networks | http://arxiv.org/abs/1508.02790 | author:Thomas M. Breuel category:cs.NE cs.LG K.3.2 published:2015-08-12 summary:Neural networks are usually trained by some form of stochastic gradientdescent (SGD)). A number of strategies are in common use intended to improveSGD optimization, such as learning rate schedules, momentum, and batching.These are motivated by ideas about the occurrence of local minima at differentscales, valleys, and other phenomena in the objective function. Empiricalresults presented here suggest that these phenomena are not significant factorsin SGD optimization of MLP-related objective functions, and that the behaviorof stochastic gradient descent in these problems is better described as thesimultaneous convergence at different rates of many, largely non-interactingsubproblems
arxiv-12900-65 | Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration | http://arxiv.org/abs/1508.02848 | author:Yunjin Chen, Thomas Pock category:cs.CV published:2015-08-12 summary:Image restoration is a long-standing problem in low-level computer visionwith many interesting applications. We describe a flexible learning frameworkto obtain simple but effective models for various image restoration problems.The proposed approach is based on the concept of nonlinear reaction diffusion,but we extend conventional nonlinear reaction diffusion models by highlyparametrized linear filters as well as highly parametrized influence functions.In contrast to previous nonlinear diffusion models, all the parameters,including the filters and the influence functions, are learned from trainingdata through a loss based approach. We call this approach TNRD -- TrainableNonlinear Reaction Diffusion. The TNRD approach is applicable for a variety ofimage restoration tasks by incorporating appropriate reaction force. Wedemonstrate its capabilities with three representative applications, Gaussianimage denoising, single image super resolution and JPEG deblocking. Experimentsshow that our trained nonlinear diffusion models largely benefit from thetraining of the parameters and finally lead to the best reported performance oncommon test datasets with respect to the tested applications. Our trainedmodels retain the structural simplicity of diffusion models and take only asmall number of steps, thus are highly efficient. Moreover, they are alsowell-suited for parallel computation on GPUs, which makes the inferenceprocedure extremely fast.
arxiv-12900-66 | Manifold regularization in structured output space for semi-supervised structured output prediction | http://arxiv.org/abs/1508.02849 | author:Fei Jiang, Lili Jia, Xiaobao Sheng, Riley LeMieux category:cs.LG cs.CV published:2015-08-12 summary:Structured output prediction aims to learn a predictor to predict astructured output from a input data vector. The structured outputs includevector, tree, sequence, etc. We usually assume that we have a training set ofinput-output pairs to train the predictor. However, in many real-world appli-cations, it is difficult to obtain the output for a input, thus for manytraining input data points, the structured outputs are missing. In this paper,we dis- cuss how to learn from a training set composed of some input-outputpairs, and some input data points without outputs. This problem is called semi-supervised structured output prediction. We propose a novel method for thisproblem by constructing a nearest neighbor graph from the input space topresent the manifold structure, and using it to regularize the structured out-put space directly. We define a slack structured output for each training datapoint, and proposed to predict it by learning a structured output predictor.The learning of both slack structured outputs and the predictor are unifiedwithin one single minimization problem. In this problem, we propose to mini-mize the structured loss between the slack structured outputs of neighboringdata points, and the prediction error measured by the structured loss. Theproblem is optimized by an iterative algorithm. Experiment results over threebenchmark data sets show its advantage.
arxiv-12900-67 | A massively parallel multi-level approach to a domain decomposition method for the optical flow estimation with varying illumination | http://arxiv.org/abs/1508.02977 | author:Diane Gilliocq-Hirtz, Zakaria Belhachmi category:cs.CV published:2015-08-12 summary:We consider a variational method to solve the optical flow problem withvarying illumination. We apply an adaptive control of the regularizationparameter which allows us to preserve the edges and fine features of thecomputed flow. To reduce the complexity of the estimation for high resolutionimages and the time of computations, we implement a multi-level parallelapproach based on the domain decomposition with the Schwarz overlapping method.The second level of parallelism uses the massively parallel solver MUMPS. Weperform some numerical simulations to show the efficiency of our approach andto validate it on classical and real-world image sequences.
arxiv-12900-68 | Towards Real-time Customer Experience Prediction for Telecommunication Operators | http://arxiv.org/abs/1508.02884 | author:Ernesto Diaz-Aviles, Fabio Pinelli, Karol Lynch, Zubair Nabi, Yiannis Gkoufas, Eric Bouillet, Francesco Calabrese, Eoin Coughlan, Peter Holland, Jason Salzwedel category:cs.CY cs.IR stat.ML published:2015-08-12 summary:Telecommunications operators (telcos) traditional sources of income, voiceand SMS, are shrinking due to customers using over-the-top (OTT) applicationssuch as WhatsApp or Viber. In this challenging environment it is critical fortelcos to maintain or grow their market share, by providing users with as goodan experience as possible on their network. But the task of extracting customer insights from the vast amounts of datacollected by telcos is growing in complexity and scale everey day. How can wemeasure and predict the quality of a user's experience on a telco network inreal-time? That is the problem that we address in this paper. We present an approach to capture, in (near) real-time, the mobile customerexperience in order to assess which conditions lead the user to place a call toa telco's customer care center. To this end, we follow a supervised learningapproach for prediction and train our 'Restricted Random Forest' model using,as a proxy for bad experience, the observed customer transactions in the telcodata feed before the user places a call to a customer care center. We evaluate our approach using a rich dataset provided by a major Africantelecommunication's company and a novel big data architecture for both thetraining and scoring of predictive models. Our empirical study shows oursolution to be effective at predicting user experience by inferring if acustomer will place a call based on his current context. These promising results open new possibilities for improved customer service,which will help telcos to reduce churn rates and improve customer experience,both factors that directly impact their revenue growth.
arxiv-12900-69 | Mountain Peak Detection in Online Social Media | http://arxiv.org/abs/1508.02959 | author:Roman Fedorov category:cs.CV cs.MM published:2015-08-12 summary:We present a system for the classification of mountain panoramas fromuser-generated photographs followed by identification and extraction ofmountain peaks from those panoramas. We have developed an automatic techniquethat, given as input a geo-tagged photograph, estimates its FOV (Field Of View)and the direction of the camera using a matching algorithm on the photographedge maps and a rendered view of the mountain silhouettes that should be seenfrom the observer's point of view. The extraction algorithm then identifies themountain peaks present in the photograph and their profiles. We discusspossible applications in social fields such as photograph peak tagging onsocial portals, augmented reality on mobile devices when viewing a mountainpanorama, and generation of collective intelligence systems (such asenvironmental models) from massive social media collections (e.g. snow wateravailability maps based on mountain peak states extracted from photographhosting services).
arxiv-12900-70 | No Regret Bound for Extreme Bandits | http://arxiv.org/abs/1508.02933 | author:Robert Nishihara, David Lopez-Paz, Léon Bottou category:stat.ML cs.LG math.OC math.ST stat.TH published:2015-08-12 summary:Algorithms for hyperparameter optimization abound, all of which work wellunder different and often unverifiable assumptions. Motivated by the generalchallenge of sequentially choosing which algorithm to use, we study the morespecific task of choosing among distributions to use for random hyperparameteroptimization. This work is naturally framed in the extreme bandit setting,which deals with sequentially choosing which distribution from a collection tosample in order to minimize (maximize) the single best cost (reward). Whereasthe distributions in the standard bandit setting are primarily characterized bytheir means, a number of subtleties arise when we care about the minimal costas opposed to the average cost. For example, there may not be a well-defined"best" distribution as there is in the standard bandit setting. The bestdistribution depends on the rewards that have been obtained and on theremaining time horizon. Whereas in the standard bandit setting, it is sensibleto compare policies with an oracle which plays the single best arm, in theextreme bandit setting, there are multiple sensible oracle models. We define asensible notion of "extreme regret" in the extreme bandit setting, whichparallels the concept of regret in the standard bandit setting. We then provethat no policy can asymptotically achieve no extreme regret.
arxiv-12900-71 | Convergence rates of sub-sampled Newton methods | http://arxiv.org/abs/1508.02810 | author:Murat A. Erdogdu, Andrea Montanari category:stat.ML published:2015-08-12 summary:We consider the problem of minimizing a sum of $n$ functions over a convexparameter set $\mathcal{C} \subset \mathbb{R}^p$ where $n\gg p\gg 1$. In thisregime, algorithms which utilize sub-sampling techniques are known to beeffective. In this paper, we use sub-sampling techniques together with low-rankapproximation to design a new randomized batch algorithm which possessescomparable convergence rate to Newton's method, yet has much smallerper-iteration cost. The proposed algorithm is robust in terms of starting pointand step size, and enjoys a composite convergence rate, namely, quadraticconvergence at start and linear convergence when the iterate is close to theminimizer. We develop its theoretical analysis which also allows us to selectnear-optimal algorithm parameters. Our theoretical results can be used toobtain convergence rates of previously proposed sub-sampling based algorithmsas well. We demonstrate how our results apply to well-known machine learningproblems. Lastly, we evaluate the performance of our algorithm on severaldatasets under various scenarios.
arxiv-12900-72 | RCR: Robust Compound Regression for Robust Estimation of Errors-in-Variables Model | http://arxiv.org/abs/1508.02925 | author:Hao Han, Wei Zhu category:stat.ME math.ST stat.ML stat.TH published:2015-08-12 summary:The errors-in-variables (EIV) regression model, being more realistic byaccounting for measurement errors in both the dependent and the independentvariables, is widely adopted in applied sciences. The traditional EIV modelestimators, however, can be highly biased by outliers and other departures fromthe underlying assumptions. In this paper, we develop a novel nonparametricregression approach - the robust compound regression (RCR) analysis method forthe robust estimation of EIV models. We first introduce a robust and efficientestimator called least sine squares (LSS). Taking full advantage of both thenew LSS method and the compound regression analysis method developed in our owngroup, we subsequently propose the RCR approach as a generalization of thosetwo, which provides a robust counterpart of the entire class of the maximumlikelihood estimation (MLE) solutions of the EIV model, in a 1-1 mapping.Technically, our approach gives users the flexibility to select from a class ofRCR estimates the optimal one with a predefined regression efficiency criterionsatisfied. Simulation studies and real-life examples are provided to illustratethe effectiveness of the RCR approach.
arxiv-12900-73 | The Effects of Hyperparameters on SGD Training of Neural Networks | http://arxiv.org/abs/1508.02788 | author:Thomas M. Breuel category:cs.NE cs.LG K.3.2 published:2015-08-12 summary:The performance of neural network classifiers is determined by a number ofhyperparameters, including learning rate, batch size, and depth. A number ofattempts have been made to explore these parameters in the literature, and attimes, to develop methods for optimizing them. However, exploration ofparameter spaces has often been limited. In this note, I report the results oflarge scale experiments exploring these different parameters and theirinteractions.
arxiv-12900-74 | What is Holding Back Convnets for Detection? | http://arxiv.org/abs/1508.02844 | author:Bojan Pepik, Rodrigo Benenson, Tobias Ritschel, Bernt Schiele category:cs.CV published:2015-08-12 summary:Convolutional neural networks have recently shown excellent results ingeneral object detection and many other tasks. Albeit very effective, theyinvolve many user-defined design choices. In this paper we want to betterunderstand these choices by inspecting two key aspects "what did the networklearn?", and "what can the network learn?". We exploit new annotations(Pascal3D+), to enable a new empirical analysis of the R-CNN detector. Despitecommon belief, our results indicate that existing state-of-the-art convnetarchitectures are not invariant to various appearance factors. In fact, allconsidered networks have similar weak points which cannot be mitigated bysimply increasing the training data (architectural changes are needed). We showthat overall performance can improve when using image renderings for dataaugmentation. We report the best known results on the Pascal3D+ detection andview-point estimation tasks.
arxiv-12900-75 | Maximum Entropy Vector Kernels for MIMO system identification | http://arxiv.org/abs/1508.02865 | author:Giulia Prando, Gianluigi Pillonetto, Alessandro Chiuso category:cs.SY stat.ML published:2015-08-12 summary:Recent contributions have framed linear system identification as anonparametric regularized inverse problem, which in some situations have provedto be advantageous w.r.t classical parametric methods. Typical formulationsexploit an $\ell_2$-type regularization which accounts for the stability andsmoothness of the impulse response to be estimated. In this paper, adoptingMaximum Entropy arguments, we derive a new type of $\ell_2$-regularizationwhich results in a vector-valued kernel; our aim is to introduce regularizationon the block Hankel matrix built with Markov coefficients, thus controlling thecomplexity of the identified model, measured by its McMillan degree. As aspecial case we recover the standard nuclear norm penalty. Combining thisHankel-based regularization with the standard $\ell_2$-type regularizationadopted in previous literature we design a kernel which, at the same time,encodes stability, smoothness and low McMillan degree. In contrast withprevious literature on reweighed nuclear norm penalties, our kernel isdescribed by a small number of hyper-prameters, which are iteratively updatedthrough marginal likelihood maximization. To this purpose we also adapt aScaled Gradient Projection (SGP) algorithm which is proved to be significantlycomputationally cheaper than other first and second order off-the-shelfoptimization methods. The effectiveness of the identification technique wepropose is confirmed by several Monte-Carlo studies.
arxiv-12900-76 | Bayesian Dropout | http://arxiv.org/abs/1508.02905 | author:Tue Herlau, Morten Mørup, Mikkel N. Schmidt category:stat.ML published:2015-08-12 summary:Dropout has recently emerged as a powerful and simple method for trainingneural networks preventing co-adaptation by stochastically omitting neurons.Dropout is currently not grounded in explicit modelling assumptions which sofar has precluded its adoption in Bayesian modelling. Using Bayesian entropicreasoning we show that dropout can be interpreted as optimal inference underconstraints. We demonstrate this on an analytically tractable regression modelproviding a Bayesian interpretation of its mechanism for regularizing andpreventing co-adaptation as well as its connection to other Bayesiantechniques. We also discuss two general approximate techniques for applyingBayesian dropout for general models, one based on an analytical approximationand the other on stochastic variational techniques. These techniques are thenapplied to a Baysian logistic regression problem and are shown to improveperformance as the model become more misspecified. Our framework roots dropoutas a theoretically justified and practical tool for statistical modellingallowing Bayesians to tap into the benefits of dropout training.
arxiv-12900-77 | De-biasing the Lasso: Optimal Sample Size for Gaussian Designs | http://arxiv.org/abs/1508.02757 | author:Adel Javanmard, Andrea Montanari category:math.ST stat.ML stat.TH published:2015-08-11 summary:Performing statistical inference in high-dimensional models is an outstandingchallenge. A major source of difficulty is the absence of precise informationon the distribution of high-dimensional regularized estimators. Here, we consider linear regression in the high-dimensional regime $p\gg n$and the Lasso estimator. In this context, we would like to perform inference ona high-dimensional parameters vector $\theta^*\in R^p$. Important progress hasbeen achieved in computing confidence intervals and p-values for singlecoordinates $\theta^*_i$, $i\in \{1,\dots,p\}$. A key role in these newinferential methods is played by a certain de-biased (or de-sparsified)estimator $\widehat{\theta}^d$ that is constructed from the Lasso estimator.Earlier work establishes that, under suitable assumptions on the design matrix,the coordinates of $\widehat{\theta}^d$ are asymptotically Gaussian providedthe true parameters vector $\theta^*$ is $s_0$-sparse with $s_0 =o(\sqrt{n}/\log p )$. The condition $s_0 = o(\sqrt{n}/ \log p )$ is considerably stronger than theone required for consistent estimation, namely $s_0 = o(n/ \log p )$. Here weconsider Gaussian designs with known or unknown population covariance. When thecovariance is known, we prove that the de-biased estimator is asymptoticallyGaussian under the nearly optimal condition $s_0 = o(n/ (\log p)^2)$. Note that\emph{earlier work was limited to $s_0 = o(\sqrt{n}/ \log p)$ even forperfectly known covariance.} The same conclusion holds if the population covariance is unknown but can beestimated sufficiently well, e.g. because its inverse is very sparse. Forintermediate regimes, we describe the trade-off between sparsity in thecoefficients $\theta^*$, and sparsity in the inverse covariance of the design.
arxiv-12900-78 | Type-Constrained Representation Learning in Knowledge Graphs | http://arxiv.org/abs/1508.02593 | author:Denis Krompaß, Stephan Baier, Volker Tresp category:cs.AI cs.LG published:2015-08-11 summary:Large knowledge graphs increasingly add value to various applications thatrequire machines to recognize and understand queries and their semantics, as insearch or question answering systems. Latent variable models have increasinglygained attention for the statistical modeling of knowledge graphs, showingpromising results in tasks related to knowledge graph completion and cleaning.Besides storing facts about the world, schema-based knowledge graphs are backedby rich semantic descriptions of entities and relation-types that allowmachines to understand the notion of things and their semantic relationships.In this work, we study how type-constraints can generally support thestatistical modeling with latent variable models. More precisely, we integratedprior knowledge in form of type-constraints in various state of the art latentvariable approaches. Our experimental results show that prior knowledge onrelation-types significantly improves these models up to 77% in link-predictiontasks. The achieved improvements are especially prominent when a low modelcomplexity is enforced, a crucial requirement when these models are applied tovery large datasets. Unfortunately, type-constraints are neither alwaysavailable nor always complete e.g., they can become fuzzy when entities lackproper typing. We show that in these cases, it can be beneficial to apply alocal closed-world assumption that approximates the semantics of relation-typesbased on observations made in the data.
arxiv-12900-79 | A Practical Guide to CNNs and Fisher Vectors for Image Instance Retrieval | http://arxiv.org/abs/1508.02496 | author:Vijay Chandrasekhar, Jie Lin, Olivier Morère, Hanlin Goh, Antoine Veillard category:cs.CV cs.IR published:2015-08-11 summary:With deep learning becoming the dominant approach in computer vision, the useof representations extracted from Convolutional Neural Nets (CNNs) is quicklygaining ground on Fisher Vectors (FVs) as favoured state-of-the-art globalimage descriptors for image instance retrieval. While the good performance ofCNNs for image classification are unambiguously recognised, which of the twohas the upper hand in the image retrieval context is not entirely clear yet. Inthis work, we propose a comprehensive study that systematically evaluates FVsand CNNs for image retrieval. The first part compares the performances of FVsand CNNs on multiple publicly available data sets. We investigate a number ofdetails specific to each method. For FVs, we compare sparse descriptors basedon interest point detectors with dense single-scale and multi-scale variants.For CNNs, we focus on understanding the impact of depth, architecture andtraining data on retrieval results. Our study shows that no descriptor issystematically better than the other and that performance gains can usually beobtained by using both types together. The second part of the study focuses onthe impact of geometrical transformations such as rotations and scale changes.FVs based on interest point detectors are intrinsically resilient to suchtransformations while CNNs do not have a built-in mechanism to ensure suchinvariance. We show that performance of CNNs can quickly degrade in presence ofrotations while they are far less affected by changes in scale. We then proposea number of ways to incorporate the required invariances in the CNN pipeline.Overall, our work is intended as a reference guide offering practically usefuland simply implementable guidelines to anyone looking for state-of-the-artglobal descriptors best suited to their specific image instance retrievalproblem.
arxiv-12900-80 | Order Selection of Autoregressive Processes using Bridge Criterion | http://arxiv.org/abs/1508.02473 | author:Jie Ding, Mohammad Noshad, Vahid Tarokh category:math.ST q-fin.EC stat.ML stat.TH published:2015-08-11 summary:A new criterion is introduced for determining the order of an autoregressivemodel fit to time series data. The proposed technique is shown to give aconsistent and asymptotically efficient order estimation. It has the benefitsof the two well-known model selection techniques, the Akaike informationcriterion and the Bayesian information criterion. When the true order of theautoregression is relatively large compared with the sample size, the Akaikeinformation criterion is known to be efficient, and the new criterion behavesin a similar manner. When the true order is finite and small compared with thesample size, the Bayesian information criterion is known to be consistent, andso is the new criterion. Thus the new criterion builds a bridge between the twoclassical criteria automatically. In practice, where the observed time seriesis given without any prior information about the autoregression, the proposedorder selection criterion is more flexible and robust compared with classicalapproaches. Numerical results are presented demonstrating the robustness of theproposed technique when applied to various datasets.
arxiv-12900-81 | Topology Control of wireless sensor network using Quantum Inspired Genetic algorithm | http://arxiv.org/abs/1508.02521 | author:Sajid Ullah, Mussarat Wahid category:cs.NE cs.NI published:2015-08-11 summary:In this work, an evolving Linked Quantum register has been introduced, whichare group vector of binary pair of genes, which in its local proximityrepresent those nodes that will have high connectivity and keep the energyconsumption at low, and which are taken into account for topology control. Theregister works in higher dimension. Here order-2 Quantum inspired geneticalgorithm has been used and also higher order can be used to achieve greaterversatility in topology control of nodes. Numerical result has been obtained,analysis is done as how the result has previously been obtained with Quantumgenetic algorithm and results are compared too. For future work, factor ishinted which would exploit the algorithm to work in more computationalintensive problem.
arxiv-12900-82 | Benchmarking of LSTM Networks | http://arxiv.org/abs/1508.02774 | author:Thomas M. Breuel category:cs.NE K.3.2 published:2015-08-11 summary:LSTM (Long Short-Term Memory) recurrent neural networks have been highlysuccessful in a number of application areas. This technical report describesthe use of the MNIST and UW3 databases for benchmarking LSTM networks andexplores the effect of di?erent architectural and hyperparameter choices onperformance. Significant ?ndings include: (1) LSTM performance depends smoothlyon learning rates, (2) batching and momentum has no significant effect onperformance, (3) softmax training outperforms least square training, (4)peephole units are not useful, (5) the standard non-linearities (tanh andsigmoid) perform best, (6) bidirectional training combined with CTC performsbetter than other methods.
arxiv-12900-83 | Normalized Hierarchical SVM | http://arxiv.org/abs/1508.02479 | author:Heejin Choi, Yutaka Sasaki, Nathan Srebro category:cs.LG published:2015-08-11 summary:We present improved methods of using structured SVMs in a large-scalehierarchical classification problem, that is when labels are leaves, or sets ofleaves, in a tree or a DAG. We examine the need to normalize both theregularization and the margin and show how doing so significantly improvesperformance, including allowing achieving state-of-the-art results whereunnormalized structured SVMs do not perform better than flat models. We alsodescribe a further extension of hierarchical SVMs that highlight the connectionbetween hierarchical SVMs and matrix factorization models.
arxiv-12900-84 | Simulating Brain Reaction to Methamphetamine Regarding Consumer Personality | http://arxiv.org/abs/1508.02505 | author:Maryam Keyvanara, Seyed Amirhassan Monadjemi category:cs.NE q-bio.NC published:2015-08-11 summary:Addiction, as a nervous disease, can be analysed using mathematical modellingand computer simulations. In this paper, we use an existing mathematical modelto predict and simulate human brain response to the consumption of a singledose of methamphetamine. The model is implemented and coded in Matlab. Threetypes of personalities including introverts, ambiverts and extroverts arestudied. The parameters of the mathematical model are calibrated and optimized,according to psychological theories, using a real coded genetic algorithm. Thesimulations show significant correlation between people response tomethamphetamine abuse and their personality. They also show that one of thecauses of tendency to stimulants roots in consumers personality traits. Theresults can be used as a tool for reducing attitude towards addiction.
arxiv-12900-85 | Artificial Prediction Markets for Online Prediction of Continuous Variables-A Preliminary Report | http://arxiv.org/abs/1508.02681 | author:Fatemeh Jahedpari, Marina De Vos, Sattar Hashemi, Benjamin Hirsch, Julian Padget category:cs.AI cs.LG published:2015-08-11 summary:We propose the Artificial Continuous Prediction Market (ACPM) as a means topredict a continuous real value, by integrating a range of data sources andaggregating the results of different machine learning (ML) algorithms. ACPMadapts the concept of the (physical) prediction market to address theprediction of real values instead of discrete events. Each ACPM participant hasa data source, a ML algorithm and a local decision-making procedure thatdetermines what to bid on what value. The contributions of ACPM are: (i)adaptation to changes in data quality by the use of learning in: (a) themarket, which weights each market participant to adjust the influence of eachon the market prediction and (b) the participants, which use a Q-learning basedtrading strategy to incorporate the market prediction into their subsequentpredictions, (ii) resilience to a changing population of low- andhigh-performing participants. We demonstrate the effectiveness of ACPM byapplication to an influenza-like illnesses data set, showing ACPM out-performsa range of well-known regression models and is resilient to variation in datasource quality.
arxiv-12900-86 | Are Slepian-Wolf Rates Necessary for Distributed Parameter Estimation? | http://arxiv.org/abs/1508.02765 | author:Mostafa El Gamal, Lifeng Lai category:cs.IT math.IT stat.ML published:2015-08-11 summary:We consider a distributed parameter estimation problem, in which multipleterminals send messages related to their local observations using limited ratesto a fusion center who will obtain an estimate of a parameter related toobservations of all terminals. It is well known that if the transmission ratesare in the Slepian-Wolf region, the fusion center can fully recover allobservations and hence can construct an estimator having the same performanceas that of the centralized case. One natural question is whether Slepian-Wolfrates are necessary to achieve the same estimation performance as that of thecentralized case. In this paper, we show that the answer to this question isnegative. We establish our result by explicitly constructing an asymptoticallyminimum variance unbiased estimator (MVUE) that has the same performance asthat of the optimal estimator in the centralized case while requiringinformation rates less than the conditions required in the Slepian-Wolf rateregion.
arxiv-12900-87 | InAR:Inverse Augmented Reality | http://arxiv.org/abs/1508.02606 | author:Hao Hu, Hainan Cui category:cs.CV published:2015-08-11 summary:Augmented reality is the art to seamlessly fuse virtual objects into realones. In this short note, we address the opposite problem, the inverseaugmented reality, that is, given a perfectly augmented reality scene wherehuman is unable to distinguish real objects from virtual ones, how the machinecould help do the job. We show by structure from motion (SFM), a simple 3Dreconstruction technique from images in computer vision, the real and virtualobjects can be easily separated in the reconstructed 3D scene.
arxiv-12900-88 | Local Algorithms for Block Models with Side Information | http://arxiv.org/abs/1508.02344 | author:Elchanan Mossel, Jiaming Xu category:stat.ML cs.CC cs.DC math.PR published:2015-08-10 summary:There has been a recent interest in understanding the power of localalgorithms for optimization and inference problems on sparse graphs. Gamarnikand Sudan (2014) showed that local algorithms are weaker than global algorithmsfor finding large independent sets in sparse random regular graphs. Montanari(2015) showed that local algorithms are suboptimal for finding a community withhigh connectivity in the sparse Erd\H{o}s-R\'enyi random graphs. For thesymmetric planted partition problem (also named community detection for theblock models) on sparse graphs, a simple observation is that local algorithmscannot have non-trivial performance. In this work we consider the effect of side information on local algorithmsfor community detection under the binary symmetric stochastic block model. Inthe block model with side information each of the $n$ vertices is labeled $+$or $-$ independently and uniformly at random; each pair of vertices isconnected independently with probability $a/n$ if both of them have the samelabel or $b/n$ otherwise. The goal is to estimate the underlying vertexlabeling given 1) the graph structure and 2) side information in the form of avertex labeling positively correlated with the true one. Assuming that theratio between in and out degree $a/b$ is $\Theta(1)$ and the average degree $(a+b) / 2 = n^{o(1)}$, we characterize three different regimes under which alocal algorithm, namely, belief propagation run on the local neighborhoods,maximizes the expected fraction of vertices labeled correctly. Thus, incontrast to the case of symmetric block models without side information, weshow that local algorithms can achieve optimal performance for the block modelwith side information.
arxiv-12900-89 | Measuring Word Significance using Distributed Representations of Words | http://arxiv.org/abs/1508.02297 | author:Adriaan M. J. Schakel, Benjamin J. Wilson category:cs.CL published:2015-08-10 summary:Distributed representations of words as real-valued vectors in a relativelylow-dimensional space aim at extracting syntactic and semantic features fromlarge text corpora. A recently introduced neural network, named word2vec(Mikolov et al., 2013a; Mikolov et al., 2013b), was shown to encode semanticinformation in the direction of the word vectors. In this brief report, it isproposed to use the length of the vectors, together with the term frequency, asmeasure of word significance in a corpus. Experimental evidence using adomain-specific corpus of abstracts is presented to support this proposal. Auseful visualization technique for text corpora emerges, where words are mappedonto a two-dimensional plane and automatically ranked by significance.
arxiv-12900-90 | Removing Biases from Trainable MT Metrics by Using Self-Training | http://arxiv.org/abs/1508.02445 | author:Miloš Stanojević category:cs.CL published:2015-08-10 summary:Most trainable machine translation (MT) metrics train their weights on humanjudgments of state-of-the-art MT systems outputs. This makes trainable metricsbiases in many ways. One of them is preferring longer translations. Thesebiased metrics when used for tuning are evaluating different types oftranslations -- n-best lists of translations with very diverse quality. Systemstuned with these metrics tend to produce overly long translations that arepreferred by the metric but not by humans. This is usually solved by manuallytweaking metric's weights to equally value recall and precision. Our solutionis more general: (1) it does not address only the recall bias but also allother biases that might be present in the data and (2) it does not require anyknowledge of the types of features used which is useful in cases when manualtuning of metric's weights is not possible. This is accomplished byself-training on unlabeled n-best lists by using metric that was initiallytrained on standard human judgments. One way of looking at this is as domainadaptation from the domain of state-of-the-art MT translations to diversen-best list translations.
arxiv-12900-91 | Adapting Phrase-based Machine Translation to Normalise Medical Terms in Social Media Messages | http://arxiv.org/abs/1508.02285 | author:Nut Limsopatham, Nigel Collier category:cs.CL published:2015-08-10 summary:Previous studies have shown that health reports in social media, such asDailyStrength and Twitter, have potential for monitoring health conditions(e.g. adverse drug reactions, infectious diseases) in particular communities.However, in order for a machine to understand and make inferences on thesehealth conditions, the ability to recognise when laymen's terms refer to aparticular medical concept (i.e.\ text normalisation) is required. To achievethis, we propose to adapt an existing phrase-based machine translation (MT)technique and a vector representation of words to map between a social mediaphrase and a medical concept. We evaluate our proposed approach using acollection of phrases from tweets related to adverse drug reactions. Ourexperimental results show that the combination of a phrase-based MT techniqueand the similarity between word vector representations outperforms thebaselines that apply only either of them by up to 55%.
arxiv-12900-92 | Dropout Training for SVMs with Data Augmentation | http://arxiv.org/abs/1508.02268 | author:Ning Chen, Jun Zhu, Jianfei Chen, Ting Chen category:cs.LG published:2015-08-10 summary:Dropout and other feature noising schemes have shown promising results incontrolling over-fitting by artificially corrupting the training data. Thoughextensive theoretical and empirical studies have been performed for generalizedlinear models, little work has been done for support vector machines (SVMs),one of the most successful approaches for supervised learning. This paperpresents dropout training for both linear SVMs and the nonlinear extension withlatent representation learning. For linear SVMs, to deal with the intractableexpectation of the non-smooth hinge loss under corrupting distributions, wedevelop an iteratively re-weighted least square (IRLS) algorithm by exploringdata augmentation techniques. Our algorithm iteratively minimizes theexpectation of a re-weighted least square problem, where the re-weights areanalytically updated. For nonlinear latent SVMs, we consider learning one layerof latent representations in SVMs and extend the data augmentation technique inconjunction with first-order Taylor-expansion to deal with the intractableexpected non-smooth hinge loss and the nonlinearity of latent representations.Finally, we apply the similar data augmentation ideas to develop a new IRLSalgorithm for the expected logistic loss under corrupting distributions, and wefurther develop a non-linear extension of logistic regression by incorporatingone layer of latent representations. Our algorithms offer insights on theconnection and difference between the hinge loss and logistic loss in dropouttraining. Empirical results on several real datasets demonstrate theeffectiveness of dropout training on significantly boosting the classificationaccuracy of both linear and nonlinear SVMs. In addition, the nonlinear SVMsfurther improve the prediction performance on several image datasets.
arxiv-12900-93 | Adaptive Sampling of RF Fingerprints for Fine-grained Indoor Localization | http://arxiv.org/abs/1508.02324 | author:Xiao-Yang Liu, Shuchin Aeron, Vaneet Aggarwal, Xiaodong Wang, Min-You Wu category:cs.IT math.IT math.OC stat.ML published:2015-08-10 summary:Indoor localization is a supporting technology for a broadening range ofpervasive wireless applications. One promis- ing approach is to locate userswith radio frequency fingerprints. However, its wide adoption in real-worldsystems is challenged by the time- and manpower-consuming site survey process,which builds a fingerprint database a priori for localization. To address thisproblem, we visualize the 3-D RF fingerprint data as a function of locations(x-y) and indices of access points (fingerprint), as a tensor and use tensoralgebraic methods for an adaptive tubal-sampling of this fingerprint space. Inparticular using a recently proposed tensor algebraic framework in [1] wecapture the complexity of the fingerprint space as a low-dimensionaltensor-column space. In this formulation the proposed scheme exploitsadaptivity to identify reference points which are highly informative forlearning this low-dimensional space. Further, under certain incoherencyconditions we prove that the proposed scheme achieves bounded recovery errorand near-optimal sampling complexity. In contrast to several existing work thatrely on random sampling, this paper shows that adaptivity in sampling can leadto significant improvements in localization accuracy. The approach is validatedon both data generated by the ray-tracing indoor model which accounts for thefloor plan and the impact of walls and the real world data. Simulation resultsshow that, while maintaining the same localization accuracy of existingapproaches, the amount of samples can be cut down by 71% for the high SNR caseand 55% for the low SNR case.
arxiv-12900-94 | Feature Learning for Interaction Activity Recognition in RGBD Videos | http://arxiv.org/abs/1508.02246 | author:Ngu Nguyen category:cs.CV published:2015-08-10 summary:This paper proposes a human activity recognition method which is based onfeatures learned from 3D video data without incorporating domain knowledge. Theexperiments on data collected by RGBD cameras produce results outperformingother techniques. Our feature encoding method follows the bag-of-visual-wordmodel, then we use a SVM classifier to recognise the activities. We do not useskeleton or tracking information and the same technique is applied on color anddepth data.
arxiv-12900-95 | Towards Machine Wald | http://arxiv.org/abs/1508.02449 | author:Houman Owhadi, Clint Scovel category:math.ST cs.LG stat.TH 62C99, 68Q32 published:2015-08-10 summary:The past century has seen a steady increase in the need of estimating andpredicting complex systems and making (possibly critical) decisions withlimited information. Although computers have made possible the numericalevaluation of sophisticated statistical models, these models are still designed\emph{by humans} because there is currently no known recipe or algorithm fordividing the design of a statistical model into a sequence of arithmeticoperations. Indeed enabling computers to \emph{think} as \emph{humans} have theability to do when faced with uncertainty is challenging in several major ways:(1) Finding optimal statistical models remains to be formulated as a well posedproblem when information on the system of interest is incomplete and comes inthe form of a complex combination of sample data, partial knowledge ofconstitutive relations and a limited description of the distribution of inputrandom variables. (2) The space of admissible scenarios along with the space ofrelevant information, assumptions, and/or beliefs, tend to be infinitedimensional, whereas calculus on a computer is necessarily discrete and finite.With this purpose, this paper explores the foundations of a rigorous frameworkfor the scientific computation of optimal statistical estimators/models andreviews their connections with Decision Theory, Machine Learning, BayesianInference, Stochastic Optimization, Robust Optimization, Optimal UncertaintyQuantification and Information Based Complexity.
arxiv-12900-96 | Training Conditional Random Fields with Natural Gradient Descent | http://arxiv.org/abs/1508.02373 | author:Yuan Cao category:cs.LG published:2015-08-10 summary:We propose a novel parameter estimation procedure that works efficiently forconditional random fields (CRF). This algorithm is an extension to the maximumlikelihood estimation (MLE), using loss functions defined by Bregmandivergences which measure the proximity between the model expectation and theempirical mean of the feature vectors. This leads to a flexible trainingframework from which multiple update strategies can be derived using naturalgradient descent (NGD). We carefully choose the convex function inducing theBregman divergence so that the types of updates are reduced, while making theoptimization procedure more effective by transforming the gradients of thelog-likelihood loss function. The derived algorithms are very simple and can beeasily implemented on top of the existing stochastic gradient descent (SGD)optimization procedure, yet it is very effective as illustrated by experimentalresults.
arxiv-12900-97 | Improve the Evaluation of Translation Fluency by Using Entropy of Matched Sub-segments | http://arxiv.org/abs/1508.02225 | author:Hui Yu, Xiaofeng Wu, Wenbin Jiang, Qun Liu, Shouxun Lin category:cs.CL published:2015-08-10 summary:The widely-used automatic evaluation metrics cannot adequately reflect thefluency of the translations. The n-gram-based metrics, like BLEU, limit themaximum length of matched fragments to n and cannot catch the matched fragmentslonger than n, so they can only reflect the fluency indirectly. METEOR, whichis not limited by n-gram, uses the number of matched chunks but it does notconsider the length of each chunk. In this paper, we propose an entropy-basedmethod, which can sufficiently reflect the fluency of translations through thedistribution of matched words. This method can easily combine with thewidely-used automatic evaluation metrics to improve the evaluation of fluency.Experiments show that the correlations of BLEU and METEOR are improved onsentence level after combining with the entropy-based method on WMT 2010 andWMT 2012.
arxiv-12900-98 | Model-based SIR for dimension reduction | http://arxiv.org/abs/1508.02186 | author:Luca Scrucca category:stat.ME stat.ML published:2015-08-10 summary:A new dimension reduction method based on Gaussian finite mixtures isproposed as an extension to sliced inverse regression (SIR). The model-basedSIR (MSIR) approach allows the main limitation of SIR to be overcome, i.e.,failure in the presence of regression symmetric relationships, without the needto impose further assumptions. Extensive numerical studies are presented tocompare the new method with some of most popular dimension reduction methods,such as SIR, sliced average variance estimation, principal Hessian direction,and directional regression. MSIR appears sufficiently flexible to accommodatevarious regression functions, and its performance is comparable with or better,particularly as sample size grows, than other available methods. Lastly, MSIRis illustrated with two real data examples about ozone concentrationregression, and hand-written digit classification.
arxiv-12900-99 | Automatic Extraction of the Passing Strategies of Soccer Teams | http://arxiv.org/abs/1508.02171 | author:Laszlo Gyarmati, Xavier Anguera category:cs.CV stat.ML published:2015-08-10 summary:Technology offers new ways to measure the locations of the players and of theball in sports. This translates to the trajectories the ball takes on the fieldas a result of the tactics the team applies. The challenge professionals insoccer are facing is to take the reverse path: given the trajectories of theball is it possible to infer the underlying strategy/tactic of a team? Wepropose a method based on Dynamic Time Warping to reveal the tactics of a teamthrough the analysis of repeating series of events. Based on the analysis of anentire season, we derive insights such as passing strategies for maintainingball possession or counter attacks, and passing styles with a focus on the teamor on the capabilities of the individual players.
arxiv-12900-100 | Feature-based Decipherment for Large Vocabulary Machine Translation | http://arxiv.org/abs/1508.02142 | author:Iftekhar Naim, Daniel Gildea category:cs.CL published:2015-08-10 summary:Orthographic similarities across languages provide a strong signal forprobabilistic decipherment, especially for closely related language pairs. Theexisting decipherment models, however, are not well-suited for exploiting theseorthographic similarities. We propose a log-linear model with latent variablesthat incorporates orthographic similarity features. Maximum likelihood trainingis computationally expensive for the proposed log-linear model. To address thischallenge, we perform approximate inference via MCMC sampling and contrastivedivergence. Our results show that the proposed log-linear model withcontrastive divergence scales to large vocabularies and outperforms theexisting generative decipherment models by exploiting the orthographicfeatures.
arxiv-12900-101 | Learning Structural Kernels for Natural Language Processing | http://arxiv.org/abs/1508.02131 | author:Daniel Beck, Trevor Cohn, Christian Hardmeier, Lucia Specia category:cs.CL cs.LG published:2015-08-10 summary:Structural kernels are a flexible learning paradigm that has been widely usedin Natural Language Processing. However, the problem of model selection inkernel-based methods is usually overlooked. Previous approaches mostly rely onsetting default values for kernel hyperparameters or using grid search, whichis slow and coarse-grained. In contrast, Bayesian methods allow efficient modelselection by maximizing the evidence on the training data throughgradient-based methods. In this paper we show how to perform this in thecontext of structural kernels by using Gaussian Processes. Experimental resultson tree kernels show that this procedure results in better predictionperformance compared to hyperparameter optimization via grid search. Theframework proposed in this paper can be adapted to other structures besidestrees, e.g., strings and graphs, thereby extending the utility of kernel-basedmethods.
arxiv-12900-102 | Approximation-Aware Dependency Parsing by Belief Propagation | http://arxiv.org/abs/1508.02375 | author:Matthew R. Gormley, Mark Dredze, Jason Eisner category:cs.CL cs.LG published:2015-08-10 summary:We show how to train the fast dependency parser of Smith and Eisner (2008)for improved accuracy. This parser can consider higher-order interactions amongedges while retaining O(n^3) runtime. It outputs the parse with maximumexpected recall -- but for speed, this expectation is taken under a posteriordistribution that is constructed only approximately, using loopy beliefpropagation through structured factors. We show how to adjust the modelparameters to compensate for the errors introduced by this approximation, byfollowing the gradient of the actual loss on training data. We find thisgradient by back-propagation. That is, we treat the entire parser(approximations and all) as a differentiable circuit, as Stoyanov et al. (2011)and Domke (2010) did for loopy CRFs. The resulting trained parser obtainshigher accuracy with fewer iterations of belief propagation than one trained byconditional log-likelihood.
arxiv-12900-103 | FactorBase: SQL for Learning A Multi-Relational Graphical Model | http://arxiv.org/abs/1508.02428 | author:Oliver Schulte, Zhensong Qian category:cs.DB cs.LG H.2.8; H.2.4 published:2015-08-10 summary:We describe FactorBase, a new SQL-based framework that leverages a relationaldatabase management system to support multi-relational model discovery. Amulti-relational statistical model provides an integrated analysis of theheterogeneous and interdependent data resources in the database. We adopt theBayesStore design philosophy: statistical models are stored and managed asfirst-class citizens inside a database. Whereas previous systems likeBayesStore support multi-relational inference, FactorBase supportsmulti-relational learning. A case study on six benchmark databases evaluateshow our system supports a challenging machine learning application, namelylearning a first-order Bayesian network model for an entire database. Modellearning in this setting has to examine a large number of potential statisticalassociations across data tables. Our implementation shows how the SQLconstructs in FactorBase facilitate the fast, modular, and reliable developmentof highly scalable model learning systems.
arxiv-12900-104 | Syntax-Aware Multi-Sense Word Embeddings for Deep Compositional Models of Meaning | http://arxiv.org/abs/1508.02354 | author:Jianpeng Cheng, Dimitri Kartsaklis category:cs.CL cs.AI cs.NE published:2015-08-10 summary:Deep compositional models of meaning acting on distributional representationsof words in order to produce vectors of larger text constituents are evolvingto a popular area of NLP research. We detail a compositional distributionalframework based on a rich form of word embeddings that aims at facilitating theinteractions between words in the context of a sentence. Embeddings andcomposition layers are jointly learned against a generic objective thatenhances the vectors with syntactic information from the surrounding context.Furthermore, each word is associated with a number of senses, the mostplausible of which is selected dynamically during the composition process. Weevaluate the produced vectors qualitatively and quantitatively with positiveresults. At the sentence level, the effectiveness of the framework isdemonstrated on the MSRPar task, for which we report results within thestate-of-the-art range.
arxiv-12900-105 | Primal-Dual Active-Set Methods for Isotonic Regression and Trend Filtering | http://arxiv.org/abs/1508.02452 | author:Zheng Han, Frank E. Curtis category:math.OC cs.LG published:2015-08-10 summary:Isotonic regression (IR) is a non-parametric calibration method used insupervised learning. For performing large-scale IR, we propose a primal-dualactive-set (PDAS) algorithm which, in contrast to the state-of-the-art PoolAdjacent Violators (PAV) algorithm, can be parallized and is easilywarm-started thus well-suited in the online settings. We prove that, like thePAV algorithm, our PDAS algorithm for IR is convergent and has a workcomplexity of O(n), though our numerical experiments suggest that our PDASalgorithm is often faster than PAV. In addition, we propose PDAS variants (withsafeguarding to ensure convergence) for solving related trend filtering (TF)problems, providing the results of experiments to illustrate theireffectiveness.
arxiv-12900-106 | Gait Assessment for Multiple Sclerosis Patients Using Microsoft Kinect | http://arxiv.org/abs/1508.02405 | author:Farnood Gholami, Daria A. Trojan, Jozsef Kovecses, Wassim M. Haddad, Behnood Gholami category:cs.CV published:2015-08-10 summary:Gait analysis of patients with neurological disorders, including multiplesclerosis (MS), is important for rehabilitation and treatment. The MircrosoftKinect sensor, which was developed for motion recognition in gamingapplications, is an ideal candidate for an inexpensive system providing thecapability for human gait analysis. In this research, we develop a framework toquantify the gait abnormality of MS patients using a Kinect for Windows camera.In addition to the previously introduced gait indices, a novel set of MS gaitindices based on the concept of dynamic time warping is introduced. The newlyintroduced indices can characterize a patient's gait pattern as a whole andquantify a subject's gait distance from the healthy population. We willinvestigate the correlation of gait indices with the multiple sclerosis walkingscale (MSWS) and the clinical ambulation score. This work establishes thefeasibility of using the Kinect sensor for clinical gait assessment for MSpatients.
arxiv-12900-107 | Lifted Representation of Relational Causal Models Revisited: Implications for Reasoning and Structure Learning | http://arxiv.org/abs/1508.02103 | author:Sanghack Lee, Vasant Honavar category:cs.AI cs.LG published:2015-08-10 summary:Maier et al. (2010) introduced the relational causal model (RCM) forrepresenting and inferring causal relationships in relational data. A liftedrepresentation, called abstract ground graph (AGG), plays a central role inreasoning with and learning of RCM. The correctness of the algorithm proposedby Maier et al. (2013a) for learning RCM from data relies on the soundness andcompleteness of AGG for relational d-separation to reduce the learning of anRCM to learning of an AGG. We revisit the definition of AGG and show that AGG,as defined in Maier et al. (2013b), does not correctly abstract all groundgraphs. We revise the definition of AGG to ensure that it correctly abstractsall ground graphs. We further show that AGG representation is not complete forrelational d-separation, that is, there can exist conditional independencerelations in an RCM that are not entailed by AGG. A careful examination of therelationship between the lack of completeness of AGG for relationald-separation and faithfulness conditions suggests that weaker notions ofcompleteness, namely adjacency faithfulness and orientation faithfulnessbetween an RCM and its AGG, can be used to learn an RCM from data.
arxiv-12900-108 | Digging Deep into the layers of CNNs: In Search of How CNNs Achieve View Invariance | http://arxiv.org/abs/1508.01983 | author:Amr Bakry, Mohamed Elhoseiny, Tarek El-Gaaly, Ahmed Elgammal category:cs.CV published:2015-08-09 summary:This paper is focused on studying the view-manifold structure in the featurespaces implied by the different layers of Convolutional Neural Networks (CNN).There are several questions that this paper aims to answer: Does the learnedCNN representation achieve viewpoint invariance? How does it achieve viewpointinvariance? Is it achieved by collapsing the view manifolds, or separating themwhile preserving them? At which layer is view invariance achieved? How can thestructure of the view manifold at each layer of a deep convolutional neuralnetwork be quantified experimentally? How does fine-tuning of a pre-trained CNNon a multi-view dataset affect the representation at each layer of the network?In order to answer these questions we propose a methodology to quantify thedeformation and degeneracy of view manifolds in CNN layers. We apply thismethodology and report interesting results in this paper that answer theaforementioned questions.
arxiv-12900-109 | A Linearly-Convergent Stochastic L-BFGS Algorithm | http://arxiv.org/abs/1508.02087 | author:Philipp Moritz, Robert Nishihara, Michael I. Jordan category:math.OC cs.LG math.NA stat.CO stat.ML published:2015-08-09 summary:We propose a new stochastic L-BFGS algorithm and prove a linear convergencerate for strongly convex and smooth functions. Our algorithm draws heavily froma recent stochastic variant of L-BFGS proposed in Byrd et al. (2014) as well asa recent approach to variance reduction for stochastic gradient descent fromJohnson and Zhang (2013). We demonstrate experimentally that our algorithmperforms well on large-scale convex and non-convex optimization problems,exhibiting linear convergence and rapidly solving the optimization problems tohigh levels of precision. Furthermore, we show that our algorithm performs wellfor a wide-range of step sizes, often differing by several orders of magnitude.
arxiv-12900-110 | Bidirectional LSTM-CRF Models for Sequence Tagging | http://arxiv.org/abs/1508.01991 | author:Zhiheng Huang, Wei Xu, Kai Yu category:cs.CL published:2015-08-09 summary:In this paper, we propose a variety of Long Short-Term Memory (LSTM) basedmodels for sequence tagging. These models include LSTM networks, bidirectionalLSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer(LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work isthe first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model toNLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF modelcan efficiently use both past and future input features thanks to abidirectional LSTM component. It can also use sentence level tag informationthanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (orclose to) accuracy on POS, chunking and NER data sets. In addition, it isrobust and has less dependence on word embedding as compared to previousobservations.
arxiv-12900-111 | Improving Decision Analytics with Deep Learning: The Case of Financial Disclosures | http://arxiv.org/abs/1508.01993 | author:Ralph Fehrer, Stefan Feuerriegel category:stat.ML cs.CL cs.LG published:2015-08-09 summary:Decision analytics commonly focuses on the text mining of financial newssources in order to provide managerial decision support and to predict stockmarket movements. Existing predictive frameworks almost exclusively applytraditional machine learning methods, whereas recent research indicates thattraditional machine learning methods are not sufficiently capable of extractingsuitable features and capturing the non-linear nature of complex tasks. As aremedy, novel deep learning models aim to overcome this issue by extendingtraditional neural network models with additional hidden layers. Indeed, deeplearning has been shown to outperform traditional methods in terms ofpredictive performance. In this paper, we adapt the novel deep learningtechnique to financial decision support. In this instance, we aim to predictthe direction of stock movements following financial disclosures. As a result,we show how deep learning can outperform the accuracy of random forests as abenchmark for machine learning by 5.66%.
arxiv-12900-112 | An Automatic Machine Translation Evaluation Metric Based on Dependency Parsing Model | http://arxiv.org/abs/1508.01996 | author:Hui Yu, Xiaofeng Wu, Wenbin Jiang, Qun Liu, ShouXun Lin category:cs.CL published:2015-08-09 summary:Most of the syntax-based metrics obtain the similarity by comparing thesub-structures extracted from the trees of hypothesis and reference. Thesesub-structures are defined by human and can't express all the information inthe trees because of the limited length of sub-structures. In addition, theoverlapped parts between these sub-structures are computed repeatedly. To avoidthese problems, we propose a novel automatic evaluation metric based ondependency parsing model, with no need to define sub-structures by human.First, we train a dependency parsing model by the reference dependency tree.Then we generate the hypothesis dependency tree and the correspondingprobability by the dependency parsing model. The quality of the hypothesis canbe judged by this probability. In order to obtain the lexicon similarity, wealso introduce the unigram F-score to the new metric. Experiment results showthat the new metric gets the state-of-the-art performance on system level, andis comparable with METEOR on sentence level.
arxiv-12900-113 | Image Representations and New Domains in Neural Image Captioning | http://arxiv.org/abs/1508.02091 | author:Jack Hessel, Nicolas Savva, Michael J. Wilber category:cs.CL cs.CV published:2015-08-09 summary:We examine the possibility that recent promising results in automatic captiongeneration are due primarily to language models. By varying imagerepresentation quality produced by a convolutional neural network, we find thata state-of-the-art neural captioning algorithm is able to produce qualitycaptions even when provided with surprisingly poor image representations. Wereplicate this result in a new, fine-grained, transfer learned captioningdomain, consisting of 66K recipe image/title pairs. We also provide someexperiments regarding the appropriateness of datasets for automatic captioning,and find that having multiple captions per image is beneficial, but not anabsolute requirement.
arxiv-12900-114 | Sensitivity study using machine learning algorithms on simulated r-mode gravitational wave signals from newborn neutron stars | http://arxiv.org/abs/1508.02064 | author:Antonis Mytidis, Athanasios A. Panagopoulos, Orestis P. Panagopoulos, Bernard Whiting category:astro-ph.IM cs.LG published:2015-08-09 summary:This is a follow-up sensitivity study on r-mode gravitational wave signalsfrom newborn neutron stars illustrating the applicability of machine learningalgorithms for the detection of long-lived gravitational-wave transients. Inthis sensitivity study we examine three machine learning algorithms (MLAs):artificial neural networks (ANNs), support vector machines (SVMs) andconstrained subspace classifiers (CSCs). The objective of this study is tocompare the detection efficiency that MLAs can achieve with the efficiency ofconventional detection algorithms discussed in an earlier paper. Comparisonsare made using 2 distinct r-mode waveforms. For the training of the MLAs weassumed that some information about the distance to the source is given so thatthe training was performed over distance ranges not wider than half an order ofmagnitude. The results of this study suggest that machine learning algorithmsare suitable for the detection of long-lived gravitational-wave transients andthat when assuming knowledge of the distance to the source, MLAs are at leastas efficient as conventional methods.
arxiv-12900-115 | Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation | http://arxiv.org/abs/1508.02096 | author:Wang Ling, Tiago Luís, Luís Marujo, Ramón Fernandez Astudillo, Silvio Amir, Chris Dyer, Alan W. Black, Isabel Trancoso category:cs.CL published:2015-08-09 summary:We introduce a model for constructing vector representations of words bycomposing characters using bidirectional LSTMs. Relative to traditional wordrepresentation models that have independent vectors for each word type, ourmodel requires only a single vector per character type and a fixed set ofparameters for the compositional model. Despite the compactness of this modeland, more importantly, the arbitrary nature of the form-function relationshipin language, our "composed" word representations yield state-of-the-art resultsin language modeling and part-of-speech tagging. Benefits over traditionalbaselines are particularly pronounced in morphologically rich languages (e.g.,Turkish).
arxiv-12900-116 | Simulation of optical flow and fuzzy based obstacle avoidance system for mobile robots | http://arxiv.org/abs/1508.01859 | author:G. D. Illeperuma, D. U. J. Sonnadara category:cs.CV cs.RO published:2015-08-08 summary:Honey bees use optical flow to avoid obstacles effectively. In this researchwork similar methodology was tested on a simulated mobile robot. Simulationframework was based on VRML and Simulink in a 3D world. Optical flow vectorswere calculated from a video scene captured by a virtual camera which was usedas inputs to a fuzzy logic controller. Fuzzy logic controller decided thelocomotion of the robot. Different fuzzy logic rules were evaluated. The robotwas able to navigate through complex static and dynamic environmentseffectively, avoiding obstacles on its path.
arxiv-12900-117 | A straightforward method to assess motion blur for different types of displays | http://arxiv.org/abs/1602.07573 | author:Fuhao Chen, Jun Chen, Feng Huang category:cs.CV published:2015-08-08 summary:A simulation method based on the liquid crystal response and the human visualsystem is suitable to characterize motion blur for LCDs but not other displaytypes. We propose a more straightforward and widely applicable method toquantify motion blur based on the width of the moving object. We thus comparevarious types of displays objectively. A perceptual experiment was conducted tovalidate the proposed method. We test varying motion velocities for ninecommercial displays. We compare the three motion blur evaluation methods(simulation, human perception, and our method) using z-scores. Our comparisonsindicate that our method accurately characterizes motion blur for variousdisplay types.
arxiv-12900-118 | Diffusion Maximum Correntropy Criterion Algorithms for Robust Distributed Estimation | http://arxiv.org/abs/1508.01903 | author:Wentao Ma, Badong Chen, Jiandong Duan, Haiquan Zhao category:stat.ML cs.LG published:2015-08-08 summary:Robust diffusion adaptive estimation algorithms based on the maximumcorrentropy criterion (MCC), including adaptation to combination MCC andcombination to adaptation MCC, are developed to deal with the distributedestimation over network in impulsive (long-tailed) noise environments. The costfunctions used in distributed estimation are in general based on the meansquare error (MSE) criterion, which is desirable when the measurement noise isGaussian. In non-Gaussian situations, such as the impulsive-noise case, MCCbased methods may achieve much better performance than the MSE methods as theytake into account higher order statistics of error distribution. The proposedmethods can also outperform the robust diffusion least mean p-power(DLMP) anddiffusion minimum error entropy (DMEE) algorithms. The mean and mean squareconvergence analysis of the new algorithms are also carried out.
arxiv-12900-119 | Deep Boosting: Joint Feature Selection and Analysis Dictionary Learning in Hierarchy | http://arxiv.org/abs/1508.01887 | author:Zhanglin Peng, Ya Li, Zhaoquan Cai, Liang Lin category:cs.CV cs.LG cs.NE published:2015-08-08 summary:This work investigates how the traditional image classification pipelines canbe extended into a deep architecture, inspired by recent successes of deepneural networks. We propose a deep boosting framework based on layer-by-layerjoint feature boosting and dictionary learning. In each layer, we construct adictionary of filters by combining the filters from the lower layer, anditeratively optimize the image representation with a jointdiscriminative-generative formulation, i.e. minimization of empiricalclassification error plus regularization of analysis image generation overtraining images. For optimization, we perform two iterating steps: i) tominimize the classification error, select the most discriminative featuresusing the gentle adaboost algorithm; ii) according to the feature selection,update the filters to minimize the regularization on analysis imagerepresentation using the gradient descent method. Once the optimization isconverged, we learn the higher layer representation in the same way. Our modeldelivers several distinct advantages. First, our layer-wise optimizationprovides the potential to build very deep architectures. Second, the generatedimage representation is compact and meaningful. In several visual recognitiontasks, our framework outperforms existing state-of-the-art approaches.
arxiv-12900-120 | A variational approach to the consistency of spectral clustering | http://arxiv.org/abs/1508.01928 | author:Nicolás García Trillos, Dejan Slepčev category:math.ST cs.LG stat.ML stat.TH published:2015-08-08 summary:This paper establishes the consistency of spectral approaches to dataclustering. We consider clustering of point clouds obtained as samples of aground-truth measure. A graph representing the point cloud is obtained byassigning weights to edges based on the distance between the points theyconnect. We investigate the spectral convergence of both unnormalized andnormalized graph Laplacians towards the appropriate operators in the continuumdomain. We obtain sharp conditions on how the connectivity radius can be scaledwith respect to the number of sample points for the spectral convergence tohold. We also show that the discrete clusters obtained via spectral clusteringconverge towards a continuum partition of the ground truth measure. Suchcontinuum partition minimizes a functional describing the continuum analogue ofthe graph-based spectral partitioning. Our approach, based on variationalconvergence, is general and flexible.
arxiv-12900-121 | The Discrete Dantzig Selector: Estimating Sparse Linear Models via Mixed Integer Linear Optimization | http://arxiv.org/abs/1508.01922 | author:Rahul Mazumder, Peter Radchenko category:stat.ME math.OC math.ST stat.CO stat.ML stat.TH published:2015-08-08 summary:We propose a new high-dimensional linear regression estimator: the DiscreteDantzig Selector, which minimizes the number of nonzero regressioncoefficients, subject to a budget on the maximal absolute correlation betweenthe features and the residuals. We show that the estimator can be expressed asa solution to a Mixed Integer Linear Optimization (MILO) problem---acomputationally tractable framework that enables the computation of provablyoptimal global solutions. Our approach has the appealing characteristic thateven if we terminate the optimization problem at an early stage, it exits witha certificate of sub-optimality on the quality of the solution. We develop newdiscrete first order methods, motivated by recent algorithmic developments infirst order continuous convex optimization, to obtain high quality feasiblesolutions for the Discrete Dantzig Selector problem. Our proposal leads toadvantages over the off-the-shelf state-of-the-art integer programmingalgorithms, which include superior upper bounds obtained for a givencomputational budget. When a solution obtained from the discrete first ordermethods is passed as a warm-start to a MILO solver, the performance of thelatter improves significantly. Exploiting problem specific information, wepropose enhanced MILO formulations that further improve the algorithmicperformance of the MILO solvers. We demonstrate, both theoretically andempirically, that, in a wide range of regimes, the statistical properties ofthe Discrete Dantzig Selector are superior to those of popular $\ell_{1}$-basedapproaches. For problem instances with $p \approx 2500$ features and $n \approx900$ observations, our computational framework delivers optimal solutions in afew minutes and certifies optimality within an hour.
arxiv-12900-122 | Crowd Access Path Optimization: Diversity Matters | http://arxiv.org/abs/1508.01951 | author:Besmira Nushi, Adish Singla, Anja Gruenheid, Erfan Zamanian, Andreas Krause, Donald Kossmann category:cs.LG cs.DB published:2015-08-08 summary:Quality assurance is one the most important challenges in crowdsourcing.Assigning tasks to several workers to increase quality through redundantanswers can be expensive if asking homogeneous sources. This limitation hasbeen overlooked by current crowdsourcing platforms resulting therefore incostly solutions. In order to achieve desirable cost-quality tradeoffs it isessential to apply efficient crowd access optimization techniques. Our workargues that optimization needs to be aware of diversity and correlation ofinformation within groups of individuals so that crowdsourcing redundancy canbe adequately planned beforehand. Based on this intuitive idea, we introducethe Access Path Model (APM), a novel crowd model that leverages the notion ofaccess paths as an alternative way of retrieving information. APM aggregatesanswers ensuring high quality and meaningful confidence. Moreover, we devise agreedy optimization algorithm for this model that finds a provably goodapproximate plan to access the crowd. We evaluate our approach on threecrowdsourced datasets that illustrate various aspects of the problem. Ourresults show that the Access Path Model combined with greedy optimization iscost-efficient and practical to overcome common difficulties in large-scalecrowdsourcing like data sparsity and anonymity.
arxiv-12900-123 | Minimax Optimal Variable Clustering in G-models via Cord | http://arxiv.org/abs/1508.01939 | author:Florentina Bunea, Christophe Giraud, Xi Luo category:stat.ME math.ST stat.ML stat.TH published:2015-08-08 summary:The goal of variable clustering is to partition a random vector ${\bf X} \inR^p$ in sub-groups of similar probabilistic behavior. Popular methods such ashierarchical clustering or $K$-means are algorithmic procedures applied toobservations on ${\bf X}$, while no population level target is defined prior toestimation. We take a different view in this paper, where we propose andinvestigate model based variable clustering. We consider three models, ofincreasing level of complexity, termed generically $G$-models, with $G$standing for the partition to be estimated. Motivated by the potential lack ofidentifiability of the $G$-latent models, which are currently used in problemsinvolving variable clustering, we introduce two new classes of models, the$G$-exchangeable and the $G$-block covariance models. We show that both classesare identifiable, for any distribution of ${\bf X}$. Our focus is on clusters that are invariant with respect to unknown monotonetransformations of the data, and that can be estimated in a computationallyfeasible manner. Both desiderata can be met if the clusters correspond toblocks in the copula correlation matrix of ${\bf X}$, assumed to have aGaussian copula distribution. This motivates the introduction of a newsimilarity metric for cluster membership, CORD, and a homonymous method forcluster estimation. Central to our work is the derivation of the minimax valueof the CORD cluster separation for exact partition recovery. We obtained thesurprising result that this value is of order $\sqrt{{\log (p)}/{n}}$,irrespective of the number of clusters, or of the size of the smallest cluster.Our new procedure, CORD, available on CRAN, achieves this bound, is easy toimplement and has computational complexity that is polynomial in $p$.
arxiv-12900-124 | Spectral Clustering and Block Models: A Review And A New Algorithm | http://arxiv.org/abs/1508.01819 | author:Sharmodeep Bhattacharyya, Peter J. Bickel category:math.ST cs.SI stat.ML stat.TH published:2015-08-07 summary:We focus on spectral clustering of unlabeled graphs and review some resultson clustering methods which achieve weak or strong consistent identification indata generated by such models. We also present a new algorithm which appears toperform optimally both theoretically using asymptotic theory and empirically.
arxiv-12900-125 | Mimicry Is Presidential: Linguistic Style Matching in Presidential Debates and Improved Polling Numbers | http://arxiv.org/abs/1508.01786 | author:Daniel M. Romero, Roderick I. Swaab, Brian Uzzi, Adam D. Galinsky category:cs.CL cs.SI published:2015-08-07 summary:The current research used the contexts of U.S. presidential debates andnegotiations to examine whether matching the linguistic style of an opponent ina two-party exchange affects the reactions of third-party observers. Buildingoff communication accommodation theory (CAT), interaction alignment theory(IAT), and processing fluency, we propose that language style matching (LSM)will improve subsequent third-party evaluations because matching an opponent'slinguistic style reflects greater perspective taking and will make one'sarguments easier to process. In contrast, research on status inferencespredicts that LSM will negatively impact third-party evaluations because LSMimplies followership. We conduct two studies to test these competinghypotheses. Study 1 analyzed transcripts of U.S. presidential debates between1976 and 2012 and found that candidates who matched their opponent's linguisticstyle increased their standing in the polls. Study 2 demonstrated a causalrelationship between LSM and third-party observer evaluations using negotiationtranscripts.
arxiv-12900-126 | An End-to-End Neural Network for Polyphonic Piano Music Transcription | http://arxiv.org/abs/1508.01774 | author:Siddharth Sigtia, Emmanouil Benetos, Simon Dixon category:stat.ML cs.LG cs.SD published:2015-08-07 summary:We present a supervised neural network model for polyphonic piano musictranscription. The architecture of the proposed model is analogous to speechrecognition systems and comprises an acoustic model and a music language model.The acoustic model is a neural network used for estimating the probabilities ofpitches in a frame of audio. The language model is a recurrent neural networkthat models the correlations between pitch combinations over time. The proposedmodel is general and can be used to transcribe polyphonic music withoutimposing any constraints on the polyphony. The acoustic and language modelpredictions are combined using a probabilistic graphical model. Inference overthe output variables is performed using the beam search algorithm. We performtwo sets of experiments. We investigate various neural network architecturesfor the acoustic models and also investigate the effect of combining acousticand music language model predictions using the proposed architecture. Wecompare performance of the neural network based acoustic models with twopopular unsupervised acoustic models. Results show that convolutional neuralnetwork acoustic models yields the best performance across all evaluationmetrics. We also observe improved performance with the application of the musiclanguage models. Finally, we present an efficient variant of beam search thatimproves performance and reduces run-times by an order of magnitude, making themodel suitable for real-time applications.
arxiv-12900-127 | Applying Deep Learning to Answer Selection: A Study and An Open Task | http://arxiv.org/abs/1508.01585 | author:Minwei Feng, Bing Xiang, Michael R. Glass, Lidan Wang, Bowen Zhou category:cs.CL cs.LG published:2015-08-07 summary:We apply a general deep learning framework to address the non-factoidquestion answering task. Our approach does not rely on any linguistic tools andcan be applied to different languages or domains. Various architectures arepresented and compared. We create and release a QA corpus and setup a new QAtask in the insurance domain. Experimental results demonstrate superiorperformance compared to the baseline methods and various technologies givefurther improvements. For this highly challenging task, the top-1 accuracy canreach up to 65.3% on a test set, which indicates a great potential forpractical use.
arxiv-12900-128 | Stochastic Language Generation in Dialogue using Recurrent Neural Networks with Convolutional Sentence Reranking | http://arxiv.org/abs/1508.01755 | author:Tsung-Hsien Wen, Milica Gasic, Dongho Kim, Nikola Mrksic, Pei-Hao Su, David Vandyke, Steve Young category:cs.CL published:2015-08-07 summary:The natural language generation (NLG) component of a spoken dialogue system(SDS) usually needs a substantial amount of handcrafting or a well-labeleddataset to be trained on. These limitations add significantly to developmentcosts and make cross-domain, multi-lingual dialogue systems intractable.Moreover, human languages are context-aware. The most natural response shouldbe directly learned from data rather than depending on predefined syntaxes orrules. This paper presents a statistical language generator based on a jointrecurrent and convolutional neural network structure which can be trained ondialogue act-utterance pairs without any semantic alignments or predefinedgrammar trees. Objective metrics suggest that this new model outperformsprevious methods under the same experimental conditions. Results of anevaluation by human judges indicate that it produces not only high quality butlinguistically varied utterances which are preferred compared to n-gram andrule-based systems.
arxiv-12900-129 | Automata networks model for alignment and least effort on vocabulary formation | http://arxiv.org/abs/1508.01577 | author:Javier Vera, Felipe Urbina, Eric Goles category:cs.CL physics.soc-ph published:2015-08-07 summary:Can artificial communities of agents develop language with scaling relationsclose to the Zipf law? As a preliminary answer to this question, we propose anAutomata Networks model of the formation of a vocabulary on a population ofindividuals, under two in principle opposite strategies: the alignment and theleast effort principle. Within the previous account to the emergence oflinguistic conventions (specially, the Naming Game), we focus on modelingspeaker and hearer efforts as actions over their vocabularies and we study theimpact of these actions on the formation of a shared language. The numericalsimulations are essentially based on an energy function, that measures theamount of local agreement between the vocabularies. The results suggests thaton one dimensional lattices the best strategy to the formation of sharedlanguages is the one that minimizes the efforts of speakers on communicativetasks.
arxiv-12900-130 | Study of Phonemes Confusions in Hierarchical Automatic Phoneme Recognition System | http://arxiv.org/abs/1508.01718 | author:Rimah Amami, Noureddine Ellouze category:cs.CL published:2015-08-07 summary:In this paper, we have analyzed the impact of confusions on the robustness ofphoneme recognitions system. The confusions are detected at the pronunciationand the confusions matrices of the phoneme recognizer. The confusions show thatsome similarities between phonemes at the pronunciation affect significantlythe recognition rates. This paper proposes to understand those confusions inorder to improve the performance of the phoneme recognition system by isolatingthe problematic phonemes. Confusion analysis leads to build a new hierarchicalrecognizer using new phoneme distribution and the information from theconfusion matrices. This new hierarchical phoneme recognition system showssignificant improvements of the recognition rates on TIMIT database.
arxiv-12900-131 | Dimension reduction for model-based clustering | http://arxiv.org/abs/1508.01713 | author:Luca Scrucca category:stat.ME stat.ML published:2015-08-07 summary:We introduce a dimension reduction method for visualizing the clusteringstructure obtained from a finite mixture of Gaussian densities. Information onthe dimension reduction subspace is obtained from the variation on group meansand, depending on the estimated mixture model, on the variation on groupcovariances. The proposed method aims at reducing the dimensionality byidentifying a set of linear combinations, ordered by importance as quantifiedby the associated eigenvalues, of the original features which capture most ofthe cluster structure contained in the data. Observations may then be projectedonto such a reduced subspace, thus providing summary plots which help tovisualize the clustering structure. These plots can be particularly appealingin the case of high-dimensional data and noisy structure. The new constructedvariables capture most of the clustering information available in the data, andthey can be further reduced to improve clustering performance. We illustratethe approach on both simulated and real data sets.
arxiv-12900-132 | Mismatch in the Classification of Linear Subspaces: Sufficient Conditions for Reliable Classification | http://arxiv.org/abs/1508.01720 | author:Jure Sokolic, Francesco Renna, Robert Calderbank, Miguel R. D. Rodrigues category:cs.IT cs.CV math.IT stat.ML published:2015-08-07 summary:This paper considers the classification of linear subspaces with mismatchedclassifiers. In particular, we assume a model where one observes signals in thepresence of isotropic Gaussian noise and the distribution of the signalsconditioned on a given class is Gaussian with a zero mean and a low-rankcovariance matrix. We also assume that the classifier knows only a mismatchedversion of the parameters of input distribution in lieu of the true parameters.By constructing an asymptotic low-noise expansion of an upper bound to theerror probability of such a mismatched classifier, we provide sufficientconditions for reliable classification in the low-noise regime that are able tosharply predict the absence of a classification error floor. Such conditionsare a function of the geometry of the true signal distribution, the geometry ofthe mismatched signal distributions as well as the interplay between suchgeometries, namely, the principal angles and the overlap between the true andthe mismatched signal subspaces. Numerical results demonstrate that ourconditions for reliable classification can sharply predict the behavior of amismatched classifier both with synthetic data and in a motion segmentation anda hand-written digit classification applications.
arxiv-12900-133 | Places205-VGGNet Models for Scene Recognition | http://arxiv.org/abs/1508.01667 | author:Limin Wang, Sheng Guo, Weilin Huang, Yu Qiao category:cs.CV published:2015-08-07 summary:VGGNets have turned out to be effective for object recognition in stillimages. However, it is unable to yield good performance by directly adaptingthe VGGNet models trained on the ImageNet dataset for scene recognition. Thisreport describes our implementation of training the VGGNets on the large-scalePlaces205 dataset. Specifically, we train three VGGNet models, namelyVGGNet-11, VGGNet-13, and VGGNet-16, by using a Multi-GPU extension of Caffetoolbox with high computational efficiency. We verify the performance oftrained Places205-VGGNet models on three datasets: MIT67, SUN397, andPlaces205. Our trained models achieve the state-of-the-art performance on thesedatasets and are made public available.
arxiv-12900-134 | Structure Learning with Bow-free Acyclic Path Diagrams | http://arxiv.org/abs/1508.01717 | author:Christopher Nowzohour, Marloes H. Maathuis, Peter Bühlmann category:stat.ML published:2015-08-07 summary:We consider the problem of structure learning for bow-free acyclic pathdiagrams (BAPs). BAPs can be viewed as a generalization of linear Gaussian DAGmodels that allow for certain hidden variables. We present a first method forthis problem using a greedy score-based search algorithm. We also investigatesome distributional equivalence properties of BAPs which are used in analgorithmic approach to compute (nearly) equivalent model structures, allowingto infer lower bounds of causal effects. The application of our method to somedatasets reveals that BAP models can represent the data much better than DAGmodels in these cases.
arxiv-12900-135 | Unconstrained Face Verification using Deep CNN Features | http://arxiv.org/abs/1508.01722 | author:Jun-Cheng Chen, Vishal M. Patel, Rama Chellappa category:cs.CV published:2015-08-07 summary:In this paper, we present an algorithm for unconstrained face verificationbased on deep convolutional features and evaluate it on the newly releasedIARPA Janus Benchmark A (IJB-A) dataset. The IJB-A dataset includes real-worldunconstrained faces from 500 subjects with full pose and illuminationvariations which are much harder than the traditional Labeled Face in the Wild(LFW) and Youtube Face (YTF) datasets. The deep convolutional neural network(DCNN) is trained using the CASIA-WebFace dataset. Extensive experiments on theIJB-A dataset are provided.
arxiv-12900-136 | Using Deep Learning for Detecting Spoofing Attacks on Speech Signals | http://arxiv.org/abs/1508.01746 | author:Alan Godoy, Flávio Simões, José Augusto Stuchi, Marcus de Assis Angeloni, Mário Uliani, Ricardo Violato category:cs.SD cs.CL cs.CR cs.LG stat.ML published:2015-08-07 summary:It is well known that speaker verification systems are subject to spoofingattacks. The Automatic Speaker Verification Spoofing and CountermeasuresChallenge -- ASVSpoof2015 -- provides a standard spoofing database, containingattacks based on synthetic speech, along with a protocol for experiments. Thispaper describes CPqD's systems submitted to the ASVSpoof2015 Challenge, basedon deep neural networks, working both as a classifier and as a featureextraction module for a GMM and a SVM classifier. Results show the validity ofthis approach, achieving less than 0.5\% EER for known attacks.
arxiv-12900-137 | Asynchronous Distributed Semi-Stochastic Gradient Optimization | http://arxiv.org/abs/1508.01633 | author:Ruiliang Zhang, Shuai Zheng, James T. Kwok category:cs.LG cs.DC published:2015-08-07 summary:With the recent proliferation of large-scale learning problems,there havebeen a lot of interest on distributed machine learning algorithms, particularlythose that are based on stochastic gradient descent (SGD) and its variants.However, existing algorithms either suffer from slow convergence due to theinherent variance of stochastic gradients, or have a fast linear convergencerate but at the expense of poorer solution quality. In this paper, we combinetheir merits by proposing a fast distributed asynchronous SGD-based algorithmwith variance reduction. A constant learning rate can be used, and it is alsoguaranteed to converge linearly to the optimal solution. Experiments on theGoogle Cloud Computing Platform demonstrate that the proposed algorithmoutperforms state-of-the-art distributed asynchronous algorithms in terms ofboth wall clock time and solution quality.
arxiv-12900-138 | The Contribution of Internal and Model Variabilities to the Uncertainty in CMIP5 Decadal Climate Predictions | http://arxiv.org/abs/1508.01609 | author:Ehud Strobach, Golan Bel category:physics.ao-ph stat.ML published:2015-08-07 summary:Decadal climate predictions, which are initialized with observed conditions,are characterized by two main sources of uncertainties--internal and modelvariabilities. Using an ensemble of climate model simulations from the CMIP5decadal experiments, we quantified the total uncertainty associated with thesepredictions and the relative importance of each source. Annual and monthlyaverages of the surface temperature and wind components were considered. Weshow that different definitions of the anomaly results in different conclusionsregarding the variance of the ensemble members. However, some features of theuncertainty are common to all the measures we considered. We found that overdecadal time scales, there is no considerable increase in the uncertainty withtime. The model variability is more sensitive to the annual cycle than theinternal variability. This, in turn, results in a maximal uncertainty duringthe winter in the northern hemisphere. The uncertainty of the surfacetemperature prediction is dominated by the model variability, whereas theuncertainty of the wind components is determined by both sources. Analysis ofthe spatial distribution of the uncertainty reveals that the surfacetemperature has higher variability over land and in high latitudes, whereas thesurface zonal wind has higher variability over the ocean. The relativeimportance of the internal and model variabilities depends on the averagingperiod, the definition of the anomaly, and the location. These findings suggestthat several methods should be combined in order to assess future climateprediction uncertainties and that weighting schemes of the ensemble members mayreduce the uncertainties.
arxiv-12900-139 | Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems | http://arxiv.org/abs/1508.01745 | author:Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Pei-Hao Su, David Vandyke, Steve Young category:cs.CL published:2015-08-07 summary:Natural language generation (NLG) is a critical component of spoken dialogueand it has a significant impact both on usability and perceived quality. MostNLG systems in common use employ rules and heuristics and tend to generaterigid and stylised responses without the natural variation of human language.They are also not easily scaled to systems covering multiple domains andlanguages. This paper presents a statistical language generator based on asemantically controlled Long Short-term Memory (LSTM) structure. The LSTMgenerator can learn from unaligned data by jointly optimising sentence planningand surface realisation using a simple cross entropy training criterion, andlanguage variation can be easily achieved by sampling from output candidates.With fewer heuristics, an objective evaluation in two differing test domainsshowed the proposed method improved performance compared to previous methods.Human judges scored the LSTM system higher on informativeness and naturalnessand overall preferred it to the other systems.
arxiv-12900-140 | Sublinear Partition Estimation | http://arxiv.org/abs/1508.01596 | author:Pushpendre Rastogi, Benjamin Van Durme category:stat.ML cs.LG published:2015-08-07 summary:The output scores of a neural network classifier are converted toprobabilities via normalizing over the scores of all competing categories.Computing this partition function, $Z$, is then linear in the number ofcategories, which is problematic as real-world problem sets continue to grow incategorical types, such as in visual object recognition or discriminativelanguage modeling. We propose three approaches for sublinear estimation of thepartition function, based on approximate nearest neighbor search and kernelfeature maps and compare the performance of the proposed approachesempirically.
arxiv-12900-141 | Automata networks for memory loss effects in the formation of linguistic conventions | http://arxiv.org/abs/1508.01580 | author:Javier Vera, Eric Goles category:cs.CL physics.soc-ph published:2015-08-07 summary:This work attempts to give new theoretical insights to the absence ofintermediate stages in the evolution of language. In particular, it isdeveloped an automata networks approach to a crucial question: how a populationof language users can reach agreement on a linguistic convention? To describethe appearance of sharp transitions in the self-organization of language, it isadopted an extremely simple model of (working) memory. At each time step,language users simply loss part of their word-memories. Through computersimulations of low-dimensional lattices, it appear sharp transitions atcritical values that depend on the size of the vicinities of the individuals.
arxiv-12900-142 | Automatic classification of bengali sentences based on sense definitions present in bengali wordnet | http://arxiv.org/abs/1508.01349 | author:Alok Ranjan Pal, Diganta Saha, Niladri Sekhar Dash category:cs.CL published:2015-08-06 summary:Based on the sense definition of words available in the Bengali WordNet, anattempt is made to classify the Bengali sentences automatically into differentgroups in accordance with their underlying senses. The input sentences arecollected from 50 different categories of the Bengali text corpus developed inthe TDIL project of the Govt. of India, while information about the differentsenses of particular ambiguous lexical item is collected from Bengali WordNet.In an experimental basis we have used Naive Bayes probabilistic model as auseful classifier of sentences. We have applied the algorithm over 1747sentences that contain a particular Bengali lexical item which, because of itsambiguous nature, is able to trigger different senses that render sentences indifferent meanings. In our experiment we have achieved around 84% accurateresult on the sense classification over the total input sentences. We haveanalyzed those residual sentences that did not comply with our experiment anddid affect the results to note that in many cases, wrong syntactic structuresand less semantic information are the main hurdles in semantic classificationof sentences. The applicational relevance of this study is attested inautomatic text classification, machine learning, information extraction, andword sense disambiguation.
arxiv-12900-143 | Automatic 3D Liver Segmentation Using Sparse Representation of Global and Local Image Information via Level Set Formulation | http://arxiv.org/abs/1508.01521 | author:Saif Dawood Salman Al-Shaikhli, Michael Ying Yang, Bodo Rosenhahn category:cs.CV published:2015-08-06 summary:In this paper, a novel framework for automated liver segmentation via a levelset formulation is presented. A sparse representation of both global(region-based) and local (voxel-wise) image information is embedded in a levelset formulation to innovate a new cost function. Two dictionaries are build: Aregion-based feature dictionary and a voxel-wise dictionary. These dictionariesare learned, using the K-SVD method, from a public database of liversegmentation challenge (MICCAI-SLiver07). The learned dictionaries provideprior knowledge to the level set formulation. For the quantitative evaluation,the proposed method is evaluated using the testing data of MICCAI-SLiver07database. The results are evaluated using different metric scores computed bythe challenge organizers. The experimental results demonstrate the superiorityof the proposed framework by achieving the highest segmentation accuracy(79.6\%) in comparison to the state-of-the-art methods.
arxiv-12900-144 | Privacy-Preserving Multi-Document Summarization | http://arxiv.org/abs/1508.01420 | author:Luís Marujo, José Portêlo, Wang Ling, David Martins de Matos, João P. Neto, Anatole Gershman, Jaime Carbonell, Isabel Trancoso, Bhiksha Raj category:cs.IR cs.CL cs.CR published:2015-08-06 summary:State-of-the-art extractive multi-document summarization systems are usuallydesigned without any concern about privacy issues, meaning that all documentsare open to third parties. In this paper we propose a privacy-preservingapproach to multi-document summarization. Our approach enables other parties toobtain summaries without learning anything else about the original documents'content. We use a hashing scheme known as Secure Binary Embeddings to convertdocuments representation containing key phrases and bag-of-words into bitstrings, allowing the computation of approximate distances, instead of exactones. Our experiments indicate that our system yields similar results to itsnon-private counterpart on standard multi-document evaluation datasets.
arxiv-12900-145 | Using Linguistic Analysis to Translate Arabic Natural Language Queries to SPARQL | http://arxiv.org/abs/1508.01447 | author:Iyad AlAgha category:cs.CL cs.AI cs.DB published:2015-08-06 summary:The logic-based machine-understandable framework of the Semantic Web oftenchallenges naive users when they try to query ontology-based knowledge bases.Existing research efforts have approached this problem by introducing NaturalLanguage (NL) interfaces to ontologies. These NL interfaces have the ability toconstruct SPARQL queries based on NL user queries. However, most efforts wererestricted to queries expressed in English, and they often benefited from theadvancement of English NLP tools. However, little research has been done tosupport querying the Arabic content on the Semantic Web by using NL queries.This paper presents a domain-independent approach to translate Arabic NLqueries to SPARQL by leveraging linguistic analysis. Based on a specialconsideration on Noun Phrases (NPs), our approach uses a language parser toextract NPs and the relations from Arabic parse trees and match them to theunderlying ontology. It then utilizes knowledge in the ontology to group NPsinto triple-based representations. A SPARQL query is finally generated byextracting targets and modifiers, and interpreting them into SPARQL. Theinterpretation of advanced semantic features including negation, conjunctiveand disjunctive modifiers is also supported. The approach was evaluated byusing two datasets consisting of OWL test data and queries, and the obtainedresults have confirmed its feasibility to translate Arabic NL queries toSPARQL.
arxiv-12900-146 | Word sense disambiguation: a survey | http://arxiv.org/abs/1508.01346 | author:Alok Ranjan Pal, Diganta Saha category:cs.CL published:2015-08-06 summary:In this paper, we made a survey on Word Sense Disambiguation (WSD). Nearabout in all major languages around the world, research in WSD has beenconducted upto different extents. In this paper, we have gone through a surveyregarding the different approaches adopted in different research works, theState of the Art in the performance in this domain, recent works in differentIndian languages and finally a survey in Bengali language. We have made asurvey on different competitions in this field and the bench mark results,obtained from those competitions.
arxiv-12900-147 | Hyponymy extraction of domain ontology concept based on ccrfs and hierarchy clustering | http://arxiv.org/abs/1508.01476 | author:Qiang Zhan, Chunhong Wang category:cs.CL published:2015-08-06 summary:Concept hierarchy is the backbone of ontology, and the concept hierarchyacquisition has been a hot topic in the field of ontology learning. this paperproposes a hyponymy extraction method of domain ontology concept based oncascaded conditional random field(CCRFs) and hierarchy clustering. It takesfree text as extracting object, adopts CCRFs identifying the domain concepts.First the low layer of CCRFs is used to identify simple domain concept, thenthe results are sent to the high layer, in which the nesting concepts arerecognized. Next we adopt hierarchy clustering to identify the hyponymyrelation between domain ontology concepts. The experimental results demonstratethe proposed method is efficient.
arxiv-12900-148 | Nonlinear Metric Learning for kNN and SVMs through Geometric Transformations | http://arxiv.org/abs/1508.01534 | author:Bibo Shi, Jundong Liu category:cs.LG cs.CV published:2015-08-06 summary:In recent years, research efforts to extend linear metric learning models tohandle nonlinear structures have attracted great interests. In this paper, wepropose a novel nonlinear solution through the utilization of deformablegeometric models to learn spatially varying metrics, and apply the strategy toboost the performance of both kNN and SVM classifiers. Thin-plate splines (TPS)are chosen as the geometric model due to their remarkable versatility andrepresentation power in accounting for high-order deformations. By transformingthe input space through TPS, we can pull same-class neighbors closer whilepushing different-class points farther away in kNN, as well as make the inputdata points more linearly separable in SVMs. Improvements in the performance ofkNN classification are demonstrated through experiments on synthetic and realworld datasets, with comparisons made with several state-of-the-art metriclearning solutions. Our SVM-based models also achieve significant improvementsover traditional linear and kernel SVMs with the same datasets.
arxiv-12900-149 | Theoretical and Empirical Analysis of a Parallel Boosting Algorithm | http://arxiv.org/abs/1508.01549 | author:Uday Kamath, Carlotta Domeniconi, Kenneth De Jong category:cs.LG cs.DC published:2015-08-06 summary:Many real-world problems involve massive amounts of data. Under thesecircumstances learning algorithms often become prohibitively expensive, makingscalability a pressing issue to be addressed. A common approach is to performsampling to reduce the size of the dataset and enable efficient learning.Alternatively, one customizes learning algorithms to achieve scalability. Ineither case, the key challenge is to obtain algorithmic efficiency withoutcompromising the quality of the results. In this paper we discuss ameta-learning algorithm (PSBML) which combines features of parallel algorithmswith concepts from ensemble and boosting methodologies to achieve the desiredscalability property. We present both theoretical and empirical analyses whichshow that PSBML preserves a critical property of boosting, specifically,convergence to a distribution centered around the margin. We then presentadditional empirical analyses showing that this meta-level algorithm provides ageneral and effective framework that can be used in combination with a varietyof learning classifiers. We perform extensive experiments to investigate thetradeoff achieved between scalability and accuracy, and robustness to noise, onboth synthetic and real-world data. These empirical results corroborate ourtheoretical analysis, and demonstrate the potential of PSBML in achievingscalability without sacrificing accuracy.
arxiv-12900-150 | Universal Approximation of Edge Density in Large Graphs | http://arxiv.org/abs/1508.01340 | author:Marc Boullé category:cs.SI cs.DB stat.ML published:2015-08-06 summary:In this paper, we present a novel way to summarize the structure of largegraphs, based on non-parametric estimation of edge density in directedmultigraphs. Following coclustering approach, we use a clustering of thevertices, with a piecewise constant estimation of the density of the edgesacross the clusters, and address the problem of automatically and reliablyinferring the number of clusters, which is the granularity of the coclustering.We use a model selection technique with data-dependent prior and obtain anexact evaluation criterion for the posterior probability of edge densityestimation models. We demonstrate, both theoretically and empirically, that ourdata-dependent modeling technique is consistent, resilient to noise, valid nonasymptotically and asymptotically behaves as an universal approximator of thetrue edge density in directed multigraphs. We evaluate our method usingartificial graphs and present its practical interest on real world graphs. Themethod is both robust and scalable. It is able to extract insightful patternsin the unsupervised learning setting and to provide state of the art accuracywhen used as a preparation step for supervised learning.
arxiv-12900-151 | A Knowledge Gradient Policy for Sequencing Experiments to Identify the Structure of RNA Molecules Using a Sparse Additive Belief Model | http://arxiv.org/abs/1508.01551 | author:Yan Li, Kristofer G. Reyes, Jorge Vazquez-Anderson, Yingfei Wang, Lydia M. Contreras, Warren B. Powell category:math.OC stat.AP stat.ML published:2015-08-06 summary:We present a sparse knowledge gradient (SpKG) algorithm for adaptivelyselecting the targeted regions within a large RNA molecule to identify whichregions are most amenable to interactions with other molecules. Experimentally,such regions can be inferred from fluorescence measurements obtained by bindinga complementary probe with fluorescence markers to the targeted regions. We usea biophysical model which shows that the fluorescence ratio under the log scalehas a sparse linear relationship with the coefficients describing theaccessibility of each nucleotide, since not all sites are accessible (due tothe folding of the molecule). The SpKG algorithm uniquely combines the Bayesianranking and selection problem with the frequentist $\ell_1$ regularizedregression approach Lasso. We use this algorithm to identify the sparsitypattern of the linear model as well as sequentially decide the best regions totest before experimental budget is exhausted. Besides, we also develop twoother new algorithms: batch SpKG algorithm, which generates more suggestionssequentially to run parallel experiments; and batch SpKG with a procedure whichwe call length mutagenesis. It dynamically adds in new alternatives, in theform of types of probes, are created by inserting, deleting or mutatingnucleotides within existing probes. In simulation, we demonstrate thesealgorithms on the Group I intron (a mid-size RNA molecule), showing that theyefficiently learn the correct sparsity pattern, identify the most accessibleregion, and outperform several other policies.
arxiv-12900-152 | On Gobbledygook and Mood of the Philippine Senate: An Exploratory Study on the Readability and Sentiment of Selected Philippine Senators' Microposts | http://arxiv.org/abs/1508.01321 | author:Fatima M. Moncada, Jaderick P. Pabico category:cs.CL cs.CY published:2015-08-06 summary:This paper presents the findings of a readability assessment and sentimentanalysis of selected six Philippine senators' microposts over the popularTwitter microblog. Using the Simple Measure of Gobbledygook (SMOG), tweets ofSenators Cayetano, Defensor-Santiago, Pangilinan, Marcos, Guingona, andEscudero were assessed. A sentiment analysis was also done to determine thepolarity of the senators' respective microposts. Results showed that on theaverage, the six senators are tweeting at an eight to ten SMOG level. Thismeans that, at least a sixth grader will be able to understand the senators'tweets. Moreover, their tweets are mostly neutral and their sentiments vary inunison at some period of time. This could mean that a senator's tweet sentimentis affected by specific Philippine-based events.
arxiv-12900-153 | A Mood-based Genre Classification of Television Content | http://arxiv.org/abs/1508.01571 | author:Humberto Corona, Michael P. O'Mahony category:cs.IR cs.CL H.3.3 published:2015-08-06 summary:The classification of television content helps users organise and navigatethrough the large list of channels and programs now available. In this paper,we address the problem of television content classification by exploiting textinformation extracted from program transcriptions. We present an analysis whichadapts a model for sentiment that has been widely and successfully applied inother fields such as music or blog posts. We use a real-world dataset obtainedfrom the Boxfish API to compare the performance of classifiers trained on anumber of different feature sets. Our experiments show that, over a largecollection of television content, program genres can be represented in athree-dimensional space of valence, arousal and dominance, and that promisingclassification results can be achieved using features based on thisrepresentation. This finding supports the use of the proposed representation oftelevision content as a feature space for similarity computation andrecommendation generation.
arxiv-12900-154 | The study of cuckoo optimization algorithm for production planning problem | http://arxiv.org/abs/1508.01310 | author:Afsane Akbarzadeh, Elham Shadkam category:math.OC cs.NE published:2015-08-06 summary:Constrained Nonlinear programming problems are hard problems, and one of themost widely used and common problems for production planning problem tooptimize. In this study, one of the mathematical models of production planningis survey and the problem solved by cuckoo algorithm. Cuckoo Algorithm isefficient method to solve continues non linear problem. Moreover, mentionedmodels of production planning solved with Genetic algorithm and Lingo softwareand the results will compared. The Cuckoo Algorithm is suitable choice foroptimization in convergence of solution
arxiv-12900-155 | Collaborative Total Variation: A General Framework for Vectorial TV Models | http://arxiv.org/abs/1508.01308 | author:Joan Duran, Michael Moeller, Catalina Sbert, Daniel Cremers category:cs.CV math.HO math.NA math.OC published:2015-08-06 summary:Even after over two decades, the total variation (TV) remains one of the mostpopular regularizations for image processing problems and has sparked atremendous amount of research, particularly to move from scalar tovector-valued functions. In this paper, we consider the gradient of a colorimage as a three dimensional matrix or tensor with dimensions corresponding tothe spatial extend, the differences to other pixels, and the spectral channels.The smoothness of this tensor is then measured by taking different norms alongthe different dimensions. Depending on the type of these norms one obtains verydifferent properties of the regularization, leading to novel models for colorimages. We call this class of regularizations collaborative total variation(CTV). On the theoretical side, we characterize the dual norm, thesubdifferential and the proximal mapping of the proposed regularizers. Wefurther prove, with the help of the generalized concept of singular vectors,that an $\ell^{\infty}$ channel coupling makes the most prior assumptions andhas the greatest potential to reduce color artifacts. Our practicalcontributions consist of an extensive experimental section where we compare theperformance of a large number of collaborative TV methods for inverse problemslike denoising, deblurring and inpainting.
arxiv-12900-156 | Compact Convolutional Neural Network Cascade for Face Detection | http://arxiv.org/abs/1508.01292 | author:Ilya Kalinovskii, Vladimir Spitsyn category:cs.CV published:2015-08-06 summary:The problem of faces detection in images or video streams is a classicalproblem of computer vision. The multiple solutions of this problem have beenproposed, but the question of their optimality is still open. Many algorithmsachieve a high quality face detection, but at the cost of high computationalcomplexity. This restricts their application in the real-time systems. Thispaper presents a new solution of the frontal face detection problem based oncompact convolutional neural networks cascade. The test results on FDDB datasetshow that it is competitive with state-of-the-art algorithms. This proposeddetector is implemented using three technologies: SSE/AVX/AVX2 instruction setsfor Intel CPUs, Nvidia CUDA, OpenCL. The detection speed of our approachconsiderably exceeds all the existing CPU-based and GPU-based algorithms.Because of high computational efficiency, our detector can processing 4K UltraHD video stream in real time (up to 27 fps) on mobile platforms (Intel IvyBridge CPUs and Nvidia Kepler GPUs) in searching objects with the dimension60x60 pixels or higher. At the same time its performance weakly dependent onthe background and number of objects in scene. This is achieved by theasynchronous computation of stages in the cascade.
arxiv-12900-157 | Replication and Generalization of PRECISE | http://arxiv.org/abs/1508.01306 | author:Michael Minock, Nils Everling category:cs.CL cs.AI cs.DB published:2015-08-06 summary:This report describes an initial replication study of the PRECISE system anddevelops a clearer, more formal description of the approach. Based on ourevaluation, we conclude that the PRECISE results do not fully replicate.However the formalization developed here suggests a road map to further enhanceand extend the approach pioneered by PRECISE. After a long, productive discussion with Ana-Maria Popescu (one of theauthors of PRECISE) we got more clarity on the PRECISE approach and how thelexicon was authored for the GEO evaluation. Based on this we built a moredirect implementation over a repaired formalism. Although our new evaluation isnot yet complete, it is clear that the system is performing much better now. Wewill continue developing our ideas and implementation and generate a futurereport/publication that more accurately evaluates PRECISE like approaches.
arxiv-12900-158 | INsight: A Neuromorphic Computing System for Evaluation of Large Neural Networks | http://arxiv.org/abs/1508.01008 | author:Jaeyong Chung, Taehwan Shin, Yongshin Kang category:cs.NE published:2015-08-05 summary:Deep neural networks have been demonstrated impressive results in variouscognitive tasks such as object detection and image classification. In order toexecute large networks, Von Neumann computers store the large number of weightparameters in external memories, and processing elements are timed-shared,which leads to power-hungry I/O operations and processing bottlenecks. Thispaper describes a neuromorphic computing system that is designed from theground up for the energy-efficient evaluation of large-scale neural networks.The computing system consists of a non-conventional compiler, a neuromorphicarchitecture, and a space-efficient microarchitecture that leverages existingintegrated circuit design methodologies. The compiler factorizes a trained,feedforward network into a sparsely connected network, compresses the weightslinearly, and generates a time delay neural network reducing the number ofconnections. The connections and units in the simplified network are mapped tosilicon synapses and neurons. We demonstrate an implementation of theneuromorphic computing system based on a field-programmable gate array thatperforms the MNIST hand-written digit classification with 97.64% accuracy.
arxiv-12900-159 | Learning from LDA using Deep Neural Networks | http://arxiv.org/abs/1508.01011 | author:Dongxu Zhang, Tianyi Luo, Dong Wang, Rong Liu category:cs.LG cs.CL cs.IR cs.NE published:2015-08-05 summary:Latent Dirichlet Allocation (LDA) is a three-level hierarchical Bayesianmodel for topic inference. In spite of its great success, inferring the latenttopic distribution with LDA is time-consuming. Motivated by the transferlearning approach proposed by~\newcite{hinton2015distilling}, we present anovel method that uses LDA to supervise the training of a deep neural network(DNN), so that the DNN can approximate the costly LDA inference with lesscomputation. Our experiments on a document classification task show that asimple DNN can learn the LDA behavior pretty well, while the inference isspeeded up tens or hundreds of times.
arxiv-12900-160 | Direct Estimation of the Derivative of Quadratic Mutual Information with Application in Supervised Dimension Reduction | http://arxiv.org/abs/1508.01019 | author:Voot Tangkaratt, Hiroaki Sasaki, Masashi Sugiyama category:stat.ML published:2015-08-05 summary:A typical goal of supervised dimension reduction is to find a low-dimensionalsubspace of the input space such that the projected input variables preservemaximal information about the output variables. The dependence maximizationapproach solves the supervised dimension reduction problem through maximizing astatistical dependence between projected input variables and output variables.A well-known statistical dependence measure is mutual information (MI) which isbased on the Kullback-Leibler (KL) divergence. However, it is known that the KLdivergence is sensitive to outliers. On the other hand, quadratic MI (QMI) is avariant of MI based on the $L_2$ distance which is more robust against outliersthan the KL divergence, and a computationally efficient method to estimate QMIfrom data, called least-squares QMI (LSQMI), has been proposed recently. Forthese reasons, developing a supervised dimension reduction method based onLSQMI seems promising. However, not QMI itself, but the derivative of QMI isneeded for subspace search in supervised dimension reduction, and thederivative of an accurate QMI estimator is not necessarily a good estimator ofthe derivative of QMI. In this paper, we propose to directly estimate thederivative of QMI without estimating QMI itself. We show that the directestimation of the derivative of QMI is more accurate than the derivative of theestimated QMI. Finally, we develop a supervised dimension reduction algorithmwhich efficiently uses the proposed derivative estimator, and demonstratethrough experiments that the proposed method is more robust against outliersthan existing methods.
arxiv-12900-161 | Listen, Attend and Spell | http://arxiv.org/abs/1508.01211 | author:William Chan, Navdeep Jaitly, Quoc V. Le, Oriol Vinyals category:cs.CL cs.LG cs.NE stat.ML published:2015-08-05 summary:We present Listen, Attend and Spell (LAS), a neural network that learns totranscribe speech utterances to characters. Unlike traditional DNN-HMM models,this model learns all the components of a speech recognizer jointly. Our systemhas two components: a listener and a speller. The listener is a pyramidalrecurrent network encoder that accepts filter bank spectra as inputs. Thespeller is an attention-based recurrent network decoder that emits charactersas outputs. The network produces character sequences without making anyindependence assumptions between the characters. This is the key improvement ofLAS over previous end-to-end CTC models. On a subset of the Google voice searchtask, LAS achieves a word error rate (WER) of 14.1% without a dictionary or alanguage model, and 10.3% with language model rescoring over the top 32 beams.By comparison, the state-of-the-art CLDNN-HMM model achieves a WER of 8.0%.
arxiv-12900-162 | Bayesian Approximate Kernel Regression with Variable Selection | http://arxiv.org/abs/1508.01217 | author:Lorin Crawford, Kris C. Wood, Xiang Zhou, Sayan Mukherjee category:stat.ME q-bio.QM stat.AP stat.ML published:2015-08-05 summary:Nonlinear kernel regression models are often used in statistics and machinelearning due to greater accuracy than linear models. Variable selection forkernel regression models is a challenge partly because, unlike the linearregression setting, there is no clear concept of an effect size for regressioncoefficients. In this paper, we propose a novel framework that provides ananalog of the effect size of each explanatory variable for Bayesian kernelregression models when the kernel is shift-invariant---for example the Gaussiankernel. We use function analytic properties of shift-invariant reproducingkernel Hilbert spaces (RKHS) to define a linear vector space that (1) capturesnonlinear structure and (2) can be projected onto the original explanatoryvariables. The projection onto the original explanatory variables serves as theanalog of effect sizes. The specific function analytic property we use is thatshift-invariant kernel functions can be approximated via random Fourier bases.Based on the random Fourier expansion we propose a computationally efficientclass of Bayesian approximate kernel regression (BAKR) models for bothnonlinear regression and binary classification for which one can compute ananalog of effect sizes. By adapting some classical results in compressivesensing we state conditions under which BAKR can recover a sparse set of effectsizes, simultaneous variable selection and regression. We illustrate theutility of BAKR by examining, in some detail, two important problems instatistical genetics: genomic selection (predicting phenotype from genotype)and association mapping (inference of significant variables or loci).State-of-the-art methods for genomic selection and association mapping arebased on kernel regression and linear models, respectively. BAKR is the firstmethod that is competitive in both settings.
arxiv-12900-163 | Socially Constrained Structural Learning for Groups Detection in Crowd | http://arxiv.org/abs/1508.01158 | author:Francesco Solera, Simone Calderara, Rita Cucchiara category:cs.CV published:2015-08-05 summary:Modern crowd theories agree that collective behavior is the result of theunderlying interactions among small groups of individuals. In this work, wepropose a novel algorithm for detecting social groups in crowds by means of aCorrelation Clustering procedure on people trajectories. The affinity betweencrowd members is learned through an online formulation of the Structural SVMframework and a set of specifically designed features characterizing both theirphysical and social identity, inspired by Proxemic theory, Granger causality,DTW and Heat-maps. To adhere to sociological observations, we introduce a lossfunction (G-MITRE) able to deal with the complexity of evaluating groupdetection performances. We show our algorithm achieves state-of-the-art resultswhen relying on both ground truth trajectories and tracklets previouslyextracted by available detector/tracker systems.
arxiv-12900-164 | 3D Automatic Segmentation Method for Retinal Optical Coherence Tomography Volume Data Using Boundary Surface Enhancement | http://arxiv.org/abs/1508.00966 | author:Yankui Sun, Tian Zhang, Yue Zhao, Yufan He category:cs.CV published:2015-08-05 summary:With the introduction of spectral-domain optical coherence tomography(SDOCT), much larger image datasets are routinely acquired compared to what waspossible using the previous generation of time-domain OCT. Thus, there is acritical need for the development of 3D segmentation methods for processingthese data. We present here a novel 3D automatic segmentation method forretinal OCT volume data. Briefly, to segment a boundary surface, two OCT volumedatasets are obtained by using a 3D smoothing filter and a 3D differentialfilter. Their linear combination is then calculated to generate new volume datawith an enhanced boundary surface, where pixel intensity, boundary positioninformation, and intensity changes on both sides of the boundary surface areused simultaneously. Next, preliminary discrete boundary points are detectedfrom the A-Scans of the volume data. Finally, surface smoothness constraintsand a dynamic threshold are applied to obtain a smoothed boundary surface bycorrecting a small number of error points. Our method can extract retinal layerboundary surfaces sequentially with a decreasing search region of volume data.We performed automatic segmentation on eight human OCT volume datasets acquiredfrom a commercial Spectralis OCT system, where each volume of data consisted of97 OCT images with a resolution of 496 512; experimental results show that thismethod can accurately segment seven layer boundary surfaces in normal as wellas some abnormal eyes.
arxiv-12900-165 | Progressive EM for Latent Tree Models and Hierarchical Topic Detection | http://arxiv.org/abs/1508.00973 | author:Peixian Chen, Nevin L. Zhang, Leonard K. M. Poon, Zhourong Chen category:cs.LG cs.CL cs.IR stat.ML published:2015-08-05 summary:Hierarchical latent tree analysis (HLTA) is recently proposed as a new methodfor topic detection. It differs fundamentally from the LDA-based methods interms of topic definition, topic-document relationship, and learning method. Ithas been shown to discover significantly more coherent topics and better topichierarchies. However, HLTA relies on the Expectation-Maximization (EM)algorithm for parameter estimation and hence is not efficient enough to dealwith large datasets. In this paper, we propose a method to drastically speed upHLTA using a technique inspired by recent advances in the moments method.Empirical experiments show that our method greatly improves the efficiency ofHLTA. It is as efficient as the state-of-the-art LDA-based method forhierarchical topic detection and finds substantially better topics and topichierarchies.
arxiv-12900-166 | Empirical Similarity for Absent Data Generation in Imbalanced Classification | http://arxiv.org/abs/1508.01235 | author:Arash Pourhabib category:stat.ML cs.LG published:2015-08-05 summary:When the training data in a two-class classification problem is overwhelmedby one class, most classification techniques fail to correctly identify thedata points belonging to the underrepresented class. We proposeSimilarity-based Imbalanced Classification (SBIC) that learns patterns in thetraining data based on an empirical similarity function. To take the imbalancedstructure of the training data into account, SBIC utilizes the concept ofabsent data, i.e. data from the minority class which can help better find theboundary between the two classes. SBIC simultaneously optimizes the weights ofthe empirical similarity function and finds the locations of absent datapoints. As such, SBIC uses an embedded mechanism for synthetic data generationwhich does not modify the training dataset, but alters the algorithm to suitimbalanced datasets. Therefore, SBIC uses the ideas of both major schools ofthoughts in imbalanced classification: Like cost-sensitive approaches SBICoperates on an algorithm level to handle imbalanced structures; and similar tosynthetic data generation approaches, it utilizes the properties of unobserveddata points from the minority class. The application of SBIC to imbalanceddatasets suggests it is comparable to, and in some cases outperforms, othercommonly used classification techniques for imbalanced datasets.
arxiv-12900-167 | A review of heterogeneous data mining for brain disorders | http://arxiv.org/abs/1508.01023 | author:Bokai Cao, Xiangnan Kong, Philip S. Yu category:cs.LG cs.CE cs.DB q-bio.NC stat.AP published:2015-08-05 summary:With rapid advances in neuroimaging techniques, the research on braindisorder identification has become an emerging area in the data miningcommunity. Brain disorder data poses many unique challenges for data miningresearch. For example, the raw data generated by neuroimaging experiments is intensor representations, with typical characteristics of high dimensionality,structural complexity and nonlinear separability. Furthermore, brainconnectivity networks can be constructed from the tensor data, embedding subtleinteractions between brain regions. Other clinical measures are usuallyavailable reflecting the disease status from different perspectives. It isexpected that integrating complementary information in the tensor data and thebrain network data, and incorporating other clinical parameters will bepotentially transformative for investigating disease mechanisms and forinforming therapeutic interventions. Many research efforts have been devoted tothis area. They have achieved great success in various applications, such astensor-based modeling, subgraph pattern mining, multi-view feature analysis. Inthis paper, we review some recent data mining methods that are used foranalyzing brain disorders.
arxiv-12900-168 | Evaluating color texture descriptors under large variations of controlled lighting conditions | http://arxiv.org/abs/1508.01108 | author:Claudio Cusano, Paolo Napoletano, Raimondo Schettini category:cs.CV published:2015-08-05 summary:The recognition of color texture under varying lighting conditions is stillan open issue. Several features have been proposed for this purpose, rangingfrom traditional statistical descriptors to features extracted with neuralnetworks. Still, it is not completely clear under what circumstances a featureperforms better than the others. In this paper we report an extensivecomparison of old and new texture features, with and without a colornormalization step, with a particular focus on how they are affected by smalland large variation in the lighting conditions. The evaluation is performed ona new texture database including 68 samples of raw food acquired under 46conditions that present single and combined variations of light color,direction and intensity. The database allows to systematically investigate therobustness of texture descriptors across a large range of variations of imagingconditions.
arxiv-12900-169 | Estimating snow cover from publicly available images | http://arxiv.org/abs/1508.01055 | author:Roman Fedorov, Alessandro Camerada, Piero Fraternali, Marco Tagliasacchi category:cs.MM cs.CV published:2015-08-05 summary:In this paper we study the problem of estimating snow cover in mountainousregions, that is, the spatial extent of the earth surface covered by snow. Weargue that publicly available visual content, in the form of user generatedphotographs and image feeds from outdoor webcams, can both be leveraged asadditional measurement sources, complementing existing ground, satellite andairborne sensor data. To this end, we describe two content acquisition andprocessing pipelines that are tailored to such sources, addressing the specificchallenges posed by each of them, e.g., identifying the mountain peaks,filtering out images taken in bad weather conditions, handling varyingillumination conditions. The final outcome is summarized in a snow cover index,which indicates for a specific mountain and day of the year, the fraction ofvisible area covered by snow, possibly at different elevations. We created amanually labelled dataset to assess the accuracy of the image snow covered areaestimation, achieving 90.0% precision at 91.1% recall. In addition, we showthat seasonal trends related to air temperature are captured by the snow coverindex.
arxiv-12900-170 | TabletGaze: Unconstrained Appearance-based Gaze Estimation in Mobile Tablets | http://arxiv.org/abs/1508.01244 | author:Qiong Huang, Ashok Veeraraghavan, Ashutosh Sabharwal category:cs.CV published:2015-08-05 summary:We study gaze estimation on tablets; our key design goal is uncalibrated gazeestimation using the front-facing camera during natural use of tablets, wherethe posture and method of holding the tablet is not constrained. We collectedthe first large unconstrained gaze dataset of tablet users, labeled RiceTabletGaze dataset. The dataset consists of 51 subjects, each with 4 differentpostures and 35 gaze locations. Subjects vary in race, gender and in their needfor prescription glasses, all of which might impact gaze estimation accuracy.Driven by our observations on the collected data, we present a TabletGazealgorithm for automatic gaze estimation using multi-level HoG feature andRandom Forests regressor. The TabletGaze algorithm achieves a mean error of3.17 cm. We perform extensive evaluation on the impact of various factors suchas dataset size, race, wearing glasses and user posture on the gaze estimationaccuracy and make important observations about the impact of these factors.
arxiv-12900-171 | Relation Classification via Recurrent Neural Network | http://arxiv.org/abs/1508.01006 | author:Dongxu Zhang, Dong Wang category:cs.CL cs.LG cs.NE published:2015-08-05 summary:Deep learning has gained much success in sentence-level relationclassification. For example, convolutional neural networks (CNN) have deliveredcompetitive performance without much effort on feature engineering as theconventional pattern-based methods. Thus a lot of works have been producedbased on CNN structures. However, a key issue that has not been well addressedby the CNN-based method is the lack of capability to learn temporal features,especially long-distance dependency between nominal pairs. In this paper, wepropose a simple framework based on recurrent neural networks (RNN) and compareit with CNN-based model. To show the limitation of popular used SemEval-2010Task 8 dataset, we introduce another dataset refined from MIMLRE(Angeli et al.,2014). Experiments on two different datasets strongly indicates that theRNN-based model can deliver better performance on relation classification, andit is particularly capable of learning long-distance relation patterns. Thismakes it suitable for real-world applications where complicated expressions areoften involved.
arxiv-12900-172 | On the convergence of the sparse possibilistic c-means algorithm | http://arxiv.org/abs/1508.01057 | author:Spyridoula D. Xenaki, Konstantinos D. Koutroumbas, Athanasios A. Rontogiannis category:cs.CV published:2015-08-05 summary:In this paper, a convergence proof for the recently proposed sparsepossibilistic c-means (SPCM) algorithm is provided, utilizing the celebratedZangwill convergence theorem. It is shown that the iterative sequence generatedby SPCM converges to a stationary point or there exists a subsequence of itthat converges to a stationary point of the cost function of the algorithm.
arxiv-12900-173 | Sparse Pseudo-input Local Kriging for Large Non-stationary Spatial Datasets with Exogenous Variables | http://arxiv.org/abs/1508.01248 | author:Babak Farmanesh, Arash Pourhabib category:stat.ML published:2015-08-05 summary:Gaussian process (GP) regression is a powerful tool for building predictivemodels for spatial systems. However, it does not scale efficiently for largedatasets. Particularly, for high-dimensional spatial datasets, i.e., spatialdatasets that contain exogenous variables, the performance of GP regressionfurther deteriorates. This paper presents the Sparse Pseudo-input Local Kriging(SPLK) which approximates the full GP for spatial datasets with exogenousvariables. SPLK employs orthogonal cuts which decompose the domain into smallersubdomains and then applies a sparse approximation of the full GP in eachsubdomain. We obtain the continuity of the global predictor by imposingcontinuity constraints on the boundaries of the neighboring subdomains. Thedomain decomposition scheme applies independent covariance structures in eachregion, and as a result, SPLK captures heterogeneous covariance structures.SPLK achieves computational efficiency by utilizing sparse approximation ineach subdomain which enables SPLK to accommodate large subdomains that containmany data points and possess a homogenous covariance structure. We Apply theproposed method to real and simulated datasets. We conclude that thecombination of orthogonal cuts and sparse approximation makes the proposedmethod an efficient algorithm for high-dimensional large spatial datasets.
arxiv-12900-174 | Non-isometric Curve to Surface Matching with Incomplete Data for Functional Calibration | http://arxiv.org/abs/1508.01240 | author:Arash Pourhabib, Balabhaskar Balasundaram category:stat.ML published:2015-08-05 summary:Calibration refers to the process of adjusting features of a computationalmodel that are not observed in the physical process so that the model matchesthe real process. We propose a framework for calibration when the unobservedfeatures, i.e. calibration parameters, do not assume a single value, but arefunctionally dependent on other inputs. We demonstrate that this problem iscurve to surface matching where the matched curve does not possess the samelength as the original curve. Therefore, we perform non-isometric matching of acurve to a surface. Since in practical applications we do not observe acontinuous curve but a sample of data points, we use a graph-theoretic approachto solve this matching of incomplete data. We define a graph structure in whichthe nodes are selected from the incomplete surface and the weights of the edgesare decided based on the response values of the curve and surface. We show thatthe problem of non-isometric incomplete curve to surface matching is a shortestpath problem in a directed acyclic graph. We apply the proposed method,graph-theoretic non-isometric matching, to real and synthetic data anddemonstrate that the proposed method improves the prediction accuracy infunctional calibration.
arxiv-12900-175 | HFirst: A Temporal Approach to Object Recognition | http://arxiv.org/abs/1508.01176 | author:Garrick Orchard, Cedric Meyer, Ralph Etienne-Cummings, Christoph Posch, Nitish Thakor, Ryad Benosman category:cs.CV published:2015-08-05 summary:This paper introduces a spiking hierarchical model for object recognitionwhich utilizes the precise timing information inherently present in the outputof biologically inspired asynchronous Address Event Representation (AER) visionsensors. The asynchronous nature of these systems frees computation andcommunication from the rigid predetermined timing enforced by system clocks inconventional systems. Freedom from rigid timing constraints opens thepossibility of using true timing to our advantage in computation. We show notonly how timing can be used in object recognition, but also how it can in factsimplify computation. Specifically, we rely on a simpletemporal-winner-take-all rather than more computationally intensive synchronousoperations typically used in biologically inspired neural networks for objectrecognition. This approach to visual computation represents a major paradigmshift from conventional clocked systems and can find application in othersensory modalities and computational tasks. We showcase effectiveness of theapproach by achieving the highest reported accuracy to date (97.5\%$\pm$3.5\%)for a previously published four class card pip recognition task and an accuracyof 84.9\%$\pm$1.9\% for a new more difficult 36 class character recognitiontask.
arxiv-12900-176 | Topic Stability over Noisy Sources | http://arxiv.org/abs/1508.01067 | author:Jing Su, Oisín Boydell, Derek Greene, Gerard Lynch category:cs.CL cs.IR published:2015-08-05 summary:Topic modelling techniques such as LDA have recently been applied to speechtranscripts and OCR output. These corpora may contain noisy or erroneous textswhich may undermine topic stability. Therefore, it is important to know howwell a topic modelling algorithm will perform when applied to noisy data. Inthis paper we show that different types of textual noise will have diverseeffects on the stability of different topic models. From these observations, wepropose guidelines for text corpus generation, with a focus on automatic speechtranscription. We also suggest topic model selection methods for noisy corpora.
arxiv-12900-177 | A MAP approach for $\ell_q$-norm regularized sparse parameter estimation using the EM algorithm | http://arxiv.org/abs/1508.01071 | author:Rodrigo Carvajal, Juan C. Agüero, Boris I. Godoy, Dimitrios Katselis category:cs.SY stat.ML published:2015-08-05 summary:In this paper, Bayesian parameter estimation through the consideration of theMaximum A Posteriori (MAP) criterion is revisited under the prism of theExpectation-Maximization (EM) algorithm. By incorporating a sparsity-promotingpenalty term in the cost function of the estimation problem through the use ofan appropriate prior distribution, we show how the EM algorithm can be used toefficiently solve the corresponding optimization problem. To this end, we relyon variance-mean Gaussian mixtures (VMGM) to describe the prior distribution,while we incorporate many nice features of these mixtures to our estimationproblem. The corresponding MAP estimation problem is completely expressed interms of the EM algorithm, which allows for handling nonlinearities and hiddenvariables that cannot be easily handled with traditional methods. Forcomparison purposes, we also develop a Coordinate Descent algorithm for the$\ell_q$-norm penalized problem and present the performance results viasimulations.
arxiv-12900-178 | Partitioned Shape Modeling with On-the-Fly Sparse Appearance Learning for Anterior Visual Pathway Segmentation | http://arxiv.org/abs/1508.01128 | author:Awais Mansoor, Juan J. Cerrolaza, Robert A. Avery, Marius G. Linguraru category:cs.CV published:2015-08-05 summary:MRI quantification of cranial nerves such as anterior visual pathway (AVP) inMRI is challenging due to their thin small size, structural variation along itspath, and adjacent anatomic structures. Segmentation of pathologically abnormaloptic nerve (e.g. optic nerve glioma) poses additional challenges due tochanges in its shape at unpredictable locations. In this work, we propose apartitioned joint statistical shape model approach with sparse appearancelearning for the segmentation of healthy and pathological AVP. Our maincontributions are: (1) optimally partitioned statistical shape models for theAVP based on regional shape variations for greater local flexibility ofstatistical shape model; (2) refinement model to accommodate pathologicalregions as well as areas of subtle variation by training the model on-the-flyusing the initial segmentation obtained in (1); (3) hierarchical deformableframework to incorporate scale information in partitioned shape and appearancemodels. Our method, entitled PAScAL (PArtitioned Shape and AppearanceLearning), was evaluated on 21 MRI scans (15 healthy + 6 glioma cases) frompediatric patients (ages 2-17). The experimental results show that the proposedlocalized shape and sparse appearance-based learning approach significantlyoutperforms segmentation approaches in the analysis of pathological data.
arxiv-12900-179 | Detection of Critical Number of People in Interlocked Doors for Security Access Control by Exploiting a Microwave Transceiver-Array | http://arxiv.org/abs/1508.01081 | author:Paolo Nesi, Gianni Pantaleo category:cs.CV published:2015-08-05 summary:Counting the number of people is something many security application focuson, when dealing with controlling accesses in restricted areas, as it occurswith banks, airports, railway stations and governmental offices. This paperpresents an automated solution for detecting the presence of more than oneperson into interlocked doors adopted in many accesses. In most cases,interlocked doors are small areas where other pieces of information and sensorsare placed in order to detect the presence of guns, explosive, etc. The generalgoals and the required environmental condition, allowed us to implement adetection system at lower costs and complexity, with respect to other existingtechniques. The system consists of a fixed array of microwave transceivermodules, whose received signals are processed to collect information related toa sort of volume occupied in the interlocked door cabin. The proposed solutionhas been statistically validated by using statistical analysis. The wholesolution has been also implemented to be used in a real time environment andthus validated against real experimental measures.
arxiv-12900-180 | Single and Multiple Illuminant Estimation Using Convolutional Neural Networks | http://arxiv.org/abs/1508.00998 | author:Simone Bianco, Claudio Cusano, Raimondo Schettini category:cs.CV published:2015-08-05 summary:In this paper we present a method for the estimation of the color of theilluminant in RAW images. The method includes a Convolutional Neural Networkthat has been specially designed to produce multiple local estimates. Amultiple illuminant detector determines whether or not the local outputs of thenetwork must be aggregated into a single estimate. We evaluated our method onstandard datasets with single and multiple illuminants, obtaining lowerestimation errors with respect to those obtained by other general purposemethods in the state of the art.
arxiv-12900-181 | Deep Convolutional Networks are Hierarchical Kernel Machines | http://arxiv.org/abs/1508.01084 | author:Fabio Anselmi, Lorenzo Rosasco, Cheston Tan, Tomaso Poggio category:cs.LG cs.NE published:2015-08-05 summary:In i-theory a typical layer of a hierarchical architecture consists of HWmodules pooling the dot products of the inputs to the layer with thetransformations of a few templates under a group. Such layers include asspecial cases the convolutional layers of Deep Convolutional Networks (DCNs) aswell as the non-convolutional layers (when the group contains only theidentity). Rectifying nonlinearities -- which are used by present-day DCNs --are one of the several nonlinearities admitted by i-theory for the HW module.We discuss here the equivalence between group averages of linear combinationsof rectifying nonlinearities and an associated kernel. This property impliesthat present-day DCNs can be exactly equivalent to a hierarchy of kernelmachines with pooling and non-pooling layers. Finally, we describe a conjecturefor theoretically understanding hierarchies of such modules. A main consequenceof the conjecture is that hierarchies of trained HW modules minimize memoryrequirements while computing a selective and invariant representation.
arxiv-12900-182 | Dimension Reduction with Non-degrading Generalization | http://arxiv.org/abs/1508.00984 | author:Pitoyo Hartono category:cs.LG cs.NE published:2015-08-05 summary:Visualizing high dimensional data by projecting them into two or threedimensional space is one of the most effective ways to intuitively understandthe data's underlying characteristics, for example their class neighborhoodstructure. While data visualization in low dimensional space can be efficientfor revealing the data's underlying characteristics, classifying a new samplein the reduced-dimensional space is not always beneficial because of the lossof information in expressing the data. It is possible to classify the data inthe high dimensional space, while visualizing them in the low dimensionalspace, but in this case, the visualization is often meaningless because itfails to illustrate the underlying characteristics that are crucial for theclassification process. In this paper, the performance-preserving property of the previously proposedRestricted Radial Basis Function Network in reducing the dimension of labeleddata is explained. Here, it is argued through empirical experiments that theinternal representation of the Restricted Radial Basis Function Network, whichduring the supervised learning process organizes a visualizable two dimensionalmap, does not only preserve the topographical structure of high dimensionaldata but also captures their class neighborhood structures that are importantfor classifying them. Hence, unlike many of the existing dimension reductionmethods, the Restricted Radial Basis Function Network offers two dimensionalvisualization that is strongly correlated with the classification process.
arxiv-12900-183 | Structured Prediction: From Gaussian Perturbations to Linear-Time Principled Algorithms | http://arxiv.org/abs/1508.00945 | author:Jean Honorio, Tommi Jaakkola category:stat.ML cs.LG published:2015-08-05 summary:Margin-based structured prediction commonly uses a maximum loss over allpossible structured outputs \cite{Altun03,Collins04b,Taskar03}. In naturallanguage processing, recent work \cite{Zhang14,Zhang15} has proposed the use ofthe maximum loss over random structured outputs sampled independently from someproposal distribution. This method is linear-time in the number of randomstructured outputs and trivially parallelizable. We study this family of lossfunctions in the PAC-Bayes framework under Gaussian perturbations\cite{McAllester07}. Under some technical conditions and up to statisticalaccuracy, we show that this family of loss functions produces a tighter upperbound of the Gibbs decoder distortion than commonly used methods. Thus, usingthe maximum loss over random structured outputs is a principled way of learningthe parameter of structured prediction models. Besides explaining theexperimental success of \cite{Zhang14,Zhang15}, our theoretical results showthat more general techniques are possible.
arxiv-12900-184 | MAP Support Detection for Greedy Sparse Signal Recovery Algorithms in Compressive Sensing | http://arxiv.org/abs/1508.00964 | author:Namyoon Lee category:cs.IT cs.LG math.IT published:2015-08-05 summary:A reliable support detection is essential for a greedy algorithm toreconstruct a sparse signal accurately from compressed and noisy measurements.This paper proposes a novel support detection method for greedy algorithms,which is referred to as "\textit{maximum a posteriori (MAP) supportdetection}". Unlike existing support detection methods that identify supportindices with the largest correlation value in magnitude per iteration, theproposed method selects them with the largest likelihood ratios computed underthe true and null support hypotheses by simultaneously exploiting thedistributions of sensing matrix, sparse signal, and noise. Leveraging thistechnique, MAP-Matching Pursuit (MAP-MP) is first presented to show theadvantages of exploiting the proposed support detection method, and asufficient condition for perfect signal recovery is derived for the case whenthe sparse signal is binary. Subsequently, a set of iterative greedyalgorithms, called MAP-generalized Orthogonal Matching Pursuit (MAP-gOMP),MAP-Compressive Sampling Matching Pursuit (MAP-CoSaMP), and MAP-SubspacePursuit (MAP-SP) are presented to demonstrate the applicability of the proposedsupport detection method to existing greedy algorithms. From empirical results,it is shown that the proposed greedy algorithms with highly reliable supportdetection can be better, faster, and easier to implement than basis pursuit vialinear programming.
arxiv-12900-185 | Asynchronous stochastic convex optimization | http://arxiv.org/abs/1508.00882 | author:John C. Duchi, Sorathan Chaturapruek, Christopher Ré category:math.OC stat.ML published:2015-08-04 summary:We show that asymptotically, completely asynchronous stochastic gradientprocedures achieve optimal (even to constant factors) convergence rates for thesolution of convex optimization problems under nearly the same conditionsrequired for asymptotic optimality of standard stochastic gradient procedures.Roughly, the noise inherent to the stochastic approximation scheme dominatesany noise from asynchrony. We also give empirical evidence demonstrating thestrong performance of asynchronous, parallel stochastic optimization schemes,demonstrating that the robustness inherent to stochastic approximation problemsallows substantially faster parallel and asynchronous solution methods.
arxiv-12900-186 | Semantic Pose using Deep Networks Trained on Synthetic RGB-D | http://arxiv.org/abs/1508.00835 | author:Jeremie Papon, Markus Schoeler category:cs.CV published:2015-08-04 summary:In this work we address the problem of indoor scene understanding from RGB-Dimages. Specifically, we propose to find instances of common furniture classes,their spatial extent, and their pose with respect to generalized class models.To accomplish this, we use a deep, wide, multi-output convolutional neuralnetwork (CNN) that predicts class, pose, and location of possible objectssimultaneously. To overcome the lack of large annotated RGB-D training sets(especially those with pose), we use an on-the-fly rendering pipeline thatgenerates realistic cluttered room scenes in parallel to training. We thenperform transfer learning on the relatively small amount of publicly availableannotated RGB-D data, and find that our model is able to successfully annotateeven highly challenging real scenes. Importantly, our trained network is ableto understand noisy and sparse observations of highly cluttered scenes with aremarkable degree of accuracy, inferring class and pose from a very limited setof cues. Additionally, our neural network is only moderately deep and computesclass, pose and position in tandem, so the overall run-time is significantlyfaster than existing methods, estimating all output parameters simultaneouslyin parallel on a GPU in seconds.
arxiv-12900-187 | Online Domain Adaptation for Multi-Object Tracking | http://arxiv.org/abs/1508.00776 | author:Adrien Gaidon, Eleonora Vig category:cs.CV published:2015-08-04 summary:Automatically detecting, labeling, and tracking objects in videos dependsfirst and foremost on accurate category-level object detectors. These might,however, not always be available in practice, as acquiring high-quality largescale labeled training datasets is either too costly or impractical for allpossible real-world application scenarios. A scalable solution consists inre-using object detectors pre-trained on generic datasets. This work is thefirst to investigate the problem of on-line domain adaptation of objectdetectors for causal multi-object tracking (MOT). We propose to alleviate thedataset bias by adapting detectors from category to instances, and back: (i) wejointly learn all target models by adapting them from the pre-trained one, and(ii) we also adapt the pre-trained model on-line. We introduce an on-linemulti-task learning algorithm to efficiently share parameters and reduce drift,while gradually improving recall. Our approach is applicable to any linearobject detector, and we evaluate both cheap "mini-Fisher Vectors" and expensive"off-the-shelf" ConvNet features. We quantitatively measure the benefit of ourdomain adaptation strategy on the KITTI tracking benchmark and on a new dataset(PASCAL-to-KITTI) we introduce to study the domain mismatch problem in MOT.
arxiv-12900-188 | Multi-Modal Bayesian Embeddings for Learning Social Knowledge Graphs | http://arxiv.org/abs/1508.00715 | author:Zhilin Yang, Jie Tang, William Cohen category:cs.CL cs.SI published:2015-08-04 summary:We study the extent to which online social networks can be connected to openknowledge bases. The problem is referred to as learning social knowledgegraphs. We propose a multi-modal Bayesian embedding model, GenVector, to learnlatent topics that generate word and network embeddings. GenVector leverageslarge-scale unlabeled data with embeddings and represents data of twomodalities---i.e., social network users and knowledge concepts---in a sharedlatent topic space. Experiments on three datasets show that the proposed methodclearly outperforms state-of-the-art methods. We then deploy the method onAMiner, a large-scale online academic search system with a network of38,049,189 researchers with a knowledge base with 35,415,011 concepts. Ourmethod significantly decreases the error rate in an online A/B test with liveusers.
arxiv-12900-189 | Recognition of Emotions using Kinects | http://arxiv.org/abs/1508.00761 | author:Shun Li, Changye Zhu, Liqing Cui, Nan Zhao, Baobin Li, Tingshao Zhu category:cs.CY cs.CV cs.HC published:2015-08-04 summary:Psychological studies indicate that emotional states are expressed in the waypeople walk and the human gait is investigated in terms of its ability toreveal a person's emotional state. And Microsoft Kinect is a rapidlydeveloping, inexpensive, portable and no-marker motion capture system. Thispaper gives a new referable method to do emotion recognition, by usingMicrosoft Kinect to do gait pattern analysis, which has not been reported. $59$subjects are recruited in this study and their gait patterns are record by twoKinect cameras. Significant joints selecting, Coordinate system transforming,Slider window gauss filter, Differential operation, and Data segmentation areused in data preprocessing. Feature extracting is based on Fouriertransformation. By using the NaiveBayes, RandomForests, libSVM and SMOclassification, the recognition rate of natural and unnatural emotions canreach above 70%.It is concluded that using the Kinect system can be a newmethod in recognition of emotions.
arxiv-12900-190 | Multi-Label Active Learning from Crowds | http://arxiv.org/abs/1508.00722 | author:Shao-Yuan Li, Yuan Jiang, Zhi-Hua Zhou category:cs.LG cs.SI published:2015-08-04 summary:Multi-label active learning is a hot topic in reducing the label cost byoptimally choosing the most valuable instance to query its label from anoracle. In this paper, we consider the poolbased multi-label active learningunder the crowdsourcing setting, where during the active query process, insteadof resorting to a high cost oracle for the ground-truth, multiple low costimperfect annotators with various expertise are available for labeling. To dealwith this problem, we propose the MAC (Multi-label Active learning from Crowds)approach which incorporate the local influence of label correlations to build aprobabilistic model over the multi-label classifier and annotators. Based onthis model, we can estimate the labels for instances as well as the expertiseof each annotator. Then we propose the instance selection and annotatorselection criteria that consider the uncertainty/diversity of instances and thereliability of annotators, such that the most reliable annotator will bequeried for the most valuable instances. Experimental results demonstrate theeffectiveness of the proposed approach.
arxiv-12900-191 | Fixed-point algorithms for learning determinantal point processes | http://arxiv.org/abs/1508.00792 | author:Zelda Mariet, Suvrit Sra category:cs.LG published:2015-08-04 summary:Determinantal point processes (DPPs) offer an elegant tool for encodingprobabilities over subsets of a ground set. Discrete DPPs are parametrized by apositive semidefinite matrix (called the DPP kernel), and estimating thiskernel is key to learning DPPs from observed data. We consider the task oflearning the DPP kernel, and develop for it a surprisingly simple yet effectivenew algorithm. Our algorithm offers the following benefits over previousapproaches: (a) it is much simpler; (b) it yields equally good and sometimeseven better local maxima; and (c) it runs an order of magnitude faster on largeproblems. We present experimental results on both real and simulated data toillustrate the numerical performance of our technique.
arxiv-12900-192 | Parameter Database : Data-centric Synchronization for Scalable Machine Learning | http://arxiv.org/abs/1508.00703 | author:Naman Goel, Divyakant Agrawal, Sanjay Chawla, Ahmed Elmagarmid category:cs.DB cs.LG published:2015-08-04 summary:We propose a new data-centric synchronization framework for carrying out ofmachine learning (ML) tasks in a distributed environment. Our frameworkexploits the iterative nature of ML algorithms and relaxes the applicationagnostic bulk synchronization parallel (BSP) paradigm that has previously beenused for distributed machine learning. Data-centric synchronization complementsfunction-centric synchronization based on using stale updates to increase thethroughput of distributed ML computations. Experiments to validate ourframework suggest that we can attain substantial improvement over BSP whileguaranteeing sequential correctness of ML tasks.
arxiv-12900-193 | Adaptivity and Computation-Statistics Tradeoffs for Kernel and Distance based High Dimensional Two Sample Testing | http://arxiv.org/abs/1508.00655 | author:Aaditya Ramdas, Sashank J. Reddi, Barnabas Poczos, Aarti Singh, Larry Wasserman category:math.ST cs.AI cs.IT cs.LG math.IT stat.ML stat.TH published:2015-08-04 summary:Nonparametric two sample testing is a decision theoretic problem thatinvolves identifying differences between two random variables without makingparametric assumptions about their underlying distributions. We refer to themost common settings as mean difference alternatives (MDA), for testingdifferences only in first moments, and general difference alternatives (GDA),which is about testing for any difference in distributions. A large number oftest statistics have been proposed for both these settings. This paper connectsthree classes of statistics - high dimensional variants of Hotelling's t-test,statistics based on Reproducing Kernel Hilbert Spaces, and energy statisticsbased on pairwise distances. We ask the question: how much statistical power dopopular kernel and distance based tests for GDA have when the unknowndistributions differ in their means, compared to specialized tests for MDA? We formally characterize the power of popular tests for GDA like the MaximumMean Discrepancy with the Gaussian kernel (gMMD) and bandwidth-dependentvariants of the Energy Distance with the Euclidean norm (eED) in thehigh-dimensional MDA regime. Some practically important properties include (a)eED and gMMD have asymptotically equal power; furthermore they enjoy a freelunch because, while they are additionally consistent for GDA, they also havethe same power as specialized high-dimensional t-test variants for MDA. Allthese tests are asymptotically optimal (including matching constants) under MDAfor spherical covariances, according to simple lower bounds, (b) The power ofgMMD is independent of the kernel bandwidth, as long as it is larger than thechoice made by the median heuristic, (c) There is a clear and smoothcomputation-statistics tradeoff for linear-time, subquadratic-time andquadratic-time versions of these tests, with more computation resulting inhigher power.
arxiv-12900-194 | Particle Swarm Optimization for Weighted Sum Rate Maximization in MIMO Broadcast Channels | http://arxiv.org/abs/1508.01168 | author:Tung T. Vu, Ha Hoang Kha, Trung Q. Duong, Nguyen-Son Vo category:cs.IT cs.NE math.IT math.OC published:2015-08-04 summary:In this paper, we investigate the downlink multiple-input-multipleoutput(MIMO) broadcast channels in which a base transceiver station (BTS) broadcastsmultiple data streams to K MIMO mobile stations (MSs) simultaneously. In orderto maximize the weighted sum-rate (WSR) of the system subject to thetransmitted power constraint, the design problem is to find the pre-codingmatrices at BTS and the decoding matrices at MSs. However, such a designproblem is typically a nonlinear and nonconvex optimization and, thus, it isquite hard to obtain the analytical solutions. To tackle with the mathematicaldifficulties, we propose an efficient stochastic optimization algorithm tooptimize the transceiver matrices. Specifically, we utilize the linear minimummean square error (MMSE) Wiener filters at MSs. Then, we introduce theconstrained particle swarm optimization (PSO) algorithm to jointly optimize theprecoding and decoding matrices. Numerical experiments are exhibited tovalidate the effectiveness of the proposed algorithm in terms of convergence,computational complexity and total WSR.
arxiv-12900-195 | Perceptron like Algorithms for Online Learning to Rank | http://arxiv.org/abs/1508.00842 | author:Sougata Chaudhuri, Ambuj Tewari category:cs.LG stat.ML published:2015-08-04 summary:Perceptron is a classic online algorithm for learning a classificationfunction. In this paper, we provide a novel extension of the perceptronalgorithm to the learning to rank problem in information retrieval. We considerpopular listwise performance measures such as Normalized Discounted CumulativeGain (NDCG) and Average Precision (AP). A modern perspective on perceptron forclassification is that it is simply an instance of online gradient descent(OGD), during mistake rounds, using the hinge loss function. Motivated by thisinterpretation, we propose a novel family of listwise, large margin rankingsurrogates. Members of this family can be thought of as analogs of the hingeloss. Exploiting a certain self-bounding property of the proposed family, weprovide a guarantee on the cumulative NDCG (or AP) induced loss incurred by ourperceptron-like algorithm. We show that, if there exists a perfect oracleranker which can correctly rank each instance in an online sequence of rankingdata, with some margin, the cumulative loss of perceptron algorithm on thatsequence is bounded by a constant, irrespective of the length of the sequence.This result is reminiscent of Novikoff's convergence theorem for theclassification perceptron. Moreover, we prove a lower bound on the cumulativeloss achievable by any deterministic algorithm, under the assumption ofexistence of perfect oracle ranker. The lower bound shows that our perceptronbound is not tight, and we propose another, \emph{purely online}, algorithmwhich achieves the lower bound. We provide empirical results on simulated andlarge commercial datasets to corroborate our theoretical results.
arxiv-12900-196 | Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs | http://arxiv.org/abs/1508.00657 | author:Miguel Ballesteros, Chris Dyer, Noah A. Smith category:cs.CL published:2015-08-04 summary:We present extensions to a continuous-state dependency parsing method thatmakes it applicable to morphologically rich languages. Starting with ahigh-performance transition-based parser that uses long short-term memory(LSTM) recurrent neural networks to learn representations of the parser state,we replace lookup-based word representations with representations constructedfrom the orthographic representations of the words, also using LSTMs. Thisallows statistical sharing across word forms that are similar on the surface.Experiments for morphologically rich languages show that the parsing modelbenefits from incorporating the character-based encodings of words.
arxiv-12900-197 | Bayesian mixtures of spatial spline regressions | http://arxiv.org/abs/1508.00635 | author:Faicel Chamroukhi category:stat.ME cs.LG stat.CO stat.ML published:2015-08-04 summary:This work relates the framework of model-based clustering for spatialfunctional data where the data are surfaces. We first introduce a Bayesianspatial spline regression model with mixed-effects (BSSR) for modeling spatialfunction data. The BSSR model is based on Nodal basis functions for spatialregression and accommodates both common mean behavior for the data through afixed-effects part, and variability inter-individuals thanks to arandom-effects part. Then, in order to model populations of spatial functionaldata issued from heterogeneous groups, we integrate the BSSR model into amixture framework. The resulting model is a Bayesian mixture of spatial splineregressions with mixed-effects (BMSSR) used for density estimation andmodel-based surface clustering. The models, through their Bayesian formulation,allow to integrate possible prior knowledge on the data structure andconstitute a good alternative to recent mixture of spatial spline regressionsmodel estimated in a maximum likelihood framework via theexpectation-maximization (EM) algorithm. The Bayesian model inference isperformed by Markov Chain Monte Carlo (MCMC) sampling. We derive two Gibbssampler to infer the BSSR and the BMSSR models and apply them on simulatedsurfaces and a real problem of handwritten digit recognition using the MNISTdata set. The obtained results highlight the potential benefit of the proposedBayesian approaches for modeling surfaces possibly dispersed in particular inclusters.
arxiv-12900-198 | Sparse PCA via Bipartite Matchings | http://arxiv.org/abs/1508.00625 | author:Megasthenis Asteris, Dimitris Papailiopoulos, Anastasios Kyrillidis, Alexandros G. Dimakis category:stat.ML cs.DS cs.LG math.OC published:2015-08-04 summary:We consider the following multi-component sparse PCA problem: given a set ofdata points, we seek to extract a small number of sparse components withdisjoint supports that jointly capture the maximum possible variance. Thesecomponents can be computed one by one, repeatedly solving the single-componentproblem and deflating the input data matrix, but as we show this greedyprocedure is suboptimal. We present a novel algorithm for sparse PCA thatjointly optimizes multiple disjoint components. The extracted features capturevariance that lies within a multiplicative factor arbitrarily close to 1 fromthe optimal. Our algorithm is combinatorial and computes the desired componentsby solving multiple instances of the bipartite maximum weight matching problem.Its complexity grows as a low order polynomial in the ambient dimension of theinput data matrix, but exponentially in its rank. However, it can beeffectively applied on a low-dimensional sketch of the data; this allows us toobtain polynomial-time approximation guarantees via spectral bounds. Weevaluate our algorithm on real data-sets and empirically demonstrate that inmany cases it outperforms existing, deflation-based approaches.
arxiv-12900-199 | Staged Multi-armed Bandits | http://arxiv.org/abs/1508.00641 | author:Cem Tekin, Mihaela van der Schaar category:cs.LG stat.ML published:2015-08-04 summary:In conventional multi-armed bandits (MAB) and other reinforcement learningmethods, the learner sequentially chooses actions and obtains a reward (whichcan be possibly missing, delayed or erroneous) after each taken action. Thisreward is then used by the learner to improve its future decisions. However, innumerous applications, ranging from personalized patient treatment topersonalized web-based education, the learner does not obtain rewards aftereach action, but only after sequences of actions are taken, intermediatefeedbacks are observed, and a final decision is made based on which a reward isobtained. In this paper, we introduce a new class of reinforcement learningmethods which can operate in such settings. We refer to this class as stagedmulti-armed bandits (S-MAB). S-MAB proceeds in rounds, each composed of severalstages; in each stage, the learner chooses an action and observes a feedbacksignal. Upon each action selection a feedback signal is observed, whilst thereward of the selected sequence of actions is only revealed after the learnerselects a stop action that ends the current round. The reward of the rounddepends both on the sequence of actions and the sequence of observed feedbacks.The goal of the learner is to maximize its total expected reward over allrounds by learning to choose the best sequence of actions based on the feedbackit gets about these actions. First, we define an oracle benchmark, whichsequentially selects the actions that maximize the expected immediate reward.This benchmark is known to be approximately optimal when the reward sequenceassociated with the selected actions is adaptive submodular. Then, we proposeour online learning algorithm, for which we prove that the regret islogarithmic in the number of rounds and linear in the number of stages withrespect to the oracle benchmark.
arxiv-12900-200 | Evaluating software-based fingerprint liveness detection using Convolutional Networks and Local Binary Patterns | http://arxiv.org/abs/1508.00537 | author:Rodrigo Frassetto Nogueira, Roberto de Alencar Lotufo, Rubens Campos Machado category:cs.CV published:2015-08-03 summary:With the growing use of biometric authentication systems in the past years,spoof fingerprint detection has become increasingly important. In this work, weimplement and evaluate two different feature extraction techniques forsoftware-based fingerprint liveness detection: Convolutional Networks withrandom weights and Local Binary Patterns. Both techniques were used inconjunction with a Support Vector Machine (SVM) classifier. DatasetAugmentation was used to increase classifier's performance and a variety ofpreprocessing operations were tested, such as frequency filtering, contrastequalization, and region of interest filtering. The experiments were made onthe datasets used in The Liveness Detection Competition of years 2009, 2011 and2013, which comprise almost 50,000 real and fake fingerprints' images. Our bestmethod achieves an overall rate of 95.2% of correctly classified samples - animprovement of 35% in test error when compared with the best previouslypublished results.
arxiv-12900-201 | A Weakly Supervised Learning Approach based on Spectral Graph-Theoretic Grouping | http://arxiv.org/abs/1508.00507 | author:Tameem Adel, Alexander Wong, Daniel Stashuk category:cs.LG cs.AI published:2015-08-03 summary:In this study, a spectral graph-theoretic grouping strategy for weaklysupervised classification is introduced, where a limited number of labelledsamples and a larger set of unlabelled samples are used to construct a largerannotated training set composed of strongly labelled and weakly labelledsamples. The inherent relationship between the set of strongly labelled samplesand the set of unlabelled samples is established via spectral grouping, withthe unlabelled samples subsequently weakly annotated based on the stronglylabelled samples within the associated spectral groups. A number of similaritygraph models for spectral grouping, including two new similarity graph modelsintroduced in this study, are explored to investigate their performance in thecontext of weakly supervised classification in handling different types ofdata. Experimental results using benchmark datasets as well as real EMGdatasets demonstrate that the proposed approach to weakly supervisedclassification can provide noticeable improvements in classificationperformance, and that the proposed similarity graph models can lead to ultimatelearning results that are either better than or on a par with existingsimilarity graph models in the context of spectral grouping for weaklysupervised classification.
arxiv-12900-202 | Evolutionary Algorithms: Concepts, Designs, and Applications in Bioinformatics: Evolutionary Algorithms for Bioinformatics | http://arxiv.org/abs/1508.00468 | author:Ka-Chun Wong category:cs.NE q-bio.GN q-bio.QM stat.CO stat.ME published:2015-08-03 summary:Since genetic algorithm was proposed by John Holland (Holland J. H., 1975) inthe early 1970s, the study of evolutionary algorithm has emerged as a popularresearch field (Civicioglu & Besdok, 2013). Researchers from various scientificand engineering disciplines have been digging into this field, exploring theunique power of evolutionary algorithms (Hadka & Reed, 2013). Many applicationshave been successfully proposed in the past twenty years. For example,mechanical design (Lampinen & Zelinka, 1999), electromagnetic optimization(Rahmat-Samii & Michielssen, 1999), environmental protection (Bertini, Felice,Moretti, & Pizzuti, 2010), finance (Larkin & Ryan, 2010), musical orchestration(Esling, Carpentier, & Agon, 2010), pipe routing (Furuholmen, Glette, Hovin, &Torresen, 2010), and nuclear reactor core design (Sacco, Henderson,Rios-Coelho, Ali, & Pereira, 2009). In particular, its function optimizationcapability was highlighted (Goldberg & Richardson, 1987) because of its highadaptability to different function landscapes, to which we cannot applytraditional optimization techniques (Wong, Leung, & Wong, 2009). Here we reviewthe applications of evolutionary algorithms in bioinformatics.
arxiv-12900-203 | Unsupervised Learning in Genome Informatics | http://arxiv.org/abs/1508.00459 | author:Ka-Chun Wong, Yue Li, Zhaolei Zhang category:q-bio.GN q-bio.QM stat.AP stat.ME stat.ML published:2015-08-03 summary:With different genomes available, unsupervised learning algorithms areessential in learning genome-wide biological insights. Especially, thefunctional characterization of different genomes is essential for us tounderstand lives. In this book chapter, we review the state-of-the-artunsupervised learning algorithms for genome informatics from DNA to MicroRNA. DNA (DeoxyriboNucleic Acid) is the basic component of genomes. A significantfraction of DNA regions (transcription factor binding sites) are bound byproteins (transcription factors) to regulate gene expression at differentdevelopment stages in different tissues. To fully understand genetics, it isnecessary of us to apply unsupervised learning algorithms to learn and inferthose DNA regions. Here we review several unsupervised learning methods fordeciphering the genome-wide patterns of those DNA regions. MicroRNA (miRNA), a class of small endogenous non-coding RNA (RiboNucleicacid) species, regulate gene expression post-transcriptionally by formingimperfect base-pair with the target sites primarily at the 3$'$ untranslatedregions of the messenger RNAs. Since the 1993 discovery of the first miRNA\emph{let-7} in worms, a vast amount of studies have been dedicated tofunctionally characterizing the functional impacts of miRNA in a networkcontext to understand complex diseases such as cancer. Here we review severalrepresentative unsupervised learning frameworks on inferring miRNA regulatorynetwork by exploiting the static sequence-based information pertinent to theprior knowledge of miRNA targeting and the dynamic information of miRNAactivities implicated by the recently available large data compendia, whichinterrogate genome-wide expression profiles of miRNAs and/or mRNAs acrossvarious cell conditions.
arxiv-12900-204 | Evolutionary Multimodal Optimization: A Short Survey | http://arxiv.org/abs/1508.00457 | author:Ka-Chun Wong category:cs.NE cs.AI q-bio.QM published:2015-08-03 summary:Real world problems always have different multiple solutions. For instance,optical engineers need to tune the recording parameters to get as many optimalsolutions as possible for multiple trials in the varied-line-spacingholographic grating design problem. Unfortunately, most traditionaloptimization techniques focus on solving for a single optimal solution. Theyneed to be applied several times; yet all solutions are not guaranteed to befound. Thus the multimodal optimization problem was proposed. In that problem,we are interested in not only a single optimal point, but also the others. Withstrong parallel search capability, evolutionary algorithms are shown to beparticularly effective in solving this type of problem. In particular, theevolutionary algorithms for multimodal optimization usually not only locatemultiple optima in a single run, but also preserve their population diversitythroughout a run, resulting in their global optimization ability on multimodalfunctions. In addition, the techniques for multimodal optimization are borrowedas diversity maintenance techniques to other problems. In this chapter, wedescribe and review the state-of-the-arts evolutionary algorithms formultimodal optimization in terms of methodology, benchmarking, and application.
arxiv-12900-205 | Kernelized Multiview Projection | http://arxiv.org/abs/1508.00430 | author:Mengyang Yu, Li Liu, Ling Shao category:cs.CV published:2015-08-03 summary:Conventional vision algorithms adopt a single type of feature or a simpleconcatenation of multiple features, which is always represented in ahigh-dimensional space. In this paper, we propose a novel unsupervised spectralembedding algorithm called Kernelized Multiview Projection (KMP) to better fuseand embed different feature representations. Computing the kernel matrices fromdifferent features/views, KMP can encode them with the corresponding weights toachieve a low-dimensional and semantically meaningful subspace where thedistribution of each view is sufficiently smooth and discriminative. Morecrucially, KMP is linear for the reproducing kernel Hilbert space (RKHS) andsolves the out-of-sample problem, which allows it to be competent for variouspractical applications. Extensive experiments on three popular image datasetsdemonstrate the effectiveness of our multiview embedding algorithm.
arxiv-12900-206 | A variational approach to path estimation and parameter inference of hidden diffusion processes | http://arxiv.org/abs/1508.00506 | author:Tobias Sutter, Arnab Ganguly, Heinz Koeppl category:math.OC cs.LG cs.SY math.PR math.ST stat.TH published:2015-08-03 summary:We consider a hidden Markov model, where the signal process, given by adiffusion, is only indirectly observed through some noisy measurements. Thearticle develops a variational method for approximating the hidden states ofthe signal process given the full set of observations. This, in particular,leads to systematic approximations of the smoothing densities of the signalprocess. The paper then demonstrates how an efficient inference scheme, basedon this variational approach to the approximation of the hidden states, can bedesigned to estimate the unknown parameters of stochastic differentialequations. Two examples at the end illustrate the efficacy and the accuracy ofthe presented method.
arxiv-12900-207 | Significance of Maximum Spectral Amplitude in Sub-bands for Spectral Envelope Estimation and Its Application to Statistical Parametric Speech Synthesis | http://arxiv.org/abs/1508.00354 | author:Sivanand Achanta, Anandaswarup Vadapalli, Sai Krishna R., Suryakanth V. Gangashetty category:cs.SD cs.CL published:2015-08-03 summary:In this paper we propose a technique for spectral envelope estimation usingmaximum values in the sub-bands of Fourier magnitude spectrum (MSASB). Mostother methods in the literature parametrize spectral envelope in cepstraldomain such as Mel-generalized cepstrum etc. Such cepstral domainrepresentations, although compact, are not readily interpretable. Thisdifficulty is overcome by our method which parametrizes in the spectral domainitself. In our experiments, spectral envelope estimated using MSASB method wasincorporated in the STRAIGHT vocoder. Both objective and subjective results ofanalysis-by-synthesis indicate that the proposed method is comparable toSTRAIGHT. We also evaluate the effectiveness of the proposed parametrization ina statistical parametric speech synthesis framework using deep neural networks.
arxiv-12900-208 | Time-series modeling with undecimated fully convolutional neural networks | http://arxiv.org/abs/1508.00317 | author:Roni Mittelman category:stat.ML cs.LG published:2015-08-03 summary:We present a new convolutional neural network-based time-series model.Typical convolutional neural network (CNN) architectures rely on the use ofmax-pooling operators in between layers, which leads to reduced resolution atthe top layers. Instead, in this work we consider a fully convolutional network(FCN) architecture that uses causal filtering operations, and allows for therate of the output signal to be the same as that of the input signal. Wefurthermore propose an undecimated version of the FCN, which we refer to as theundecimated fully convolutional neural network (UFCNN), and is motivated by theundecimated wavelet transform. Our experimental results verify that using theundecimated version of the FCN is necessary in order to allow for effectivetime-series modeling. The UFCNN has several advantages compared to othertime-series models such as the recurrent neural network (RNN) and longshort-term memory (LSTM), since it does not suffer from either the vanishing orexploding gradients problems, and is therefore easier to train. Convolutionoperations can also be implemented more efficiently compared to the recursionthat is involved in RNN-based models. We evaluate the performance of our modelin a synthetic target tracking task using bearing only measurements generatedfrom a state-space model, a probabilistic modeling of polyphonic musicsequences problem, and a high frequency trading task using a time-series ofask/bid quotes and their corresponding volumes. Our experimental results usingsynthetic and real datasets verify the significant advantages of the UFCNNcompared to the RNN and LSTM baselines.
arxiv-12900-209 | Local Color Contrastive Descriptor for Image Classification | http://arxiv.org/abs/1508.00307 | author:Sheng Guo, Weilin Huang, Yu Qiao category:cs.CV published:2015-08-03 summary:Image representation and classification are two fundamental tasks towardsmultimedia content retrieval and understanding. The idea that shape and textureinformation (e.g. edge or orientation) are the key features for visualrepresentation is ingrained and dominated in current multimedia and computervision communities. A number of low-level features have been proposed bycomputing local gradients (e.g. SIFT, LBP and HOG), and have achieved greatsuccesses on numerous multimedia applications. In this paper, we present asimple yet efficient local descriptor for image classification, referred asLocal Color Contrastive Descriptor (LCCD), by leveraging the neural mechanismsof color contrast. The idea originates from the observation in neural sciencethat color and shape information are linked inextricably in visual corticalprocessing. The color contrast yields key information for visual colorperception and provides strong linkage between color and shape. We propose anovel contrastive mechanism to compute the color contrast in both spatiallocation and multiple channels. The color contrast is computed by measuring\emph{f}-divergence between the color distributions of two regions. Ourdescriptor enriches local image representation with both color and contrastinformation. We verified experimentally that it can compensate strongly for theshape based descriptor (e.g. SIFT), while keeping computationally simple.Extensive experimental results on image classification show that our descriptorimproves the performance of SIFT substantially by combinations, and achievesthe state-of-the-art performance on three challenging benchmark datasets. Itimproves recent Deep Learning model (DeCAF) [1] largely from the accuracy of40.94% to 49.68% in the large scale SUN397 database. Codes for the LCCD will beavailable.
arxiv-12900-210 | Compositional Semantic Parsing on Semi-Structured Tables | http://arxiv.org/abs/1508.00305 | author:Panupong Pasupat, Percy Liang category:cs.CL published:2015-08-03 summary:Two important aspects of semantic parsing for question answering are thebreadth of the knowledge source and the depth of logical compositionality.While existing work trades off one aspect for another, this papersimultaneously makes progress on both fronts through a new task: answeringcomplex questions on semi-structured tables using question-answer pairs assupervision. The central challenge arises from two compounding factors: thebroader domain results in an open-ended set of relations, and the deepercompositionality results in a combinatorial explosion in the space of logicalforms. We propose a logical-form driven parsing algorithm guided by strongtyping constraints and show that it obtains significant improvements overnatural baselines. For evaluation, we created a new dataset of 22,033 complexquestions on Wikipedia tables, which is made publicly available.
arxiv-12900-211 | Identifying Emotion from Natural Walking | http://arxiv.org/abs/1508.00413 | author:Liqing Cui, Shun Li, Wan Zhang, Zhan Zhang, Tingshao Zhu category:cs.CV cs.HC published:2015-08-03 summary:Emotion identification from gait aims to automatically determine personsaffective state, it has attracted a great deal of interests and offered immensepotential value in action tendency, health care, psychological detection andhuman-computer(robot) interaction.In this paper, we propose a new method ofidentifying emotion from natural walking, and analyze the relevance between thetraits of walking and affective states. After obtaining the pure accelerationdata of wrist and ankle, we set a moving average filter window with differentsizes w, then extract 114 features including time-domain, frequency-domain,power and distribution features from each data slice, and run principalcomponent analysis (PCA) to reduce dimension. In experiments, we train SVM,Decision Tree, multilayerperception, Random Tree and Random Forestclassification models, and compare the classification accuracy on data of wristand ankle with respect to different w. The performance of emotionidentification on acceleration data of ankle is better than wrist.Comparingdifferent classification models' results, SVM has best accuracy of identifyinganger and happy could achieve 90:31% and 89:76% respectively, andidentification ratio of anger-happy is 87:10%.The anger-neutral-happyclassification reaches 85%-78%-78%.The results show that it is capable ofidentifying personal emotional states through the gait of walking.
arxiv-12900-212 | When Crowdsourcing Meets Mobile Sensing: A Social Network Perspective | http://arxiv.org/abs/1508.00299 | author:Pin-Yu Chen, Shin-Ming Cheng, Pai-Shun Ting, Chia-Wei Lien, Fu-Jen Chu category:cs.SI stat.ML published:2015-08-03 summary:Mobile sensing is an emerging technology that utilizes agent-participatorydata for decision making or state estimation, including multimediaapplications. This article investigates the structure of mobile sensing schemesand introduces crowdsourcing methods for mobile sensing. Inspired by socialnetwork, one can establish trust among participatory agents to leverage thewisdom of crowds for mobile sensing. A prototype of social network inspiredmobile multimedia and sensing application is presented for illustrativepurpose. Numerical experiments on real-world datasets show improved performanceof mobile sensing via crowdsourcing. Challenges for mobile sensing with respectto Internet layers are discussed.
arxiv-12900-213 | Maintaining prediction quality under the condition of a growing knowledge space | http://arxiv.org/abs/1508.00509 | author:Christoph Jahnz category:cs.AI cs.LG published:2015-08-03 summary:Intelligence can be understood as an agent's ability to predict itsenvironment's dynamic by a level of precision which allows it to effectivelyforesee opportunities and threats. Under the assumption that such intelligencerelies on a knowledge space any effective reasoning would benefit from amaximum portion of useful and a minimum portion of misleading knowledgefragments. It begs the question of how the quality of such knowledge space canbe kept high as the amount of knowledge keeps growing. This article proposes amathematical model to describe general principles of how quality of a growingknowledge space evolves depending on error rate, error propagation andcountermeasures. There is also shown to which extend the quality of a knowledgespace collapses as removal of low quality knowledge fragments occurs too slowlyfor a given knowledge space's growth rate.
arxiv-12900-214 | On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units | http://arxiv.org/abs/1508.00330 | author:Zhibin Liao, Gustavo Carneiro category:cs.CV cs.LG cs.NE published:2015-08-03 summary:Deep feedforward neural networks with piecewise linear activations arecurrently producing the state-of-the-art results in several public datasets.The combination of deep learning models and piecewise linear activationfunctions allows for the estimation of exponentially complex functions with theuse of a large number of subnetworks specialized in the classification ofsimilar input examples. During the training process, these subnetworks avoidoverfitting with an implicit regularization scheme based on the fact that theymust share their parameters with other subnetworks. Using this framework, wehave made an empirical observation that can improve even more the performanceof such models. We notice that these models assume a balanced initialdistribution of data points with respect to the domain of the piecewise linearactivation function. If that assumption is violated, then the piecewise linearactivation units can degenerate into purely linear activation units, which canresult in a significant reduction of their capacity to learn complex functions.Furthermore, as the number of model layers increases, this unbalanced initialdistribution makes the model ill-conditioned. Therefore, we propose theintroduction of batch normalisation units into deep feedforward neural networkswith piecewise linear activations, which drives a more balanced use of theseactivation units, where each region of the activation function is trained witha relatively large proportion of training samples. Also, this batchnormalisation promotes the pre-conditioning of very deep learning models. Weshow that by introducing maxout and batch normalisation units to the network innetwork model results in a model that produces classification results that arebetter than or comparable to the current state of the art in CIFAR-10,CIFAR-100, MNIST, and SVHN datasets.
arxiv-12900-215 | Integrated Inference and Learning of Neural Factors in Structural Support Vector Machines | http://arxiv.org/abs/1508.00451 | author:Rein Houthooft, Filip De Turck category:stat.ML cs.CV cs.LG cs.NE published:2015-08-03 summary:Tackling pattern recognition problems in areas such as computer vision,bioinformatics, speech or text recognition is often done best by taking intoaccount task-specific statistical relations between output variables. Instructured prediction, this internal structure is used to predict multipleoutputs simultaneously, leading to more accurate and coherent predictions.Structural support vector machines (SSVMs) are nonprobabilistic models thatoptimize a joint input-output function through margin-based learning. BecauseSSVMs generally disregard the interplay between unary and interaction factorsduring the training phase, final parameters are suboptimal. Moreover, itsfactors are often restricted to linear combinations of input features, limitingits generalization power. To improve prediction accuracy, this paper proposes:(i) Joint inference and learning by integration of back-propagation andloss-augmented inference in SSVM subgradient descent; (ii) Extending SSVMfactors to neural networks that form highly nonlinear functions of inputfeatures. Image segmentation benchmark results demonstrate improvements overconventional SSVM training methods in terms of accuracy, highlighting thefeasibility of end-to-end SSVM training with neural factors.
arxiv-12900-216 | Dictionary and Image Recovery from Incomplete and Random Measurements | http://arxiv.org/abs/1508.00278 | author:Mohammad Aghagolzadeh, Hayder Radha category:cs.CV published:2015-08-02 summary:This paper tackles algorithmic and theoretical aspects of dictionary learningfrom incomplete and random block-wise image measurements and the performance ofthe adaptive dictionary for sparse image recovery. This problem is related toblind compressed sensing in which the sparsifying dictionary or basis is viewedas an unknown variable and subject to estimation during sparse recovery.However, unlike existing guarantees for a successful blind compressed sensing,our results do not rely on additional structural constraints on the learneddictionary or the measured signal. In particular, we rely on the spatialdiversity of compressive measurements to guarantee that the solution is uniquewith a high probability. Moreover, our distinguishing goal is to measure andreduce the estimation error with respect to the ideal dictionary that is basedon the complete image. Using recent results from random matrix theory, we showthat applying a slightly modified dictionary learning algorithm overcompressive measurements results in accurate estimation of the ideal dictionaryfor large-scale images. Empirically, we experiment with both space-invariantand space-varying sensing matrices and demonstrate the critical role of spatialdiversity in measurements. Simulation results confirm that the presentedalgorithm outperforms the typical non-adaptive sparse recovery based onoffline-learned universal dictionaries.
arxiv-12900-217 | Partial matching face recognition method for rehabilitation nursing robots beds | http://arxiv.org/abs/1508.00239 | author:Dongmei Liang, Wushan Cheng category:cs.CV published:2015-08-02 summary:In order to establish face recognition system in rehabilitation nursingrobots beds and achieve real-time monitor the patient on the bed. We propose aface recognition method based on partial matching Hu moments which apply forrehabilitation nursing robots beds. Firstly we using Haar classifier to detecthuman faces automatically in dynamic video frames. Secondly we using Otsuthreshold method to extract facial features (eyebrows, eyes, mouth) in the faceimage and its Hu moments. Finally, we using Hu moment feature set to achievethe automatic face recognition. Experimental results show that this method canefficiently identify face in a dynamic video and it has high practical value(the accuracy rate is 91% and the average recognition time is 4.3s).
arxiv-12900-218 | Toward a Robust Sparse Data Representation for Wireless Sensor Networks | http://arxiv.org/abs/1508.00230 | author:Mohammad Abu Alsheikh, Shaowei Lin, Hwee-Pink Tan, Dusit Niyato category:cs.NI cs.LG cs.NE published:2015-08-02 summary:Compressive sensing has been successfully used for optimized operations inwireless sensor networks. However, raw data collected by sensors may be neitheroriginally sparse nor easily transformed into a sparse data representation.This paper addresses the problem of transforming source data collected bysensor nodes into a sparse representation with a few nonzero elements. Ourcontributions that address three major issues include: 1) an effective methodthat extracts population sparsity of the data, 2) a sparsity ratio guaranteescheme, and 3) a customized learning algorithm of the sparsifying dictionary.We introduce an unsupervised neural network to extract an intrinsic sparsecoding of the data. The sparse codes are generated at the activation of thehidden layer using a sparsity nomination constraint and a shrinking mechanism.Our analysis using real data samples shows that the proposed method outperformsconventional sparsity-inducing methods.
arxiv-12900-219 | On Hyperspectral Classification in the Compressed Domain | http://arxiv.org/abs/1508.00282 | author:Mohammad Aghagolzadeh, Hayder Radha category:cs.CV published:2015-08-02 summary:In this paper, we study the problem of hyperspectral pixel classificationbased on the recently proposed architectures for compressive whisk-broomhyperspectral imagers without the need to reconstruct the complete data cube. Aclear advantage of classification in the compressed domain is its suitabilityfor real-time on-site processing of the sensed data. Moreover, it is assumedthat the training process also takes place in the compressed domain, thus,isolating the classification unit from the recovery unit at the receiver'sside. We show that, perhaps surprisingly, using distinct measurement matricesfor different pixels results in more accuracy of the learned classifier andconsistent classification performance, supporting the role of informationdiversity in learning.
arxiv-12900-220 | PTE: Predictive Text Embedding through Large-scale Heterogeneous Text Networks | http://arxiv.org/abs/1508.00200 | author:Jian Tang, Meng Qu, Qiaozhu Mei category:cs.CL cs.LG cs.NE I.2.6 published:2015-08-02 summary:Unsupervised text embedding methods, such as Skip-gram and Paragraph Vector,have been attracting increasing attention due to their simplicity, scalability,and effectiveness. However, comparing to sophisticated deep learningarchitectures such as convolutional neural networks, these methods usuallyyield inferior results when applied to particular machine learning tasks. Onepossible reason is that these text embedding methods learn the representationof text in a fully unsupervised way, without leveraging the labeled informationavailable for the task. Although the low dimensional representations learnedare applicable to many different tasks, they are not particularly tuned for anytask. In this paper, we fill this gap by proposing a semi-supervisedrepresentation learning method for text data, which we call the\textit{predictive text embedding} (PTE). Predictive text embedding utilizesboth labeled and unlabeled data to learn the embedding of text. The labeledinformation and different levels of word co-occurrence information are firstrepresented as a large-scale heterogeneous text network, which is then embeddedinto a low dimensional space through a principled and efficient algorithm. Thislow dimensional embedding not only preserves the semantic closeness of wordsand documents, but also has a strong predictive power for the particular task.Compared to recent supervised approaches based on convolutional neuralnetworks, predictive text embedding is comparable or more effective, much moreefficient, and has fewer parameters to tune.
arxiv-12900-221 | Optimal Radio Frequency Energy Harvesting with Limited Energy Arrival Knowledge | http://arxiv.org/abs/1508.00285 | author:Zhenhua Zou, Anders Gidmark, Themistoklis Charalambous, Mikael Johansson category:cs.IT cs.LG math.IT published:2015-08-02 summary:In this paper, we develop optimal policies for deciding when a wireless nodewith radio frequency (RF) energy harvesting (EH) capabilities should try andharvest ambient RF energy. While the idea of RF-EH is appealing, it is notalways beneficial to attempt to harvest energy; in environments where theambient energy is low, nodes could consume more energy being awake with theirharvesting circuits turned on than what they can extract from the ambient radiosignals; it is then better to enter a sleep mode until the ambient RF energyincreases. Towards this end, we consider a scenario with intermittent energyarrivals and a wireless node that wakes up for a period of time (herein calledthe time-slot) and harvests energy. If enough energy is harvested during thetime-slot, then the harvesting is successful and excess energy is stored;however, if there does not exist enough energy the harvesting is unsuccessfuland energy is lost. We assume that the ambient energy level is constant during the time-slot, andchanges at slot boundaries. The energy level dynamics are described by atwo-state Gilbert-Elliott Markov chain model, where the state of the Markovchain can only be observed during the harvesting action, and not when in sleepmode. Two scenarios are studied under this model. In the first scenario, weassume that we have knowledge of the transition probabilities of the Markovchain and formulate the problem as a Partially Observable Markov DecisionProcess (POMDP), where we find a threshold-based optimal policy. In the secondscenario, we assume that we don't have any knowledge about these parameters andformulate the problem as a Bayesian adaptive POMDP; to reduce the complexity ofthe computations we also propose a heuristic posterior sampling algorithm. Theperformance of our approaches is demonstrated via numerical examples.
arxiv-12900-222 | Class Vectors: Embedding representation of Document Classes | http://arxiv.org/abs/1508.00189 | author:Devendra Singh Sachan, Shailesh Kumar category:cs.CL cs.IR published:2015-08-02 summary:Distributed representations of words and paragraphs as semantic embeddings inhigh dimensional data are used across a number of Natural LanguageUnderstanding tasks such as retrieval, translation, and classification. In thiswork, we propose "Class Vectors" - a framework for learning a vector per classin the same embedding space as the word and paragraph embeddings. Similaritybetween these class vectors and word vectors are used as features to classify adocument to a class. In experiment on several sentiment analysis tasks such asYelp reviews and Amazon electronic product reviews, class vectors have shownbetter or comparable results in classification while learning very meaningfulclass embeddings.
arxiv-12900-223 | An Analytic Framework for Maritime Situation Analysis | http://arxiv.org/abs/1508.00181 | author:Hamed Yaghoubi Shahir, Uwe Glässer, Amir Yaghoubi Shahir, Hans Wehn category:cs.LG published:2015-08-02 summary:Maritime domain awareness is critical for protecting sea lanes, ports,harbors, offshore structures and critical infrastructures against commonthreats and illegal activities. Limited surveillance resources constrainmaritime domain awareness and compromise full security coverage at all times.This situation calls for innovative intelligent systems for interactivesituation analysis to assist marine authorities and security personal in theirroutine surveillance operations. In this article, we propose a novel situationanalysis framework to analyze marine traffic data and differentiate variousscenarios of vessel engagement for the purpose of detecting anomalies ofinterest for marine vessels that operate over some period of time in relativeproximity to each other. The proposed framework views vessel behavior asprobabilistic processes and uses machine learning to model common vesselinteraction patterns. We represent patterns of interest as left-to-right HiddenMarkov Models and classify such patterns using Support Vector Machines.
arxiv-12900-224 | Indexing of CNN Features for Large Scale Image Search | http://arxiv.org/abs/1508.00217 | author:Ruoyu Liu, Yao Zhao, Shikui Wei, Zhenfeng Zhu, Lixin Liao, Shuang Qiu category:cs.CV published:2015-08-02 summary:Convolutional neural network (CNN) feature that represents an image with aglobal and high-dimensional vector has shown highly discriminative capabilityin image search. Although CNN features are more compact than most of localrepresentation schemes, it still cannot efficiently deal with large-scale imagesearch issues due to its non-negligible computational cost and storage usage.In this paper, we propose a simple but effective image indexing framework toimprove the computational and storage efficiency of CNN features. Instead ofprojecting each CNN feature vector into a global hashing code, the proposedframework adapts Bag-of-Word model and inverted table to global featureindexing. To this end, two strategies, which are based on semantic informationassociated with CNN features, are proposed to convert a global vector to one orseveral discrete words. In addition, several strategies for compensatingquantization error are fully investigated under the indexing framework.Extensive experimental results on two public benchmarks show the superiority ofour framework.
arxiv-12900-225 | Recurrent Network Models for Human Dynamics | http://arxiv.org/abs/1508.00271 | author:Katerina Fragkiadaki, Sergey Levine, Panna Felsen, Jitendra Malik category:cs.CV published:2015-08-02 summary:We propose the Encoder-Recurrent-Decoder (ERD) model for recognition andprediction of human body pose in videos and motion capture. The ERD model is arecurrent neural network that incorporates nonlinear encoder and decodernetworks before and after recurrent layers. We test instantiations of ERDarchitectures in the tasks of motion capture (mocap) generation, body poselabeling and body pose forecasting in videos. Our model handles mocap trainingdata across multiple subjects and activity domains, and synthesizes novelmotions while avoid drifting for long periods of time. For human pose labeling,ERD outperforms a per frame body part detector by resolving left-right bodypart confusions. For video pose forecasting, ERD predicts body jointdisplacements across a temporal horizon of 400ms and outperforms a first ordermotion model based on optical flow. ERDs extend previous Long Short Term Memory(LSTM) models in the literature to jointly learn representations and theirdynamics. Our experiments show such representation learning is crucial for bothlabeling and prediction in space-time. We find this is a distinguishing featurebetween the spatio-temporal visual domain in comparison to 1D text, speech orhandwriting, where straightforward hard coded representations have shownexcellent results when directly combined with recurrent units.
arxiv-12900-226 | Separated by an Un-common Language: Towards Judgment Language Informed Vector Space Modeling | http://arxiv.org/abs/1508.00106 | author:Ira Leviant, Roi Reichart category:cs.CL published:2015-08-01 summary:A common evaluation practice in the vector space models (VSMs) literature isto measure the models' ability to predict human judgments about lexicalsemantic relations between word pairs. Most existing evaluation sets, however,consist of scores collected for English word pairs only, ignoring the potentialimpact of the judgment language in which word pairs are presented on the humanscores. In this paper we translate two prominent evaluation sets, wordsim353(association) and SimLex999 (similarity), from English to Italian, German andRussian and collect scores for each dataset from crowdworkers fluent in itslanguage. Our analysis reveals that human judgments are strongly impacted bythe judgment language. Moreover, we show that the predictions of monolingualVSMs do not necessarily best correlate with human judgments made with thelanguage used for model training, suggesting that models and humans areaffected differently by the language they use when making semantic judgments.Finally, we show that in a large number of setups, multilingual VSM combinationresults in improved correlations with human judgments, suggesting thatmultilingualism may partially compensate for the judgment language effect onhuman judgments.
arxiv-12900-227 | The Interactive Effects of Operators and Parameters to GA Performance Under Different Problem Sizes | http://arxiv.org/abs/1508.00097 | author:Jaderick P. Pabico, Elizer A. Albacea category:cs.NE published:2015-08-01 summary:The complex effect of genetic algorithm's (GA) operators and parameters toits performance has been studied extensively by researchers in the past butnone studied their interactive effects while the GA is under different problemsizes. In this paper, We present the use of experimental model (1)~toinvestigate whether the genetic operators and their parameters interact toaffect the offline performance of GA, (2)~to find what combination of geneticoperators and parameter settings will provide the optimum performance for GA,and (3)~to investigate whether these operator-parameter combination isdependent on the problem size. We designed a GA to optimize a family oftraveling salesman problems (TSP), with their optimal solutions known forconvenient benchmarking. Our GA was set to use different algorithms insimulating selection ($\Omega_s$), different algorithms ($\Omega_c$) andparameters ($p_c$) in simulating crossover, and different parameters ($p_m$) insimulating mutation. We used several $n$-city TSPs ($n=\{5, 7, 10, 100,1000\}$) to represent the different problem sizes (i.e., size of the resultingsearch space as represented by GA schemata). Using analysis of variance of3-factor factorial experiments, we found out that GA performance is affected by$\Omega_s$ at small problem size (5-city TSP) where the algorithm PartiallyMatched Crossover significantly outperforms Cycle Crossover at $95\%$confidence level.
arxiv-12900-228 | Land Use Classification in Remote Sensing Images by Convolutional Neural Networks | http://arxiv.org/abs/1508.00092 | author:Marco Castelluccio, Giovanni Poggi, Carlo Sansone, Luisa Verdoliva category:cs.CV published:2015-08-01 summary:We explore the use of convolutional neural networks for the semanticclassification of remote sensing scenes. Two recently proposed architectures,CaffeNet and GoogLeNet, are adopted, with three different learning modalities.Besides conventional training from scratch, we resort to pre-trained networksthat are only fine-tuned on the target data, so as to avoid overfittingproblems and reduce design time. Experiments on two remote sensing datasets,with markedly different characteristics, testify on the effectiveness and wideapplicability of the proposed solution, which guarantees a significantperformance improvement over all state-of-the-art references.
arxiv-12900-229 | Towards Distortion-Predictable Embedding of Neural Networks | http://arxiv.org/abs/1508.00102 | author:Axel Angel category:cs.CV published:2015-08-01 summary:Current research in Computer Vision has shown that Convolutional NeuralNetworks (CNN) give state-of-the-art performance in many classification tasksand Computer Vision problems. The embedding of CNN, which is the internalrepresentation produced by the last layer, can indirectly learn topological andrelational properties. Moreover, by using a suitable loss function, CNN modelscan learn invariance to a wide range of non-linear distortions such asrotation, viewpoint angle or lighting condition. In this work, new insights arediscovered about CNN embeddings and a new loss function is proposed, derivedfrom the contrastive loss, that creates models with more predicable mappingsand also quantifies distortions. In typical distortion-dependent methods, thereis no simple relation between the features corresponding to one image and thefeatures of this image distorted. Therefore, these methods require tofeed-forward inputs under every distortions in order to find the correspondingfeatures representations. Our contribution makes a step towards embeddingswhere features of distorted inputs are related and can be derived from eachothers by the intensity of the distortion.
arxiv-12900-230 | Regularized Multi-Task Learning for Multi-Dimensional Log-Density Gradient Estimation | http://arxiv.org/abs/1508.00085 | author:Ikko Yamane, Hiroaki Sasaki, Masashi Sugiyama category:stat.ML published:2015-08-01 summary:Log-density gradient estimation is a fundamental statistical problem andpossesses various practical applications such as clustering and measuringnon-Gaussianity. A naive two-step approach of first estimating the density andthen taking its log-gradient is unreliable because an accurate density estimatedoes not necessarily lead to an accurate log-density gradient estimate. To copewith this problem, a method to directly estimate the log-density gradientwithout density estimation has been explored, and demonstrated to work muchbetter than the two-step method. The objective of this paper is to furtherimprove the performance of this direct method in multi-dimensional cases. Ouridea is to regard the problem of log-density gradient estimation in eachdimension as a task, and apply regularized multi-task learning to the directlog-density gradient estimator. We experimentally demonstrate the usefulness ofthe proposed multi-task method in log-density gradient estimation andmode-seeking clustering.
arxiv-12900-231 | Turnover Prediction Of Shares using Data Mining techniques : A Case Study | http://arxiv.org/abs/1508.00088 | author:D. S. Shashaank, V. Sruthi, M. L. S Vijayalakshimi, Jacob Shomona Garcia category:cs.LG published:2015-08-01 summary:Predicting the turnover of a company in the ever fluctuating Stock market hasalways proved to be a precarious situation and most certainly a difficult taskin hand. Data mining is a well-known sphere of Computer Science that aims onextracting meaningful information from large databases. However, despite theexistence of many algorithms for the purpose of predicting the future trends,their efficiency is questionable as their predictions suffer from a high errorrate. The objective of this paper is to investigate various classificationalgorithms to predict the turnover of different companies based on the Stockprice. The authorized dataset for predicting the turnover was taken fromwww.bsc.com and included the stock market values of various companies over thepast 10 years. The algorithms were investigated using the "R" tool. The featureselection algorithm, Boruta, was run on this dataset to extract the importantand influential features for classification. With these extracted features, theTotal Turnover of the company was predicted using various classificationalgorithms like Random Forest, Decision Tree, SVM and Multinomial Regression.This prediction mechanism was implemented to predict the turnover of a companyon an everyday basis and hence could help navigate through dubious stock markettrades. An accuracy rate of 95% was achieved by the above prediction process.Moreover, the importance of stock market attributes was established as well.
arxiv-12900-232 | Quantitative evaluation of the performance of discrete-time reservoir computers in the forecasting, filtering, and reconstruction of stochastic stationary signals | http://arxiv.org/abs/1508.00144 | author:Lyudmila Grigoryeva, Julie Henriques, Juan-Pablo Ortega category:cs.ET cs.NE math.ST stat.TH published:2015-08-01 summary:This paper extends the notion of information processing capacity fornon-independent input signals in the context of reservoir computing (RC). Thepresence of input autocorrelation makes worthwhile the treatment of forecastingand filtering problems for which we explicitly compute this generalizedcapacity as a function of the reservoir parameter values using a streamlinedmodel. The reservoir model leading to these developments is used to show that,whenever that approximation is valid, this computational paradigm satisfies theso called separation and fading memory properties that are usually associatedwith good information processing performances. We show that several standardmemory, forecasting, and filtering problems that appear in the parametricstochastic time series context can be readily formulated and tackled via RCwhich, as we show, significantly outperforms standard techniques in someinstances.
arxiv-12900-233 | Action-Conditional Video Prediction using Deep Networks in Atari Games | http://arxiv.org/abs/1507.08750 | author:Junhyuk Oh, Xiaoxiao Guo, Honglak Lee, Richard Lewis, Satinder Singh category:cs.LG cs.AI cs.CV published:2015-07-31 summary:Motivated by vision-based reinforcement learning (RL) problems, in particularAtari games from the recent benchmark Aracade Learning Environment (ALE), weconsider spatio-temporal prediction problems where future (image-)frames aredependent on control variables or actions as well as previous frames. While notcomposed of natural scenes, frames in Atari games are high-dimensional in size,can involve tens of objects with one or more objects being controlled by theactions directly and many other objects being influenced indirectly, caninvolve entry and departure of objects, and can involve deep partialobservability. We propose and evaluate two deep neural network architecturesthat consist of encoding, action-conditional transformation, and decodinglayers based on convolutional neural networks and recurrent neural networks.Experimental results show that the proposed architectures are able to generatevisually-realistic frames that are also useful for control over approximately100-step action-conditional futures in some games. To the best of ourknowledge, this paper is the first to make and evaluate long-term predictionson high-dimensional video conditioned by control inputs.
arxiv-12900-234 | Hidden Markov Models for Gene Sequence Classification: Classifying the VSG genes in the Trypanosoma brucei Genome | http://arxiv.org/abs/1508.05367 | author:Andrea Mesa, Sebastián Basterrech, Gustavo Guerberoff, Fernando Alvarez-Valin category:q-bio.GN cs.CE cs.LG published:2015-07-31 summary:The article presents an application of Hidden Markov Models (HMMs) forpattern recognition on genome sequences. We apply HMM for identifying genesencoding the Variant Surface Glycoprotein (VSG) in the genomes of Trypanosomabrucei (T. brucei) and other African trypanosomes. These are parasitic protozoacausative agents of sleeping sickness and several diseases in domestic and wildanimals. These parasites have a peculiar strategy to evade the host's immunesystem that consists in periodically changing their predominant cellularsurface protein (VSG). The motivation for using patterns recognition methods toidentify these genes, instead of traditional homology based ones, is that thelevels of sequence identity (amino acid and DNA sequence) amongst these genesis often below of what is considered reliable in these methods. Among patternrecognition approaches, HMM are particularly suitable to tackle this problembecause they can handle more naturally the determination of gene edges. Weevaluate the performance of the model using different number of states in theMarkov model, as well as several performance metrics. The model is appliedusing public genomic data. Our empirical results show that the VSG genes on T.brucei can be safely identified (high sensitivity and low rate of falsepositives) using HMM.
arxiv-12900-235 | Artificial Neural Networks Applied to Taxi Destination Prediction | http://arxiv.org/abs/1508.00021 | author:Alexandre de Brébisson, Étienne Simon, Alex Auvolat, Pascal Vincent, Yoshua Bengio category:cs.LG cs.NE published:2015-07-31 summary:We describe our first-place solution to the ECML/PKDD discovery challenge ontaxi destination prediction. The task consisted in predicting the destinationof a taxi based on the beginning of its trajectory, represented as avariable-length sequence of GPS points, and diverse associatedmeta-information, such as the departure time, the driver id and clientinformation. Contrary to most published competitor approaches, we used analmost fully automated approach based on neural networks and we ranked firstout of 381 teams. The architectures we tried use multi-layer perceptrons,bidirectional recurrent neural networks and models inspired from recentlyintroduced memory networks. Our approach could easily be adapted to otherapplications in which the goal is to predict a fixed-length output from avariable-length sequence.
arxiv-12900-236 | Beyond Gauss: Image-Set Matching on the Riemannian Manifold of PDFs | http://arxiv.org/abs/1507.08711 | author:Mehrtash Harandi, Mathieu Salzmann, Mahsa Baktashmotlagh category:cs.CV published:2015-07-31 summary:State-of-the-art image-set matching techniques typically implicitly modeleach image-set with a Gaussian distribution. Here, we propose to go beyondthese representations and model image-sets as probability distributionfunctions (PDFs) using kernel density estimators. To compare and matchimage-sets, we exploit Csiszar f-divergences, which bear strong connections tothe geodesic distance defined on the space of PDFs, i.e., the statisticalmanifold. Furthermore, we introduce valid positive definite kernels on thestatistical manifolds, which let us make use of more powerful classificationschemes to match image-sets. Finally, we introduce a supervised dimensionalityreduction technique that learns a latent space where f-divergences reflect theclass labels of the data. Our experiments on diverse problems, such asvideo-based face recognition and dynamic texture classification, evidence thebenefits of our approach over the state-of-the-art image-set matching methods.
arxiv-12900-237 | Fast Stochastic Algorithms for SVD and PCA: Convergence Properties and Convexity | http://arxiv.org/abs/1507.08788 | author:Ohad Shamir category:cs.LG cs.NA math.NA math.OC stat.ML published:2015-07-31 summary:We study the convergence properties of the VR-PCA algorithm introduced by\cite{shamir2015stochastic} for fast computation of leading singular vectors.We prove several new results, including a formal analysis of a block version ofthe algorithm, and convergence from random initialization. We also make a fewobservations of independent interest, such as how pre-initializing with just asingle exact power iteration can significantly improve the runtime ofstochastic methods, and what are the convexity and non-convexity properties ofthe underlying optimization problem.
arxiv-12900-238 | Deep Networks for Image Super-Resolution with Sparse Prior | http://arxiv.org/abs/1507.08905 | author:Zhaowen Wang, Ding Liu, Jianchao Yang, Wei Han, Thomas Huang category:cs.CV published:2015-07-31 summary:Deep learning techniques have been successfully applied in many areas ofcomputer vision, including low-level image restoration problems. For imagesuper-resolution, several models based on deep neural networks have beenrecently proposed and attained superior performance that overshadows allprevious handcrafted models. The question then arises whether large-capacityand data-driven models have become the dominant solution to the ill-posedsuper-resolution problem. In this paper, we argue that domain expertiserepresented by the conventional sparse coding model is still valuable, and itcan be combined with the key ingredients of deep learning to achieve furtherimproved results. We show that a sparse coding model particularly designed forsuper-resolution can be incarnated as a neural network, and trained in acascaded structure from end to end. The interpretation of the network based onsparse coding leads to much more efficient and effective training, as well as areduced model size. Our model is evaluated on a wide range of images, and showsclear advantage over existing state-of-the-art methods in terms of bothrestoration accuracy and human subjective quality.
arxiv-12900-239 | A Visual Embedding for the Unsupervised Extraction of Abstract Semantics | http://arxiv.org/abs/1507.08818 | author:D. Garcia-Gasulla, J. Béjar, U. Cortés, E. Ayguadé, J. Labarta category:cs.CV cs.LG cs.NE published:2015-07-31 summary:Vector-space word representations obtained from neural network models havebeen shown to enable semantic operations based on vector arithmetic. In thispaper, we explore the existence of similar information on vectorrepresentations of images. For that purpose we define a methodology to obtainlarge, sparse vector representations of image classes, and generate vectorsthrough the state-of-the-art deep learning architecture GoogLeNet for 20Kimages obtained from ImageNet. We first evaluate the resultant vector-spacesemantics through its correlation with WordNet distances, and find vectordistances to be strongly correlated with linguistic semantics. We then explorethe location of images within the vector space, finding elements close inWordNet to be clustered together, regardless of significant visual variances(e.g., 118 dog types). More surprisingly, we find that the space unsupervisedlyseparates complex classes without prior knowledge (e.g., living things).Finally, we consider vector arithmetics, and find them to be related with imageconcatenation (e.g., "Horse cart - Horse = Rickshaw"), image overlap ("Panda -Brown bear = Skunk") and regularities ("Panda is to Brown bear as Soccer ballis to Helmet"). These results indicate that image vector embeddings as the oneproposed here contain rich visual semantics usable for learning and reasoningpurposes.
arxiv-12900-240 | A Sinc Wavelet Describes the Receptive Fields of Neurons in the Motion Cortex | http://arxiv.org/abs/1507.08736 | author:Stephen G. Odaibo category:q-bio.NC cs.CV cs.IT math.IT physics.bio-ph published:2015-07-31 summary:Visual perception results from a systematic transformation of the informationflowing through the visual system. In the neuronal hierarchy, the responseproperties of single neurons are determined by neurons located one level below,and in turn, determine the responses of neurons located one level above.Therefore in modeling receptive fields, it is essential to ensure that theresponse properties of neurons in a given level can be generated by combiningthe response models of neurons in its input levels. However, existing responsemodels of neurons in the motion cortex do not inherently yield the temporalfrequency filtering gradient (TFFG) property that is known to emerge along theprimary visual cortex (V1) to middle temporal (MT) motion processing stream.TFFG is the change from predominantly lowpass to predominantly bandpasstemporal frequency filtering character along the V1 to MT pathway (Foster et al1985; DeAngelis et al 1993; Hawken et al 1996). We devised a new model, thesinc wavelet model (Odaibo, 2014), which logically and efficiently generatesthe TFFG. The model replaces the Gabor function's sine wave carrier with a sinc(sin(x)/x) function, and has the same or fewer number of parameters as existingmodels. Because of its logical consistency with the emergent network propertyof TFFG, we conclude that the sinc wavelet is a better model for the receptivefields of motion cortex neurons. This model will provide new physiologicalinsights into how the brain represents visual information.
arxiv-12900-241 | A novel multivariate performance optimization method based on sparse coding and hyper-predictor learning | http://arxiv.org/abs/1507.08847 | author:Jiachen Yanga, Zhiyong Dinga, Fei Guoa, Huogen Wanga, Nick Hughesb category:cs.LG cs.CV cs.NA published:2015-07-31 summary:In this paper, we investigate the problem of optimization multivariateperformance measures, and propose a novel algorithm for it. Different fromtraditional machine learning methods which optimize simple loss functions tolearn prediction function, the problem studied in this paper is how to learneffective hyper-predictor for a tuple of data points, so that a complex lossfunction corresponding to a multivariate performance measure can be minimized.We propose to present the tuple of data points to a tuple of sparse codes via adictionary, and then apply a linear function to compare a sparse code against agive candidate class label. To learn the dictionary, sparse codes, andparameter of the linear function, we propose a joint optimization problem. Inthis problem, the both the reconstruction error and sparsity of sparse code,and the upper bound of the complex loss function are minimized. Moreover, theupper bound of the loss function is approximated by the sparse codes and thelinear function parameter. To optimize this problem, we develop an iterativealgorithm based on descent gradient methods to learn the sparse codes andhyper-predictor parameter alternately. Experiment results on some benchmarkdata sets show the advantage of the proposed methods over otherstate-of-the-art algorithms.
arxiv-12900-242 | An Optimal Algorithm for Bandit and Zero-Order Convex Optimization with Two-Point Feedback | http://arxiv.org/abs/1507.08752 | author:Ohad Shamir category:cs.LG math.OC stat.ML published:2015-07-31 summary:We consider the closely related problems of bandit convex optimization withtwo-point feedback, and zero-order stochastic convex optimization with twofunction evaluations per round. We provide a simple algorithm and analysiswhich is optimal for convex Lipschitz functions. This improves on\cite{dujww13}, which only provides an optimal result for smooth functions;Moreover, the algorithm and analysis are simpler, and readily extend tonon-Euclidean problems. The algorithm is based on a small but surprisinglypowerful modification of the gradient estimator.
arxiv-12900-243 | Flip-Rotate-Pooling Convolution and Split Dropout on Convolution Neural Networks for Image Classification | http://arxiv.org/abs/1507.08754 | author:Fa Wu, Peijun Hu, Dexing Kong category:cs.CV published:2015-07-31 summary:This paper presents a new version of Dropout called Split Dropout (sDropout)and rotational convolution techniques to improve CNNs' performance on imageclassification. The widely used standard Dropout has advantage of preventingdeep neural networks from overfitting by randomly dropping units duringtraining. Our sDropout randomly splits the data into two subsets and keeps bothrather than discards one subset. We also introduce two rotational convolutiontechniques, i.e. rotate-pooling convolution (RPC) and flip-rotate-poolingconvolution (FRPC) to boost CNNs' performance on the robustness for rotationtransformation. These two techniques encode rotation invariance into thenetwork without adding extra parameters. Experimental evaluations onImageNet2012 classification task demonstrate that sDropout not only enhancesthe performance but also converges faster. Additionally, RPC and FRPC make CNNsmore robust for rotation transformations. Overall, FRPC together with sDropoutbring $1.18\%$ (model of Zeiler and Fergus~\cite{zeiler2013visualizing},10-view, top-1) accuracy increase in ImageNet 2012 classification task comparedto the original network.
arxiv-12900-244 | Mobile Multi-View Object Image Search | http://arxiv.org/abs/1507.08861 | author:Fatih Çalışır, Özgür Ulusoy, Uğur Güdükbay, Muhammet Baştan category:cs.MM cs.CV published:2015-07-31 summary:High user interaction capability of mobile devices can help improve theaccuracy of mobile visual search systems. At query time, it is possible tocapture multiple views of an object from different viewing angles and atdifferent scales with the mobile device camera to obtain richer informationabout the object compared to a single view and hence return more accurateresults. Motivated by this, we developed a mobile multi-view object imagesearch system, using a client-server architecture. Multi-view images of objectsacquired by the mobile clients are processed and local features are sent to theserver, which combines the query image representations with early/late fusionmethods based on bag-of-visual-words and sends back the query results. Weperformed a comprehensive analysis of early and late fusion approaches usingvarious similarity functions, on an existing single view and a new multi-viewobject image database. The experimental results show that multi-view searchprovides significantly better retrieval accuracy compared to single viewsearch.
arxiv-12900-245 | Multimodal Multipart Learning for Action Recognition in Depth Videos | http://arxiv.org/abs/1507.08761 | author:Amir Shahroudy, Gang Wang, Tian-Tsong Ng, Qingxiong Yang category:cs.CV published:2015-07-31 summary:The articulated and complex nature of human actions makes the task of actionrecognition difficult. One approach to handle this complexity is dividing it tothe kinetics of body parts and analyzing the actions based on these partialdescriptors. We propose a joint sparse regression based learning method whichutilizes the structured sparsity to model each action as a combination ofmultimodal features from a sparse set of body parts. To represent dynamics andappearance of parts, we employ a heterogeneous set of depth and skeleton basedfeatures. The proper structure of multimodal multipart features are formulatedinto the learning framework via the proposed hierarchical mixed norm, toregularize the structured features of each part and to apply sparsity betweenthem, in favor of a group feature selection. Our experimental results exposethe effectiveness of the proposed learning method in which it outperforms othermethods in all three tested datasets while saturating one of them by achievingperfect accuracy.
arxiv-12900-246 | Spin Glass Models of Syntax and Language Evolution | http://arxiv.org/abs/1508.00504 | author:Karthik Siva, Jim Tao, Matilde Marcolli category:cs.CL physics.soc-ph 91F20, 82B20 published:2015-07-31 summary:Using the SSWL database of syntactic parameters of world languages, and theMIT Media Lab data on language interactions, we construct a spin glass model oflanguage evolution. We treat binary syntactic parameters as spin states, withlanguages as vertices of a graph, and assigned interaction energies along theedges. We study a rough model of syntax evolution, under the assumption that astrong interaction energy tends to cause parameters to align, as in the case offerromagnetic materials. We also study how the spin glass model needs to bemodified to account for entailment relations between syntactic parameters. Thismodification leads naturally to a generalization of Potts models with externalmagnetic field, which consists of a coupling at the vertices of an Ising modeland a Potts model with q=3, that have the same edge interactions. We describethe results of simulations of the dynamics of these models, in differenttemperature and energy regimes. We discuss the linguistic interpretation of theparameters of the physical model.
arxiv-12900-247 | Efficient and robust calibration of the Heston option pricing model for American options using an improved Cuckoo Search Algorithm | http://arxiv.org/abs/1507.08937 | author:Stefan Haring, Ronald Hochreiter category:cs.NE q-fin.PR published:2015-07-31 summary:In this paper an improved Cuckoo Search Algorithm is developed to allow foran efficient and robust calibration of the Heston option pricing model forAmerican options. Calibration of stochastic volatility models like the Hestonis significantly harder than classical option pricing models as more parametershave to be estimated. The difficult task of calibrating one of these models toAmerican Put options data is the main objective of this paper. Numericalresults are shown to substantiate the suitability of the chosen method totackle this problem.
arxiv-12900-248 | SnowWatch: Snow Monitoring through Acquisition and Analysis of User-Generated Content | http://arxiv.org/abs/1507.08958 | author:Roman Fedorov, Piero Fraternali, Chiara Pasini, Marco Tagliasacchi category:cs.CV cs.CY published:2015-07-31 summary:We present a system for complementing snow phenomena monitoring with virtualmeasurements extracted from public visual content. The proposed systemintegrates an automatic acquisition and analysis of photographs and webcamimages depicting Alpine mountains. In particular, the technical demonstrationconsists in a web portal that interfaces the whole system with the population.It acts as an entertaining photo-sharing social web site, acquiring at the sametime visual content necessary for environmental monitoring.
arxiv-12900-249 | A Model for Foraging Ants, Controlled by Spiking Neural Networks and Double Pheromones | http://arxiv.org/abs/1507.08467 | author:Cristian Jimenez-Romero, David Sousa-Rodrigues, Jeffrey H. Johnson, Vitorino Ramos category:cs.NE cs.AI published:2015-07-30 summary:A model of an Ant System where ants are controlled by a spiking neuralcircuit and a second order pheromone mechanism in a foraging task is presented.A neural circuit is trained for individual ants and subsequently the ants areexposed to a virtual environment where a swarm of ants performed a resourceforaging task. The model comprises an associative and unsupervised learningstrategy for the neural circuit of the ant. The neural circuit adapts to theenvironment by means of classical conditioning. The initially unknownenvironment includes different types of stimuli representing food and obstacleswhich, when they come in direct contact with the ant, elicit a reflex responsein the motor neural system of the ant: moving towards or away from the sourceof the stimulus. The ants are released on a landscape with multiple foodsources where one ant alone would have difficulty harvesting the landscape tomaximum efficiency. The introduction of a double pheromone mechanism yieldsbetter results than traditional ant colony optimization strategies. Traditionalant systems include mainly a positive reinforcement pheromone. This approachuses a second pheromone that acts as a marker for forbidden paths (negativefeedback). This blockade is not permanent and is controlled by the evaporationrate of the pheromones. The combined action of both pheromones acts as acollective stigmergic memory of the swarm, which reduces the search space ofthe problem. This paper explores how the adaptation and learning abilitiesobserved in biologically inspired cognitive architectures is synergisticallyenhanced by swarm optimization strategies. The model portraits two forms ofartificial intelligent behaviour: at the individual level the spiking neuralnetwork is the main controller and at the collective level the pheromonedistribution is a map towards the solution emerged by the colony.
arxiv-12900-250 | Agglomerative clustering and collectiveness measure via exponent generating function | http://arxiv.org/abs/1507.08571 | author:Wei-Ya Ren, Shuo-Hao Li, Qiang Guo, Guo-Hui Li, Jun Zhang category:cs.CV cs.GR published:2015-07-30 summary:The key in agglomerative clustering is to define the affinity measure betweentwo sets. A novel agglomerative clustering method is proposed by utilizing thepath integral to define the affinity measure. Firstly, the path integraldescriptor of an edge, a node and a set is computed by path integral andexponent generating function. Then, the affinity measure between two sets isobtained by path integral descriptor of sets. Several good properties of thepath integral descriptor is proposed in this paper. In addition, we give thephysical interpretation of the proposed path integral descriptor of a set. Theproposed path integral descriptor of a set can be regard as the collectivenessmeasure of a set, which can be a moving system such as human crowd, sheep herdand so on. Self-driven particle (SDP) model is used to test the ability of theproposed method in measuring collectiveness.
arxiv-12900-251 | One model, two languages: training bilingual parsers with harmonized treebanks | http://arxiv.org/abs/1507.08449 | author:David Vilares, Carlos Gómez-Rodríguez, Miguel A. Alonso category:cs.CL published:2015-07-30 summary:We introduce an approach to train lexicalized parsers using bilingual corporaobtained by merging harmonized treebanks of different languages, producingparsers that can analyze sentences in either of the learned languages, or evensentences that mix both. We test the approach on the Universal DependencyTreebanks, training with MaltParser and MaltOptimizer. The results show thatthese bilingual parsers are more than competitive, as most combinations notonly preserve accuracy, but some even achieve significant improvements over thecorresponding monolingual parsers. Preliminary experiments also show theapproach to be promising on texts with code-switching and when more languagesare added.
arxiv-12900-252 | Information-theoretical analysis of the statistical dependencies among three variables: Applications to written language | http://arxiv.org/abs/1508.03530 | author:Damián G. Hernández, Damián H. Zanette, Inés Samengo category:cs.CL physics.soc-ph published:2015-07-30 summary:We develop the information-theoretical concepts required to study thestatistical dependencies among three variables. Some of such dependencies arepure triple interactions, in the sense that they cannot be explained in termsof a combination of pairwise correlations. We derive bounds for tripledependencies, and characterize the shape of the joint probability distributionof three binary variables with high triple interaction. The analysis alsoallows us to quantify the amount of redundancy in the mutual informationbetween pairs of variables, and to assess whether the information between twovariables is or is not mediated by a third variable. These concepts are appliedto the analysis of written texts. We find that the probability that a givenword is found in a particular location within the text is not only modulated bythe presence or absence of other nearby words, but also, on the presence orabsence of nearby pairs of words. We identify the words enclosing the keysemantic concepts of the text, the triplets of words with high pairwise andtriple interactions, and the words that mediate the pairwise interactionsbetween other words.
arxiv-12900-253 | Action recognition in still images by latent superpixel classification | http://arxiv.org/abs/1507.08363 | author:Shaukat Abidi, Massimo Piccardi, Mary-Anne Williams category:cs.CV published:2015-07-30 summary:Action recognition from still images is an important task of computer visionapplications such as image annotation, robotic navigation, video surveillanceand several others. Existing approaches mainly rely on either bag-of-featurerepresentations or articulated body-part models. However, the relationshipbetween the action and the image segments is still substantially unexplored.For this reason, in this paper we propose to approach action recognition byleveraging an intermediate layer of "superpixels" whose latent classes can actas attributes of the action. In the proposed approach, the action class ispredicted by a structural model(learnt by Latent Structural SVM) based onmeasurements from the image superpixels and their latent classes. Experimentalresults over the challenging Stanford 40 Actions dataset report a significantaverage accuracy of 74.06% for the positive class and 88.50% for the negativeclass, giving evidence to the performance of the proposed approach.
arxiv-12900-254 | When VLAD met Hilbert | http://arxiv.org/abs/1507.08373 | author:Mehrtash Harandi, Mathieu Salzmann, Fatih Porikli category:cs.CV published:2015-07-30 summary:Vectors of Locally Aggregated Descriptors (VLAD) have emerged as powerfulimage/video representations that compete with or even outperformstate-of-the-art approaches on many challenging visual recognition tasks. Inthis paper, we address two fundamental limitations of VLAD: its requirement forthe local descriptors to have vector form and its restriction to linearclassifiers due to its high-dimensionality. To this end, we introduce akernelized version of VLAD. This not only lets us inherently exploit moresophisticated classification schemes, but also enables us to efficientlyaggregate non-vector descriptors (e.g., tensors) in the VLAD framework.Furthermore, we propose three approximate formulations that allow us toaccelerate the coding process while still benefiting from the properties ofkernel VLAD. Our experiments demonstrate the effectiveness of our approach athandling manifold-valued data, such as covariance descriptors, on severalclassification tasks. Our results also evidence the benefits of our nonlinearVLAD descriptors against the linear ones in Euclidean space using severalstandard benchmark datasets.
arxiv-12900-255 | VMF-SNE: Embedding for Spherical Data | http://arxiv.org/abs/1507.08379 | author:Mian Wang, Dong Wang category:cs.LG published:2015-07-30 summary:T-SNE is a well-known approach to embedding high-dimensional data and hasbeen widely used in data visualization. The basic assumption of t-SNE is thatthe data are non-constrained in the Euclidean space and the local proximity canbe modelled by Gaussian distributions. This assumption does not hold for a widerange of data types in practical applications, for instance spherical data forwhich the local proximity is better modelled by the von Mises-Fisher (vMF)distribution instead of the Gaussian. This paper presents a vMF-SNE embeddingalgorithm to embed spherical data. An iterative process is derived to producean efficient embedding. The results on a simulation data set demonstrated thatvMF-SNE produces better embeddings than t-SNE for spherical data.
arxiv-12900-256 | Tag-Weighted Topic Model For Large-scale Semi-Structured Documents | http://arxiv.org/abs/1507.08396 | author:Shuangyin Li, Jiefei Li, Guan Huang, Ruiyang Tan, Rong Pan category:cs.CL cs.IR cs.LG stat.ML published:2015-07-30 summary:To date, there have been massive Semi-Structured Documents (SSDs) during theevolution of the Internet. These SSDs contain both unstructured features (e.g.,plain text) and metadata (e.g., tags). Most previous works focused on modelingthe unstructured text, and recently, some other methods have been proposed tomodel the unstructured text with specific tags. To build a general model forSSDs remains an important problem in terms of both model fitness andefficiency. We propose a novel method to model the SSDs by a so-calledTag-Weighted Topic Model (TWTM). TWTM is a framework that leverages both thetags and words information, not only to learn the document-topic and topic-worddistributions, but also to infer the tag-topic distributions for text miningtasks. We present an efficient variational inference method with an EMalgorithm for estimating the model parameters. Meanwhile, we propose threelarge-scale solutions for our model under the MapReduce distributed computingplatform for modeling large-scale SSDs. The experimental results show theeffectiveness, efficiency and the robustness by comparing our model with thestate-of-the-art methods in document modeling, tags prediction and textclassification. We also show the performance of the three distributed solutionsin terms of time and accuracy on document modeling.
arxiv-12900-257 | Multilinear Map Layer: Prediction Regularization by Structural Constraint | http://arxiv.org/abs/1507.08429 | author:Shuchang Zhou, Yuxin Wu category:cs.CV published:2015-07-30 summary:In this paper we propose and study a technique to impose structuralconstraints on the output of a neural network, which can reduce amount ofcomputation and number of parameters besides improving prediction accuracy whenthe output is known to approximately conform to the low-rankness prior. Thetechnique proceeds by replacing the output layer of neural network with theso-called MLM layers, which forces the output to be the result of someMultilinear Map, like a hybrid-Kronecker-dot product or Kronecker TensorProduct. In particular, given an "autoencoder" model trained on SVHN dataset,we can construct a new model with MLM layer achieving 62\% reduction in totalnumber of parameters and reduction of $\ell_2$ reconstruction error from 0.088to 0.004. Further experiments on other autoencoder model variants trained onSVHN datasets also demonstrate the efficacy of MLM layers.
arxiv-12900-258 | People Counting in High Density Crowds from Still Images | http://arxiv.org/abs/1507.08445 | author:Ankan Bansal, K. S. Venkatesh category:cs.CV published:2015-07-30 summary:We present a method of estimating the number of people in high density crowdsfrom still images. The method estimates counts by fusing information frommultiple sources. Most of the existing work on crowd counting deals with verysmall crowds (tens of individuals) and use temporal information from videos.Our method uses only still images to estimate the counts in high density images(hundreds to thousands of individuals). At this scale, we cannot rely on onlyone set of features for count estimation. We, therefore, use multiple sources,viz. interest points (SIFT), Fourier analysis, wavelet decomposition, GLCMfeatures and low confidence head detections, to estimate the counts. Each ofthese sources gives a separate estimate of the count along with confidences andother statistical measures which are then combined to obtain the finalestimate. We test our method on an existing dataset of fifty images containingover 64000 individuals. Further, we added another fifty annotated images ofcrowds and tested on the complete dataset of hundred images containing over87000 individuals. The counts per image range from 81 to 4633. We report theperformance in terms of mean absolute error, which is a measure of accuracy ofthe method, and mean normalised absolute error, which is a measure of therobustness.
arxiv-12900-259 | Unsupervised Sentence Simplification Using Deep Semantics | http://arxiv.org/abs/1507.08452 | author:Shashi Narayan, Claire Gardent category:cs.CL published:2015-07-30 summary:We present a novel approach to sentence simplification which departs fromprevious work in two main ways. First, it requires neither hand written rulesnor a training corpus of aligned standard and simplified sentences. Second,sentence splitting operates on deep semantic structure. We show (i) that theunsupervised framework we propose is competitive with four state-of-the-artsupervised systems and (ii) that our semantic based approach allows for aprincipled and effective handling of sentence splitting.
arxiv-12900-260 | Framework for learning agents in quantum environments | http://arxiv.org/abs/1507.08482 | author:Vedran Dunjko, Jacob M. Taylor, Hans J. Briegel category:quant-ph cs.AI cs.LG published:2015-07-30 summary:In this paper we provide a broad framework for describing learning agents ingeneral quantum environments. We analyze the types of classically specifiedenvironments which allow for quantum enhancements in learning, by contrastingenvironments to quantum oracles. We show that whether or not quantumimprovements are at all possible depends on the internal structure of thequantum environment. If the environments are constructed and the internalstructure is appropriately chosen, or if the agent has limited capacities toinfluence the internal states of the environment, we show that improvements inlearning times are possible in a broad range of scenarios. Such scenarios wecall luck-favoring settings. The case of constructed environments isparticularly relevant for the class of model-based learning agents, where ourresults imply a near-generic improvement.
arxiv-12900-261 | Orthogonal parallel MCMC methods for sampling and optimization | http://arxiv.org/abs/1507.08577 | author:L. Martino, V. Elvira, D. Luengo, J. Corander, F. Louzada category:stat.CO stat.ML published:2015-07-30 summary:Monte Carlo (MC) methods are widely used in statistics, signal processing andmachine learning. A well-known class of MC methods are Markov Chain Monte Carlo(MCMC) algorithms. In order to foster better exploration of the state space,specially in high-dimensional applications, several schemes employing multipleparallel MCMC chains have been recently introduced. In this work, we describe anovel parallel interacting MCMC scheme, called orthogonal MCMC (O-MCMC), wherea set of vertical parallel MCMC chains share information using some horizontalMCMC techniques working on the entire population of current states. Morespecifically, the vertical chains are led by random-walk proposals, whereas thehorizontal MCMC techniques employ independent proposals, thus allowing anefficient combination of global exploration and local approximation. Theinteraction is contained in these horizontal iterations. Within the analysis ofdifferent implementations of O-MCMC, novel schemes for reducing the overallcomputational cost of parallel multiple try Metropolis (MTM) chains are alsopresented. Furthermore, a modified version of O-MCMC for optimization isprovided by considering parallel simulated annealing (SA) algorithms. Finally,we also discuss the application of O-MCMC in a big bata framework. Numericalresults show the advantages of the proposed sampling scheme in terms ofefficiency in the estimation, as well as robustness in terms of independencewith respect to initial values and the choice of the parameters.
arxiv-12900-262 | Multilayer Network of Language: a Unified Framework for Structural Analysis of Linguistic Subsystems | http://arxiv.org/abs/1507.08539 | author:Domagoj Margan, Ana Meštrović, Sanda Martinčić-Ipšić category:cs.CL published:2015-07-30 summary:Recently, the focus of complex networks research has shifted from theanalysis of isolated properties of a system toward a more realistic modeling ofmultiple phenomena - multilayer networks. Motivated by the prosperity ofmultilayer approach in social, transport or trade systems, we propose theintroduction of multilayer networks for language. The multilayer network oflanguage is a unified framework for modeling linguistic subsystems and theirstructural properties enabling the exploration of their mutual interactions.Various aspects of natural language systems can be represented as complexnetworks, whose vertices depict linguistic units, while links model theirrelations. The multilayer network of language is defined by three aspects: thenetwork construction principle, the linguistic subsystem and the language ofinterest. More precisely, we construct a word-level (syntax, co-occurrence andits shuffled counterpart) and a subword level (syllables and graphemes) networklayers, from five variations of original text (in the modeled language). Theobtained results suggest that there are substantial differences between thenetworks structures of different language subsystems, which are hidden duringthe exploration of an isolated layer. The word-level layers share structuralproperties regardless of the language (e.g. Croatian or English), while thesyllabic subword level expresses more language dependent structural properties.The preserved weighted overlap quantifies the similarity of word-level layersin weighted and directed networks. Moreover, the analysis of motifs reveals aclose topological structure of the syntactic and syllabic layers for bothlanguages. The findings corroborate that the multilayer network framework is apowerful, consistent and systematic approach to model several linguisticsubsystems simultaneously and hence to provide a more unified view on language.
arxiv-12900-263 | EESEN: End-to-End Speech Recognition using Deep RNN Models and WFST-based Decoding | http://arxiv.org/abs/1507.08240 | author:Yajie Miao, Mohammad Gowayyed, Florian Metze category:cs.CL cs.LG published:2015-07-29 summary:The performance of automatic speech recognition (ASR) has improvedtremendously due to the application of deep neural networks (DNNs). Despitethis progress, building a new ASR system remains a challenging task, requiringvarious resources, multiple training stages and significant expertise. Thispaper presents our Eesen framework which drastically simplifies the existingpipeline to build state-of-the-art ASR systems. Acoustic modeling in Eeseninvolves learning a single recurrent neural network (RNN) predictingcontext-independent targets (phonemes or characters). To remove the need forpre-generated frame labels, we adopt the connectionist temporal classification(CTC) objective function to infer the alignments between speech and labelsequences. A distinctive feature of Eesen is a generalized decoding approachbased on weighted finite-state transducers (WFSTs), which enables the efficientincorporation of lexicons and language models into CTC decoding. Experimentsshow that compared with the standard hybrid DNN systems, Eesen achievescomparable word error rates (WERs), while at the same time speeding up decodingsignificantly.
arxiv-12900-264 | A Gauss-Newton Method for Markov Decision Processes | http://arxiv.org/abs/1507.08271 | author:Thomas Furmston, Guy Lever category:cs.AI cs.LG stat.ML published:2015-07-29 summary:Approximate Newton methods are a standard optimization tool which aim tomaintain the benefits of Newton's method, such as a fast rate of convergence,whilst alleviating its drawbacks, such as computationally expensive calculationor estimation of the inverse Hessian. In this work we investigate approximateNewton methods for policy optimization in Markov Decision Processes (MDPs). Wefirst analyse the structure of the Hessian of the objective function for MDPs.We show that, like the gradient, the Hessian exhibits useful structure in thecontext of MDPs and we use this analysis to motivate two Gauss-Newton Methodsfor MDPs. Like the Gauss-Newton method for non-linear least squares, thesemethods involve approximating the Hessian by ignoring certain terms in theHessian which are difficult to estimate. The approximate Hessians possessdesirable properties, such as negative definiteness, and we demonstrate severalimportant performance guarantees including guaranteed ascent directions,invariance to affine transformation of the parameter space, and convergenceguarantees. We finally provide a unifying perspective of key policy searchalgorithms, demonstrating that our second Gauss-Newton algorithm is closelyrelated to both the EM-algorithm and natural gradient ascent applied to MDPs,but performs significantly better in practice on a range of challengingdomains.
arxiv-12900-265 | Tracking Randomly Moving Objects on Edge Box Proposals | http://arxiv.org/abs/1507.08085 | author:Gao Zhu, Fatih Porikli, Hongdong Li category:cs.CV published:2015-07-29 summary:Most tracking-by-detection methods employ a local search window around thepredicted object location in the current frame assuming the previous locationis accurate, the trajectory is smooth, and the computational capacity permits asearch radius that can accommodate the maximum speed yet small enough to reducemismatches. These, however, may not be valid always, in particular for fast andirregularly moving objects. Here, we present an object tracker that is notlimited to a local search window and has ability to probe efficiently theentire frame. Our method generates a small number of "high-quality" proposalsby a novel instance-specific objectness measure and evaluates them against theobject model that can be adopted from an existing tracking-by-detectionapproach as a core tracker. During the tracking process, we update the objectmodel concentrating on hard false-positives supplied by the proposals, whichhelp suppressing distractors caused by difficult background clutters, and learnhow to re-rank proposals according to the object model. Since we reducesignificantly the number of hypotheses the core tracker evaluates, we can usericher object descriptors and stronger detector. Our method outperforms mostrecent state-of-the-art trackers on popular tracking benchmarks, and providesimproved robustness for fast moving objects as well as for ultra low-frame-ratevideos.
arxiv-12900-266 | Diffusion Adaptation Over Clustered Multitask Networks Based on the Affine Projection Algorithm | http://arxiv.org/abs/1507.08566 | author:Vinay Chakravarthi Gogineni, Mrityunjoy Chakraborty category:cs.DC cs.SY math.ST stat.ML stat.TH published:2015-07-29 summary:Distributed adaptive networks achieve better estimation performance byexploiting temporal and as well spatial diversity while consuming fewresources. Recent works have studied the single task distributed estimationproblem, in which the nodes estimate a single optimum parameter vectorcollaboratively. However, there are many important applications where themultiple vectors have to estimated simultaneously, in a collaborative manner.This paper presents multi-task diffusion strategies based on the AffineProjection Algorithm (APA), usage of APA makes the algorithm robust against thecorrelated input. The performance analysis of the proposed multi-task diffusionAPA algorithm is studied in mean and mean square sense. And also a modifiedmulti-task diffusion strategy is proposed that improves the performance interms of convergence rate and steady state EMSE as well. Simulations areconducted to verify the analytical results.
arxiv-12900-267 | Document Embedding with Paragraph Vectors | http://arxiv.org/abs/1507.07998 | author:Andrew M. Dai, Christopher Olah, Quoc V. Le category:cs.CL cs.AI cs.LG published:2015-07-29 summary:Paragraph Vectors has been recently proposed as an unsupervised method forlearning distributed representations for pieces of texts. In their work, theauthors showed that the method can learn an embedding of movie review textswhich can be leveraged for sentiment analysis. That proof of concept, whileencouraging, was rather narrow. Here we consider tasks other than sentimentanalysis, provide a more thorough comparison of Paragraph Vectors to otherdocument modelling algorithms such as Latent Dirichlet Allocation, and evaluateperformance of the method as we vary the dimensionality of the learnedrepresentation. We benchmarked the models on two document similarity data sets,one from Wikipedia, one from arXiv. We observe that the Paragraph Vector methodperforms significantly better than other methods, and propose a simpleimprovement to enhance embedding quality. Somewhat surprisingly, we also showthat much like word embeddings, vector operations on Paragraph Vectors canperform useful semantic results.
arxiv-12900-268 | Fast Robust PCA on Graphs | http://arxiv.org/abs/1507.08173 | author:Nauman Shahid, Nathanael Perraudin, Vassilis Kalofolias, Gilles Puy, Pierre Vandergheynst category:cs.CV published:2015-07-29 summary:Mining useful clusters from high dimensional data has received significantattention of the computer vision and pattern recognition community in therecent years. Linear and non-linear dimensionality reduction has played animportant role to overcome the curse of dimensionality. However, often suchmethods are accompanied with three different problems: high computationalcomplexity (usually associated with the nuclear norm minimization),non-convexity (for matrix factorization methods) and susceptibility to grosscorruptions in the data. In this paper we propose a principal componentanalysis (PCA) based solution that overcomes these three issues andapproximates a low-rank recovery method for high dimensional datasets. Wetarget the low-rank recovery by enforcing two types of graph smoothnessassumptions, one on the data samples and the other on the features by designinga convex optimization problem. The resulting algorithm is fast, efficient andscalable for huge datasets with O(nlog(n)) computational complexity in thenumber of data samples. It is also robust to gross corruptions in the datasetas well as to the model parameters. Clustering experiments on 7 benchmarkdatasets with different types of corruptions and background separationexperiments on 3 video datasets show that our proposed model outperforms 10state-of-the-art dimensionality reduction models. Our theoretical analysisproves that the proposed model is able to recover approximate low-rankrepresentations with a bounded error for clusterable data.
arxiv-12900-269 | On Proportions of Fit Individuals in Population of Genetic Algorithm with Tournament Selection | http://arxiv.org/abs/1507.08007 | author:Anton Eremeev category:cs.NE published:2015-07-29 summary:In this paper, we consider a fitness-level model of a non-elitistmutation-only genetic algorithm (GA) with tournament selection. The modelprovides upper and lower bounds for the expected proportion of the individualswith fitness above given thresholds. In the case of GA with bitwise mutationand OneMax fitness function, the lower bounds are tight when population sizeequals one, while the upper bounds are asymptotically tight when populationsize tends to infinity. The lower bounds on expected proportions of sufficiently fit individuals maybe obtained from the probability distribution of an appropriate Markov chain.This approach yields polynomial upper bounds on the runtime of an Iteratedversion of the GA on 2-SAT problem and on a family of Set Cover problemsproposed by E. Balas.
arxiv-12900-270 | Beamforming through regularized inverse problems in ultrasound medical imaging | http://arxiv.org/abs/1507.08184 | author:Teodora Szasz, Adrian Basarab, Denis Kouamé category:cs.CV published:2015-07-29 summary:Beamforming in ultrasound imaging has significant impact on the quality ofthe final image, controlling its resolution and contrast. Despite its lowspatial resolution and contrast, delay-and-sum is still extensively usednowadays in clinical applications, due to its real-time capabilities. The mostcommon alternatives are minimum variance method and its variants, whichovercome the drawbacks of delay-and-sum, at the cost of higher computationalcomplexity that limits its utilization in real-time applications. In this paper, we propose to perform beamforming in ultrasound imagingthrough a regularized inverse problem based on a linear model relating thereflected echoes to the signal to be recovered. Our approach presents two majoradvantages: i) its flexibility in the choice of statistical assumptions on thesignal to be beamformed (Laplacian and Gaussian statistics are tested herein)and ii) its robustness to a reduced number of pulse emissions. The proposedframework is flexible and allows for choosing the right trade-off between noisesuppression and sharpness of the resulted image. We illustrate the performanceof our approach on both simulated and experimental data, with \textit{in vivo}examples of carotid and thyroid. Compared to delay-and-sum, minimimum varianceand two other recently published beamforming techniques, our method offersbetter spatial resolution, respectively contrast, when using Laplacian andGaussian priors.
arxiv-12900-271 | IT-Dendrogram: A New Member of the In-Tree (IT) Clustering Family | http://arxiv.org/abs/1507.08155 | author:Teng Qiu, Yongjie Li category:stat.ML cs.CV cs.LG stat.ME published:2015-07-29 summary:Previously, we proposed a physically-inspired method to construct data pointsinto an effective in-tree (IT) structure, in which the underlying clusterstructure in the dataset is well revealed. Although there are some edges in theIT structure requiring to be removed, such undesired edges are generallydistinguishable from other edges and thus are easy to be determined. Forinstance, when the IT structures for the 2-dimensional (2D) datasets aregraphically presented, those undesired edges can be easily spotted andinteractively determined. However, in practice, there are many datasets that donot lie in the 2D Euclidean space, thus their IT structures cannot begraphically presented. But if we can effectively map those IT structures into avisualized space in which the salient features of those undesired edges arepreserved, then the undesired edges in the IT structures can still be visuallydetermined in a visualization environment. Previously, this purpose was reachedby our method called IT-map. The outstanding advantage of IT-map is thatclusters can still be found even with the so-called crowding problem in theembedding. In this paper, we propose another method, called IT-Dendrogram, to achievethe same goal through an effective combination of the IT structure and thesingle link hierarchical clustering (SLHC) method. Like IT-map, IT-Dendrogramcan also effectively represent the IT structures in a visualizationenvironment, whereas using another form, called the Dendrogram. IT-Dendrogramcan serve as another visualization method to determine the undesired edges inthe IT structures and thus benefit the IT-based clustering analysis. This wasdemonstrated on several datasets with different shapes, dimensions, andattributes. Unlike IT-map, IT-Dendrogram can always avoid the crowding problem,which could help users make more reliable cluster analysis in certain problems.
arxiv-12900-272 | Learning Representations for Outlier Detection on a Budget | http://arxiv.org/abs/1507.08104 | author:Barbora Micenková, Brian McWilliams, Ira Assent category:cs.LG published:2015-07-29 summary:The problem of detecting a small number of outliers in a large dataset is animportant task in many fields from fraud detection to high-energy physics. Twoapproaches have emerged to tackle this problem: unsupervised and supervised.Supervised approaches require a sufficient amount of labeled data and arechallenged by novel types of outliers and inherent class imbalance, whereasunsupervised methods do not take advantage of available labeled trainingexamples and often exhibit poorer predictive performance. We propose BORE (aBagged Outlier Representation Ensemble) which uses unsupervised outlier scoringfunctions (OSFs) as features in a supervised learning framework. BORE is ableto adapt to arbitrary OSF feature representations, to the imbalance in labeleddata as well as to prediction-time constraints on computational cost. Wedemonstrate the good performance of BORE compared to a variety of competingmethods in the non-budgeted and the budgeted outlier detection problem on 12real-world datasets.
arxiv-12900-273 | Adapted sampling for 3D X-ray computed tomography | http://arxiv.org/abs/1507.08030 | author:Anthony Cazasnoves, Fanny Buyens, Sylvie Sevestre category:cs.CV published:2015-07-29 summary:In this paper, we introduce a method to build an adapted mesh representationof a 3D object for X-Ray tomography reconstruction. Using this representation,we provide means to reduce the computational cost of reconstruction by way ofiterative algorithms. The adapted sampling of the reconstruction space isdirectly obtained from the projection dataset and prior to any reconstruction.It is built following two stages : firstly, 2D structural information isextracted from the projection images and is secondly merged in 3D to obtain a3D pointcloud sampling the interfaces of the object. A relevant mesh is thenbuilt from this cloud by way of tetrahedralization. Critical parametersselections have been automatized through a statistical framework, thus avoidingdependence on users expertise. Applying this approach on geometrical shapes andon a 3D Shepp-Logan phantom, we show the relevance of such a sampling -obtained in a few seconds - and the drastic decrease in cells number to beestimated during reconstruction when compared to the usual regular voxellattice. A first iterative reconstruction of the Shepp-Logan using this kind ofsampling shows the relevant advantages in terms of low dose or sparseacquisition sampling contexts. The method can also prove useful for otherapplications such as finite element method computations.
arxiv-12900-274 | Collaborative Representation Classification Ensemble for Face Recognition | http://arxiv.org/abs/1507.08064 | author:Xiaochao Qu, Suah Kim, Run Cui, Hyoung Joong Kim category:cs.CV published:2015-07-29 summary:Collaborative Representation Classification (CRC) for face recognitionattracts a lot attention recently due to its good recognition performance andfast speed. Compared to Sparse Representation Classification (SRC), CRCachieves a comparable recognition performance with 10-1000 times faster speed.In this paper, we propose to ensemble several CRC models to promote therecognition rate, where each CRC model uses different and divergent randomlygenerated biologically-inspired features as the face representation. Theproposed ensemble algorithm calculates an ensemble weight for each CRC modelthat guided by the underlying classification rule of CRC. The obtained weightsreflect the confidences of those CRC models where the more confident CRC modelshave larger weights. The proposed weighted ensemble method proves to be veryeffective and improves the performance of each CRC model significantly.Extensive experiments are conducted to show the superior performance of theproposed method.
arxiv-12900-275 | Distributed Mini-Batch SDCA | http://arxiv.org/abs/1507.08322 | author:Martin Takáč, Peter Richtárik, Nathan Srebro category:cs.LG math.OC published:2015-07-29 summary:We present an improved analysis of mini-batched stochastic dual coordinateascent for regularized empirical loss minimization (i.e. SVM and SVM-typeobjectives). Our analysis allows for flexible sampling schemes, including wheredata is distribute across machines, and combines a dependence on the smoothnessof the loss and/or the data spread (measured through the spectral norm).
arxiv-12900-276 | Deep Learning for Single-View Instance Recognition | http://arxiv.org/abs/1507.08286 | author:David Held, Sebastian Thrun, Silvio Savarese category:cs.CV cs.LG cs.NE cs.RO published:2015-07-29 summary:Deep learning methods have typically been trained on large datasets in whichmany training examples are available. However, many real-world product datasetshave only a small number of images available for each product. We explore theuse of deep learning methods for recognizing object instances when we have onlya single training example per class. We show that feedforward neural networksoutperform state-of-the-art methods for recognizing objects from novelviewpoints even when trained from just a single image per object. To furtherimprove our performance on this task, we propose to take advantage of asupplementary dataset in which we observe a separate set of objects frommultiple viewpoints. We introduce a new approach for training deep learningmethods for instance recognition with limited training data, in which we use anauxiliary multi-view dataset to train our network to be robust to viewpointchanges. We find that this approach leads to a more robust classifier forrecognizing objects from novel viewpoints, outperforming previousstate-of-the-art approaches including keypoint-matching, template-basedtechniques, and sparse coding.
arxiv-12900-277 | Context-aware learning for finite mixture models | http://arxiv.org/abs/1507.08272 | author:Serafeim Perdikis, Robert Leeb, Ricardo Chavarriaga, José del R. Millán category:stat.ML published:2015-07-29 summary:This work introduces algorithms able to exploit contextual information inorder to improve maximum-likelihood (ML) parameter estimation in finite mixturemodels (FMM), demonstrating their benefits and properties in several scenarios.The proposed algorithms are derived in a probabilistic framework with regard tosituations where the regular FMM graphs can be extended with context-relatedvariables, respecting the standard expectation-maximization (EM) methodologyand, thus, rendering explicit supervision completely redundant. We show that,by direct application of the missing information principle, the comparedalgorithms' learning behaviour operates between the extremities of supervisedand unsupervised learning, proportionally to the information content ofcontextual assistance. Our simulation results demonstrate the superiority ofcontext-aware FMM training as compared to conventional unsupervised training interms of estimation precision, standard errors, convergence rates andclassification accuracy or regression fitness in various scenarios, while alsohighlighting important differences among the outlined situations. Finally, theimproved classification outcome of contextually enhanced FMMs is showcased in abrain-computer interface application scenario.
arxiv-12900-278 | STC Anti-spoofing Systems for the ASVspoof 2015 Challenge | http://arxiv.org/abs/1507.08074 | author:Sergey Novoselov, Alexandr Kozlov, Galina Lavrentyeva, Konstantin Simonchik, Vadim Shchemelinin category:cs.SD cs.LG stat.ML published:2015-07-29 summary:This paper presents the Speech Technology Center (STC) systems submitted toAutomatic Speaker Verification Spoofing and Countermeasures (ASVspoof)Challenge 2015. In this work we investigate different acoustic feature spacesto determine reliable and robust countermeasures against spoofing attacks. Inaddition to the commonly used front-end MFCC features we explored featuresderived from phase spectrum and features based on applying the multiresolutionwavelet transform. Similar to state-of-the-art ASV systems, we used thestandard TV-JFA approach for probability modelling in spoofing detectionsystems. Experiments performed on the development and evaluation datasets ofthe Challenge demonstrate that the use of phase-related and wavelet-basedfeatures provides a substantial input into the efficiency of the resulting STCsystems. In our research we also focused on the comparison of the linear (SVM)and nonlinear (DBN) classifiers.
arxiv-12900-279 | Cross-pose Face Recognition by Canonical Correlation Analysis | http://arxiv.org/abs/1507.08076 | author:Annan Li, Shiguang Shan, Xilin Chen, Bingpeng Ma, Shuicheng Yan, Wen Gao category:cs.CV published:2015-07-29 summary:The pose problem is one of the bottlenecks in automatic face recognition. Weargue that one of the diffculties in this problem is the severe misalignment inface images or feature vectors with different poses. In this paper, we proposethat this problem can be statistically solved or at least mitigated bymaximizing the intra-subject across-pose correlations via canonical correlationanalysis (CCA). In our method, based on the data set with coupled face imagesof the same identities and across two different poses, CCA learnssimultaneously two linear transforms, each for one pose. In the transformedsubspace, the intra-subject correlations between the different poses aremaximized, which implies pose-invariance or pose-robustness is achieved. Theexperimental results show that our approach could considerably improve therecognition performance. And if further enhanced with holistic+local featurerepresentation, the performance could be comparable to the state-of-the-art.
arxiv-12900-280 | Zero-Shot Domain Adaptation via Kernel Regression on the Grassmannian | http://arxiv.org/abs/1507.07830 | author:Yongxin Yang, Timothy Hospedales category:cs.LG cs.CV published:2015-07-28 summary:Most visual recognition methods implicitly assume the data distributionremains unchanged from training to testing. However, in practice domain shiftoften exists, where real-world factors such as lighting and sensor type changebetween train and test, and classifiers do not generalise from source to targetdomains. It is impractical to train separate models for all possible situationsbecause collecting and labelling the data is expensive. Domain adaptationalgorithms aim to ameliorate domain shift, allowing a model trained on a sourceto perform well on a different target domain. However, even for the setting ofunsupervised domain adaptation, where the target domain is unlabelled,collecting data for every possible target domain is still costly. In thispaper, we propose a new domain adaptation method that has no need to accesseither data or labels of the target domain when it can be described by aparametrised vector and there exits several related source domains within thesame parametric space. It greatly reduces the burden of data collection andannotation, and our experiments show some promising results.
arxiv-12900-281 | Optimally Confident UCB: Improved Regret for Finite-Armed Bandits | http://arxiv.org/abs/1507.07880 | author:Tor Lattimore category:cs.LG math.OC published:2015-07-28 summary:I present the first algorithm for stochastic finite-armed bandits thatsimultaneously enjoys order-optimal problem-dependent regret and worst-caseregret. Besides the theoretical results, the new algorithm is simple, efficientand empirically superb. The approach is based on UCB, but with a carefullychosen confidence parameter that optimally balances the risk of failingconfidence intervals against the cost of excessive optimism.
arxiv-12900-282 | Training recurrent networks online without backtracking | http://arxiv.org/abs/1507.07680 | author:Yann Ollivier, Corentin Tallec, Guillaume Charpiat category:cs.NE cs.LG stat.ML published:2015-07-28 summary:We introduce the "NoBackTrack" algorithm to train the parameters of dynamicalsystems such as recurrent neural networks. This algorithm works in an online,memoryless setting, thus requiring no backpropagation through time, and isscalable, avoiding the large computational and memory cost of maintaining thefull gradient of the current state with respect to the parameters. The algorithm essentially maintains, at each time, a single search directionin parameter space. The evolution of this search direction is partly stochasticand is constructed in such a way to provide, at every time, an unbiased randomestimate of the gradient of the loss function with respect to the parameters.Because the gradient estimate is unbiased, on average over time the parameteris updated as it should. The resulting gradient estimate can then be fed to a lightweight Kalman-likefilter to yield an improved algorithm. For recurrent neural networks, theresulting algorithms scale linearly with the number of parameters. Small-scale experiments confirm the suitability of the approach, showing thatthe stochastic approximation of the gradient introduced in the algorithm is notdetrimental to learning. In particular, the Kalman-like version of NoBackTrackis superior to backpropagation through time (BPTT) when the time span ofdependencies in the data is longer than the truncation span for BPTT.
arxiv-12900-283 | Offline Handwritten Signature Verification - Literature Review | http://arxiv.org/abs/1507.07909 | author:Luiz G. Hafemann, Robert Sabourin, Luiz S. Oliveira category:cs.CV stat.ML I.5.4 published:2015-07-28 summary:The area of Handwritten Signature Verification has been broadly researched inthe last decades and still remains as an open research problem. This reportfocuses on offline signature verification, characterized by the usage of static(scanned) images of signatures, where the objective is to discriminate if agiven signature is genuine (produced by the claimed individual), or a forgery(produced by an impostor). We present an overview of how the problem has beenhandled by several researchers in the past few decades and the recentadvancements in the field.
arxiv-12900-284 | Learning 3D Articulation and Deformation using 2D Images | http://arxiv.org/abs/1507.07646 | author:Angjoo Kanazawa, Shahar Kovalsky, Ronen Basri, David W. Jacobs category:cs.CV published:2015-07-28 summary:Understanding how an animal can deform and articulate is essential for arealistic modification of its 3D model. In this paper, we show that suchinformation can be learned from user-clicked 2D images and a template 3D modelof the target animal. We present a volumetric deformation framework thatproduces a set of new 3D models by deforming a template 3D model according to aset of user-clicked images. Our framework is based on a novel locally-boundeddeformation energy, where every local region has its own stiffness value thatbounds how much distortion is allowed at that location. We jointly learn thelocal stiffness bounds as we deform the template 3D mesh to match eachuser-clicked image. We show that this seemingly complex task can be solved as asequence of convex optimization problems. We demonstrate the effectiveness ofour approach on cats and horses, which are highly deformable and articulatedanimals. Our framework produces new 3D models of animals that are significantlymore plausible than methods without learned stiffness.
arxiv-12900-285 | Reasoning about Linguistic Regularities in Word Embeddings using Matrix Manifolds | http://arxiv.org/abs/1507.07636 | author:Sridhar Mahadevan, Sarath Chandar category:cs.CL published:2015-07-28 summary:Recent work has explored methods for learning continuous vector space wordrepresentations reflecting the underlying semantics of words. Simple vectorspace arithmetic using cosine distances has been shown to capture certain typesof analogies, such as reasoning about plurals from singulars, past tense frompresent tense, etc. In this paper, we introduce a new approach to captureanalogies in continuous word representations, based on modeling not justindividual word vectors, but rather the subspaces spanned by groups of words.We exploit the property that the set of subspaces in n-dimensional Euclideanspace form a curved manifold space called the Grassmannian, a quotient subgroupof the Lie group of rotations in n- dimensions. Based on this mathematicalmodel, we develop a modified cosine distance model based on geodesic kernelsthat captures relation-specific distances across word categories. Ourexperiments on analogy tasks show that our approach performs significantlybetter than the previous approaches for the given task.
arxiv-12900-286 | A Hyperelastic Two-Scale Optimization Model for Shape Matching | http://arxiv.org/abs/1507.07760 | author:Konrad Simon, Sameer Sheorey, David Jacobs, Ronen Basri category:cs.CG cs.CV cs.GR published:2015-07-28 summary:We suggest a novel shape matching algorithm for three-dimensional surfacemeshes of disk or sphere topology. The method is based on the physical theoryof nonlinear elasticity and can hence handle large rotations and deformations.Deformation boundary conditions that supplement the underlying equations areusually unknown. Given an initial guess, these are optimized such that themechanical boundary forces that are responsible for the deformation are of asimple nature. We show a heuristic way to approximate the nonlinearoptimization problem by a sequence of convex problems using finite elements.The deformation cost, i.e, the forces, is measured on a coarse scale whileICP-like matching is done on the fine scale. We demonstrate the plausibility ofour algorithm on examples taken from different datasets.
arxiv-12900-287 | SynapCountJ --- a Tool for Analyzing Synaptic Densities in Neurons | http://arxiv.org/abs/1507.07800 | author:Gadea Mata, Jónathan Heras, Miguel Morales, Ana Romero, Julio Rubio category:cs.CV q-bio.NC published:2015-07-28 summary:The quantification of synapses is instrumental to measure the evolution ofsynaptic densities of neurons under the effect of some physiologicalconditions, neuronal diseases or even drug treatments. However, the manualquantification of synapses is a tedious, error-prone, time-consuming andsubjective task; therefore, tools that might automate this process aredesirable. In this paper, we present SynapCountJ, an ImageJ plugin, that canmeasure synaptic density of individual neurons obtained by immunofluorescencetechniques, and also can be applied for batch processing of neurons that havebeen obtained in the same experiment or using the same setting. The procedureto quantify synapses implemented in SynapCountJ is based on the colocalizationof three images of the same neuron (the neuron marked with two antibody markersand the structure of the neuron) and is inspired by methods coming fromComputational Algebraic Topology. SynapCountJ provides a procedure tosemi-automatically quantify the number of synapses of neuron cultures; as aresult, the time required for such an analysis is greatly reduced.
arxiv-12900-288 | An algorithm for online tensor prediction | http://arxiv.org/abs/1507.07974 | author:John Pothier, Josh Girson, Shuchin Aeron category:stat.ML cs.IT cs.LG math.IT published:2015-07-28 summary:We present a new method for online prediction and learning of tensors($N$-way arrays, $N >2$) from sequential measurements. We focus on the specificcase of 3-D tensors and exploit a recently developed framework of structuredtensor decompositions proposed in [1]. In this framework it is possible totreat 3-D tensors as linear operators and appropriately generalize notions ofrank and positive definiteness to tensors in a natural way. Using these notionswe propose a generalization of the matrix exponentiated gradient descentalgorithm [2] to a tensor exponentiated gradient descent algorithm using anextension of the notion of von-Neumann divergence to tensors. Then following asimilar construction as in [3], we exploit this algorithm to propose an onlinealgorithm for learning and prediction of tensors with provable regretguarantees. Simulations results are presented on semi-synthetic data sets ofratings evolving in time under local influence over a social network. Theresult indicate superior performance compared to other (online) convex tensorcompletion methods.
arxiv-12900-289 | An Analytically Tractable Bayesian Approximation to Optimal Point Process Filtering | http://arxiv.org/abs/1507.07813 | author:Yuval Harel, Ron Meir, Manfred Opper category:stat.ML q-bio.NC published:2015-07-28 summary:The process of dynamic state estimation (filtering) based on point processobservations is in general intractable. Numerical sampling techniques are oftenpractically useful, but lead to limited conceptual insight about optimalencoding/decoding strategies, which are of significant relevance toComputational Neuroscience. We develop an analytically tractable Bayesianapproximation to optimal filtering based on point process observations, whichallows us to introduce distributional assumptions about sensory cellproperties, that greatly facilitates the analysis of optimal encoding insituations deviating from common assumptions of uniform coding. The analyticframework leads to insights which are difficult to obtain from numericalalgorithms, and is consistent with experiments about the distribution of tuningcurve centers. Interestingly, we find that the information gained from theabsence of spikes may be crucial to performance.
arxiv-12900-290 | A Multi-Camera Image Processing and Visualization System for Train Safety Assessment | http://arxiv.org/abs/1507.07815 | author:Giuseppe Lisanti, Svebor Karaman, Daniele Pezzatini, Alberto Del Bimbo category:cs.CV published:2015-07-28 summary:In this paper we present a machine vision system to efficiently monitor,analyze and present visual data acquired with a railway overhead gantryequipped with multiple cameras. This solution aims to improve the safety ofdaily life railway transportation in a two- fold manner: (1) by providingautomatic algorithms that can process large imagery of trains (2) by helpingtrain operators to keep attention on any possible malfunction. The system isdesigned with the latest cutting edge, high-rate visible and thermal camerasthat ob- serve a train passing under an railway overhead gantry. The machinevision system is composed of three principal modules: (1) an automatic wagonidentification system, recognizing the wagon ID according to the UICclassification of railway coaches; (2) a temperature monitoring system; (3) asystem for the detection, localization and visualization of the pantograph ofthe train. These three machine vision modules process batch trains sequencesand their resulting analysis are presented to an operator using a multitouchuser interface. We detail all technical aspects of our multi-camera portal: thehardware requirements, the software developed to deal with the high-frame ratecameras and ensure reliable acquisition, the algorithms proposed to solve eachcomputer vision task, and the multitouch interaction and visualizationinterface. We evaluate each component of our system on a dataset recorded in anad-hoc railway test-bed, showing the potential of our proposed portal for trainsafety assessment.
arxiv-12900-291 | Classifying informative and imaginative prose using complex networks | http://arxiv.org/abs/1507.07826 | author:Henrique F. de Arruda, Luciano da F. Costa, Diego R. Amancio category:cs.CL published:2015-07-28 summary:Statistical methods have been widely employed in recent years to grasp manylanguage properties. The application of such techniques have allowed animprovement of several linguistic applications, which encompasses machinetranslation, automatic summarization and document classification. In thelatter, many approaches have emphasized the semantical content of texts, as itis the case of bag-of-word language models. This approach has certainly yieldedreasonable performance. However, some potential features such as the structuralorganization of texts have been used only on a few studies. In this context, weprobe how features derived from textual structure analysis can be effectivelyemployed in a classification task. More specifically, we performed a supervisedclassification aiming at discriminating informative from imaginative documents.Using a networked model that describes the local topological/dynamicalproperties of function words, we achieved an accuracy rate of up to 95%, whichis much higher than similar networked approaches. A systematic analysis offeature relevance revealed that symmetry and accessibility measurements areamong the most prominent network measurements. Our results suggest that thesemeasurements could be used in related language applications, as they play acomplementary role in characterizing texts.
arxiv-12900-292 | A constrained optimization perspective on actor critic algorithms and application to network routing | http://arxiv.org/abs/1507.07984 | author:Prashanth L. A., H. L. Prasad, Shalabh Bhatnagar, Prakash Chandra category:cs.LG math.OC published:2015-07-28 summary:We propose a novel actor-critic algorithm with guaranteed convergence to anoptimal policy for a discounted reward Markov decision process. The actorincorporates a descent direction that is motivated by the solution of a certainnon-linear optimization problem. We also discuss an extension to incorporatefunction approximation and demonstrate the practicality of our algorithms on anetwork routing application.
arxiv-12900-293 | Sparse Multidimensional Patient Modeling using Auxiliary Confidence Labels | http://arxiv.org/abs/1507.07955 | author:Eric Heim, Milos Hauskrecht category:cs.LG published:2015-07-28 summary:In this work, we focus on the problem of learning a classification model thatperforms inference on patient Electronic Health Records (EHRs). Often, a largeamount of costly expert supervision is required to learn such a model. Toreduce this cost, we obtain confidence labels that indicate how sure an expertis in the class labels she provides. If meaningful confidence information canbe incorporated into a learning method, fewer patient instances may need to belabeled to learn an accurate model. In addition, while accuracy of predictionsis important for any inference model, a model of patients must be interpretableso that clinicians can understand how the model is making decisions. To theseends, we develop a novel metric learning method called Confidence bAsed MEtricLearning (CAMEL) that supports inclusion of confidence labels, but alsoemphasizes interpretability in three ways. First, our method induces sparsity,thus producing simple models that use only a few features from patient EHRs.Second, CAMEL naturally produces confidence scores that can be taken intoconsideration when clinicians make treatment decisions. Third, the metricslearned by CAMEL induce multidimensional spaces where each dimension representsa different "factor" that clinicians can use to assess patients. In ourexperimental evaluation, we show on a real-world clinical data set that ourCAMEL methods are able to learn models that are as or more accurate as othermethods that use the same supervision. Furthermore, we show that when CAMELuses confidence scores it is able to learn models as or more accurate as otherswe tested while using only 10% of the training instances. Finally, we performqualitative assessments on the metrics learned by CAMEL and show that theyidentify and clearly articulate important factors in how the model performsinference.
arxiv-12900-294 | Real-time 2D/3D Registration via CNN Regression | http://arxiv.org/abs/1507.07505 | author:Shun Miao, Z. Jane Wang, Rui Liao category:cs.CV published:2015-07-27 summary:In this paper, we present a Convolutional Neural Network (CNN) regressionapproach for real-time 2-D/3-D registration. Different from optimization-basedmethods, which iteratively optimize the transformation parameters over ascalar-valued metric function representing the quality of the registration, theproposed method exploits the information embedded in the appearances of theDigitally Reconstructed Radiograph and X-ray images, and employs CNN regressorsto directly estimate the transformation parameters. The CNN regressors aretrained for local zones and applied in a hierarchical manner to break down thecomplex regression task into simpler sub-tasks that can be learned separately.Our experiment results demonstrate the advantage of the proposed method incomputational efficiency with negligible degradation of registration accuracycompared to intensity-based methods.
arxiv-12900-295 | Distributed Stochastic Variance Reduced Gradient Methods and A Lower Bound for Communication Complexity | http://arxiv.org/abs/1507.07595 | author:Jason D. Lee, Qihang Lin, Tengyu Ma, Tianbao Yang category:math.OC cs.LG stat.ML published:2015-07-27 summary:We study distributed optimization algorithms for minimizing the average ofconvex functions. The applications include empirical risk minimization problemsin statistical machine learning where the datasets are large and have to bestored on different machines. We design a distributed stochastic variancereduced gradient algorithm that, under certain conditions on the conditionnumber, simultaneously achieves the optimal parallel runtime, amount ofcommunication and rounds of communication among all distributed first-ordermethods up to constant factors. Our method and its accelerated extension alsooutperform existing distributed algorithms in terms of the rounds ofcommunication as long as the condition number is not too large compared to thesize of data in each machine. We also prove a lower bound for the number ofrounds of communication for a broad class of distributed first-order methodsincluding the proposed algorithms in this paper. We show that our accelerateddistributed stochastic variance reduced gradient algorithm achieves this lowerbound so that it uses the fewest rounds of communication among all distributedfirst-order algorithms.
arxiv-12900-296 | Estimating an Activity Driven Hidden Markov Model | http://arxiv.org/abs/1507.07495 | author:David A. Meyer, Asif Shakeel category:stat.ML cs.DS cs.LG cs.SI math.ST stat.TH published:2015-07-27 summary:We define a Hidden Markov Model (HMM) in which each hidden state hastime-dependent $\textit{activity levels}$ that drive transitions and emissions,and show how to estimate its parameters. Our construction is motivated by theproblem of inferring human mobility on sub-daily time scales from, for example,mobile phone records.
arxiv-12900-297 | Discovery of Shared Semantic Spaces for Multi-Scene Video Query and Summarization | http://arxiv.org/abs/1507.07458 | author:Xun Xu, Timothy Hospedales, Shaogang Gong category:cs.CV published:2015-07-27 summary:The growing rate of public space CCTV installations has generated a need forautomated methods for exploiting video surveillance data including sceneunderstanding, query, behaviour annotation and summarization. For this reason,extensive research has been performed on surveillance scene understanding andanalysis. However, most studies have considered single scenes, or groups ofadjacent scenes. The semantic similarity between different but related scenes(e.g., many different traffic scenes of similar layout) is not generallyexploited to improve any automated surveillance tasks and reduce manual effort.Exploiting commonality, and sharing any supervised annotations, betweendifferent scenes is however challenging due to: Some scenes are totallyun-related -- and thus any information sharing between them would bedetrimental; while others may only share a subset of common activities -- andthus information sharing is only useful if it is selective. Moreover,semantically similar activities which should be modelled together and sharedacross scenes may have quite different pixel-level appearance in each scene. Toaddress these issues we develop a new framework for distributed multiple-sceneglobal understanding that clusters surveillance scenes by their ability toexplain each other's behaviours; and further discovers which subset ofactivities are shared versus scene-specific within each cluster. We show how touse this structured representation of multiple scenes to improve commonsurveillance tasks including scene activity understanding, cross-scenequery-by-example, behaviour classification with reduced supervised labellingrequirements, and video summarization. In each case we demonstrate how ourmulti-scene model improves on a collection of standard single scene models anda flat model of all scenes.
arxiv-12900-298 | A Social Spider Algorithm for Solving the Non-convex Economic Load Dispatch Problem | http://arxiv.org/abs/1507.07301 | author:James J. Q. Yu, Victor O. K. Li category:cs.NE published:2015-07-27 summary:Economic Load Dispatch (ELD) is one of the essential components in powersystem control and operation. Although conventional ELD formulation can besolved using mathematical programming techniques, modern power systemintroduces new models of the power units which are non-convex,non-differentiable, and sometimes non-continuous. In order to solve suchnon-convex ELD problems, in this paper we propose a new approach based on theSocial Spider Algorithm (SSA). The classical SSA is modified and enhanced toadapt to the unique characteristics of ELD problems, e.g., valve-point effects,multi-fuel operations, prohibited operating zones, and line losses. Todemonstrate the superiority of our proposed approach, five widely-adopted testsystems are employed and the simulation results are compared with thestate-of-the-art algorithms. In addition, the parameter sensitivity isillustrated by a series of simulations. The simulation results show that SSAcan solve ELD problems effectively and efficiently.
arxiv-12900-299 | Occlusion-Aware Object Localization, Segmentation and Pose Estimation | http://arxiv.org/abs/1507.07882 | author:Samarth Brahmbhatt, Heni Ben Amor, Henrik Christensen category:cs.CV published:2015-07-27 summary:We present a learning approach for localization and segmentation of objectsin an image in a manner that is robust to partial occlusion. Our algorithmproduces a bounding box around the full extent of the object and labels pixelsin the interior that belong to the object. Like existing segmentation awaredetection approaches, we learn an appearance model of the object and considerregions that do not fit this model as potential occlusions. However, inaddition to the established use of pairwise potentials for encouraging localconsistency, we use higher order potentials which capture information at thelevel of im- age segments. We also propose an efficient loss function thattargets both localization and segmentation performance. Our algorithm achieves13.52% segmentation error and 0.81 area under the false-positive per image vs.recall curve on average over the challenging CMU Kitchen Occlusion Dataset.This is a 42.44% decrease in segmentation error and a 16.13% increase inlocalization performance compared to the state-of-the-art. Finally, we showthat the visibility labelling produced by our algorithm can make full 3D poseestimation from a single image robust to occlusion.
arxiv-12900-300 | A genetic algorithm for autonomous navigation in partially observable domain | http://arxiv.org/abs/1507.07374 | author:Maxim Borisyak, Andrey Ustyuzhanin category:cs.LG cs.AI cs.NE 68T05 published:2015-07-27 summary:The problem of autonomous navigation is one of the basic problems forrobotics. Although, in general, it may be challenging when an autonomousvehicle is placed into partially observable domain. In this paper we considersimplistic environment model and introduce a navigation algorithm based onLearning Classifier System.
