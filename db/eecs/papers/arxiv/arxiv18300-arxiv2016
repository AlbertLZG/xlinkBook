arxiv-18300-1 | Linear-memory and Decomposition-invariant Linearly Convergent Conditional Gradient Algorithm for Structured Polytopes | http://arxiv.org/pdf/1605.06492v1.pdf | author:Dan Garber, Ofer Meshi category:math.OC cs.LG published:2016-05-20 summary:Recently, several works have shown that natural modifications of theclassical conditional gradient method (aka Frank-Wolfe algorithm) forconstrained convex optimization, provably converge with a linear rate when: i)the feasible set is a polytope, and ii) the objective is smooth andstrongly-convex. However, all of these results suffer from two significantshortcomings: large memory requirement due to the need to store an explicitconvex decomposition of the current iterate, and as a consequence, largerunning-time overhead per iteration, and worst case convergence rate thatdepends unfavorably on the dimension. In this work we present a new conditional gradient variant and acorresponding analysis that improves on both of the above shortcomings. Inparticular: both memory and computation overheads are only linear in thedimension. Moreover, in case the optimal solution is sparse, the newconvergence rate replaces a factor which is at least linear in the dimension inprevious works, with a linear dependence on the number of non-zeros in theoptimal solution. At the heart of our method, and corresponding analysis, is a novel way tocompute decomposition-invariant away-steps. While our theoretical guarantees donot apply to any polytope, they apply to several important structured polytopesthat capture central concepts such as paths in graphs, perfect matchings inbipartite graphs, marginal distributions that arise in structured predictiontasks, and more. Our theoretical findings are complemented by empiricalevidence which shows that our method delivers state-of-the-art performance.
arxiv-18300-2 | Deep Roots: Improving CNN Efficiency with Hierarchical Filter Groups | http://arxiv.org/pdf/1605.06489v1.pdf | author:Yani Ioannou, Duncan Robertson, Roberto Cipolla, Antonio Criminisi category:cs.NE cs.CV cs.LG published:2016-05-20 summary:We propose a new method for training computationally efficient and compactconvolutional neural networks (CNNs) using a novel sparse connection structurethat resembles a tree root. Our sparse connection structure facilitates asignificant reduction in computational cost and number of parameters ofstate-of-the-art deep CNNs without compromising accuracy. We validate ourapproach by using it to train more efficient variants of state-of-the-art CNNarchitectures, evaluated on the CIFAR10 and ILSVRC datasets. Our results showsimilar or higher accuracy than the baseline architectures with much lesscompute, as measured by CPU and GPU timings. For example, for ResNet 50, ourmodel has 40% fewer parameters, 45% fewer floating point operations, and is 31%(12%) faster on a CPU (GPU). For the deeper ResNet 200 our model has 25% fewerfloating point operations and 44% fewer parameters, while maintainingstate-of-the-art accuracy. For GoogLeNet, our model has 7% fewer parameters andis 21% (16%) faster on a CPU (GPU).
arxiv-18300-3 | Regression with n$\to$1 by Expert Knowledge Elicitation | http://arxiv.org/pdf/1605.06477v1.pdf | author:Marta Soare, Muhammad Ammad-ud-din, Samuel Kaski category:cs.LG published:2016-05-20 summary:We consider regression under the "extremely small $n$ large $p$" condition.In particular, we focus on problems with so small sample sizes $n$ compared tothe dimensionality $p$, even $n\to 1$, that predictors cannot be estimatedwithout prior knowledge. Furthermore, we assume all prior knowledge that can beautomatically extracted from databases has already been taken into account.This setup occurs in personalized medicine, for instance, when predictingtreatment outcomes for an individual patient based on noisy high-dimensionalgenomics data. A remaining source of information is expert knowledge which hasreceived relatively little attention in recent years. We formulate theinference problem of asking expert feedback on features on a budget, presentexperimental results for two setups: "small $n$" and "n=1 with similar dataavailable", and derive conditions under which the elicitation strategy isoptimal. Experiments on simulated experts, both on simulated and genomics data,demonstrate that the proposed strategy can drastically improve predictionaccuracy.
arxiv-18300-4 | X-ray image separation via coupled dictionary learning | http://arxiv.org/pdf/1605.06474v1.pdf | author:Nikos Deligiannis, Jo√£o F. C. Mota, Bruno Cornelis, Miguel R. D. Rodrigues, Ingrid Daubechies category:cs.CV published:2016-05-20 summary:In support of art investigation, we propose a new source sepa- ration methodthat unmixes a single X-ray scan acquired from double-sided paintings. Unlikeprior source separation meth- ods, which are based on statistical or structuralincoherence of the sources, we use visual images taken from the front- andback-side of the panel to drive the separation process. The coupling of the twoimaging modalities is achieved via a new multi-scale dictionary learningmethod. Experimental results demonstrate that our method succeeds in thediscrimination of the sources, while state-of-the-art methods fail to do so.
arxiv-18300-5 | Swapout: Learning an ensemble of deep architectures | http://arxiv.org/pdf/1605.06465v1.pdf | author:Saurabh Singh, Derek Hoiem, David Forsyth category:cs.CV cs.LG cs.NE published:2016-05-20 summary:We describe Swapout, a new stochastic training method, that outperformsResNets of identical network structure yielding impressive results on CIFAR-10and CIFAR-100. Swapout samples from a rich set of architectures includingdropout, stochastic depth and residual architectures as special cases. Whenviewed as a regularization method swapout not only inhibits co-adaptation ofunits in a layer, similar to dropout, but also across network layers. Weconjecture that swapout achieves strong regularization by implicitly tying theparameters across layers. When viewed as an ensemble training method, itsamples a much richer set of architectures than existing methods such asdropout or stochastic depth. We propose a parameterization that revealsconnections to exiting architectures and suggests a much richer set ofarchitectures to be explored. We show that our formulation suggests anefficient training method and validate our conclusions on CIFAR-10 andCIFAR-100 matching state of the art accuracy. Remarkably, our 32 layer widermodel performs similar to a 1001 layer ResNet model.
arxiv-18300-6 | Katyusha: The First Truly Accelerated Stochastic Gradient Method | http://arxiv.org/pdf/1603.05953v2.pdf | author:Zeyuan Allen-Zhu category:math.OC cs.DS stat.ML published:2016-03-18 summary:We introduce $\mathtt{Katyusha}$, the first direct stochastic gradient methodthat has an accelerated convergence rate. Given an objective that is an average of $n$ convex and smooth functions,$\mathtt{Katyusha}$ converges to an $\varepsilon$-approximate minimizer using$O((n + \sqrt{n \kappa})\cdot \log\frac{f(x_0)-f(x^*)}{\varepsilon})$stochastic iterations, where $\kappa$ is the condition number.$\mathtt{Katyusha}$ also resolves the following open questions in optimizationand machine learning $\bullet$ For weakly convex and smooth objectives (e.g., Lasso, LogisticRegression), $\mathtt{Katyusha}$ is the first stochastic method that achievesthe optimal $1/\sqrt{\varepsilon}$ rate. $\bullet$ For strongly-convex but non-smooth ERM objectives (e.g., SVM),$\mathtt{Katyusha}$ gives the first stochastic method that achieves the optimal$1/\sqrt{\varepsilon}$ rate. $\bullet$ For weakly convex and non-smooth ERM objectives (e.g., L1SVM),$\mathtt{Katyusha}$ gives the first stochastic method that achieves the optimal$1/\varepsilon$ rate.
arxiv-18300-7 | Virtual Worlds as Proxy for Multi-Object Tracking Analysis | http://arxiv.org/pdf/1605.06457v1.pdf | author:Adrien Gaidon, Qiao Wang, Yohann Cabon, Eleonora Vig category:cs.CV cs.LG cs.NE stat.ML published:2016-05-20 summary:Modern computer vision algorithms typically require expensive dataacquisition and accurate manual labeling. In this work, we instead leverage therecent progress in computer graphics to generate fully labeled, dynamic, andphoto-realistic proxy virtual worlds. We propose an efficient real-to-virtualworld cloning method, and validate our approach by building and publiclyreleasing a new video dataset, called Virtual KITTI (seehttp://www.xrce.xerox.com/Research-Development/Computer-Vision/Proxy-Virtual-Worlds),automatically labeled with accurate ground truth for object detection,tracking, scene and instance segmentation, depth, and optical flow. We providequantitative experimental evidence suggesting that (i) modern deep learningalgorithms pre-trained on real data behave similarly in real and virtualworlds, and (ii) pre-training on virtual data improves performance. As the gapbetween real and virtual worlds is small, virtual worlds enable measuring theimpact of various weather and imaging conditions on recognition performance,all other things being equal. We show these factors may affect drasticallyotherwise high-performing deep models for tracking.
arxiv-18300-8 | Fixed Points of Belief Propagation -- An Analysis via Polynomial Homotopy Continuation | http://arxiv.org/pdf/1605.06451v1.pdf | author:Christian Knoll, Franz Pernkopf, Dhagash Mehta, Tianran Chen category:stat.ML published:2016-05-20 summary:Belief propagation (BP) is an iterative method to perform approximateinference on arbitrary graphical models. Whether BP converges and if thesolution is a unique fixed point depends on both, the structure and theparametrization of the model. To understand this dependence we are interestedin finding \emph{all} fixed points. In this work, we formulate BP as a set ofpolynomial equations, the solutions of which correspond to the BP fixed points.We apply the numerical polynomial-homotopy-continuation (NPHC) method to solvesuch systems. It is commonly believed that uniqueness of BP fixed pointsimplies convergence to this fixed point. Contrary to this conjecture, we findgraphs for which BP fails to converge, even though a unique fixed point exists.Moreover, we show that this fixed point gives a good approximation of the exactmarginal distribution.
arxiv-18300-9 | Query-Efficient Imitation Learning for End-to-End Autonomous Driving | http://arxiv.org/pdf/1605.06450v1.pdf | author:Jiakai Zhang, Kyunghyun Cho category:cs.LG cs.AI cs.RO published:2016-05-20 summary:One way to approach end-to-end autonomous driving is to learn a policyfunction that maps from a sensory input, such as an image frame from afront-facing camera, to a driving action, by imitating an expert driver, or areference policy. This can be done by supervised learning, where a policyfunction is tuned to minimize the difference between the predicted andground-truth actions. A policy function trained in this way however is known tosuffer from unexpected behaviours due to the mismatch between the statesreachable by the reference policy and trained policy functions. More advancedalgorithms for imitation learning, such as DAgger, addresses this issue byiteratively collecting training examples from both reference and trainedpolicies. These algorithms often requires a large number of queries to areference policy, which is undesirable as the reference policy is oftenexpensive. In this paper, we propose an extension of the DAgger, calledSafeDAgger, that is query-efficient and more suitable for end-to-end autonomousdriving. We evaluate the proposed SafeDAgger in a car racing simulator and showthat it indeed requires less queries to a reference policy. We observe asignificant speed up in convergence, which we conjecture to be due to theeffect of automated curriculum learning.
arxiv-18300-10 | ATD: Anomalous Topic Discovery in High Dimensional Discrete Data | http://arxiv.org/pdf/1512.06452v2.pdf | author:Hossein Soleimani, David J. Miller category:stat.ML cs.LG published:2015-12-20 summary:We propose an algorithm for detecting patterns exhibited by anomalousclusters in high dimensional discrete data. Unlike most anomaly detection (AD)methods, which detect individual anomalies, our proposed method detects groups(clusters) of anomalies; i.e. sets of points which collectively exhibitabnormal patterns. In many applications this can lead to better understandingof the nature of the atypical behavior and to identifying the sources of theanomalies. Moreover, we consider the case where the atypical patterns exhibiton only a small (salient) subset of the very high dimensional feature space.Individual AD techniques and techniques that detect anomalies using all thefeatures typically fail to detect such anomalies, but our method can detectsuch instances collectively, discover the shared anomalous patterns exhibitedby them, and identify the subsets of salient features. In this paper, we focuson detecting anomalous topics in a batch of text documents, developing ouralgorithm based on topic models. Results of our experiments show that ourmethod can accurately detect anomalous topics and salient features (words)under each such topic in a synthetic data set and two real-world text corporaand achieves better performance compared to both standard group AD andindividual AD techniques. All required code to reproduce our experiments isavailable from https://github.com/hsoleimani/ATD
arxiv-18300-11 | Unreasonable Effectiveness of Learning Neural Nets: Accessible States and Robust Ensembles | http://arxiv.org/pdf/1605.06444v1.pdf | author:Carlo Baldassi, Christian Borgs, Jennifer Chayes, Alessandro Ingrosso, Carlo Lucibello, Luca Saglietti, Riccardo Zecchina category:stat.ML published:2016-05-20 summary:In artificial neural networks, learning from data is a computationallydemanding task in which a large number of connection weights are iterativelytuned through stochastic-gradient-based heuristic processes over acost-function. It is not well understood how learning occurs in these systems,in particular how they avoid getting trapped in configurations with poorcomputational performance. Here we study the difficult case of networks withdiscrete weights, where the optimization landscape is very rough even forsimple architectures, and provide theoretical and numerical evidence of theexistence of rare---but extremely dense and accessible---regions ofconfigurations in the network weight space. We define a novel measure, which wecall the \emph{robust ensemble} (RE), which suppresses trapping by isolatedconfigurations and amplifies the role of these dense regions. We analyticallycompute the RE in some exactly solvable models, and also provide a generalalgorithmic scheme which is straightforward to implement: define acost-function given by a sum of a finite number of replicas of the originalcost-function, with a constraint centering the replicas around a drivingassignment. To illustrate this, we derive several powerful new algorithms,ranging from Markov Chains to message passing to gradient descent processes,where the algorithms target the robust dense states, resulting in substantialimprovements in performance. The weak dependence on the number of precisionbits of the weights leads us to conjecture that very similar reasoning appliesto more conventional neural networks. Analogous algorithmic schemes can also beapplied to other optimization problems.
arxiv-18300-12 | Structured Prediction Theory and Voted Risk Minimization | http://arxiv.org/pdf/1605.06443v1.pdf | author:Corinna Cortes, Mehryar Mohri, Vitaly Kuznetsov, Scott Yang category:stat.ML cs.LG published:2016-05-20 summary:We present a general theoretical analysis of structured prediction. Byintroducing a new complexity measure that explicitly factors in the structureof the output space and the loss function, we are able to derive newdata-dependent learning guarantees for a broad family of losses and forhypothesis sets with an arbitrary factor graph decomposition. We extend thistheory by leveraging the principle of Voted Risk Minimization (VRM) and showingthat learning is possible with complex factor graphs. We both present newlearning bounds in this advanced setting as well as derive two new families ofalgorithms, \emph{Voted Conditional Random Fields} and \emph{Voted StructuredBoosting}, which can make use of very complex features and factor graphswithout overfitting. Finally, we also validate our theory through experimentson several datasets.
arxiv-18300-13 | Combining Adversarial Guarantees and Stochastic Fast Rates in Online Learning | http://arxiv.org/pdf/1605.06439v1.pdf | author:Wouter M. Koolen, Peter Gr√ºnwald, Tim van Erven category:cs.LG published:2016-05-20 summary:We consider online learning algorithms that guarantee worst-case regret ratesin adversarial environments (so they can be deployed safely and will performrobustly), yet adapt optimally to favorable stochastic environments (so theywill perform well in a variety of settings of practical importance). Wequantify the friendliness of stochastic environments by means of the well-knownBernstein (a.k.a. generalized Tsybakov margin) condition. For two recentalgorithms (Squint for the Hedge setting and MetaGrad for online convexoptimization) we show that the particular form of their data-dependentindividual-sequence regret guarantees implies that they adapt automatically tothe Bernstein parameters of the stochastic environment. We prove that thesealgorithms attain fast rates in their respective settings both in expectationand with high probability.
arxiv-18300-14 | Optimal Black-Box Reductions Between Optimization Objectives | http://arxiv.org/pdf/1603.05642v3.pdf | author:Zeyuan Allen-Zhu, Elad Hazan category:math.OC cs.DS cs.LG stat.ML published:2016-03-17 summary:The diverse world of machine learning applications has given rise to aplethora of algorithms and optimization methods, finely tuned to the specificregression or classification task at hand. We reduce the complexity ofalgorithm design for machine learning by reductions: we develop reductions thattake a method developed for one setting and apply it to the entire spectrum ofsmoothness and strong-convexity in applications. Furthermore, unlike existing results, our new reductions are OPTIMAL and morePRACTICAL. We show how these new reductions give rise to new and faster runningtimes on training linear classifiers for various families of loss functions,and conclude with experiments showing their successes also in practice.
arxiv-18300-15 | Learning shape correspondence with anisotropic convolutional neural networks | http://arxiv.org/pdf/1605.06437v1.pdf | author:Davide Boscaini, Jonathan Masci, Emanuele Rodol√†, Michael M. Bronstein category:cs.CV published:2016-05-20 summary:Establishing correspondence between shapes is a fundamental problem ingeometry processing, arising in a wide variety of applications. The problem isespecially difficult in the setting of non-isometric deformations, as well asin the presence of topological noise and missing parts, mainly due to thelimited capability to model such deformations axiomatically. Several recentworks showed that invariance to complex shape transformations can be learnedfrom examples. In this paper, we introduce an intrinsic convolutional neuralnetwork architecture based on anisotropic diffusion kernels, which we termAnisotropic Convolutional Neural Network (ACNN). In our construction, wegeneralize convolutions to non-Euclidean domains by constructing a set oforiented anisotropic diffusion kernels, creating in this way a local intrinsicpolar representation of the data (`patch'), which is then correlated with afilter. Several cascades of such filters, linear, and non-linear operators arestacked to form a deep neural network whose parameters are learned byminimizing a task-specific cost. We use ACNNs to effectively learn intrinsicdense correspondences between deformable shapes in very challenging settings,achieving state-of-the-art results on some of the most difficult recentcorrespondence benchmarks.
arxiv-18300-16 | Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data | http://arxiv.org/pdf/1605.06432v1.pdf | author:Maximilian Karl, Maximilian Soelch, Justin Bayer, Patrick van der Smagt category:stat.ML cs.LG cs.SY published:2016-05-20 summary:We introduce Deep Variational Bayes Filters (DVBF), a new method forunsupervised learning of latent Markovian state space models. Leveraging recentadvances in Stochastic Gradient Variational Bayes, DVBF can overcomeintractable inference distributions by means of variational inference. Thus, itcan handle highly nonlinear input data with temporal and spatial dependenciessuch as image sequences without domain knowledge. Our experiments show thatenabling backpropagation through transitions enforces state space assumptionsand significantly improves information content of the latent embedding. Thisalso enables realistic long-term prediction.
arxiv-18300-17 | An unsupervised spatiotemporal graphical modeling approach to anomaly detection in distributed CPS | http://arxiv.org/pdf/1512.07876v2.pdf | author:Chao Liu, Sambuddha Ghosal, Zhanhong Jiang, Soumik Sarkar category:cs.LG published:2015-12-24 summary:Modern distributed cyber-physical systems (CPSs) encounter a large variety ofphysical faults and cyber anomalies and in many cases, they are vulnerable tocatastrophic fault propagation scenarios due to strong connectivity among thesub-systems. This paper presents a new data-driven framework for system-wideanomaly detection for addressing such issues. The framework is based on aspatiotemporal feature extraction scheme built on the concept of symbolicdynamics for discovering and representing causal interactions among thesubsystems of a CPS. The extracted spatiotemporal features are then used tolearn system-wide patterns via a Restricted Boltzmann Machine (RBM). Theresults show that: (1) the RBM free energy in the off-nominal conditions isdifferent from that in the nominal conditions and can be used for anomalydetection; (2) the framework can capture multiple nominal modes with onegraphical model; (3) the case studies with simulated data and an integratedbuilding system validate the proposed approach.
arxiv-18300-18 | Residual Networks are Exponential Ensembles of Relatively Shallow Networks | http://arxiv.org/pdf/1605.06431v1.pdf | author:Andreas Veit, Michael Wilber, Serge Belongie category:cs.CV cs.AI cs.LG cs.NE published:2016-05-20 summary:In this work, we introduce a novel interpretation of residual networksshowing they are exponential ensembles. This observation is supported by alarge-scale lesion study that demonstrates they behave just like ensembles attest time. Subsequently, we perform an analysis showing these ensembles mostlyconsist of networks that are each relatively shallow. For example, contrary toour expectations, most of the gradient in a residual network with 110 layerscomes from an ensemble of very short networks, i.e., only 10-34 layers deep.This suggests that in addition to describing neural networks in terms of widthand depth, there is a third dimension: multiplicity, the size of the implicitensemble. Ultimately, residual networks do not resolve the vanishing gradientproblem by preserving gradient flow throughout the entire depth of the network- rather, they avoid the problem simply by ensembling many short networkstogether. This insight reveals that depth is still an open research questionand invites the exploration of the related notion of multiplicity.
arxiv-18300-19 | Coresets for Scalable Bayesian Logistic Regression | http://arxiv.org/pdf/1605.06423v1.pdf | author:Jonathan H. Huggins, Trevor Campbell, Tamara Broderick category:stat.CO cs.DS stat.ML published:2016-05-20 summary:The use of Bayesian models in large-scale data settings is attractive becauseof the rich hierarchical models, uncertainty quantification, and priorspecification they provide. Standard Bayesian inference algorithms arecomputationally expensive, however, making their direct application to largedatasets difficult or infeasible. Recent work on scaling Bayesian inference hasfocused on modifying the underlying algorithms to, for example, use only arandom data subsample at each iteration. We leverage the insight that data isoften redundant to instead obtain a weighted subset of the data (called acoreset) that is much smaller than the original dataset. We can then use thissmall coreset in any number of existing posterior inference algorithms withoutmodification. In this paper, we develop an efficient coreset constructionalgorithm for Bayesian logistic regression models. We provide theoreticalguarantees on the size and approximation quality of the coreset -- both forfixed, known datasets, and in expectation for a wide class of data generativemodels. The proposed approach also permits efficient construction of thecoreset in both streaming and parallel settings, with minimal additionaleffort. We demonstrate the efficacy of our approach on a number of syntheticand real-world datasets, and find that, in practice, the size of the coreset isindependent of the original dataset size.
arxiv-18300-20 | Fast Randomized Semi-Supervised Clustering | http://arxiv.org/pdf/1605.06422v1.pdf | author:Alaa Saade, Florent Krzakala, Marc Lelarge, Lenka Zdeborov√° category:cs.LG stat.ML published:2016-05-20 summary:We consider the problem of clustering partially labeled data from a minimalnumber of randomly chosen pairwise comparisons between the items. We introducean efficient local algorithm based on a power iteration of the non-backtrackingoperator and study its performance on a simple model. For the case of twoclusters, we give bounds on the classification error and show that a smallerror can be achieved from $O(n)$ randomly chosen measurements, where $n$ isthe number of items in the dataset. Our algorithm is therefore efficient bothin terms of time and space complexities. We also investigate numerically theperformance of the algorithm on synthetic and real world data.
arxiv-18300-21 | Root-cause analysis for time-series anomalies via spatiotemporal causal graphical modeling | http://arxiv.org/pdf/1605.06421v1.pdf | author:Chao Liu, Kin Gwn Lore, Soumik Sarkar category:cs.LG published:2016-05-20 summary:Modern distributed cyber-physical systems encounter a large variety ofanomalies and in many cases, they are vulnerable to catastrophic faultpropagation scenarios due to strong connectivity among the sub-systems. In thisregard, root-cause analysis becomes highly intractable due to complex faultpropagation mechanisms in combination with diverse operating modes. This paperpresents a new data-driven framework for root-cause analysis for addressingsuch issues. The framework is based on a spatiotemporal feature extractionscheme for multivariate time series built on the concept of symbolic dynamicsfor discovering and representing causal interactions among subsystems of acomplex system. We propose sequential state switching ($S^3$) and artificialanomaly association ($A^3$) methods to implement root-cause analysis in anunsupervised and semi-supervised manner respectively. Synthetic data from caseswith failed pattern(s) and anomalous node are simulated to validate theproposed approaches, then compared with the performance of vectorautoregressive (VAR) model-based root-cause analysis. The results show that:(1) $S^3$ and $A^3$ approaches can obtain high accuracy in root-cause analysisand successfully handle multiple nominal operation modes, and (2) the proposedtool-chain is shown to be scalable while maintaining high accuracy.
arxiv-18300-22 | Quantifying the accuracy of approximate diffusions and Markov chains | http://arxiv.org/pdf/1605.06420v1.pdf | author:Jonathan H. Huggins, James Zou category:math.ST math.PR stat.CO stat.ML stat.TH published:2016-05-20 summary:Diffusions and their discretizations as Markov chains are a workhorse forinference, sampling and modeling. With the growth of large-scale datasets, thecomputational cost associated with simulating these stochastic processes can beconsiderable, and many algorithms have been proposed to approximate theunderlying Markov chain or diffusion. A fundamental question is how thecomputational savings trade off against the statistical error incurred due toapproximations. This paper develops general results to investigate thisquestion. We bound the Wasserstein distance between the equilibriumdistributions of two diffusions as a function of their mixing rates and thedeviation in their drifts. We show that this error bound is exact in simpleGaussian settings. This general result on continuous diffusions can bediscretized to provide insights on the computational--statistical trade-off ofMarkov chains. As an illustration, we apply our framework to derivefinite-sample error bounds of approximate unadjusted Langevin dynamics. Wecharacterize computation-constrained settings where, by using fast-to-computeapproximate gradients in the Langevin dynamics, we obtain more accurate samplescompared to using the exact gradients. Our theoretical analyses are supportedby simulation experiments.
arxiv-18300-23 | Shape Recognition by Bag of Skeleton-associated Contour Parts | http://arxiv.org/pdf/1605.06417v1.pdf | author:Wei Shen, Yuan Jiang, Wenjing Gao, Dan Zeng, Xinggang Wang category:cs.CV published:2016-05-20 summary:Contour and skeleton are two complementary representations for shaperecognition. However combining them in a principal way is nontrivial, as theyare generally abstracted by different structures (closed string vs graph),respectively. This paper aims at addressing the shape recognition problem bycombining contour and skeleton according to the correspondence between them.The correspondence provides a straightforward way to associate skeletalinformation with a shape contour. More specifically, we propose a new shapedescriptor. named Skeleton-associated Shape Context (SSC), which captures thefeatures of a contour fragment associated with skeletal information. Benefitedfrom the association, the proposed shape descriptor provides the complementarygeometric information from both contour and skeleton parts, including thespatial distribution and the thickness change along the shape part. To form ameaningful shape feature vector for an overall shape, the Bag of Featuresframework is applied to the SSC descriptors extracted from it. Finally, theshape feature vector is fed into a linear SVM classifier to recognize theshape. The encouraging experimental results demonstrate that the proposed wayto combine contour and skeleton is effective for shape recognition, whichachieves the state-of-the-art performances on several standard shapebenchmarks.
arxiv-18300-24 | Statistical Inference for Cluster Trees | http://arxiv.org/pdf/1605.06416v1.pdf | author:Yen-Chi Chen, Jisu Kim, Sivaraman Balakrishnan, Alessandro Rinaldo, Larry Wasserman category:math.ST stat.ME stat.ML stat.TH published:2016-05-20 summary:A cluster tree provides a highly-interpretable summary of a density functionby representing the hierarchy of its high-density clusters. It is estimatedusing the empirical tree, which is the cluster tree constructed from a densityestimator. This paper addresses the basic question of quantifying ouruncertainty by assessing the statistical significance of features of anempirical cluster tree. We first study a variety of metrics that can be used tocompare different trees, analyze their properties and assess their suitabilityfor inference. We then propose methods to construct and summarize confidencesets for the unknown true cluster tree. We introduce a partial ordering oncluster trees which we use to prune some of the statistically insignificantfeatures of the empirical tree, yielding interpretable and parsimonious clustertrees. Finally, we illustrate the proposed methods on a variety of syntheticexamples and furthermore demonstrate their utility in the analysis of aGraft-versus-Host Disease (GvHD) data set.
arxiv-18300-25 | A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues | http://arxiv.org/pdf/1605.06069v2.pdf | author:Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin, Joelle Pineau, Aaron Courville, Yoshua Bengio category:cs.CL cs.AI cs.LG cs.NE I.5.1; I.2.7 published:2016-05-19 summary:Sequential data often possesses a hierarchical structure with complexdependencies between subsequences, such as found between the utterances in adialogue. In an effort to model this kind of generative process, we propose aneural network-based generative architecture, with latent stochastic variablesthat span a variable number of time steps. We apply the proposed model to thetask of dialogue response generation and compare it with recent neural networkarchitectures. We evaluate the model performance through automatic evaluationmetrics and by carrying out a human evaluation. The experiments demonstratethat our model improves upon recently proposed models and that the latentvariables facilitate the generation of long outputs and maintain the context.
arxiv-18300-26 | R-FCN: Object Detection via Region-based Fully Convolutional Networks | http://arxiv.org/pdf/1605.06409v1.pdf | author:Jifeng Dai, Yi Li, Kaiming He, Jian Sun category:cs.CV published:2016-05-20 summary:We present region-based, fully convolutional networks for accurate andefficient object detection. In contrast to previous region-based detectors suchas Fast/Faster R-CNN that apply a costly per-region subnetwork hundreds oftimes, our region-based detector is fully convolutional with almost allcomputation shared on the entire image. To achieve this goal, we proposeposition-sensitive score maps to address a dilemma betweentranslation-invariance in image classification and translation-variance inobject detection. Our method can thus naturally adopt fully convolutional imageclassifier backbones, such as the latest Residual Networks (ResNets), forobject detection. We show competitive results on the PASCAL VOC datasets (e.g.,83.6% mAP on the 2007 set) with the 101-layer ResNet. Meanwhile, our result isachieved at a test-time speed of 170ms per image, 2.5-20x faster than theFaster R-CNN counterpart. Code will be made publicly available.
arxiv-18300-27 | Ristretto: Hardware-Oriented Approximation of Convolutional Neural Networks | http://arxiv.org/pdf/1605.06402v1.pdf | author:Philipp Gysel category:cs.CV cs.LG cs.NE published:2016-05-20 summary:Convolutional neural networks (CNN) have achieved major breakthroughs inrecent years. Their performance in computer vision have matched and in someareas even surpassed human capabilities. Deep neural networks can capturecomplex non-linear features; however this ability comes at the cost of highcomputational and memory requirements. State-of-art networks require billionsof arithmetic operations and millions of parameters. To enable embedded devicessuch as smartphones, Google glasses and monitoring cameras with the astonishingpower of deep learning, dedicated hardware accelerators can be used to decreaseboth execution time and power consumption. In applications where fastconnection to the cloud is not guaranteed or where privacy is important,computation needs to be done locally. Many hardware accelerators for deepneural networks have been proposed recently. A first important step ofaccelerator design is hardware-oriented approximation of deep networks, whichenables energy-efficient inference. We present Ristretto, a fast and automatedframework for CNN approximation. Ristretto simulates the hardware arithmetic ofa custom hardware accelerator. The framework reduces the bit-width of networkparameters and outputs of resource-intense layers, which reduces the chip areafor multiplication units significantly. Alternatively, Ristretto can remove theneed for multipliers altogether, resulting in an adder-only arithmetic. Thetool fine-tunes trimmed networks to achieve high classification accuracy. Sincetraining of deep neural networks can be time-consuming, Ristretto uses highlyoptimized routines which run on the GPU. This enables fast compression of anygiven network. Given a maximum tolerance of 1%, Ristretto can successfullycondense CaffeNet and SqueezeNet to 8-bit. The code for Ristretto is available.
arxiv-18300-28 | Stochastic Variance Reduction Methods for Saddle-Point Problems | http://arxiv.org/pdf/1605.06398v1.pdf | author:P Balamurugan, Francis Bach category:cs.LG math.OC published:2016-05-20 summary:We consider convex-concave saddle-point problems where the objectivefunctions may be split in many components, and extend recent stochasticvariance reduction methods (such as SVRG or SAGA) to provide the firstlarge-scale linearly convergent algorithms for this class of problems which iscommon in machine learning. While the algorithmic extension is straightforward,it comes with challenges and opportunities: (a) the convex minimizationanalysis does not apply and we use the notion of monotone operators to proveconvergence, showing in particular that the same algorithm applies to a largerclass of problems, such as variational inequalities, (b) there are two notionsof splits, in terms of functions, or in terms of partial derivatives, (c) thesplit does need to be done with convex-concave terms, (d) non-uniform samplingis key to an efficient algorithm, both in theory and practice, and (e) theseincremental algorithms can be easily accelerated using a simple extension ofthe "catalyst" framework, leading to an algorithm which is always superior toaccelerated batch algorithms.
arxiv-18300-29 | Bayesian Hyperparameter Optimization for Ensemble Learning | http://arxiv.org/pdf/1605.06394v1.pdf | author:Julien-Charles L√©vesque, Christian Gagn√©, Robert Sabourin category:cs.LG published:2016-05-20 summary:In this paper, we bridge the gap between hyperparameter optimization andensemble learning by performing Bayesian optimization of an ensemble withregards to its hyperparameters. Our method consists in building a fixed-sizeensemble, optimizing the configuration of one classifier of the ensemble ateach iteration of the hyperparameter optimization algorithm, taking intoconsideration the interaction with the other models when evaluating potentialperformances. We also consider the case where the ensemble is to bereconstructed at the end of the hyperparameter optimization phase, through agreedy selection over the pool of models generated during the optimization. Westudy the performance of our proposed method on three different hyperparameterspaces, showing that our approach is better than both the best single model anda greedy ensemble construction over the models produced by a standard Bayesianoptimization.
arxiv-18300-30 | Deep Multi-task Representation Learning: A Tensor Factorisation Approach | http://arxiv.org/pdf/1605.06391v1.pdf | author:Yongxin Yang, Timothy Hospedales category:cs.LG published:2016-05-20 summary:Most contemporary multi-task learning methods assume linear models. Thissetting is considered shallow in the era of deep learning. In this paper, wepresent a new deep multi-task representation learning framework that learnscross-task sharing structure at every layer in a deep network. Our approach isbased on generalising the matrix factorisation techniques explicitly orimplicitly used by many conventional MTL algorithms to tensor factorisation, torealise automatic learning of end-to-end knowledge sharing in deep networks.This is in contrast to existing deep learning approaches that need auser-defined multi-task sharing strategy. Our approach applies to bothhomogeneous and heterogeneous MTL. Experiments demonstrate the efficacy of ourdeep multi-task representation learning in terms of both higher accuracy andfewer design choices.
arxiv-18300-31 | Towards Automation of Knowledge Understanding: An Approach for Probabilistic Generative Classifiers | http://arxiv.org/pdf/1605.06377v1.pdf | author:Dominik Fisch, Christian Gruhl, Edgar Kalkowski, Bernhard Sick, Seppo J. Ovaska category:cs.LG cs.AI published:2016-05-20 summary:After data selection, pre-processing, transformation, and feature extraction,knowledge extraction is not the final step in a data mining process. It is thennecessary to understand this knowledge in order to apply it efficiently andeffectively. Up to now, there is a lack of appropriate techniques that supportthis significant step. This is partly due to the fact that the assessment ofknowledge is often highly subjective, e.g., regarding aspects such as noveltyor usefulness. These aspects depend on the specific knowledge and requirementsof the data miner. There are, however, a number of aspects that are objectiveand for which it is possible to provide appropriate measures. In this articlewe focus on classification problems and use probabilistic generativeclassifiers based on mixture density models that are quite common in datamining applications. We define objective measures to assess theinformativeness, uniqueness, importance, discrimination, representativity,uncertainty, and distinguishability of rules contained in these classifiersnumerically. These measures not only support a data miner in evaluating resultsof a data mining process based on such classifiers. As we will see inillustrative case studies, they may also be used to improve the data miningprocess itself or to support the later application of the extracted knowledge.
arxiv-18300-32 | Fast $Œµ$-free Inference of Simulation Models with Bayesian Conditional Density Estimation | http://arxiv.org/pdf/1605.06376v1.pdf | author:George Papamakarios, Iain Murray category:stat.ML cs.LG stat.CO published:2016-05-20 summary:Many statistical models can be simulated forwards but have intractablelikelihoods. Approximate Bayesian Computation (ABC) methods are used to inferproperties of these models from data. Traditionally these methods approximatethe posterior over parameters by conditioning on data being inside an$\epsilon$-ball around the observed data, which is only correct in the limit$\epsilon\!\rightarrow\!0$. Monte Carlo methods can then draw samples from theapproximate posterior to approximate predictions or error bars on parameters.These algorithms critically slow down as $\epsilon\!\rightarrow\!0$, and inpractice draw samples from a broader distribution than the posterior. Wepropose a new approach to likelihood-free inference based on Bayesianconditional density estimation. Preliminary inferences based on limitedsimulation data are used to guide later simulations. In some cases, learning anaccurate parametric representation of the entire true posterior distributionrequires fewer model simulations than Monte Carlo ABC methods need to produce asingle sample from an approximate posterior.
arxiv-18300-33 | A Network-based End-to-End Trainable Task-oriented Dialogue System | http://arxiv.org/pdf/1604.04562v2.pdf | author:Tsung-Hsien Wen, David Vandyke, Nikola Mrksic, Milica Gasic, Lina M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, Steve Young category:cs.CL cs.AI cs.NE stat.ML published:2016-04-15 summary:Teaching machines to accomplish tasks by conversing naturally with humans ischallenging. Currently, developing task-oriented dialogue systems requirescreating multiple components and typically this involves either a large amountof handcrafting, or acquiring labelled datasets and solving a statisticallearning problem for each component. In this work we introduce a neuralnetwork-based text-in, text-out end-to-end trainable dialogue system along witha new way of collecting task-oriented dialogue data based on a novel pipe-linedWizard-of-Oz framework. This approach allows us to develop dialogue systemseasily and without making too many assumptions about the task at hand. Theresults show that the model can converse with human subjects naturally whilsthelping them to accomplish tasks in a restaurant search domain.
arxiv-18300-34 | Quantum Energy Regression using Scattering Transforms | http://arxiv.org/pdf/1502.02077v3.pdf | author:Matthew Hirn, Nicolas Poilvert, St√©phane Mallat category:cs.LG cs.CV quant-ph published:2015-02-06 summary:We present a novel approach to the regression of quantum mechanical energiesbased on a scattering transform of an intermediate electron densityrepresentation. A scattering transform is a deep convolution network computedwith a cascade of multiscale wavelet transforms. It possesses appropriateinvariant and stability properties for quantum energy regression. This newframework removes fundamental limitations of Coulomb matrix based energyregressions, and numerical experiments give state-of-the-art accuracy overplanar molecules.
arxiv-18300-35 | Learning to Discover Probabilistic Graphical Model Structures | http://arxiv.org/pdf/1605.06359v1.pdf | author:Eugene Belilovsky, Kyle Kastner, Ga√´l Varoquaux, Matthew Blaschko category:stat.ML published:2016-05-20 summary:In this work we consider structure discovery of undirected graphical modelsfrom observational data. Inferring likely structures from few examples is acomplex task often requiring formulating priors and sophisticated inferenceprocedures. In the setting of Gaussian Graphical Models (GGMs) a popularapproach to formulating an estimator is with a penalized maximum likelihoodobjective on the precision matrix. This objective is often difficult to designto specifically fit ones priors and the graph structure recovery is often notexplicitly possible to embed in the objective, moreover incorporating anyadditional assumptions often requires a great deal of research effort. Bycontrast, it may be easier to generate samples of data that are arise fromgraphs with the desired properties. We propose here to leverage this lattersource of information in order to learn a function that maps from empiricalcovariance matrices to estimated graph structures. This learned function bringstwo benefits: it implicitly models the desired structure or sparsity propertiesto form suitable priors, and it can more directly be tailored to the specificproblem of edge structure discovery. We apply this framework to severalcritical real world problems in structure discovery and show that it can becompetitive to standard approaches such as graphical lasso, at a fraction ofthe execution speed. We use deep neural networks to parametrize our estimators.Experimentally, our learn able graph discovery method trained on synthetic datageneralizes well to different data: identifying relevant edges in real data,completely unknown at training time. We find that on genetics, brain imaging,and simulation data we obtain competitive (and often superior) performance,compared with analytical methods.
arxiv-18300-36 | Phrase-based Machine Translation is State-of-the-Art for Automatic Grammatical Error Correction | http://arxiv.org/pdf/1605.06353v1.pdf | author:Marcin Junczys-Dowmunt, Roman Grundkiewicz category:cs.CL published:2016-05-20 summary:In this work, we study parameter tuning towards the M$^2$ metric, thestandard metric for automatic grammar error correction (GEC) tasks. Afterimplementing M$^2$ as a scorer in the Moses tuning framework, we investigateinteractions of dense and sparse features, different optimizers, and tuningstrategies for the CoNLL-2014 shared task. We notice erratic behavior whenoptimizing sparse feature weights with M$^2$ and offer partial solutions. Toour surprise, we find that a bare-bones phrase-based SMT setup withtask-specific parameter-tuning outperforms all previously published results forthe CoNLL-2014 test set by a large margin (46.37% M$^2$ over previously 40.56%,by a neural encoder-decoder model) while being trained on the same data. Ournewly introduced dense and sparse features widen that gap, and we improve thestate-of-the-art to 49.49% M$^2$.
arxiv-18300-37 | Localized Lasso for High-Dimensional Regression | http://arxiv.org/pdf/1603.06743v2.pdf | author:Makoto Yamada, Koh Takeuchi, Tomoharu Iwata, John Shawe-Taylor, Samuel Kaski category:stat.ML cs.LG stat.ME published:2016-03-22 summary:We introduce the localized Lasso, which is suited for learning models thatare both interpretable and have a high predictive power in problems with highdimensionality $d$ and small sample size $n$. More specifically, we consider afunction defined by local sparse models, one at each data point. We introducesample-wise network regularization to borrow strength across the models, andsample-wise exclusive group sparsity (a.k.a., $\ell_{1,2}^2$ norm) to introducediversity into the choice of feature sets in the local models. The local modelsare interpretable in terms of similarity of their sparsity patterns. The costfunction is convex, and thus has a globally optimal solution. Moreover, wepropose a simple yet efficient iterative least-squares based optimizationprocedure for the localized Lasso, which does not need a tuning parameter, andis guaranteed to converge to a globally optimal solution. The solution isempirically shown to outperform alternatives for both simulated and genomicpersonalized medicine data.
arxiv-18300-38 | A Spectral Algorithm with Additive Clustering for the Recovery of Overlapping Communities in Networks | http://arxiv.org/pdf/1506.04158v2.pdf | author:Emilie Kaufmann, Thomas Bonald, Marc Lelarge category:stat.ML published:2015-06-12 summary:This paper presents a novel spectral algorithm with additive clustering,designed to identify overlapping communities in networks. The algorithm isbased on geometric properties of the spectrum of the expected adjacency matrixin a random graph model that we call stochastic blockmodel withoverlap (SBMO).An adaptive version of the algorithm, that does not require the knowledge ofthe number of hidden communities, is proved to be consistent under the SBMOwhen the degrees in the graph are (slightly more than) logarithmic. Thealgorithm is shown to perform well on simulateddata and on real-world graphswith known overlapping communities.
arxiv-18300-39 | Unsupervised Feature Extraction by Time-Contrastive Learning and Nonlinear ICA | http://arxiv.org/pdf/1605.06336v1.pdf | author:Aapo Hyvarinen, Hiroshi Morioka category:stat.ML cs.LG published:2016-05-20 summary:Nonlinear independent component analysis (ICA) provides an appealingframework for unsupervised feature learning, but the models proposed so far arenot identifiable. Here, we first propose a new intuitive principle ofunsupervised deep learning from time series which uses the nonstationarystructure of the data. Our learning principle, time-contrastive learning (TCL),finds a representation which allows optimal discrimination of time segments(windows). Surprisingly, we show how TCL can be related to a nonlinear ICAmodel, when ICA is redefined to include temporal nonstationarities. Inparticular, we show that TCL combined with linear ICA estimates the nonlinearICA model up to point-wise transformations of the sources, and this solution isunique --- thus providing the first identifiability result for nonlinear ICAwhich is rigorous, constructive, as well as very general.
arxiv-18300-40 | Superpixel Hierarchy | http://arxiv.org/pdf/1605.06325v1.pdf | author:Xing Wei, Qingxiong Yang, Yihong Gong, Ming-Hsuan Yang, Narendra Ahuja category:cs.CV published:2016-05-20 summary:Superpixel segmentation is becoming ubiquitous in computer vision. Inpractice, an object can either be represented by a number of segments in finerlevels of detail or included in a surrounding region at coarser levels ofdetail, and thus a superpixel segmentation hierarchy is useful for applicationsthat require different levels of image segmentation detail depending on theparticular image objects segmented. Unfortunately, there is no method that cangenerate all scales of superpixels accurately in real-time. As a result, asimple yet effective algorithm named Super Hierarchy (SH) is proposed in thispaper. It is as accurate as the state-of-the-art but 1-2 orders of magnitudefaster. The proposed method can be directly integrated with recent efficientedge detectors like the structured forest edges to significantly outperformsthe state-of-the-art in terms of segmentation accuracy. Quantitative andqualitative evaluation on a number of computer vision applications wasconducted, demonstrating that the proposed method is the top performer.
arxiv-18300-41 | Random sampling of bandlimited signals on graphs | http://arxiv.org/pdf/1511.05118v2.pdf | author:Gilles Puy, Nicolas Tremblay, R√©mi Gribonval, Pierre Vandergheynst category:cs.SI cs.LG stat.ML published:2015-11-16 summary:We study the problem of sampling k-bandlimited signals on graphs. We proposetwo sampling strategies that consist in selecting a small subset of nodes atrandom. The first strategy is non-adaptive, i.e., independent of the graphstructure, and its performance depends on a parameter called the graphcoherence. On the contrary, the second strategy is adaptive but yields optimalresults. Indeed, no more than O(k log(k)) measurements are sufficient to ensurean accurate and stable recovery of all k-bandlimited signals. This secondstrategy is based on a careful choice of the sampling distribution, which canbe estimated quickly. Then, we propose a computationally efficient decoder toreconstruct k-bandlimited signals from their samples. We prove that it yieldsaccurate reconstructions and that it is also stable to noise. Finally, weconduct several experiments to test these techniques.
arxiv-18300-42 | A single hidden layer feedforward network with only one neuron in the hidden layer can approximate any univariate function | http://arxiv.org/pdf/1601.00013v2.pdf | author:Namig J. Guliyev, Vugar E. Ismailov category:cs.NE cs.IT math.IT math.NA published:2015-12-31 summary:The possibility of approximating a continuous function on a compact subset ofthe real line by a feedforward single hidden layer neural network with asigmoidal activation function has been studied in many papers. Such networkscan approximate an arbitrary continuous function provided that an unlimitednumber of neurons in a hidden layer is permitted. In this paper, we considerconstructive approximation on any finite interval of $\mathbb{R}$ by neuralnetworks with only one neuron in the hidden layer. We construct algorithmicallya smooth, sigmoidal, almost monotone activation function $\sigma$ providingapproximation to an arbitrary continuous function within any degree ofaccuracy. This algorithm is implemented in a computer program, which computesthe value of $\sigma$ at any reasonable point of the real axis.
arxiv-18300-43 | As Cool as a Cucumber: Towards a Corpus of Contemporary Similes in Serbian | http://arxiv.org/pdf/1605.06319v1.pdf | author:Nikola Milosevic, Goran Nenadic category:cs.CL cs.AI published:2016-05-20 summary:Similes are natural language expressions used to compare unlikely things,where the comparison is not taken literally. They are often used in everydaycommunication and are an important part of cultural heritage. Having anup-to-date corpus of similes is challenging, as they are constantly coinedand/or adapted to the contemporary times. In this paper we present amethodology for semi-automated collection of similes from the world wide webusing text mining techniques. We expanded an existing corpus of traditionalsimiles (containing 333 similes) by collecting 446 additional expressions. We,also, explore how crowdsourcing can be used to extract and curate new similes.
arxiv-18300-44 | Poisson multi-Bernoulli conjugate prior for multiple extended object estimation | http://arxiv.org/pdf/1605.06311v1.pdf | author:Karl Granstrom, Maryam Fatemi, Lennart Svensson category:stat.CO cs.CV cs.SY published:2016-05-20 summary:This paper presents a Poisson multi-Bernoulli mixture (PMBM) conjugate priorfor multiple extended object estimation. A Poisson point process is used todescribe the existence of yet undetected targets, while a multi-Bernoullimixture describes the distribution of the targets that have been detected. Theconjugacy property allows the posterior PMBM density to be computed exactly,meaning that given enough computational power the PMBM filter is correct.However, in practice, the data association problem requires approximations. Theupdate and the prediction of the PMBM density parameters are presented and aregiven interpretations, and a simple linear Gaussian implementation is presentedalong with methods to handle the data association problem. A simulation studyshows that the extended target PMBM filter outperforms the extended targetcardinalized probability hypothesis density (CPHD) filter in scenarios wherethe expected number of detections per target per time step is low.
arxiv-18300-45 | Online Optimization of Smoothed Piecewise Constant Functions | http://arxiv.org/pdf/1604.01999v2.pdf | author:Vincent Cohen-Addad, Varun Kanade category:cs.LG stat.ML published:2016-04-07 summary:We study online optimization of smoothed piecewise constant functions overthe domain [0, 1). This is motivated by the problem of adaptively pickingparameters of learning algorithms as in the recently introduced framework byGupta and Roughgarden (2016). Majority of the machine learning literature hasfocused on Lipschitz-continuous functions or functions with bounded gradients.1 This is with good reason---any learning algorithm suffers linear regret evenagainst piecewise constant functions that are chosen adversarially, arguablythe simplest of non-Lipschitz continuous functions. The smoothed setting weconsider is inspired by the seminal work of Spielman and Teng (2004) and therecent work of Gupta and Roughgarden---in this setting, the sequence offunctions may be chosen by an adversary, however, with some uncertainty in thelocation of discontinuities. We give algorithms that achieve sublinear regretin the full information and bandit settings.
arxiv-18300-46 | Local communities obstruct global consensus: Naming game on multi-local-world networks | http://arxiv.org/pdf/1605.06304v1.pdf | author:Yang Lou, Guanrong Chen, Zhengping Fan, Luna Xiang category:cs.SI cs.CL physics.soc-ph published:2016-05-20 summary:Community structure is essential for social communications, where individualsbelonging to the same community are much more actively interacting andcommunicating with each other than those in different communities within thehuman society. Naming game, on the other hand, is a social communication modelthat simulates the process of learning a name of an object within a communityof humans, where the individuals can reach global consensus on naming an objectasymptotically through iterative pair-wise conversations. The underlyingcommunication network indicates the relationships among the individuals. Inthis paper, three typical topologies of human communication networks, namelyrandom-graph, small-world and scale-free networks, are employed, which areembedded with the multi-local-world community structure, to study the naminggame. Simulations show that 1) when the intra-community connections increasewhile the inter-community connections remain to be unchanged, the convergenceto global consensus is slow and eventually might fail; 2) when theinter-community connections are sufficiently dense, both the number and thesize of the communities do not affect the convergence process; and 3) fordifferent topologies with the same average node-degree, local clustering ofindividuals obstruct or prohibit global consensus to take place. The resultsreveal the role of local communities in a global naming game in social networkstudies.
arxiv-18300-47 | On the Robustness of Decision Tree Learning under Label Noise | http://arxiv.org/pdf/1605.06296v1.pdf | author:Aritra Ghosh, Naresh Manwani, P. S. Sastry category:cs.LG published:2016-05-20 summary:In most practical problems of classifier learning, the training data suffersfrom the label noise. Hence, it is important to understand how robust is alearning algorithm to such label noise. Experimentally, Decision trees havebeen found to be more robust against label noise than SVM and logisticregression. This paper presents some theoretical results to show that decisiontree algorithms are robust to symmetric label noise under the assumption oflarge sample size. We also present some sample complexity results for thisrobustness. Through extensive simulations we illustrate this robustness.
arxiv-18300-48 | Towards Storytelling from Visual Lifelogging: An Overview | http://arxiv.org/pdf/1507.06120v4.pdf | author:Marc Bola√±os, Mariella Dimiccoli, Petia Radeva category:cs.CV published:2015-07-22 summary:Visual lifelogging consists of acquiring images that capture the dailyexperiences of the user by wearing a camera over a long period of time. Thepictures taken offer considerable potential for knowledge mining concerning howpeople live their lives, hence, they open up new opportunities for manypotential applications in fields including healthcare, security, leisure andthe quantified self. However, automatically building a story from a hugecollection of unstructured egocentric data presents major challenges. Thispaper provides a thorough review of advances made so far in egocentric dataanalysis, and in view of the current state of the art, indicates new lines ofresearch to move us towards storytelling from visual lifelogging.
arxiv-18300-49 | Piece-wise quadratic lego set for constructing arbitrary error potentials and their fast optimization | http://arxiv.org/pdf/1605.06276v1.pdf | author:A. N. Gorban, E. M. Mirkes, A. Zinovyev category:cs.LG stat.ML published:2016-05-20 summary:Most of machine learning approaches have stemmed from the application ofminimizing the mean squared distance principle, based on the computationallyefficient quadratic optimization methods. However, when faced withhigh-dimensional and noisy data, the quadratic error functionals demonstratemany weaknesses including high sensitivity to contaminating factors anddimensionality curse. Therefore, a lot of recent applications in machinelearning exploited the properties of non-quadratic error functionals based onL1 norm or even sub-linear potentials corresponding to fractional norms. Theback side of these approaches is tremendous increase in computational cost foroptimization. Till so far, no approaches have been suggested to deal with {\itarbitrary} error functionals, in a flexible and computationally efficientframework. In this paper, we develop the theory and basic universal dataapproximation algorithms ($k$-means, principal components, principal manifoldsand graphs), based on piece-wise quadratic error potentials of subquadraticgrowth (PQSQ potentials). We develop a new and universal framework to minimize{\it arbitrary sub-quadratic error potentials} using an algorithm withguaranteed fast convergence to the local or global error minimum. The approachcan be applied in most of existing machine learning methods, including methodsof data approximation and regularized regression, leading to the improvement inthe computational cost/accuracy trade-off.
arxiv-18300-50 | End-to-End Kernel Learning with Supervised Convolutional Kernel Networks | http://arxiv.org/pdf/1605.06265v1.pdf | author:Julien Mairal category:stat.ML cs.CV cs.LG published:2016-05-20 summary:In this paper, we propose a new image representation based on a multilayerkernel machine that performs end-to-end learning. Unlike traditional kernelmethods, where the kernel is handcrafted or adapted to data in an unsupervisedmanner, we learn how to shape the kernel for a supervised prediction problem.We proceed by generalizing convolutional kernel networks, which originallyprovide unsupervised image representations, and we derive backpropagation rulesto optimize model parameters. As a result, we obtain a new type ofconvolutional neural network with the following properties: (i) at each layer,learning filters is equivalent to optimizing a linear subspace in a reproducingkernel Hilbert space (RKHS), where we project data, (ii) the network may belearned with supervision or without, (iii) the model comes with a naturalregularization function (the norm in the RKHS). We show that our methodachieves reasonably competitive performance on some standard "deep learning"image classification datasets such as CIFAR-10 and SVHN, and alsostate-of-the-art results for image super-resolution, demonstrating theapplicability of our approach to a large variety of image-related tasks.
arxiv-18300-51 | R√©nyi Divergence Variational Inference | http://arxiv.org/pdf/1602.02311v2.pdf | author:Yingzhen Li, Richard E. Turner category:stat.ML cs.LG published:2016-02-06 summary:This paper introduces the variational R\'enyi bound (VR) that extendstraditional variational inference to R\'enyi's alpha-divergences. This newfamily of variational methods unifies a number of existing approaches, andenables a smooth interpolation from the evidence lower-bound to the logmarginal likelihood that is controlled by the value of alpha that parametrisesthe divergence. The reparameterization trick, Monte Carlo approximation andstochastic optimisation methods are deployed to obtain a unified framework foroptimisation. We further consider negative alpha values and propose a novelvariational inference method as a new special case in the proposed framework.Experiments on Bayesian neural networks and variational auto-encodersdemonstrate the wide applicability of the VR bound.
arxiv-18300-52 | A Latent-Variable Lattice Model | http://arxiv.org/pdf/1512.07587v5.pdf | author:Rajasekaran Masatran category:cs.LG cs.CV stat.ML published:2015-12-23 summary:The MRF is frequently used in computer vision, but MRF approximationalgorithms are computationally expensive. Since only a small subset of MRF isused in computer vision, we characterize this subset with three concepts: (1)Lattice, (2) Homogenity, and (3) Inertia. We design a non-markov high-biaslow-variance model as an alternative to this subclass of MRF. Our goal isrobust learning, from small datasets. Our learning algorithm uses vectorquantization and, at time complexity O(T^d log T^d) for a hypercube of sizeT^d, is much faster than that of MRF.
arxiv-18300-53 | FPNN: Field Probing Neural Networks for 3D Data | http://arxiv.org/pdf/1605.06240v1.pdf | author:Yangyan Li, Soeren Pirk, Hao Su, Charles R. Qi, Leonidas J. Guibas category:cs.CV I.5.1, I.2.10 published:2016-05-20 summary:Building discriminative representations for 3D data has been an importanttask in computer graphics and computer vision research. Convolutional NeuralNetworks (CNNs) have shown to operate on 2D images with great success for avariety of tasks. Lifting convolution operators to 3D (3DCNNs) seems like aplausible and promising next step. Unfortunately, the computational complexityof 3D CNNs grows cubically with respect to voxel resolution. Moreover, sincemost 3D geometry representations are boundary based, occupied regions do notincrease proportionately with the size of the discretization, resulting inwasted computation. In this work, we represent 3D spaces as volumetric fields,and propose a novel design that employs field probing filters to efficientlyextract features from them. Each field probing filter is a set of probingpoints --- sensors that perceive the space. Our learning algorithm optimizesnot only the weights associated with the probing points, but also theirlocations, which deforms the shape of the probing filters and adaptivelydistributes them in 3D space. The optimized probing points sense the 3D space"intelligently", rather than operating blindly over the entire domain. We showthat field probing is significantly more efficient than 3DCNNs, while providingstate-of-the-art performance, on classification tasks for 3D object recognitionbenchmark datasets.
arxiv-18300-54 | SPSD Matrix Approximation vis Column Selection: Theories, Algorithms, and Extensions | http://arxiv.org/pdf/1406.5675v6.pdf | author:Shusen Wang, Luo Luo, Zhihua Zhang category:cs.LG published:2014-06-22 summary:Symmetric positive semidefinite (SPSD) matrix approximation is an importantproblem with applications in kernel methods. However, existing SPSD matrixapproximation methods such as the Nystr\"om method only have weak error bounds.In this paper we conduct in-depth studies of an SPSD matrix approximation modeland establish strong relative-error bounds. We call it the prototype model forit has more efficient and effective extensions, and some of its extensions havehigh scalability. Though the prototype model itself is not suitable forlarge-scale data, it is still useful to study its properties, on which theanalysis of its extensions relies. This paper offers novel theoretical analysis, efficient algorithms, and ahighly accurate extension. First, we establish a lower error bound for theprototype model and improve the error bound of an existing column selectionalgorithm to match the lower bound. In this way, we obtain the first optimalcolumn selection algorithm for the prototype model. We also prove that theprototype model is exact under certain conditions. Second, we develop a simplecolumn selection algorithm with a provable error bound. Third, we propose aso-called spectral shifting model to make the approximation more accurate whenthe eigenvalues of the matrix decay slowly, and the improvement istheoretically quantified. The spectral shifting method can also be applied toimprove other SPSD matrix approximation models.
arxiv-18300-55 | Brain Tumor Segmentation with Deep Neural Networks | http://arxiv.org/pdf/1505.03540v3.pdf | author:Mohammad Havaei, Axel Davy, David Warde-Farley, Antoine Biard, Aaron Courville, Yoshua Bengio, Chris Pal, Pierre-Marc Jodoin, Hugo Larochelle category:cs.CV cs.AI published:2015-05-13 summary:In this paper, we present a fully automatic brain tumor segmentation methodbased on Deep Neural Networks (DNNs). The proposed networks are tailored toglioblastomas (both low and high grade) pictured in MR images. By their verynature, these tumors can appear anywhere in the brain and have almost any kindof shape, size, and contrast. These reasons motivate our exploration of amachine learning solution that exploits a flexible, high capacity DNN whilebeing extremely efficient. Here, we give a description of different modelchoices that we've found to be necessary for obtaining competitive performance.We explore in particular different architectures based on Convolutional NeuralNetworks (CNN), i.e. DNNs specifically adapted to image data. We present a novel CNN architecture which differs from those traditionallyused in computer vision. Our CNN exploits both local features as well as moreglobal contextual features simultaneously. Also, different from mosttraditional uses of CNNs, our networks use a final layer that is aconvolutional implementation of a fully connected layer which allows a 40 foldspeed up. We also describe a 2-phase training procedure that allows us totackle difficulties related to the imbalance of tumor labels. Finally, weexplore a cascade architecture in which the output of a basic CNN is treated asan additional source of information for a subsequent CNN. Results reported onthe 2013 BRATS test dataset reveal that our architecture improves over thecurrently published state-of-the-art while being over 30 times faster.
arxiv-18300-56 | Convergence of Contrastive Divergence with Annealed Learning Rate in Exponential Family | http://arxiv.org/pdf/1605.06220v1.pdf | author:Bai Jiang, Tung-yu Wu, Wing H. Wong category:stat.ML cs.LG published:2016-05-20 summary:In our recent paper, we showed that in exponential family, contrastivedivergence (CD) with fixed learning rate will give asymptotically consistentestimates \cite{wu2016convergence}. In this paper, we establish consistency andconvergence rate of CD with annealed learning rate $\eta_t$. Specifically,suppose CD-$m$ generates the sequence of parameters $\{\theta_t\}_{t \ge 0}$using an i.i.d. data sample $\mathbf{X}_1^n \sim p_{\theta^*}$ of size $n$,then $\delta_n(\mathbf{X}_1^n) = \limsup_{t \to \infty} \Vert \sum_{s=t_0}^t\eta_s \theta_s / \sum_{s=t_0}^t \eta_s - \theta^* \Vert$ converges inprobability to 0 at a rate of $1/\sqrt[3]{n}$. The number ($m$) of MCMCtransitions in CD only affects the coefficient factor of convergence rate. Ourproof is not a simple extension of the one in \cite{wu2016convergence}. whichdepends critically on the fact that $\{\theta_t\}_{t \ge 0}$ is a homogeneousMarkov chain conditional on the observed sample $\mathbf{X}_1^n$. Underannealed learning rate, the homogeneous Markov property is not available and wehave to develop an alternative approach based on super-martingales. Experimentresults of CD on a fully-visible $2\times 2$ Boltzmann Machine are provided todemonstrate our theoretical results.
arxiv-18300-57 | Localizing by Describing: Attribute-Guided Attention Localization for Fine-Grained Recognition | http://arxiv.org/pdf/1605.06217v1.pdf | author:Xiao Liu, Jiang Wang, Shilei Wen, Errui Ding, Yuanqing Lin category:cs.CV published:2016-05-20 summary:A key challenge in fine-grained recognition is how to find and representdiscriminative local regions. Recent attention models are capable of learningdiscriminative region localizers only from category labels with reinforcementlearning. However, not utilizing any explicit part information, they are notable to accurately find multiple distinctive regions. In this work, weintroduce an attribute-guided attention localization scheme where the localregion localizers are learned under the guidance of part attributedescriptions. By designing a novel reward strategy, we are able to learn tolocate regions that are spatially and semantically distinctive withreinforcement learning algorithm. The attribute labeling requirement of thescheme is more amenable than the accurate part location annotation required bytraditional part-based fine-grained recognition methods. Experimental resultson the CUB-200-2011 dataset demonstrate the superiority of the proposed schemeon both fine-grained recognition and attribute recognition.
arxiv-18300-58 | TRIM: Triangulating Images for Efficient Registration | http://arxiv.org/pdf/1605.06215v1.pdf | author:Chun Pang Yung, Gary Pui-Tung Choi, Ke Chen, Lok Ming Lui category:cs.GR cs.CG cs.CV published:2016-05-20 summary:With the advancement in the digital camera technology, the use of highresolution images and videos has been widespread in the modern society. Inparticular, image and video frame registration is frequently applied incomputer graphics and film production. However, the conventional registrationapproaches usually require long computational time for high quality images andvideo frames. This hinders the applications of the registration approaches inthe modern industries. In this work, we propose a novel approach called {\emTRIM} to accelerate the computations of the registration by triangulating theimages. More specifically, given a high resolution image or video frame, wecompute an optimal coarse triangulation which captures the important featuresof the image. Then, the computation of the registration can be simplified withthe aid of the coarse triangulation. Experimental results suggest that thecomputational time of the registration is significantly reduced using ourtriangulation-based approach, meanwhile the accuracy of the registration iswell retained when compared with the conventional grid-based approach.
arxiv-18300-59 | Facial Expression Recognition from World Wild Web | http://arxiv.org/pdf/1605.03639v2.pdf | author:Ali Mollahosseini, Behzad Hassani, Michelle J. Salvador, Hojjat Abdollahi, David Chan, Mohammad H. Mahoor category:cs.CV cs.NE published:2016-05-11 summary:Recognizing facial expression in a wild setting has remained a challengingtask in computer vision. The World Wide Web is a good source of facial imageswhich most of them are captured in uncontrolled conditions. In fact, theInternet is a Word Wild Web of facial images with expressions. This paperpresents the results of a new study on collecting, annotating, and analyzingwild facial expressions from the web. Three search engines were queried using1250 emotion related keywords in six different languages and the retrievedimages were mapped by two annotators to six basic expressions and neutral. Deepneural networks and noise modeling were used in three different trainingscenarios to find how accurately facial expressions can be recognized whentrained on noisy images collected from the web using query terms (e.g. happyface, laughing man, etc)? The results of our experiments show that deep neuralnetworks can recognize wild facial expressions with an accuracy of 82.12%.
arxiv-18300-60 | Fully Convolutional Networks for Semantic Segmentation | http://arxiv.org/pdf/1605.06211v1.pdf | author:Evan Shelhamer, Jonathan Long, Trevor Darrell category:cs.CV published:2016-05-20 summary:Convolutional networks are powerful visual models that yield hierarchies offeatures. We show that convolutional networks by themselves, trainedend-to-end, pixels-to-pixels, improve on the previous best result in semanticsegmentation. Our key insight is to build "fully convolutional" networks thattake input of arbitrary size and produce correspondingly-sized output withefficient inference and learning. We define and detail the space of fullyconvolutional networks, explain their application to spatially dense predictiontasks, and draw connections to prior models. We adapt contemporaryclassification networks (AlexNet, the VGG net, and GoogLeNet) into fullyconvolutional networks and transfer their learned representations byfine-tuning to the segmentation task. We then define a skip architecture thatcombines semantic information from a deep, coarse layer with appearanceinformation from a shallow, fine layer to produce accurate and detailedsegmentations. Our fully convolutional network achieves improved segmentationof PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFTFlow, and PASCAL-Context, while inference takes one tenth of a second for atypical image.
arxiv-18300-61 | Efficient Globally Convergent Stochastic Optimization for Canonical Correlation Analysis | http://arxiv.org/pdf/1604.01870v3.pdf | author:Weiran Wang, Jialei Wang, Dan Garber, Nathan Srebro category:cs.LG published:2016-04-07 summary:We study the stochastic optimization of canonical correlation analysis (CCA),whose objective is nonconvex and does not decouple over training samples.Although several stochastic gradient based optimization algorithms have beenrecently proposed to solve this problem, no global convergence guarantee wasprovided by any of them. Inspired by the alternating least squares/poweriterations formulation of CCA, and the shift-and-invert preconditioning methodfor PCA, we propose two globally convergent meta-algorithms for CCA, both ofwhich transform the original problem into sequences of least squares problemsthat need only be solved approximately. We instantiate the meta-algorithms withstate-of-the-art SGD methods and obtain time complexities that significantlyimprove upon that of previous work. Experimental results demonstrate theirsuperior performance.
arxiv-18300-62 | Faster Projection-free Convex Optimization over the Spectrahedron | http://arxiv.org/pdf/1605.06203v1.pdf | author:Dan Garber category:math.OC cs.LG published:2016-05-20 summary:Minimizing a convex function over the spectrahedron, i.e., the set of allpositive semidefinite matrices with unit trace, is an important optimizationtask with many applications in optimization, machine learning, and signalprocessing. It is also notoriously difficult to solve in large-scale sincestandard techniques require expensive matrix decompositions. An alternative, isthe conditional gradient method (aka Frank-Wolfe algorithm) that regained muchinterest in recent years, mostly due to its application to this specificsetting. The key benefit of the CG method is that it avoids expensive matrixdecompositions all together, and simply requires a single eigenvectorcomputation per iteration, which is much more efficient. On the downside, theCG method, in general, converges with an inferior rate. The error forminimizing a $\beta$-smooth function after $t$ iterations scales like$\beta/t$. This convergence rate does not improve even if the function is alsostrongly convex. In this work we present a modification of the CG method tailored for convexoptimization over the spectrahedron. The per-iteration complexity of the methodis essentially identical to that of the standard CG method: only a singleeigenvecor computation is required. For minimizing an $\alpha$-strongly convexand $\beta$-smooth function, the expected approximation error of the methodafter $t$ iterations is: $$O\left({\min\{\frac{\beta{}}{t},\left({\frac{\beta\sqrt{\textrm{rank}(\textbf{X}^*)}}{\alpha^{1/4}t}}\right)^{4/3},\left({\frac{\beta}{\sqrt{\alpha}\lambda_{\min}(\textbf{X}^*)t}}\right)^{2}\}}\right),$$ where $\textbf{X}^*$ is the optimal solution. To the best of our knowledge,this is the first result that attains provably faster convergence rates for aCG variant for optimization over the spectrahedron. We also present encouragingpreliminary empirical results.
arxiv-18300-63 | Adversarial Delays in Online Strongly-Convex Optimization | http://arxiv.org/pdf/1605.06201v1.pdf | author:Daniel Khashabi, Kent Quanrud, Amirhossein Taghvaei category:cs.LG cs.AI stat.ML published:2016-05-20 summary:We consider the problem of strongly-convex online optimization in presence ofadversarial delays; in a T-iteration online game, the feedback of the player'squery at time t is arbitrarily delayed by an adversary for d_t rounds anddelivered before the game ends, at iteration t+d_t-1. Specifically for\algo{online-gradient-descent} algorithm we show it has a simple regret boundof \Oh{\sum_{t=1}^T \log (1+ \frac{d_t}{t})}. This gives a clear and simplebound without resorting any distributional and limiting assumptions on thedelays. We further show how this result encompasses and generalizes several ofthe existing known results in the literature. Specifically it matches thecelebrated logarithmic regret \Oh{\log T} when there are no delays (i.e. d_t =1) and regret bound of \Oh{\tau \log T} for constant delays d_t = \tau.
arxiv-18300-64 | Dialog-based Language Learning | http://arxiv.org/pdf/1604.06045v4.pdf | author:Jason Weston category:cs.CL published:2016-04-20 summary:A long-term goal of machine learning research is to build an intelligentdialog agent. Most research in natural language understanding has focused onlearning from fixed training sets of labeled data, with supervision either atthe word level (tagging, parsing tasks) or sentence level (question answering,machine translation). This kind of supervision is not realistic of how humanslearn, where language is both learned by, and used for, communication. In thiswork, we study dialog-based language learning, where supervision is givennaturally and implicitly in the response of the dialog partner during theconversation. We study this setup in two domains: the bAbI dataset of (Westonet al., 2015) and large-scale question answering from (Dodge et al., 2015). Weevaluate a set of baseline learning strategies on these tasks, and show that anovel model incorporating predictive lookahead is a promising approach forlearning from a teacher's response. In particular, a surprising result is thatit can learn to answer questions correctly without any reward-based supervisionat all.
arxiv-18300-65 | Deep Generative Models with Stick-Breaking Priors | http://arxiv.org/pdf/1605.06197v1.pdf | author:Eric Nalisnick, Padhraic Smyth category:stat.ML published:2016-05-20 summary:Bayesian nonparametric models are attractive for their data-dependentcapacity, but their implementation can be problematic due to computational oranalytical obstacles. We make progress on this problem by extending StochasticGradient Variational Bayes (Kingma & Welling, 2013), a 'black box' method forapproximate posterior inference, to stick-breaking priors (Ishwaran & James,2001). This innovation allows us to define deep generative models (DGMs) withinfinite dimensional latent variables. We experimentally demonstrate that DGMswith Dirichlet process priors learn highly discriminative latentrepresentations that are well suited for semi-supervised settings and oftenoutperform the popular Gaussian alternative.
arxiv-18300-66 | Deep Action Sequence Learning for Causal Shape Transformation | http://arxiv.org/pdf/1605.05368v2.pdf | author:Kin Gwn Lore, Daniel Stoecklein, Michael Davies, Baskar Ganapathysubramanian, Soumik Sarkar category:cs.LG cs.CV cs.NE published:2016-05-17 summary:Deep learning (DL) became the method of choice in recent years for solvingproblems ranging from object recognition and speech recognition to roboticperception and human disease prediction. In this paper, we present a hybridarchitecture of convolutional neural networks (CNN) and stacked autoencoders(SAE) to learn a sequence of actions that nonlinearly transforms an input shapeor distribution into a target shape or distribution with the same support.While such a framework can be useful in a variety of problems such as roboticpath planning, sequential decision-making in games and identifying materialprocessing pathways to achieve desired microstructures, this paper focuses oncontrolling fluid deformations in a microfluidic channel by deliberatelyplacing a sequence of pillars, which has a significant impact on manufacturingfor biomedical and textile applications where highly targeted shapes aredesired. We propose an architecture which simultaneously predicts theintermediate shape lying in the nonlinear transformation pathway between theundeformed and desired flow shape, then learns the causal action--the singlepillar which results in the deformation of the flow--one at a time. Thelearning of stage-wise transformations provides deep insights into the physicalflow deformation. Results show that under the current framework, our model isable to predict a sequence of pillars that reconstructs the flow shape whichhighly resembles the desired shape.
arxiv-18300-67 | Re-ranking Object Proposals for Object Detection in Automatic Driving | http://arxiv.org/pdf/1605.05904v2.pdf | author:Zhun Zhong, Mingyi Lei, Shaozi Li, Jianping Fan category:cs.CV published:2016-05-19 summary:Object detection often suffers from a plenty of bootless proposals, selectinghigh quality proposals remains a great challenge. In this paper, we propose asemantic, class-specific approach to re-rank object proposals, which canconsistently improve the recall performance even with less proposals. We firstextract features for each proposal including semantic segmentation, stereoinformation, contextual information, CNN-based objectness and low-level cue,and then score them using class-specific weights learnt by Structured SVM. Theadvantages of the proposed model are twofold: 1) it can be easily merged toexisting generators with few computational costs, and 2) it can achieve highrecall rate uner strict critical even using less proposals. Experimentalevaluation on the KITTI benchmark demonstrates that our approach significantlyimproves existing popular generators on recall performance. Moreover, in theexperiment conducted for object detection, even with 1,500 proposals, ourapproach can still have higher average precision (AP) than baselines with 5,000proposals.
arxiv-18300-68 | Modelling Interaction of Sentence Pair with coupled-LSTMs | http://arxiv.org/pdf/1605.05573v2.pdf | author:Pengfei Liu, Xipeng Qiu, Xuanjing Huang category:cs.CL published:2016-05-18 summary:Recently, there is rising interest in modelling the interactions of twosentences with deep neural networks. However, most of the existing methodsencode two sequences with separate encoders, in which a sentence is encodedwith little or no information from the other sentence. In this paper, wepropose a deep architecture to model the strong interaction of sentence pairwith two coupled-LSTMs. Specifically, we introduce two coupled ways to modelthe interdependences of two LSTMs, coupling the local contextualizedinteractions of two sentences. We then aggregate these interactions and use adynamic pooling to select the most informative features. Experiments on twovery large datasets demonstrate the efficacy of our proposed architecture andits superiority to state-of-the-art methods.
arxiv-18300-69 | Dimensionality Reduction on SPD Manifolds: The Emergence of Geometry-Aware Methods | http://arxiv.org/pdf/1605.06182v1.pdf | author:Mehrtash Harandi, Mathieu Salzmann, Richard Hartley category:cs.CV published:2016-05-20 summary:Representing images and videos with Symmetric Positive Definite (SPD)matrices, and considering the Riemannian geometry of the resulting space, hasbeen shown to yield high discriminative power in many visual recognition tasks.Unfortunately, computation on the Riemannian manifold of SPD matrices-especially of high-dimensional ones- comes at a high cost that limits theapplicability of existing techniques. In this paper, we introduce algorithmsable to handle high-dimensional SPD matrices by constructing alower-dimensional SPD manifold. To this end, we propose to model the mappingfrom the high-dimensional SPD manifold to the low-dimensional one with anorthonormal projection. This lets us formulate dimensionality reduction as theproblem of finding a projection that yields a low-dimensional manifold eitherwith maximum discriminative power in the supervised scenario, or with maximumvariance of the data in the unsupervised one. We show that learning can beexpressed as an optimization problem on a Grassmann manifold and discuss fastsolutions for special cases. Our evaluation on several classification tasksevidences that our approach leads to a significant accuracy gain overstate-of-the-art methods.
arxiv-18300-70 | Variational hybridization and transformation for large inaccurate noisy-or networks | http://arxiv.org/pdf/1605.06181v1.pdf | author:Yusheng Xie, Nan Du, Wei Fan, Jing Zhai, Weicheng Zhu category:cs.LG cs.AI stat.ML published:2016-05-20 summary:Variational inference provides approximations to the computationallyintractable posterior distribution in Bayesian networks. A prominent medicalapplication of noisy-or Bayesian network is to infer potential diseases givenobserved symptoms. Previous studies focus on approximating a handful ofcomplicated pathological cases using variational transformation. Our goal is touse variational transformation as part of a novel hybridized inference forserving reliable and real time diagnosis at web scale. We propose a hybridizedinference that allows variational parameters to be estimated without diseaseposteriors or priors, making the inference faster and much of its computationrecyclable. In addition, we propose a transformation ranking algorithm that isvery stable to large variances in network prior probabilities, a common issuethat arises in medical applications of Bayesian networks. In experiments, weperform comparative study on a large real life medical network and scalabilitystudy on a much larger (36,000x) synthesized network.
arxiv-18300-71 | Fine-Grained Classification of Pedestrians in Video: Benchmark and State of the Art | http://arxiv.org/pdf/1605.06177v1.pdf | author:David Hall, Pietro Perona category:cs.CV published:2016-05-20 summary:A video dataset that is designed to study fine-grained categorisation ofpedestrians is introduced. Pedestrians were recorded "in-the-wild" from amoving vehicle. Annotations include bounding boxes, tracks, 14 keypoints withocclusion information and the fine-grained categories of age (5 classes), sex(2 classes), weight (3 classes) and clothing style (4 classes). There are atotal of 27,454 bounding box and pose labels across 4222 tracks. This datasetis designed to train and test algorithms for fine-grained categorisation ofpeople, it is also useful for benchmarking tracking, detection and poseestimation of pedestrians. State-of-the-art algorithms for fine-grainedclassification and pose estimation were tested using the dataset and theresults are reported as a useful performance baseline.
arxiv-18300-72 | Evaluation System for a Bayesian Optimization Service | http://arxiv.org/pdf/1605.06170v1.pdf | author:Ian Dewancker, Michael McCourt, Scott Clark, Patrick Hayes, Alexandra Johnson, George Ke category:cs.LG published:2016-05-19 summary:Bayesian optimization is an elegant solution to the hyperparameteroptimization problem in machine learning. Building a reliable and robustBayesian optimization service requires careful testing methodology and soundstatistical analysis. In this talk we will outline our development of anevaluation framework to rigorously test and measure the impact of changes tothe SigOpt optimization service. We present an overview of our evaluationsystem and discuss how this framework empowers our research engineers toconfidently and quickly make changes to our core optimization engine
arxiv-18300-73 | Neural Machine Translation by Jointly Learning to Align and Translate | http://arxiv.org/pdf/1409.0473v7.pdf | author:Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio category:cs.CL cs.LG cs.NE stat.ML published:2014-09-01 summary:Neural machine translation is a recently proposed approach to machinetranslation. Unlike the traditional statistical machine translation, the neuralmachine translation aims at building a single neural network that can bejointly tuned to maximize the translation performance. The models proposedrecently for neural machine translation often belong to a family ofencoder-decoders and consists of an encoder that encodes a source sentence intoa fixed-length vector from which a decoder generates a translation. In thispaper, we conjecture that the use of a fixed-length vector is a bottleneck inimproving the performance of this basic encoder-decoder architecture, andpropose to extend this by allowing a model to automatically (soft-)search forparts of a source sentence that are relevant to predicting a target word,without having to form these parts as a hard segment explicitly. With this newapproach, we achieve a translation performance comparable to the existingstate-of-the-art phrase-based system on the task of English-to-Frenchtranslation. Furthermore, qualitative analysis reveals that the(soft-)alignments found by the model agree well with our intuition.
arxiv-18300-74 | Inter-Battery Topic Representation Learning | http://arxiv.org/pdf/1605.06155v1.pdf | author:Cheng Zhang, Hedvig Kjellstrom, Carl Henrik Ek category:cs.LG cs.CV published:2016-05-19 summary:In this paper, we present the Inter-Battery Topic Model (IBTM). Our approachextends traditional topic models by learning a factorized latent variablerepresentation. The structured representation leads to a model that marriesbenefits traditionally associated with a discriminative approach, such asfeature selection, with those of a generative model, such as principledregularization and ability to handle missing data. The factorization isprovided by representing data in terms of aligned pairs of observations asdifferent views. This provides means for selecting a representation thatseparately models topics that exist in both views from the topics that areunique to a single view. This structured consolidation allows for efficient androbust inference and provides a compact and efficient representation. Learningis performed in a Bayesian fashion by maximizing a rigorous bound on thelog-likelihood. Firstly, we illustrate the benefits of the model on a syntheticdataset,. The model is then evaluated in both uni- and multi-modality settingson two different classification tasks with off-the-shelf convolutional neuralnetwork (CNN) features which generate state-of-the-art results with extremelycompact representations.
arxiv-18300-75 | How Deep Neural Networks Can Improve Emotion Recognition on Video Data | http://arxiv.org/pdf/1602.07377v2.pdf | author:Pooya Khorrami, Tom Le Paine, Kevin Brady, Charlie Dagli, Thomas S. Huang category:cs.CV published:2016-02-24 summary:We consider the task of dimensional emotion recognition on video data usingdeep learning. While several previous methods have shown the benefits oftraining temporal neural network models such as recurrent neural networks(RNNs) on hand-crafted features, few works have considered combiningconvolutional neural networks (CNNs) with RNNs. In this work, we present asystem that performs emotion recognition on video data using both CNNs andRNNs, and we also analyze how much each neural network component contributes tothe system's overall performance. We present our findings on videos from theAudio/Visual+Emotion Challenge (AV+EC2015). In our experiments, we analyze theeffects of several hyperparameters on overall performance while also achievingsuperior performance to the baseline and other competing methods.
arxiv-18300-76 | Variational Inference for On-line Anomaly Detection in High-Dimensional Time Series | http://arxiv.org/pdf/1602.07109v4.pdf | author:Maximilian Soelch, Justin Bayer, Marvin Ludersdorfer, Patrick van der Smagt category:stat.ML cs.LG published:2016-02-23 summary:Approximate variational inference has shown to be a powerful tool formodeling unknown complex probability distributions. Recent advances in thefield allow us to learn probabilistic models of sequences that ac- tivelyexploit spatial and temporal structure. We apply a Stochastic Recurrent Network(STORN) to learn robot time series data. Our evaluation demonstrates that wecan ro- bustly detect anomalies both off- and on-line.
arxiv-18300-77 | Development of a 3D tongue motion visualization platform based on ultrasound image sequences | http://arxiv.org/pdf/1605.06106v1.pdf | author:Kele Xu, Yin Yang, Aurore Jaumard-Hakoun, Clemence Leboullenger, Gerard Dreyfus, Pierre Roussel, Maureen Stone, Bruce Denby category:cs.CV published:2016-05-19 summary:This article describes the development of a platform designed to visualizethe 3D motion of the tongue using ultrasound image sequences. An overview ofthe system design is given and promising results are presented. Compared to theanalysis of motion in 2D image sequences, such a system can provide additionalvisual information and a quantitative description of the tongue 3D motion. Theplatform can be useful in a variety of fields, such as speech production,articulation training, etc.
arxiv-18300-78 | Automatic Selection of the Optimal Local Feature Detector | http://arxiv.org/pdf/1605.06094v1.pdf | author:Bruno Ferrarini, Shoaib Ehsan, Naveed Ur Rehman, Ales Leonardis, Klaus D. McDonald-Maier category:cs.CV published:2016-05-19 summary:A large number of different feature detectors has been proposed so far. Anyexisting approach presents strengths and weaknesses, which make a detectoroptimal only for a limited range of applications. A tool capable of selectingthe optimal feature detector in relation to the operating conditions ispresented in this paper. The input images are quickly analyzed to determinewhat type of image transformation is applied to them and at which amount.Finally, the detector that is expected to obtain the highest repeatabilityunder such conditions, is chosen to extract features from the input images. Theefficiency and the good accuracy in determining the optimal feature detectorfor any operating condition, make the proposed tool suitable to be utilized inreal visual applications. %A large number of different feature detectors hasbeen proposed so far. Any existing approach presents strengths and weaknesses,which make a detector optimal only for a limited range of applications. A largenumber of different local feature detectors have been proposed in the last fewyears. However, each feature detector has its own strengths ad weaknesses thatlimit its use to a specific range of applications. In this paper is presented atool capable of quickly analysing input images to determine which type andamount of transformation is applied to them and then selecting the optimalfeature detector, which is expected to perform the best. The results show thatthe performance and the fast execution time render the proposed tool suitablefor real-world vision applications.
arxiv-18300-79 | Low-rank passthrough neural networks | http://arxiv.org/pdf/1603.03116v2.pdf | author:Antonio Valerio Miceli Barone category:cs.LG cs.NE published:2016-03-10 summary:Deep learning consists in training neural networks to perform computationsthat sequentially unfold in many steps over a time dimension or an intrinsicdepth dimension. Effective learning in this setting is usually accomplished byspecialized network architectures that are designed to mitigate the vanishinggradient problem of naive deep networks. Many of these architectures, such asLSTMs, GRUs, Highway Networks and Deep Residual Network, are based on a singlestructural principle: the state passthrough. We observe that these architectures, hereby characterized as PassthroughNetworks, in addition to the mitigation of the vanishing gradient problem,enable the decoupling of the network state size from the number of parametersof the network, a possibility that is exploited in some recent works but notthoroughly explored. In this work we propose simple, yet effective, low-rank and low-rank plusdiagonal matrix parametrizations for Passthrough Networks which exploit thisdecoupling property, reducing the data complexity and memory requirements ofthe network while preserving its memory capacity. We present competitiveexperimental results on synthetic tasks and a near state of the art result onsequential randomly-permuted MNIST classification, a hard task on natural data.
arxiv-18300-80 | Stereotyping and Bias in the Flickr30K Dataset | http://arxiv.org/pdf/1605.06083v1.pdf | author:Emiel van Miltenburg category:cs.CL cs.CV published:2016-05-19 summary:An untested assumption behind the crowdsourced descriptions of the images inthe Flickr30K dataset (Young et al., 2014) is that they "focus only on theinformation that can be obtained from the image alone" (Hodosh et al., 2013, p.859). This paper presents some evidence against this assumption, and provides alist of biases and unwarranted inferences that can be found in the Flickr30Kdataset. Finally, it considers methods to find examples of these, and discusseshow we should deal with stereotype-driven descriptions in future applications.
arxiv-18300-81 | On a convergent off -policy temporal difference learning algorithm in on-line learning environment | http://arxiv.org/pdf/1605.06076v1.pdf | author:Prasenjit Karmakar, Rajkumar Maity, Shalabh Bhatnagar category:cs.LG published:2016-05-19 summary:In this paper we provide a rigorous convergence analysis of a "off"-policytemporal difference learning algorithm with linear function approximation andper time-step linear computational complexity in "online" learning environment.The algorithm considered here is TDC with importance weighting introduced byMaei et al. We support our theoretical results by providing suitable empiricalresults for standard off-policy counterexamples.
arxiv-18300-82 | Perfect Recovery Conditions For Non-Negative Sparse Modeling | http://arxiv.org/pdf/1512.02743v2.pdf | author:Yuki Itoh, Marco F. Duarte, Mario Parente category:cs.IT cs.LG math.IT published:2015-12-09 summary:Sparse modeling has been widely and successfully used in many applicationssuch as computer vision, machine learning, and pattern recognition and,accompanied with those applications, significant research has studied thetheoretical limits and algorithm design for convex relaxations in sparsemodeling. However, only little has been done for theoretical limits ofnon-negative versions of sparse modeling. The behavior is expected to besimilar as the general sparse modeling, but a precise analysis has not beenexplored. This paper studies the performance of non-negative sparse modeling,especially for non-negativity constrained and $\ell_1$-penalized least squares,and gives an exact bound for which this problem can recover the correct signalelements. We pose two conditions to guarantee the correct signal recovery:minimum coefficient condition (MCC) and non-linearity vs. subset coherencecondition (NSCC). The former defines the minimum weight for each of the correctatoms present in the signal and the latter defines the tolerable deviation fromthe linear model relative to the positive subset coherence (PSC), a novel typeof "coherence" metric. We provide rigorous performance guarantees based onthese conditions and experimentally verify their precise predictive power in ahyperspectral data unmixing application.
arxiv-18300-83 | One-shot Learning with Memory-Augmented Neural Networks | http://arxiv.org/pdf/1605.06065v1.pdf | author:Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, Timothy Lillicrap category:cs.LG published:2016-05-19 summary:Despite recent breakthroughs in the applications of deep neural networks, onesetting that presents a persistent challenge is that of "one-shot learning."Traditional gradient-based networks require a lot of data to learn, oftenthrough extensive iterative training. When new data is encountered, the modelsmust inefficiently relearn their parameters to adequately incorporate the newinformation without catastrophic interference. Architectures with augmentedmemory capacities, such as Neural Turing Machines (NTMs), offer the ability toquickly encode and retrieve new information, and hence can potentially obviatethe downsides of conventional models. Here, we demonstrate the ability of amemory-augmented neural network to rapidly assimilate new data, and leveragethis data to make accurate predictions after only a few samples. We alsointroduce a new method for accessing an external memory that focuses on memorycontent, unlike previous methods that additionally use memory location-basedfocusing mechanisms.
arxiv-18300-84 | Hierarchical Clustering in Face Similarity Score Space | http://arxiv.org/pdf/1605.06052v1.pdf | author:Jason Grant, Patrick Flynn category:cs.CV published:2016-05-19 summary:Similarity scores in face recognition represent the proximity between pairsof images as computed by a matching algorithm. Given a large set of images andthe proximities between all pairs, a similarity score space is defined. Clusteranalysis was applied to the similarity score space to develop varioustaxonomies. Given the number of subjects in the dataset, we used hierarchicalmethods to aggregate images of the same subject. We also explored the hierarchyabove and below the subject level, including clusters that reflect gender andethnicity. Evidence supports the existence of clustering by race, gender,subject, and illumination condition.
arxiv-18300-85 | Asynchronous Stochastic Gradient Descent with Variance Reduction for Non-Convex Optimization | http://arxiv.org/pdf/1604.03584v3.pdf | author:Zhouyuan Huo, Heng Huang category:cs.LG math.OC published:2016-04-12 summary:We provide the first theoretical analysis on the convergence rate of theasynchronous stochastic variance reduced gradient (SVRG) descent algorithm onnon-convex optimization. Recent studies have shown that the asynchronousstochastic gradient descent (SGD) based algorithms with variance reductionconverge with a linear convergent rate on convex problems. However, there is nowork to analyze asynchronous SGD with variance reduction technique onnon-convex problem. In this paper, we study two asynchronous parallelimplementations of SVRG: one is on a distributed memory system and the other ison a shared memory system. We provide the theoretical analysis that bothalgorithms can obtain a convergence rate of $O(1/T)$, and linear speed up isachievable if the number of workers is upper bounded.
arxiv-18300-86 | A Multi-Batch L-BFGS Method for Machine Learning | http://arxiv.org/pdf/1605.06049v1.pdf | author:Albert S. Berahas, Jorge Nocedal, Martin Tak√°ƒç category:math.OC cs.LG stat.ML published:2016-05-19 summary:The question of how to parallelize the stochastic gradient descent (SGD)method has received much attention in the literature. In this paper, we focusinstead on batch methods that use a sizeable fraction of the training set ateach iteration to facilitate parallelism, and that employ second-orderinformation. In order to improve the learning process, we follow a multi-batchapproach in which the batch changes at each iteration. This inherently givesthe algorithm a stochastic flavor that can cause instability in L-BFGS, apopular batch method in machine learning. These difficulties arise becauseL-BFGS employs gradient differences to update the Hessian approximations; whenthese gradients are computed using different data points the process can beunstable. This paper shows how to perform stable quasi-Newton updating in themulti-batch setting, illustrates the behavior of the algorithm in a distributedcomputing platform, and studies its convergence properties for both the convexand nonconvex cases.
arxiv-18300-87 | AMSOM: Adaptive Moving Self-organizing Map for Clustering and Visualization | http://arxiv.org/pdf/1605.06047v1.pdf | author:Gerasimos Spanakis, Gerhard Weiss category:cs.AI cs.NE published:2016-05-19 summary:Self-Organizing Map (SOM) is a neural network model which is used to obtain atopology-preserving mapping from the (usually high dimensional) input/featurespace to an output/map space of fewer dimensions (usually two or three in orderto facilitate visualization). Neurons in the output space are connected witheach other but this structure remains fixed throughout training and learning isachieved through the updating of neuron reference vectors in feature space.Despite the fact that growing variants of SOM overcome the fixed structurelimitation they increase computational cost and also do not allow the removalof a neuron after its introduction. In this paper, a variant of SOM is proposedcalled AMSOM (Adaptive Moving Self-Organizing Map) that on the one hand createsa more flexible structure where neuron positions are dynamically altered duringtraining and on the other hand tackles the drawback of having a predefined gridby allowing neuron addition and/or removal during training. Experiments usingmultiple literature datasets show that the proposed method improves trainingperformance of SOM, leads to a better visualization of the input dataset andprovides a framework for determining the optimal number and structure ofneurons.
arxiv-18300-88 | Machine Translation Evaluation: A Survey | http://arxiv.org/pdf/1605.04515v3.pdf | author:Aaron Li-Feng Han, Khalil Sima'an, Derek Fai Wong category:cs.CL I.2.7; I.2.1 published:2016-05-15 summary:This paper introduces the state-of-the-art MT evaluation survey that containsboth manual and automatic evaluation methods. The traditional human evaluationcriteria mainly include the intelligibility, fidelity, fluency, adequacy,comprehension, and informativeness. We classify the automatic evaluationmethods into two categories, including lexical similarity and linguisticfeatures application. The lexical similarity methods contain edit distance,precision, recall, and word order, etc. The linguistic features can be dividedinto syntactic features and semantic features. Subsequently, we also introducethe evaluation methods for MT evaluation and the recent quality estimationtasks for MT.
arxiv-18300-89 | Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss | http://arxiv.org/pdf/1604.05529v2.pdf | author:Barbara Plank, Anders S√∏gaard, Yoav Goldberg category:cs.CL published:2016-04-19 summary:Bidirectional long short-term memory (bi-LSTM) networks have recently provensuccessful for various NLP sequence modeling tasks, but little is known abouttheir reliance to input representations, target languages, data set size, andlabel noise. We address these issues and evaluate bi-LSTMs with word,character, and unicode byte embeddings for POS tagging. We compare bi-LSTMs totraditional POS taggers across languages and data sizes. We also present anovel bi-LSTM model, which combines the POS tagging loss function with anauxiliary loss function that accounts for rare words. The model obtainsstate-of-the-art performance across 22 languages, and works especially well formorphologically complex languages. Our analysis suggests that bi-LSTMs are lesssensitive to training data size and label corruptions (at small noise levels)than previously assumed.
arxiv-18300-90 | One model, two languages: training bilingual parsers with harmonized treebanks | http://arxiv.org/pdf/1507.08449v2.pdf | author:David Vilares, Carlos G√≥mez-Rodr√≠guez, Miguel A. Alonso category:cs.CL published:2015-07-30 summary:We introduce an approach to train lexicalized parsers using bilingual corporaobtained by merging harmonized treebanks of different languages, producingparsers that can analyze sentences in either of the learned languages, or evensentences that mix both. We test the approach on the Universal DependencyTreebanks, training with MaltParser and MaltOptimizer. The results show thatthese bilingual parsers are more than competitive, as most combinations notonly preserve accuracy, but some even achieve significant improvements over thecorresponding monolingual parsers. Preliminary experiments also show theapproach to be promising on texts with code-switching and when more languagesare added.
arxiv-18300-91 | A Geometric Approach to Color Image Regularization | http://arxiv.org/pdf/1605.05977v1.pdf | author:Freddie √Östr√∂m, Christoph Schn√∂rr category:cs.CV published:2016-05-19 summary:We present a new vectorial total variation method that addresses the problemof color consistent image filtering. Our approach is inspired from thedouble-opponent cell representation in the human visual cortex. Existingmethods of vectorial total variation regularizers have insufficient (or no)coupling between the color channels and thus may introduce color artifacts. Weaddress this problem by introducing a novel coupling between the color channelsrelated to a pullback-metric from the opponent space to the data (RGB color)space. Our energy is a non-convex, non-smooth higher-order vectorial totalvariation approach and promotes color consistent image filtering via a couplingterm. For a convex variant, we show well-posedness and existence of a solutionin the space of vectorial bounded variation. For the higher-order scheme weemploy a half-quadratic strategy, which model the non-convex energy terms asthe infimum of a sequence of quadratic functions. In experiments, we elaborateon traditional image restoration applications of inpainting, deblurring anddenoising. Regarding the latter, we demonstrate state of the art restorationquality with respect to structure coherence and color consistency.
arxiv-18300-92 | Randomized Primal-Dual Proximal Block Coordinate Updates | http://arxiv.org/pdf/1605.05969v1.pdf | author:Xiang Gao, Yangyang Xu, Shuzhong Zhang category:math.OC math.NA stat.ML published:2016-05-19 summary:In this paper we propose a randomized primal-dual proximal block coordinateupdating framework for a general multi-block convex optimization model withcoupled objective function and linear constraints. Assuming mere convexity, weestablish its $O(1/t)$ convergence rate in terms of the objective value andfeasibility measure. The framework includes several existing algorithms asspecial cases such as a primal-dual method for bilinear saddle-point problems(PD-S), the proximal Jacobian ADMM (Prox-JADMM) and a randomized variant of theADMM method for multi-block convex optimization. Our analysis recovers and/orstrengthens the convergence properties of several existing algorithms. Forexample, for PD-S our result leads to the same order of convergence ratewithout the previously assumed boundedness condition on the constraint sets,and for Prox-JADMM the new result provides convergence rate in terms of theobjective value and the feasibility violation. It is well known that theoriginal ADMM may fail to converge when the number of blocks exceeds two. Ourresult shows that if an appropriate randomization procedure is invoked toselect the updating blocks, then a sublinear rate of convergence in expectationcan be guaranteed for multi-block ADMM, without assuming any strong convexity.The new approach is also extended to solve problems where only a stochasticapproximation of the (sub-)gradient of the objective is available, and weestablish an $O(1/\sqrt{t})$ convergence rate of the extended approach forsolving stochastic programming.
arxiv-18300-93 | Associative Long Short-Term Memory | http://arxiv.org/pdf/1602.03032v2.pdf | author:Ivo Danihelka, Greg Wayne, Benigno Uria, Nal Kalchbrenner, Alex Graves category:cs.NE published:2016-02-09 summary:We investigate a new method to augment recurrent neural networks with extramemory without increasing the number of network parameters. The system has anassociative memory based on complex-valued vectors and is closely related toHolographic Reduced Representations and Long Short-Term Memory networks.Holographic Reduced Representations have limited capacity: as they store moreinformation, each retrieval becomes noisier due to interference. Our system incontrast creates redundant copies of stored information, which enablesretrieval with reduced noise. Experiments demonstrate faster learning onmultiple memorization tasks.
arxiv-18300-94 | Contour-based 3d tongue motion visualization using ultrasound image sequences | http://arxiv.org/pdf/1605.05967v1.pdf | author:Kele Xu, Yin Yang, Cl√©mence Leboullenger, Pierre Roussel, Bruce Denby category:cs.CV published:2016-05-19 summary:This article describes a contour-based 3D tongue deformation visualizationframework using B-mode ultrasound image sequences. A robust, automatic trackingalgorithm characterizes tongue motion via a contour, which is then used todrive a generic 3D Finite Element Model (FEM). A novel contour-based 3D dynamicmodeling method is presented. Modal reduction and modal warping techniques areapplied to model the deformation of the tongue physically and efficiently. Thiswork can be helpful in a variety of fields, such as speech production, silentspeech recognition, articulation training, speech disorder study, etc.
arxiv-18300-95 | Character-based Neural Machine Translation | http://arxiv.org/pdf/1603.00810v2.pdf | author:Marta R. Costa-Juss√†, Jos√© A. R. Fonollosa category:cs.CL cs.LG cs.NE stat.ML published:2016-03-02 summary:Neural Machine Translation (MT) has reached state-of-the-art results.However, one of the main challenges that neural MT still faces is dealing withvery large vocabularies and morphologically rich languages. In this paper, wepropose a neural MT system using character-based embeddings in combination withconvolutional and highway layers to replace the standard lookup-based wordrepresentations. The resulting unlimited-vocabulary and affix-aware source wordembeddings are tested in a state-of-the-art neural MT based on anattention-based bidirectional recurrent neural network. The proposed MT schemeprovides improved results even when the source language is not morphologicallyrich. Improvements up to 3 BLEU points are obtained in the German-English WMTtask.
arxiv-18300-96 | T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos | http://arxiv.org/pdf/1604.02532v2.pdf | author:Kai Kang, Hongsheng Li, Junjie Yan, Xingyu Zeng, Bin Yang, Tong Xiao, Cong Zhang, Zhe Wang, Ruohui Wang, Xiaogang Wang, Wanli Ouyang category:cs.CV published:2016-04-09 summary:The state-of-the-art performance for object detection has been significantlyimproved over the past two years. Besides the introduction of powerful deepneural networks such as GoogleNet and VGG, novel object detection frameworkssuch as R-CNN and its successors, Fast R-CNN and Faster R-CNN, play anessential role in improving the state-of-the-art. Despite their effectivenesson still images, those frameworks are not specifically designed for objectdetection from videos. Temporal and contextual information of videos are notfully investigated and utilized. In this work, we propose a deep learningframework that incorporates temporal and contextual information from tubeletsobtained in videos, which dramatically improves the baseline performance ofexisting still-image detection frameworks when they are applied to videos. Itis called T-CNN, i.e. tubelets with convolutional neueral networks. Theproposed framework won the recently introduced object-detection-from-video(VID) task with provided data in the ImageNet Large-Scale Visual RecognitionChallenge 2015 (ILSVRC2015).
arxiv-18300-97 | Hierarchical Piecewise-Constant Super-regions | http://arxiv.org/pdf/1605.05937v1.pdf | author:Imanol Luengo, Mark Basham, Andrew P. French category:cs.CV published:2016-05-19 summary:Recent applications in computer vision have come to heavily rely onsuperpixel over-segmentation as a pre-processing step for higher level visiontasks, such as object recognition, image labelling or image segmentation. Herewe present a new superpixel algorithm called Hierarchical Piecewise-ConstantSuper-regions (HPCS), which not only obtains superpixels comparable to thestate-of-the-art, but can also be applied hierarchically to form what we calln-th order super-regions. In essence, a Markov Random Field (MRF)-basedanisotropic denoising formulation over the quantized feature space is adoptedto form piecewise-constant image regions, which are then combined with agraph-based split & merge post-processing step to form superpixels. The graphand quantized feature based formulation of the problem allows us to generalizeit hierarchically to preserve boundary adherence with fewer superpixels.Experimental results show that, despite the simplicity of our framework, it isable to provide high quality superpixels, and to hierarchically apply them toform layers of over-segmentation, each with a decreasing number of superpixels,while maintaining the same desired properties (such as adherence to strongimage edges). The algorithm is also memory efficient and has a lowcomputational cost.
arxiv-18300-98 | Matching Handwritten Document Images | http://arxiv.org/pdf/1605.05923v1.pdf | author:Praveen Krishnan, C. V. Jawahar category:cs.CV published:2016-05-19 summary:We address the problem of predicting similarity between a pair of handwrittendocument images written by different individuals. This has applications relatedto matching and mining in image collections containing handwritten content. Asimilarity score is computed by detecting patterns of text re-usages betweendocument images irrespective of the minor variations in word morphology, wordordering, layout and paraphrasing of the content. Our method does not depend onan accurate segmentation of words and lines. We formulate the document matchingproblem as a structured comparison of the word distributions across twodocument images. To match two word images, we propose a convolutional neuralnetwork (CNN) based feature descriptor. Performance of this representationsurpasses the state-of-the-art on handwritten word spotting. Finally, wedemonstrate the applicability of our method on a practical problem of matchinghandwritten assignments.
arxiv-18300-99 | Bayesian Variable Selection for Globally Sparse Probabilistic PCA | http://arxiv.org/pdf/1605.05918v1.pdf | author:Charles Bouveyron, Pierre Latouche, Pierre-Alexandre Mattei category:stat.ML published:2016-05-19 summary:With the flourishing development of high-dimensional data, sparse versions ofprincipal component analysis (PCA) have imposed themselves as simple, yetpowerful ways of selecting relevant features in an unsupervised manner.However, when several sparse principal components are computed, theinterpretation of the selected variables may be difficult since each axis hasits own sparsity pattern and has to be interpreted separately. To overcome thisdrawback, we propose a Bayesian procedure that allows to obtain several sparsecomponents with the same sparsity pattern. This allows the practitioner toidentify the original variables which are relevant to describe the data. Tothis end, using Roweis' probabilistic interpretation of PCA and an isotropicGaussian prior on the loading matrix, we provide the first exact computation ofthe marginal likelihood of a Bayesian PCA model. In order to avoid thedrawbacks of discrete model selection, we propose a simple relaxation of ourframework which allows to find a path of models using a variationalexpectation-maximization algorithm. The exact marginal likelihood caneventually be maximized over this path, relying on Occam's razor to select therelevant variables. Since the sparsity pattern is common to all components, wecall this approach globally sparse probabilistic PCA (GSPPCA). Its usefulnessis illustrated on synthetic data sets and on several real unsupervised featureselection problems.
arxiv-18300-100 | Tongue contour extraction from ultrasound images based on deep neural network | http://arxiv.org/pdf/1605.05912v1.pdf | author:Aurore Jaumard-Hakoun, Kele Xu, Pierre Roussel-Ragot, G√©rard Dreyfus, Bruce Denby category:cs.CV published:2016-05-19 summary:Studying tongue motion during speech using ultrasound is a standardprocedure, but automatic ultrasound image labelling remains a challenge, asstandard tongue shape extraction methods typically require human intervention.This article presents a method based on deep neural networks to automaticallyextract tongue contour from ultrasound images on a speech dataset. We use adeep autoencoder trained to learn the relationship between an image and itsrelated contour, so that the model is able to automatically reconstructcontours from the ultrasound image alone. In this paper, we use an automaticlabelling algorithm instead of time-consuming hand-labelling during thetraining process, and estimate the performances of both automatic labelling andcontour extraction as compared to hand-labelling. Observed results show qualityscores comparable to the state of the art.
arxiv-18300-101 | Automatic TM Cleaning through MT and POS Tagging: Autodesk's Submission to the NLP4TM 2016 Shared Task | http://arxiv.org/pdf/1605.05906v1.pdf | author:Alena Zwahlen, Olivier Carnal, Samuel L√§ubli category:cs.CL published:2016-05-19 summary:We describe a machine learning based method to identify incorrect entries intranslation memories. It extends previous work by Barbu (2015) throughincorporating recall-based machine translation and part-of-speech-taggingfeatures. Our system ranked first in the Binary Classification (II) task fortwo out of three language pairs: English-Italian and English-Spanish.
arxiv-18300-102 | COCO: The Experimental Procedure | http://arxiv.org/pdf/1603.08776v2.pdf | author:Nikolaus Hansen, Tea Tusar, Olaf Mersmann, Anne Auger, Dimo Brockhoff category:cs.AI cs.NE published:2016-03-29 summary:We present a budget-free experimental setup and procedure for benchmarkingnumericaloptimization algorithms in a black-box scenario. This procedure can beapplied with the COCO benchmarking platform. We describe initialization of andinput to the algorithm and touch upon therelevance of termination and restarts.
arxiv-18300-103 | Twitter as a Lifeline: Human-annotated Twitter Corpora for NLP of Crisis-related Messages | http://arxiv.org/pdf/1605.05894v1.pdf | author:Muhammad Imran, Prasenjit Mitra, Carlos Castillo category:cs.CL cs.CY cs.SI published:2016-05-19 summary:Microblogging platforms such as Twitter provide active communication channelsduring mass convergence and emergency events such as earthquakes, typhoons.During the sudden onset of a crisis situation, affected people post usefulinformation on Twitter that can be used for situational awareness and otherhumanitarian disaster response efforts, if processed timely and effectively.Processing social media information pose multiple challenges such as parsingnoisy, brief and informal messages, learning information categories from theincoming stream of messages and classifying them into different classes amongothers. One of the basic necessities of many of these tasks is the availabilityof data, in particular human-annotated data. In this paper, we presenthuman-annotated Twitter corpora collected during 19 different crises that tookplace between 2013 and 2015. To demonstrate the utility of the annotations, wetrain machine learning classifiers. Moreover, we publish first largest word2vecword embeddings trained on 52 million crisis-related tweets. To deal withtweets language issues, we present human-annotated normalized lexical resourcesfor different lexical variations.
arxiv-18300-104 | Blind system identification using kernel-based methods | http://arxiv.org/pdf/1412.4056v2.pdf | author:Giulio Bottegal, Riccardo S. Risuleo, H√•kan Hjalmarsson category:cs.SY stat.ML published:2014-12-12 summary:We propose a new method for blind system identification. Resorting to aGaussian regression framework, we model the impulse response of the unknownlinear system as a realization of a Gaussian process. The structure of thecovariance matrix (or kernel) of such a process is given by the stable splinekernel, which has been recently introduced for system identification purposesand depends on an unknown hyperparameter. We assume that the input can belinearly described by few parameters. We estimate these parameters, togetherwith the kernel hyperparameter and the noise variance, using an empirical Bayesapproach. The related optimization problem is efficiently solved with a noveliterative scheme based on the Expectation-Maximization method. In particular,we show that each iteration consists of a set of simple update rules. We show,through some numerical experiments, very promising performance of the proposedmethod.
arxiv-18300-105 | On the estimation of initial conditions in kernel-based system identification | http://arxiv.org/pdf/1504.08196v3.pdf | author:Riccardo Sven Risuleo, Giulio Bottegal, H√•kan Hjalmarsson category:cs.SY stat.ML published:2015-04-30 summary:Recent developments in system identification have brought attention toregularized kernel-based methods, where, adopting the recently introducedstable spline kernel, prior information on the unknown process is enforced.This reduces the variance of the estimates and thus makes kernel-based methodsparticularly attractive when few input-output data samples are available. Insuch cases however, the influence of the system initial conditions may have asignificant impact on the output dynamics. In this paper, we specificallyaddress this point. We propose three methods that deal with the estimation ofinitial conditions using different types of information. The methods consist invarious mixed maximum likelihood--a posteriori estimators which estimate theinitial conditions and tune the hyperparameters characterizing the stablespline kernel. To solve the related optimization problems, we resort to theexpectation-maximization method, showing that the solutions can be attained byiterating among simple update steps. Numerical experiments show the advantages,in terms of accuracy in reconstructing the system impulse response, of theproposed strategies, compared to other kernel-based schemes not accounting forthe effect initial conditions.
arxiv-18300-106 | Siamese Instance Search for Tracking | http://arxiv.org/pdf/1605.05863v1.pdf | author:Ran Tao, Efstratios Gavves, Arnold W. M. Smeulders category:cs.CV published:2016-05-19 summary:In this paper we present a tracker, which is radically different fromstate-of-the-art trackers: we apply no model updating, no occlusion detection,no combination of trackers, no geometric matching, and still deliverstate-of-the-art tracking performance, as demonstrated on the popular onlinetracking benchmark (OTB) and six very challenging YouTube videos. The presentedtracker simply matches the initial patch of the target in the first frame withcandidates in a new frame and returns the most similar patch by a learnedmatching function. The strength of the matching function comes from beingextensively trained generically, i.e., without any data of the target, using aSiamese deep neural network, which we design for tracking. Once learned, thematching function is used as is, without any adapting, to track previouslyunseen targets. It turns out that the learned matching function is so powerfulthat a simple tracker built upon it, coined Siamese INstance search Tracker,SINT, which only uses the original observation of the target from the firstframe, suffices to reach state-of-the-art performance. Further, we show theproposed tracker even allows for target re-identification after the target wasabsent for a complete video shot.
arxiv-18300-107 | False Discovery Rate Control and Statistical Quality Assessment of Annotators in Crowdsourced Ranking | http://arxiv.org/pdf/1605.05860v1.pdf | author:Qianqian Xu, Jiechao Xiong, Xiaochun Cao, Yuan Yao category:stat.ML published:2016-05-19 summary:With the rapid growth of crowdsourcing platforms it has become easy andrelatively inexpensive to collect a dataset labeled by multiple annotators in ashort time. However due to the lack of control over the quality of theannotators, some abnormal annotators may be affected by position bias which canpotentially degrade the quality of the final consensus labels. In this paper weintroduce a statistical framework to model and detect annotator's position biasin order to control the false discovery rate (FDR) without a prior knowledge onthe amount of biased annotators - the expected fraction of false discoveriesamong all discoveries being not too high, in order to assure that most of thediscoveries are indeed true and replicable. The key technical developmentrelies on some new knockoff filters adapted to our problem and new algorithmsbased on the Inverse Scale Space dynamics whose discretization is potentiallysuitable for large scale crowdsourcing data analysis. Our studies are supportedby experiments with both simulated examples and real-world data. The proposedframework provides us a useful tool for quantitatively studying annotator'sabnormal behavior in crowdsourcing data arising from machine learning,sociology, computer vision, multimedia, etc.
arxiv-18300-108 | Syntactically Guided Neural Machine Translation | http://arxiv.org/pdf/1605.04569v2.pdf | author:Felix Stahlberg, Eva Hasler, Aurelien Waite, Bill Byrne category:cs.CL published:2016-05-15 summary:We investigate the use of hierarchical phrase-based SMT lattices inend-to-end neural machine translation (NMT). Weight pushing transforms theHiero scores for complete translation hypotheses, with the full translationgrammar score and full n-gram language model score, into posteriors compatiblewith NMT predictive probabilities. With a slightly modified NMT beam-searchdecoder we find gains over both Hiero and NMT decoding alone, with practicaladvantages in extending NMT to very large input and output vocabularies.
arxiv-18300-109 | Texture Synthesis Through Convolutional Neural Networks and Spectrum Constraints | http://arxiv.org/pdf/1605.01141v3.pdf | author:Gang Liu, Yann Gousseau, Gui-Song Xia category:cs.CV published:2016-05-04 summary:This paper presents a significant improvement for the synthesis of textureimages using convolutional neural networks (CNNs), making use of constraints onthe Fourier spectrum of the results. More precisely, the texture synthesis isregarded as a constrained optimization problem, with constraints conditioningboth the Fourier spectrum and statistical features learned by CNNs. In contrastwith existing methods, the presented method inherits from previous CNNapproaches the ability to depict local structures and fine scale details, andat the same time yields coherent large scale structures, even in the case ofquasi-periodic images. This is done at no extra computational cost. Synthesisexperiments on various images show a clear improvement compared to a recentstate-of-the art method relying on CNN constraints only.
arxiv-18300-110 | Low-Rank Matrices on Graphs: Generalized Recovery & Applications | http://arxiv.org/pdf/1605.05579v2.pdf | author:Nauman Shahid, Nathanael Perraudin, Gilles Puy, Pierre Vandergheynst category:cs.CV published:2016-05-18 summary:Many real world datasets subsume a linear or non-linear low-rank structure ina very low-dimensional space. Unfortunately, one often has very little or noinformation about the geometry of the space, resulting in a highlyunder-determined recovery problem. Under certain circumstances,state-of-the-art algorithms provide an exact recovery for linear low-rankstructures but at the expense of highly inscalable algorithms which use nuclearnorm. However, the case of non-linear structures remains unresolved. We revisitthe problem of low-rank recovery from a totally different perspective,involving graphs which encode pairwise similarity between the data samples andfeatures. Surprisingly, our analysis confirms that it is possible to recovermany approximate linear and non-linear low-rank structures with recoveryguarantees with a set of highly scalable and efficient algorithms. We call suchdata matrices as \textit{Low-Rank matrices on graphs} and show that many realworld datasets satisfy this assumption approximately due to underlyingstationarity. Our detailed theoretical and experimental analysis unveils thepower of the simple, yet very novel recovery framework \textit{Fast Robust PCAon Graphs}
arxiv-18300-111 | On the Sampling Strategy for Evaluation of Spectral-spatial Methods in Hyperspectral Image Classification | http://arxiv.org/pdf/1605.05829v1.pdf | author:Jie Liang, Jun Zhou, Yuntao Qian, Lian Wen, Xiao Bai, Yongsheng Gao category:cs.CV published:2016-05-19 summary:Spectral-spatial processing has been increasingly explored in remote sensinghyperspectral image classification. While extensive studies have focused ondeveloping methods to improve the classification accuracy, experimental settingand design for method evaluation have drawn little attention. In the scope ofsupervised classification, we find that traditional experimental designs forspectral processing are often improperly used in the spectral-spatialprocessing context, leading to unfair or biased performance evaluation. This isespecially the case when training and testing samples are randomly drawn fromthe same image - a practice that has been commonly adopted in the experiments.Under such setting, the dependence caused by overlap between the training andtesting samples may be artificially enhanced by some spatial informationprocessing methods such as spatial filtering and morphological operation. Suchinteraction between training and testing sets has violated data independenceassumption that is abided by supervised learning theory and performanceevaluation mechanism. Therefore, the widely adopted pixel-based random samplingstrategy is not always suitable to evaluate spectral-spatial classificationalgorithms because it is difficult to determine whether the improvement ofclassification accuracy is caused by incorporating spatial information intoclassifier or by increasing the overlap between training and testing samples.To partially solve this problem, we propose a novel controlled random samplingstrategy for spectral-spatial methods. It can greatly reduce the overlapbetween training and testing samples and provides more objective and accurateevaluation.
arxiv-18300-112 | Declarative Machine Learning - A Classification of Basic Properties and Types | http://arxiv.org/pdf/1605.05826v1.pdf | author:Matthias Boehm, Alexandre V. Evfimievski, Niketan Pansare, Berthold Reinwald category:cs.DB cs.DC cs.LG cs.PL published:2016-05-19 summary:Declarative machine learning (ML) aims at the high-level specification of MLtasks or algorithms, and automatic generation of optimized execution plans fromthese specifications. The fundamental goal is to simplify the usage and/ordevelopment of ML algorithms, which is especially important in the context oflarge-scale computations. However, ML systems at different abstraction levelshave emerged over time and accordingly there has been a controversy about themeaning of this general definition of declarative ML. Specificationalternatives range from ML algorithms expressed in domain-specific languages(DSLs) with optimization for performance, to ML task (learning problem)specifications with optimization for performance and accuracy. We argue thatthese different types of declarative ML complement each other as they addressdifferent users (data scientists and end users). This paper makes an attempt tocreate a taxonomy for declarative ML, including a definition of essential basicproperties and types of declarative ML. Along the way, we provide insights intoimplications of these properties. We also use this taxonomy to classifyexisting systems. Finally, we draw conclusions on defining appropriatebenchmarks and specification languages for declarative ML.
arxiv-18300-113 | Clustering from Sparse Pairwise Measurements | http://arxiv.org/pdf/1601.06683v2.pdf | author:Alaa Saade, Marc Lelarge, Florent Krzakala, Lenka Zdeborov√° category:cs.SI cs.LG published:2016-01-25 summary:We consider the problem of grouping items into clusters based on few randompairwise comparisons between the items. We introduce three closely relatedalgorithms for this task: a belief propagation algorithm approximating theBayes optimal solution, and two spectral algorithms based on thenon-backtracking and Bethe Hessian operators. For the case of two symmetricclusters, we conjecture that these algorithms are asymptotically optimal inthat they detect the clusters as soon as it is information theoreticallypossible to do so. We substantiate this claim for one of the spectralapproaches we introduce.
arxiv-18300-114 | Bacterial foraging optimization based brain magnetic resonance image segmentation | http://arxiv.org/pdf/1605.05815v1.pdf | author:Abdul kayom Md Khairuzzaman category:cs.CV cs.NE published:2016-05-19 summary:Segmentation partitions an image into its constituent parts. It isessentially the pre-processing stage of image analysis and computer vision. Inthis work, T1 and T2 weighted brain magnetic resonance images are segmentedusing multilevel thresholding and bacterial foraging optimization (BFO)algorithm. The thresholds are obtained by maximizing the between class variance(multilevel Otsu method) of the image. The BFO algorithm is used to optimizethe threshold searching process. The edges are then obtained from thethresholded image by comparing the intensity of each pixel with its eightconnected neighbourhood. Post processing is performed to remove spuriousresponses in the segmented image. The proposed segmentation technique isevaluated using edge detector evaluation parameters such as figure of merit,Rand Index and variation of information. The proposed brain MR imagesegmentation technique outperforms the traditional edge detectors such as cannyand sobel.
arxiv-18300-115 | Recurrent Exponential-Family Harmoniums without Backprop-Through-Time | http://arxiv.org/pdf/1605.05799v1.pdf | author:Joseph G. Makin, Benjamin K. Dichter, Philip N. Sabes category:cs.LG stat.ML published:2016-05-19 summary:Exponential-family harmoniums (EFHs), which extend restricted Boltzmannmachines (RBMs) from Bernoulli random variables to other exponential families(Welling et al., 2005), are generative models that can be trained withunsupervised-learning techniques, like contrastive divergence (Hinton et al.2006; Hinton, 2002), as density estimators for static data. Methods forextending RBMs--and likewise EFHs--to data with temporal dependencies have beenproposed previously (Sutskever and Hinton, 2007; Sutskever et al., 2009), thelearning procedure being validated by qualitative assessment of the generativemodel. Here we propose and justify, from a very different perspective, analternative training procedure, proving sufficient conditions for optimalinference under that procedure. The resulting algorithm can be learned withonly forward passes through the data--backprop-through-time is not required, asin previous approaches. The proof exploits a recent result about informationretention in density estimators (Makin and Sabes, 2015), and applies it to a"recurrent EFH" (rEFH) by induction. Finally, we demonstrate optimality bysimulation, testing the rEFH: (1) as a filter on training data generated with alinear dynamical system, the position of which is noisily reported by apopulation of "neurons" with Poisson-distributed spike counts; and (2) with thequalitative experiments proposed by Sutskever et al. (2009).
arxiv-18300-116 | A Generic Framework for Assessing the Performance Bounds of Image Feature Detectors | http://arxiv.org/pdf/1605.05791v1.pdf | author:Shoaib Ehsan, Adrian F. Clark, Ales Leonardis, Naveed ur Rehman, Klaus D. McDonald-Maier category:cs.CV published:2016-05-19 summary:Since local feature detection has been one of the most active research areasin computer vision during the last decade, a large number of detectors havebeen proposed. The interest in feature-based applications continues to grow andhas thus rendered the task of characterizing the performance of various featuredetection methods an important issue in vision research. Inspired by the goodpractices of electronic system design, a generic framework based on therepeatability measure is presented in this paper that allows assessment of theupper and lower bounds of detector performance and finds statisticallysignificant performance differences between detectors as a function of imagetransformation amount by introducing a new variant of McNemars test in aneffort to design more reliable and effective vision systems. The proposedframework is then employed to establish operating and guarantee regions forseveral state-of-the-art detectors and to identify their statisticalperformance differences for three specific image transformations: JPEGcompression, uniform light changes and blurring. The results are obtained usinga newly acquired, large image database (20482) images with 539 differentscenes. These results provide new insights into the behaviour of detectors andare also useful from the vision systems design perspective.
arxiv-18300-117 | Efficient Nonparametric Smoothness Estimation | http://arxiv.org/pdf/1605.05785v1.pdf | author:Shashank Singh, Simon S. Du, Barnab√°s P√≥czos category:math.ST cs.IT math.IT stat.ML stat.TH published:2016-05-19 summary:Sobolev quantities (norms, inner products, and distances) of probabilitydensity functions are important in the theory of nonparametric statistics, buthave rarely been used in practice, partly due to a lack of practicalestimators. They also include, as special cases, $L^2$ quantities which areused in many applications. We propose and analyze a family of estimators forSobolev quantities of unknown probability density functions. We bound the biasand variance of our estimators over finite samples, finding that they aregenerally minimax rate-optimal. Our estimators are significantly morecomputationally tractable than previous estimators, and exhibit astatistical/computational trade-off allowing them to adapt to computationalconstraints. We also draw theoretical connections to recent work on fasttwo-sample testing. Finally, we empirically validate our estimators onsynthetic data.
arxiv-18300-118 | A comparison of semi-deterministic and stochastic search techniques | http://arxiv.org/pdf/1605.05782v1.pdf | author:Andy M. Connor, Kristina Shea category:cs.NE math.OC published:2016-05-18 summary:This paper presents an investigation of two search techniques, tabu search(TS) and simulated annealing (SA), to assess their relative merits when appliedto engineering design optimisation. Design optimisation problems are generallycharacterised as having multi-modal search spaces and discontinuities makingglobal optimisation techniques beneficial. Both techniques claim to be capableof locating globally optimum solutions on a range of problems but thiscapability is derived from different underlying philosophies. While tabu searchuses a semi-deterministic approach to escape local optima, simulated annealinguses a complete stochastic approach. The performance of each technique isinvestigated using a structural optimisation problem. These performances arethen compared to each other as and to a steepest descent (SD) method.
arxiv-18300-119 | Beamforming through regularized inverse problems in ultrasound medical imaging | http://arxiv.org/pdf/1507.08184v2.pdf | author:Teodora Szasz, Adrian Basarab, Denis Kouam√© category:cs.CV published:2015-07-29 summary:Beamforming in ultrasound imaging has significant impact on the quality ofthe final image, controlling its resolution and contrast. Despite its lowspatial resolution and contrast, delay-and-sum is still extensively usednowadays in clinical applications, due to its real-time capabilities. The mostcommon alternatives are minimum variance method and its variants, whichovercome the drawbacks of delay-and-sum, at the cost of higher computationalcomplexity that limits its utilization in real-time applications. In this paper, we propose to perform beamforming in ultrasound imagingthrough a regularized inverse problem based on a linear model relating thereflected echoes to the signal to be recovered. Our approach presents two majoradvantages: i) its flexibility in the choice of statistical assumptions on thesignal to be beamformed (Laplacian and Gaussian statistics are tested herein)and ii) its robustness to a reduced number of pulse emissions. The proposedframework is flexible and allows for choosing the right trade-off between noisesuppression and sharpness of the resulted image. We illustrate the performanceof our approach on both simulated and experimental data, with \textit{in vivo}examples of carotid and thyroid. Compared to delay-and-sum, minimimum varianceand two other recently published beamforming techniques, our method offersbetter spatial resolution, respectively contrast, when using Laplacian andGaussian priors.
arxiv-18300-120 | The Quality of the Covariance Selection Through Detection Problem and AUC Bounds | http://arxiv.org/pdf/1605.05776v1.pdf | author:Navid Tafaghodi Khajavi, Anthony Kuh category:cs.IT math.IT stat.ML published:2016-05-18 summary:We consider the problem of quantifying the quality of a model selectionproblem for a graphical model. We discuss this by formulating the problem as adetection problem. Model selection problems usually minimize the distance withthe model distribution. For the special case of Gaussian distributions, thisproblem simplifies to the covariance selection problem which is widelydiscussed in literature by Dempster [1] where the Kullback-Leibler (KL)divergence is minimized or equivalently the likelihood criterion maximized tocompute the model covariance matrix. While this solution is optimal forGaussian distributions in the sense of the KL divergence, it is not optimalwhen compared with other information divergences and criteria such as AreaUnder the Curve (AUC). In this paper, we discuss the quality of model approximation using the AUCand its bounds as an average measure of accuracy in detection problem. Wecompute upper and lower bounds for the AUC. We define the correlationapproximation matrix (CAM) and show that the KL divergence and AUC and itsupper and lower bounds depend on the eigenvalues of the CAM. We also show therelationship between the AUC, the KL divergence and the ROC curve by optimizingwith respect to the ROC curve. In the examples provided, we pick treestructures as the simplest graphical models. We perform simulations onfully-connected graphs and compute the tree structured models by applying thewidely used Chow-Liu algorithm. Examples show that the quality of treeapproximation models are not good in general based on information divergences,AUC and its bounds when the number of nodes in the graphical model is large.Specially for 1-AUC, it is shown both in theory and using simulations that the1-AUC for the tree approximation model decays exponentially as the dimension ofthe graphical model increases.
arxiv-18300-121 | Supervised Learning with Quantum-Inspired Tensor Networks | http://arxiv.org/pdf/1605.05775v1.pdf | author:E. Miles Stoudenmire, David J. Schwab category:stat.ML cs.LG published:2016-05-18 summary:Tensor networks are efficient representations of high-dimensional tensorswhich have been very successful for physics and mathematics applications. Wedemonstrate how algorithms for optimizing such networks can be adapted tosupervised learning tasks by using matrix product states (tensor trains) toparameterize models for classifying images. For the MNIST data set we obtainless than 1% test set classification error. We discuss how the tensor networkform imparts additional structure to the learned model and suggest a possiblegenerative interpretation.
arxiv-18300-122 | Robust Image Descriptors for Real-Time Inter-Examination Retargeting in Gastrointestinal Endoscopy | http://arxiv.org/pdf/1605.05757v1.pdf | author:Menglong Ye, Edward Johns, Benjamin Walter, Alexander Meining, Guang-Zhong Yang category:cs.CV published:2016-05-18 summary:For early diagnosis of malignancies in the gastrointestinal tract,surveillance endoscopy is increasingly used to monitor abnormal tissue changesin serial examinations of the same patient. Despite successes with opticalbiopsy for in vivo and in situ tissue characterisation, biopsy retargeting forserial examinations is challenging because tissue may change in appearancebetween examinations. In this paper, we propose an inter-examinationretargeting framework for optical biopsy, based on an image descriptor designedfor matching between endoscopic scenes over significant time intervals. Eachscene is described by a hierarchy of regional intensity comparisons at variousscales, offering tolerance to long-term change in tissue appearance whilstremaining discriminative. Binary coding is then used to compress the descriptorvia a novel random forests approach, providing fast comparisons in Hammingspace and real-time retargeting. Extensive validation conducted on 13 in vivogastrointestinal videos, collected from six patients, show that our approachoutperforms state-of-the-art methods.
arxiv-18300-123 | Generalized Min-Max Kernel and Generalized Consistent Weighted Sampling | http://arxiv.org/pdf/1605.05721v1.pdf | author:Ping Li category:cs.LG cs.IR stat.ML published:2016-05-18 summary:We propose the "generalized min-max" (GMM) kernel as a measure of datasimilarity, where data vectors can have both positive and negative entries. GMMis positive definite as there is an associate hashing method named "generalizedconsistent weighted sampling" (GCWS) which linearizes this (nonlinear) kernel.A natural competitor of the GMM kernel is the radial basis function (RBF)kernel, whose corresponding hashing method is known as the "random Fourierfeatures" (RFF). Our classification experiments on public datasets illustratethat both the GMM and RBF kernels can substantially improve linear classifiers.Furthermore, we show that GCWS typically requires substantially fewer samplesthan RFF. We expect that GMM and GCWS will be adopted in practice forlarge-scale machine learning applications and near neighbor search.
arxiv-18300-124 | Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches | http://arxiv.org/pdf/1510.05970v2.pdf | author:Jure ≈Ωbontar, Yann LeCun category:cs.CV cs.LG cs.NE published:2015-10-20 summary:We present a method for extracting depth information from a rectified imagepair. Our approach focuses on the first stage of many stereo algorithms: thematching cost computation. We approach the problem by learning a similaritymeasure on small image patches using a convolutional neural network. Trainingis carried out in a supervised manner by constructing a binary classificationdata set with examples of similar and dissimilar pairs of patches. We examinetwo network architectures for this task: one tuned for speed, the other foraccuracy. The output of the convolutional neural network is used to initializethe stereo matching cost. A series of post-processing steps follow: cross-basedcost aggregation, semiglobal matching, a left-right consistency check, subpixelenhancement, a median filter, and a bilateral filter. We evaluate our method onthe KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that itoutperforms other approaches on all three data sets.
arxiv-18300-125 | Active Learning On Weighted Graphs Using Adaptive And Non-adaptive Approaches | http://arxiv.org/pdf/1605.05710v1.pdf | author:Eyal En Gad, Akshay Gadde, A. Salman Avestimehr, Antonio Ortega category:cs.LG published:2016-05-18 summary:This paper studies graph-based active learning, where the goal is toreconstruct a binary signal defined on the nodes of a weighted graph, bysampling it on a small subset of the nodes. A new sampling algorithm isproposed, which sequentially selects the graph nodes to be sampled, based on anaggressive search for the boundary of the signal over the graph. The algorithmgeneralizes a recent method for sampling nodes in unweighted graphs. Thegeneralization improves the sampling performance using the information gainedfrom the available graph weights. An analysis of the number of samples requiredby the proposed algorithm is provided, and the gain over the unweighted methodis further demonstrated in simulations. Additionally, the proposed method iscompared with an alternative state of-the-art method, which is based on thegraph's spectral properties. It is shown that the proposed method significantlyoutperforms the spectral sampling method, if the signal needs to be predictedwith high accuracy. On the other hand, if a higher level of inaccuracy istolerable, then the spectral method outperforms the proposed aggressive searchmethod. Consequently, we propose a hybrid method, which is shown to combine theadvantages of both approaches.
arxiv-18300-126 | Online Algorithms For Parameter Mean And Variance Estimation In Dynamic Regression Models | http://arxiv.org/pdf/1605.05697v1.pdf | author:Carlos Alberto Gomez-Uribe category:stat.ML published:2016-05-18 summary:We study the problem of estimating the parameters of a regression model froma set of observations, each consisting of a response and a predictor. Theresponse is assumed to be related to the predictor via a regression model ofunknown parameters. Often, in such models the parameters to be estimated areassumed to be constant. Here we consider the more general scenario where theparameters are allowed to evolve over time, a more natural assumption for manyapplications. We model these dynamics via a linear update equation withadditive noise that is often used in a wide range of engineering applications,particularly in the well-known and widely used Kalman filter (where the systemstate it seeks to estimate maps to the parameter values here). We derive anapproximate algorithm to estimate both the mean and the variance of theparameter estimates in an online fashion for a generic regression model. Thisalgorithm turns out to be equivalent to the extended Kalman filter. Wespecialize our algorithm to the multivariate exponential family distribution toobtain a generalization of the generalized linear model (GLM). Because thecommon regression models encountered in practice such as logistic, exponentialand multinomial all have observations modeled through an exponential familydistribution, our results are used to easily obtain algorithms for online meanand variance parameter estimation for all these regression models in thecontext of time-dependent parameters. Lastly, we propose to use thesealgorithms in the contextual multi-armed bandit scenario, where so far modelparameters are assumed static and observations univariate and Gaussian orBernoulli. Both of these restrictions can be relaxed using the algorithmsdescribed here, which we combine with Thompson sampling to show the resultingperformance on a simulation.
arxiv-18300-127 | Low dimensional manifold model in hyperspectral image reconstruction | http://arxiv.org/pdf/1605.05652v1.pdf | author:Zuoqiang Shi, Wei Zhu, Stanley Osher category:cs.CV cs.IT math.IT published:2016-05-18 summary:We present the application of a low dimensional manifold model (LDMM) onhyperspectral image (HSI) reconstruction. An important property ofhyperspectral images is that the patch manifold, which is sampled by thethree-dimensional blocks in the data cube, is generally of a low dimensionalnature. This is a generalization of low-rank models in that hyperspectralimages with nonlinear mixing terms can also fit in this framework. The pointintegral method (PIM) is used to solve a Laplace-Beltrami equation over a pointcloud sampling the patch manifold in LDMM. Both numerical simulations andtheoretical analysis show that the sample points constraint is correctlyenforced by PIM. The framework is demonstrated by experiments on thereconstruction of both linear and nonlinear mixed hyperspectral images with asignificant number of missing voxels and several entirely missing spectralbands.
arxiv-18300-128 | Detecting Novel Processes with CANDIES -- An Holistic Novelty Detection Technique based on Probabilistic Models | http://arxiv.org/pdf/1605.05628v1.pdf | author:Christian Gruhl, Bernhard Sick category:cs.LG published:2016-05-18 summary:In this article, we propose CANDIES (Combined Approach for Novelty Detectionin Intelligent Embedded Systems), a new approach to novelty detection intechnical systems. We assume that in a technical system several processesinteract. If we observe these processes with sensors, we are able to model theobservations (samples) with a probabilistic model, where, in an ideal case, thecomponents of the parametric mixture density model we use, correspond to theprocesses in the real world. Eventually, at run-time, novel processes emerge inthe technical systems such as in the case of an unpredictable failure. As aconsequence, new kinds of samples are observed that require an adaptation ofthe model. CANDIES relies on mixtures of Gaussians which can be used forclassification purposes, too. New processes may emerge in regions of themodels' input spaces where few samples were observed before (low-densityregions) or in regions where already many samples were available (high-densityregions). The latter case is more difficult, but most existing solutions focuson the former. Novelty detection in low- and high-density regions requiresdifferent detection strategies. With CANDIES, we introduce a new technique todetect novel processes in high-density regions by means of a fast onlinegoodness-of-fit test. For detection in low-density regions we combine thisapproach with a 2SND (Two-Stage-Novelty-Detector) which we presented inpreliminary work. The properties of CANDIES are evaluated using artificial dataand benchmark data from the field of intrusion detection in computer networks,where the task is to detect new kinds of attacks.
arxiv-18300-129 | Learning Convolutional Neural Networks for Graphs | http://arxiv.org/pdf/1605.05273v2.pdf | author:Mathias Niepert, Mohamed Ahmed, Konstantin Kutzkov category:cs.LG cs.AI stat.ML published:2016-05-17 summary:Numerous important problems can be framed as learning from graph data. Wepropose a framework for learning convolutional neural networks for arbitrarygraphs. These graphs may be undirected, directed, and with both discrete andcontinuous node and edge attributes. Analogous to image-based convolutionalnetworks that operate on locally connected regions of the input, we present ageneral approach to extracting locally connected regions from graphs. Usingestablished benchmark data sets, we demonstrate that the learned featurerepresentations are competitive with state of the art graph kernels and thattheir computation is highly efficient.
arxiv-18300-130 | Gaussian variational approximation with sparse precision matrix | http://arxiv.org/pdf/1605.05622v1.pdf | author:Linda S. L. Tan, David J. Nott category:stat.CO stat.ML published:2016-05-18 summary:We consider the problem of learning a Gaussian variational approximation tothe posterior distribution for a high-dimensional parameter, where we imposesparsity in the precision matrix to reflect appropriate conditionalindependence structure in the model. Incorporating sparsity in the precisionmatrix allows the Gaussian variational distribution to be both flexible andparsimonious, and the sparsity is achieved through parameterization in terms ofthe Cholesky factor. Efficient stochastic gradient methods which makeappropriate use of gradient information for the target distribution aredeveloped for the optimization. We consider alternative estimators of thestochastic gradients which have lower variation and are more stable. Ourapproach is illustrated using generalized linear mixed models and state spacemodels for time series.
arxiv-18300-131 | Variational Gaussian Copula Inference | http://arxiv.org/pdf/1506.05860v3.pdf | author:Shaobo Han, Xuejun Liao, David B. Dunson, Lawrence Carin category:stat.ML cs.LG stat.CO published:2015-06-19 summary:We utilize copulas to constitute a unified framework for constructing andoptimizing variational proposals in hierarchical Bayesian models. For modelswith continuous and non-Gaussian hidden variables, we propose a semiparametricand automated variational Gaussian copula approach, in which the parametricGaussian copula family is able to preserve multivariate posterior dependence,and the nonparametric transformations based on Bernstein polynomials provideample flexibility in characterizing the univariate marginal posteriors.
arxiv-18300-132 | On Structured Sparsity of Phonological Posteriors for Linguistic Parsing | http://arxiv.org/pdf/1601.05647v2.pdf | author:Milos Cernak, Afsaneh Asaei, Herv√© Bourlard category:cs.CL published:2016-01-21 summary:The speech signal conveys information on different time scales from shorttime scale or segmental, associated to phonological and phonetic information tolong time scale or supra segmental, associated to syllabic and prosodicinformation. Linguistic and neurocognitive studies recognize the phonologicalclasses at segmental level as the essential and invariant representations usedin speech temporal organization. In the context of speech processing, a deepneural network (DNN) is an effective computational method to infer theprobability of individual phonological classes from a short segment of speechsignal. A vector of all phonological class probabilities is referred to asphonological posterior. There are only very few classes comprising a short termspeech signal; hence, the phonological posterior is a sparse vector. Althoughthe phonological posteriors are estimated at segmental level, we claim thatthey convey supra-segmental information. Specifically, we demonstrate thatphonological posteriors are indicative of syllabic and prosodic events.Building on findings from converging linguistic evidence on the gestural modelof Articulatory Phonology as well as the neural basis of speech perception, wehypothesize that phonological posteriors convey properties of linguisticclasses at multiple time scales, and this information is embedded in theirsupport (index) of active coefficients. To verify this hypothesis, we obtain abinary representation of phonological posteriors at the segmental level whichis referred to as first-order sparsity structure; the high-order structures areobtained by the concatenation of first-order binary vectors. It is thenconfirmed that the classification of supra-segmental linguistic events, theproblem known as linguistic parsing, can be achieved with high accuracy usingasimple binary pattern matching of first-order or high-order structures.
arxiv-18300-133 | The AMU-UEDIN Submission to the WMT16 News Translation Task: Attention-based NMT Models as Feature Functions in Phrase-based SMT | http://arxiv.org/pdf/1605.04809v2.pdf | author:Marcin Junczys-Dowmunt, Tomasz Dwojak, Rico Sennrich category:cs.CL published:2016-05-16 summary:This paper describes the AMU-UEDIN submissions to the WMT 2016 shared task onnews translation. We explore methods of decode-time integration ofattention-based neural translation models with phrase-based statistical machinetranslation. Efficient batch-algorithms for GPU-querying are proposed andimplemented. For English-Russian, the phrase-based system cannot surpassstate-of-the-art pure neural models. For the Russian-English task, oursubmission achieves the top BLEU result, outperforming the best pure neuralsystem by 1.1 BLEU points and our own phrase-based baseline by 1.6 BLEU. Infollow-up experiments we improve these results by additional 0.7 BLEU.
arxiv-18300-134 | A deep learning approach to single-particle recognition in cryo-electron microscopy | http://arxiv.org/pdf/1605.05543v1.pdf | author:Yanan Zhu, Qi Ouyang, Youdong Mao category:cs.CV published:2016-05-18 summary:Particle extraction represents a major practical bottleneck in the structuredetermination of biological macromolecular complexes by single-particlecryo-electron microscopy (cryo-EM). We developed a deep learning-basedalgorithmic framework, DeepEM, for single-particle recognition from noisycryo-EM micrographs, enabling automated particle picking, selection andverification in an integrated fashion. Our approach exhibits improvedperformance and high accuracy when tested on the standard KLH dataset as wellas several challenging experimental cryo-EM datasets.
arxiv-18300-135 | Improving Weakly-Supervised Object Localization By Micro-Annotation | http://arxiv.org/pdf/1605.05538v1.pdf | author:Alexander Kolesnikov, Christoph H. Lampert category:cs.CV published:2016-05-18 summary:Weakly-supervised object localization methods tend to fail for object classesthat consistently co-occur with the same background elements, e.g. trains ontracks. We propose a method to overcome these failures by adding a very smallamount of model-specific additional annotation. The main idea is to cluster adeep network's mid-level representations and assign object or distractor labelsto each cluster. Experiments show substantially improved localization resultson the challenging ILSVC2014 dataset for bounding box detection and the PASCALVOC2012 dataset for semantic segmentation.
arxiv-18300-136 | ABC random forests for Bayesian parameter inference | http://arxiv.org/pdf/1605.05537v1.pdf | author:Jean-Michel Marin, Louis Raynal, Pierre Pudlo, Mathieu Ribatet, Christian P. Robert category:stat.ME stat.CO stat.ML published:2016-05-18 summary:Approximate Bayesian Computation (ABC) has grown into a standard methodologyto handle Bayesian inference in models associated with intractable likelihoodfunctions. Most ABC implementations require the selection of a summarystatistic as the data itself is too large or too complex to be compared tosimulated realisations from the assumed model. The dimension of this statisticis generally constrained to be close to the dimension of the model parameterfor efficiency reasons. Furthermore, the tolerance level that governs theacceptance or rejection of parameter values needs to be calibrated and therange of calibration techniques available so far is mostly based on asymptoticarguments. We propose here to conduct Bayesian inference based on anarbitrarily large vector of summary statistics without imposing a selection ofthe relevant components and bypassing the derivation of a tolerance. Theapproach relies on the random forest methodology of Breiman (2001) when appliedto regression. We advocate the derivation of a new random forest for eachcomponent of the parameter vector, a tool from which an approximation to themarginal posterior distribution can be derived. Correlations between parametercomponents are handled by separate random forests. This technology offerssignificant gains in terms of robustness to the choice of the summarystatistics and of computing time, when compared with more standard ABCsolutions.
arxiv-18300-137 | Characteristic Kernels and Infinitely Divisible Distributions | http://arxiv.org/pdf/1403.7304v2.pdf | author:Yu Nishiyama, Kenji Fukumizu category:stat.ML published:2014-03-28 summary:We connect shift-invariant characteristic kernels to infinitely divisibledistributions on $\mathbb{R}^{d}$. Characteristic kernels play an importantrole in machine learning applications with their kernel means to distinguishany two probability measures. The contribution of this paper is two-fold.First, we show, using the L\'evy-Khintchine formula, that any shift-invariantkernel given by a bounded, continuous and symmetric probability densityfunction (pdf) of an infinitely divisible distribution on $\mathbb{R}^d$ ischaracteristic. We also present some closure property of such characteristickernels under addition, pointwise product, and convolution. Second, indeveloping various kernel mean algorithms, it is fundamental to compute thefollowing values: (i) kernel mean values $m_P(x)$, $x \in \mathcal{X}$, and(ii) kernel mean RKHS inner products ${\left\langle m_P, m_Q \right\rangle_{\mathcal{H}}}$, for probability measures $P, Q$. If $P, Q$, and kernel $k$are Gaussians, then computation (i) and (ii) results in Gaussian pdfs that istractable. We generalize this Gaussian combination to more general cases in theclass of infinitely divisible distributions. We then introduce a {\itconjugate} kernel and {\it convolution trick}, so that the above (i) and (ii)have the same pdf form, expecting tractable computation at least in some cases.As specific instances, we explore $\alpha$-stable distributions and a richclass of generalized hyperbolic distributions, where the Laplace, Cauchy andStudent-t distributions are included.
arxiv-18300-138 | Learning activation functions from data using cubic spline interpolation | http://arxiv.org/pdf/1605.05509v1.pdf | author:Simone Scardapane, Michele Scarpiniti, Danilo Comminiello, Aurelio Uncini category:stat.ML cs.LG cs.NE published:2016-05-18 summary:Neural networks require a careful design in order to perform properly on agiven task. In particular, selecting a good activation function (possibly in adata-dependent fashion) is a crucial step, which remains an open problem in theresearch community. Despite a large amount of investigations, most currentimplementations simply select one fixed function from a small set ofcandidates, which is not adapted during training, and is shared among allneurons throughout the different layers. However, neither two of theseassumptions can be supposed optimal in practice. In this paper, we present aprincipled way to have data-dependent adaptation of the activation functions,which is performed independently for each neuron. This is achieved byleveraging over past and present advances on cubic spline interpolation,allowing for local adaptation of the functions around their regions of use. Theresulting algorithm is relatively cheap to implement, and overfitting iscounterbalanced by the inclusion of a novel damping criterion, which penalizesunwanted oscillations from a predefined shape. Experimental results validatethe proposal over two well-known benchmarks.
arxiv-18300-139 | A new kernel-based approach for overparameterized Hammerstein system identification | http://arxiv.org/pdf/1504.08190v2.pdf | author:Riccardo Sven Risuleo, Giulio Bottegal, H√•kan Hjalmarsson category:cs.SY stat.ML published:2015-04-30 summary:In this paper we propose a new identification scheme for Hammerstein systems,which are dynamic systems consisting of a static nonlinearity and a lineartime-invariant dynamic system in cascade. We assume that the nonlinear functioncan be described as a linear combination of $p$ basis functions. We reconstructthe $p$ coefficients of the nonlinearity together with the first $n$ samples ofthe impulse response of the linear system by estimating an $np$-dimensionaloverparameterized vector, which contains all the combinations of the unknownvariables. To avoid high variance in these estimates, we adopt a regularizedkernel-based approach and, in particular, we introduce a new kernel tailoredfor Hammerstein system identification. We show that the resulting schemeprovides an estimate of the overparameterized vector that can be uniquelydecomposed as the combination of an impulse response and $p$ coefficients ofthe static nonlinearity. We also show, through several numerical experiments,that the proposed method compares very favorably with two standard methods forHammerstein system identification.
arxiv-18300-140 | Causality on Cross-Sectional Data: Stable Specification Search in Constrained Structural Equation Modeling | http://arxiv.org/pdf/1506.05600v2.pdf | author:Ridho Rahmadi, Perry Groot, Marianne Heins, Hans Knoop, Tom Heskes, The OPTIMISTIC consortium category:stat.ML cs.LG published:2015-06-18 summary:Causal modeling has long been an attractive topic for many researchers and inrecent decades there has seen a surge in theoretical development and discoveryalgorithms. Generally discovery algorithms can be divided into two approaches:constraint-based and score-based. The constraint-based approach is able todetect common causes of the observed variables but the use of independencetests makes it less reliable. The score-based approach produces a result thatis easier to interpret as it also measures the reliability of the inferredcausal relationships, but it is unable to detect common confounders of theobserved variables. A drawback of both score-based and constrained-basedapproaches is the inherent instability in structure estimation. With finitesamples small changes in the data can lead to completely different optimalstructures. The present work introduces a new hypothesis-free score-basedcausal discovery algorithm that is robust for finite samples based on recentadvances in stability selection using subsampling and selection algorithms.Structure search is performed over Structural Equation Models. Our approachuses exploratory search but allows incorporation of prior background knowledge.We validated our approach on one simulated data set, which we compare to theknown the ground truth, and two real-world data sets for Chronic FatigueSyndrome and Attention Deficit Hyperactivity Disorder, which we compare toearlier medical studies. The result on the simulated data set shows accuratestructure estimates and the results on the real-word data sets show consistencywith the hypothesis driven models constructed by medical experts.
arxiv-18300-141 | Image segmentation with superpixel-based covariance descriptors in low-rank representation | http://arxiv.org/pdf/1605.05466v1.pdf | author:Xianbin Gu, Jeremiah D. Deng, Martin K. Purvis category:cs.CV published:2016-05-18 summary:This paper investigates the problem of image segmentation using superpixels.We propose two approaches to enhance the discriminative ability of thesuperpixel's covariance descriptors. In the first one, we employ theLog-Euclidean distance as the metric on the covariance manifolds, and then usethe RBF kernel to measure the similarities between covariance descriptors. Thesecond method is focused on extracting the subspace structure of the set ofcovariance descriptors by extending a low rank representation algorithm on tothe covariance manifolds. Experiments are carried out with the BerklySegmentation Dataset, and compared with the state-of-the-art segmentationalgorithms, both methods are competitive.
arxiv-18300-142 | Dual Local-Global Contextual Pathways for Recognition in Aerial Imagery | http://arxiv.org/pdf/1605.05462v1.pdf | author:Alina Marcu, Marius Leordeanu category:cs.CV published:2016-05-18 summary:Visual context is important in object recognition and it is still an openproblem in computer vision. Along with the advent of deep convolutional neuralnetworks (CNN), using contextual information with such systems starts toreceive attention in the literature. At the same time, aerial imagery isgaining momentum. While advances in deep learning make good progress in aerialimage analysis, this problem still poses many great challenges. Aerial imagesare often taken under poor lighting conditions and contain low resolutionobjects, many times occluded by trees or taller buildings. In this domain, inparticular, visual context could be of great help, but there are still very fewpapers that consider context in aerial image understanding. Here we introducecontext as a complementary way of recognizing objects. We propose a dual-streamdeep neural network model that processes information along two independentpathways, one for local and another for global visual reasoning. The two arelater combined in the final layers of processing. Our model learns to combinelocal object appearance as well as information from the larger scene at thesame time and in a complementary way, such that together they form a powerfulclassifier. We test our dual-stream network on the task of segmentation ofbuildings and roads in aerial images and obtain state-of-the-art results on theMassachusetts Buildings Dataset. We also introduce two new datasets, forbuildings and road segmentation, respectively, and study the relativeimportance of local appearance vs. the larger scene, as well as theirperformance in combination. While our local-global model could also be usefulin general recognition tasks, we clearly demonstrate the effectiveness ofvisual context in conjunction with deep nets for aerial image understanding.
arxiv-18300-143 | The Bees Algorithm for the Vehicle Routing Problem | http://arxiv.org/pdf/1605.05448v1.pdf | author:Aish Fenton category:cs.NE cs.AI published:2016-05-18 summary:In this thesis we present a new algorithm for the Vehicle Routing Problemcalled the Enhanced Bees Algorithm. It is adapted from a fairly recentalgorithm, the Bees Algorithm, which was developed for continuous optimisationproblems. We show that the results obtained by the Enhanced Bees Algorithm arecompetitive with the best meta-heuristics available for the Vehicle RoutingProblem (within 0.5% of the optimal solution for common benchmark problems). Weshow that the algorithm has good runtime performance, producing results within2% of the optimal solution within 60 seconds, making it suitable for use withinreal world dispatch scenarios.
arxiv-18300-144 | Online Object Tracking, Learning and Parsing with And-Or Graphs | http://arxiv.org/pdf/1509.08067v5.pdf | author:Tianfu Wu, Yang Lu, Song-Chun Zhu category:cs.CV cs.LG published:2015-09-27 summary:This paper presents a method, called AOGTracker, for simultaneously tracking,learning and parsing (TLP) unknown objects in video sequences with ahierarchical and compositional And-Or graph (AOG) representation. %The AOGcaptures both structural and appearance variations of a target object in aprincipled way. The TLP method is formulated in the Bayesian framework with aspatial and a temporal dynamic programming (DP) algorithms inferring objectbounding boxes on-the-fly. During online learning, the AOG is discriminativelylearned using latent SVM to account for appearance (e.g., lighting and partialocclusion) and structural (e.g., different poses and viewpoints) variations ofa tracked object, as well as distractors (e.g., similar objects) in background.Three key issues in online inference and learning are addressed: (i)maintaining purity of positive and negative examples collected online, (ii)controling model complexity in latent structure learning, and (iii) identifyingcritical moments to re-learn the structure of AOG based on its intrackability.The intrackability measures uncertainty of an AOG based on its score maps in aframe. In experiments, our AOGTracker is tested on two popular trackingbenchmarks with the same parameter setting: the TB-100/50/CVPR2013 benchmarks,and the VOT benchmarks --- VOT 2013, 2014, 2015 and TIR2015 (thermal imagerytracking). In the former, our AOGTracker outperforms state-of-the-art trackingalgorithms including two trackers based on deep convolutional network. In thelatter, our AOGTracker outperforms all other trackers in VOT2013 and iscomparable to the state-of-the-art methods in VOT2014, 2015 and TIR2015. Reproducibility: The source code is released with this paper for reproducingall results, which is available at https://github.com/tfwu/RGM-AOGTracker.
arxiv-18300-145 | Beyond Caption To Narrative: Video Captioning With Multiple Sentences | http://arxiv.org/pdf/1605.05440v1.pdf | author:Andrew Shin, Katsunori Ohnishi, Tatsuya Harada category:cs.CV published:2016-05-18 summary:Recent advances in image captioning task have led to increasing interests invideo captioning task. However, most works on video captioning are focused ongenerating single input of aggregated features, which hardly deviates fromimage captioning process and does not fully take advantage of dynamic contentspresent in videos. We attempt to generate video captions that convey richercontents by temporally segmenting the video with action localization,generating multiple captions from multiple frames, and connecting them withnatural language processing techniques, in order to generate a story-likecaption. We show that our proposed method can generate captions that are richerin contents and can compete with state-of-the-art method without explicitlyusing video-level features as input.
arxiv-18300-146 | Relations such as Hypernymy: Identifying and Exploiting Hearst Patterns in Distributional Vectors for Lexical Entailment | http://arxiv.org/pdf/1605.05433v1.pdf | author:Stephen Roller, Katrin Erk category:cs.CL cs.AI published:2016-05-18 summary:We consider the task of predicting lexical entailment using distributionalvectors. We focus experiments on one previous classifier which was shown toonly learn to detect prototypicality of a word pair. Analysis shows that themodel single-mindedly learns to detect Hearst Patterns, which are well known tobe predictive of lexical relations. We present a new model which exploits thisHearst Detector functionality, matching or outperforming prior work on multipledata sets.
arxiv-18300-147 | Optimization Beyond Prediction: Prescriptive Price Optimization | http://arxiv.org/pdf/1605.05422v1.pdf | author:Shinji Ito, Ryohei Fujimaki category:math.OC cs.LG stat.ML published:2016-05-18 summary:This paper addresses a novel data science problem, prescriptive priceoptimization, which derives the optimal price strategy to maximize futureprofit/revenue on the basis of massive predictive formulas produced by machinelearning. The prescriptive price optimization first builds sales forecastformulas of multiple products, on the basis of historical data, which revealcomplex relationships between sales and prices, such as price elasticity ofdemand and cannibalization. Then, it constructs a mathematical optimizationproblem on the basis of those predictive formulas. We present that theoptimization problem can be formulated as an instance of binary quadraticprogramming (BQP). Although BQP problems are NP-hard in general andcomputationally intractable, we propose a fast approximation algorithm using asemi-definite programming (SDP) relaxation, which is closely related to theGoemans-Williamson's Max-Cut approximation. Our experiments on simulation andreal retail datasets show that our prescriptive price optimizationsimultaneously derives the optimal prices of tens/hundreds products withpractical computational time, that potentially improve 8.2% of gross profit ofthose products.
arxiv-18300-148 | Leveraging Lexical Resources for Learning Entity Embeddings in Multi-Relational Data | http://arxiv.org/pdf/1605.05416v1.pdf | author:Teng Long, Ryan Lowe, Jackie Chi Kit Cheung, Doina Precup category:cs.CL published:2016-05-18 summary:Recent work in learning vector-space embeddings for multi-relational data hasfocused on combining relational information derived from knowledge bases withdistributional information derived from large text corpora. We propose a simpleapproach that leverages the descriptions of entities or phrases available inlexical resources, in conjunction with distributional semantics, in order toderive a better initialization for training relational models. Applying thisinitialization to the TransE model results in significant new state-of-the-artperformances on the WordNet dataset, decreasing the mean rank from the previousbest of 212 to 51. It also results in faster convergence of the entityrepresentations. We find that there is a trade-off between improving the meanrank and the hits@10 with this approach. This illustrates that much remains tobe understood regarding performance improvements in relational models.
arxiv-18300-149 | Relative distance features for gait recognition with Kinect | http://arxiv.org/pdf/1605.05415v1.pdf | author:Ke Yang, Yong Dou, Shaohe Lv, Fei Zhang, Qi Lv category:cs.CV published:2016-05-18 summary:Gait and static body measurement are important biometric technologies forpassive human recognition. Many previous works argue that recognitionperformance based completely on the gait feature is limited. The reason forthis limited performance remains unclear. This study focuses on humanrecognition with gait feature obtained by Kinect and shows that gait featurecan effectively distinguish from different human beings through a novelrepresentation -- relative distance-based gait features. Experimental resultsshow that the recognition accuracy with relative distance features reaches upto 85%, which is comparable with that of anthropometric features. Thecombination of relative distance features and anthropometric features canprovide an accuracy of more than 95%. Results indicate that the relativedistance feature is quite effective and worthy of further study in more generalscenarios (e.g., without Kinect).
arxiv-18300-150 | On the Evaluation of Dialogue Systems with Next Utterance Classification | http://arxiv.org/pdf/1605.05414v1.pdf | author:Ryan Lowe, Iulian V. Serban, Mike Noseworthy, Laurent Charlin, Joelle Pineau category:cs.CL cs.LG published:2016-05-18 summary:An open challenge in constructing dialogue systems is developing methods forautomatically learning dialogue strategies from large amounts of unlabelleddata. Recent work has proposed Next-Utterance-Classification (NUC) as asurrogate task for building dialogue systems from text data. In this paper weinvestigate the performance of humans on this task to validate the relevance ofNUC as a method of evaluation. Our results show three main findings: (1) humansare able to correctly classify responses at a rate much better than chance,thus confirming that the task is feasible, (2) human performance levels varyacross task domains (we consider 3 datasets) and expertise levels (novice vsexperts), thus showing that a range of performance is possible on this type oftask, (3) automated dialogue systems built using state-of-the-art machinelearning methods have similar performance to the human novices, but worse thanthe experts, thus confirming the utility of this class of tasks for drivingfurther research in automated dialogue systems.
arxiv-18300-151 | Are Facial Attributes Adversarially Robust? | http://arxiv.org/pdf/1605.05411v1.pdf | author:Andras Rozsa, Manuel G√ºnther, Ethan M. Rudd, Terrance E. Boult category:cs.CV published:2016-05-18 summary:Facial attributes are emerging soft biometrics that have the potential toreject non-matches, for example, based on on mismatching gender. To be usablein stand-alone systems, facial attributes must be extracted from imagesautomatically and reliably. In this paper we propose a simple yet effectivesolution for automatic facial attribute extraction by training a deepconvolutional neural network (DCNN) for each facial attribute separately,without using any pre-training or dataset augmentation, and we obtain newstate-of-the-art facial attribute classification results on the CelebAbenchmark. To test the stability of the networks, we generated adversarialimages via a novel fast flipping attribute (FFA) technique. We show that FFAgenerates more adversarials than other related algorithms, and that the DCNNsfor certain attributes are generally robust to adversarial inputs, while DCNNsfor other attributes are not. This result is surprising because no DCNNs testedto date have exhibited robustness to adversarial images without explicitaugmentation in the training procedure to account for adversarial examples.Finally, we introduce the concept of natural adversarial images, i.e., imagesthat are misclassified but can be easily turned into correctly classifiedimages by applying small perturbations. We demonstrate that naturaladversarials commonly occur, even within the training set, and show that mostof these images remain misclassified even with additional training epochs. Thisphenomenon is surprising because correcting the misclassification, particularlywhen guided by training data, should require only a small adjustment to theDCNN parameters.
arxiv-18300-152 | The Extreme Value Machine | http://arxiv.org/pdf/1506.06112v3.pdf | author:Ethan M. Rudd, Lalit P. Jain, Walter J. Scheirer, Terrance E. Boult category:cs.LG published:2015-06-19 summary:It is often desirable to be able to recognize when inputs to a recognitionfunction correspond to classes unseen at training time. With this ability,these inputs could be re-labeled by a human, and later incorporated into therecognition function -- ideally under an efficient incremental updatemechanism. While good models that assume inputs from a fixed set of classesexist, e.g., artificial neural networks and kernel machines, it is notimmediately obvious how to extend them to perform incremental learning in thepresence of unknown query classes. Models that do so take little otherdistributional information into account when constructing recognition functionsand lack strong theoretical foundations. We take steps to address this gap byformulating a novel, theoretically grounded classifier -- the Extreme ValueMachine (EVM) -- which is capable of performing open world recognition. The EVMhas a well-grounded interpretation derived from statistical extreme valuetheory (EVT), and is the first classifier of its kind to be able to performnonlinear, kernel-free, variable bandwidth, incremental learning. Wedemonstrate experimentally that, compared to other classifiers in the same deepnetwork derived feature space, the EVM is accurate and efficient on anestablished benchmark partition of the ImageNet dataset.
arxiv-18300-153 | Learning a low-rank shared dictionary for object classification | http://arxiv.org/pdf/1602.00310v2.pdf | author:Tiep H. Vu, Vishal Monga category:cs.CV published:2016-01-31 summary:Despite the fact that different objects possess distinct class-specificfeatures, they also usually share common patterns. Inspired by thisobservation, we propose a novel method to explicitly and simultaneously learn aset of common patterns as well as class-specific features for classification.Our dictionary learning framework is hence characterized by both a shareddictionary and particular (class-specific) dictionaries. For the shareddictionary, we enforce a low-rank constraint, i.e. claim that its spanningsubspace should have low dimension and the coefficients corresponding to thisdictionary should be similar. For the particular dictionaries, we impose onthem the well-known constraints stated in the Fisher discrimination dictionarylearning (FDDL). Further, we propose a new fast and accurate algorithm to solvethe sparse coding problems in the learning step, accelerating its convergence.The said algorithm could also be applied to FDDL and its extensions.Experimental results on widely used image databases establish the advantages ofour method over state-of-the-art dictionary learning methods.
arxiv-18300-154 | Detecting Burnscar from Hyperspectral Imagery via Sparse Representation with Low-Rank Interference | http://arxiv.org/pdf/1605.00287v2.pdf | author:Minh Dao, Xiang Xiang, Bulent Ayhan, Chiman Kwan, Trac D. Tran category:cs.CV published:2016-05-01 summary:In this paper, we propose a burnscar detection model for hyperspectralimaging (HSI) data. The proposed model contains two-processing steps in whichthe first step separate and then suppress the cloud information presenting inthe data set using an RPCA algorithm and the second step detect the burnscararea in the low-rank component output of the first step. Experiments areconducted on the public MODIS dataset available at NASA official website.
arxiv-18300-155 | Generative Adversarial Text to Image Synthesis | http://arxiv.org/pdf/1605.05396v1.pdf | author:Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, Honglak Lee category:cs.NE cs.CV published:2016-05-17 summary:Automatic synthesis of realistic images from text would be interesting anduseful, but current AI systems are still far from this goal. However, in recentyears generic and powerful recurrent neural network architectures have beendeveloped to learn discriminative text feature representations. Meanwhile, deepconvolutional generative adversarial networks (GANs) have begun to generatehighly compelling images of specific categories such as faces, album covers,room interiors etc. In this work, we develop a novel deep architecture and GANformulation to effectively bridge these advances in text and image modeling,translating visual concepts from characters to pixels. We demonstrate thecapability of our model to generate plausible images of birds and flowers fromdetailed text descriptions.
arxiv-18300-156 | Learning Deep Representations of Fine-grained Visual Descriptions | http://arxiv.org/pdf/1605.05395v1.pdf | author:Scott Reed, Zeynep Akata, Bernt Schiele, Honglak Lee category:cs.CV published:2016-05-17 summary:State-of-the-art methods for zero-shot visual recognition formulate learningas a joint embedding problem of images and side information. In theseformulations the current best complement to visual features are attributes:manually encoded vectors describing shared characteristics among categories.Despite good performance, attributes have limitations: (1) finer-grainedrecognition requires commensurately more attributes, and (2) attributes do notprovide a natural language interface. We propose to overcome these limitationsby training neural language models from scratch; i.e. without pre-training andonly consuming words and characters. Our proposed models train end-to-end toalign with the fine-grained and category-specific content of images. Naturallanguage provides a flexible and compact way of encoding only the salientvisual aspects for distinguishing categories. By training on raw text, ourmodel can do inference on raw text as well, providing humans a familiar modeboth for annotation and retrieval. Our model achieves strong performance onzero-shot text-based image retrieval and significantly outperforms theattribute-based state-of-the-art for zero-shot classification on the CaltechUCSD Birds 200-2011 dataset.
arxiv-18300-157 | Dynamic Frame skip Deep Q Network | http://arxiv.org/pdf/1605.05365v1.pdf | author:Aravind S. Lakshminarayanan, Sahil Sharma, Balaraman Ravindran category:cs.LG cs.AI cs.NE published:2016-05-17 summary:Deep Reinforcement Learning methods have achieved state of the artperformance in learning control policies for the games in the Atari 2600domain. One of the important parameters in the Arcade Learning Environment(ALE) is the frame skip rate. It decides the granularity at which agents cancontrol game play. A frame skip value of $k$ allows the agent to repeat aselected action $k$ number of times. The current state of the art architectureslike Deep Q-Network (DQN) and Dueling Network Architectures (DuDQN) consist ofa framework with a static frame skip rate, where the action output from thenetwork is repeated for a fixed number of frames regardless of the currentstate. In this paper, we propose a new architecture, Dynamic Frame skip DeepQ-Network (DFDQN) which makes the frame skip rate a dynamic learnableparameter. This allows us to choose the number of times an action is to berepeated based on the current state. We show empirically that such a settingimproves the performance on relatively harder games like Seaquest.
arxiv-18300-158 | Yelp Dataset Challenge: Review Rating Prediction | http://arxiv.org/pdf/1605.05362v1.pdf | author:Nabiha Asghar category:cs.CL cs.IR cs.LG published:2016-05-17 summary:Review websites, such as TripAdvisor and Yelp, allow users to post onlinereviews for various businesses, products and services, and have been recentlyshown to have a significant influence on consumer shopping behaviour. An onlinereview typically consists of free-form text and a star rating out of 5. Theproblem of predicting a user's star rating for a product, given the user's textreview for that product, is called Review Rating Prediction and has latelybecome a popular, albeit hard, problem in machine learning. In this paper, wetreat Review Rating Prediction as a multi-class classification problem, andbuild sixteen different prediction models by combining four feature extractionmethods, (i) unigrams, (ii) bigrams, (iii) trigrams and (iv) Latent SemanticIndexing, with four machine learning algorithms, (i) logistic regression, (ii)Naive Bayes classification, (iii) perceptrons, and (iv) linear Support VectorClassification. We analyse the performance of each of these sixteen models tocome up with the best model for predicting the ratings from reviews. We use thedataset provided by Yelp for training and testing the models.
arxiv-18300-159 | Unsupervised Total Variation Loss for Semi-supervised Deep Learning of Semantic Segmentation | http://arxiv.org/pdf/1605.01368v2.pdf | author:Mehran Javanmardi, Mehdi Sajjadi, Ting Liu, Tolga Tasdizen category:cs.CV published:2016-05-04 summary:We introduce a novel unsupervised loss function for learning semanticsegmentation with deep convolutional neural nets (ConvNet) when densely labeledtraining images are not available. More specifically, the proposed lossfunction penalizes the L1-norm of the gradient of the label probability vectorimage , i.e. total variation, produced by the ConvNet. This can be seen as aregularization term that promotes piecewise smoothness of the label probabilityvector image produced by the ConvNet during learning. The unsupervised lossfunction is combined with a supervised loss in a semi-supervised setting tolearn ConvNets that can achieve high semantic segmentation accuracy even whenonly a tiny percentage of the pixels in the training images are labeled. Wedemonstrate significant improvements over the purely supervised setting in theWeizmann horse, Stanford background and Sift Flow datasets. Furthermore, weshow that using the proposed piecewise smoothness constraint in the learningphase significantly outperforms post-processing results from a purelysupervised approach with Markov Random Fields (MRF). Finally, we note that theframework we introduce is general and can be used to learn to label other typesof structures such as curvilinear structures by modifying the unsupervised lossfunction accordingly.
arxiv-18300-160 | Hierarchical Reinforcement Learning using Spatio-Temporal Abstractions and Deep Neural Networks | http://arxiv.org/pdf/1605.05359v1.pdf | author:Ramnandan Krishnamurthy, Aravind S. Lakshminarayanan, Peeyush Kumar, Balaraman Ravindran category:cs.LG cs.AI cs.CV cs.NE published:2016-05-17 summary:This paper introduces an automated skill acquisition framework inreinforcement learning which involves identifying a hierarchical description ofthe given task in terms of abstract states and extended actions betweenabstract states. Identifying such structures present in the task provides waysto simplify and speed up reinforcement learning learning algorithms. Thesestructures also help to generalize such algorithms over multiple tasks withoutrelearning policies from scratch. We use ideas from dynamical systems to findmetastable regions in the state space and associate them with abstract states.The spectral clustering algorithm PCCA+ is used to identify suitableabstractions aligned to the underlying structure. Skills are defined in termsof the transitions between such abstract states. The connectivity informationfrom PCCA+ is used to generate these skills or options. The skills areindependent of the learning task and can be efficiently reused across a varietyof tasks defined over a common state space. Another major advantage of theapproach is that it does not need a prior model of the MDP and can work welleven when the MDPs are constructed from sampled trajectories. Finally, wepresent our attempts to extend the automated skills acquisition framework tocomplex tasks such as learning to play video games where we use deep learningtechniques for representation learning to aid our spatio-temporal abstractionframework.
arxiv-18300-161 | Orthogonal symmetric non-negative matrix factorization under the stochastic block model | http://arxiv.org/pdf/1605.05349v1.pdf | author:Subhadeep Paul, Yuguo Chen category:stat.ML published:2016-05-17 summary:We present a method based on the orthogonal symmetric non-negative matrixtri-factorization of the normalized Laplacian matrix for community detection incomplex networks. While the exact factorization of a given order may not existand is NP hard to compute, we obtain an approximate factorization by solving anoptimization problem. We establish the connection of the factors obtainedthrough the factorization to a non-negative basis of an invariant subspace ofthe estimated matrix, drawing parallel with the spectral clustering. Using suchfactorization for clustering in networks is motivated by analyzing ablock-diagonal Laplacian matrix with the blocks representing the connectedcomponents of a graph. The method is shown to be consistent for communitydetection in graphs generated from the stochastic block model and the degreecorrected stochastic block model. Simulation results and real data analysisshow the effectiveness of these methods under a wide variety of situations,including sparse and highly heterogeneous graphs where the usual spectralclustering is known to fail. Our method also performs better than the state ofthe art in popular benchmark network datasets, e.g., the political web blogsand the karate club data.
arxiv-18300-162 | Fast and Accurate Performance Analysis of LTE Radio Access Networks | http://arxiv.org/pdf/1605.04652v2.pdf | author:Anand Padmanabha Iyer, Ion Stoica, Mosharaf Chowdhury, Li Erran Li category:cs.DC cs.LG cs.NI published:2016-05-16 summary:An increasing amount of analytics is performed on data that is procured in areal-time fashion to make real-time decisions. Such tasks include simplereporting on streams to sophisticated model building. However, the practicalityof such analyses are impeded in several domains because they are faced with afundamental trade-off between data collection latency and analysis accuracy. In this paper, we study this trade-off in the context of a specific domain,Cellular Radio Access Networks (RAN). Our choice of this domain is influencedby its commonalities with several other domains that produce real-time data,our access to a large live dataset, and their real-time nature anddimensionality which makes it a natural fit for a popular analysis technique,machine learning (ML). We find that the latency accuracy trade-off can beresolved using two broad, general techniques: intelligent data grouping andtask formulations that leverage domain characteristics. Based on this, wepresent CellScope, a system that addresses this challenge by applying a domainspecific formulation and application of Multi-task Learning (MTL) to RANperformance analysis. It achieves this goal using three techniques: featureengineering to transform raw data into effective features, a PCA inspiredsimilarity metric to group data from geographically nearby base stationssharing performance commonalities, and a hybrid online-offline model forefficient model updates. Our evaluation of CellScope shows that its accuracyimprovements over direct application of ML range from 2.5x to 4.4x whilereducing the model update overhead by up to 4.8x. We have also used CellScopeto analyze a live LTE consisting of over 2 million subscribers for a period ofover 10 months, where it uncovered several problems and insights, some of thempreviously unknown.
arxiv-18300-163 | Fuzzy Sets Across the Natural Language Generation Pipeline | http://arxiv.org/pdf/1605.05303v1.pdf | author:A. Ramos-Soto, A. Bugar√≠n, S. Barro category:cs.AI cs.CL published:2016-05-17 summary:We explore the implications of using fuzzy techniques (mainly those commonlyused in the linguistic description/summarization of data discipline) from anatural language generation perspective. For this, we provide an extensivediscussion of some general convergence points and an exploration of therelationship between the different tasks involved in the standard NLG systempipeline architecture and the most common fuzzy approaches used in linguisticsummarization/description of data, such as fuzzy quantified statements,evaluation criteria or aggregation operators. Each individual discussion isillustrated with a related use case. Recent work made in the context ofcross-fertilization of both research fields is also referenced. This paperencompasses general ideas that emerged as part of the PhD thesis "Applicationof fuzzy sets in data-to-text systems". It does not present a specificapplication or a formal approach, but rather discusses current high-levelissues and potential usages of fuzzy sets (focused on linguistic summarizationof data) in natural language generation.
arxiv-18300-164 | Dataflow matrix machines as programmable, dynamically expandable, self-referential generalized recurrent neural networks | http://arxiv.org/pdf/1605.05296v1.pdf | author:Michael Bukatin, Steve Matthews, Andrey Radul category:cs.NE cs.PL published:2016-05-17 summary:Dataflow matrix machines are a powerful generalization of recurrent neuralnetworks. They work with multiple types of linear streams and multiple types ofneurons, including higher-order neurons which dynamically update the matrixdescribing weights and topology of the network in question while the network isrunning. It seems that the power of dataflow matrix machines is sufficient forthem to be a convenient general purpose programming platform. This paperexplores a number of useful programming idioms and constructions arising inthis context.
arxiv-18300-165 | Minimax Lower Bounds for Kronecker-Structured Dictionary Learning | http://arxiv.org/pdf/1605.05284v1.pdf | author:Zahra Shakeri, Waheed U. Bajwa, Anand D. Sarwate category:cs.IT cs.LG math.IT stat.ML published:2016-05-17 summary:Dictionary learning is the problem of estimating the collection of atomicelements that provide a sparse representation of measured/collected signals ordata. This paper finds fundamental limits on the sample complexity ofestimating dictionaries for tensor data by proving a lower bound on the minimaxrisk. This lower bound depends on the dimensions of the tensor and parametersof the generative model. The focus of this paper is on second-order tensordata, with the underlying dictionaries constructed by taking the Kroneckerproduct of two smaller dictionaries and the observed data generated by sparselinear combinations of dictionary atoms observed through white Gaussian noise.In this regard, the paper provides a general lower bound on the minimax riskand also adapts the proof techniques for equivalent results using sparse andGaussian coefficient models. The reported results suggest that the samplecomplexity of dictionary learning for tensor data can be significantly lowerthan that for unstructured data.
arxiv-18300-166 | Exact Simulation of Noncircular or Improper Complex-Valued Stationary Gaussian Processes using Circulant Embedding | http://arxiv.org/pdf/1605.05278v1.pdf | author:Adam M. Sykulski, Donald B. Percival category:stat.ME stat.CO stat.ML published:2016-05-17 summary:This paper provides an algorithm for simulating improper (or noncircular)complex-valued stationary Gaussian processes. The technique utilizes recentlydeveloped methods for multivariate Gaussian processes from the circulantembedding literature. The method can be performed in $\mathcal{O}(nlog_2n)$operations, where n is the length of the desired sequence. The method is exact,except when eigenvalues of prescribed circulant matrices are negative. Weevaluate the performance of the algorithm empirically, and provide a practicalexample where the method is guaranteed to be exact for all $n$, with animproper fractional Gaussian noise process.
arxiv-18300-167 | Fast and Accurate Algorithm for Eye Localization for Gaze Tracking in Low Resolution Images | http://arxiv.org/pdf/1605.05272v1.pdf | author:Anjith George, Aurobinda Routray category:cs.CV published:2016-05-17 summary:Iris centre localization in low-resolution visible images is a challengingproblem in computer vision community due to noise, shadows, occlusions, posevariations, eye blinks, etc. This paper proposes an efficient method fordetermining iris centre in low-resolution images in the visible spectrum. Evenlow-cost consumer-grade webcams can be used for gaze tracking without anyadditional hardware. A two-stage algorithm is proposed for iris centrelocalization. The proposed method uses geometrical characteristics of the eye.In the first stage, a fast convolution based approach is used for obtaining thecoarse location of iris centre (IC). The IC location is further refined in thesecond stage using boundary tracing and ellipse fitting. The algorithm has beenevaluated in public databases like BioID, Gi4E and is found to outperform thestate of the art methods.
arxiv-18300-168 | Real-time Eye Gaze Direction Classification Using Convolutional Neural Network | http://arxiv.org/pdf/1605.05258v1.pdf | author:Anjith George, Aurobinda Routray category:cs.CV published:2016-05-17 summary:Estimation eye gaze direction is useful in various human-computer interactiontasks. Knowledge of gaze direction can give valuable information regardingusers point of attention. Certain patterns of eye movements known as eyeaccessing cues are reported to be related to the cognitive processes in thehuman brain. We propose a real-time framework for the classification of eyegaze direction and estimation of eye accessing cues. In the first stage, thealgorithm detects faces using a modified version of the Viola-Jones algorithm.A rough eye region is obtained using geometric relations and facial landmarks.The eye region obtained is used in the subsequent stage to classify the eyegaze direction. A convolutional neural network is employed in this work for theclassification of eye gaze direction. The proposed algorithm was tested on EyeChimera database and found to outperform state of the art methods. Thecomputational complexity of the algorithm is very less in the testing phase.The algorithm achieved an average frame rate of 24 fps in the desktopenvironment.
arxiv-18300-169 | Biologically Inspired Radio Signal Feature Extraction with Sparse Denoising Autoencoders | http://arxiv.org/pdf/1605.05239v1.pdf | author:Benjamin Migliori, Riley Zeller-Townson, Daniel Grady, Daniel Gebhardt category:stat.ML cs.LG cs.NE published:2016-05-17 summary:Automatic modulation classification (AMC) is an important task for moderncommunication systems; however, it is a challenging problem when signalfeatures and precise models for generating each modulation may be unknown. Wepresent a new biologically-inspired AMC method without the need for models ormanually specified features --- thus removing the requirement for expert priorknowledge. We accomplish this task using regularized stacked sparse denoisingautoencoders (SSDAs). Our method selects efficient classification featuresdirectly from raw in-phase/quadrature (I/Q) radio signals in an unsupervisedmanner. These features are then used to construct higher-complexity abstractfeatures which can be used for automatic modulation classification. Wedemonstrate this process using a dataset generated with a software definedradio, consisting of random input bits encoded in 100-sample segments ofvarious common digital radio modulations. Our results show correctclassification rates of > 99% at 7.5 dB signal-to-noise ratio (SNR) and > 92%at 0 dB SNR in a 6-way classification test. Our experiments demonstrate adramatically new and broadly applicable mechanism for performing AMC andrelated tasks without the need for expert-defined or modulation-specific signalinformation.
arxiv-18300-170 | On the boosting ability of top-down decision tree learning algorithm for multiclass classification | http://arxiv.org/pdf/1605.05223v1.pdf | author:Anna Choromanska, Krzysztof Choromanski, Mariusz Bojarski category:cs.LG published:2016-05-17 summary:We analyze the performance of the top-down multiclass classificationalgorithm for decision tree learning called LOMtree, recently proposed in theliterature Choromanska and Langford (2014) for solving efficientlyclassification problems with very large number of classes. The algorithm onlineoptimizes the objective function which simultaneously controls the depth of thetree and its statistical accuracy. We prove important properties of thisobjective and explore its connection to three well-known entropy-based decisiontree objectives, i.e. Shannon entropy, Gini-entropy and its modified version,for which instead online optimization schemes were not yet developed. We show,via boosting-type guarantees, that maximizing the considered objective leadsalso to the reduction of all of these entropy-based objectives. The bounds weobtain critically depend on the strong-concavity properties of theentropy-based criteria, where the mildest dependence on the number of classes(only logarithmic) corresponds to the Shannon entropy.
arxiv-18300-171 | A simple and low redundancy method of image compressed sampling | http://arxiv.org/pdf/1601.00311v3.pdf | author:Leonid Yaroslavsky category:cs.CV physics.optics published:2016-01-03 summary:A problem is addressed of minimization of the number of measurements neededfor image acquisition and reconstruction with a given accuracy. In last severalyears, the compressed sensing approach to solving this problem was advanced,which promises reducing the number of required measurements by means ofobtaining sparse approximations of images. However, the number of measurementsrequired by compressive sensing substantially exceeds the theoretical minimumdefined by sparsity of the image sparse approximation. In the paper, a samplingtheory based method of image sampling is suggested that represents a practicaland substantially more economical alternative to the compressed sensingapproach. Presented and discussed are also results of experimental verificationof the method, its possible applicability extensions and some its limitations.
arxiv-18300-172 | Combinatorially Generated Piecewise Activation Functions | http://arxiv.org/pdf/1605.05216v1.pdf | author:Justin Chen category:cs.NE published:2016-05-17 summary:In the neuroevolution literature, research has primarily focused on evolvingthe number of nodes, connections, and weights in artificial neural networks.Few attempts have been made to evolve activation functions. Research inevolving activation functions has mainly focused on evolving functionparameters, and developing heterogeneous networks by selecting from a fixedpool of activation functions. This paper introduces a novel technique forevolving heterogeneous artificial neural networks through combinatoriallygenerating piecewise activation functions to enhance expressive power. Idemonstrate this technique on NeuroEvolution of Augmenting Topologies usingArcTan and Sigmoid, and show that it outperforms the original algorithm onnon-Markovian double pole balancing. This technique expands the landscape ofunconventional activation functions by demonstrating that they are competitivewith canonical choices, and introduces a purview for further exploration ofautomatic model selection for artificial neural networks.
arxiv-18300-173 | Multimodal Sparse Coding for Event Detection | http://arxiv.org/pdf/1605.05212v1.pdf | author:Youngjune Gwon, William Campbell, Kevin Brady, Douglas Sturim, Miriam Cha, H. T. Kung category:cs.LG cs.CV published:2016-05-17 summary:Unsupervised feature learning methods have proven effective forclassification tasks based on a single modality. We present multimodal sparsecoding for learning feature representations shared across multiple modalities.The shared representations are applied to multimedia event detection (MED) andevaluated in comparison to unimodal counterparts, as well as other featurelearning methods such as GMM supervectors and sparse RBM. We report thecross-validated classification accuracy and mean average precision of the MEDsystem trained on features learned from our unimodal and multimodal settingsfor a subset of the TRECVID MED 2014 dataset.
arxiv-18300-174 | Tweet2Vec: Character-Based Distributed Representations for Social Media | http://arxiv.org/pdf/1605.03481v2.pdf | author:Bhuwan Dhingra, Zhong Zhou, Dylan Fitzpatrick, Michael Muehl, William W. Cohen category:cs.LG cs.CL published:2016-05-11 summary:Text from social media provides a set of challenges that can causetraditional NLP approaches to fail. Informal language, spelling errors,abbreviations, and special characters are all commonplace in these posts,leading to a prohibitively large vocabulary size for word-level approaches. Wepropose a character composition model, tweet2vec, which finds vector-spacerepresentations of whole tweets by learning complex, non-local dependencies incharacter sequences. The proposed model outperforms a word-level baseline atpredicting user-annotated hashtags associated with the posts, doingsignificantly better when the input contains many out-of-vocabulary words orunusual character sequences. Our tweet2vec encoder is publicly available.
arxiv-18300-175 | Towards Weakly-Supervised Action Localization | http://arxiv.org/pdf/1605.05197v1.pdf | author:Philippe Weinzaepfel, Xavier Martin, Cordelia Schmid category:cs.CV published:2016-05-17 summary:This paper presents a novel approach for weakly-supervised actionlocalization, i.e., that does not require per-frame spatial annotations fortraining. We first introduce an effective method for extracting human tubes bycombining a state-of-the-art human detector with a tracking-by-detectionapproach. Our tube extraction leverages the large amount of annotated humansavailable today and outperforms the state of the art by an order of magnitude:with less than 5 tubes per video, we obtain a recall of 95% on the UCF-Sportsand J-HMDB datasets. Given these human tubes, we perform weakly-supervisedselection based on multi-fold Multiple Instance Learning (MIL) with improveddense trajectories and achieve excellent results. We obtain a mAP of 84% onUCF-Sports, 54% on J-HMDB and 45% on UCF-101, which outperforms the state ofthe art for weakly-supervised action localization and is close to theperformance of the best fully-supervised approaches. The second contribution of this paper is a new realistic dataset for actionlocalization, named DALY (Daily Action Localization in YouTube). It containshigh quality temporal and spatial annotations for 10 actions in 31 hours ofvideos (3.3M frames), which is an order of magnitude larger than standardaction localization datasets. On the DALY dataset, our tubes have a spatialrecall of 82%, but the detection task is extremely challenging, we obtain 10.8%mAP.
arxiv-18300-176 | Enhanced Twitter Sentiment Classification Using Contextual Information | http://arxiv.org/pdf/1605.05195v1.pdf | author:Soroush Vosoughi, Helen Zhou, Deb Roy category:cs.SI cs.AI cs.CL cs.IR published:2016-05-17 summary:The rise in popularity and ubiquity of Twitter has made sentiment analysis oftweets an important and well-covered area of research. However, the 140character limit imposed on tweets makes it hard to use standard linguisticmethods for sentiment classification. On the other hand, what tweets lack instructure they make up with sheer volume and rich metadata. This metadataincludes geolocation, temporal and author information. We hypothesize thatsentiment is dependent on all these contextual factors. Different locations,times and authors have different emotional valences. In this paper, we exploredthis hypothesis by utilizing distant supervision to collect millions oflabelled tweets from different locations, times and authors. We used this datato analyse the variation of tweet sentiments across different authors, timesand locations. Once we explored and understood the relationship between thesevariables and sentiment, we used a Bayesian approach to combine these variableswith more standard linguistic features such as n-grams to create a Twittersentiment classifier. This combined classifier outperforms the purelylinguistic classifier, showing that integrating the rich contextual informationavailable on Twitter into sentiment classification is a promising direction ofresearch.
arxiv-18300-177 | Hierarchical image simplification and segmentation based on Mumford-Shah-salient level line selection | http://arxiv.org/pdf/1603.04838v2.pdf | author:Yongchao Xu, Thierry G√©raud, Laurent Najman category:cs.CV published:2016-03-15 summary:Hierarchies, such as the tree of shapes, are popular representations forimage simplification and segmentation thanks to their multiscale structures.Selecting meaningful level lines (boundaries of shapes) yields to simplifyimage while preserving intact salient structures. Many image simplification andsegmentation methods are driven by the optimization of an energy functional,for instance the celebrated Mumford-Shah functional. In this paper, we proposean efficient approach to hierarchical image simplification and segmentationbased on the minimization of the piecewise-constant Mumford-Shah functional.This method conforms to the current trend that consists in producinghierarchical results rather than a unique partition. Contrary to classicalapproaches which compute optimal hierarchical segmentations from an inputhierarchy of segmentations, we rely on the tree of shapes, a unique andwell-defined representation equivalent to the image. Simply put, we compute foreach level line of the image an attribute function that characterizes itspersistence under the energy minimization. Then we stack the level lines frommeaningless ones to salient ones through a saliency map based on extinctionvalues defined on the tree-based shape space. Qualitative illustrations andquantitative evaluation on Weizmann segmentation evaluation databasedemonstrate the state-of-the-art performance of our method.
arxiv-18300-178 | Structured Prediction of 3D Human Pose with Deep Neural Networks | http://arxiv.org/pdf/1605.05180v1.pdf | author:Bugra Tekin, Isinsu Katircioglu, Mathieu Salzmann, Vincent Lepetit, Pascal Fua category:cs.CV published:2016-05-17 summary:Most recent approaches to monocular 3D pose estimation rely on Deep Learning.They either train a Convolutional Neural Network to directly regress from imageto 3D pose, which ignores the dependencies between human joints, or model thesedependencies via a max-margin structured learning framework, which involves ahigh computational cost at inference time. In this paper, we introduce a Deep Learning regression architecture forstructured prediction of 3D human pose from monocular images that relies on anovercomplete auto-encoder to learn a high-dimensional latent poserepresentation and account for joint dependencies. We demonstrate that ourapproach outperforms state-of-the-art ones both in terms of structurepreservation and prediction accuracy.
arxiv-18300-179 | Sentence Pair Scoring: Towards Unified Framework for Text Comprehension | http://arxiv.org/pdf/1603.06127v4.pdf | author:Petr Baudi≈°, Jan Pichl, Tom√°≈° Vyskoƒçil, Jan ≈†ediv√Ω category:cs.CL cs.AI cs.LG cs.NE published:2016-03-19 summary:We review the task of Sentence Pair Scoring, popular in the literature invarious forms - viewed as Answer Sentence Selection, Semantic Text Scoring,Next Utterance Ranking, Recognizing Textual Entailment, Paraphrasing or e.g. acomponent of Memory Networks. We argue that all such tasks are similar from the model perspective andpropose new baselines by comparing the performance of common IR metrics andpopular convolutional, recurrent and attention-based neural models across manySentence Pair Scoring tasks and datasets. We discuss the problem of evaluatingrandomized models, propose a statistically grounded methodology, and attempt toimprove comparisons by releasing new datasets that are much harder than some ofthe currently used well explored benchmarks. We introduce a unified open sourcesoftware framework with easily pluggable models and tasks, which enables us toexperiment with multi-task reusability of trained sentence model. We set a newstate-of-art in performance on the Ubuntu Dialogue dataset.
arxiv-18300-180 | Siamese convolutional networks based on phonetic features for cognate identification | http://arxiv.org/pdf/1605.05172v1.pdf | author:Taraka Rama category:cs.CL published:2016-05-17 summary:In this paper, we explore the use of convolutional networks (ConvNets) forthe purpose of cognate identification. We compare our architecture with binaryclassifiers based on string similarity measures on different language families.Our experiments show that convolutional networks achieve competitive resultsacross concepts and across language families at the task of cognateidentification.
arxiv-18300-181 | Digital Stylometry: Linking Profiles Across Social Networks | http://arxiv.org/pdf/1605.05166v1.pdf | author:Soroush Vosoughi, Helen Zhou, Deb Roy category:cs.SI cs.AI cs.CL cs.IR published:2016-05-17 summary:There is an ever growing number of users with accounts on multiple socialmedia and networking sites. Consequently, there is increasing interest inmatching user accounts and profiles across different social networks in orderto create aggregate profiles of users. In this paper, we present models forDigital Stylometry, which is a method for matching users through stylometryinspired techniques. We experimented with linguistic, temporal, and combinedtemporal-linguistic models for matching user accounts, using standard and noveltechniques. Using publicly available data, our best model, a combinedtemporal-linguistic one, was able to correctly match the accounts of 31% of5,612 distinct users across Twitter and Facebook.
arxiv-18300-182 | Monocular Urban Localization using Street View | http://arxiv.org/pdf/1605.05157v1.pdf | author:Li Yu, Cyril Joly, Guillaume Bresson, Fabien Moutarde category:cs.RO cs.CV published:2016-05-17 summary:This paper presents a metric global localization in the urban environmentonly with a monocular camera and the Google Street View database. We fullyleverage the abundant sources from the Street View and benefits from itstopo-metric structure to build a coarse-to-fine positioning, namely atopological place recognition process and then a metric pose estimation bylocal bundle adjustment. Our method is tested on a 3 km urban environment anddemonstrates both sub-meter accuracy and robustness to viewpoint changes,illumination and occlusion. To our knowledge, this is the first work thatstudies the global urban localization simply with a single camera and StreetView.
arxiv-18300-183 | Tweet Acts: A Speech Act Classifier for Twitter | http://arxiv.org/pdf/1605.05156v1.pdf | author:Soroush Vosoughi, Deb Roy category:cs.CL cs.SI published:2016-05-17 summary:Speech acts are a way to conceptualize speech as action. This holds true forcommunication on any platform, including social media platforms such asTwitter. In this paper, we explored speech act recognition on Twitter bytreating it as a multi-class classification problem. We created a taxonomy ofsix speech acts for Twitter and proposed a set of semantic and syntacticfeatures. We trained and tested a logistic regression classifier using a dataset of manually labelled tweets. Our method achieved a state-of-the-artperformance with an average F1 score of more than $0.70$. We also exploredclassifiers with three different granularities (Twitter-wide, type-specific andtopic-specific) in order to find the right balance between generalization andoverfitting for our task.
arxiv-18300-184 | Automatic Detection and Categorization of Election-Related Tweets | http://arxiv.org/pdf/1605.05150v1.pdf | author:Prashanth Vijayaraghavan, Soroush Vosoughi, Deb Roy category:cs.CL cs.IT cs.SI math.IT published:2016-05-17 summary:With the rise in popularity of public social media and micro-bloggingservices, most notably Twitter, the people have found a venue to hear and beheard by their peers without an intermediary. As a consequence, and aided bythe public nature of Twitter, political scientists now potentially have themeans to analyse and understand the narratives that organically form, spreadand decline among the public in a political campaign. However, the volume anddiversity of the conversation on Twitter, combined with its noisy andidiosyncratic nature, make this a hard task. Thus, advanced data mining andlanguage processing techniques are required to process and analyse the data. Inthis paper, we present and evaluate a technical framework, based on recentadvances in deep neural networks, for identifying and analysingelection-related conversation on Twitter on a continuous, longitudinal basis.Our models can detect election-related tweets with an F-score of 0.92 and cancategorize these tweets into 22 topics with an F-score of 0.90.
arxiv-18300-185 | Automatic Classification of Irregularly Sampled Time Series with Unequal Lengths: A Case Study on Estimated Glomerular Filtration Rate | http://arxiv.org/pdf/1605.05142v1.pdf | author:Santosh Tirunagari, Simon Bull, Norman Poh category:cs.LG cs.CE published:2016-05-17 summary:A patient's estimated glomerular filtration rate (eGFR) can provide importantinformation about disease progression and kidney function. Traditionally, aneGFR time series is interpreted by a human expert labelling it as stable orunstable. While this approach works for individual patients, the time consumingnature of it precludes the quick evaluation of risk in large numbers ofpatients. However, automating this process poses significant challenges as eGFRmeasurements are usually recorded at irregular intervals and the series ofmeasurements differs in length between patients. Here we present a two-tiersystem to automatically classify an eGFR trend. First, we model the time seriesusing Gaussian process regression (GPR) to fill in `gaps' by resampling a fixedsize vector of fifty time-dependent observations. Second, we classify theresampled eGFR time series using a K-NN/SVM classifier, and evaluate itsperformance via 5-fold cross validation. Using this approach we achieved anF-score of 0.90, compared to 0.96 for 5 human experts when scored amongstthemselves.
arxiv-18300-186 | A Semi-automatic Method for Efficient Detection of Stories on Social Media | http://arxiv.org/pdf/1605.05134v1.pdf | author:Soroush Vosoughi, Deb Roy category:cs.SI cs.CL cs.IR published:2016-05-17 summary:Twitter has become one of the main sources of news for many people. Asreal-world events and emergencies unfold, Twitter is abuzz with hundreds ofthousands of stories about the events. Some of these stories are harmless,while others could potentially be life-saving or sources of malicious rumors.Thus, it is critically important to be able to efficiently track stories thatspread on Twitter during these events. In this paper, we present a novelsemi-automatic tool that enables users to efficiently identify and trackstories about real-world events on Twitter. We ran a user study with 25participants, demonstrating that compared to more conventional methods, ourtool can increase the speed and the accuracy with which users can track storiesabout real-world events.
arxiv-18300-187 | Incorporating Loose-Structured Knowledge into LSTM with Recall Gate for Conversation Modeling | http://arxiv.org/pdf/1605.05110v1.pdf | author:Zhen Xu, Bingquan Liu, Baoxun Wang, Chengjie Sun, Xiaolong Wang category:cs.CL published:2016-05-17 summary:Modeling human conversations is the essence for building satisfying chat-botswith multi-turn dialog ability. Conversation modeling will notably benefit fromdomain knowledge since the relationships between sentences can be clarified dueto semantic hints introduced by knowledge. In this paper, a deep neural networkis proposed to incorporate background knowledge for conversation modeling.Through a specially designed Recall gate, domain knowledge can be transformedinto the extra global memory of Long Short-Term Memory (LSTM), so as to enhanceLSTM by cooperating with its local memory to capture the implicit semanticrelevance between sentences within conversations. In addition, this paperintroduces the loose structured domain knowledge base, which can be built withslight amount of manual work and easily adopted by the Recall gate. Our modelis evaluated on the context-oriented response selecting task, and experimentalresults on both two datasets have shown that our approach is promising formodeling human conversations and building key components of automatic chattingsystems.
arxiv-18300-188 | Detecting Violent Crowds using Temporal Analysis of GLCM Texture | http://arxiv.org/pdf/1605.05106v1.pdf | author:Kaelon Lloyd, David Marshall, Simon C. Moore, Paul L. Rosin category:cs.CV published:2016-05-17 summary:The severity of sustained injury resulting from assault-related violence canbe minimized by reducing detection time. However, it has been shown that humanoperators perform poorly at detecting events found in video footage whenpresented with simultaneous feeds. We utilize computer vision techniques todevelop an automated method of violence detection that can aid a humanoperator. We observed that violence in city centre environments often occur incrowded areas, resulting in individual actions being occluded by other crowdmembers. Measures of visual texture have shown to be effective at encodingcrowd appearance. Therefore, we propose modelling crowd dynamics using changesin crowd texture. We refer to this approach as Violent Crowd Texture (VCT).Real-world surveillance footage of night time environments and the violentflows dataset were tested using a random forest classifier to evaluate theability of the VCT method at discriminating between violent and non-violentbehaviour. Our method achieves ROC values of 0.98 and 0.91 on our own realworld CCTV dataset and the violent flows dataset respectively.
arxiv-18300-189 | Recurrent Neural Network for Text Classification with Multi-Task Learning | http://arxiv.org/pdf/1605.05101v1.pdf | author:Pengfei Liu, Xipeng Qiu, Xuanjing Huang category:cs.CL published:2016-05-17 summary:Neural network based methods have obtained great progress on a variety ofnatural language processing tasks. However, in most previous works, the modelsare learned based on single-task supervised objectives, which often suffer frominsufficient training data. In this paper, we use the multi-task learningframework to jointly learn across multiple related tasks. Based on recurrentneural network, we propose three different mechanisms of sharing information tomodel text with task-specific and shared layers. The entire network is trainedjointly on all these tasks. Experiments on four benchmark text classificationtasks show that our proposed models can improve the performance of a task withthe help of other related tasks.
arxiv-18300-190 | Word2Vec is only a special case of Kernel Correspondence Analysis and Kernels for Natural Language Processing | http://arxiv.org/pdf/1605.05087v1.pdf | author:Hirotaka Niitsuma category:cs.LG cs.CL published:2016-05-17 summary:We show Correspondence Analysis (CA) is equivalent to defining Gini-indexwith appropriate scaled one-hot encoding. Using this relation, we introducenon-linear kernel extension of CA. The extended CA gives well-known analysisfor categorical data (CD) and natural language processing by specializingkernels. For example, our formulation can give G-test, skip-gram withnegative-sampling (SGNS), and GloVe as a special case. We introduce two kernelsfor natural language processing based on our formulation. First is a stopword(SW) kernel. Second is word similarity(WS) kernel. The SW kernel is thesystem introducing appropriate weights for SW. The WS kernel enables to use WStest data as training data for vector space representations of words. We showthese kernels enhances accuracy when training data is not sufficiently large.
arxiv-18300-191 | HARRISON: A Benchmark on HAshtag Recommendation for Real-world Images in Social Networks | http://arxiv.org/pdf/1605.05054v1.pdf | author:Minseok Park, Hanxiang Li, Junmo Kim category:cs.CV cs.IR cs.SI published:2016-05-17 summary:Simple, short, and compact hashtags cover a wide range of information onsocial networks. Although many works in the field of natural languageprocessing (NLP) have demonstrated the importance of hashtag recommendation,hashtag recommendation for images has barely been studied. In this paper, weintroduce the HARRISON dataset, a benchmark on hashtag recommendation for realworld images in social networks. The HARRISON dataset is a realistic dataset,composed of 57,383 photos from Instagram and an average of 4.5 associatedhashtags for each photo. To evaluate our dataset, we design a baselineframework consisting of visual feature extractor based on convolutional neuralnetwork (CNN) and multi-label classifier based on neural network. Based on thisframework, two single feature-based models, object-based and scene-based model,and an integrated model of them are evaluated on the HARRISON dataset. Ourdataset shows that hashtag recommendation task requires a wide and contextualunderstanding of the situation conveyed in the image. As far as we know, thiswork is the first vision-only attempt at hashtag recommendation for real worldimages in social networks. We expect this benchmark to accelerate theadvancement of hashtag recommendation.
arxiv-18300-192 | DehazeNet: An End-to-End System for Single Image Haze Removal | http://arxiv.org/pdf/1601.07661v2.pdf | author:Bolun Cai, Xiangmin Xu, Kui Jia, Chunmei Qing, Dacheng Tao category:cs.CV published:2016-01-28 summary:Single image haze removal is a challenging ill-posed problem. Existingmethods use various constraints/priors to get plausible dehazing solutions. Thekey to achieve haze removal is to estimate a medium transmission map for aninput hazy image. In this paper, we propose a trainable end-to-end systemcalled DehazeNet, for medium transmission estimation. DehazeNet takes a hazyimage as input, and outputs its medium transmission map that is subsequentlyused to recover a haze-free image via atmospheric scattering model. DehazeNetadopts Convolutional Neural Networks (CNN) based deep architecture, whoselayers are specially designed to embody the established assumptions/priors inimage dehazing. Specifically, layers of Maxout units are used for featureextraction, which can generate almost all haze-relevant features. We alsopropose a novel nonlinear activation function in DehazeNet, called BilateralRectified Linear Unit (BReLU), which is able to improve the quality ofrecovered haze-free image. We establish connections between components of theproposed DehazeNet and those used in existing methods. Experiments on benchmarkimages show that DehazeNet achieves superior performance over existing methods,yet keeps efficient and easy to use.
arxiv-18300-193 | Incremental Object Recognition in Robotics with Extension to New Classes in Constant Time | http://arxiv.org/pdf/1605.05045v1.pdf | author:Raffaello Camoriano, Giulia Pasquale, Carlo Ciliberto, Lorenzo Natale, Lorenzo Rosasco, Giorgio Metta category:stat.ML cs.CV cs.LG cs.RO published:2016-05-17 summary:We consider object recognition in the context of lifelong learning, where arobotic agent learns to discriminate between a growing number of object classesas it accumulates experience about the environment. We propose an incrementalvariant of the Regularized Least Squares for Classification (RLSC) algorithm,and exploit its structure to seamlessly add new classes to the learned model.The presented algorithm addresses the problem of having unbalanced proportionof training examples per class, which occurs when new objects are presented tothe system for the first time. We evaluate our algorithm on both a machinelearning benchmark dataset and a challenging object recognition task in arobotic setting. Empirical evidence on both problems shows that our approach issignificantly faster than its batch counterparts while achieving comparable orbetter classification performance when classes are unbalanced.
arxiv-18300-194 | LIME: A Method for Low-light IMage Enhancement | http://arxiv.org/pdf/1605.05034v1.pdf | author:Xiaojie Guo category:cs.CV published:2016-05-17 summary:When one captures images in low-light conditions, the images often sufferfrom low visibility. This poor quality may significantly degrade theperformance of many computer vision and multimedia algorithms that areprimarily designed for high-quality inputs. In this paper, we propose a verysimple and effective method, named as LIME, to enhance low-light images. Moreconcretely, the illumination of each pixel is first estimated individually byfinding the maximum value in R, G and B channels (Max-RGB). Further, we refinethe initial illumination map by imposing a structure prior on it, as the finalillumination map. Having the well-constructed illumination map, the enhancementcan be achieved accordingly. Experiments on a number of challenging real-worldlow-light images are present to reveal the efficacy of our LIME and show itssuperiority over several state-of-the-arts.
arxiv-18300-195 | Image stitching with perspective-preserving warping | http://arxiv.org/pdf/1605.05019v1.pdf | author:Tianzhu Xiang, Gui-Song Xia, Liangpei Zhang category:cs.CV published:2016-05-17 summary:Image stitching algorithms often adopt the global transformation, such ashomography, and work well for planar scenes or parallax free camera motions.However, these conditions are easily violated in practice. With casual cameramotions, variable taken views, large depth change, or complex structures, it isa challenging task for stitching these images. The global transformation modeloften provides dreadful stitching results, such as misalignments or projectivedistortions, especially perspective distortion. To this end, we suggest aperspective-preserving warping for image stitching, which spatially combineslocal projective transformations and similarity transformation. By weightedcombination scheme, our approach gradually extrapolates the local projectivetransformations of the overlapping regions into the non-overlapping regions,and thus the final warping can smoothly change from projective to similarity.The proposed method can provide satisfactory alignment accuracy as well asreduce the projective distortions and maintain the multi-perspective view.Experiments on a variety of challenging images confirm the efficiency of theapproach.
arxiv-18300-196 | Relation Schema Induction using Tensor Factorization with Side Information | http://arxiv.org/pdf/1605.04227v2.pdf | author:Madhav Nimishakavi, Uday Singh Saini, Partha Talukdar category:cs.IR cs.CL cs.DB published:2016-05-12 summary:Given a set of documents from a specific domain (e.g., medical researchjournals), how do we automatically identify the schema of relations i.e., typesignature of arguments of relations (e.g., undergo (Patient, Surgery)) - anecessary first step towards building a Knowledge Graph (KG) out of the givenset of documents? We refer to this problem as Relation Schema Induction (RSI).While Open Information Extraction (OIE) techniques aim at extracting surfacelevel triples of the form (John, underwent, Angioplasty), they don't induce theyet unknown schema of relations themselves. Tensors provide a naturalrepresentation for such triples, and factorization of such tensors provide aplausible solution for the RSI problem. To the best of our knowledge, tensorfactorization methods have not been used for the RSI problem. We fill this gapand propose Coupled Non-negative Tensor Factorization (CNTF), a tensorfactorization method which is able to incorporate additional side informationin a principled way for more effective Relation Schema Induction. We report ourfindings on multiple real-world datasets and demonstrate CNTF's effectivenessover state-of-the-art baselines both in terms of accuracy and speed.
arxiv-18300-197 | FRIST - Flipping and Rotation Invariant Sparsifying Transform Learning and Applications to Inverse Problems | http://arxiv.org/pdf/1511.06359v3.pdf | author:Bihan Wen, Saiprasad Ravishankar, Yoram Bresler category:cs.LG cs.CV published:2015-11-19 summary:Features based on sparse representation, especially using the synthesisdictionary model, have been heavily exploited in signal processing and computervision. However, synthesis dictionary learning typically involves NP-hardsparse coding and expensive learning steps. Recently, sparsifying transformlearning received interest for its cheap computation and its optimal updates inthe alternating algorithms. In this work, we develop a methodology for learningof Flipping and Rotation Invariant Sparsifying Transforms, dubbed FRIST, tobetter represent natural images that contain textures with various geometricaldirections. The proposed alternating learning algorithm involves efficientoptimal updates. We provide a convergence guarantee, and demonstrate theempirical convergence behavior of the proposed FRIST learning algorithm.Preliminary experiments show the usefulness of adaptive sparse representationby FRIST for image sparse representation, segmentation, denoising, robustinpainting, and MRI reconstruction with promising performances.
arxiv-18300-198 | Locally Weighted Ensemble Clustering | http://arxiv.org/pdf/1605.05011v1.pdf | author:Dong Huang, Chang-Dong Wang, Jian-Huang Lai category:cs.LG published:2016-05-17 summary:Due to its ability to combine multiple base clusterings into a probablybetter and more robust clustering, the ensemble clustering technique has beenattracting increasing attention in recent years. Despite the significantsuccess, one limitation to most of the existing ensemble clustering methods isthat they generally treat all base clusterings equally regardless of theirreliability, which makes them vulnerable to low-quality base clusterings.Although some efforts have been made to (globally) evaluate and weight the baseclusterings, yet these methods tend to view each base clustering as anindividual and neglect the local diversity of clusters inside the same baseclustering. It remains an open problem how to evaluate the reliability ofclusters and exploit the local diversity in the ensemble to enhance theconsensus performance, without access to data features or specific assumptionson data distribution. To address this, in this paper, we propose a novelensemble clustering approach based on ensemble-driven cluster uncertaintyestimation and local weighting strategy. In particular, the uncertainty of eachcluster is estimated by considering the cluster labels in the entire ensemblevia an entropic criterion. A novel ensemble-driven cluster validity measure isintroduced, and a locally weighted co-association matrix is presented to serveas a summary for the ensemble of diverse clusters. With the local diversity inensembles exploited, two novel consensus functions are further proposed.Extensive experiments on a variety of real-world datasets demonstrate thesuperiority of the proposed approach over the state-of-the-art.
arxiv-18300-199 | Adversarial Diversity and Hard Positive Generation | http://arxiv.org/pdf/1605.01775v2.pdf | author:Andras Rozsa, Ethan M. Rudd, Terrance E. Boult category:cs.CV published:2016-05-05 summary:State-of-the-art deep neural networks suffer from a fundamental problem -they misclassify adversarial examples formed by applying small perturbations toinputs. In this paper, we present a new psychometric perceptual adversarialsimilarity score (PASS) measure for quantifying adversarial images, introducethe notion of hard positive generation, and use a diverse set of adversarialperturbations - not just the closest ones - for data augmentation. We introducea novel hot/cold approach for adversarial example generation, which providesmultiple possible adversarial perturbations for every single image. Theperturbations generated by our novel approach often correspond to semanticallymeaningful image structures, and allow greater flexibility to scaleperturbation-amplitudes, which yields an increased diversity of adversarialimages. We present adversarial images on several network topologies anddatasets, including LeNet on the MNIST dataset, and GoogLeNet and ResidualNeton the ImageNet dataset. Finally, we demonstrate on LeNet and GoogLeNet thatfine-tuning with a diverse set of hard positives improves the robustness ofthese networks compared to training with prior methods of generatingadversarial images.
arxiv-18300-200 | SemiContour: A Semi-supervised Learning Approach for Contour Detection | http://arxiv.org/pdf/1605.04996v1.pdf | author:Zizhao Zhang, Fuyong Xing, Xiaoshuang Shi, Lin Yang category:cs.CV published:2016-05-17 summary:Supervised contour detection methods usually require many labeled trainingimages to obtain satisfactory performance. However, a large set of annotateddata might be unavailable or extremely labor intensive. In this paper, weinvestigate the usage of semi-supervised learning (SSL) to obtain competitivedetection accuracy with very limited training data (three labeled images).Specifically, we propose a semi-supervised structured ensemble learningapproach for contour detection built on structured random forests (SRF). Toallow SRF to be applicable to unlabeled data, we present an effective sparserepresentation approach to capture inherent structure in image patches byfinding a compact and discriminative low-dimensional subspace representation inan unsupervised manner, enabling the incorporation of abundant unlabeledpatches with their estimated structured labels to help SRF perform better nodesplitting. We re-examine the role of sparsity and propose a novel and fastsparse coding algorithm to boost the overall learning efficiency. To the bestof our knowledge, this is the first attempt to apply SSL for contour detection.Extensive experiments on the BSDS500 segmentation dataset and the NYU Depthdataset demonstrate the superiority of the proposed method.
arxiv-18300-201 | Going Deeper into Action Recognition: A Survey | http://arxiv.org/pdf/1605.04988v1.pdf | author:Samitha Herath, Mehrtash Harandi, Fatih Porikli category:cs.CV published:2016-05-16 summary:We provide a detailed review of the work on human action recognition over thepast decade. We refer to "actions" as meaningful human motions. Starting withmethods that are based on handcrafted representations, we review the impact ofrevamped deep neural networks on action recognition. We follow a systematictaxonomy of action recognition approaches to present a coherent discussion overtheir improvements and fall-backs.
arxiv-18300-202 | A Constant-Factor Bi-Criteria Approximation Guarantee for $k$-means++ | http://arxiv.org/pdf/1605.04986v1.pdf | author:Dennis Wei category:cs.LG cs.CG I.5.3; G.1.6 published:2016-05-16 summary:This paper studies the $k$-means++ algorithm for clustering as well as theclass of $D^\ell$ sampling algorithms to which $k$-means++ belongs. It is shownthat for any constant factor $\beta > 1$, selecting $\beta k$ cluster centersby $D^\ell$ sampling yields a constant-factor approximation to the optimalclustering with $k$ centers, in expectation and without conditions on thedataset. This result extends the previously known $O(\log k)$ guarantee for thecase $\beta = 1$ to the constant-factor bi-criteria regime. It also improvesupon an existing constant-factor bi-criteria result that holds only withconstant probability.
arxiv-18300-203 | Convex Optimization for Linear Query Processing under Approximate Differential Privacy | http://arxiv.org/pdf/1602.04302v3.pdf | author:Ganzhao Yuan, Yin Yang, Zhenjie Zhang, Zhifeng Hao category:cs.DB cs.LG stat.ML published:2016-02-13 summary:Differential privacy enables organizations to collect accurate aggregatesover sensitive data with strong, rigorous guarantees on individuals' privacy.Previous work has found that under differential privacy, computing multiplecorrelated aggregates as a batch, using an appropriate \emph{strategy}, mayyield higher accuracy than computing each of them independently. However,finding the best strategy that maximizes result accuracy is non-trivial, as itinvolves solving a complex constrained optimization program that appears to benon-linear and non-convex. Hence, in the past much effort has been devoted insolving this non-convex optimization program. Existing approaches includevarious sophisticated heuristics and expensive numerical solutions. None ofthem, however, guarantees to find the optimal solution of this optimizationproblem. This paper points out that under ($\epsilon$, $\delta$)-differential privacy,the optimal solution of the above constrained optimization problem in search ofa suitable strategy can be found, rather surprisingly, by solving a simple andelegant convex optimization program. Then, we propose an efficient algorithmbased on Newton's method, which we prove to always converge to the optimalsolution with linear global convergence rate and quadratic local convergencerate. Empirical evaluations demonstrate the accuracy and efficiency of theproposed solution.
arxiv-18300-204 | Probing the Geometry of Data with Diffusion Fr√©chet Functions | http://arxiv.org/pdf/1605.04955v1.pdf | author:Diego Hern√°n D√≠az Mart√≠nez, Christine H. Lee, Peter T. Kim, Washington Mio category:stat.ML 62-07, 92C50 published:2016-05-16 summary:Many complex ecosystems, such as those formed by multiple microbial taxa,involve intricate interactions amongst various sub-communities. The most basicrelationships are frequently modeled as co-occurrence networks in which thenodes represent the various players in the community and the weighted edgesencode levels of interaction. In this setting, the composition of a communitymay be viewed as a probability distribution on the nodes of the network. Thispaper develops methods for modeling the organization of such data, as well astheir Euclidean counterparts, across spatial scales. Using the notion ofdiffusion distance, we introduce diffusion Fr\'echet functions and diffusionFr\'echet vectors associated with probability distributions on Euclidean spacesand the vertex set of a weighted network, respectively. We prove that thesefunctional statistics are stable with respect to the Wasserstein distancebetween probability measures, thus yielding robust descriptors of their shapes.We apply the methodology to investigate bacterial communities in the human gut,seeking to characterize divergence from intestinal homeostasis in patients withClostridium difficile infection (CDI) and the effects of fecal microbiotatransplantation, a treatment used in CDI patients that has proven to besignificantly more effective than traditional treatment with antibiotics. Theproposed method proves useful in deriving a biomarker that might help elucidatethe mechanisms that drive these processes.
arxiv-18300-205 | Viziometrics: Analyzing Visual Information in the Scientific Literature | http://arxiv.org/pdf/1605.04951v1.pdf | author:Po-shen Lee, Jevin D. West, Bill Howe category:cs.SI cs.CV cs.DL cs.IR published:2016-05-16 summary:Scientific results are communicated visually in the literature throughdiagrams, visualizations, and photographs. These information-dense objects havebeen largely ignored in bibliometrics and scientometrics studies when comparedto citations and text. In this paper, we use techniques from computer visionand machine learning to classify more than 8 million figures from PubMed into 5figure types and study the resulting patterns of visual information as theyrelate to impact. We find that the distribution of figures and figure types inthe literature has remained relatively constant over time, but can vary widelyacross field and topic. Remarkably, we find a significant correlation betweenscientific impact and the use of visual information, where higher impact paperstend to include more diagrams, and to a lesser extent more plots andphotographs. To explore these results and other ways of extracting this visualinformation, we have built a visual browser to illustrate the concept andexplore design alternatives for supporting viziometric analysis and organizingvisual information. We use these results to articulate a new research agenda --viziometrics -- to study the organization and presentation of visualinformation in the scientific literature.
arxiv-18300-206 | Classification of Big Data with Application to Imaging Genetics | http://arxiv.org/pdf/1605.04932v1.pdf | author:Magnus O. Ulfarsson, Frosti Palsson, Jakob Sigurdsson, Johannes R. Sveinsson category:cs.CV stat.ML published:2016-05-16 summary:Big data applications, such as medical imaging and genetics, typicallygenerate datasets that consist of few observations n on many more variables p,a scenario that we denote as p>>n. Traditional data processing methods areoften insufficient for extracting information out of big data. This calls forthe development of new algorithms that can deal with the size, complexity, andthe special structure of such datasets. In this paper, we consider the problemof classifying p>>n data and propose a classification method based on lineardiscriminant analysis (LDA). Traditional LDA depends on the covariance estimateof the data, but when p>>n the sample covariance estimate is singular. Theproposed method estimates the covariance by using a sparse version of noisyprincipal component analysis (nPCA). The use of sparsity in this setting aimsat automatically selecting variables that are relevant for classification. Inexperiments, the new method is compared to state-of-the art methods for bigdata problems using both simulated datasets and imaging genetics datasets.
arxiv-18300-207 | Large Scale Distributed Semi-Supervised Learning Using Streaming Approximation | http://arxiv.org/pdf/1512.01752v2.pdf | author:Sujith Ravi, Qiming Diao category:cs.LG cs.AI published:2015-12-06 summary:Traditional graph-based semi-supervised learning (SSL) approaches, eventhough widely applied, are not suited for massive data and large labelscenarios since they scale linearly with the number of edges $E$ and distinctlabels $m$. To deal with the large label size problem, recent works proposesketch-based methods to approximate the distribution on labels per node therebyachieving a space reduction from $O(m)$ to $O(\log m)$, under certainconditions. In this paper, we present a novel streaming graph-based SSLapproximation that captures the sparsity of the label distribution and ensuresthe algorithm propagates labels accurately, and further reduces the spacecomplexity per node to $O(1)$. We also provide a distributed version of thealgorithm that scales well to large data sizes. Experiments on real-worlddatasets demonstrate that the new method achieves better performance thanexisting state-of-the-art algorithms with significant reduction in memoryfootprint. We also study different graph construction mechanisms for naturallanguage applications and propose a robust graph augmentation strategy trainedusing state-of-the-art unsupervised deep learning architectures that yieldsfurther significant quality gains.
arxiv-18300-208 | Data-driven Sequential Monte Carlo in Probabilistic Programming | http://arxiv.org/pdf/1512.04387v2.pdf | author:Yura N Perov, Tuan Anh Le, Frank Wood category:cs.AI stat.AP stat.ML published:2015-12-14 summary:Most of Markov Chain Monte Carlo (MCMC) and sequential Monte Carlo (SMC)algorithms in existing probabilistic programming systems suboptimally use onlymodel priors as proposal distributions. In this work, we describe an approachfor training a discriminative model, namely a neural network, in order toapproximate the optimal proposal by using posterior estimates from previousruns of inference. We show an example that incorporates a data-driven proposalfor use in a non-parametric model in the Anglican probabilistic programmingsystem. Our results show that data-driven proposals can significantly improveinference performance so that considerably fewer particles are necessary toperform a good posterior estimation.
arxiv-18300-209 | On Distributed Cooperative Decision-Making in Multiarmed Bandits | http://arxiv.org/pdf/1512.06888v2.pdf | author:Peter Landgren, Vaibhav Srivastava, Naomi Ehrich Leonard category:cs.SY cs.MA math.OC stat.ML published:2015-12-21 summary:We study the explore-exploit tradeoff in distributed cooperativedecision-making using the context of the multiarmed bandit (MAB) problem. Forthe distributed cooperative MAB problem, we design the cooperative UCBalgorithm that comprises two interleaved distributed processes: (i) runningconsensus algorithms for estimation of rewards, and (ii)upper-confidence-bound-based heuristics for selection of arms. We rigorouslyanalyze the performance of the cooperative UCB algorithm and characterize theinfluence of communication graph structure on the decision-making performanceof the group.
arxiv-18300-210 | Reducing the Model Order of Deep Neural Networks Using Information Theory | http://arxiv.org/pdf/1605.04859v1.pdf | author:Ming Tu, Visar Berisha, Yu Cao, Jae-sun Seo category:cs.LG cs.NE published:2016-05-16 summary:Deep neural networks are typically represented by a much larger number ofparameters than shallow models, making them prohibitive for small footprintdevices. Recent research shows that there is considerable redundancy in theparameter space of deep neural networks. In this paper, we propose a method tocompress deep neural networks by using the Fisher Information metric, which weestimate through a stochastic optimization method that keeps track ofsecond-order information in the network. We first remove unimportant parametersand then use non-uniform fixed point quantization to assign more bits toparameters with higher Fisher Information estimates. We evaluate our method ona classification task with a convolutional neural network trained on the MNISTdata set. Experimental results show that our method outperforms existingmethods for both network pruning and quantization.
arxiv-18300-211 | Video2GIF: Automatic Generation of Animated GIFs from Video | http://arxiv.org/pdf/1605.04850v1.pdf | author:Michael Gygli, Yale Song, Liangliang Cao category:cs.CV cs.MM published:2016-05-16 summary:We introduce the novel problem of automatically generating animated GIFs fromvideo. GIFs are short looping video with no sound, and a perfect combinationbetween image and video that really capture our attention. GIFs tell a story,express emotion, turn events into humorous moments, and are the new wave ofphotojournalism. We pose the question: Can we automate the entirely manual andelaborate process of GIF creation by leveraging the plethora of user generatedGIF content? We propose a Robust Deep RankNet that, given a video, generates aranked list of its segments according to their suitability as GIF. We train ourmodel to learn what visual content is often selected for GIFs by using over100K user generated GIFs and their corresponding video sources. We effectivelydeal with the noisy web data by proposing a novel adaptive Huber loss in theranking formulation. We show that our approach is robust to outliers and picksup several patterns that are frequently present in popular animated GIFs. Onour new large-scale benchmark dataset, we show the advantage of our approachover several state-of-the-art methods.
arxiv-18300-212 | Antisocial Behavior in Online Discussion Communities | http://arxiv.org/pdf/1504.00680v2.pdf | author:Justin Cheng, Cristian Danescu-Niculescu-Mizil, Jure Leskovec category:cs.SI cs.CY stat.AP stat.ML published:2015-04-02 summary:User contributions in the form of posts, comments, and votes are essential tothe success of online communities. However, allowing user participation alsoinvites undesirable behavior such as trolling. In this paper, we characterizeantisocial behavior in three large online discussion communities by analyzingusers who were banned from these communities. We find that such users tend toconcentrate their efforts in a small number of threads, are more likely to postirrelevantly, and are more successful at garnering responses from other users.Studying the evolution of these users from the moment they join a community upto when they get banned, we find that not only do they write worse than otherusers over time, but they also become increasingly less tolerated by thecommunity. Further, we discover that antisocial behavior is exacerbated whencommunity feedback is overly harsh. Our analysis also reveals distinct groupsof users with different levels of antisocial behavior that can change overtime. We use these insights to identify antisocial users early on, a task ofhigh practical importance to community maintainers.
arxiv-18300-213 | Compressing Word Embeddings | http://arxiv.org/pdf/1511.06397v2.pdf | author:Martin Andrews category:cs.CL cs.LG published:2015-11-19 summary:Recent methods for learning vector space representations of words havesucceeded in capturing fine-grained semantic and syntactic regularities usingvector arithmetic. However, these vector space representations (created throughlarge-scale text analysis) are typically stored verbatim, since their internalstructure is opaque. Using word-analogy tests to monitor the level of detailstored in compressed re-representations of the same vector space, thetrade-offs between the reduction in memory usage and expressiveness areinvestigated. A simple scheme is outlined that can reduce the memory footprintof a state-of-the-art embedding by a factor of 10, with only minimal impact onperformance. Then, using the same `bit budget', a binary (approximate)factorisation of the same space is also explored, with the aim of creating anequivalent representation with better interpretability.
arxiv-18300-214 | Off-policy evaluation for slate recommendation | http://arxiv.org/pdf/1605.04812v1.pdf | author:Adith Swaminathan, Akshay Krishnamurthy, Alekh Agarwal, Miroslav Dud√≠k, John Langford, Damien Jose, Imed Zitouni category:cs.LG cs.AI stat.ML published:2016-05-16 summary:This paper studies the evaluation of policies which recommend an ordered setof items based on some context---a common scenario in web search, ads, andrecommender systems. We develop a novel technique to evaluate such policiesoffline using logged past data with negligible bias. Our method builds on theassumption that the observed quality of the entire recommended set additivelydecomposes across items, but per-item quality is not directly observable, andwe might not be able to model it from the item's features. Empirical evidencereveals that this assumption fits many realistic scenarios and theoreticalanalysis shows that we can achieve exponential savings in the amount ofrequired data compared with na\"ive unbiased approaches.
arxiv-18300-215 | Multilevel Thresholding Segmentation of T2 weighted Brain MRI images using Convergent Heterogeneous Particle Swarm Optimization | http://arxiv.org/pdf/1605.04806v1.pdf | author:Mohammad Hamed Mozaffari, Won-Sook Lee category:cs.CV published:2016-05-16 summary:This paper proposes a new image thresholding segmentation approach using theheuristic method, Convergent Heterogeneous Particle Swarm Optimizationalgorithm. The proposed algorithm incorporates a new strategy of searching theproblem space by dividing the swarm into subswarms. Each subswarm particlessearch for better solution separately lead to better exploitation while theycooperate with each other to find the best global position. The consequence ofthe aforementioned cooperation is better exploration, convergence and it ablethe algorithm to jump from local optimal solution to the better spots. Apractical application of this method is demonstrated for the problem of medicalimage thresholding segmentation. We considered two classical thresholdingtechniques of Otsu and Kapur separately as the objective function for theoptimization method and applied on a set of brain MR images. Comparativeexperimental results reveal that the proposed method outperforms another stateof the art method from the literature in terms of accuracy, computation timeand stable results.
arxiv-18300-216 | Detecting Relative Anomaly | http://arxiv.org/pdf/1605.03805v2.pdf | author:Richard Neuberg, Yixin Shi category:stat.ML cs.LG published:2016-05-12 summary:System states that are anomalous from the perspective of a domain expertoccur frequently in some anomaly detection problems. The performance ofcommonly used unsupervised anomaly detection methods may suffer in thatsetting, because they use frequency as a proxy for anomaly. We propose a novelconcept for anomaly detection, called relative anomaly detection. It istailored to be robust towards anomalies that occur frequently, by taking intoaccount their location relative to the most typical observations. Theapproaches we develop are computationally feasible even for large data sets,and they allow real-time detection. We illustrate using data sets of potentialscraping attempts and Wi-Fi channel utilization, both from Google, Inc.
arxiv-18300-217 | Log-linear Combinations of Monolingual and Bilingual Neural Machine Translation Models for Automatic Post-Editing | http://arxiv.org/pdf/1605.04800v1.pdf | author:Marcin Junczys-Dowmunt, Roman Grundkiewicz category:cs.CL published:2016-05-16 summary:This paper describes the submission of the AMU (Adam Mickiewicz University)team to the Automatic Post-Editing (APE) task of WMT 2016. We explore theapplication of neural translation models to the APE problem and achieve goodresults by treating different models as components in a log-linear model,allowing for multiple inputs (the MT-output and the source) that are decoded tothe same target language (post-edited translations). A simple string-matchingpenalty integrated within the log-linear model can be used to control forhigher faithfulness with regard to the to-be-corrected machine translationinput. Our submission outperforms the uncorrected baseline on the unseen testset by -3.2% TER and +5.5% BLEU.
arxiv-18300-218 | An Alternative Matting Laplacian | http://arxiv.org/pdf/1605.04785v1.pdf | author:Fran√ßois Piti√© category:cs.CV published:2016-05-16 summary:Cutting out and object and estimate its transparency mask is a key task inmany applications. We take on the work on closed-form matting by Levin et al.,that is used at the core of many matting techniques, and propose an alternativeformulation that offers more flexible controls over the matting priors. We alsoshow that this new approach is efficient at upscaling transparency maps fromcoarse estimates.
arxiv-18300-219 | Con-Patch: When a Patch Meets its Context | http://arxiv.org/pdf/1603.06812v2.pdf | author:Yaniv Romano, Michael Elad category:cs.CV published:2016-03-22 summary:Measuring the similarity between patches in images is a fundamental buildingblock in various tasks. Naturally, the patch-size has a major impact on thematching quality, and on the consequent application performance. Under theassumption that our patch database is sufficiently sampled, using large patches(e.g. 21-by-21) should be preferred over small ones (e.g. 7-by-7). However,this "dense-sampling" assumption is rarely true; in most cases large patchescannot find relevant nearby examples. This phenomenon is a consequence of thecurse of dimensionality, stating that the database-size should growexponentially with the patch-size to ensure proper matches. This explains thefavored choice of small patch-size in most applications. Is there a way to keep the simplicity and work with small patches whilegetting some of the benefits that large patches provide? In this work we offersuch an approach. We propose to concatenate the regular content of aconventional (small) patch with a compact representation of its (large)surroundings - its context. Therefore, with a minor increase of the dimensions(e.g. with additional 10 values to the patch representation), weimplicitly/softly describe the information of a large patch. The additionaldescriptors are computed based on a self-similarity behavior of the patchsurrounding. We show that this approach achieves better matches, compared to the use ofconventional-size patches, without the need to increase the database-size.Also, the effectiveness of the proposed method is tested on three distinctproblems: (i) External natural image denoising, (ii) Depth imagesuper-resolution, and (iii) Motion-compensated frame-rate up-conversion.
arxiv-18300-220 | A Review of Co-saliency Detection Technique: Fundamentals, Applications, and Challenges | http://arxiv.org/pdf/1604.07090v2.pdf | author:Dingwen Zhang, Huazhu Fu, Junwei Han, Feng Wu category:cs.CV published:2016-04-24 summary:Co-saliency detection is a newly emerging and rapidly growing research areain computer vision community. As a novel branch of visual saliency, co-saliencydetection refers to discovery of the common and salient foregrounds existed intwo or more relevant images, and can be more widely used in many computervision tasks. The existing co-saliency detection algorithms mainly consist ofthree components: extracting effective features to represent the image regions,exploring the informative cues or factors to characterize co-saliency, anddesigning effective computational framework to formulate co-saliency. Althoughenormous methods have been developed, a deep review of the literaturesconcerning about the co-saliency detection technique is still lacking. In thispaper, we aim to provide a comprehensive review of the fundamentals,challenges, and applications in co-saliency detection area. Specifically, thispaper provides the overview of some related computer vision works, reviews thehistory of co-saliency detection briefly, summarizes and categorizes the majoralgorithms in this research area, presents the potential applications ofco-saliency detection, discusses some open issues in this research area, andfinally points out some unsolved challenges and promising future works. It isour hope that this review will be beneficial for both the fresh and seniorresearchers in this field as well as researchers working in other relevantfields to have a better understanding about what they can do with co-saliencydetection in the future.
arxiv-18300-221 | Automatic Image Annotation via Label Transfer in the Semantic Space | http://arxiv.org/pdf/1605.04770v1.pdf | author:Tiberio Uricchio, Lamberto Ballan, Lorenzo Seidenari, Alberto Del Bimbo category:cs.CV cs.IR cs.MM published:2016-05-16 summary:While most automatic image annotation methods rely solely on visual features,we consider integrating additional information into an unified embeddingcomprised of visual and textual information. We propose an approach based onKernel Canonical Correlation Analysis, which builds a latent semantic spacewhere correlation of visual and textual features are well preserved into asemantic embedding. Images in the semantic space have reduced semantic gap andthus they are likely to give better annotation performance. The proposedapproach is robust and can work either when the training set is well annotatedby experts, as well as when it is noisy such as in the case of user-generatedtags in social media. We evaluate our framework on four popular datasets. Ourresults show that our KCCA-based approach can be applied to severalstate-of-the-art label transfer methods to obtain significant improvements. Inparticular, nearest neighbor methods for label transfer get the most benefitand enable our approach to scale on never seen labels at training time. Ourapproach works even with the noisy tags of social users, provided thatappropriate denoising is performed. Experiments on a large scale setting showthat our method can provide some benefits even when the semantic space isestimated on a subset of training images.
arxiv-18300-222 | Geometry Aware Mappings for High Dimensional Sparse Factors | http://arxiv.org/pdf/1605.04764v1.pdf | author:Avradeep Bhowmik, Nathan Liu, Erheng Zhong, Badri Narayan Bhaskar, Suju Rajan category:cs.LG cs.IR stat.ML published:2016-05-16 summary:While matrix factorisation models are ubiquitous in large scalerecommendation and search, real time application of such models requires innerproduct computations over an intractably large set of item factors. In thismanuscript we present a novel framework that uses the inverted indexrepresentation to exploit structural properties of sparse vectors tosignificantly reduce the run time computational cost of factorisation models.We develop techniques that use geometry aware permutation maps on a tessellatedunit sphere to obtain high dimensional sparse embeddings for latent factorswith sparsity patterns related to angular closeness of the original latentfactors. We also design several efficient and deterministic realisations withinthis framework and demonstrate with experiments that our techniques lead tofaster run time operation with minimal loss of accuracy.
arxiv-18300-223 | String and Membrane Gaussian Processes | http://arxiv.org/pdf/1507.06977v3.pdf | author:Yves-Laurent Kom Samo, Stephen Roberts category:stat.ML 60G15 published:2015-07-24 summary:In this paper we introduce a novel framework for making exact nonparametricBayesian inference on latent functions, that is particularly suitable for BigData tasks. Firstly, we introduce a class of stochastic processes we refer toas string Gaussian processes (string GPs), which are not to be mistaken forGaussian processes operating on text. We construct string GPs so that theirfinite-dimensional marginals exhibit suitable local conditional independencestructures, which allow for scalable, distributed, and flexible nonparametricBayesian inference, without resorting to approximations, and while ensuringsome mild global regularity constraints. Furthermore, string GP priorsnaturally cope with heterogeneous input data, and the gradient of the learnedlatent function is readily available for explanatory analysis. Secondly, weprovide some theoretical results relating our approach to the standard GPparadigm. In particular, we prove that some string GPs are Gaussian processes,which provides a complementary global perspective on our framework. Finally, wederive a scalable and distributed MCMC scheme for supervised learning tasksunder string GP priors. The proposed MCMC scheme has computational timecomplexity $\mathcal{O}(N)$ and memory requirement $\mathcal{O}(dN)$, where $N$is the data size and $d$ the dimension of the input space. We illustrate theefficacy of the proposed approach on several synthetic and real-world datasets,including a dataset with $6$ millions input points and $8$ attributes.
arxiv-18300-224 | CNN based texture synthesize with Semantic segment | http://arxiv.org/pdf/1605.04731v1.pdf | author:Xianye Liang, Bocheng Zhuo, Peijie Li, Liangju He category:cs.CV cs.GR cs.LG published:2016-05-16 summary:Deep learning algorithm display powerful ability in Computer Vision area, inrecent year, the CNN has been applied to solve problems in the subarea ofImage-generating, which has been widely applied in areas such as photo editing,image design, computer animation, real-time rendering for large scale of scenesand for visual effects in movies. However in the texture synthesize procedure.The state-of-art CNN can not capture the spatial location of texture in image,lead to significant distortion after texture synthesize, we propose a new wayto generating-image by adding the semantic segment step with deep learningalgorithm as Pre-Processing and analyze the outcome.
arxiv-18300-225 | Implementing a Bayes Filter in a Neural Circuit: The Case of Unknown, Nonlinear Stimulus Dynamics | http://arxiv.org/pdf/1512.07839v2.pdf | author:Sacha Sokoloski category:cs.LG stat.ML published:2015-12-22 summary:In order to interact intelligently with objects in the world, animals mustfirst transform neural population responses into estimates of the unknownstimuli which caused them. The Bayesian solution to this problem is known as aBayes filter, and previous work has shown how to exactly implement a Bayesfilter in a theoretical neural circuit when the stimulus dynamics are known andlinear. In this paper we develop a method for approximating a Bayes filter whenthe stimulus dynamics are unknown and nonlinear, by training a recurrent neuralnetwork to approximate the predictions of the Bayes filter. To train thenetwork, we use a combination of contrastive divergence minimization andbackpropagation, in order to maximize the likelihood of the parameters of thenetwork given the population responses. We demonstrate this method on a problemwhere the stimulus is a stochastic pendulum, and show how the learned networkdisplays many of the characteristic properties found in research on populationsof neurons.
arxiv-18300-226 | Ternary Weight Networks | http://arxiv.org/pdf/1605.04711v1.pdf | author:Fengfu Li, Bin Liu category:cs.CV published:2016-05-16 summary:We introduce Ternary Weight Networks (TWNs) - neural networks with weightsconstrained to +1, 0 and -1. The L2 distance between the full (float or double)precision weights and the ternary weights along with a scaling factor isminimized. With the optimization, the TWNs own high capacity of modelexpression that is good enough to approximate the Full Precision WeightNetworks (FPWNs) counterpart. Besides, the TWNs achieve up to 16x or 32x modelcompression rate and own much fewer multiplications compared with the FPWNs.Compared with recently proposed Binary Precision Weight Networks (BPWNs), theTWNs own nearly 38x more power of expression in a 3$\times$3 size filter, whichis commonly used in most of the state-of-the-art CNN models like residualnetworks or VGG. Besides, the TWNs eliminate the singularity at zero andconverge faster and more stablely at training time. Benchmarks on MNIST,CIFAR-10, and the large scale ImageNet dataset show that TWNs achievestate-of-the-art performance which is only slightly worse than the FPWNscounterpart but outperforms the analogous BPWNs.
arxiv-18300-227 | Estimation of Fiber Orientations Using Neighborhood Information | http://arxiv.org/pdf/1601.04115v2.pdf | author:Chuyang Ye, Jiachen Zhuo, Rao P. Gullapalli, Jerry L. Prince category:cs.CV published:2016-01-16 summary:Data from diffusion magnetic resonance imaging (dMRI) can be used toreconstruct fiber tracts, for example, in muscle and white matter. Estimationof fiber orientations (FOs) is a crucial step in the reconstruction process andthese estimates can be corrupted by noise. In this paper, a new method calledFiber Orientation Reconstruction using Neighborhood Information (FORNI) isdescribed and shown to reduce the effects of noise and improve FO estimationperformance by incorporating spatial consistency. FORNI uses a fixed tensorbasis to model the diffusion weighted signals, which has the advantage ofproviding an explicit relationship between the basis vectors and the FOs. FOspatial coherence is encouraged using weighted l1-norm regularization terms,which contain the interaction of directional information between neighborvoxels. Data fidelity is encouraged using a squared error between the observedand reconstructed diffusion weighted signals. After appropriate weighting ofthese competing objectives, the resulting objective function is minimized usinga block coordinate descent algorithm, and a straightforward parallelizationstrategy is used to speed up processing. Experiments were performed on adigital crossing phantom, ex vivo tongue dMRI data, and in vivo brain dMRI datafor both qualitative and quantitative evaluation. The results demonstrate thatFORNI improves the quality of FO estimation over other state of the artalgorithms.
arxiv-18300-228 | A Critical Examination of RESCAL for Completion of Knowledge Bases with Transitive Relations | http://arxiv.org/pdf/1605.04672v1.pdf | author:Pushpendre Rastogi, Benjamin Van Durme category:stat.ML cs.AI cs.DB cs.LG published:2016-05-16 summary:Link prediction in large knowledge graphs has received a lot of attentionrecently because of its importance for inferring missing relations and forcompleting and improving noisily extracted knowledge graphs. Over the years anumber of machine learning researchers have presented various models forpredicting the presence of missing relations in a knowledge base. Although allthe previous methods are presented with empirical results that show highperformance on select datasets, there is almost no previous work onunderstanding the connection between properties of a knowledge base and theperformance of a model. In this paper we analyze the RESCAL method and provethat it can not encode asymmetric transitive relations in knowledge bases.
arxiv-18300-229 | Exclusivity Regularized Machine | http://arxiv.org/pdf/1603.08318v2.pdf | author:Xiaojie Guo category:cs.LG published:2016-03-28 summary:It has been recognized that the diversity of base learners is of utmostimportance to a good ensemble. This paper defines a novel measurement ofdiversity, termed as exclusivity. With the designed exclusivity, we furtherpropose an ensemble model, namely Exclusivity Regularized Machine (ERM), tojointly suppress the training error of ensemble and enhance the diversitybetween bases. Moreover, an Augmented Lagrange Multiplier based algorithm iscustomized to effectively and efficiently seek the optimal solution of ERM.Theoretical analysis on convergence and global optimality of the proposedalgorithm, as well as experiments are provided to reveal the efficacy of ourmethod and show its superiority over state-of-the-art alternatives in terms ofaccuracy and efficiency.
arxiv-18300-230 | Solve-Select-Scale: A Three Step Process For Sparse Signal Estimation | http://arxiv.org/pdf/1605.04657v1.pdf | author:Mithun Das Gupta category:cs.IT cs.LG math.IT stat.ML published:2016-05-16 summary:In the theory of compressed sensing (CS), the sparsity $\x\_0$ of theunknown signal $\mathbf{x} \in \mathcal{R}^n$ is of prime importance and thefocus of reconstruction algorithms has mainly been either $\x\_0$ or itsconvex relaxation (via $\x\_1$). However, it is typically unknown in practiceand has remained a challenge when nothing about the size of the support isknown. As pointed recently, $\x\_0$ might not be the best metric to minimizedirectly, both due to its inherent complexity as well as its noise performance.Recently a novel stable measure of sparsity $s(\mathbf{x}) :=\\mathbf{x}\_1^2/\\mathbf{x}\_2^2$ has been investigated by Lopes\cite{Lopes2012}, which is a sharp lower bound on $\\mathbf{x}\_0$. Theestimation procedure for this measure uses only a small number of linearmeasurements, does not rely on any sparsity assumptions, and requires verylittle computation. The usage of the quantity $s(\mathbf{x})$ in sparse signalestimation problems has not received much importance yet. We develop the ideaof incorporating $s(\mathbf{x})$ into the signal estimation framework. We alsoprovide a three step algorithm to solve problems of the form $\mathbf{Ax=b}$with no additional assumptions on the original signal $\mathbf{x}$.
arxiv-18300-231 | Joint Learning of Sentence Embeddings for Relevance and Entailment | http://arxiv.org/pdf/1605.04655v1.pdf | author:Petr Baudis, Silvestr Stanko, Jan Sedivy category:cs.CL cs.LG cs.NE published:2016-05-16 summary:We consider the problem of Recognizing Textual Entailment within anInformation Retrieval context, where we must simultaneously determine therelevancy as well as degree of entailment for individual pieces of evidence todetermine a yes/no answer to a binary natural language question. We compare several variants of neural networks for sentence embeddings in asetting of decision-making based on evidence of varying relevance. We propose abasic model to integrate evidence for entailment, show that joint training ofthe sentence embeddings to model relevance and entailment is feasible even withno explicit per-evidence supervision, and show the importance of evaluatingstrong baselines. We also demonstrate the benefit of carrying over textcomprehension model trained on an unrelated task for our small datasets. Our research is motivated primarily by a new open dataset we introduce,consisting of binary questions and news-based evidence snippets. We also applythe proposed relevance-entailment model on a similar task of rankingmultiple-choice test answers, evaluating it on a preliminary dataset of schooltest questions as well as the standard MCTest dataset, where we improve theneural model state-of-art.
arxiv-18300-232 | Wavelet Scattering Regression of Quantum Chemical Energies | http://arxiv.org/pdf/1605.04654v1.pdf | author:Matthew Hirn, St√©phane Mallat, Nicolas Poilvert category:math.CA quant-ph stat.ML published:2016-05-16 summary:We introduce multiscale invariant dictionaries to estimate quantum chemicalenergies of organic molecules, from training databases. Molecular energies areinvariant to isometric atomic displacements, and are Lipschitz continuous tomolecular deformations. Similarly to density functional theory (DFT), themolecule is represented by an electronic density function. A multiscaleinvariant dictionary is calculated with wavelet scattering invariants. Itcascades a first wavelet transform which separates scales, with a secondwavelet transform which computes interactions across scales. Sparse scatteringregressions give state of the art results over two databases of organic planarmolecules. On these databases, the regression error is of the order of theerror produced by DFT codes, but at a fraction of the computational cost.
arxiv-18300-233 | Stochastic Optimization Techniques for Quantification Performance Measures | http://arxiv.org/pdf/1605.04135v2.pdf | author:Shuai Li, Harikrishna Narasimhan, Purushottam Kar, Sanjay Chawla, Fabrizio Sebastiani category:stat.ML cs.AI cs.IR cs.LG published:2016-05-13 summary:The estimation of class prevalence, i.e., the fraction of the population thatbelongs to a certain class, is a very useful tool in data analytics andlearning, and finds applications in many domains, such as sentiment analysis,epidemiology, etc. For example, in sentiment analysis, the objective is oftennot to estimate whether a specific text conveys positive or negative sentiment,but rather estimate the overall distribution of positive and negative sentimentduring an event window. A popular way of performing the above task, oftendubbed quantification, is to use supervised learning to train a prevalenceestimator from labelled data. In this paper we propose the first onlinestochastic algorithms for directly optimizing (i) performance measures forquantification, and (ii) hybrid performance measures that seek to balancequantification and classification performance. We prove rigorous bounds for ouralgorithms which demonstrate that they exhibit optimal convergence. Ouralgorithms present a significant advancement in the theory of multivariateoptimization. We also report extensive experiments on benchmark and real datasets which demonstrate that our methods significantly outperform existingoptimization techniques used for the quantification problem.
arxiv-18300-234 | Alternating optimization method based on nonnegative matrix factorizations for deep neural networks | http://arxiv.org/pdf/1605.04639v1.pdf | author:Tetsuya Sakurai, Akira Imakura, Yuto Inoue, Yasunori Futamura category:cs.LG cs.NE stat.ML published:2016-05-16 summary:The backpropagation algorithm for calculating gradients has been widely usedin computation of weights for deep neural networks (DNNs). This method requiresderivatives of objective functions and has some difficulties findingappropriate parameters such as learning rate. In this paper, we propose a novelapproach for computing weight matrices of fully-connected DNNs by using twotypes of semi-nonnegative matrix factorizations (semi-NMFs). In this method,optimization processes are performed by calculating weight matricesalternately, and backpropagation (BP) is not used. We also present a method tocalculate stacked autoencoder using a NMF. The output results of theautoencoder are used as pre-training data for DNNs. The experimental resultsshow that our method using three types of NMFs attains similar error rates tothe conventional DNNs with BP.
arxiv-18300-235 | Tracking Slowly Moving Clairvoyant: Optimal Dynamic Regret of Online Learning with True and Noisy Gradient | http://arxiv.org/pdf/1605.04638v1.pdf | author:Tianbao Yang, Lijun Zhang, Rong Jin, Jinfeng Yi category:cs.LG math.OC stat.ML published:2016-05-16 summary:This work focuses on dynamic regret of online convex optimization thatcompares the performance of online learning to a clairvoyant who knows thesequence of loss functions in advance and hence selects the minimizer of theloss function at each step. By assuming that the clairvoyant moves slowly(i.e., the minimizers change slowly), we present several improvedvariation-based upper bounds of the dynamic regret under the true and noisygradient feedback, which are {\it optimal} in light of the presented lowerbounds. The key to our analysis is to explore a regularity metric that measuresthe temporal changes in the clairvoyant's minimizers, to which we refer as {\itpath variation}. Firstly, we present a general lower bound in terms of the pathvariation, and then show that under full information or gradient feedback weare able to achieve an optimal dynamic regret. Secondly, we present a lowerbound with noisy gradient feedback and then show that we can achieve optimaldynamic regrets under a stochastic gradient feedback and two-point banditfeedback. Moreover, for a sequence of smooth loss functions that admit a smallvariation in the gradients, our dynamic regret under the two-point banditfeedback matches what is achieved with full information.
arxiv-18300-236 | Heart Beat Characterization from Ballistocardiogram Signals using Extended Functions of Multiple Instances | http://arxiv.org/pdf/1605.04634v1.pdf | author:Changzhe Jiao, Princess Lyons, Alina Zare, Licet Rosales, Marjorie Skubic category:cs.CV published:2016-05-16 summary:A multiple instance learning (MIL) method, extended Function of MultipleInstances ($e$FUMI), is applied to ballistocardiogram (BCG) signals produced bya hydraulic bed sensor. The goal of this approach is to learn a personalizedheartbeat "concept" for an individual. This heartbeat concept is a prototype(or "signature") that characterizes the heartbeat pattern for an individual inballistocardiogram data. The $e$FUMI method models the problem of learning aheartbeat concept from a BCG signal as a MIL problem. This approach elegantlyaddresses the uncertainty inherent in a BCG signal e. g., misalignment betweentraining data and ground truth, mis-collection of heartbeat by sometransducers, etc. Given a BCG training signal coupled with a ground truthsignal (e.g., a pulse finger sensor), training "bags" labeled with only binarylabels denoting if a training bag contains a heartbeat signal or not can begenerated. Then, using these bags, $e$FUMI learns a personalized concept ofheartbeat for a subject as well as several non-heartbeat background concepts.After learning the heartbeat concept, heartbeat detection and heart rateestimation can be applied to test data. Experimental results show that theestimated heartbeat concept found by $e$FUMI is more representative and a morediscriminative prototype of the heartbeat signals than those found bycomparison MIL methods in the literature.
arxiv-18300-237 | Learning to Rank Personalized Search Results in Professional Networks | http://arxiv.org/pdf/1605.04624v1.pdf | author:Viet Ha-Thuc, Shakti Sinha category:cs.IR cs.LG published:2016-05-16 summary:LinkedIn search is deeply personalized - for the same queries, differentsearchers expect completely different results. This paper presents our approachto achieving this by mining various data sources available in LinkedIn to infersearchers' intents (such as hiring, job seeking, etc.), as well as extendingthe concept of homophily to capture the searcher-result similarities on manyaspects. Then, learning-to-rank (LTR) is applied to combine these signals withstandard search features.
arxiv-18300-238 | Rank Pooling for Action Recognition | http://arxiv.org/pdf/1512.01848v2.pdf | author:Basura Fernando, Efstratios Gavves, Jose Oramas, Amir Ghodrati, Tinne Tuytelaars category:cs.CV published:2015-12-06 summary:We propose a function-based temporal pooling method that captures the latentstructure of the video sequence data - e.g. how frame-level features evolveover time in a video. We show how the parameters of a function that has beenfit to the video data can serve as a robust new video representation. As aspecific example, we learn a pooling function via ranking machines. By learningto rank the frame-level features of a video in chronological order, we obtain anew representation that captures the video-wide temporal dynamics of a video,suitable for action recognition. Other than ranking functions, we exploredifferent parametric models that could also explain the temporal changes invideos. The proposed functional pooling methods, and rank pooling inparticular, is easy to interpret and implement, fast to compute and effectivein recognizing a wide variety of actions. We evaluate our method on variousbenchmarks for generic action, fine-grained action and gesture recognition.Results show that rank pooling brings an absolute improvement of 7-10 averagepooling baseline. At the same time, rank pooling is compatible with andcomplementary to several appearance and local motion based methods andfeatures, such as improved trajectories and deep learning features.
arxiv-18300-239 | Quantized Convolutional Neural Networks for Mobile Devices | http://arxiv.org/pdf/1512.06473v3.pdf | author:Jiaxiang Wu, Cong Leng, Yuhang Wang, Qinghao Hu, Jian Cheng category:cs.CV published:2015-12-21 summary:Recently, convolutional neural networks (CNN) have demonstrated impressiveperformance in various computer vision tasks. However, high performancehardware is typically indispensable for the application of CNN models due tothe high computation complexity, which prohibits their further extensions. Inthis paper, we propose an efficient framework, namely Quantized CNN, tosimultaneously speed-up the computation and reduce the storage and memoryoverhead of CNN models. Both filter kernels in convolutional layers andweighting matrices in fully-connected layers are quantized, aiming atminimizing the estimation error of each layer's response. Extensive experimentson the ILSVRC-12 benchmark demonstrate 4~6x speed-up and 15~20x compressionwith merely one percentage loss of classification accuracy. With our quantizedCNN model, even mobile devices can accurately classify images within onesecond.
arxiv-18300-240 | DeepLearningKit - an GPU Optimized Deep Learning Framework for Apple's iOS, OS X and tvOS developed in Metal and Swift | http://arxiv.org/pdf/1605.04614v1.pdf | author:Amund Tveit, Torbj√∏rn Morland, Thomas Brox R√∏st category:cs.LG cs.DC cs.NE published:2016-05-15 summary:In this paper we present DeepLearningKit - an open source framework thatsupports using pretrained deep learning models (convolutional neural networks)for iOS, OS X and tvOS. DeepLearningKit is developed in Metal in order toutilize the GPU efficiently and Swift for integration with applications, e.g.iOS-based mobile apps on iPhone/iPad, tvOS-based apps for the big screen, or OSX desktop applications. The goal is to support using deep learning modelstrained with popular frameworks such as Caffe, Torch, TensorFlow, Theano,Pylearn, Deeplearning4J and Mocha. Given the massive GPU resources and timerequired to train Deep Learning models we suggest an App Store like model todistribute and download pretrained and reusable Deep Learning models.
arxiv-18300-241 | Improving the Neural Algorithm of Artistic Style | http://arxiv.org/pdf/1605.04603v1.pdf | author:Roman Novak, Yaroslav Nikulin category:cs.CV published:2016-05-15 summary:In this work we investigate different avenues of improving the NeuralAlgorithm of Artistic Style (by Leon A. Gatys, Alexander S. Ecker and MatthiasBethge, arXiv:1508.06576). While showing great results when transferring homogeneous and repetitivepatterns, the original style representation often fails to capture more complexproperties, like having separate styles of foreground and background. Thisleads to visual artifacts and undesirable textures appearing in unexpectedregions when performing style transfer. We tackle this issue with a variety of approaches, mostly by modifying thestyle representation in order for it to capture more information and impose atighter constraint on the style transfer result. In our experiments, we subjectively evaluate our best method as producingfrom barely noticeable to significant improvements in the quality of styletransfer.
arxiv-18300-242 | A Distributed Quaternion Kalman Filter With Applications to Fly-by-Wire Systems | http://arxiv.org/pdf/1605.05588v1.pdf | author:Sayed Pouria Talebi category:cs.SY stat.AP stat.ML published:2016-05-15 summary:The introduction of automated flight control and management systems have madepossible aircraft designs that sacrifice arodynamic stability in order toincorporate stealth technology intro their shape, operate more efficiently, andare highly maneuverable. Therefore, modern flight management systems arereliant on multiple redundant sensors to monitor and control the rotations ofthe aircraft. To this end, a novel distributed quaternion Kalman filteringalgorithm is developed for tracking the rotation and orientation of an aircraftin the three-dimensional space. The algorithm is developed to distributecomputation among the sensors in a manner that forces them to consent to aunique solution while being robust to sensor and link failure, a desirablecharacteristic for flight management systems. In addition, the underlyingquaternion-valued state space model allows to avoid problems associated withgimbal lock. The performance of the developed algorithm is verified throughsimulations.
arxiv-18300-243 | Projected Nesterov's Proximal-Gradient Algorithm for Sparse Signal Reconstruction with a Convex Constraint | http://arxiv.org/pdf/1502.02613v4.pdf | author:Renliang Gu, Aleksandar Dogand≈æiƒá category:stat.CO stat.ML published:2015-02-09 summary:We develop a projected Nesterov's proximal-gradient (PNPG) approach forsparse signal reconstruction that combines adaptive step size with Nesterov'smomentum acceleration. The objective function that we wish to minimize is thesum of a convex differentiable data-fidelity (negative log-likelihood (NLL))term and a convex regularization term. We apply sparse signal regularizationwhere the signal belongs to a closed convex set within the closure of thedomain of the NLL; the convex-set constraint facilitates flexible NLL domainsand accurate signal recovery. Signal sparsity is imposed using the$\ell_1$-norm penalty on the signal's linear transform coefficients or gradientmap, respectively. The PNPG approach employs projected Nesterov's accelerationstep with restart and an inner iteration to compute the proximal mapping. Wepropose an adaptive step-size selection scheme to obtain a good localmajorizing function of the NLL and reduce the time spent backtracking. Thanksto step-size adaptation, PNPG does not require Lipschitz continuity of thegradient of the NLL. We present an integrated derivation of the momentumacceleration and its $\mathcal{O}(k^{-2})$ convergence-rate and iterateconvergence proofs, which account for adaptive step-size selection, inexactnessof the iterative proximal mapping, and the convex-set constraint. The tuning ofPNPG is largely application-independent. Tomographic and compressed-sensingreconstruction experiments with Poisson generalized linear and Gaussian linearmeasurement models demonstrate the performance of the proposed approach.
arxiv-18300-244 | Learning 3D Articulation and Deformation using 2D Images | http://arxiv.org/pdf/1507.07646v2.pdf | author:Angjoo Kanazawa, Shahar Kovalsky, Ronen Basri, David W. Jacobs category:cs.CV published:2015-07-28 summary:Understanding how an animal can deform and articulate is essential for arealistic modification of its 3D model. In this paper, we show that suchinformation can be learned from user-clicked 2D images and a template 3D modelof the target animal. We present a volumetric deformation framework thatproduces a set of new 3D models by deforming a template 3D model according to aset of user-clicked images. Our framework is based on a novel locally-boundeddeformation energy, where every local region has its own stiffness value thatbounds how much distortion is allowed at that location. We jointly learn thelocal stiffness bounds as we deform the template 3D mesh to match eachuser-clicked image. We show that this seemingly complex task can be solved as asequence of convex optimization problems. We demonstrate the effectiveness ofour approach on cats and horses, which are highly deformable and articulatedanimals. Our framework produces new 3D models of animals that are significantlymore plausible than methods without learned stiffness.
arxiv-18300-245 | Novelty Detection in MultiClass Scenarios with Incomplete Set of Class Labels | http://arxiv.org/pdf/1604.06242v2.pdf | author:Nomi Vinokurov, Daphna Weinshall category:cs.CV published:2016-04-21 summary:We address the problem of novelty detection in multiclass scenarios wheresome class labels are missing from the training set. Our method is based on theinitial assignment of confidence values, which measure the affinity between anew test point and each known class. We first compare the values of the two topelements in this vector of confidence values. In the heart of our method liesthe training of an ensemble of classifiers, each trained to discriminate knownfrom novel classes based on some partition of the training data intopresumed-known and presumednovel classes. Our final novelty score is derivedfrom the output of this ensemble of classifiers. We evaluated our method on twodatasets of images containing a relatively large number of classes - theCaltech-256 and Cifar-100 datasets. We compared our method to 3 alternativemethods which represent commonly used approaches, including the one-class SVM,novelty based on k-NN, novelty based on maximal confidence, and the recentKNFST method. The results show a very clear and marked advantage for our methodover all alternative methods, in an experimental setup where class labels aremissing during training.
arxiv-18300-246 | Visualization Regularizers for Neural Network based Image Recognition | http://arxiv.org/pdf/1604.02646v2.pdf | author:Biswajit Paria, Anirban Santara, Pabitra Mitra category:cs.LG cs.CV cs.NE published:2016-04-10 summary:The success of deep neural networks is mostly due their ability to learnmeaningful features from the data. Features learned in the hidden layers ofdeep neural networks trained in computer vision tasks have been shown to besimilar to mid-level vision features. We leverage this fact in this work andpropose the visualization regularizer for image tasks. The proposedregularization technique enforces smoothness of the features learned by hiddennodes and turns out to be a special case of Tikhonov regularization. We achievehigher classification accuracy as compared to existing regularizers such as theL2 norm regularizer and dropout, on benchmark datasets with no change in thetraining computational complexity.
arxiv-18300-247 | Treating Similarity with Respect: How to Evaluate Models of Meaning? | http://arxiv.org/pdf/1605.04553v1.pdf | author:Dmitrijs Milajevs, Sascha Griffiths category:cs.CL published:2016-05-15 summary:Similarity is a core notion that is used in psychology, theoretical andcomputational linguistics. The similarity datasets that come from the twofields differ in design: psychological datasets are focused around a certaintopic such as fruit names; linguistic datasets contain words from variouscategories. The later makes humans assign low similarity scores to the wordsthat have nothing in common and to the words that have contrast in meaning,making similarity scores ambiguous. In this work we discuss the similaritycollection procedure for a multi-category dataset that avoids score ambiguityand suggest changes to the evaluation procedure to reflect the insights ofpsychological literature for word, phrase and sentence similarity. We suggestto ask humans to provide a list of commonalities and differences instead ofnumerical similarity scores and employ the structure of human judgements beyondpairwise similarity. We believe that the proposed approach will give rise todatasets that test meaning representation models more thoroughly with respectto the human treatment of similarity.
arxiv-18300-248 | Data Collection for Interactive Learning through the Dialog | http://arxiv.org/pdf/1603.09631v2.pdf | author:Miroslav Vodol√°n, Filip Jurƒç√≠ƒçek category:cs.CL cs.LG published:2016-03-31 summary:This paper presents a dataset collected from natural dialogs which enables totest the ability of dialog systems to learn new facts from user utterancesthroughout the dialog. This interactive learning will help with one of the mostprevailing problems of open domain dialog system, which is the sparsity offacts a dialog system can reason about. The proposed dataset, consisting of1900 collected dialogs, allows simulation of an interactive gaining ofdenotations and questions explanations from users which can be used for theinteractive learning.
arxiv-18300-249 | Recurrent Mixture Density Network for Spatiotemporal Visual Attention | http://arxiv.org/pdf/1603.08199v3.pdf | author:Loris Bazzani, Hugo Larochelle, Lorenzo Torresani category:cs.CV published:2016-03-27 summary:The high-dimensional and redundant nature of video have pushed researchers toseek the design of attentional models that can dynamically focus computationson the spatiotemporal volumes that are most relevant. Specifically, thesemodels have been used to eliminate or down-weight background pixels that arenot important for the task at hand. In order to deal with this problem, wepropose an attentional model that learns where to look in a video directly fromhuman fixation data. The proposed model leverages deep 3D convolutionalfeatures to represent clip segments in videos. This clip-level representationis aggregated over time by a long short-term memory network that connects intoa mixture density network model of the likely positions of fixations in eachframe. The resulting model is trained end to end using backpropagation. Ourexperiments show state-of-the-art performance on saliency prediction forvideos. Experiments on Hollywood2 and UCF101 also show that the saliency can beused to improve classification accuracy on action recognition tasks.
arxiv-18300-250 | On Some Properties of Calibrated Trifocal Tensors | http://arxiv.org/pdf/1601.01467v3.pdf | author:Evgeniy Martyushev category:cs.CV published:2016-01-07 summary:In two-view geometry, the essential matrix describes the relative positionand orientation of two calibrated images. In three views, a similar role isassigned to the calibrated trifocal tensor. It is a particular case of the(uncalibrated) trifocal tensor and thus it inherits all its properties but, dueto the smaller degrees of freedom, satisfies a number of additional algebraicconstraints. Some of them are described in this paper. More specifically, wedefine a new notion --- the trifocal essential matrix. On the one hand, it is ageneralization of the ordinary (bifocal) essential matrix, and, on the otherhand, it is closely related to the calibrated trifocal tensor. We prove the twonecessary and sufficient conditions that characterize the set of trifocalessential matrices. Based on these characterizations, we propose threenecessary conditions on a calibrated trifocal tensor. They have a form of 15quartic and 99 quintic polynomial equations. We show that in the practicallysignificant real case the 15 quartic constraints are also sufficient.
arxiv-18300-251 | Joint Learning of Convolutional Neural Networks and Temporally Constrained Metrics for Tracklet Association Based on Large-Scale Datasets | http://arxiv.org/pdf/1605.04502v1.pdf | author:Bing Wang, Kap Luk Chan, Li Wang, Bing Shuai, Zhen Zuo, Ting Liu, Gang Wang category:cs.CV published:2016-05-15 summary:In this paper, we study the challenging problem of multi-object tracking in acomplex scene captured by a single camera. Different from the existing trackletassociation-based tracking methods, we propose a novel and efficient way toobtain discriminative appearance-based tracklet affinity models. Our proposedmethod jointly learns the convolutional neural networks (CNNs) and temporallyconstrained metrics. In our method, a siamese convolutional neural network(CNN) is first pre-trained on the auxiliary data. Then the siamese CNN andtemporally constrained metrics are jointly learned online to construct theappearance-based tracklet affinity models. The proposed method can jointlylearn the hierarchical deep features and temporally constrained segment-wisemetrics under a unified framework. For reliable association between tracklets,a novel loss function incorporating temporally constrained multi-task learningmechanism is proposed. By employing the proposed method, tracklet associationcan be accomplished even in challenging situations. Moreover, a large-scaledataset with 40 fully annotated sequences is created to facilitate the trackingevaluation. Experimental results on five public datasets and the newlarge-scale dataset show that our method outperforms several state-of-the-artapproaches in multi-object tracking.
arxiv-18300-252 | Bias and Agreement in Syntactic Annotations | http://arxiv.org/pdf/1605.04481v1.pdf | author:Yevgeni Berzak, Yan Huang, Andrei Barbu, Anna Korhonen, Boris Katz category:cs.CL published:2016-05-15 summary:We present a study on two key characteristics of human syntactic annotations:anchoring and agreement. Anchoring is a well known cognitive bias in humandecision making, where judgments are drawn towards pre-existing values. Westudy the influence of anchoring on a standard approach to creation ofsyntactic resources where syntactic annotations are obtained via human editingof tagger and parser output. Our experiments demonstrate a clear anchoringeffect and reveal unwanted consequences, including overestimation of parsingperformance and lower quality of annotations in comparison with human-basedannotations. Using sentences from the Penn Treebank WSJ, we also report thefirst systematically obtained inter-annotator agreement estimates for Englishsyntactic parsing. Our agreement results control for anchoring bias, and areconsequential in that they are \emph{on par} with state of the art parsingperformance for English. We discuss the impact of our findings on strategiesfor future annotation efforts and parser evaluations.
arxiv-18300-253 | Gabor Barcodes for Medical Image Retrieval | http://arxiv.org/pdf/1605.04478v1.pdf | author:Mina Nouredanesh, Hamid R. Tizhoosh, Ershad Banijamali category:cs.CV published:2016-05-14 summary:In recent years, advances in medical imaging have led to the emergence ofmassive databases, containing images from a diverse range of modalities. Thishas significantly heightened the need for automated annotation of the images onone side, and fast and memory-efficient content-based image retrieval systemson the other side. Binary descriptors have recently gained more attention as apotential vehicle to achieve these goals. One of the recently introduced binarydescriptors for tagging of medical images are Radon barcodes (RBCs) that aredriven from Radon transform via local thresholding. Gabor transform is also apowerful transform to extract texture-based information. Gabor features haveexhibited robustness against rotation, scale, and also photometricdisturbances, such as illumination changes and image noise in manyapplications. This paper introduces Gabor Barcodes (GBCs), as a novel frameworkfor the image annotation. To find the most discriminative GBC for a given queryimage, the effects of employing Gabor filters with different parameters, i.e.,different sets of scales and orientations, are investigated, resulting indifferent barcode lengths and retrieval performances. The proposed method hasbeen evaluated on the IRMA dataset with 193 classes comprising of 12,677 x-rayimages for indexing, and 1,733 x-rays images for testing. A total error scoreas low as $351$ ($\approx 80\%$ accuracy for the first hit) was achieved.
arxiv-18300-254 | Capturing divergence in dependency trees to improve syntactic projection | http://arxiv.org/pdf/1605.04475v1.pdf | author:Ryan Georgi, Fei Xia, William D. Lewis category:cs.CL published:2016-05-14 summary:Obtaining syntactic parses is a crucial part of many NLP pipelines. However,most of the world's languages do not have large amounts of syntacticallyannotated corpora available for building parsers. Syntactic projectiontechniques attempt to address this issue by using parallel corpora consistingof resource-poor and resource-rich language pairs, taking advantage of a parserfor the resource-rich language and word alignment between the languages toproject the parses onto the data for the resource-poor language. Theseprojection methods can suffer, however, when the two languages are divergent.In this paper, we investigate the possibility of using small, parallel,annotated corpora to automatically detect divergent structural patterns betweentwo languages. These patterns can then be used to improve structural projectionalgorithms, allowing for better performing NLP tools for resource-poorlanguages, in particular those that may not have large amounts of annotateddata necessary for traditional, fully-supervised methods. While this detectionprocess is not exhaustive, we demonstrate that common patterns of divergencecan be identified automatically without prior knowledge of a given languagepair, and the patterns can be used to improve performance of projectionalgorithms.
arxiv-18300-255 | Rationale-Augmented Convolutional Neural Networks for Text Classification | http://arxiv.org/pdf/1605.04469v1.pdf | author:Ye Zhang, Iain Marshall, Byron C. Wallace category:cs.CL published:2016-05-14 summary:We present a new Convolutional Neural Network (CNN) model for textclassification that jointly exploits labels on documents and their componentsentences. Specifically, we consider scenarios in which annotators explicitlymark sentences (or snippets) that support their overall documentcategorization, i.e., they provide rationales. Our model uses such supervisionvia a hierarchical approach in which each document is represented by a linearcombination of the vector representations of its constituent sentences. Wepropose a sentence-level convolutional model that estimates the probabilitythat a given sentence is a rationale, and we then scale the contribution ofeach sentence to the aggregate document representation in proportion to theseestimates. Experiments on five classification datasets that have documentlabels and associated rationales demonstrate that our approach consistentlyoutperforms strong baselines. Moreover, our model naturally providesexplanations for its predictions.
arxiv-18300-256 | Generalized Linear Models for Aggregated Data | http://arxiv.org/pdf/1605.04466v1.pdf | author:Avradeep Bhowmik, Joydeep Ghosh, Oluwasanmi Koyejo category:stat.ML cs.AI cs.LG published:2016-05-14 summary:Databases in domains such as healthcare are routinely released to the publicin aggregated form. Unfortunately, naive modeling with aggregated data maysignificantly diminish the accuracy of inferences at the individual level. Thispaper addresses the scenario where features are provided at the individuallevel, but the target variables are only available as histogram aggregates ororder statistics. We consider a limiting case of generalized linear modelingwhen the target variables are only known up to permutation, and explore howthis relates to permutation testing; a standard technique for assessingstatistical dependency. Based on this relationship, we propose a simplealgorithm to estimate the model parameters and individual level inferences viaalternating imputation and standard generalized linear model fitting. Ourresults suggest the effectiveness of the proposed approach when, in theoriginal data, permutation testing accurately ascertains the veracity of thelinear relationship. The framework is extended to general histogram data withlarger bins - with order statistics such as the median as a limiting case. Ourexperimental results on simulated data and aggregated healthcare data suggest adiminishing returns property with respect to the granularity of the histogram -when a linear relationship holds in the original data, the targets can bepredicted accurately given relatively coarse histograms.
arxiv-18300-257 | Monotone Retargeting for Unsupervised Rank Aggregation with Object Features | http://arxiv.org/pdf/1605.04465v1.pdf | author:Avradeep Bhowmik, Joydeep Ghosh category:stat.ML cs.AI cs.LG published:2016-05-14 summary:Learning the true ordering between objects by aggregating a set of expertopinion rank order lists is an important and ubiquitous problem in manyapplications ranging from social choice theory to natural language processingand search aggregation. We study the problem of unsupervised rank aggregationwhere no ground truth ordering information in available, neither about the truepreference ordering between any set of objects nor about the quality ofindividual rank lists. Aggregating the often inconsistent and poor quality ranklists in such an unsupervised manner is a highly challenging problem, andstandard consensus-based methods are often ill-defined, and difficult to solve.In this manuscript we propose a novel framework to bypass these issues by usingobject attributes to augment the standard rank aggregation framework. We designalgorithms that learn joint models on both rank lists and object features toobtain an aggregated rank ordering that is more accurate and robust, and alsohelps weed out rank lists of dubious validity. We validate our techniques onsynthetic datasets where our algorithm is able to estimate the true rankordering even when the rank lists are corrupted. Experiments on three realdatasets, MQ2008, MQ2008 and OHSUMED, show that using object features canresult in significant improvement in performance over existing rank aggregationmethods that do not use object information. Furthermore, when at least some ofthe rank lists are of high quality, our methods are able to effectively exploittheir high expertise to output an aggregated rank ordering of great accuracy.
arxiv-18300-258 | Natural Language Processing for Mental Health: Large Scale Discourse Analysis of Counseling Conversations | http://arxiv.org/pdf/1605.04462v1.pdf | author:Tim Althoff, Kevin Clark, Jure Leskovec category:cs.CL cs.CY cs.SI published:2016-05-14 summary:Mental illness is one of the most pressing public health issues of our time.While counseling and psychotherapy can be effective treatments, our knowledgeabout how to conduct successful counseling conversations has been limited dueto lack of large-scale data with labeled outcomes of the conversations. In thispaper, we present a large-scale, quantitative study on the discourse oftext-message-based counseling conversations. We develop a set of novelcomputational discourse analysis methods to measure how various linguisticaspects of conversations are correlated with conversation outcomes. Applyingtechniques such as sequence-based conversation models, language modelcomparisons, message clustering, and psycholinguistics-inspired word frequencyanalyses, we discover actionable conversation strategies that are associatedwith better conversation outcomes.
arxiv-18300-259 | Proceedings of the 5th Workshop on Machine Learning and Interpretation in Neuroimaging (MLINI) at NIPS 2015 | http://arxiv.org/pdf/1605.04435v1.pdf | author:I. Rish, L. Wehbe, G. Langs, M. Grosse-Wentrup, B. Murphy, G. Cecchi category:stat.ML published:2016-05-14 summary:This volume is a collection of contributions from the 5th Workshop on MachineLearning and Interpretation in Neuroimaging (MLINI) at the Neural InformationProcessing Systems (NIPS 2015) conference. Modern multivariate statisticalmethods developed in the rapidly growing field of machine learning are beingincreasingly applied to various problems in neuroimaging, from cognitive statedetection to clinical diagnosis and prognosis. Multivariate pattern analysismethods are designed to examine complex relationships between high-dimensionalsignals, such as brain images, and outcomes of interest, such as the categoryof a stimulus, a type of a mental state of a subject, or a specific mentaldisorder. Such techniques are in contrast with the traditional mass-univariateapproaches that dominated neuroimaging in the past and treated each individualimaging measurement in isolation. We believe that machine learning has a prominent role in shaping howquestions in neuroscience are framed, and that the machine-learning mind set isnow entering modern psychology and behavioral studies. It is also equallyimportant that practical applications in these fields motivate a rapidlyevolving line or research in the machine learning community. In parallel, thereis an intense interest in learning more about brain function in the context ofrich naturalistic environments and scenes. Efforts to go beyond highly specificparadigms that pinpoint a single function, towards schemes for measuring theinteraction with natural and more varied scene are made. The goal of theworkshop is to pinpoint the most pressing issues and common challenges acrossthe neuroscience, neuroimaging, psychology and machine learning fields, and tosketch future directions and open questions in the light of novel methodology.
arxiv-18300-260 | Better safe than sorry: Risky function exploitation through safe optimization | http://arxiv.org/pdf/1602.01052v2.pdf | author:Eric Schulz, Quentin J. M. Huys, Dominik R. Bach, Maarten Speekenbrink, Andreas Krause category:stat.AP cs.LG stat.ML published:2016-02-02 summary:Exploration-exploitation of functions, that is learning and optimizing amapping between inputs and expected outputs, is ubiquitous to many real worldsituations. These situations sometimes require us to avoid certain outcomes atall cost, for example because they are poisonous, harmful, or otherwisedangerous. We test participants' behavior in scenarios in which they have tofind the optimum of a function while at the same time avoid outputs below acertain threshold. In two experiments, we find that Safe-Optimization, aGaussian Process-based exploration-exploitation algorithm, describesparticipants' behavior well and that participants seem to care firstly whethera point is safe and then try to pick the optimal point from all such safepoints. This means that their trade-off between exploration and exploitationcan be seen as an intelligent, approximate, and homeostasis-driven strategy.
arxiv-18300-261 | Online Optimization for Large-Scale Max-Norm Regularization | http://arxiv.org/pdf/1406.3190v4.pdf | author:Jie Shen, Huan Xu, Ping Li category:stat.ML cs.LG published:2014-06-12 summary:Max-norm regularizer has been extensively studied in the last decade as itpromotes an effective low-rank estimation for the underlying data. However,such max-norm regularized problems are typically formulated and solved in abatch manner, which prevents it from processing big data due to possible memorybudget. In this paper, hence, we propose an online algorithm that is scalableto large-scale setting. Particularly, we consider the matrix decompositionproblem as an example, although a simple variant of the algorithm and analysiscan be adapted to other important problems such as matrix completion. Thecrucial technique in our implementation is to reformulating the max-norm to anequivalent matrix factorization form, where the factors consist of a (possiblyovercomplete) basis component and a coefficients one. In this way, we maymaintain the basis component in the memory and optimize over it and thecoefficients for each sample alternatively. Since the memory footprint of thebasis component is independent of the sample size, our algorithm is appealingwhen manipulating a large collection of samples. We prove that the sequence ofthe solutions (i.e., the basis component) produced by our algorithm convergesto a stationary point of the expected loss function asymptotically. Numericalstudy demonstrates encouraging results for the efficacy and robustness of ouralgorithm compared to the widely used nuclear norm solvers.
arxiv-18300-262 | Neural Dataset Generality | http://arxiv.org/pdf/1605.04369v1.pdf | author:Ragav Venkatesan, Vijetha Gattupalli, Baoxin Li category:cs.CV published:2016-05-14 summary:Often the filters learned by Convolutional Neural Networks (CNNs) fromdifferent datasets appear similar. This is prominent in the first few layers.This similarity of filters is being exploited for the purposes of transferlearning and some studies have been made to analyse such transferability offeatures. This is also being used as an initialization technique for differenttasks in the same dataset or for the same task in similar datasets.Off-the-shelf CNN features have capitalized on this idea to promote theirnetworks as best transferable and most general and are used in a cavaliermanner in day-to-day computer vision tasks. It is curious that while the filters learned by these CNNs are related to theatomic structures of the images from which they are learnt, all datasets learnsimilar looking low-level filters. With the understanding that a dataset thatcontains many such atomic structures learn general filters and are thereforeuseful to initialize other networks with, we propose a way to analyse andquantify generality among datasets from their accuracies on transferredfilters. We applied this metric on several popular character recognition,natural image and a medical image dataset, and arrived at some interestingconclusions. On further experimentation we also discovered that particularclasses in a dataset themselves are more general than others.
arxiv-18300-263 | Many Languages, One Parser | http://arxiv.org/pdf/1602.01595v3.pdf | author:Waleed Ammar, George Mulcaire, Miguel Ballesteros, Chris Dyer, Noah A. Smith category:cs.CL published:2016-02-04 summary:We train one multilingual model for dependency parsing and use it to parsesentences in several languages. The parsing model uses (i) multilingual wordclusters and embeddings; (ii) token-level language information; and (iii)language-specific features (fine-grained POS tags). This input representationenables the parser not only to parse effectively in multiple languages, butalso to generalize across languages based on linguistic universals andtypological similarities, making it more effective to learn from limitedannotations. Our parser's performance compares favorably to strong baselines ina range of data scenarios, including when the target language has a largetreebank, a small treebank, or no treebank for training.
arxiv-18300-264 | Occurrence Statistics of Entities, Relations and Types on the Web | http://arxiv.org/pdf/1605.04359v1.pdf | author:Aman Madaan, Sunita Sarawagi category:cs.CL published:2016-05-14 summary:The problem of collecting reliable estimates of occurrence of entities on theopen web forms the premise for this report. The models learned for taggingentities cannot be expected to perform well when deployed on the web. This isowing to the severe mismatch in the distributions of such entities on the weband in the relatively diminutive training data. In this report, we build up thecase for maximum mean discrepancy for estimation of occurrence statistics ofentities on the web, taking a review of named entity disambiguation techniquesand related concepts along the way.
arxiv-18300-265 | Support Vector Algorithms for Optimizing the Partial Area Under the ROC Curve | http://arxiv.org/pdf/1605.04337v1.pdf | author:Harikrishna Narasimhan, Shivani Agarwal category:cs.LG published:2016-05-13 summary:The area under the ROC curve (AUC) is a widely used performance measure inmachine learning. Increasingly, however, in several applications, ranging fromranking to biometric screening to medicine, performance is measured not interms of the full area under the ROC curve, but in terms of the \emph{partial}area under the ROC curve between two false positive rates. In this paper, wedevelop support vector algorithms for directly optimizing the partial AUCbetween any two false positive rates. Our methods are based on minimizing asuitable proxy or surrogate objective for the partial AUC error. In the case ofthe full AUC, one can readily construct and optimize convex surrogates byexpressing the performance measure as a summation of pairwise terms. Thepartial AUC, on the other hand, does not admit such a simple decomposablestructure, making it more challenging to design and optimize (tight) convexsurrogates for this measure. Our approach builds on the structural SVM framework of Joachims (2005) todesign convex surrogates for partial AUC, and solves the resulting optimizationproblem using a cutting plane solver. Unlike the full AUC, where thecombinatorial optimization needed in each iteration of the cutting plane solvercan be decomposed and solved efficiently, the corresponding problem for thepartial AUC is harder to decompose. One of our main contributions is apolynomial time algorithm for solving the combinatorial optimization problemassociated with partial AUC. We also develop an approach for optimizing atighter non-convex hinge loss based surrogate for the partial AUC usingdifference-of-convex programming. Our experiments on a variety of real-worldand benchmark tasks confirm the efficacy of the proposed methods.
arxiv-18300-266 | Modeling and Estimation of Discrete-Time Reciprocal Processes via Probabilistic Graphical Models | http://arxiv.org/pdf/1603.04419v3.pdf | author:Francesca Paola Carli category:stat.ML math.OC published:2016-03-14 summary:Reciprocal processes are acausal generalizations of Markov processesintroduced by Bernstein in 1932. In the literature, a significant amount ofattention has been focused on developing dynamical models for reciprocalprocesses. In this paper, we provide a probabilistic graphical model forreciprocal processes. This leads to a principled solution of the smoothingproblem via message passing algorithms. For the finite state space case,convergence analysis is revisited via the Hilbert metric.
arxiv-18300-267 | Synthesized Classifiers for Zero-Shot Learning | http://arxiv.org/pdf/1603.00550v2.pdf | author:Soravit Changpinyo, Wei-Lun Chao, Boqing Gong, Fei Sha category:cs.CV published:2016-03-02 summary:Given semantic descriptions of object classes, zero-shot learning aims toaccurately recognize objects of the unseen classes, from which no examples areavailable at the training stage, by associating them to the seen classes, fromwhich labeled examples are provided. We propose to tackle this problem from theperspective of manifold learning. Our main idea is to align the semantic spacethat is derived from external information to the model space that concernsitself with recognizing visual features. To this end, we introduce a set of"phantom" object classes whose coordinates live in both the semantic space andthe model space. Serving as bases in a dictionary, they can be optimized fromlabeled data such that the synthesized real object classifiers achieve optimaldiscriminative performance. We demonstrate superior accuracy of our approachover the state of the art on four benchmark datasets for zero-shot learning,including the full ImageNet Fall 2011 dataset with more than 20,000 unseenclasses.
arxiv-18300-268 | Universal Dependencies for Learner English | http://arxiv.org/pdf/1605.04278v1.pdf | author:Yevgeni Berzak, Jessica Kenney, Carolyn Spadine, Jing Xian Wang, Lucia Lam, Keiko Sophie Mori, Sebastian Garza, Boris Katz category:cs.CL published:2016-05-13 summary:We introduce the Treebank of Learner English (TLE), the first publiclyavailable syntactic treebank for English as a Second Language (ESL). The TLEprovides manually annotated POS tags and Universal Dependency (UD) trees for5,124 sentences from the Cambridge First Certificate in English (FCE) corpus.The UD annotations are tied to a pre-existing error annotation of the FCE,whereby full syntactic analyses are provided for both the original and errorcorrected versions of each sentence. Further on, we delineate ESL annotationguidelines that allow for consistent syntactic treatment of ungrammaticalEnglish. Finally, we benchmark POS tagging and dependency parsing performanceon the TLE dataset and measure the effect of grammatical errors on parsingaccuracy. We envision the treebank to support a wide range of linguistic andcomputational research on second language acquisition as well as automaticprocessing of ungrammatical language.
arxiv-18300-269 | ABtree: An Algorithm for Subgroup-Based Treatment Assignment | http://arxiv.org/pdf/1605.04262v1.pdf | author:Derek Feng, Xiaofei Wang category:stat.ML published:2016-05-13 summary:Given two possible treatments, there may exist subgroups who benefit greaterfrom one treatment than the other. This problem is relevant to the field ofmarketing, where treatments may correspond to different ways of selling aproduct. It is similarly relevant to the field of public policy, wheretreatments may correspond to specific government programs. And finally,personalized medicine is a field wholly devoted to understanding whichsubgroups of individuals will benefit from particular medical treatments. Wepresent a computationally fast tree-based method, ABtree, for treatment effectdifferentiation. Unlike other methods, ABtree specifically produces decisionrules for optimal treatment assignment on a per-individual basis. The treatmentchoices are selected for maximizing the overall occurrence of a desired binaryoutcome, conditional on a set of covariates. In this poster, we present themethodology on tree growth and pruning, and show performance results whenapplied to simulated data as well as real data.
arxiv-18300-270 | An Empirical Study and Analysis of Generalized Zero-Shot Learning for Object Recognition in the Wild | http://arxiv.org/pdf/1605.04253v1.pdf | author:Wei-Lun Chao, Soravit Changpinyo, Boqing Gong, Fei Sha category:cs.CV published:2016-05-13 summary:We investigate the problem of generalized zero-shot learning (GZSL). GZSLrelaxes the unrealistic assumption in conventional ZSL that test data belongonly to unseen novel classes. In GZSL, test data might also come from seenclasses and the labeling space is the union of both types of classes. We showempirically that a straightforward application of the classifiers provided byexisting ZSL approaches does not perform well in the setting of GZSL. Motivatedby this, we propose a surprisingly simple but effective method to adapt ZSLapproaches for GZSL. The main idea is to introduce a calibration factor tocalibrate the classifiers for both seen and unseen classes so as to balance twoconflicting forces: recognizing data from seen classes and those from unseenones. We develop a new performance metric called the Area Under Seen-Unseenaccuracy Curve to characterize this tradeoff. We demonstrate the utility ofthis metric by analyzing existing ZSL approaches applied to the generalizedsetting. Extensive empirical studies reveal strengths and weaknesses of thoseapproaches on three well-studied benchmark datasets, including the large-scaleImageNet Full 2011 with 21,000 unseen categories. We complement our comparativestudies in learning methods by further establishing an upper-bound on theperformance limit of GZSL. There, our idea is to use class-representativevisual features as the idealized semantic embeddings. We show that there is alarge gap between the performance of existing approaches and the performancelimit, suggesting that improving the quality of class semantic embeddings isvital to improving zero-shot learning.
arxiv-18300-271 | Color Homography | http://arxiv.org/pdf/1605.04250v1.pdf | author:Graham Finlayson, Han Gong, Robert Fisher category:cs.CV published:2016-05-13 summary:We show the surprising result that colors across a change in viewingcondition (changing light color, shading and camera) are related by ahomography. Our homography color correction application delivers improved colorfidelity compared with the linear least-square.
arxiv-18300-272 | LSTM with Working Memory | http://arxiv.org/pdf/1605.01988v2.pdf | author:Andrew Pulver, Siwei Lyu category:cs.NE published:2016-05-06 summary:LSTM is arguably the most successful RNN architecture for many tasks thatinvolve sequential information. In the past few years there have been severalproposed improvements to LSTM. We propose an improvement to LSTM which allowscommunication between memory cells in different blocks and allows an LSTM layerto carry out internal computation within its memory.
arxiv-18300-273 | Unbiased Bayesian Inference for Population Markov Jump Processes via Random Truncations | http://arxiv.org/pdf/1509.08327v2.pdf | author:Anastasis Georgoulas, Jane Hillston, Guido Sanguinetti category:stat.ML published:2015-09-28 summary:We consider continuous time Markovian processes where populations ofindividual agents interact stochastically according to kinetic rules. Despitethe increasing prominence of such models in fields ranging from biology tosmart cities, Bayesian inference for such systems remains challenging, as theseare continuous time, discrete state systems with potentially infinitestate-space. Here we propose a novel efficient algorithm for joint state /parameter posterior sampling in population Markov Jump processes. We introducea class of pseudo-marginal sampling algorithms based on a random truncationmethod which enables a principled treatment of infinite state spaces. Extensiveevaluation on a number of benchmark models shows that this approach achievesconsiderable savings compared to state of the art methods, retaining accuracyand fast convergence. We also present results on a synthetic biology data setshowing the potential for practical usefulness of our work.
arxiv-18300-274 | Simultaneous Surface Reflectance and Fluorescence Spectra Estimation | http://arxiv.org/pdf/1605.04243v1.pdf | author:Henryk Blasinski, Joyce Farrell, Brian Wandell category:cs.CV published:2016-05-13 summary:There is widespread interest in estimating the fluorescence properties ofnatural materials in an image. However, the separation between reflected andfluoresced components is difficult, because it is impossible to distinguishreflected and fluoresced photons without controlling the illuminant spectrum.We show how to jointly estimate the reflectance and fluorescence from a singleset of images acquired under multiple illuminants. We present a framework basedon a linear approximation to the physical equations describing image formationin terms of surface spectral reflectance and fluorescence due to multiplefluorophores. We relax the non-convex, inverse estimation problem in order tojointly estimate the reflectance and fluorescence properties in a singleoptimization step and we use the Alternating Direction Method of Multipliers(ADMM) approach to efficiently find a solution. We provide a softwareimplementation of the solver for our method and prior methods. We evaluate theaccuracy and reliability of the method using both simulations and experimentaldata. To acquire data to test the methods, we built a custom imaging systemusing a monochrome camera, a filter wheel with bandpass transmissive filtersand a small number of light emitting diodes. We compared the system andalgorithm performance with the ground truth as well as with prior methods. Ourapproach produces lower errors compared to earlier algorithms.
arxiv-18300-275 | Semantic Spaces | http://arxiv.org/pdf/1605.04238v1.pdf | author:Yuri Manin, Matilde Marcolli category:cs.CL 68Q55, 14M15 published:2016-05-13 summary:Any natural language can be considered as a tool for producing largedatabases (consisting of texts, written, or discursive). This tool for itsdescription in turn requires other large databases (dictionaries, grammarsetc.). Nowadays, the notion of database is associated with computer processingand computer memory. However, a natural language resides also in human brainsand functions in human communication, from interpersonal to intergenerationalone. We discuss in this survey/research paper mathematical, in particulargeometric, constructions, which help to bridge these two worlds. In particular,in this paper we consider the Vector Space Model of semantics based onfrequency matrices, as used in Natural Language Processing. We investigateunderlying geometries, formulated in terms of Grassmannians, projective spaces,and flag varieties. We formulate the relation between vector space models andsemantic spaces based on semic axes in terms of projectability of subvarietiesin Grassmannians and projective spaces. We interpret Latent Semantics as ageometric flow on Grassmannians. We also discuss how to formulate G\"ardenfors'notion of "meeting of minds" in our geometric setting.
arxiv-18300-276 | Natural Language Inference by Tree-Based Convolution and Heuristic Matching | http://arxiv.org/pdf/1512.08422v3.pdf | author:Lili Mou, Rui Men, Ge Li, Yan Xu, Lu Zhang, Rui Yan, Zhi Jin category:cs.CL cs.LG published:2015-12-28 summary:In this paper, we propose the TBCNN-pair model to recognize entailment andcontradiction between two sentences. In our model, a tree-based convolutionalneural network (TBCNN) captures sentence-level semantics; then heuristicmatching layers like concatenation, element-wise product/difference combine theinformation in individual sentences. Experimental results show that our modeloutperforms existing sentence encoding-based approaches by a large margin.
arxiv-18300-277 | Distributed Deep Learning for Answer Selection | http://arxiv.org/pdf/1511.01158v2.pdf | author:Minwei Feng, Bing Xiang, Bowen Zhou category:cs.LG cs.CL cs.DC published:2015-11-03 summary:This paper is an empirical study of the distributed deep learning for aquestion answering subtask: answer selection. Comparison studies of SGD, MSGD,DOWNPOUR and EASGD/EAMSGD algorithms have been presented. Experimental resultsshow that the message passing interface based distributed framework canaccelerate the convergence speed at a sublinear scale. This paper demonstratesthe importance of distributed training: with 120 workers, an 83x speedup isachievable and running time is decreased from 107.9 hours to 1.3 hours, whichwill benefit the productivity significantly.
arxiv-18300-278 | High Dimensional Bayesian Optimisation and Bandits via Additive Models | http://arxiv.org/pdf/1503.01673v3.pdf | author:Kirthevasan Kandasamy, Jeff Schneider, Barnabas Poczos category:stat.ML cs.LG published:2015-03-05 summary:Bayesian Optimisation (BO) is a technique used in optimising a$D$-dimensional function which is typically expensive to evaluate. While therehave been many successes for BO in low dimensions, scaling it to highdimensions has been notoriously difficult. Existing literature on the topic areunder very restrictive settings. In this paper, we identify two key challengesin this endeavour. We tackle these challenges by assuming an additive structurefor the function. This setting is substantially more expressive and contains aricher class of functions than previous work. We prove that, for additivefunctions the regret has only linear dependence on $D$ even though the functiondepends on all $D$ dimensions. We also demonstrate several other statisticaland computational benefits in our framework. Via synthetic examples, ascientific simulation and a face detection problem we demonstrate that ourmethod outperforms naive BO on additive functions and on several examples wherethe function is not additive.
arxiv-18300-279 | Learning scale-variant and scale-invariant features for deep image classification | http://arxiv.org/pdf/1602.01255v2.pdf | author:Nanne van Noord, Eric Postma category:cs.CV published:2016-02-03 summary:Convolutional Neural Networks (CNNs) require large image corpora to betrained on classification tasks. The variation in image resolutions, sizes ofobjects and patterns depicted, and image scales, hampers CNN training andperformance, because the task-relevant information varies over spatial scales.Previous work attempting to deal with such scale variations focused onencouraging scale-invariant CNN representations. However, scale-invariantrepresentations are incomplete representations of images, because imagescontain scale-variant information as well. This paper addresses the combineddevelopment of scale-invariant and scale-variant representations. We propose amulti- scale CNN method to encourage the recognition of both types of featuresand evaluate it on a challenging image classification task involvingtask-relevant characteristics at multiple scales. The results show that ourmulti-scale CNN outperforms single-scale CNN. This leads to the conclusion thatencouraging the combined development of a scale-invariant and scale-variantrepresentation in CNNs is beneficial to image recognition performance.
arxiv-18300-280 | Deep Gate Recurrent Neural Network | http://arxiv.org/pdf/1604.02910v3.pdf | author:Yuan Gao, Dorota Glowacka category:cs.NE published:2016-04-11 summary:This paper introduces two recurrent neural network structures called SimpleGated Unit (SGU) and Deep Simple Gated Unit (DSGU), which are generalstructures for learning long term dependencies. Compared to traditional LongShort-Term Memory (LSTM) and Gated Recurrent Unit (GRU), both structuresrequire fewer parameters and less computation time in sequence classificationtasks. Unlike GRU and LSTM, which require more than one gates to controlinformation flow in the network, SGU and DSGU only use one multiplicative gateto control the flow of information. We show that this difference can acceleratethe learning speed in tasks that require long dependency information. We alsoshow that DSGU is more numerically stable than SGU. In addition, we alsopropose a standard way of representing inner structure of RNN called RNNConventional Graph (RCG), which helps analyzing the relationship between inputunits and hidden units of RNN.
arxiv-18300-281 | Clustering with Missing Features: A Penalized Dissimilarity Measure based approach | http://arxiv.org/pdf/1604.06602v2.pdf | author:Shounak Datta, Supritam Bhattacharjee, Swagatam Das category:cs.LG 62H30 published:2016-04-22 summary:Many real-world clustering problems are plagued by incomplete datacharacterized by missing or absent features for some or all of the datainstances. Traditional clustering methods cannot be directly applied to suchdata without preprocessing by imputation or marginalization techniques. In thisarticle, we put forth the concept of Penalized Dissimilarity Measures whichestimate the actual distance between two data points (the distance between themif they were to be fully observed) by adding a penalty to the distance due tothe observed features common to both the instances. We then propose such adissimilarity measure called the Feature Weighted Penalty based Dissimilarity(FWPD) measure. Using the proposed dissimilarity measure, we also modify thetraditional k-means clustering algorithm and the standard hierarchicalagglomerative clustering techniques so as to make them directly applicable todatasets with missing features. We present time complexity analyses for thesenew techniques and also present a detailed analysis showing that the new FWPDbased k-means algorithm converges to a local optimum within a finite number ofiterations. We have also conducted extensive experiments on various benchmarkdatasets showing that the proposed clustering techniques have generally betterresults compared to some of the popular imputation methods which are commonlyused to handle such incomplete data. We have appended a possible extension ofthe proposed dissimilarity measure to the case of absent features (where theunobserved features are known to be non-existent).
arxiv-18300-282 | Structured Receptive Fields in CNNs | http://arxiv.org/pdf/1605.02971v2.pdf | author:J√∂rn-Henrik Jacobsen, Jan van Gemert, Zhongyu Lou, Arnold W. M. Smeulders category:cs.CV published:2016-05-10 summary:Learning powerful feature representations with CNNs is hard when trainingdata are limited. Pre-training is one way to overcome this, but it requireslarge datasets sufficiently similar to the target domain. Another option is todesign priors into the model, which can range from tuned hyperparameters tofully engineered representations like Scattering Networks. We combine theseideas into structured receptive field networks, a model which has a fixedfilter basis and yet retains the flexibility of CNNs. This flexibility isachieved by expressing receptive fields in CNNs as a weighted sum over a fixedbasis which is similar in spirit to Scattering Networks. The key difference isthat we learn arbitrary effective filter sets from the basis rather thanmodeling the filters. This approach explicitly connects classical multiscaleimage analysis with general CNNs. With structured receptive field networks, weimprove considerably over unstructured CNNs for small and medium datasetscenarios as well as over Scattering for large datasets. We validate ourfindings on ILSVRC2012, Cifar-10, Cifar-100 and MNIST. As a realistic smalldataset example, we show state-of-the-art classification results on popular 3DMRI brain-disease datasets where pre-training is difficult due to a lack oflarge public datasets in a similar domain.
arxiv-18300-283 | Barzilai-Borwein Step Size for Stochastic Gradient Descent | http://arxiv.org/pdf/1605.04131v1.pdf | author:Conghui Tan, Shiqian Ma, Yu-Hong Dai, Yuqiu Qian category:math.OC cs.LG stat.ML published:2016-05-13 summary:One of the major issues in stochastic gradient descent (SGD) methods is howto choose an appropriate step size while running the algorithm. Since thetraditional line search technique does not apply for stochastic optimizationalgorithms, the common practice in SGD is either to use a diminishing stepsize, or to tune a fixed step size by hand. Apparently, these two approachescan be time consuming in practice. In this paper, we propose to use theBarzilai-Borwein (BB) method to automatically compute step sizes for SGD andits variant: stochastic variance reduced gradient (SVRG) method, which leads totwo algorithms: SGD-BB and SVRG-BB. We prove that SVRG-BB converges linearlyfor strongly convex objective function. As a by-product, we prove the linearconvergence result of SVRG with Option I proposed in [10], whose convergenceresult has been missing in the literature. Numerical experiments on standarddata sets show that the performance of SGD-BB and SVRG-BB is comparable to andsometimes even better than SGD and SVRG with best-tuned step sizes, and issuperior to some advanced SGD variants.
arxiv-18300-284 | With Whom Do I Interact? Detecting Social Interactions in Egocentric Photo-streams | http://arxiv.org/pdf/1605.04129v1.pdf | author:Maedeh Aghaei, Mariella Dimiccoli, Petia Radeva category:cs.CV published:2016-05-13 summary:Given a user wearing a low frame rate wearable camera during a day, this workaims to automatically detect the moments when the user gets engaged into asocial interaction solely by reviewing the automatically captured photos by theworn camera. The proposed method, inspired by the sociological concept ofF-formation, exploits distance and orientation of the appearing individuals-with respect to the user- in the scene from a bird-view perspective. As aresult, the interaction pattern over the sequence can be understood as atwo-dimensional time series that corresponds to the temporal evolution of thedistance and orientation features over time. A Long-Short Term Memory-basedRecurrent Neural Network is then trained to classify each time series.Experimental evaluation over a dataset of 30.000 images has shown promisingresults on the proposed method for social interaction detection in egocentricphoto-streams.
arxiv-18300-285 | Natural Language Semantics and Computability | http://arxiv.org/pdf/1605.04122v1.pdf | author:Richard Moot, Christian Retor√© category:cs.CL cs.AI cs.CC published:2016-05-13 summary:This paper is a reflexion on the computability of natural language semantics.It does not contain a new model or new results in the formal semantics ofnatural language: it is rather a computational analysis of the logical modelsand algorithms currently used in natural language semantics, defined as themapping of a statement to logical formulas - formulas, because a statement canbe ambiguous. We argue that as long as possible world semantics is left out,one can compute the semantic representation(s) of a given statement, includingaspects of lexical meaning. We also discuss the algorithmic complexity of thisprocess.
arxiv-18300-286 | Fast methods for training Gaussian processes on large data sets | http://arxiv.org/pdf/1604.01250v2.pdf | author:Christopher J. Moore, Alvin J. K. Chua, Christopher P. L. Berry, Jonathan R. Gair category:stat.ML stat.CO stat.ME published:2016-04-05 summary:Gaussian process regression (GPR) is a non-parametric Bayesian technique forinterpolating or fitting data. The main barrier to further uptake of thispowerful tool rests in the computational costs associated with the matriceswhich arise when dealing with large data sets. Here, we derive some simpleresults which we have found useful for speeding up the learning stage in theGPR algorithm, and especially for performing Bayesian model comparison betweendifferent covariance functions. We apply our techniques to both synthetic andreal data and quantify the speed-up relative to using nested sampling tonumerically evaluate model evidences.
arxiv-18300-287 | Wisdom of Crowds cluster ensemble | http://arxiv.org/pdf/1605.04074v1.pdf | author:Hosein Alizadeh, Muhammad Yousefnezhad, Behrouz Minaei Bidgoli category:stat.ML cs.AI cs.SI published:2016-05-13 summary:The Wisdom of Crowds is a phenomenon described in social science thatsuggests four criteria applicable to groups of people. It is claimed that, ifthese criteria are satisfied, then the aggregate decisions made by a group willoften be better than those of its individual members. Inspired by this concept,we present a novel feedback framework for the cluster ensemble problem, whichwe call Wisdom of Crowds Cluster Ensemble (WOCCE). Although many conventionalcluster ensemble methods focusing on diversity have recently been proposed,WOCCE analyzes the conditions necessary for a crowd to exhibit this collectivewisdom. These include decentralization criteria for generating primary results,independence criteria for the base algorithms, and diversity criteria for theensemble members. We suggest appropriate procedures for evaluating thesemeasures, and propose a new measure to assess the diversity. We evaluate theperformance of WOCCE against some other traditional base algorithms as well asstate-of-the-art ensemble methods. The results demonstrate the efficiency ofWOCCE's aggregate decision-making compared to other algorithms.
arxiv-18300-288 | Towards Empathetic Human-Robot Interactions | http://arxiv.org/pdf/1605.04072v1.pdf | author:Pascale Fung, Dario Bertero, Yan Wan, Anik Dey, Ricky Ho Yin Chan, Farhad Bin Siddique, Yang Yang, Chien-Sheng Wu, Ruixi Lin category:cs.CL cs.AI cs.HC cs.RO published:2016-05-13 summary:Since the late 1990s when speech companies began providing theircustomer-service software in the market, people have gotten used to speaking tomachines. As people interact more often with voice and gesture controlledmachines, they expect the machines to recognize different emotions, andunderstand other high level communication features such as humor, sarcasm andintention. In order to make such communication possible, the machines need anempathy module in them which can extract emotions from human speech andbehavior and can decide the correct response of the robot. Although research onempathetic robots is still in the early stage, we described our approach usingsignal processing techniques, sentiment analysis and machine learningalgorithms to make robots that can "understand" human emotion. We propose Zarathe Supergirl as a prototype system of empathetic robots. It is a softwarebased virtual android, with an animated cartoon character to present itself onthe screen. She will get "smarter" and more empathetic through its deeplearning algorithms, and by gathering more data and learning from it. In thispaper, we present our work so far in the areas of deep learning of emotion andsentiment recognition, as well as humor recognition. We hope to explore thefuture direction of android development and how it can help improve people'slives.
arxiv-18300-289 | A Reinforcement Learning System to Encourage Physical Activity in Diabetes Patients | http://arxiv.org/pdf/1605.04070v1.pdf | author:Irit Hochberg, Guy Feraru, Mark Kozdoba, Shie Mannor, Moshe Tennenholtz, Elad Yom-Tov category:cs.CY cs.LG published:2016-05-13 summary:Regular physical activity is known to be beneficial to people suffering fromdiabetes type 2. Nevertheless, most such people are sedentary. Smartphonescreate new possibilities for helping people to adhere to their physicalactivity goals, through continuous monitoring and communication, coupled withpersonalized feedback. We provided 27 sedentary diabetes type 2 patients with a smartphone-basedpedometer and a personal plan for physical activity. Patients were sent SMSmessages to encourage physical activity between once a day and once per week.Messages were personalized through a Reinforcement Learning (RL) algorithmwhich optimized messages to improve each participant's compliance with theactivity regimen. The RL algorithm was compared to a static policy for sendingmessages and to weekly reminders. Our results show that participants who received messages generated by the RLalgorithm increased the amount of activity and pace of walking, while thecontrol group patients did not. Patients assigned to the RL algorithm groupexperienced a superior reduction in blood glucose levels (HbA1c) compared tocontrol policies, and longer participation caused greater reductions in bloodglucose levels. The learning algorithm improved gradually in predicting whichmessages would lead participants to exercise. Our results suggest that a mobile phone application coupled with a learningalgorithm can improve adherence to exercise in diabetic patients. As a learningalgorithm is automated, and delivers personalized messages, it could be used inlarge populations of diabetic patients to improve health and glycemic control.Our results can be expanded to other areas where computer-led health coachingof humans may have a positive impact.
arxiv-18300-290 | Fast Semantic Image Segmentation with High Order Context and Guided Filtering | http://arxiv.org/pdf/1605.04068v1.pdf | author:Falong Shen, Gang Zeng category:cs.CV published:2016-05-13 summary:This paper describes a fast and accurate semantic image segmentation approachthat encodes not only the discriminative features from deep neural networks,but also the high-order context compatibility among adjacent objects as well aslow level image features. We formulate the underlying problem as theconditional random field that embeds local feature extraction, clique potentialconstruction, and guided filtering within the same framework, and provide anefficient coarse-to-fine solver. At the coarse level, we combine local featurerepresentation and context interaction using a deep convolutional network, anddirectly learn the interaction from high order cliques with a message passingroutine, avoiding time-consuming explicit graph inference for joint probabilitydistribution. At the fine level, we introduce a guided filtering interpretationfor the mean field algorithm, and achieve accurate object boundaries with 100+faster than classic learning methods. The two parts are connected and jointlytrained in an end-to-end fashion. Experimental results on Pascal VOC 2012dataset have shown that the proposed algorithm outperforms thestate-of-the-art, and that it achieves the rank 1 performance at the time ofsubmission, both of which prove the effectiveness of this unified framework forsemantic image segmentation.
arxiv-18300-291 | Causal Discovery for Manufacturing Domains | http://arxiv.org/pdf/1605.04056v1.pdf | author:Katerina Marazopoulou, Rumi Ghosh, Prasanth Lade, David Jensen category:cs.LG cs.AI published:2016-05-13 summary:Yield and quality improvement is of paramount importance to any manufacturingcompany. One of the ways of improving yield is through discovery of the rootcausal factors affecting yield. We propose the use of data-driven interpretablecausal models to identify key factors affecting yield. We focus on factors thatare measured in different stages of production and testing in the manufacturingcycle of a product. We apply causal structure learning techniques on real datacollected from this line. Specifically, the goal of this work is to learninterpretable causal models from observational data produced by manufacturinglines. Emphasis has been given to the interpretability of the models to make themactionable in the field of manufacturing. We highlight the challenges presentedby assembly line data and propose ways to alleviate them.We also identifyunique characteristics of data originating from assembly lines and how toleverage them in order to improve causal discovery. Standard evaluationtechniques for causal structure learning shows that the learned causal modelsseem to closely represent the underlying latent causal relationship betweendifferent factors in the production process. These results were also validatedby manufacturing domain experts who found them promising. This workdemonstrates how data mining and knowledge discovery can be used for root causeanalysis in the domain of manufacturing and connected industry.
arxiv-18300-292 | Modeling the Mind: A brief review | http://arxiv.org/pdf/1507.01122v3.pdf | author:Gabriel Makdah category:cs.AI cs.NE published:2015-07-04 summary:The brain is a powerful tool used to achieve amazing feats. There have beenseveral significant advances in neuroscience and artificial brain research inthe past two decades. This article is a review of such advances, ranging fromthe concepts of connectionism, to neural network architectures andhigh-dimensional representations. There have also been advances in biologicallyinspired cognitive architectures of which we will cite a few. We will bepositioning relatively specific models in a much broader perspective, whilecomparing and contrasting their advantages and weaknesses. The projectspresented are targeted to model the brain at different levels, utilizingdifferent methodologies.
arxiv-18300-293 | Track Extraction with Hidden Reciprocal Chain Models | http://arxiv.org/pdf/1605.04046v1.pdf | author:George Stamatescu, Langford B White, Riley Bruce-Doust category:cs.CV published:2016-05-13 summary:This paper develops Bayesian track extraction algorithms for targets modelledas hidden reciprocal chains (HRC). HRC are a class of finite-state randomprocess models that generalise the familiar hidden Markov chains (HMC). HRC areable to model the "intention" of a target to proceed from a given origin to adestination, behaviour which cannot be properly captured by a HMC. WhileBayesian estimation problems for HRC have previously been studied, this paperfocusses principally on the problem of track extraction, of which the primarytask is confirming target existence in a set of detections obtained fromthresholding sensor measurements. Simulation examples are presented which showthat the additional model information contained in a HRC improves detectionperformance when compared to HMC models.
arxiv-18300-294 | Cross-Domain Visual Matching via Generalized Similarity Measure and Feature Learning | http://arxiv.org/pdf/1605.04039v1.pdf | author:Liang Lin, Guangrun Wang, Wangmeng Zuo, Xiangchu Feng, Lei Zhang category:cs.CV cs.AI stat.ML published:2016-05-13 summary:Cross-domain visual data matching is one of the fundamental problems in manyreal-world vision tasks, e.g., matching persons across ID photos andsurveillance videos. Conventional approaches to this problem usually involvestwo steps: i) projecting samples from different domains into a common space,and ii) computing (dis-)similarity in this space based on a certain distance.In this paper, we present a novel pairwise similarity measure that advancesexisting models by i) expanding traditional linear projections into affinetransformations and ii) fusing affine Mahalanobis distance and Cosinesimilarity by a data-driven combination. Moreover, we unify our similaritymeasure with feature representation learning via deep convolutional neuralnetworks. Specifically, we incorporate the similarity measure matrix into thedeep architecture, enabling an end-to-end way of model optimization. Weextensively evaluate our generalized similarity model in several challengingcross-domain matching tasks: person re-identification under different views andface verification over different modalities (i.e., faces from still images andvideos, older and younger faces, and sketch and photo portraits). Theexperimental results demonstrate superior performance of our model over otherstate-of-the-art methods.
arxiv-18300-295 | Transfer Hashing with Privileged Information | http://arxiv.org/pdf/1605.04034v1.pdf | author:Joey Tianyi Zhou, Xinxing Xu, Sinno Jialin Pan, Ivor W. Tsang, Zheng Qin, Rick Siow Mong Goh category:cs.LG stat.ML published:2016-05-13 summary:Most existing learning to hash methods assume that there are sufficient data,either labeled or unlabeled, on the domain of interest (i.e., the targetdomain) for training. However, this assumption cannot be satisfied in somereal-world applications. To address this data sparsity issue in hashing,inspired by transfer learning, we propose a new framework named TransferHashing with Privileged Information (THPI). Specifically, we extend thestandard learning to hash method, Iterative Quantization (ITQ), in a transferlearning manner, namely ITQ+. In ITQ+, a new slack function is learned fromauxiliary data to approximate the quantization error in ITQ. We developed analternating optimization approach to solve the resultant optimization problemfor ITQ+. We further extend ITQ+ to LapITQ+ by utilizing the geometry structureamong the auxiliary data for learning more precise binary codes in the targetdomain. Extensive experiments on several benchmark datasets verify theeffectiveness of our proposed approaches through comparisons with severalstate-of-the-art baselines.
arxiv-18300-296 | Tensor decomposition with generalized lasso penalties | http://arxiv.org/pdf/1502.06930v3.pdf | author:Oscar Hernan Madrid Padilla, James G. Scott category:stat.ME stat.CO stat.ML published:2015-02-24 summary:We present an approach for penalized tensor decomposition (PTD) thatestimates smoothly varying latent factors in multi-way data. This generalizesexisting work on sparse tensor decomposition and penalized matrixdecompositions, in a manner parallel to the generalized lasso for regressionand smoothing problems. Our approach presents many nontrivial challenges at theintersection of modeling and computation, which are studied in detail. Anefficient coordinate-wise optimization algorithm for (PTD) is presented, andits convergence properties are characterized. The method is applied both tosimulated data and real data on flu hospitalizations in Texas. These resultsshow that our penalized tensor decomposition can offer major improvements onexisting methods for analyzing multi-way data that exhibit smooth spatial ortemporal features.
arxiv-18300-297 | Machine Comprehension Based on Learning to Rank | http://arxiv.org/pdf/1605.03284v2.pdf | author:Tian Tian, Yuezhang Li category:cs.CL published:2016-05-11 summary:Machine comprehension plays an essential role in NLP and has been widelyexplored with dataset like MCTest. However, this dataset is too simple and toosmall for learning true reasoning abilities. \cite{hermann2015teaching}therefore release a large scale news article dataset and propose a deep LSTMreader system for machine comprehension. However, the training process isexpensive. We therefore try feature-engineered approach with semantics on thenew dataset to see how traditional machine learning technique and semantics canhelp with machine comprehension. Meanwhile, our proposed L2R reader systemachieves good performance with efficiency and less training data.
arxiv-18300-298 | Joint Embeddings of Hierarchical Categories and Entities | http://arxiv.org/pdf/1605.03924v2.pdf | author:Yuezhang Li, Ronghuo Zheng, Tian Tian, Zhiting Hu, Rahul Iyer, Katia Sycara category:cs.CL published:2016-05-12 summary:Due to the lack of structured knowledge applied in learning distributedrepresentation of categories, existing work cannot incorporate categoryhierarchies into entity information.~We propose a framework that embedsentities and categories into a semantic space by integrating structuredknowledge and taxonomy hierarchy from large knowledge bases. The frameworkallows to compute meaningful semantic relatedness between entities andcategories.~Compared with the previous state of the art, our framework canhandle both single-word concepts and multiple-word concepts with superiorperformance in concept categorization and semantic relatedness.
arxiv-18300-299 | A corpus-based toy model for DisCoCat | http://arxiv.org/pdf/1605.04013v1.pdf | author:Stefano Gogioso category:cs.CL cs.LO math.CT published:2016-05-13 summary:We construct an abstract categorical model for DisCoCat starting from ageneric corpus annotated with constituent structure trees. Concretely, we willwork with context-free grammars \`{a} la Chomsky, but Combinatory CategorialGrammar (CCG) and dependency grammars could also be used. We begin by dividingwords in the corpus according to three semantic functions: (i) object words,directly modelled in the semantic space; (ii) modifier words, acting onindividual object words; (iii) interaction words, connecting the meaning ofdistinct object words. We then consider the compact closed symmetric monoidalcategory of $R$-semimodules over an involutive commutative semiring $R$, and wemodel object words as vectors in a free $R$-semimodule $\mathcal{H}$,constructed from the corpus. Based on the grammatical structure annotating thecorpus, we use Frobenius algebras to model modifier words as unary operators on$\mathcal{H}$, and interaction words as binary operators on $\mathcal{H}$. Wediscuss some possible future extensions and improvements of this model.
arxiv-18300-300 | LightNet: A Versatile, Standalone Matlab-based Environment for Deep Learning | http://arxiv.org/pdf/1605.02766v2.pdf | author:Chengxi Ye, Chen Zhao, Yezhou Yang, Cornelia Fermuller, Yiannis Aloimonos category:cs.LG cs.CV cs.NE published:2016-05-09 summary:LightNet is a lightweight, versatile and purely Matlab-based deep learningframework. The aim of the design is to provide an easy-to-understand,easy-to-use and efficient computational platform for deep learning research.The implemented framework supports major deep learning architectures such asMultilayer Perceptron Networks (MLP), Convolutional Neural Networks (CNN) andRecurrent Neural Networks (RNN). The framework also supports both CPU and GPUfor computation and the switch between them is straightforward. Differentapplications in computer vision, natural language processing and robotics aredemonstrated as experiments.
