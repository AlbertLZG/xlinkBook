arxiv-1612-06856 | Temporal Feature Selection on Networked Time Series | http://arxiv.org/abs/1612.06856 | id:1612.06856 author:Haishuai Wang, Jia Wu, Peng Zhang, Chengqi Zhang category:cs.LG  published:2016-12-20 summary:This paper formulates the problem of learning discriminative features (\textit{i.e.,} segments) from networked time series data considering the linked information among time series. For example, social network users are considered to be social sensors that continuously generate social signals (tweets) represented as a time series. The discriminative segments are often referred to as \emph{shapelets} in a time series. Extracting shapelets for time series classification has been widely studied. However, existing works on shapelet selection assume that the time series are independent and identically distributed (i.i.d.). This assumption restricts their applications to social networked time series analysis, since a user's actions can be correlated to his/her social affiliations. In this paper we propose a new Network Regularized Least Squares (NetRLS) feature selection model that combines typical time series data and user network data for analysis. Experiments on real-world networked time series Twitter and DBLP data demonstrate the performance of the proposed method. NetRLS performs better than LTS, the state-of-the-art time series feature selection approach, on real-world data. version:2
arxiv-1612-07796 | Online Semantic Activity Forecasting with DARKO | http://arxiv.org/abs/1612.07796 | id:1612.07796 author:Nicholas Rhinehart, Kris M. Kitani category:cs.CV  published:2016-12-22 summary:We address the problem of continuously observing and forecasting long-term semantic activities of a first-person camera wearer: what the person will do, where they will go, and what goal they are seeking. In contrast to prior work in trajectory forecasting and short-term activity forecasting, our algorithm, DARKO, reasons about the future position, future semantic state, and future high-level goals of the camera-wearer at arbitrary spatial and temporal horizons defined only by the wearer's behaviors. DARKO learns and forecasts online from first-person observations of the user's daily behaviors. We derive novel mathematical results that enable efficient forecasting of different semantic quantities of interest. We apply our method to a dataset of 5 large-scale environments with 3 different environment types, collected from 3 different users, and experimentally validate DARKO on forecasting tasks. version:1
arxiv-1612-07771 | Highway and Residual Networks learn Unrolled Iterative Estimation | http://arxiv.org/abs/1612.07771 | id:1612.07771 author:Klaus Greff, Rupesh K. Srivastava, Jürgen Schmidhuber category:cs.NE cs.AI cs.LG I.2.6; I.5.1  published:2016-12-22 summary:The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent. While depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer. In this report, we argue that this view is incomplete and does not adequately explain several recent findings. We propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation. We demonstrate that this viewpoint directly leads to the construction of Highway and Residual networks. Finally we provide preliminary experiments to discuss the similarities and differences between the two architectures. version:1
arxiv-1612-07767 | Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics | http://arxiv.org/abs/1612.07767 | id:1612.07767 author:Xin Li, Fuxin Li category:cs.CV  published:2016-12-22 summary:Deep learning has greatly improved visual recognition in recent years. However, recent research has shown that there exist many adversarial examples that can negatively impact the performance of such an architecture. This paper focuses on detecting those adversarial examples by analyzing whether they come from the same distribution as the normal examples. Instead of directly training a deep neural network to detect adversarials, a much simpler approach is proposed based on statistics on outputs from convolutional layers. A cascade classifier is designed to efficiently detect adversarials. Furthermore, trained from one particular adversarial generating mechanism, the resulting classifier can successfully detect adversarials from a completely different mechanism as well. After detecting adversarial examples, we show that many of them can be recovered by simply performing a small average filter on the image. Those findings should provoke us to think more about the classification mechanisms in deep convolutional neural networks. version:1
arxiv-1612-07728 | Statistical limits of spiked tensor models | http://arxiv.org/abs/1612.07728 | id:1612.07728 author:Amelia Perry, Alexander S. Wein, Afonso S. Bandeira category:math.PR cs.IT math.IT math.ST stat.ML stat.TH  published:2016-12-22 summary:We study the statistical limits of both detecting and estimating a rank-one deformation of a symmetric random Gaussian tensor. We establish upper and lower bounds on the critical signal-to-noise ratio, under a variety of priors for the planted vector: (i) a uniformly sampled unit vector, (ii) i.i.d. $\pm 1$ entries, and (iii) a sparse vector where a constant fraction $\rho$ of entries are i.i.d. $\pm 1$ and the rest are zero. For each of these cases, our upper and lower bounds match up to a $1+o(1)$ factor as the order $d$ of the tensor becomes large. For sparse signals (iii), our bounds are also asymptotically tight in the sparse limit $\rho \to 0$ for any fixed $d$ (including the $d=2$ case of sparse PCA). Our upper bounds for (i) demonstrate a phenomenon reminiscent of the work of Baik, Ben Arous and P\'ech\'e: an `eigenvalue' of a perturbed tensor emerges from the bulk at a strictly lower signal-to-noise ratio than when the perturbation itself exceeds the bulk; we quantify the size of this effect. We also provide some general results for larger classes of priors. In particular, the large $d$ asymptotics of the threshold location differs between problems with discrete priors versus continuous priors. Finally, for priors (i) and (ii) we carry out the replica prediction from statistical physics, which is conjectured to give the exact information-theoretic threshold for any fixed $d$. Of independent interest, we introduce a new improvement to the second moment method for contiguity, on which our lower bounds are based. Our technique conditions away from rare `bad' events that depend on interactions between the signal and noise. This enables us to close $\sqrt{2}$-factor gaps present in several previous works. version:1
arxiv-1612-02965 | BaTFLED: Bayesian Tensor Factorization Linked to External Data | http://arxiv.org/abs/1612.02965 | id:1612.02965 author:Nathan H Lazar, Mehmet Gönen, Kemal Sönmez category:stat.ML cs.LG q-bio.QM  published:2016-12-09 summary:The vast majority of current machine learning algorithms are designed to predict single responses or a vector of responses, yet many types of response are more naturally organized as matrices or higher-order tensor objects where characteristics are shared across modes. We present a new machine learning algorithm BaTFLED (Bayesian Tensor Factorization Linked to External Data) that predicts values in a three-dimensional response tensor using input features for each of the dimensions. BaTFLED uses a probabilistic Bayesian framework to learn projection matrices mapping input features for each mode into latent representations that multiply to form the response tensor. By utilizing a Tucker decomposition, the model can capture weights for interactions between latent factors for each mode in a small core tensor. Priors that encourage sparsity in the projection matrices and core tensor allow for feature selection and model regularization. This method is shown to far outperform elastic net and neural net models on 'cold start' tasks from data simulated in a three-mode structure. Additionally, we apply the model to predict dose-response curves in a panel of breast cancer cell lines treated with drug compounds that was used as a Dialogue for Reverse Engineering Assessments and Methods (DREAM) challenge. version:2
arxiv-1612-07697 | Internet-Based Image Retrieval Using End-to-End Trained Deep Distributions | http://arxiv.org/abs/1612.07697 | id:1612.07697 author:A. Vakhitov, A. Kuzmin, V. Lempitsky category:cs.CV  published:2016-12-22 summary:Internet image search engines have long been considered as a promising tool for handling open-vocabulary textual user queries to unannotated image datasets. However, systems that use this tool have to deal with multi-modal and noisy image sets returned by search engines, especially for polysemous queries. Generally, for many queries, only a small part of the returned sets can be relevant to the user intent. In this work, we suggest an approach that explicitly accounts for the complex and noisy structure of the image sets returned by Internet image search engines. Similarly to a considerable number of previous image retrieval works, we train a deep convolutional network that maps images to high-dimensional descriptors. To model image sets obtained from the Internet, our approach then fits a simple probabilistic model that accounts for multi-modality and noise (e.g. a Gaussian mixture model) to the deep descriptors of the images in this set. Finally, the resulting distribution model can be used to search in the unannotated image dataset by evaluating likelihoods of individual images. As our main contribution, we develop an end-to-end training procedure that tunes the parameters of a deep network using an annotated training set, while accounting for the distribution fitting and the subsequent matching. In the experiments, we show that such an end-to-end approach boosts the accuracy of the Internet-based image retrieval for hold-out concepts, as compared to retrieval systems that fit similar distribution models to pre-trained features and to simpler end-to-end trained baselines. version:1
arxiv-1612-07695 | MultiNet: Real-time Joint Semantic Reasoning for Autonomous Driving | http://arxiv.org/abs/1612.07695 | id:1612.07695 author:Marvin Teichmann, Michael Weber, Marius Zoellner, Roberto Cipolla, Raquel Urtasun category:cs.CV cs.RO  published:2016-12-22 summary:While most approaches to semantic reasoning have focused on improving performance, in this paper we argue that computational times are very important in order to enable real time applications such as autonomous driving. Towards this goal, we present an approach to joint classification, detection and semantic segmentation via a unified architecture where the encoder is shared amongst the three tasks. Our approach is very simple, can be trained end-to-end and performs extremely well in the challenging KITTI dataset, outperforming the state-of-the-art in the road segmentation task. Our approach is also very efficient, taking less than 100 ms to perform all tasks. version:1
arxiv-1612-07659 | Structured Sequence Modeling with Graph Convolutional Recurrent Networks | http://arxiv.org/abs/1612.07659 | id:1612.07659 author:Youngjoo Seo, Michaël Defferrard, Pierre Vandergheynst, Xavier Bresson category:stat.ML cs.LG  published:2016-12-22 summary:This paper introduces Graph Convolutional Recurrent Network (GCRN), a deep learning model able to predict structured sequences of data. Precisely, GCRN is a generalization of classical recurrent neural networks (RNN) to data structured by an arbitrary graph. Such structured sequences can represent series of frames in videos, spatio-temporal measurements on a network of sensors, or random walks on a vocabulary graph for natural language modeling. The proposed model combines convolutional neural networks (CNN) on graphs to identify spatial structures and RNN to find dynamic patterns. We study two possible architectures of GCRN, and apply the models to two practical problems: predicting moving MNIST data, and modeling natural language with the Penn Treebank dataset. Experiments show that exploiting simultaneously graph spatial and dynamic information about data can improve both precision and learning speed. version:1
arxiv-1612-07625 | Hardware for Machine Learning: Challenges and Opportunities | http://arxiv.org/abs/1612.07625 | id:1612.07625 author:Vivienne Sze, Yu-Hsin Chen, Joel Emer, Amr Suleiman, Zhengdong Zhang category:cs.CV  published:2016-12-22 summary:Machine learning plays a critical role in extracting meaningful information out of the zetabytes of sensor data collected every day. For some applications, the goal is to analyze and understand the data to identify trends (e.g., surveillance, portable/wearable electronics); in other applications, the goal is to take immediate action based the data (e.g., robotics/drones, self-driving cars, smart Internet of Things). For many of these applications, local embedded processing near the sensor is preferred over the cloud due to privacy or latency concerns, or limitations in the communication bandwidth. However, at the sensor there are often stringent constraints on energy consumption and cost in addition to throughput and accuracy requirements. Furthermore, flexibility is often required such that the processing can be adapted for different applications or environments (e.g., update the weights and model in the classifier). In many applications, machine learning often involves transforming the input data into a higher dimensional space, which, along with programmable weights, increases data movement and consequently energy consumption. In this paper, we will discuss how these challenges can be addressed at various levels of hardware design ranging from architecture, hardware-friendly algorithms, mixed-signal circuits, and advanced technologies (including memories and sensors). version:1
arxiv-1612-07602 | Jointly Extracting Relations with Class Ties via Effective Deep Ranking | http://arxiv.org/abs/1612.07602 | id:1612.07602 author:Hai Ye, Wenhan Chao, Zhunchen Luo category:cs.AI cs.CL  published:2016-12-22 summary:In distant supervised relation extraction, the connection between relations of one entity tuple, which we call class ties, is common. Exploiting this connection may be promising for relation extraction. However, this property is seldom considered by previous work. In this work, to leverage class ties, we propose to make joint relation extraction with a unified model that integrates convolutional neural network with a general pairwise ranking framework, in which two novel ranking loss functions are introduced. Besides, an effective method is proposed to relieve the impact of relation NR (not relation) for model training and test. Experimental results on a widely used dataset show that: (1) Our model is much more superior than the baselines, achieving state-of-the-art performance; (2) Leveraging class ties, joint extraction is indeed better than separated extraction; (3) Relieving the impact of NR will significantly boost our model performance; (4) Our model can primely deal with wrong labeling problem. version:1
arxiv-1612-07600 | Re-evaluating Automatic Metrics for Image Captioning | http://arxiv.org/abs/1612.07600 | id:1612.07600 author:Mert Kilickaya, Aykut Erdem, Nazli Ikizler-Cinbis, Erkut Erdem category:cs.CL cs.CV  published:2016-12-22 summary:The task of generating natural language descriptions from images has received a lot of attention in recent years. Consequently, it is becoming increasingly important to evaluate such image captioning approaches in an automatic manner. In this paper, we provide an in-depth evaluation of the existing image captioning metrics through a series of carefully designed experiments. Moreover, we explore the utilization of the recently proposed Word Mover's Distance (WMD) document metric for the purpose of image captioning. Our findings outline the differences and/or similarities between metrics and their relative robustness by means of extensive correlation, accuracy and distraction based evaluations. Our results also demonstrate that WMD provides strong advantages over other metrics. version:1
arxiv-1612-07597 | Finding Statistically Significant Attribute Interactions | http://arxiv.org/abs/1612.07597 | id:1612.07597 author:Andreas Henelius, Antti Ukkonen, Kai Puolamäki category:stat.ML cs.LG  published:2016-12-22 summary:In many data exploration tasks it is meaningful to identify groups of attribute interactions that are specific to a variable of interest. These interactions are also useful in several practical applications, for example, to gain insight into the structure of the data, in feature selection, and in data anonymisation. We present a novel method, based on statistical significance testing, that can be used to verify if the data set has been created by a given factorized class-conditional joint distribution, where the distribution is parametrized by partition of its attributes. Furthermore, we provide a method, named ASTRID, to automatically find a partition of attributes that describes the distribution that has generated the data. The state-of-the-art classifiers are utilized to capture the interactions present in the data by systematically breaking attribute interactions and observing the effect of this breaking on classifier performance. We empirically demonstrate the utility of the proposed method with real and synthetic data as well as with usage examples. version:1
arxiv-1612-07562 | A note on the function approximation error bound for risk-sensitive reinforcement learning | http://arxiv.org/abs/1612.07562 | id:1612.07562 author:Prasenjit Karmakar, Shalabh Bhatnagar category:cs.LG  published:2016-12-22 summary:In this paper we improve the existing function approximation error bound for the policy evaluation algorithm when the aim is to find the risk-sensitive cost represented using exponential utility. version:1
arxiv-1612-07548 | Non-Deterministic Policy Improvement Stabilizes Approximated Reinforcement Learning | http://arxiv.org/abs/1612.07548 | id:1612.07548 author:Wendelin Böhmer, Rong Guo, Klaus Obermayer category:cs.AI cs.LG stat.ML  published:2016-12-22 summary:This paper investigates a type of instability that is linked to the greedy policy improvement in approximated reinforcement learning. We show empirically that non-deterministic policy improvement can stabilize methods like LSPI by controlling the improvements' stochasticity. Additionally we show that a suitable representation of the value function also stabilizes the solution to some degree. The presented approach is simple and should also be easily transferable to more sophisticated algorithms like deep reinforcement learning. version:1
arxiv-1612-07545 | A Revisit of Hashing Algorithms for Approximate Nearest Neighbor Search | http://arxiv.org/abs/1612.07545 | id:1612.07545 author:Deng Cai category:cs.CV  published:2016-12-22 summary:Approximate Nearest Neighbor (ANN) search is a fundamental problem in many areas of machine learning and data mining. During the past decade, numerous hashing algorithms are proposed to solve this problem. Every proposed algorithm claims outperforms other state-of-the-art methods. However, there are serious drawbacks in the evaluation of existing hashing papers and most of the claims in these papers should be re-examined. 1) Most of the existing papers failed to correctly measure the search time which is essential for the ANN search problem. 2) As a result, most of the papers report the performance increases as the code length increases, which is wrong if we measure the search time correctly. 3) The performance of some hashing algorithms (\eg, LSH) can easily be boosted if one uses multiple hash tables, which is an important factor should be considered in the evaluation while most of the papers failed to do so. In this paper, we carefully revisit many popular hashing algorithms and suggest one possible promising direction. For the sake of reproducibility, all the codes used in the paper are released on Github, which can be used as a testing platform to fairly compare various hashing algorithms. version:1
arxiv-1612-07528 | Cohort of LSTM and lexicon verification for handwriting recognition with gigantic lexicon | http://arxiv.org/abs/1612.07528 | id:1612.07528 author:Bruno Stuner, Clément Chatelain, Thierry Paquet category:cs.CV  published:2016-12-22 summary:Handwriting recognition state of the art methods are based on Long Short Term Memory (LSTM) recurrent neural networks (RNN) coupled with the use of linguistic knowledge. LSTM RNN presents high raw performance and interesting training properties that allow us to break with the standard method at the state of the art. We present a simple and efficient way to extract from a single training a large number of complementary LSTM RNN, called cohort, combined in a cascade architecture with a lexical verification. This process does not require fine tuning, making it easy to use. Our verification allow to deal quickly and efficiently with gigantic lexicon (over 3 million words). We achieve state of the art results for isolated word recognition with very large lexicon and present novel results for an unprecedented gigantic lexicon. version:1
arxiv-1612-07523 | Robustness of Voice Conversion Techniques Under Mismatched Conditions | http://arxiv.org/abs/1612.07523 | id:1612.07523 author:Monisankha Pal, Dipjyoti Paul, Md Sahidullah, Goutam Saha category:cs.SD cs.LG stat.ML  published:2016-12-22 summary:Most of the existing studies on voice conversion (VC) are conducted in acoustically matched conditions between source and target signal. However, the robustness of VC methods in presence of mismatch remains unknown. In this paper, we report a comparative analysis of different VC techniques under mismatched conditions. The extensive experiments with five different VC techniques on CMU ARCTIC corpus suggest that performance of VC methods substantially degrades in noisy conditions. We have found that bilinear frequency warping with amplitude scaling (BLFWAS) outperforms other methods in most of the noisy conditions. We further explore the suitability of different speech enhancement techniques for robust conversion. The objective evaluation results indicate that spectral subtraction and log minimum mean square error (logMMSE) based speech enhancement techniques can be used to improve the performance in specific noisy conditions. version:1
arxiv-1612-07516 | On Coreset Constructions for the Fuzzy $K$-Means Problem | http://arxiv.org/abs/1612.07516 | id:1612.07516 author:Johannes Blömer, Sascha Brauer, Kathrin Bujna category:cs.LG cs.DS  published:2016-12-22 summary:In this paper, we present coreset constructions for the fuzzy $K$-means problem. First, we show that one can construct a weak coresets for fuzzy $K$-means. Second, we show that there are coresets for fuzzy $K$-means with respect to balanced fuzzy $K$-means solutions. Third, we use these coresets to develop a randomized approximation algorithm whose runtime is polynomial in the number of the given points and the dimension of these points. version:1
arxiv-1612-07512 | Causal Effect Identification in Acyclic Directed Mixed Graphs and Gated Models | http://arxiv.org/abs/1612.07512 | id:1612.07512 author:Jose M. Peña, Marcus Bendtsen category:stat.ML cs.AI  published:2016-12-22 summary:We introduce a new family of graphical models that consists of graphs with possibly directed, undirected and bidirected edges but without directed cycles. We show that these models are suitable for representing causal models with additive error terms. We provide a set of sufficient graphical criteria for the identification of arbitrary causal effects when the new models contain directed and undirected edges but no bidirected edge. We also provide a necessary and sufficient graphical criterion for the identification of the causal effect of a single variable on the rest of the variables. Moreover, we develop an exact algorithm for learning the new models from observational and interventional data via answer set programming. Finally, we introduce gated models for causal effect identification, a new family of graphical models that exploits context specific independences to identify additional causal effects. version:1
arxiv-1612-07139 | Deep-learning in Mobile Robotics - from Perception to Control Systems: A Survey on Why and Why not | http://arxiv.org/abs/1612.07139 | id:1612.07139 author:Lei Tai, Ming Liu category:cs.RO cs.AI cs.LG cs.SY  published:2016-12-21 summary:Deep-learning has dramatically changed the world overnight. It greatly boosted the development of visual perception, object detection, and speech recognition, etc. That was attributed to the multiple convolutional processing layers for abstraction of learning representations from massive data. The advantages of deep convolutional structures in data processing motivated the applications of artificial intelligence methods in robotic problems, especially perception and control system, the two typical and challenging problems in robotics. This paper presents a survey of the deep-learning research landscape in mobile robotics. We start with introducing the definition and development of deep-learning in related fields, especially the essential distinctions between image processing and robotic tasks. We described and discussed several typical applications and related works in this domain, followed by the benefits from deep-learning, and related existing frameworks. Besides, operation in the complex dynamic environment is regarded as a critical bottleneck for mobile robots, such as that for autonomous driving. We thus further emphasize the recent achievement on how deep-learning contributes to navigation and control systems for mobile robots. At the end, we discuss the open challenges and research frontiers. version:2
arxiv-1612-07495 | Noise Mitigation for Neural Entity Typing and Relation Extraction | http://arxiv.org/abs/1612.07495 | id:1612.07495 author:Yadollah Yaghoobzadeh, Heike Adel, Hinrich Schütze category:cs.CL  published:2016-12-22 summary:In this paper, we address two different types of noise in information extraction models: noise from distant supervision and noise from pipeline input features. Our target tasks are entity typing and relation extraction. For the first noise type, we introduce multi-instance multi-label learning algorithms using neural network models, and apply them to fine-grained entity typing for the first time. This gives our models comparable performance with the state-of-the-art supervised approach which uses global embeddings of entities. For the second noise type, we propose ways to improve the integration of noisy entity type predictions into relation extraction. Our experiments show that probabilistic predictions are more robust than discrete predictions and that joint training of the two tasks performs best. version:1
arxiv-1612-06505 | Parallelized Tensor Train Learning For Polynomial Pattern Classification | http://arxiv.org/abs/1612.06505 | id:1612.06505 author:Zhongming Chen, Kim Batselier, Johan A. K. Suykens, Ngai Wong category:cs.LG cs.AI  published:2016-12-20 summary:In pattern classification, polynomial classifiers are well-studied methods as they are capable of generating complex decision surfaces. Unfortunately, the use of multivariate polynomials is limited to support vector machine kernels, as polynomials quickly become impractical for high-dimensional problems. In this paper, we effectively overcome the curse of dimensionality by employing the tensor train format to represent a polynomial classifier. Based on the structure of tensor trains, two learning algorithms are proposed which involve solving different optimization problems of low computational complexity. Furthermore, we show how both regularization to prevent overfitting and parallelization, which enables the use of large training sets, are incorporated into these methods. Both the efficiency and efficacy of our tensor-based polynomial classifier are then demonstrated on the two popular datasets USPS and MNIST. version:2
arxiv-1612-07486 | Continuous multilinguality with language vectors | http://arxiv.org/abs/1612.07486 | id:1612.07486 author:Robert Östling, Jörg Tiedemann category:cs.CL  published:2016-12-22 summary:Most existing models for multilingual natural language processing (NLP) treat language as a discrete category, and make predictions for either one language or the other. In contrast, we propose using continuous vector representations of language. We show that these can be learned efficiently with a character-based neural language model, and used to improve inference about language varieties not seen during training. In experiments with 1303 Bible translations into 990 different languages, we empirically explore the capacity of multilingual language models, and also show that the language vectors capture genetic relationships between languages. version:1
arxiv-1203-3896 | Fast and Adaptive Sparse Precision Matrix Estimation in High Dimensions | http://arxiv.org/abs/1203.3896 | id:1203.3896 author:Weidong Liu, Xi Luo category:stat.ME math.ST stat.AP stat.CO stat.ML stat.TH  published:2012-03-17 summary:This paper proposes a new method for estimating sparse precision matrices in the high dimensional setting. It has been popular to study fast computation and adaptive procedures for this problem. We propose a novel approach, called Sparse Column-wise Inverse Operator, to address these two issues. We analyze an adaptive procedure based on cross validation, and establish its convergence rate under the Frobenius norm. The convergence rates under other matrix norms are also established. This method also enjoys the advantage of fast computation for large-scale problems, via a coordinate descent algorithm. Numerical merits are illustrated using both simulated and real datasets. In particular, it performs favorably on an HIV brain tissue dataset and an ADHD resting-state fMRI dataset. version:2
arxiv-1612-07454 | How to Train Your Deep Neural Network with Dictionary Learning | http://arxiv.org/abs/1612.07454 | id:1612.07454 author:Vanika Singhal, Shikha Singh, Angshul Majumdar category:cs.LG stat.ML  published:2016-12-22 summary:Currently there are two predominant ways to train deep neural networks. The first one uses restricted Boltzmann machine (RBM) and the second one autoencoders. RBMs are stacked in layers to form deep belief network (DBN); the final representation layer is attached to the target to complete the deep neural network. Autoencoders are nested one inside the other to form stacked autoencoders; once the stcaked autoencoder is learnt the decoder portion is detached and the target attached to the deepest layer of the encoder to form the deep neural network. This work proposes a new approach to train deep neural networks using dictionary learning as the basic building block; the idea is to use the features from the shallower layer as inputs for training the next deeper layer. One can use any type of dictionary learning (unsupervised, supervised, discriminative etc.) as basic units till the pre-final layer. In the final layer one needs to use the label consistent dictionary learning formulation for classification. We compare our proposed framework with existing state-of-the-art deep learning techniques on benchmark problems; we are always within the top 10 results. In actual problems of age and gender classification, we are better than the best known techniques. version:1
arxiv-1612-07453 | Deep Blind Compressed Sensing | http://arxiv.org/abs/1612.07453 | id:1612.07453 author:Shikha Singh, Vanika Singhal, Angshul Majumdar category:cs.CV G.1.6; I.4.5  published:2016-12-22 summary:This work addresses the problem of extracting deeply learned features directly from compressive measurements. There has been no work in this area. Existing deep learning tools only give good results when applied on the full signal, that too usually after preprocessing. These techniques require the signal to be reconstructed first. In this work we show that by learning directly from the compressed domain, considerably better results can be obtained. This work extends the recently proposed framework of deep matrix factorization in combination with blind compressed sensing; hence the term deep blind compressed sensing. Simulation experiments have been carried out on imaging via single pixel camera, under-sampled biomedical signals, arising in wireless body area network and compressive hyperspectral imaging. In all cases, the superiority of our proposed deep blind compressed sensing can be envisaged. version:1
arxiv-1612-07429 | Physically-Based Rendering for Indoor Scene Understanding Using Convolutional Neural Networks | http://arxiv.org/abs/1612.07429 | id:1612.07429 author:Yinda Zhang, Shuran Song, Ersin Yumer, Manolis Savva, Joon-Young Lee, Hailin Jin, Thomas Funkhouser category:cs.CV  published:2016-12-22 summary:Indoor scene understanding is central to applications such as robot navigation and human companion assistance. Over the last years, data-driven deep neural networks have outperformed many traditional approaches thanks to their representation learning capabilities. One of the bottlenecks in training for better representations is the amount of available per-pixel ground truth data that is required for core scene understanding tasks such as semantic segmentation, normal prediction, and object edge detection. To address this problem, a number of works proposed using synthetic data. However, a systematic study of how such synthetic data is generated is missing. In this work, we introduce a large-scale synthetic dataset with 400K physically-based rendered images from 45K realistic 3D indoor scenes. We study the effects of rendering methods and scene lighting on training for three computer vision tasks: surface normal prediction, semantic segmentation, and object boundary detection. This study provides insights into the best practices for training with synthetic data (more realistic rendering is worth it) and shows that pretraining with our new synthetic dataset can improve results beyond the current state of the art on all three tasks. version:1
arxiv-1612-07411 | A Context-aware Attention Network for Interactive Question Answering | http://arxiv.org/abs/1612.07411 | id:1612.07411 author:Huayu Li, Martin Renqiang Min, Yong Ge, Asim Kadav category:cs.CL cs.LG  published:2016-12-22 summary:We develop a new model for Interactive Question Answering (IQA), using Gated-Recurrent-Unit recurrent networks (GRUs) as encoders for statements and questions, and another GRU as a decoder for outputs. Distinct from previous work, our approach employs context-dependent word-level attention for more accurate statement representations and question-guided sentence-level attention for better context modeling. Employing these mechanisms, our model accurately understands when it can output an answer or when it requires generating a supplementary question for additional input. When available, user's feedback is encoded and directly applied to update sentence-level attention to infer the answer. Extensive experiments on QA and IQA datasets demonstrate quantitatively the effectiveness of our model with significant improvement over conventional QA models. version:1
arxiv-1612-07403 | Efficient Action Detection in Untrimmed Videos via Multi-Task Learning | http://arxiv.org/abs/1612.07403 | id:1612.07403 author:Yi Zhu, Shawn Newsam category:cs.CV cs.MM  published:2016-12-22 summary:This paper studies the joint learning of action recognition and temporal localization in long, untrimmed videos. We employ a multi-task learning framework that performs the three highly related steps of action proposal, action recognition, and action localization refinement in parallel instead of the standard sequential pipeline that performs the steps in order. We develop a novel temporal actionness regression module that estimates what proportion of a clip contains action. We use it for temporal localization but it could have other applications like video retrieval, surveillance, summarization, etc. We also introduce random shear augmentation during training to simulate viewpoint change. We evaluate our framework on three popular video benchmarks. Results demonstrate that our joint model is efficient in terms of storage and computation in that we do not need to compute and cache dense trajectory features, and that it is several times faster than its sequential ConvNets counterpart. Yet, despite being more efficient, it outperforms state-of-the-art methods with respect to accuracy. version:1
arxiv-1612-07401 | Microstructure Representation and Reconstruction of Heterogeneous Materials via Deep Belief Network for Computational Material Design | http://arxiv.org/abs/1612.07401 | id:1612.07401 author:Ruijin Cang, Yaopengxiao Xu, Shaohua Chen, Yongming Liu, Yang Jiao, Max Yi Ren category:cs.LG stat.ML  published:2016-12-22 summary:Integrated Computational Materials Engineering (ICME) aims to accelerate optimal design of complex material systems by integrating material science and design automation. For tractable ICME, it is required that (1) a structural feature space be identified to allow reconstruction of new designs, and (2) the reconstruction process be property-preserving. The majority of existing structural presentation schemes rely on the designer's understanding of specific material systems to identify geometric and statistical features, which could be biased and insufficient for reconstructing physically meaningful microstructures of complex material systems. In this paper, we develop a feature learning mechanism based on convolutional deep belief network to automate a two-way conversion between microstructures and their lower-dimensional feature representations, and to achieves a 1000-fold dimension reduction from the microstructure space. The proposed model is applied to a wide spectrum of heterogeneous material systems with distinct microstructural features including Ti-6Al-4V alloy, Pb63-Sn37 alloy, Fontainebleau sandstone, and Spherical colloids, to produce material reconstructions that are close to the original samples with respect to 2-point correlation functions and mean critical fracture strength. This capability is not achieved by existing synthesis methods that rely on the Markovian assumption of material microstructures. version:1
arxiv-1612-07379 | Automatic Identification of Scenedesmus Polymorphic Microalgae from Microscopic Images | http://arxiv.org/abs/1612.07379 | id:1612.07379 author:Jhony-Heriberto Giraldo-Zuluaga, Geman Diez, Alexander Gomez, Tatiana Martinez, Mariana Peñuela Vasquez, Jesus Francisco Vargas Bonilla, Augusto Salazar category:cs.CV  published:2016-12-21 summary:Microalgae counting is used to measure biomass quantity. Usually, it is performed in a manual way using a Neubauer chamber and expert criterion, with the risk of a high error rate. This paper addresses the methodology for automatic identification of Scenedesmus microalgae (used in the methane production and food industry) and applies it to images captured by a digital microscope. The use of contrast adaptive histogram equalization for pre-processing, and active contours for segmentation are presented. The calculation of statistical features (Histogram of Oriented Gradients, Hu and Zernike moments) with texture features (Haralick and Local Binary Patterns descriptors) are proposed for algae characterization. Scenedesmus algae can build coenobia consisting of 1, 2, 4 and 8 cells. The amount of algae of each coenobium helps to determine the amount of lipids, proteins, and other substances in a given sample of a algae crop. The knowledge of the quantity of those elements improves the quality of bioprocess applications. Classification of coenobia achieves accuracies of 98.63% and 97.32% with Support Vector Machine (SVM) and Artificial Neural Network (ANN), respectively. According to the results it is possible to consider the proposed methodology as an alternative to the traditional technique for algae counting. The database used in this paper is publicly available for download. version:1
arxiv-1612-07374 | Detecting Unusual Input-Output Associations in Multivariate Conditional Data | http://arxiv.org/abs/1612.07374 | id:1612.07374 author:Charmgil Hong, Milos Hauskrecht category:cs.LG stat.ML  published:2016-12-21 summary:Despite tremendous progress in outlier detection research in recent years, the majority of existing methods are designed only to detect unconditional outliers that correspond to unusual data patterns expressed in the joint space of all data attributes. Such methods are not applicable when we seek to detect conditional outliers that reflect unusual responses associated with a given context or condition. This work focuses on multivariate conditional outlier detection, a special type of the conditional outlier detection problem, where data instances consist of multi-dimensional input (context) and output (responses) pairs. We present a novel outlier detection framework that identifies abnormal input-output associations in data with the help of a decomposable conditional probabilistic model that is learned from all data instances. Since components of this model can vary in their quality, we combine them with the help of weights reflecting their reliability in assessment of outliers. We study two ways of calculating the component weights: global that relies on all data, and local that relies only on instances similar to the target instance. Experimental results on data from various domains demonstrate the ability of our framework to successfully identify multivariate conditional outliers. version:1
arxiv-1612-07360 | Top-down Visual Saliency Guided by Captions | http://arxiv.org/abs/1612.07360 | id:1612.07360 author:Vasili Ramanishka, Abir Das, Jianming Zhang, Kate Saenko category:cs.CV  published:2016-12-21 summary:Top-down saliency methods based on deep neural networks have recently been proposed for task-driven visual search. However existing methods focus on object or scene classification tasks and cannot be used to compute saliency heatmaps using a natural language sentence as the top-down input. Current state-of-the-art image and video captioning models can generate accurate sentence captions but are difficult to understand, as they do not expose the internal process by which spatial and temporal regions are mapped to predicted words. In this paper, we expose this mapping and demonstrate that spatio-temporal saliency is learned implicitly by the combination of CNN and LSTM parts of modern encoder-decoder networks. Our approach, which we call Caption-Guided Visual Saliency, can produce spatial or spatio-temporal heatmaps for both given input sentences or sentences predicted by our model. Unlike recent efforts that introduce explicit "attention" layers to selectively attend to certain inputs while generating each word, our approach recovers saliency without the overhead of explicit attention layers, and can be used to analyze a variety of existing model architectures and improve their design. We evaluate our approach on large scale video and image datasets and make several interesting discoveries about the inner workings of captioning models. The source code is publicly available at github.com/VisionLearningGroup/caption-guided-saliency. version:1
arxiv-1612-07335 | Distributed Dictionary Learning | http://arxiv.org/abs/1612.07335 | id:1612.07335 author:Amir Daneshmand, Gesualdo Scutari, Francisco Facchinei category:math.OC cs.LG  published:2016-12-21 summary:The paper studies distributed Dictionary Learning (DL) problems where the learning task is distributed over a multi-agent network with time-varying (nonsymmetric) connectivity. This formulation is relevant, for instance, in big-data scenarios where massive amounts of data are collected/stored in different spatial locations and it is unfeasible to aggregate and/or process all the data in a fusion center, due to resource limitations, communication overhead or privacy considerations. We develop a general distributed algorithmic framework for the (nonconvex) DL problem and establish its asymptotic convergence. The new method hinges on Successive Convex Approximation (SCA) techniques coupled with i) a gradient tracking mechanism instrumental to locally estimate the missing global information; and ii) a consensus step, as a mechanism to distribute the computations among the agents. To the best of our knowledge, this is the first distributed algorithm with provable convergence for the DL problem and, more in general, bi-convex optimization problems over (time-varying) directed graphs. version:1
arxiv-1607-03854 | The Partially Observable Hidden Markov Model and its Application to Keystroke Dynamics | http://arxiv.org/abs/1607.03854 | id:1607.03854 author:John V. Monaco, Charles C. Tappert category:cs.IT cs.CR math.IT stat.ML  published:2016-07-13 summary:The partially observable hidden Markov model is an extension of the hidden Markov Model in which the hidden states are conditioned on an independent Markov chain. The structure of the POHMM is motivated by sequences that contain discrete metadata, such as an event type, that partially reveal the underlying hidden state. Such a scenario is encountered in keystroke dynamics. Under the assumption that the user can be in either an active or passive state of typing, the keyboard key names are event types that partially reveal the hidden state due to the presence of relatively longer time intervals between words and sentences than between letters of a word. Using five public datasets, the proposed model is shown to consistently outperform other anomaly detectors, including the standard HMM, in biometric identification and verification tasks and is generally preferred over the HMM in a Monte Carlo goodness of fit test. version:4
arxiv-1612-07307 | Loss is its own Reward: Self-Supervision for Reinforcement Learning | http://arxiv.org/abs/1612.07307 | id:1612.07307 author:Evan Shelhamer, Parsa Mahmoudieh, Max Argus, Trevor Darrell category:cs.LG  published:2016-12-21 summary:Reinforcement learning, driven by reward, addresses tasks by optimizing policies for expected return. Need the supervision be so narrow? Reward is delayed and sparse for many tasks, so we argue that reward alone is a difficult and impoverished signal for end-to-end optimization. To augment reward, we consider a range of self-supervised tasks that incorporate states, actions, and successors to provide auxiliary losses. These losses offer ubiquitous and instantaneous supervision for representation learning even in the absence of reward. While current results show that learning from reward alone is feasible, pure reinforcement learning methods are constrained by computational and data efficiency issues that can be remedied by auxiliary losses. Self-supervised pre-training improves the data efficiency and policy returns of end-to-end reinforcement learning. version:1
arxiv-1612-07725 | Stacking machine learning classifiers to identify Higgs bosons at the LHC | http://arxiv.org/abs/1612.07725 | id:1612.07725 author:Alexandre Alves category:hep-ph cs.LG physics.data-an  published:2016-12-21 summary:Machine learning (ML) algorithms have been employed in the problem of classifying signal and background events with high accuracy in particle physics. In this paper, we use a widespread ML technique, namely, \emph{stacked generalization}, for the task of discovering a new neutral Higgs boson in gluon fusion. We found that, at the same time it demands far less computation efforts, \emph{stacking} ML algorithms performs almost as well as deep neural networks (DNN) trained exclusively with kinematic distributions for the same task by building either a highly discriminating linear model or a shallower neural network with stacked ML outputs. We also show that it is possible to outperform DNN in this channel by partially exploring correlations among the classifiers outputs in a multivariate statistical analysis. version:1
arxiv-1612-07222 | Bayesian Decision Process for Cost-Efficient Dynamic Ranking via Crowdsourcing | http://arxiv.org/abs/1612.07222 | id:1612.07222 author:Xi Chen, Kevin Jiao, Qihang Lin category:stat.ML cs.LG stat.ME  published:2016-12-21 summary:Rank aggregation based on pairwise comparisons over a set of items has a wide range of applications. Although considerable research has been devoted to the development of rank aggregation algorithms, one basic question is how to efficiently collect a large amount of high-quality pairwise comparisons for the ranking purpose. Because of the advent of many crowdsourcing services, a crowd of workers are often hired to conduct pairwise comparisons with a small monetary reward for each pair they compare. Since different workers have different levels of reliability and different pairs have different levels of ambiguity, it is desirable to wisely allocate the limited budget for comparisons among the pairs of items and workers so that the global ranking can be accurately inferred from the comparison results. To this end, we model the active sampling problem in crowdsourced ranking as a Bayesian Markov decision process, which dynamically selects item pairs and workers to improve the ranking accuracy under a budget constraint. We further develop a computationally efficient sampling policy based on knowledge gradient as well as a moment matching technique for posterior approximation. Experimental evaluations on both synthetic and real data show that the proposed policy achieves high ranking accuracy with a lower labeling cost. version:1
arxiv-1612-07217 | Learning Motion Patterns in Videos | http://arxiv.org/abs/1612.07217 | id:1612.07217 author:Pavel Tokmakov, Karteek Alahari, Cordelia Schmid category:cs.CV  published:2016-12-21 summary:The problem of determining whether an object is in motion, irrespective of the camera motion, is far from being solved. We address this challenging task by learning motion patterns in videos. The core of our approach is a fully convolutional network, which is learnt entirely from synthetic video sequences, and their ground-truth optical flow and motion segmentation. This encoder-decoder style architecture first learns a coarse representation of the optical flow field features, and then refines it iteratively to produce motion labels at the original high-resolution. The output label of each pixel denotes whether it has undergone independent motion, i.e., irrespective of the camera motion. We demonstrate the benefits of this learning framework on the moving object segmentation task, where the goal is to segment all the objects in motion. To this end we integrate an objectness measure into the framework. Our approach outperforms the top method on the recently released DAVIS benchmark dataset, comprising real-world sequences, by 5.6%. We also evaluate on the Berkeley motion segmentation database, achieving state-of-the-art results. version:1
arxiv-1612-07215 | Inverted Bilingual Topic Models for Lexicon Extraction from Non-parallel Data | http://arxiv.org/abs/1612.07215 | id:1612.07215 author:Tengfei Ma category:cs.CL  published:2016-12-21 summary:A good lexicon is an important resource for various cross-lingual tasks such as information retrieval and text mining. In this paper, we focus on extracting translation pairs from non-parallel cross-lingual corpora. Previous lexicon extraction algorithms for non-parallel data generally rely on an accurate seed dictionary and extract translation pairs by using context similarity. However, there are two problems. One, a lot of semantic information is lost if we just use seed dictionary words to construct context vectors and obtain the context similarity. Two, in practice, we may not have a clean seed dictionary. For example, if we use a generic dictionary as a seed dictionary in a special domain, it might be very noisy. To solve these two problems, we propose two new bilingual topic models to better capture the semantic information of each word while discriminating the multiple translations in a noisy seed dictionary. We then use an effective measure to evaluate the similarity of words in different languages and select the optimal translation pairs. Results of experiments using real Japanese-English data demonstrate the effectiveness of our models. version:1
arxiv-1612-07182 | Multi-Agent Cooperation and the Emergence of (Natural) Language | http://arxiv.org/abs/1612.07182 | id:1612.07182 author:Angeliki Lazaridou, Alexander Peysakhovich, Marco Baroni category:cs.CL cs.CV cs.GT cs.LG cs.MA  published:2016-12-21 summary:The current mainstream approach to train natural language systems is to expose them to large amounts of text. This passive learning is problematic if we are interested in developing interactive machines, such as conversational agents. We propose a framework for language learning that relies on multi-agent communication. We study this learning in the context of referential games. In these games, a sender and a receiver see a pair of images. The sender is told one of them is the target and is allowed to send a message from a fixed, arbitrary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of the need to communicate. We show that two networks with simple configurations are able to learn to coordinate in the referential game. We further explore how to make changes to the game environment to cause the "word meanings" induced in the game to better reflect intuitive semantic properties of the images. In addition, we present a simple strategy for grounding the agents' code into natural language. Both of these are necessary steps towards developing machines that are able to communicate with humans productively. version:1
arxiv-1612-07180 | A Unified Framework for Tumor Proliferation Score Prediction in Breast Histopathology | http://arxiv.org/abs/1612.07180 | id:1612.07180 author:Kyunghyun Paeng, Sangheum Hwang, Sunggyun Park, Minsoo Kim, Seokhwi Kim category:cs.CV  published:2016-12-21 summary:Predicting tumor proliferation scores is an important biomarker indicative of breast cancer patients' prognosis. In this paper, we present a unified framework to predict tumor proliferation scores from whole slide images in breast histopathology. The proposed system is offers a fully automated solution to predicting both a molecular data based, and a mitosis counting based tumor proliferation score. The framework integrates three modules, each fine-tuned to maximize the overall performance: an image processing component for handling whole slide images, a deep learning based mitosis detection network, and a proliferation scores prediction module. We have achieved 0.567 quadratic weighted Cohen's kappa in mitosis counting based score prediction and 0.652 F1-score in mitosis detection. On Spearman's correlation coefficient, which evaluates prediction on the molecular data based score, the system obtained 0.6171. Our system won first place in all of the three tasks in Tumor Proliferation Assessment Challenge at MICCAI 2016, outperforming all other approaches. version:1
arxiv-1612-07153 | Trilaminar Multiway Reconstruction Tree for Efficient Large Scale Structure from Motion | http://arxiv.org/abs/1612.07153 | id:1612.07153 author:Kun Sun, Wenbing Tao category:cs.CV  published:2016-12-21 summary:Accuracy and efficiency are two key problems in large scale incremental Structure from Motion (SfM). In this paper, we propose a unified framework to divide the image set into clusters suitable for reconstruction as well as find multiple reliable and stable starting points. Image partitioning performs in two steps. First, some small image groups are selected at places with high image density, and then all the images are clustered according to their optimal reconstruction paths to these image groups. This promises that the scene is always reconstructed from dense places to sparse areas, which can reduce error accumulation when images have weak overlap. To enable faster speed, images outside the selected group in each cluster are further divided to achieve a greater degree of parallelism. Experiments show that our method achieves significant speedup, higher accuracy and better completeness. version:1
arxiv-1612-07603 | Difficulty Adjustable and Scalable Constrained Multi-objective Test Problem Toolkit | http://arxiv.org/abs/1612.07603 | id:1612.07603 author:Zhun Fan, Wenji Li, Xinye Cai, Hui Li, Kaiwen Hu, Qingfu Zhang, Kalyanmoy Deb, Erik D. Goodman category:cs.NE cs.AI  published:2016-12-21 summary:In order to better understand the advantages and disadvantages of a constrained multi-objective evolutionary algorithm (CMOEA), it is important to understand the nature of difficulty of a constrained multi-objective optimization problem (CMOP) that the CMOEA is going to deal with. In this paper, we first propose three primary types of difficulty to characterize the constraints in CMOPs, including feasibility-hardness, convergence-hardness and diversity-hardness. We then develop a general toolkit to construct difficulty adjustable CMOPs with three types of parameterized constraint functions according to the proposed three primary types of difficulty. In fact, combination of the three primary constraint functions with different parameters can lead to construct a large variety of CMOPs and CMaOPs, whose difficulty can be uniquely defined by a triplet with each of its parameter specifying the level of each primary difficulty type respectively. Based on this toolkit, we suggest fifteen difficulty adjustable CMOPs named DAC-MOP1-15 with different types and levels of difficulty. To study the effectiveness of DAC-MOP1-15, two popular CMOEAs - MOEA/D-CDP and NSGA-II-CDP are adopted to test their performances on them. Furthermore, this toolkit also has the ability to scale the number of objectives. Nine difficulty adjustable constrained many-objective optimization problems (DAC-MaOPs) named DAC-MaOP1-9 with the scalability to the number of objectives are also proposed using this toolkit. Two constrained many-objective evolutionary algorithms (CMaOEAs) - CNSGA-III and CMOEA/DD are applied to test their performances on three, five, seven and ten-objective DAC-MaOP1-9 with different difficulty levels and types. version:1
arxiv-1612-07146 | Collaborative Filtering with User-Item Co-Autoregressive Models | http://arxiv.org/abs/1612.07146 | id:1612.07146 author:Chao Du, Chongxuan Li, Yin Zheng, Jun Zhu, Cailiang Liu, Hanning Zhou, Bo Zhang category:cs.LG  published:2016-12-21 summary:Besides the success on object recognition, machine translation and system control in games, (deep) neural networks have achieved state-of-the-art results in collaborative filtering (CF) recently. Previous neural approaches for CF are either user-based or item-based, which cannot leverage all relevant information explicitly. We propose CF-UIcA, a neural co-autoregressive model for CF tasks, which exploit the structural autoregressiveness in the domains of both users and items. Furthermore, we separate the inherent dependence in this structure under a natural assumption and develop an efficient stochastic learning algorithm to handle large scale datasets. We evaluate CF-UIcA on two popular benchmarks: MovieLens 1M and Netflix, and achieve state-of-the-art predictive performance, which demonstrates the effectiveness of CF-UIcA. version:1
arxiv-1612-07141 | Robust Classification of Graph-Based Data | http://arxiv.org/abs/1612.07141 | id:1612.07141 author:Carlos M. Alaíz, Michaël Fanuel, Johan A. K. Suykens category:cs.LG  published:2016-12-21 summary:A graph-based classification method is proposed both for semi-supervised learning in the case of Euclidean data and for classification in the case of graph data. Our manifold learning technique is based on a convex optimization problem involving a convex regularization term and a concave loss function with a trade-off parameter carefully chosen so that the objective function remains convex. As shown experimentally, the advantage of considering a concave loss function is that the learning problem becomes more robust in the presence of noisy labels. Furthermore, the loss function considered is then more similar to a classification loss while several other methods treat graph-based classification problems as regression problems. version:1
arxiv-1612-07130 | Sparse Coding of Neural Word Embeddings for Multilingual Sequence Labeling | http://arxiv.org/abs/1612.07130 | id:1612.07130 author:Gábor Berend category:cs.CL  published:2016-12-21 summary:In this paper we propose and carefully evaluate a sequence labeling framework which solely utilizes sparse indicator features derived from dense distributed word representations. The proposed model obtains (near) state-of-the art performance for both part-of-speech tagging and named entity recognition for a variety of languages. Our model relies only on a few thousand sparse coding-derived features, without applying any modification of the word representations employed for the different tasks. The proposed model has favorable generalization properties as it retains over 89.8% of its average POS tagging accuracy when trained at 1.2% of the total available training data, i.e.~150 sentences per language. version:1
arxiv-1612-05730 | Towards Wide Learning: Experiments in Healthcare | http://arxiv.org/abs/1612.05730 | id:1612.05730 author:Snehasis Banerjee, Tanushyam Chattopadhyay, Swagata Biswas, Rohan Banerjee, Anirban Dutta Choudhury, Arpan Pal, Utpal Garain category:stat.ML cs.LG  published:2016-12-17 summary:In this paper, a Wide Learning architecture is proposed that attempts to automate the feature engineering portion of the machine learning (ML) pipeline. Feature engineering is widely considered as the most time consuming and expert knowledge demanding portion of any ML task. The proposed feature recommendation approach is tested on 3 healthcare datasets: a) PhysioNet Challenge 2016 dataset of phonocardiogram (PCG) signals, b) MIMIC II blood pressure classification dataset of photoplethysmogram (PPG) signals and c) an emotion classification dataset of PPG signals. While the proposed method beats the state of the art techniques for 2nd and 3rd dataset, it reaches 94.38% of the accuracy level of the winner of PhysioNet Challenge 2016. In all cases, the effort to reach a satisfactory performance was drastically less (a few days) than manual feature engineering. version:2
arxiv-1612-07089 | Stochastic Multidimensional Scaling | http://arxiv.org/abs/1612.07089 | id:1612.07089 author:Ketan Rajawat, Sandeep Kumar category:math.OC cs.CV  published:2016-12-21 summary:Multidimensional scaling (MDS) is a popular dimensionality reduction techniques that has been widely used for network visualization and cooperative localization. However, the traditional stress minimization formulation of MDS necessitates the use of batch optimization algorithms that are not scalable to large-sized problems. This paper considers an alternative stochastic stress minimization framework that is amenable to incremental and distributed solutions. A novel linear-complexity stochastic optimization algorithm is proposed that is provably convergent and simple to implement. The applicability of the proposed algorithm to localization and visualization tasks is also expounded. Extensive tests on synthetic and real datasets demonstrate the efficacy of the proposed algorithm. version:1
arxiv-1612-07086 | Recurrent Highway Networks with Language CNN for Image Captioning | http://arxiv.org/abs/1612.07086 | id:1612.07086 author:Jiuxiang Gu, Gang Wang, Tsuhan Chen category:cs.CV cs.LG  published:2016-12-21 summary:In this paper, we propose a Recurrent Highway Network with Language CNN for image caption generation. Our network consists of three sub-networks: the deep Convolutional Neural Network for image representation, the Convolutional Neural Network for language modeling, and the Multimodal Recurrent Highway Network for sequence prediction. Our proposed model can naturally exploit the hierarchical and temporal structure of history words, which are critical for image caption generation. The effectiveness of our model is validated on two datasets MS COCO and Flickr30K. Our extensive experiment results show that our method is competitive with the state-of-the-art methods. version:1
arxiv-1612-07040 | A deep learning approach for predicting the quality of online health expert question-answering services | http://arxiv.org/abs/1612.07040 | id:1612.07040 author:Ze Hu, Zhan Zhang, Qing Chen, Haiqin Yang, Decheng Zuo category:cs.IR cs.CL  published:2016-12-21 summary:Currently, a growing number of health consumers are asking health-related questions online, at any time and from anywhere, which effectively lowers the cost of health care. The most common approach is using online health expert question-answering (HQA) services, as health consumers are more willing to trust answers from professional physicians. However, these answers can be of varying quality depending on circumstance. In addition, as the available HQA services grow, how to predict the answer quality of HQA services via machine learning becomes increasingly important and challenging. In an HQA service, answers are normally short texts, which are severely affected by the data sparsity problem. Furthermore, HQA services lack community features such as best answer and user votes. Therefore, the wisdom of the crowd is not available to rate answer quality. To address these problems, in this paper, the prediction of HQA answer quality is defined as a classification task. First, based on the characteristics of HQA services and feedback from medical experts, a standard for HQA service answer quality evaluation is defined. Next, based on the characteristics of HQA services, several novel non-textual features are proposed, including surface linguistic features and social features. Finally, a deep belief network (DBN)-based HQA answer quality prediction framework is proposed to predict the quality of answers by learning the high-level hidden semantic representation from the physicians' answers. Our results prove that the proposed framework overcomes the problem of overly sparse textual features in short text answers and effectively identifies high-quality answers. version:1
arxiv-1612-07029 | Scale-invariance of ruggedness measures in fractal fitness landscapes | http://arxiv.org/abs/1612.07029 | id:1612.07029 author:Hendrik Richter category:nlin.CD cs.NE q-bio.PE  published:2016-12-21 summary:The paper deals with using chaos to direct trajectories to targets and analyzes ruggedness and fractality of the resulting fitness landscapes. The targeting problem is formulated as a dynamic fitness landscape and four different chaotic maps generating such a landscape are studied. By using a computational approach, we analyze properties of the landscapes and quantify their fractal and rugged characteristics. In particular, it is shown that ruggedness measures such as correlation length and information content are scale-invariant and self-similar. version:1
arxiv-1612-05555 | Neural Networks Classifier for Data Selection in Statistical Machine Translation | http://arxiv.org/abs/1612.05555 | id:1612.05555 author:Álvaro Peris, Mara Chinea-Rios, Francisco Casacuberta category:cs.CL  published:2016-12-16 summary:We address the data selection problem in statistical machine translation (SMT) as a classification task. The new data selection method is based on a neural network classifier. We present a new method description and empirical results proving that our data selection method provides better translation quality, compared to a state-of-the-art method (i.e., Cross entropy). Moreover, the empirical results reported are coherent across different language pairs. version:2
arxiv-1612-07019 | Robust Learning with Kernel Mean p-Power Error Loss | http://arxiv.org/abs/1612.07019 | id:1612.07019 author:Badong Chen, Lei Xing, Xin Wang, Jing Qin, Nanning Zheng category:stat.ML cs.LG  published:2016-12-21 summary:Correntropy is a second order statistical measure in kernel space, which has been successfully applied in robust learning and signal processing. In this paper, we define a nonsecond order statistical measure in kernel space, called the kernel mean-p power error (KMPE), including the correntropic loss (CLoss) as a special case. Some basic properties of KMPE are presented. In particular, we apply the KMPE to extreme learning machine (ELM) and principal component analysis (PCA), and develop two robust learning algorithms, namely ELM-KMPE and PCA-KMPE. Experimental results on synthetic and benchmark data show that the developed algorithms can achieve consistently better performance when compared with some existing methods. version:1
arxiv-1612-07003 | Image biomarker standardisation initiative - feature definitions | http://arxiv.org/abs/1612.07003 | id:1612.07003 author:Alex Zwanenburg, Stefan Leger, Martin Vallières, Steffen Löck, for the Image Biomar category:cs.CV  published:2016-12-21 summary:While analysis of medical images has practically taken place since the first image was recorded, high throughput analysis of medical images is a more recent phenomenon. The aim of such a radiomics process is to provide decision support based on medical imaging. Part of the radiomics process is the conversion of image data into numerical features which capture different medical image aspects, and can be subsequently correlated as biomarkers to e.g. expected oncological treatment outcome. With the growth of the radiomics field, it has become clear that results are often difficult to reproduce, that standards for image processing and feature extraction are missing, and that reporting guidelines are absent. The image biomarker standardisation initiative (IBSI) seeks to address these issues. The current document provides definitions for a large number of image features. version:1
arxiv-1612-05000 | Development of a Real-time Colorectal Tumor Classification System for Narrow-band Imaging zoom-videoendoscopy | http://arxiv.org/abs/1612.05000 | id:1612.05000 author:Tsubasa Hirakawa, Toru Tamaki, Bisser Raytchev, Kazufumi Kaneda, Tetsushi Koide, Shigeto Yoshida, Hiroshi Mieno, Shinji Tanaka category:cs.CV  published:2016-12-15 summary:Colorectal endoscopy is important for the early detection and treatment of colorectal cancer and is used worldwide. A computer-aided diagnosis (CAD) system that provides an objective measure to endoscopists during colorectal endoscopic examinations would be of great value. In this study, we describe a newly developed CAD system that provides real-time objective measures. Our system captures the video stream from an endoscopic system and transfers it to a desktop computer. The captured video stream is then classified by a pretrained classifier and the results are displayed on a monitor. The experimental results show that our developed system works efficiently in actual endoscopic examinations and is medically significant. version:2
arxiv-1612-06962 | Stochastic Runtime Analysis of a Cross Entropy Algorithm for Traveling Salesman Problems | http://arxiv.org/abs/1612.06962 | id:1612.06962 author:Zijun Wu, Rolf Moehring, Jianhui Lai category:cs.DS cs.AI cs.NE  published:2016-12-21 summary:This article analyzes the stochastic runtime of a Cross-Entropy Algorithm on two classes of traveling salesman problems. The algorithm shares main features of the famous Max-Min Ant System with iteration-best reinforcement. For simple instances that have a $\{1,n\}$-valued distance function and a unique optimal solution, we prove a stochastic runtime of $O(n^{6+\epsilon})$ with the vertex-based random solution generation, and a stochastic runtime of $O(n^{3+\epsilon}\ln n)$ with the edge-based random solution generation for an arbitrary $\epsilon\in (0,1)$. These runtimes are very close to the known expected runtime for variants of Max-Min Ant System with best-so-far reinforcement. They are obtained for the stronger notion of stochastic runtime, which means that an optimal solution is obtained in that time with an overwhelming probability, i.e., a probability tending exponentially fast to one with growing problem size. We also inspect more complex instances with $n$ vertices positioned on an $m\times m$ grid. When the $n$ vertices span a convex polygon, we obtain a stochastic runtime of $O(n^{3}m^{5+\epsilon})$ with the vertex-based random solution generation, and a stochastic runtime of $O(n^{2}m^{5+\epsilon})$ for the edge-based random solution generation. When there are $k = O(1)$ many vertices inside a convex polygon spanned by the other $n-k$ vertices, we obtain a stochastic runtime of $O(n^{4}m^{5+\epsilon}+n^{6k-1}m^{\epsilon})$ with the vertex-based random solution generation, and a stochastic runtime of $O(n^{3}m^{5+\epsilon}+n^{3k}m^{\epsilon})$ with the edge-based random solution generation. These runtimes are better than the expected runtime for the so-called $(\mu\!+\!\lambda)$ EA reported in a recent article, and again obtained for the stronger notion of stochastic runtime. version:1
arxiv-1612-06950 | Temporal Tessellation for Video Annotation and Summarization | http://arxiv.org/abs/1612.06950 | id:1612.06950 author:Dotan Kaufman, Gil Levi, Tal Hassner, Lior Wolf category:cs.CV  published:2016-12-21 summary:We present a general approach to video understanding, inspired by semantic transfer techniques successfully used for 2D image understanding. Our method considers a video to be a 1D sequence of clips, each one associated with its own semantics. The nature of these semantics -- natural language captions or other labels -- depends on the task at hand. A test video is processed by forming correspondences between its clips and the clips of reference videos with known semantics, following which, reference semantics can be transferred to the test video. We describe two matching methods, both designed to ensure that (a) reference clips appear similar to test clips and (b), taken together, the semantics of selected reference clips is consistent and maintains temporal coherence. We use our method for video captioning on the LSMDC'16 benchmark and video summarization on the SumMe benchmark. In both cases, our method not only surpasses state of the art results, but importantly, it is the only method we know of that was successfully applied to both video understanding tasks. version:1
arxiv-1612-05628 | A New Softmax Operator for Reinforcement Learning | http://arxiv.org/abs/1612.05628 | id:1612.05628 author:Kavosh Asadi, Michael L. Littman category:cs.AI cs.LG stat.ML  published:2016-12-16 summary:A softmax operator applied to a set of values acts somewhat like the maximization function and somewhat like an average. In sequential decision making, softmax is often used in settings where it is necessary to maximize utility but also to hedge against problems that arise from putting all of one's weight behind a single maximum utility decision. The Boltzmann softmax operator is the most commonly used softmax operator in this setting, but we show that this operator is prone to misbehavior. In this work, we study an alternative softmax operator that, among other properties, is both a non-expansion (ensuring convergent behavior in learning and planning) and differentiable (making it possible to improve decisions via gradient descent methods). We provide proofs of these properties and present empirical comparisons between various softmax operators. version:3
arxiv-1612-06935 | Exploiting Rich Contents for Personalized Video Recommendation | http://arxiv.org/abs/1612.06935 | id:1612.06935 author:Xingzhong Du, Hongzhi Yin, Ling Chen, Yang Wang, Yi Yang, Xiaofang Zhou category:cs.IR cs.LG  published:2016-12-21 summary:Video recommendation has become an essential way of helping people explore the video world and discover the ones that may be of interest to them. However, mainstream collaborative filtering techniques usually suffer from limited performance due to the sparsity of user-video interactions, and hence are ineffective for new video recommendation. Although some recent recommender models such as CTR and CDL, have integrated text information to boost performance, user-generated videos typically include scarce or low-quality text information, which seriously degenerates performance. In this paper, we investigate how to leverage the non-textual content contained in videos to improve the quality of recommendations. We propose to first extract and encode the diverse audio, visual and action information that rich video content provides, then effectively incorporate these features with collaborative filtering using a collaborative embedding regression model (CER). We also study how to fuse multiple types of content features to further improve video recommendation using a novel fusion method that unifies both non-textual and textual features. We conducted extensive experiments on a large video dataset collected from multiple sources. The experimental results reveal that our proposed recommender model and feature fusion method outperform the state-of-the-art methods. version:1
arxiv-1612-06933 | Unsupervised Place Discovery for Visual Place Classification | http://arxiv.org/abs/1612.06933 | id:1612.06933 author:Fei Xiaoxiao, Tanaka Kanji, Inamoto Kouya category:cs.CV  published:2016-12-21 summary:In this study, we explore the use of deep convolutional neural networks (DCNNs) in visual place classification for robotic mapping and localization. An open question is how to partition the robot's workspace into places to maximize the performance (e.g., accuracy, precision, recall) of potential DCNN classifiers. This is a chicken and egg problem: If we had a well-trained DCNN classifier, it is rather easy to partition the robot's workspace into places, but the training of a DCNN classifier requires a set of pre-defined place classes. In this study, we address this problem and present several strategies for unsupervised discovery of place classes ("time cue," "location cue," "time-appearance cue," and "location-appearance cue"). We also evaluate the efficacy of the proposed methods using the publicly available University of Michigan North Campus Long-Term (NCLT) Dataset. version:1
arxiv-1612-06919 | A Statistical Approach to Continuous Self-Calibrating Eye Gaze Tracking for Head-Mounted Virtual Reality Systems | http://arxiv.org/abs/1612.06919 | id:1612.06919 author:Subarna Tripathi, Brian Guenter category:cs.CV  published:2016-12-20 summary:We present a novel, automatic eye gaze tracking scheme inspired by smooth pursuit eye motion while playing mobile games or watching virtual reality contents. Our algorithm continuously calibrates an eye tracking system for a head mounted display. This eliminates the need for an explicit calibration step and automatically compensates for small movements of the headset with respect to the head. The algorithm finds correspondences between corneal motion and screen space motion, and uses these to generate Gaussian Process Regression models. A combination of those models provides a continuous mapping from corneal position to screen space position. Accuracy is nearly as good as achieved with an explicit calibration step. version:1
arxiv-1612-06897 | Fast Domain Adaptation for Neural Machine Translation | http://arxiv.org/abs/1612.06897 | id:1612.06897 author:Markus Freitag, Yaser Al-Onaizan category:cs.CL  published:2016-12-20 summary:Neural Machine Translation (NMT) is a new approach for automatic translation of text from one human language into another. The basic concept in NMT is to train a large Neural Network that maximizes the translation performance on a given parallel corpus. NMT is gaining popularity in the research community because it outperformed traditional SMT approaches in several translation tasks at WMT and other evaluation tasks/benchmarks at least for some language pairs. However, many of the enhancements in SMT over the years have not been incorporated into the NMT framework. In this paper, we focus on one such enhancement namely domain adaptation. We propose an approach for adapting a NMT system to a new domain. The main idea behind domain adaptation is that the availability of large out-of-domain training data and a small in-domain training data. We report significant gains with our proposed method in both automatic metrics and a human subjective evaluation metric on two language pairs. With our adaptation method, we show large improvement on the new domain while the performance of our general domain only degrades slightly. In addition, our approach is fast enough to adapt an already trained system to a new domain within few hours without the need to retrain the NMT model on the combined data which usually takes several days/weeks depending on the volume of the data. version:1
arxiv-1612-06890 | CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning | http://arxiv.org/abs/1612.06890 | id:1612.06890 author:Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Lawrence Zitnick, Ross Girshick category:cs.CV cs.CL cs.LG  published:2016-12-20 summary:When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover shortcomings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations. version:1
arxiv-1612-06851 | Beyond Skip Connections: Top-Down Modulation for Object Detection | http://arxiv.org/abs/1612.06851 | id:1612.06851 author:Abhinav Shrivastava, Rahul Sukthankar, Jitendra Malik, Abhinav Gupta category:cs.CV cs.LG  published:2016-12-20 summary:In recent years, we have seen tremendous progress in the field of object detection. Most of the recent improvements have been achieved by targeting deeper feedforward networks. However, many hard object categories, such as bottle and remote, require representation of fine details and not coarse, semantic representations. But most of these fine details are lost in the early convolutional layers. What we need is a way to incorporate finer details from lower layers into the detection architecture. Skip connections have been proposed to combine high-level and low-level features, but we argue that selecting the right features from low-level requires top-down contextual information. Inspired by the human visual pathway, in this paper we propose top-down modulations as a way to incorporate fine details into the detection framework. Our approach supplements the standard bottom-up, feedforward ConvNet with a top-down modulation (TDM) network, connected using lateral connections. These connections are responsible for the modulation of lower layer filters, and the top-down network handles the selection and integration of features. The proposed architecture provides a significant boost on the COCO benchmark for VGG16, ResNet101, and InceptionResNet-v2 architectures. Preliminary experiments using InceptionResNet-v2 achieve 36.8 AP, which is the best performance to-date on the COCO benchmark using a single-model without any bells and whistles (e.g., multi-scale, iterative box refinement, etc.). version:1
arxiv-1612-06836 | Understanding Higher-Order Shape via 3D Shape Attributes | http://arxiv.org/abs/1612.06836 | id:1612.06836 author:David F. Fouhey, Abhinav Gupta, Andrew Zisserman category:cs.CV  published:2016-12-20 summary:In this paper we investigate 3D shape attributes as a means to understand the shape of an object in a single image. To this end, we make a number of contributions: (i) we introduce and define a set of 3D shape attributes, including planarity, symmetry and occupied space; (ii) we show that such properties can be successfully inferred from a single image using a Convolutional Neural Network (CNN); (iii) we introduce a 143K image dataset of sculptures with 2197 works over 242 artists for training and evaluating the CNN; (iv) we show that the 3D attributes trained on this dataset generalize to images of other (non-sculpture) object classes; (v) we show that the CNN also provides a shape embedding that can be used to match previously unseen sculptures largely independent of viewpoint; and furthermore (vi) we analyze how the CNN predicts these attributes. version:1
arxiv-1612-06825 | Center-Focusing Multi-task CNN with Injected Features for Classification of Glioma Nuclear Images | http://arxiv.org/abs/1612.06825 | id:1612.06825 author:Veda Murthy, Le Hou, Dimitris Samaras, Tahsin M. Kurc, Joel H. Saltz category:cs.CV  published:2016-12-20 summary:Classifying the various shapes and attributes of a glioma cell nucleus is crucial for diagnosis and understanding the disease. We investigate automated classification of glioma nuclear shapes and visual attributes using Convolutional Neural Networks (CNNs) on pathology images of automatically segmented nuclei. We propose three methods that improve the performance of a previously-developed semi-supervised CNN. First, we propose a method that allows the CNN to focus on the most important part of an image- the image's center containing the nucleus. Second, we inject (concatenate) pre-extracted VGG features into an intermediate layer of our Semi-Supervised CNN so that during training, the CNN can learn a set of complementary features. Third, we separate the losses of the two groups of target classes (nuclear shapes and attributes) into a single-label loss and a multi-label loss so that the prior knowledge of inter-label exclusiveness can be incorporated. On a dataset of 2078 images, the proposed methods combined reduce the error rate of attribute and shape classification by 21.54% and 15.07% respectively compared to the existing state-of-the-art method on the same dataset. version:1
arxiv-1612-06821 | User Bias Removal in Fine Grained Sentiment Analysis | http://arxiv.org/abs/1612.06821 | id:1612.06821 author:Rahul Wadbude, Vivek Gupta, Dheeraj Mekala, Janish Jindal, Harish Karnick category:cs.CL  published:2016-12-20 summary:Fine-grained sentiment analysis of text reviews has recently gained a lot of attention in the natural language processing community. Most work done earlier focuses on creating efficient feature representations of text reviews for classification. The methods generally ignore other common attributes like user identity, product identity, and helpfulness rating during fine-grained sentiment classification. A major problem in current classification models is noise due to the presence of user bias in review ratings. We propose two simple statistical methods to remove such noise and improve fine-grained sentiment classification. We apply our methods on the SNAP published Amazon Fine Food Reviews dataset and on two major categories Electronics and Movies and TV of the e-Commerce Reviews data-set. After removing user bias, we get improved fine-grained sentiment classification with three commonly used feature representations. version:1
arxiv-1612-06795 | Two decades of local binary patterns: A survey | http://arxiv.org/abs/1612.06795 | id:1612.06795 author:Matti Pietikäinen, Guoying Zhao category:cs.CV  published:2016-12-20 summary:Texture is an important characteristic for many types of images. In recent years very discriminative and computationally efficient local texture descriptors based on local binary patterns (LBP) have been developed, which has led to significant progress in applying texture methods to different problems and applications. Due to this progress, the division between texture descriptors and more generic image or video descriptors has been disappearing. A large number of different variants of LBP have been developed to improve its robustness, and to increase its discriminative power and applicability to different types of problems. In this chapter, the most recent and important variants of LBP in 2D, spatiotemporal, 3D, and 4D domains are surveyed. Interesting new developments of LBP in 1D signal analysis are also considered. Finally, some future challenges for research are presented. version:1
arxiv-1612-06778 | Text classification with sparse composite document vectors | http://arxiv.org/abs/1612.06778 | id:1612.06778 author:Dheeraj Mekala, Vivek Gupta, Harish Karnick category:cs.CL  published:2016-12-20 summary:In this work, we present a modified feature formation technique - graded-weighted Bag of Word Vectors (gwBoWV) by Vivek Gupta, 2016 for faster and better composite document feature representation. We propose a very simple feature construction algorithm that potentially overcomes many weaknesses in current distributional vector representations and other composite document representation methods widely used for text representation. Through extensive experiments on multi-class classification on 20newsgroup dataset and multi-label text classification on Reuters-21578, we achieve better performance results and also a significant reduction in training and prediction time compared to composite document representation methods gwBoWV and TWE Liu et al., 2015b. version:1
arxiv-1612-06746 | Correlations and forecast of death tolls in the Syrian conflict | http://arxiv.org/abs/1612.06746 | id:1612.06746 author:Kazuki Fujita, Shigeru Shinomoto, Luis E C Rocha category:physics.soc-ph physics.data-an physics.pop-ph stat.AP stat.ML  published:2016-12-20 summary:The Syrian civil war has been ongoing since 2011 and has already caused thousands of deaths. The analysis of death tolls helps to understand the dynamics of the conflict and to better allocate resources to the affected areas. In this article, we use information on the daily number of deaths to study temporal and spatial correlations in the data, and exploit this information to forecast events of deaths. We find that the number of deaths per day follows a log-normal distribution during the conflict. We have also identified strong correlations between cities and on consecutive days, implying that major deaths in one location are typically followed by major deaths in both the same location and in other areas. We find that war-related deaths are not random events and observing death tolls in some cities helps to better predict these numbers across the system. version:1
arxiv-1612-06738 | Local Sparse Approximation for Image Restoration with Adaptive Block Size Selection | http://arxiv.org/abs/1612.06738 | id:1612.06738 author:Sujit Kumar Sahoo category:cs.CV cs.IR stat.AP  published:2016-12-20 summary:In this paper the problem of image restoration (denoising and inpainting) is approached using sparse approximation of local image blocks. The local image blocks are extracted by sliding square windows over the image. An adaptive block size selection procedure for local sparse approximation is proposed, which affects the global recovery of underlying image. Ideally the adaptive local block selection yields the minimum mean square error (MMSE) in recovered image. This framework gives us a clustered image based on the selected block size, then each cluster is restored separately using sparse approximation. The results obtained using the proposed framework are very much comparable with the recently proposed image restoration techniques. version:1
arxiv-1612-06704 | Action-Driven Object Detection with Top-Down Visual Attentions | http://arxiv.org/abs/1612.06704 | id:1612.06704 author:Donggeun Yoo, Sunggyun Park, Kyunghyun Paeng, Joon-Young Lee, In So Kweon category:cs.CV cs.AI cs.LG  published:2016-12-20 summary:A dominant paradigm for deep learning based object detection relies on a "bottom-up" approach using "passive" scoring of class agnostic proposals. These approaches are efficient but lack of holistic analysis of scene-level context. In this paper, we present an "action-driven" detection mechanism using our "top-down" visual attention model. We localize an object by taking sequential actions that the attention model provides. The attention model conditioned with an image region provides required actions to get closer toward a target object. An action at each time step is weak itself but an ensemble of the sequential actions makes a bounding-box accurately converge to a target object boundary. This attention model we call AttentionNet is composed of a convolutional neural network. During our whole detection procedure, we only utilize the actions from a single AttentionNet without any modules for object proposals nor post bounding-box regression. We evaluate our top-down detection mechanism over the PASCAL VOC series and ILSVRC CLS-LOC dataset, and achieve state-of-the-art performances compared to the major bottom-up detection methods. In particular, our detection mechanism shows a strong advantage in elaborate localization by outperforming Faster R-CNN with a margin of +7.1% over PASCAL VOC 2007 when we increase the IoU threshold for positive detection to 0.7. version:1
arxiv-1612-06703 | Dynamic Action Recognition: A convolutional neural network model for temporally organized joint location data | http://arxiv.org/abs/1612.06703 | id:1612.06703 author:Adhavan Jayabalan, Harish Karunakaran, Shravan Murlidharan, Tesia Shizume category:cs.CV  published:2016-12-20 summary:Motivation: Recognizing human actions in a video is a challenging task which has applications in various fields. Previous works in this area have either used images from a 2D or 3D camera. Few have used the idea that human actions can be easily identified by the movement of the joints in the 3D space and instead used a Recurrent Neural Network (RNN) for modeling. Convolutional neural networks (CNN) have the ability to recognise even the complex patterns in data which makes it suitable for detecting human actions. Thus, we modeled a CNN which can predict the human activity using the joint data. Furthermore, using the joint data representation has the benefit of lower dimensionality than image or video representations. This makes our model simpler and faster than the RNN models. In this study, we have developed a six layer convolutional network, which reduces each input feature vector of the form 15x1961x4 to an one dimensional binary vector which gives us the predicted activity. Results: Our model is able to recognise an activity correctly upto 87% accuracy. Joint data is taken from the Cornell Activity Datasets which have day to day activities like talking, relaxing, eating, cooking etc. version:1
arxiv-1612-06699 | Unsupervised Perceptual Rewards for Imitation Learning | http://arxiv.org/abs/1612.06699 | id:1612.06699 author:Pierre Sermanet, Kelvin Xu, Sergey Levine category:cs.CV cs.RO  published:2016-12-20 summary:Reward function design and exploration time are arguably the biggest obstacles to the deployment of reinforcement learning (RL) agents in the real world. In many real-world tasks, designing a suitable reward function takes considerable manual engineering and often requires additional and potentially visible sensors to be installed just to measure whether the task has been executed successfully. Furthermore, many interesting tasks consist of multiple steps that must be executed in sequence. Even when the final outcome can be measured, it does not necessarily provide useful feedback on these implicit intermediate steps or sub-goals. To address these issues, we propose leveraging the abstraction power of intermediate visual representations learned by deep models to quickly infer perceptual reward functions from small numbers of demonstrations. We present a method that is able to identify the key intermediate steps of a task from only a handful of demonstration sequences, and automatically identify the most discriminative features for identifying these steps. This method makes use of the features in a pre-trained deep model, but does not require any explicit sub-goal supervision. The resulting reward functions can then be used by an RL agent to learn to perform the task in real-world settings. To evaluate the learned reward functions, we present qualitative results on two real-world tasks and a quantitative evaluation against a human-designed reward function. We also demonstrate that our method can be used to learn a complex real-world door opening skill using a real robot, even when the demonstration used for reward learning is provided by a human using their own hand. To our knowledge, these are the first results showing that complex robotic manipulation skills can be learned directly and without supervised labels from a video of a human performing the task. version:1
arxiv-1612-07117 | Classification and Learning-to-rank Approaches for Cross-Device Matching at CIKM Cup 2016 | http://arxiv.org/abs/1612.07117 | id:1612.07117 author:Nam Khanh Tran category:cs.IR cs.LG  published:2016-12-20 summary:In this paper, we propose two methods for tackling the problem of cross-device matching for online advertising at CIKM Cup 2016. The first method considers the matching problem as a binary classification task and solve it by utilizing ensemble learning techniques. The second method defines the matching problem as a ranking task and effectively solve it with using learning-to-rank algorithms. The results show that the proposed methods obtain promising results, in which the ranking-based method outperforms the classification-based method for the task. version:1
arxiv-1612-06685 | Stateology: State-Level Interactive Charting of Language, Feelings, and Values | http://arxiv.org/abs/1612.06685 | id:1612.06685 author:Konstantinos Pappas, Steven Wilson, Rada Mihalcea category:cs.CL  published:2016-12-20 summary:People's personality and motivations are manifest in their everyday language usage. With the emergence of social media, ample examples of such usage are procurable. In this paper, we aim to analyze the vocabulary used by close to 200,000 Blogger users in the U.S. with the purpose of geographically portraying various demographic, linguistic, and psychological dimensions at the state level. We give a description of a web-based tool for viewing maps that depict various characteristics of the social media users as derived from this large blog dataset of over two billion words. version:1
arxiv-1612-06676 | Multivariate Industrial Time Series with Cyber-Attack Simulation: Fault Detection Using an LSTM-based Predictive Data Model | http://arxiv.org/abs/1612.06676 | id:1612.06676 author:Pavel Filonov, Andrey Lavrentyev, Artem Vorontsov category:cs.LG stat.ML  published:2016-12-20 summary:We adopted an approach based on an LSTM neural network to monitor and detect faults in industrial multivariate time series data. To validate the approach we created a Modelica model of part of a real gasoil plant. By introducing hacks into the logic of the Modelica model, we were able to generate both the roots and causes of fault behavior in the plant. Having a self-consistent data set with labeled faults, we used an LSTM architecture with a forecasting error threshold to obtain precision and recall quality metrics. The dependency of the quality metric on the threshold level is considered. An appropriate mechanism such as "one handle" was introduced for filtering faults that are outside of the plant operator field of interest. version:1
arxiv-1612-06671 | Inferring the location of authors from words in their texts | http://arxiv.org/abs/1612.06671 | id:1612.06671 author:Max Berggren, Jussi Karlgren, Robert Östling, Mikael Parkvall category:cs.CL H.3.1; I.2.7  published:2016-12-20 summary:For the purposes of computational dialectology or other geographically bound text analysis tasks, texts must be annotated with their or their authors' location. Many texts are locatable through explicit labels but most have no explicit annotation of place. This paper describes a series of experiments to determine how positionally annotated microblog posts can be used to learn location-indicating words which then can be used to locate blog texts and their authors. A Gaussian distribution is used to model the locational qualities of words. We introduce the notion of placeness to describe how locational words are. We find that modelling word distributions to account for several locations and thus several Gaussian distributions per word, defining a filter which picks out words with high placeness based on their local distributional context, and aggregating locational information in a centroid for each text gives the most useful results. The results are applied to data in the Swedish language. version:1
arxiv-1612-06669 | Enhancing Observability in Distribution Grids using Smart Meter Data | http://arxiv.org/abs/1612.06669 | id:1612.06669 author:Siddharth Bhela, Vassilis Kekatos, Sriharsha Veeramachaneni category:math.OC cs.LG stat.ML  published:2016-12-20 summary:Due to limited metering infrastructure, distribution grids are currently challenged by observability issues. On the other hand, smart meter data, including local voltage magnitudes and power injections, are communicated to the utility operator from grid buses with renewable generation and demand-response programs. This work employs grid data from metered buses towards inferring the underlying grid state. To this end, a coupled formulation of the power flow problem (CPF) is put forth. Exploiting the high variability of injections at metered buses, the controllability of solar inverters, and the relative time-invariance of conventional loads, the idea is to solve the non-linear power flow equations jointly over consecutive time instants. An intuitive and easily verifiable rule pertaining to the locations of metered and non-metered buses on the physical grid is shown to be a necessary and sufficient criterion for local observability in radial networks. To account for noisy smart meter readings, a coupled power system state estimation (CPSSE) problem is further developed. Both CPF and CPSSE tasks are tackled via augmented semi-definite program relaxations. The observability criterion along with the CPF and CPSSE solvers are numerically corroborated using synthetic and actual solar generation and load data on the IEEE 34-bus benchmark feeder. version:1
arxiv-1612-06650 | Partially blind domain adaptation for age prediction from DNA methylation data | http://arxiv.org/abs/1612.06650 | id:1612.06650 author:Lisa Handl, Adrin Jalali, Michael Scherer, Nico Pfeifer category:q-bio.QM stat.ML  published:2016-12-20 summary:Over the last years, huge resources of biological and medical data have become available for research. This data offers great chances for machine learning applications in health care, e.g. for precision medicine, but is also challenging to analyze. Typical challenges include a large number of possibly correlated features and heterogeneity in the data. One flourishing field of biological research in which this is relevant is epigenetics. Here, especially large amounts of DNA methylation data have emerged. This epigenetic mark has been used to predict a donor's 'epigenetic age' and increased epigenetic aging has been linked to lifestyle and disease history. In this paper we propose an adaptive model which performs feature selection for each test sample individually based on the distribution of the input data. The method can be seen as partially blind domain adaptation. We apply the model to the problem of age prediction based on DNA methylation data from a variety of tissues, and compare it to a standard model, which does not take heterogeneity into account. The standard approach has particularly bad performance on one tissue type on which we show substantial improvement with our new adaptive approach even though no samples of that tissue were part of the training data. version:1
arxiv-1612-06623 | Supervised Learning for Optimal Power Flow as a Real-Time Proxy | http://arxiv.org/abs/1612.06623 | id:1612.06623 author:Raphael Canyasse, Gal Dalal, Shie Mannor category:cs.LG  published:2016-12-20 summary:In this work we design and compare different supervised learning algorithms to compute the cost of Alternating Current Optimal Power Flow (ACOPF). The motivation for quick calculation of OPF cost outcomes stems from the growing need of algorithmic-based long-term and medium-term planning methodologies in power networks. Integrated in a multiple time-horizon coordination framework, we refer to this approximation module as a proxy for predicting short-term decision outcomes without the need of actual simulation and optimization of them. Our method enables fast approximate calculation of OPF cost with less than 1% error on average, achieved in run-times that are several orders of magnitude lower than of exact computation. Several test-cases such as IEEE-RTS96 are used to demonstrate the efficiency of our approach. version:1
arxiv-1612-06615 | Deep Motion Features for Visual Tracking | http://arxiv.org/abs/1612.06615 | id:1612.06615 author:Susanna Gladh, Martin Danelljan, Fahad Shahbaz Khan, Michael Felsberg category:cs.CV  published:2016-12-20 summary:Robust visual tracking is a challenging computer vision problem, with many real-world applications. Most existing approaches employ hand-crafted appearance features, such as HOG or Color Names. Recently, deep RGB features extracted from convolutional neural networks have been successfully applied for tracking. Despite their success, these features only capture appearance information. On the other hand, motion cues provide discriminative and complementary information that can improve tracking performance. Contrary to visual tracking, deep motion features have been successfully applied for action recognition and video classification tasks. Typically, the motion features are learned by training a CNN on optical flow images extracted from large amounts of labeled videos. This paper presents an investigation of the impact of deep motion features in a tracking-by-detection framework. We further show that hand-crafted, deep RGB, and deep motion features contain complementary information. To the best of our knowledge, we are the first to propose fusing appearance information with deep motion features for visual tracking. Comprehensive experiments clearly suggest that our fusion approach with deep motion features outperforms standard methods relying on appearance information alone. version:1
arxiv-1612-06598 | WoCE: a framework for clustering ensemble by exploiting the wisdom of Crowds theory | http://arxiv.org/abs/1612.06598 | id:1612.06598 author:Muhammad Yousefnezhad, Sheng-Jun Huang, Daoqiang Zhang category:stat.ML cs.LG  published:2016-12-20 summary:The Wisdom of Crowds (WOC), as a theory in the social science, gets a new paradigm in computer science. The WOC theory explains that the aggregate decision made by a group is often better than those of its individual members if specific conditions are satisfied. This paper presents a novel framework for unsupervised and semi-supervised cluster ensemble by exploiting the WOC theory. We employ four conditions in the WOC theory, i.e., diversity, independency, decentralization and aggregation, to guide both the constructing of individual clustering results and the final combination for clustering ensemble. Firstly, independency criterion, as a novel mapping system on the raw data set, removes the correlation between features on our proposed method. Then, decentralization as a novel mechanism generates high-quality individual clustering results. Next, uniformity as a new diversity metric evaluates the generated clustering results. Further, weighted evidence accumulation clustering method is proposed for the final aggregation without using thresholding procedure. Experimental study on varied data sets demonstrates that the proposed approach achieves superior performance to state-of-the-art methods. version:1
arxiv-1612-06581 | Grammar rules for the isiZulu complex verb | http://arxiv.org/abs/1612.06581 | id:1612.06581 author:C. Maria Keet, Langa Khumalo category:cs.CL I.2.7  published:2016-12-20 summary:The isiZulu verb is known for its morphological complexity, which is a subject for on-going linguistics research, as well as for prospects of computational use, such as controlled natural language interfaces, machine translation, and spellcheckers. To this end, we seek to answer the question as to what the precise grammar rules for the isiZulu complex verb are (and, by extension, the Bantu verb morphology). To this end, we iteratively specify the grammar as a Context Free Grammar, and evaluate it computationally. The grammar presented in this paper covers the subject and object concords, negation, present tense, aspect, mood, and the causative, applicative, stative, and the reciprocal verbal extensions, politeness, the wh-question modifiers, and aspect doubling, ensuring their correct order as they appear in verbs. The grammar conforms to specification. version:1
arxiv-1612-06573 | Detecting Unexpected Obstacles for Self-Driving Cars: Fusing Deep Learning and Geometric Modeling | http://arxiv.org/abs/1612.06573 | id:1612.06573 author:Sebastian Ramos, Stefan Gehrig, Peter Pinggera, Uwe Franke, Carsten Rother category:cs.CV cs.RO  published:2016-12-20 summary:The detection of small road hazards, such as lost cargo, is a vital capability for self-driving cars. We tackle this challenging and rarely addressed problem with a vision system that leverages appearance, contextual as well as geometric cues. To utilize the appearance and contextual cues, we propose a new deep learning-based obstacle detection framework. Here a variant of a fully convolutional network is used to predict a pixel-wise semantic labeling of (i) free-space, (ii) on-road unexpected obstacles, and (iii) background. The geometric cues are exploited using a state-of-the-art detection approach that predicts obstacles from stereo input images via model-based statistical hypothesis tests. We present a principled Bayesian framework to fuse the semantic and stereo-based detection results. The mid-level Stixel representation is used to describe obstacles in a flexible, compact and robust manner. We evaluate our new obstacle detection system on the Lost and Found dataset, which includes very challenging scenes with obstacles of only 5 cm height. Overall, we report a major improvement over the state-of-the-art, with relative performance gains of up to 50%. In particular, we achieve a detection rate of over 90% for distances of up to 50 m. Our system operates at 22 Hz on our self-driving platform. version:1
arxiv-1612-06572 | Unsupervised Dialogue Act Induction using Gaussian Mixtures | http://arxiv.org/abs/1612.06572 | id:1612.06572 author:Tomáš Brychcín, Pavel Král category:cs.CL  published:2016-12-20 summary:This paper introduces a new unsupervised approach for dialogue act induction. Given the sequence of dialogue utterances, the task is to assign them the labels representing their function in the dialogue. Utterances are represented as real-valued vectors encoding their meaning. We model the dialogue as Hidden Markov model with emission probabilities estimated by Gaussian mixtures. We use Gibbs sampling for posterior inference. We present the results on the standard Switchboard-DAMSL corpus. Our algorithm achieves promising results compared with strong supervised baselines and outperforms other unsupervised algorithms. version:1
arxiv-1612-06565 | RIDS: Robust Identification of Sparse Gene Regulatory Networks from Perturbation Experiments | http://arxiv.org/abs/1612.06565 | id:1612.06565 author:Hoi-To Wai, Anna Scaglione, Uzi Harush, Baruch Barzel, Amir Leshem category:q-bio.QM cs.IT math.IT q-bio.MN stat.ML  published:2016-12-20 summary:Reconstructing the causal network in a complex dynamical system plays a crucial role in many applications, from sub-cellular biology to economic systems. Here we focus on inferring gene regulation networks (GRNs) from perturbation or gene deletion experiments. Despite their scientific merit, such perturbation experiments are not often used for such inference due to their costly experimental procedure, requiring significant resources to complete the measurement of every single experiment. To overcome this challenge, we develop the Robust IDentification of Sparse networks (RIDS) method that reconstructs the GRN from a small number of perturbation experiments. Our method uses the gene expression data observed in each experiment and translates that into a steady state condition of the system's nonlinear interaction dynamics. Applying a sparse optimization criterion, we are able to extract the parameters of the underlying weighted network, even from very few experiments. In fact, we demonstrate analytically that, under certain conditions, the GRN can be perfectly reconstructed using $K = \Omega (d_{max})$ perturbation experiments, where $d_{max}$ is the maximum in-degree of the GRN, a small value for realistic sparse networks, indicating that RIDS can achieve high performance with a scalable number of experiments. We test our method on both synthetic and experimental data extracted from the DREAM5 network inference challenge. We show that the RIDS achieves superior performance compared to the state-of-the-art methods, while requiring as few as ~60% less experimental data. Moreover, as opposed to almost all competing methods, RIDS allows us to infer the directionality of the GRN links, allowing us to infer empirical GRNs, without relying on the commonly provided list of transcription factors. version:1
arxiv-1612-06558 | End-to-End Pedestrian Collision Warning System based on a Convolutional Neural Network with Semantic Segmentation | http://arxiv.org/abs/1612.06558 | id:1612.06558 author:Heechul Jung, Min-Kook Choi, Kwon Soon, Woo Young Jung category:cs.CV  published:2016-12-20 summary:Traditional pedestrian collision warning systems sometimes raise alarms even when there is no danger (e.g., when all pedestrians are walking on the sidewalk). These false alarms can make it difficult for drivers to concentrate on their driving. In this paper, we propose a novel framework for an end-to-end pedestrian collision warning system based on a convolutional neural network. Semantic segmentation information is used to train the convolutional neural network and two loss functions, such as cross entropy and Euclidean losses, are minimized. Finally, we demonstrate the effectiveness of our method in reducing false alarms and increasing warning accuracy compared to a traditional histogram of oriented gradients (HoG)-based system. version:1
arxiv-1612-06549 | Exploring Different Dimensions of Attention for Uncertainty Detection | http://arxiv.org/abs/1612.06549 | id:1612.06549 author:Heike Adel, Hinrich Schütze category:cs.CL  published:2016-12-20 summary:Neural networks with attention have proven effective for many natural language processing tasks. In this paper, we develop attention mechanisms for uncertainty detection. In particular, we generalize standardly used attention mechanisms by introducing external attention and sequence-preserving attention. These novel architectures differ from standard approaches in that they use external resources to compute attention weights and preserve sequence information. We compare them to other configurations along different dimensions of attention. Our novel architectures set the new state of the art on a Wikipedia benchmark dataset and perform similar to the state-of-the-art model on a biomedical benchmark which uses a large set of linguistic features. version:1
arxiv-1612-06543 | Wide-Slice Residual Networks for Food Recognition | http://arxiv.org/abs/1612.06543 | id:1612.06543 author:Niki Martinel, Gian Luca Foresti, Christian Micheloni category:cs.CV  published:2016-12-20 summary:Food diary applications represent a tantalizing market. Such applications, based on image food recognition, opened to new challenges for computer vision and pattern recognition algorithms. Recent works in the field are focusing either on hand-crafted representations or on learning these by exploiting deep neural networks. Despite the success of such a last family of works, these generally exploit off-the shelf deep architectures to classify food dishes. Thus, the architectures are not cast to the specific problem. We believe that better results can be obtained if the deep architecture is defined with respect to an analysis of the food composition. Following such an intuition, this work introduces a new deep scheme that is designed to handle the food structure. Specifically, inspired by the recent success of residual deep network, we exploit such a learning scheme and introduce a slice convolution block to capture the vertical food layers. Outputs of the deep residual blocks are combined with the sliced convolution to produce the classification score for specific food categories. To evaluate our proposed architecture we have conducted experimental results on three benchmark datasets. Results demonstrate that our solution shows better performance with respect to existing approaches (e.g., a top-1 accuracy of 90.27% on the Food-101 challenging dataset). version:1
arxiv-1612-06530 | Automatic Generation of Grounded Visual Questions | http://arxiv.org/abs/1612.06530 | id:1612.06530 author:Shijie Zhang, Lizhen Qu, Shaodi You, Zhenglu Yang, Jiawan Zhang category:cs.CV cs.CL  published:2016-12-20 summary:In this paper, we propose a new task and solution for vision and language: generation of grounded visual questions. Visual question answering (VQA) is an emerging topic which links textual questions with visual input. To the best of our knowledge, it lacks automatic method to generate reasonable and versatile questions. So far, almost all the textual questions are generated manually, as well as the corresponding answers. To this end, we propose a system that automatically generates visually grounded questions . First, visual input is analyzed with deep caption model. Second, the captions along with VGG-16 features are used as input for our proposed question generator to generate visually grounded questions. Finally, to enable generating of versatile questions, a question type selection module is provided which selects reasonable question types and provide them as parameters for question generation. This is done using a hybrid LSTM with both visual and answer input. Our system is trained using VQA and Visual7W dataset and shows reasonable results on automatically generating of new visual questions. We also propose a quantitative metric for automatic evaluation of the question quality. version:1
arxiv-1612-06524 | 3D Human Pose Estimation = 2D Pose Estimation + Matching | http://arxiv.org/abs/1612.06524 | id:1612.06524 author:Ching-Hang Chen, Deva Ramanan category:cs.CV  published:2016-12-20 summary:We explore 3D human pose estimation from a single RGB image. While many approaches try to directly predict 3D pose from image measurements, we explore a simple architecture that reasons through intermediate 2D pose predictions. Our approach is based on two key observations (1) Deep neural nets have revolutionized 2D pose estimation, producing accurate 2D predictions even for poses with self occlusions. (2) Big-data sets of 3D mocap data are now readily available, making it tempting to lift predicted 2D poses to 3D through simple memorization (e.g., nearest neighbors). The resulting architecture is trivial to implement with off-the-shelf 2D pose estimation systems and 3D mocap libraries. Importantly, we demonstrate that such methods outperform almost all state-of-the-art 3D pose estimation systems, most of which directly try to regress 3D pose from 2D measurements. version:1
arxiv-1612-06519 | Exploring the Design Space of Deep Convolutional Neural Networks at Large Scale | http://arxiv.org/abs/1612.06519 | id:1612.06519 author:Forrest Iandola category:cs.CV cs.LG cs.NE  published:2016-12-20 summary:In recent years, the research community has discovered that deep neural networks (DNNs) and convolutional neural networks (CNNs) can yield higher accuracy than all previous solutions to a broad array of machine learning problems. To our knowledge, there is no single CNN/DNN architecture that solves all problems optimally. Instead, the "right" CNN/DNN architecture varies depending on the application at hand. CNN/DNNs comprise an enormous design space. Quantitatively, we find that a small region of the CNN design space contains 30 billion different CNN architectures. In this dissertation, we develop a methodology that enables systematic exploration of the design space of CNNs. Our methodology is comprised of the following four themes. 1. Judiciously choosing benchmarks and metrics. 2. Rapidly training CNN models. 3. Defining and describing the CNN design space. 4. Exploring the design space of CNN architectures. Taken together, these four themes comprise an effective methodology for discovering the "right" CNN architectures to meet the needs of practical applications. version:1
arxiv-1612-06508 | Deeply Aggregated Alternating Minimization for Image Restoration | http://arxiv.org/abs/1612.06508 | id:1612.06508 author:Youngjung Kim, Hyungjoo Jung, Dongbo Min, Kwanghoon Sohn category:cs.CV  published:2016-12-20 summary:Regularization-based image restoration has remained an active research topic in computer vision and image processing. It often leverages a guidance signal captured in different fields as an additional cue. In this work, we present a general framework for image restoration, called deeply aggregated alternating minimization (DeepAM). We propose to train deep neural network to advance two of the steps in the conventional AM algorithm: proximal mapping and ?- continuation. Both steps are learned from a large dataset in an end-to-end manner. The proposed framework enables the convolutional neural networks (CNNs) to operate as a prior or regularizer in the AM algorithm. We show that our learned regularizer via deep aggregation outperforms the recent data-driven approaches as well as the nonlocalbased methods. The flexibility and effectiveness of our framework are demonstrated in several image restoration tasks, including single image denoising, RGB-NIR restoration, and depth super-resolution. version:1
arxiv-1612-06496 | Efficiently Computing Piecewise Flat Embeddings for Data Clustering and Image Segmentation | http://arxiv.org/abs/1612.06496 | id:1612.06496 author:Renee T. Meinhold, Tyler L. Hayes, Nathan D. Cahill category:cs.CV  published:2016-12-20 summary:Image segmentation is a popular area of research in computer vision that has many applications in automated image processing. A recent technique called piecewise flat embeddings (PFE) has been proposed for use in image segmentation; PFE transforms image pixel data into a lower dimensional representation where similar pixels are pulled close together and dissimilar pixels are pushed apart. This technique has shown promising results, but its original formulation is not computationally feasible for large images. We propose two improvements to the algorithm for computing PFE: first, we reformulate portions of the algorithm to enable various linear algebra operations to be performed in parallel; second, we propose utilizing an iterative linear solver (preconditioned conjugate gradient) to quickly solve a linear least-squares problem that occurs in the inner loop of a nested iteration. With these two computational improvements, we show on a publicly available image database that PFE can be sped up by an order of magnitude without sacrificing segmentation performance. Our results make this technique more practical for use on large data sets, not only for image segmentation, but for general data clustering problems. version:1
arxiv-1612-06043 | Reducing Redundant Computations with Flexible Attention | http://arxiv.org/abs/1612.06043 | id:1612.06043 author:Raphael Shu, Hideki Nakayama category:cs.CL cs.AI  published:2016-12-19 summary:Recently, attention mechanism plays a key role to achieve high performance for Neural Machine Translation models. It applies a score function to the encoder states to obtain alignment weights. However, as this computation is done for all positions in each decoding step, the attention mechanism greatly increases the computational complexity. In this paper we propose a novel attention model which can reduce redundant attentional computations in a flexible manner. The proposed mechanism tracks the center of attention in each decoding step, and computes position-based penalties. In the test time, the computations of the score function for heavily penalized positions are skipped. In our experiments, we found that the computations in the attention model can be reduced by 54% in average with almost no loss of accuracy. version:2
arxiv-1612-06475 | Span-Based Constituency Parsing with a Structure-Label System and Provably Optimal Dynamic Oracles | http://arxiv.org/abs/1612.06475 | id:1612.06475 author:James Cross, Liang Huang category:cs.CL  published:2016-12-20 summary:Parsing accuracy using efficient greedy transition systems has improved dramatically in recent years thanks to neural networks. Despite striking results in dependency parsing, however, neural models have not surpassed state-of-the-art approaches in constituency parsing. To remedy this, we introduce a new shift-reduce system whose stack contains merely sentence spans, represented by a bare minimum of LSTM features. We also design the first provably optimal dynamic oracle for constituency parsing, which runs in amortized O(1) time, compared to O(n^3) oracles for standard dependency parsing. Training with this oracle, we achieve the best F1 scores on both English and French of any parser that does not use reranking or external data. version:1
arxiv-1612-06470 | Randomized Clustered Nystrom for Large-Scale Kernel Machines | http://arxiv.org/abs/1612.06470 | id:1612.06470 author:Farhad Pourkamali-Anaraki, Stephen Becker category:stat.ML cs.LG  published:2016-12-20 summary:The Nystrom method has been popular for generating the low-rank approximation of kernel matrices that arise in many machine learning problems. The approximation quality of the Nystrom method depends crucially on the number of selected landmark points and the selection procedure. In this paper, we present a novel algorithm to compute the optimal Nystrom low-approximation when the number of landmark points exceed the target rank. Moreover, we introduce a randomized algorithm for generating landmark points that is scalable to large-scale data sets. The proposed method performs K-means clustering on low-dimensional random projections of a data set and, thus, leads to significant savings for high-dimensional data sets. Our theoretical results characterize the tradeoffs between the accuracy and efficiency of our proposed method. Extensive experiments demonstrate the competitive performance as well as the efficiency of our proposed method. version:1
arxiv-1612-06457 | High Performance Software in Multidimensional Reduction Methods for Image Processing with Application to Ancient Manuscripts | http://arxiv.org/abs/1612.06457 | id:1612.06457 author:Corneliu T. C. Arsene, Peter E. Pormann, Naima Afif, Stephen Church, Mark Dickinson category:cs.CV  published:2016-12-19 summary:Multispectral imaging is an important technique for improving the readability of written or printed text where the letters have faded, either due to deliberate erasing or simply due to the ravages of time. Often the text can be read simply by looking at individual wavelengths, but in some cases the images need further enhancement to maximise the chances of reading the text. There are many possible enhancement techniques and this paper assesses and compares an extended set of dimensionality reduction methods for image processing. We assess 15 dimensionality reduction methods in two different manuscripts. This assessment was performed both subjectively by asking the opinions of scholars who were experts in the languages used in the manuscripts which of the techniques they preferred and also by using the Davies-Bouldin and Dunn indexes for assessing the quality of the resulted image clusters. We found that the Canonical Variates Analysis (CVA) method which was using a Matlab implementation and we have used previously to enhance multispectral images, it was indeed superior to all the other tested methods. However it is very likely that other approaches will be more suitable in specific circumstance so we would still recommend that a range of these techniques are tried. In particular, CVA is a supervised clustering technique so it requires considerably more user time and effort than a non-supervised technique such as the much more commonly used Principle Component Analysis Approach (PCA). If the results from PCA are adequate to allow a text to be read then the added effort required for CVA may not be justified. For the purposes of comparing the computational times and the image results, a CVA method is also implemented in C programming language and using the GNU (GNUs Not Unix) Scientific Library (GSL) and the OpenCV (OPEN source Computer Vision) computer vision programming library. version:1
arxiv-1612-06454 | Exploring Structure for Long-Term Tracking of Multiple Objects in Sports Videos | http://arxiv.org/abs/1612.06454 | id:1612.06454 author:Henrique Morimitsu, Isabelle Bloch, Roberto M. Cesar-Jr category:cs.CV  published:2016-12-19 summary:In this paper, we propose a novel approach for exploiting structural relations to track multiple objects that may undergo long-term occlusion and abrupt motion. We use a model-free approach that relies only on annotations given in the first frame of the video to track all the objects online, i.e. without knowledge from future frames. We initialize a probabilistic Attributed Relational Graph (ARG) from the first frame, which is incrementally updated along the video. Instead of using the structural information only to evaluate the scene, the proposed approach considers it to generate new tracking hypotheses. In this way, our method is capable of generating relevant object candidates that are used to improve or recover the track of lost objects. The proposed method is evaluated on several videos of table tennis, volleyball, and on the ACASVA dataset. The results show that our approach is very robust, flexible and able to outperform other state-of-the-art methods in sports videos that present structural patterns. version:1
arxiv-1612-06443 | Binary Distance Transform to Improve Feature Extraction | http://arxiv.org/abs/1612.06443 | id:1612.06443 author:Mariane Barros Neiva, Antoine Manzanera, Odemir Martinez Bruno category:cs.CV  published:2016-12-19 summary:To recognize textures many methods have been developed along the years. However, texture datasets may be hard to be classified due to artefacts such as a variety of scale, illumination and noise. This paper proposes the application of binary distance transform on the original dataset to add information to texture representation and consequently improve recognition. Texture images, usually in grayscale, suffers a binarization prior to distance transform and one of the resulted images are combined with original texture to improve the amount of information. Four datasets are used to evaluate our approach. For Outex dataset, for instance, the proposal outperforms all rates, improvements of an up to 10\%, compared to traditional approach where descriptors are applied on the original dataset, showing the importance of this approach. version:1
arxiv-1612-06435 | Fractal Descriptors of Texture Images Based on the Triangular Prism Dimension | http://arxiv.org/abs/1612.06435 | id:1612.06435 author:João B. Florindo, Odemir M. Bruno category:cs.CV  published:2016-12-19 summary:This work presents a novel descriptor for texture images based on fractal geometry and its application to image analysis. The descriptors are provided by estimating the triangular prism fractal dimension under different scales with a weight exponential parameter, followed by dimensionality reduction using Karhunen-Lo\`{e}ve transform. The efficiency of the proposed descriptors is tested on two well-known texture data sets, that is, Brodatz and Vistex, both for classification and image retrieval. The novel method is also tested concerning invariances in situations when the textures are rotated or affected by Gaussian noise. The obtained results outperform other classical and state-of-the-art descriptors in the literature and demonstrate the power of the triangular descriptors in these tasks, suggesting their use in practical applications of image analysis based on texture features. version:1
arxiv-1612-06423 | Feature Encoding in Band-limited Distributed Surveillance Systems | http://arxiv.org/abs/1612.06423 | id:1612.06423 author:Alireza Rahimpour, Ali Taalimi, Hairong Qi category:cs.CV  published:2016-12-19 summary:Distributed surveillance systems have become popular in recent years due to security concerns. However, transmitting high dimensional data in bandwidth-limited distributed systems becomes a major challenge. In this paper, we address this issue by proposing a novel probabilistic algorithm based on the divergence between the probability distributions of the visual features in order to reduce their dimensionality and thus save the network bandwidth in distributed wireless smart camera networks. We demonstrate the effectiveness of the proposed approach through extensive experiments on two surveillance recognition tasks. version:1
arxiv-1612-06404 | Random Walk Models of Network Formation and Sequential Monte Carlo Methods for Graphs | http://arxiv.org/abs/1612.06404 | id:1612.06404 author:Benjamin Bloem-Reddy, Peter Orbanz category:stat.ME stat.ML  published:2016-12-19 summary:We introduce a class of network models that insert edges by connecting the starting and terminal vertices of a random walk on the network graph. Within the taxonomy of statistical network models, this class is distinguished by permitting the location of a new edge to explicitly depend on the structure of the graph, but being nonetheless statistically and computationally tractable. In the limit of infinite walk length, the model converges to an extension of the preferential attachment model---in this sense, it can be motivated alternatively by asking what preferential attachment is an approximation to. Theoretical properties, including the limiting degree sequence, are studied analytically. If the entire history of the graph is observed, parameters can be estimated by maximum likelihood. If only the final graph is available, its history can be imputed using MCMC. We develop a class of sequential Monte Carlo algorithms that are more generally applicable to sequential random graph models, and may be of interest in their own right. The model parameters can be recovered from a single graph generated by the model. Applications to data clarify the role of the random walk length as a length scale of interactions within the graph. version:1
arxiv-1612-06391 | Talk it up or play it down? (Un)expected correlations between (de-)emphasis and recurrence of discussion points in consequential U.S. economic policy meetings | http://arxiv.org/abs/1612.06391 | id:1612.06391 author:Chenhao Tan, Lillian Lee category:cs.SI cs.CL physics.soc-ph  published:2016-12-19 summary:In meetings where important decisions get made, what items receive more attention may influence the outcome. We examine how different types of rhetorical (de-)emphasis -- including hedges, superlatives, and contrastive conjunctions -- correlate with what gets revisited later, controlling for item frequency and speaker. Our data consists of transcripts of recurring meetings of the Federal Reserve's Open Market Committee (FOMC), where important aspects of U.S. monetary policy are decided on. Surprisingly, we find that words appearing in the context of hedging, which is usually considered a way to express uncertainty, are more likely to be repeated in subsequent meetings, while strong emphasis indicated by superlatives has a slightly negative effect on word recurrence in subsequent meetings. We also observe interesting patterns in how these effects vary depending on social factors such as status and gender of the speaker. For instance, the positive effects of hedging are more pronounced for female speakers than for male speakers. version:1
arxiv-1612-06371 | Asynchronous Temporal Fields for Action Recognition | http://arxiv.org/abs/1612.06371 | id:1612.06371 author:Gunnar A. Sigurdsson, Santosh Divvala, Ali Farhadi, Abhinav Gupta category:cs.CV  published:2016-12-19 summary:Actions are more than just movements and trajectories: we cook to eat and we hold a cup to drink from it. A thorough understanding of videos requires going beyond appearance modeling and necessitates reasoning about the sequence of activities, as well as the higher-level constructs such as intentions. But how do we model and reason about these? We propose a fully-connected temporal CRF model for reasoning over various aspects of activities that includes objects, actions, and intentions, where the potentials are predicted by a deep network. End-to-end training of such structured models is a challenging endeavor: For inference and learning we need to construct mini-batches consisting of whole videos, leading to mini-batches with only a few videos. This causes high-correlation between data points leading to breakdown of the backprop algorithm. To address this challenge, we present an asynchronous variational inference method that allows efficient end-to-end training. Our method achieves a classification mAP of 21.9% on the Charades benchmark, outperforming the state-of-the-art (17.2% mAP), and offers equal gains on the task of temporal localization. version:1
arxiv-1612-06370 | Learning Features by Watching Objects Move | http://arxiv.org/abs/1612.06370 | id:1612.06370 author:Deepak Pathak, Ross Girshick, Piotr Dollár, Trevor Darrell, Bharath Hariharan category:cs.CV cs.AI cs.LG cs.NE stat.ML  published:2016-12-19 summary:This paper presents a novel yet intuitive approach to unsupervised feature learning. Inspired by the human visual system, we explore whether low-level motion-based grouping cues can be used to learn an effective visual representation. Specifically, we use unsupervised motion-based segmentation on videos to obtain segments, which we use as 'pseudo ground truth' to train a convolutional network to segment objects from a single frame. Given the extensive evidence that motion plays a key role in the development of the human visual system, we hope that this straightforward approach to unsupervised learning will be more effective than cleverly designed 'pretext' tasks studied in the literature. Indeed, our extensive experiments show that this is the case. When used for transfer learning on object detection, our representation significantly outperforms previous unsupervised approaches across multiple settings, especially when training data for the target task is scarce. version:1
arxiv-1612-06341 | Dense Supervision for Visual Comparisons via Synthetic Images | http://arxiv.org/abs/1612.06341 | id:1612.06341 author:Aron Yu, Kristen Grauman category:cs.CV  published:2016-12-19 summary:Distinguishing subtle differences in attributes is valuable, yet learning to make visual comparisons remains non-trivial. Not only is the number of possible comparisons quadratic in the number of training images, but also access to images adequately spanning the space of fine-grained visual differences is limited. We propose to overcome the sparsity of supervision problem via synthetically generated images. Building on a state-of-the-art image generation engine, we sample pairs of training images exhibiting slight modifications of individual attributes. Augmenting real training image pairs with these examples, we then train attribute ranking models to predict the relative strength of an attribute in novel pairs of real images. Our results on datasets of faces and fashion images show the great promise of bootstrapping imperfect image generators to counteract sample sparsity for learning to rank. version:1
arxiv-1612-06340 | Learning Human-Understandable Strategies | http://arxiv.org/abs/1612.06340 | id:1612.06340 author:Sam Ganzfried, Farzana Yusuf category:cs.GT cs.AI cs.LG cs.MA  published:2016-12-19 summary:Algorithms for equilibrium computation generally make no attempt to ensure that the computed strategies are understandable by humans. For instance the strategies for the strongest poker agents are represented as massive binary files. In many situations, we would like to compute strategies that can actually be implemented by humans, who may have computational limitations and may only be able to remember a small number of features or components of the strategies that have been computed. We study poker games where private information distributions can be arbitrary. We create a large training set of game instances and solutions, by randomly selecting the private information probabilities, and present algorithms that learn from the training instances in order to perform well in games with unseen information distributions. One approach first clusters the training points into a small number of clusters and then creates a small decision tree based on the cluster centers. This approach produces low test error and could be easily implemented by humans since it only requires memorizing a small number of "if-then" rules. version:1
arxiv-1612-06321 | Image Retrieval with Deep Local Features and Attention-based Keypoints | http://arxiv.org/abs/1612.06321 | id:1612.06321 author:Hyeonwoo Noh, Andre Araujo, Jack Sim, Bohyung Han category:cs.CV  published:2016-12-19 summary:We introduce a local feature descriptor for large-scale image retrieval applications, called DELF (DEep Local Feature). The new feature is based on convolutional neural networks, which are trained without object- and patch-level annotations on a landmark image dataset. To enhance DELF's image retrieval performance, we also propose an attention mechanism for keypoint selection, which shares most network layers with the descriptor. This new framework can be used in image retrieval as a drop-in replacement for other keypoint detectors and descriptors, enabling more accurate feature matching and geometric verification. Our technique is particularly useful for the large-scale setting, where a system must operate with high precision. In this case, our system produces reliable confidence scores to reject false positives effectively---in particular, our system is robust against queries that have no correct match in the database. We present an evaluation methodology for this challenging retrieval setting, using standard and large-scale datasets. We show that recently proposed methods do not perform well in this setup; DELF outperforms several recent global and local descriptors by substantial margins. version:1
arxiv-1612-06305 | Handwritten Signature Verification Using Hand-Worn Devices | http://arxiv.org/abs/1612.06305 | id:1612.06305 author:Ben Nassi, Alona Levy, Yuval Elovici, Erez Shmueli category:cs.CR cs.CV cs.CY  published:2016-12-19 summary:Online signature verification technologies, such as those available in banks and post offices, rely on dedicated digital devices such as tablets or smart pens to capture, analyze and verify signatures. In this paper, we suggest a novel method for online signature verification that relies on the increasingly available hand-worn devices, such as smartwatches or fitness trackers, instead of dedicated ad-hoc devices. Our method uses a set of known genuine and forged signatures, recorded using the motion sensors of a hand-worn device, to train a machine learning classifier. Then, given the recording of an unknown signature and a claimed identity, the classifier can determine whether the signature is genuine or forged. In order to validate our method, it was applied on 1980 recordings of genuine and forged signatures that we collected from 66 subjects in our institution. Using our method, we were able to successfully distinguish between genuine and forged signatures with a high degree of accuracy (0.98 AUC and 0.05 EER). version:1
arxiv-1612-06299 | Simple Black-Box Adversarial Perturbations for Deep Networks | http://arxiv.org/abs/1612.06299 | id:1612.06299 author:Nina Narodytska, Shiva Prasad Kasiviswanathan category:cs.LG cs.CR stat.ML  published:2016-12-19 summary:Deep neural networks are powerful and popular learning models that achieve state-of-the-art pattern recognition performance on many computer vision, speech, and language processing tasks. However, these networks have also been shown susceptible to carefully crafted adversarial perturbations which force misclassification of the inputs. Adversarial examples enable adversaries to subvert the expected system behavior leading to undesired consequences and could pose a security risk when these systems are deployed in the real world. In this work, we focus on deep convolutional neural networks and demonstrate that adversaries can easily craft adversarial examples even without any internal knowledge of the target network. Our attacks treat the network as an oracle (black-box) and only assume that the output of the network can be observed on the probed inputs. Our first attack is based on a simple idea of adding perturbation to a randomly selected single pixel or a small set of them. We then improve the effectiveness of this attack by carefully constructing a small set of pixels to perturb by using the idea of greedy local-search. Our proposed attacks also naturally extend to a stronger notion of misclassification. Our extensive experimental results illustrate that even these elementary attacks can reveal a deep neural network's vulnerabilities. The simplicity and effectiveness of our proposed schemes mean that they could serve as a litmus test for designing robust networks. version:1
arxiv-1612-04440 | Disentangling Space and Time in Video with Hierarchical Variational Auto-encoders | http://arxiv.org/abs/1612.04440 | id:1612.04440 author:Will Grathwohl, Aaron Wilson category:cs.CV cs.LG stat.ML  published:2016-12-14 summary:There are many forms of feature information present in video data. Principle among them are object identity information which is largely static across multiple video frames, and object pose and style information which continuously transforms from frame to frame. Most existing models confound these two types of representation by mapping them to a shared feature space. In this paper we propose a probabilistic approach for learning separable representations of object identity and pose information using unsupervised video data. Our approach leverages a deep generative model with a factored prior distribution that encodes properties of temporal invariances in the hidden feature set. Learning is achieved via variational inference. We present results of learning identity and pose information on a dataset of moving characters as well as a dataset of rotating 3D objects. Our experimental results demonstrate our model's success in factoring its representation, and demonstrate that the model achieves improved performance in transfer learning tasks. version:2
arxiv-1612-06259 | Photo-Quality Evaluation based on Computational Aesthetics: Review of Feature Extraction Techniques | http://arxiv.org/abs/1612.06259 | id:1612.06259 author:Dimitris Spathis category:cs.CV  published:2016-12-19 summary:Researchers try to model the aesthetic quality of photographs into low and high- level features, drawing inspiration from art theory, psychology and marketing. We attempt to describe every feature extraction measure employed in the above process. The contribution of this literature review is the taxonomy of each feature by its implementation complexity, considering real-world applications and integration in mobile apps and digital cameras. Also, we discuss the machine learning results along with some unexplored research areas as future work. version:1
arxiv-1612-06246 | Corralling a Band of Bandit Algorithms | http://arxiv.org/abs/1612.06246 | id:1612.06246 author:Alekh Agarwal, Haipeng Luo, Behnam Neyshabur, Robert E. Schapire category:cs.LG stat.ML  published:2016-12-19 summary:We study the problem of combining multiple bandit algorithms (that is, online learning algorithms with partial feedback) with the goal of creating a master algorithm that performs almost as well as the best base algorithm if it were to be run on its own. The main challenge is that when run with a master, base algorithms unavoidably receive much less feedback and it is thus critical that the master not starve a base algorithm that might performs uncompetitively initially but would eventually outperform others if given enough feedback. We address this difficulty by devising a version of Online Mirror Descent with a special mirror map together with a sophisticated learning rate scheme. We show that this approach manages to achieve a more delicate balance between exploiting and exploring base algorithms than previous works yielding superior regret bounds. Our results are applicable to many settings, such as multi-armed bandits, contextual bandits, and convex bandits. As examples, we present two main applications. The first is to create an algorithm that enjoys worst-case robustness while at the same time performing much better when the environment is relatively easy. The second is to create an algorithm that works simultaneously under different assumptions of the environment, such as different priors or different loss structures. version:1
arxiv-1612-06212 | A recurrent neural network without chaos | http://arxiv.org/abs/1612.06212 | id:1612.06212 author:Thomas Laurent, James von Brecht category:cs.NE cs.CL cs.LG  published:2016-12-19 summary:We introduce an exceptionally simple gated recurrent neural network (RNN) that achieves performance comparable to well-known gated architectures, such as LSTMs and GRUs, on the word-level language modeling task. We prove that our model has simple, predicable and non-chaotic dynamics. This stands in stark contrast to more standard gated architectures, whose underlying dynamical systems exhibit chaotic behavior. version:1
arxiv-1612-06176 | An extended Perona-Malik model based on probabilistic models | http://arxiv.org/abs/1612.06176 | id:1612.06176 author:Lars M. Mescheder, Dirk A. Lorenz category:cs.CV math.NA stat.ML  published:2016-12-19 summary:The Perona-Malik model has been very successful at restoring images from noisy input. In this paper, we reinterpret the Perona-Malik model in the language of Gaussian scale mixtures and derive some extensions of the model. Specifically, we show that the expectation-maximization (EM) algorithm applied to Gaussian scale mixtures leads to the lagged-diffusivity algorithm for computing stationary points of the Perona-Malik diffusion equations. Moreover, we show how mean field approximations to these Gaussian scale mixtures lead to a modification of the lagged-diffusivity algorithm that better captures the uncertainties in the restoration. Since this modification can be hard to compute in practice we propose relaxations to the mean field objective to make the algorithm computationally feasible. Our numerical experiments show that this modified lagged-diffusivity algorithm often performs better at restoring textured areas and fuzzy edges than the unmodified algorithm. As a second application of the Gaussian scale mixture framework, we show how an efficient sampling procedure can be obtained for the probabilistic model, making the computation of the conditional mean and other expectations algorithmically feasible. Again, the resulting algorithm has a strong resemblance to the lagged-diffusivity algorithm. Finally, we show that a probabilistic version of the Mumford-Shah segementation model can be obtained in the same framework with a discrete edge-prior. version:1
arxiv-1612-06170 | Crowd collectiveness measure via graph-based node clique learning | http://arxiv.org/abs/1612.06170 | id:1612.06170 author:Weiya Ren category:cs.CV cs.SI  published:2016-12-19 summary:Collectiveness motions of crowd systems have attracted a great deal of attentions in recently years. In this paper, we try to measure the collectiveness of a crowd system by the proposed node clique learning method. The proposed method is a graph based method, and investigates the influence from one node to other nodes. A node is represented by a set of nodes which named a clique, which is obtained by spreading information from this node to other nodes in graph. Then only nodes with sufficient information are selected as the clique of this node. The motion coherence between two nodes is defined by node cliques comparing. The collectiveness of a node and the collectiveness of the crowd system are defined by the nodes coherence. Self-driven particle (SDP) model and the crowd motion database are used to test the ability of the proposed method in measuring collectiveness. version:1
arxiv-1612-06152 | Few-Shot Object Recognition from Machine-Labeled Web Images | http://arxiv.org/abs/1612.06152 | id:1612.06152 author:Zhongwen Xu, Linchao Zhu, Yi Yang category:cs.CV  published:2016-12-19 summary:With the tremendous advances of Convolutional Neural Networks (ConvNets) on object recognition, we can now obtain reliable enough machine-labeled annotations easily by predictions from off-the-shelf ConvNets. In this work, we present an abstraction memory based framework for few-shot learning, building upon machine-labeled image annotations. Our method takes some large-scale machine-annotated datasets (e.g., OpenImages) as an external memory bank. In the external memory bank, the information is stored in the memory slots with the form of key-value, where image feature is regarded as key and label embedding serves as value. When queried by the few-shot examples, our model selects visually similar data from the external memory bank, and writes the useful information obtained from related external data into another memory bank, i.e., abstraction memory. Long Short-Term Memory (LSTM) controllers and attention mechanisms are utilized to guarantee the data written to the abstraction memory is correlated to the query example. The abstraction memory concentrates information from the external memory bank, so that it makes the few-shot recognition effective. In the experiments, we firstly confirm that our model can learn to conduct few-shot object recognition on clean human-labeled data from ImageNet dataset. Then, we demonstrate that with our model, machine-labeled image annotations are very effective and abundant resources to perform object recognition on novel categories. Experimental results show that our proposed model with machine-labeled annotations achieves great performance, only with a gap of 1% between of the one with human-labeled annotations. version:1
arxiv-1612-06141 | Domain specialization: a post-training domain adaptation for Neural Machine Translation | http://arxiv.org/abs/1612.06141 | id:1612.06141 author:Christophe Servan, Josep Crego, Jean Senellart category:cs.CL  published:2016-12-19 summary:Domain adaptation is a key feature in Machine Translation. It generally encompasses terminology, domain and style adaptation, especially for human post-editing workflows in Computer Assisted Translation (CAT). With Neural Machine Translation (NMT), we introduce a new notion of domain adaptation that we call "specialization" and which is showing promising results both in the learning speed and in adaptation accuracy. In this paper, we propose to explore this approach under several perspectives. version:1
arxiv-1612-06140 | Domain Control for Neural Machine Translation | http://arxiv.org/abs/1612.06140 | id:1612.06140 author:Catherine Kobus, Josep Crego, Jean Senellart category:cs.CL  published:2016-12-19 summary:Machine translation systems are very sensitive to the domains they were trained on. Several domain adaptation techniques have been deeply studied. We propose a new technique for neural machine translation (NMT) that we call domain control which is performed at runtime using a unique neural network covering multiple domains. The presented approach shows quality improvements when compared to dedicated domains translating on any of the covered domains and even on out-of-domain data. In addition, model parameters do not need to be re-estimated for each domain, making this effective to real use cases. Evaluation is carried out on English-to-French translation for two different testing scenarios. We first consider the case where an end-user performs translations on a known domain. Secondly, we consider the scenario where the domain is not known and predicted at the sentence level before translating. Results show consistent accuracy improvements for both conditions. version:1
arxiv-1612-06139 | Neural Machine Translation from Simplified Translations | http://arxiv.org/abs/1612.06139 | id:1612.06139 author:Josep Crego, Jean Senellart category:cs.CL  published:2016-12-19 summary:Text simplification aims at reducing the lexical, grammatical and structural complexity of a text while keeping the same meaning. In the context of machine translation, we introduce the idea of simplified translations in order to boost the learning ability of deep neural translation models. We conduct preliminary experiments showing that translation complexity is actually reduced in a translation of a source bi-text compared to the target reference of the bi-text while using a neural machine translation (NMT) system learned on the exact same bi-text. Based on knowledge distillation idea, we then train an NMT system using the simplified bi-text, and show that it outperforms the initial system that was built over the reference data set. Performance is further boosted when both reference and automatic translations are used to learn the network. We perform an elementary analysis of the translated corpus and report accuracy results of the proposed approach on English-to-French and English-to-German translation tasks. version:1
arxiv-1612-06138 | Boosting Neural Machine Translation | http://arxiv.org/abs/1612.06138 | id:1612.06138 author:Dakun Zhang, Jungi Kim, Josep Crego, Jean Senellart category:cs.CL  published:2016-12-19 summary:Training efficiency is one of the main problems for Neural Machine Translation (NMT). Deep networks, very large data and many training iterations are necessary to achieve state-of-the-art performance for NMT. This results in very high computation cost and slow down research and industrialization. In this paper, we first investigate the instability by randomizations for NMT training, and further propose an efficient training method based on data boosting and bootstrapping with no modifications to the neural network. Experiments show that this method can converge much faster compared with a baseline system and achieve stable improvement up to 2.36 BLEU points with 80% training cost. version:1
arxiv-1612-06131 | Monte Carlo sampling for stochastic weight functions | http://arxiv.org/abs/1612.06131 | id:1612.06131 author:Daan Frenkel, K. Julian Schrenk, Stefano Martiniani category:cond-mat.stat-mech physics.comp-ph stat.ME stat.ML  published:2016-12-19 summary:Conventional Monte Carlo simulations are stochastic in the sense that the acceptance of a trial move is decided by comparing a computed acceptance probability with a random number, uniformly distributed between 0 and 1. Here we consider the case that the weight determining the acceptance probability itself is fluctuating. This situation is common in many numerical studies. We show that it is possible to construct a rigorous Monte Carlo algorithm that visits points in state space with a probability proportional to their average weight. The same approach has the potential to transform the methodology of a certain class of high-throughput experiments or the analysis of noisy datasets. version:1
arxiv-1612-06129 | Active and Continuous Exploration with Deep Neural Networks and Expected Model Output Changes | http://arxiv.org/abs/1612.06129 | id:1612.06129 author:Christoph Käding, Erik Rodner, Alexander Freytag, Joachim Denzler category:cs.CV  published:2016-12-19 summary:The demands on visual recognition systems do not end with the complexity offered by current large-scale image datasets, such as ImageNet. In consequence, we need curious and continuously learning algorithms that actively acquire knowledge about semantic concepts which are present in available unlabeled data. As a step towards this goal, we show how to perform continuous active learning and exploration, where an algorithm actively selects relevant batches of unlabeled examples for annotation. These examples could either belong to already known or to yet undiscovered classes. Our algorithm is based on a new generalization of the Expected Model Output Change principle for deep architectures and is especially tailored to deep neural networks. Furthermore, we show easy-to-implement approximations that yield efficient techniques for active selection. Empirical experiments show that our method outperforms currently used heuristics. version:1
arxiv-1612-06098 | Cross-Modal Manifold Learning for Cross-modal Retrieval | http://arxiv.org/abs/1612.06098 | id:1612.06098 author:Sailesh Conjeti, Anees Kazi, Nassir Navab, Amin Katouzian category:cs.CV  published:2016-12-19 summary:This paper presents a new scalable algorithm for cross-modal similarity preserving retrieval in a learnt manifold space. Unlike existing approaches that compromise between preserving global and local geometries, the proposed technique respects both simultaneously during manifold alignment. The global topologies are maintained by recovering underlying mapping functions in the joint manifold space by deploying partially corresponding instances. The inter-, and intra-modality affinity matrices are then computed to reinforce original data skeleton using perturbed minimum spanning tree (pMST), and maximizing the affinity among similar cross-modal instances, respectively. The performance of proposed algorithm is evaluated upon two multimodal image datasets (coronary atherosclerosis histology and brain MRI) for two applications: classification, and regression. Our exhaustive validations and results demonstrate the superiority of our technique over comparative methods and its feasibility for improving computer-assisted diagnosis systems, where disease-specific complementary information shall be aggregated and interpreted across modalities to form the final decision. version:1
arxiv-1612-06096 | X-ray In-Depth Decomposition: Can Deep Learning Reveal The Latent Structures? | http://arxiv.org/abs/1612.06096 | id:1612.06096 author:Shadi Albarqouni, Javad Fotouhi, Nassir Navab category:cs.CV  published:2016-12-19 summary:X-ray radiography is the most readily available imaging modality and has a broad range of applications that spans from diagnosis to intra-operative guidance in cardiac, orthopedics, and trauma procedures. Proper interpretation of the hidden and obscured anatomy in X-ray images remains a challenge and often requires high radiation dose and imaging from several perspectives. In this work, we aim at decomposing the conventional X-ray image into d X-ray components of independent, non-overlapped, clipped sub-volumes using deep learning approach. Despite the challenging aspects of modelling such a highly ill-posed problem, exciting and encouraging results are obtained paving the path for further contributions in this direction. version:1
arxiv-1612-06093 | Transfer Learning based Dynamic Multiobjective Optimization Algorithms | http://arxiv.org/abs/1612.06093 | id:1612.06093 author:Min Jiang, Zhongqiang Huang, Liming Qiu, Wenzhen Huang, Gary G. Yen category:cs.NE  published:2016-12-19 summary:One of the major distinguishing features of the dynamic multiobjective optimization problems (DMOPs) is the optimization objectives will change over time, thus tracking the varying Pareto-optimal front becomes a challenge. One of the promising solutions is reusing the "experiences" to construct a prediction model via statistical machine learning approaches. However most of the existing methods ignore the non-independent and identically distributed nature of data used to construct the prediction model. In this paper, we propose an algorithmic framework, called Tr-DMOEA, which integrates transfer learning and population-based evolutionary algorithm for solving the DMOPs. This approach takes the transfer learning method as a tool to help reuse the past experience for speeding up the evolutionary process, and at the same time, any population based multiobjective algorithms can benefit from this integration without any extensive modifications. To verify this, we incorporate the proposed approach into the development of three well-known algorithms, nondominated sorting genetic algorithm II (NSGA-II), multiobjective particle swarm optimization (MOPSO), and the regularity model-based multiobjective estimation of distribution algorithm (RM-MEDA), and then employ twelve benchmark functions to test these algorithms as well as compare with some chosen state-of-the-art designs. The experimental results confirm the effectiveness of the proposed method through exploiting machine learning technology. version:1
arxiv-1612-06083 | Hierarchical Partitioning of the Output Space in Multi-label Data | http://arxiv.org/abs/1612.06083 | id:1612.06083 author:Yannis Papanikolaou, Ioannis Katakis, Grigorios Tsoumakas category:stat.ML  published:2016-12-19 summary:Hierarchy Of Multi-label classifiers (HOMER) is a multi-label learning algorithm that breaks the initial learning task to several, easier sub-tasks by first constructing a hierarchy of labels from a given label set and secondly employing a given base multi-label classifier (MLC) to the resulting sub-problems. The primary goal is to effectively address class imbalance and scalability issues that often arise in real-world multi-label classification problems. In this work, we present the general setup for a HOMER model and a simple extension of the algorithm that is suited for MLCs that output rankings. Furthermore, we provide a detailed analysis of the properties of the algorithm, both from an aspect of effectiveness and computational complexity. A secondary contribution involves the presentation of a balanced variant of the k means algorithm, which serves in the first step of the label hierarchy construction. We conduct extensive experiments on six real-world datasets, studying empirically HOMER's parameters and providing examples of instantiations of the algorithm with different clustering approaches and MLCs, The empirical results demonstrate a significant improvement over the given base MLC. version:1
arxiv-1612-06070 | On Random Weights for Texture Generation in One Layer Neural Networks | http://arxiv.org/abs/1612.06070 | id:1612.06070 author:Mihir Mongia, Kundan Kumar, Akram Erraqabi, Yoshua Bengio category:cs.CV cs.LG  published:2016-12-19 summary:Recent work in the literature has shown experimentally that one can use the lower layers of a trained convolutional neural network (CNN) to model natural textures. More interestingly, it has also been experimentally shown that only one layer with random filters can also model textures although with less variability. In this paper we ask the question as to why one layer CNNs with random filters are so effective in generating textures? We theoretically show that one layer convolutional architectures (without a non-linearity) paired with the an energy function used in previous literature, can in fact preserve and modulate frequency coefficients in a manner so that random weights and pretrained weights will generate the same type of images. Based on the results of this analysis we question whether similar properties hold in the case where one uses one convolution layer with a non-linearity. We show that in the case of ReLu non-linearity there are situations where only one input will give the minimum possible energy whereas in the case of no nonlinearity, there are always infinite solutions that will give the minimum possible energy. Thus we can show that in certain situations adding a ReLu non-linearity generates less variable images. version:1
arxiv-1612-06062 | Improving Tweet Representations using Temporal and User Context | http://arxiv.org/abs/1612.06062 | id:1612.06062 author:Ganesh J, Manish Gupta, Vasudeva Varma category:cs.CL cs.AI  published:2016-12-19 summary:In this work we propose a novel representation learning model which computes semantic representations for tweets accurately. Our model systematically exploits the chronologically adjacent tweets ('context') from users' Twitter timelines for this task. Further, we make our model user-aware so that it can do well in modeling the target tweet by exploiting the rich knowledge about the user such as the way the user writes the post and also summarizing the topics on which the user writes. We empirically demonstrate that the proposed models outperform the state-of-the-art models in predicting the user profile attributes like spouse, education and job by 19.66%, 2.27% and 2.22% respectively. version:1
arxiv-1612-06061 | Mixing Times and Structural Inference for Bernoulli Autoregressive Processes | http://arxiv.org/abs/1612.06061 | id:1612.06061 author:Dimitrios Katselis, Carolyn L. Beck, R. Srikant category:stat.ML  published:2016-12-19 summary:We introduce a novel multivariate random process producing Bernoulli outputs per dimension, that can possibly formalize binary interactions in various graphical structures and can be used to model opinion dynamics, epidemics, financial and biological time series data, etc. We call this a Bernoulli Autoregressive Process (BAR). A BAR process models a discrete-time vector random sequence of $p$ scalar Bernoulli processes with autoregressive dynamics and corresponds to a particular Markov Chain. The benefit from the autoregressive dynamics is the description of a $2^p\times 2^p$ transition matrix by at most $pd$ effective parameters for some $d\ll p$ or by two sparse matrices of dimensions $p\times p^2$ and $p\times p$, respectively, parameterizing the transitions. Additionally, we show that the BAR process mixes rapidly, by proving that the mixing time is $O(\log p)$. The hidden constant in the previous mixing time bound depends explicitly on the values of the chain parameters and implicitly on the maximum allowed in-degree of a node in the corresponding graph. For a network with $p$ nodes, where each node has in-degree at most $d$ and corresponds to a scalar Bernoulli process generated by a BAR, we provide a greedy algorithm that can efficiently learn the structure of the underlying directed graph with a sample complexity proportional to the mixing time of the BAR process. The sample complexity of the proposed algorithm is nearly order-optimal as it is only a $\log p$ factor away from an information-theoretic lower bound. We present simulation results illustrating the performance of our algorithm in various setups, including a model for a biological signaling network. version:1
arxiv-1612-06053 | Dual Deep Network for Visual Tracking | http://arxiv.org/abs/1612.06053 | id:1612.06053 author:Zhizhen Chi, Hongyang Li, Huchuan Lu, Ming-Hsuan Yang category:cs.CV  published:2016-12-19 summary:Visual tracking addresses the problem of identifying and localizing an unknown target in a video given the target specified by a bounding box in the first frame. In this paper, we propose a dual network to better utilize features among layers for visual tracking. It is observed that features in higher layers encode semantic context while its counterparts in lower layers are sensitive to discriminative appearance. Thus we exploit the hierarchical features in different layers of a deep model and design a dual structure to obtain better feature representation from various streams, which is rarely investigated in previous work. To highlight geometric contours of the target, we integrate the hierarchical feature maps with an edge detector as the coarse prior maps to further embed local details around the target. To leverage the robustness of our dual network, we train it with random patches measuring the similarities between the network activation and target appearance, which serves as a regularization to enforce the dual network to focus on target object. The proposed dual network is updated online in a unique manner based on the observation that the target being tracked in consecutive frames should share more similar feature representations than those in the surrounding background. It is also found that for a target object, the prior maps can help further enhance performance by passing message into the output maps of the dual network. Therefore, an independent component analysis with reference algorithm (ICA-R) is employed to extract target context using prior maps as guidance. Online tracking is conducted by maximizing the posterior estimate on the final maps with stochastic and periodic update. Quantitative and qualitative evaluations on two large-scale benchmark data sets show that the proposed algorithm performs favourably against the state-of-the-arts. version:1
arxiv-1612-06052 | Training Ternary Neural Networks with Exact Proximal Operator | http://arxiv.org/abs/1612.06052 | id:1612.06052 author:Penghang Yin, Shuai Zhang, Jack Xin, Yingyong Qi category:cs.LG  published:2016-12-19 summary:In this paper, we propose a stochastic proximal gradient method to train ternary weight neural networks (TNN). The proposed method features weight ternarization via an exact formula of proximal operator. Our experiments show that our trained TNN are able to preserve the state-of-the-art performance on MNIST and CIFAR10 benchmark datesets. version:1
arxiv-1612-06027 | Neural Multi-Source Morphological Reinflection | http://arxiv.org/abs/1612.06027 | id:1612.06027 author:Katharina Kann, Ryan Cotterell, Hinrich Schütze category:cs.CL  published:2016-12-19 summary:We explore the task of multi-source morphological reinflection, which generalizes the standard, single-source version. The input consists of (i) a target tag and (ii) multiple pairs of source form and source tag for a lemma. The motivation is that it is beneficial to have access to more than one source form since different source forms can provide complementary information, e.g., different stems. We further present a novel extension to the encoder- decoder recurrent neural architecture, consisting of multiple encoders, to better solve the task. We show that our new architecture outperforms single-source reinflection models and publish our dataset for multi-source morphological reinflection to facilitate future research. version:1
arxiv-1612-06018 | Self-Correcting Models for Model-Based Reinforcement Learning | http://arxiv.org/abs/1612.06018 | id:1612.06018 author:Erik Talvitie category:cs.LG cs.AI I.2.6; I.2.8  published:2016-12-19 summary:When an agent cannot represent a perfectly accurate model of its environment's dynamics, model-based reinforcement learning (MBRL) can fail catastrophically. Planning involves composing the predictions of the model; when flawed predictions are composed, even minor errors can compound and render the model useless for planning. Hallucinated Replay (Talvitie 2014) trains the model to "correct" itself when it produces errors, substantially improving MBRL with flawed models. This paper theoretically analyzes this approach, illuminates settings in which it is likely to be effective or ineffective, and presents a novel error bound, showing that a model's ability to self-correct is more tightly related to MBRL performance than one-step prediction error. These results inspire an MBRL algorithm for deterministic MDPs with performance guarantees that are robust to model class limitations. version:1
arxiv-1612-06017 | Parsing Images of Overlapping Organisms with Deep Singling-Out Networks | http://arxiv.org/abs/1612.06017 | id:1612.06017 author:Victor Yurchenko, Victor Lempitsky category:cs.CV  published:2016-12-19 summary:This work is motivated by the mostly unsolved task of parsing biological images with multiple overlapping articulated model organisms (such as worms or larvae). We present a general approach that separates the two main challenges associated with such data, individual object shape estimation and object groups disentangling. At the core of the approach is a deep feed-forward singling-out network (SON) that is trained to map each local patch to a vectorial descriptor that is sensitive to the characteristics (e.g. shape) of a central object, while being invariant to the variability of all other surrounding elements. Given a SON, a local image patch can be matched to a gallery of isolated elements using their SON-descriptors, thus producing a hypothesis about the shape of the central element in that patch. The image-level optimization based on integer programming can then pick a subset of the hypotheses to explain (parse) the whole image and disentangle groups of organisms. While sharing many similarities with existing "analysis-by-synthesis" approaches, our method avoids the need for stochastic search in the high-dimensional configuration space and numerous rendering operations at test-time. We show that our approach can parse microscopy images of three popular model organisms (the C.Elegans roundworms, the Drosophila larvae, and the E.Coli bacteria) even under significant crowding and overlaps between organisms. We speculate that the overall approach is applicable to a wider class of image parsing problems concerned with crowded articulated objects, for which rendering training images is possible. version:1
arxiv-1612-06007 | A Hidden Absorbing Semi-Markov Model for Informatively Censored Temporal Data: Learning and Inference | http://arxiv.org/abs/1612.06007 | id:1612.06007 author:Ahmed M. Alaa, Mihaela van der Schaar category:cs.AI stat.ML  published:2016-12-18 summary:Modeling continuous-time physiological processes that manifest a patient's evolving clinical states is a key step in approaching many problems in healthcare. In this paper, we develop the Hidden Absorbing Semi-Markov Model (HASMM): a versatile probabilistic model that is capable of capturing the modern electronic health record (EHR) data. Unlike exist- ing models, an HASMM accommodates irregularly sampled, temporally correlated, and informatively censored physiological data, and can describe non-stationary clinical state transitions. Learning an HASMM from the EHR data is achieved via a novel forward- filtering backward-sampling Monte-Carlo EM algorithm that exploits the knowledge of the end-point clinical outcomes (informative censoring) in the EHR data, and implements the E-step by sequentially sampling the patients' clinical states in the reverse-time direction while conditioning on the future states. Real-time inferences are drawn via a forward- filtering algorithm that operates on a virtually constructed discrete-time embedded Markov chain that mirrors the patient's continuous-time state trajectory. We demonstrate the di- agnostic and prognostic utility of the HASMM in a critical care prognosis setting using a real-world dataset for patients admitted to the Ronald Reagan UCLA Medical Center. version:1
arxiv-1612-06003 | Inexact Proximal Gradient Methods for Non-convex and Non-smooth Optimization | http://arxiv.org/abs/1612.06003 | id:1612.06003 author:Bin Gu, Zhouyuan Huo, Heng Huang category:cs.LG  published:2016-12-18 summary:Non-convex and non-smooth optimization plays an important role in machine learning. Proximal gradient method is one of the most important methods for solving the non-convex and non-smooth problems, where a proximal operator need to be solved exactly for each step. However, in a lot of problems the proximal operator does not have an analytic solution, or is expensive to obtain an exact solution. In this paper, we propose inexact proximal gradient methods (not only a basic inexact proximal gradient method (IPG), but also a Nesterov's accelerated inexact proximal gradient method (AIPG)) for non-convex and non-smooth optimization, which tolerate an error in the calculation of the proximal operator. Theoretical analysis shows that IPG and AIPG have the same convergence rates as in the error-free case, provided that the errors decrease at appropriate rates. version:1
arxiv-1612-06000 | Sample-efficient Deep Reinforcement Learning for Dialog Control | http://arxiv.org/abs/1612.06000 | id:1612.06000 author:Kavosh Asadi, Jason D. Williams category:cs.AI cs.LG stat.ML  published:2016-12-18 summary:Representing a dialog policy as a recurrent neural network (RNN) is attractive because it handles partial observability, infers a latent representation of state, and can be optimized with supervised learning (SL) or reinforcement learning (RL). For RL, a policy gradient approach is natural, but is sample inefficient. In this paper, we present 3 methods for reducing the number of dialogs required to optimize an RNN-based dialog policy with RL. The key idea is to maintain a second RNN which predicts the value of the current policy, and to apply experience replay to both networks. On two tasks, these methods reduce the number of dialogs/episodes required by about a third, vs. standard policy gradient methods. version:1
arxiv-1612-05970 | Adversarial Deep Structural Networks for Mammographic Mass Segmentation | http://arxiv.org/abs/1612.05970 | id:1612.05970 author:Wentao Zhu, Xiaohui Xie category:cs.CV cs.LG  published:2016-12-18 summary:Mass segmentation is an important task in mammogram analysis, providing effective morphological features and regions of interest (ROI) for mass detection and classification. Inspired by the success of using deep convolutional features for natural image analysis and conditional random fields (CRF) for structural learning, we propose an end-to-end network for mammographic mass segmentation. The network employs a fully convolutional network (FCN) to model potential function, followed by a CRF to perform structural learning. Because the mass distribution varies greatly with pixel position, the FCN is combined with position priori for the task. Due to the small size of mammogram datasets, we use adversarial training to control over-fitting. Four models with different convolutional kernels are further fused to improve the segmentation results. Experimental results on two public datasets, INbreast and DDSM-BCRP, show that our end-to-end network combined with adversarial training achieves the-state-of-the-art results. version:1
arxiv-1612-05968 | Deep Multi-instance Networks with Sparse Label Assignment for Whole Mammogram Classification | http://arxiv.org/abs/1612.05968 | id:1612.05968 author:Wentao Zhu, Qi Lou, Yeeleng Scott Vang, Xiaohui Xie category:cs.CV cs.LG  published:2016-12-18 summary:Mammogram classification is directly related to computer-aided diagnosis of breast cancer. Traditional methods requires great effort to annotate the training data by costly manual labeling and specialized computational models to detect these annotations during test. Inspired by the success of using deep convolutional features for natural image analysis and multi-instance learning for labeling a set of instances/patches, we propose end-to-end trained deep multi-instance networks for mass classification based on whole mammogram without the aforementioned costly need to annotate the training data. We explore three different schemes to construct deep multi-instance networks for whole mammogram classification. Experimental results on the INbreast dataset demonstrate the robustness of proposed deep networks compared to previous work using segmentation and detection annotations in the training. version:1
arxiv-1612-05907 | Optimal tuning for divide-and-conquer kernel ridge regression with massive data | http://arxiv.org/abs/1612.05907 | id:1612.05907 author:Ganggang Xu, Zuofeng Shang, Guang Cheng category:stat.ML  published:2016-12-18 summary:We propose a first data-driven tuning procedure for divide-and-conquer kernel ridge regression (Zhang et al., 2015). While the proposed criterion is computationally scalable for massive data sets, it is also shown to be asymptotically optimal under mild conditions. The effectiveness of our method is illustrated by extensive simulations and an application to Million Song Dataset. version:1
arxiv-1612-05890 | Learning a No-Reference Quality Metric for Single-Image Super-Resolution | http://arxiv.org/abs/1612.05890 | id:1612.05890 author:Chao Ma, Chih-Yuan Yang, Xiaokang Yang, Ming-Hsuan Yang category:cs.CV  published:2016-12-18 summary:Numerous single-image super-resolution algorithms have been proposed in the literature, but few studies address the problem of performance evaluation based on visual perception. While most super-resolution images are evaluated by fullreference metrics, the effectiveness is not clear and the required ground-truth images are not always available in practice. To address these problems, we conduct human subject studies using a large set of super-resolution images and propose a no-reference metric learned from visual perceptual scores. Specifically, we design three types of low-level statistical features in both spatial and frequency domains to quantify super-resolved artifacts, and learn a two-stage regression model to predict the quality scores of super-resolution images without referring to ground-truth images. Extensive experimental results show that the proposed metric is effective and efficient to assess the quality of super-resolution images based on human perception. version:1
arxiv-1612-05888 | Building Diversified Multiple Trees for Classification in High Dimensional Noise Data | http://arxiv.org/abs/1612.05888 | id:1612.05888 author:Jiuyong Li, Lin Liu, Jixue Liu, Ryan Green category:cs.LG stat.ML  published:2016-12-18 summary:It is common that a trained classification model is applied to the operating data that is deviated from the training data because of noise. This paper demonstrate an ensemble classifier, Diversified Multiple Trees (DMT) is more robust to classify noised data than other widely used ensemble methods. DMT is tested on three real world biological data sets from different laboratories in comparison with four benchmark ensemble classifiers. Experimental results show that DMT is significantly more accurate than other benchmark ensemble classifiers on noised test data. We also discussed a limitation of DMT and its possible variations. version:1
arxiv-1612-05877 | Deep Learning on Lie Groups for Skeleton-based Action Recognition | http://arxiv.org/abs/1612.05877 | id:1612.05877 author:Zhiwu Huang, Chengde Wan, Thomas Probst, Luc Van Gool category:cs.CV  published:2016-12-18 summary:In recent years, skeleton-based action recognition has become a popular 3D classification problem. State-of-the-art methods typically first represent each motion sequence as a high-dimensional trajectory on a Lie group with an additional dynamic time warping, and then shallowly learn favorable Lie group features. In this paper we incorporate the Lie group structure into a deep network architecture to learn more appropriate Lie group features for 3D action recognition. Within the network structure, we design rotation mapping layers to transform the input Lie group features into desirable ones, which are aligned better in the temporal domain. To reduce the high feature dimensionality, the architecture is equipped with rotation pooling layers for the elements on the Lie group. Furthermore, we propose a logarithm mapping layer to map the resulting manifold data into a tangent space that facilitates the application of regular output layers for the final classification. Evaluations of the proposed network for standard 3D human action recognition datasets clearly demonstrate its superiority over existing shallow Lie group feature learning methods as well as most conventional deep learning methods. version:1
arxiv-1612-05872 | 3D Shape Induction from 2D Views of Multiple Objects | http://arxiv.org/abs/1612.05872 | id:1612.05872 author:Matheus Gadelha, Subhransu Maji, Rui Wang category:cs.CV  published:2016-12-18 summary:In this paper we investigate the problem of inducing a distribution over three-dimensional structures given two-dimensional views of multiple objects taken from unknown viewpoints. Our approach called "projective generative adversarial networks" (PrGANs) trains a deep generative model of 3D shapes whose projections match the distributions of the input 2D views. The addition of a projection module allows us to infer the underlying 3D shape distribution without using any 3D, viewpoint information, or annotation during the learning phase. We show that our approach produces 3D shapes of comparable quality to GANs trained on 3D data for a number of shape categories including chairs, airplanes, and cars. Experiments also show that the disentangled representation of 2D shapes into geometry and viewpoint leads to a good generative model of 2D shapes. The key advantage is that our model allows us to predict 3D, viewpoint, and generate novel views from an input image in a completely unsupervised manner. version:1
arxiv-1612-02913 | Field-Programmable Crossbar Array (FPCA) for Reconfigurable Computing | http://arxiv.org/abs/1612.02913 | id:1612.02913 author:Mohammed A. Zidan, YeonJoo Jeong, Jong Hong Shin, Chao Du, Zhengya Zhang, Wei D. Lu category:cs.ET cs.AR cs.NE  published:2016-12-09 summary:For decades, advances in electronics were directly related to the scaling of CMOS transistors according to Moore's law. However, both the CMOS scaling and the classical computer architecture are approaching fundamental and practical limits, and new computing architectures based on emerging devices, such as non-volatile memories e.g. resistive memory (RRAM) devices, are expected to sustain the exponential growth of computing capability. Here we propose a novel memory-centric, reconfigurable, general purpose computing platform to handle the explosive amount of data in a fast and energy-efficient manner. The proposed computing architecture is based on a single physical resistive memory-centric fabric that can be optimally reconfigured and utilized to perform different computing and data storage tasks in a massively parallel approach. The system can be tailored to achieve maximal energy efficiency based on the data flow by dynamically allocating the basic computing fabric to storage, arithmetic, and analog computing including neuromorphic computing tasks. version:2
arxiv-1612-05846 | Efficient Global Spatial-Angular Sparse Coding for Diffusion MRI with Separable Dictionaries | http://arxiv.org/abs/1612.05846 | id:1612.05846 author:Evan Schwab, René Vidal, Nicolas Charon category:stat.ML cs.CV q-bio.QM  published:2016-12-18 summary:Diffusion MRI (dMRI) can reconstruct neuronal fibers in the brain, in vivo, by measuring water diffusion along angular gradient directions in q-space. High angular resolution diffusion imaging (HARDI) can produce better estimates of fiber orientation than the popularly used diffusion tensor imaging, but the high number of samples needed to estimate diffusivity requires lengthy patient scan times. To accelerate dMRI, compressed sensing (CS) has been utilized by exploiting a sparse representation of the data, discovered through sparse coding. The sparser the representation, the fewer samples are needed to reconstruct a high resolution signal with limited information loss and so a focus of much dMRI research has been finding the sparsest possible dictionary representation. All prior methods, however, rely on an angular model of q-space signals in each voxel which fundamentally limits the global sparsity level since at least one dictionary atom is needed for each voxel. In contrast, we formulate a global spatial-angular representation of dMRI that will allow us to sparsely model an entire dMRI brain signal below the limit of one atom per voxel using joint spatial-angular sparse coding. But a main challenge is optimizing over large-scale dMRI data. In this work, we present extensions to a number of sparse coding algorithms that are better suited for large-scale problems by exploiting the separable Kronecker structure of our global spatial-angular dictionary. We compare the complexity and speed of our methods with prior Kronecker sparse coding algorithms and show promising sparsity results on phantom and real HARDI brain data for various dictionary choices. With great efficiency our method achieves significantly sparser HARDI representations than the state-of-the-art which has the potential achieve new levels of HARDI acceleration within a unified (k,q)-CS framework. version:1
arxiv-1612-05836 | EgoTransfer: Transferring Motion Across Egocentric and Exocentric Domains using Deep Neural Networks | http://arxiv.org/abs/1612.05836 | id:1612.05836 author:Shervin Ardeshir, Krishna Regmi, Ali Borji category:cs.CV cs.LG cs.NE  published:2016-12-17 summary:Mirror neurons have been observed in the primary motor cortex of primate species, in particular in humans and monkeys. A mirror neuron fires when a person performs a certain action, and also when he observes the same action being performed by another person. A crucial step towards building fully autonomous intelligent systems with human-like learning abilities is the capability in modeling the mirror neuron. On one hand, the abundance of egocentric cameras in the past few years has offered the opportunity to study a lot of vision problems from the first-person perspective. A great deal of interesting research has been done during the past few years, trying to explore various computer vision tasks from the perspective of the self. On the other hand, videos recorded by traditional static cameras, capture humans performing different actions from an exocentric third-person perspective. In this work, we take the first step towards relating motion information across these two perspectives. We train models that predict motion in an egocentric view, by observing it from an exocentric view, and vice versa. This allows models to predict how an egocentric motion would look like from outside. To do so, we train linear and nonlinear models and evaluate their performance in terms of retrieving the egocentric (exocentric) motion features, while having access to an exocentric (egocentric) motion feature. Our experimental results demonstrate that motion information can be successfully transferred across the two views. version:1
arxiv-1612-05794 | A new recurrent neural network based predictive model for Faecal Calprotectin analysis: A retrospective study | http://arxiv.org/abs/1612.05794 | id:1612.05794 author:Zeeshan Khawar Malik, Zain U. Hussain, Ziad Kobti, Charlie W. Lees, Newton Howard, Amir Hussain category:cs.LG  published:2016-12-17 summary:Faecal Calprotectin (FC) is a surrogate marker for intestinal inflammation, termed Inflammatory Bowel Disease (IBD), but not for cancer. In this retrospective study of 804 patients, an enhanced benchmark predictive model for analyzing FC is developed, based on a novel state-of-the-art Echo State Network (ESN), an advanced dynamic recurrent neural network which implements a biologically plausible architecture, and a supervised learning mechanism. The proposed machine learning driven predictive model is benchmarked against a conventional logistic regression model, demonstrating statistically significant performance improvements. version:1
arxiv-1612-05753 | Learning to predict where to look in interactive environments using deep recurrent q-learning | http://arxiv.org/abs/1612.05753 | id:1612.05753 author:Sajad Mousavi, Ali Borji, Nasser Mozayani category:cs.CV cs.LG  published:2016-12-17 summary:Bottom-Up (BU) saliency models do not perform well in complex interactive environments where humans are actively engaged in tasks (e.g., sandwich making and playing the video games). In this paper, we leverage Reinforcement Learning (RL) to highlight task-relevant locations of input frames. We propose a soft attention mechanism combined with the Deep Q-Network (DQN) model to teach an RL agent how to play a game and where to look by focusing on the most pertinent parts of its visual input. Our evaluations on several Atari 2600 games show that the soft attention based model could predict fixation locations significantly better than bottom-up models such as Itti-Kochs saliency and Graph-Based Visual Saliency (GBVS) models. version:1
arxiv-1612-05740 | Machine Learning, Linear and Bayesian Models for Logistic Regression in Failure Detection Problems | http://arxiv.org/abs/1612.05740 | id:1612.05740 author:B. Pavlyshenko category:cs.LG  published:2016-12-17 summary:In this work, we study the use of logistic regression in manufacturing failures detection. As a data set for the analysis, we used the data from Kaggle competition Bosch Production Line Performance. We considered the use of machine learning, linear and Bayesian models. For machine learning approach, we analyzed XGBoost tree based classifier to obtain high scored classification. Using the generalized linear model for logistic regression makes it possible to analyze the influence of the factors under study. The Bayesian approach for logistic regression gives the statistical distribution for the parameters of the model. It can be useful in the probabilistic analysis, e.g. risk assessment. version:1
arxiv-1612-05729 | Exploiting sparsity to build efficient kernel based collaborative filtering for top-N item recommendation | http://arxiv.org/abs/1612.05729 | id:1612.05729 author:Mirko Polato, Fabio Aiolli category:cs.IR cs.AI cs.LG  published:2016-12-17 summary:The increasing availability of implicit feedback datasets has raised the interest in developing effective collaborative filtering techniques able to deal asymmetrically with unambiguous positive feedback and ambiguous negative feedback. In this paper, we propose a principled kernel-based collaborative filtering method for top-N item recommendation with implicit feedback. We present an efficient implementation using the linear kernel, and we show how to generalize it to kernels of the dot product family preserving the efficiency. We also investigate on the elements which influence the sparsity of a standard cosine kernel. This analysis shows that the sparsity of the kernel strongly depends on the properties of the dataset, in particular on the long tail distribution. We compare our method with state-of-the-art algorithms achieving good results both in terms of efficiency and effectiveness. version:1
arxiv-1612-05719 | Microscopic Muscle Image Enhancement | http://arxiv.org/abs/1612.05719 | id:1612.05719 author:Xiangfei Kong, Lin Yang category:cs.CV  published:2016-12-17 summary:We propose a robust image enhancement algorithm dedicated for muscle fiber specimen images captured by optical microscopes. Blur or out of focus problems are prevalent in muscle images during the image acquisition stage. Traditional image deconvolution methods do not work since they assume the blur kernels are known and also produce ring artifacts. We provide a compact framework which involves a novel spatially non-uniform blind deblurring approach specialized to muscle images which automatically detects and alleviates degraded regions. Ring artifacts problems are addressed and a kernel propagation strategy is proposed to speedup the algorithm and deals with the high non-uniformity of the blur kernels on muscle images. Experiments show that the proposed framework performs well on muscle images taken with modern advanced optical microscopes. Our framework is free of laborious parameter settings and is computationally efficient. version:1
arxiv-1612-05712 | A Fusion Method Based on Decision Reliability Ratio for Finger Vein Verification | http://arxiv.org/abs/1612.05712 | id:1612.05712 author:Liao Ni, Yi Zhang, He Zheng, Shilei Liu, Houjun Huang, Wenxin Li category:cs.CV  published:2016-12-17 summary:Finger vein verification has developed a lot since its first proposal, but there is still not a perfect algorithm. It is proved that algorithms with the same overall accuracy may have different misclassified patterns. We could make use of this complementation to fuse individual algorithms together for more precise result. According to our observation, algorithm has different confidence on its decisions but it is seldom considered in fusion methods. Our work is first to define decision reliability ratio to quantify this confidence, and then propose the Maximum Decision Reliability Ratio (MDRR) fusion method incorporating Weighted Voting. Experiment conducted on a data set of 1000 fingers and 5 images per finger proves the effectiveness of the method. The classifier obtained by MDRR method gets an accuracy of 99.42% while the maximum accuracy of the original individual classifiers is 97.77%. The experiment results also show the MDRR outperforms the traditional fusion methods as Voting, Weighted Voting, Sum and Weighted Sum. version:1
arxiv-1612-05708 | Mutual information for fitting deep nonlinear models | http://arxiv.org/abs/1612.05708 | id:1612.05708 author:Jacob S. Hunter, Nathan O. Hodas category:math.OC cs.LG stat.ML  published:2016-12-17 summary:Deep nonlinear models pose a challenge for fitting parameters due to lack of knowledge of the hidden layer and the potentially non-affine relation of the initial and observed layers. In the present work we investigate the use of information theoretic measures such as mutual information and Kullback-Leibler (KL) divergence as objective functions for fitting such models without knowledge of the hidden layer. We investigate one model as a proof of concept and one application of cogntive performance. We further investigate the use of optimizers with these methods. Mutual information is largely successful as an objective, depending on the parameters. KL divergence is found to be similarly succesful, given some knowledge of the statistics of the hidden layer. version:1
arxiv-1612-02814 | Task-Guided and Path-Augmented Heterogeneous Network Embedding for Author Identification | http://arxiv.org/abs/1612.02814 | id:1612.02814 author:Ting Chen, Yizhou Sun category:cs.LG cs.AI cs.IR stat.ML  published:2016-12-08 summary:In this paper, we study the problem of author identification under double-blind review setting, which is to identify potential authors given information of an anonymized paper. Different from existing approaches that rely heavily on feature engineering, we propose to use network embedding approach to address the problem, which can automatically represent nodes into lower dimensional feature vectors. However, there are two major limitations in recent studies on network embedding: (1) they are usually general-purpose embedding methods, which are independent of the specific tasks; and (2) most of these approaches can only deal with homogeneous networks, where the heterogeneity of the network is ignored. Hence, challenges faced here are two folds: (1) how to embed the network under the guidance of the author identification task, and (2) how to select the best type of information due to the heterogeneity of the network. To address the challenges, we propose a task-guided and path-augmented heterogeneous network embedding model. In our model, nodes are first embedded as vectors in latent feature space. Embeddings are then shared and jointly trained according to task-specific and network-general objectives. We extend the existing unsupervised network embedding to incorporate meta paths in heterogeneous networks, and select paths according to the specific task. The guidance from author identification task for network embedding is provided both explicitly in joint training and implicitly during meta path selection. Our experiments demonstrate that by using path-augmented network embedding with task guidance, our model can obtain significantly better accuracy at identifying the true authors comparing to existing methods. version:2
arxiv-1612-05695 | Quantum Reinforcement Learning | http://arxiv.org/abs/1612.05695 | id:1612.05695 author:Daniel Crawford, Anna Levit, Navid Ghadermarzy, Jaspreet S. Oberoi, Pooya Ronagh category:quant-ph cs.AI cs.LG cs.NE math.OC  published:2016-12-17 summary:We investigate whether quantum annealers with select chip layouts can outperform classical computers in reinforcement learning tasks. We associate a transverse field Ising spin Hamiltonian with a layout of qubits similar to that of a deep Boltzmann machine (DBM) and use simulated quantum annealing (SQA) to numerically simulate quantum sampling from this system. We design a reinforcement learning algorithm in which the set of visible nodes representing the states and actions of an optimal policy are the first and last layers of the deep network. In absence of a transverse field, our simulations show that DBMs train more effectively than restricted Boltzmann machines (RBM) with the same number of weights. Since sampling from Boltzmann distributions of a DBM is not classically feasible, this is evidence of supremacy of a non-Turing sampling oracle. We then develop a framework for training the network as a quantum Boltzmann machine (QBM) in the presence of a significant transverse field for reinforcement learning. The latter method further improves the reinforcement learning method using DBMs. version:1
arxiv-1612-05688 | A User Simulator for Task-Completion Dialogues | http://arxiv.org/abs/1612.05688 | id:1612.05688 author:Xiujun Li, Zachary C. Lipton, Bhuwan Dhingra, Lihong Li, Jianfeng Gao, Yun-Nung Chen category:cs.LG cs.AI cs.CL  published:2016-12-17 summary:Despite widespread interests in reinforcement-learning for task-oriented dialogue systems, several obstacles can frustrate research and development progress. First, reinforcement learners typically require interaction with the environment, so conventional dialogue corpora cannot be used directly. Second, each task presents specific challenges, requiring separate corpus of task-specific annotated data. Third, collecting and annotating human-machine or human-human conversations for task-oriented dialogues requires extensive domain knowledge. Because building an appropriate dataset can be both financially costly and time-consuming, one popular approach is to build a user simulator based upon a corpus of example dialogues. Then, one can train reinforcement learning agents in an online fashion as they interact with the simulator. Dialogue agents trained on these simulators can serve as an effective starting point. Once agents master the simulator, they may be deployed in a real environment to interact with humans, and continue to be trained online. To ease empirical algorithmic comparisons in dialogues, this paper introduces a new, publicly available simulation framework, where our simulator, designed for the movie-booking domain, leverages both rules and collected data. The simulator supports two tasks: movie ticket booking and movie seeking. Finally, we demonstrate several agents and detail the procedure to add and test your own agent in the proposed framework. version:1
arxiv-1612-05678 | Causal Discovery as Semi-Supervised Learning | http://arxiv.org/abs/1612.05678 | id:1612.05678 author:Chris. J. Oates, Sach Mukherjee category:stat.ML  published:2016-12-16 summary:In this short report, we discuss an approach to estimating causal graphs in which indicators of causal influence between variables are treated as labels in a machine learning formulation. Available data on the variables of interest are used as "inputs" to estimate the labels. We frame the problem as one of semi-supervised learning: available interventional data or background knowledge provide labels on some edges in the graph and the remaining edges are treated as unlabelled objects. To illustrate the key ideas, we consider a simple approach to feature construction (rooted in bivariate kernel density estimation) and embed this within a semi-supervised manifold framework. Results on yeast knockout data demonstrate that the proposed approach can identify causal relationships as validated by unseen interventional experiments. An advantage of the formulation we propose is that by reframing causal discovery as semi-supervised learning, it allows a range of data-driven approaches to be brought to bear on causal discovery, without demanding specification of full probability models or explicit models of underlying mechanisms. version:1
arxiv-1612-03929 | Online Sequence-to-Sequence Active Learning for Open-Domain Dialogue Generation | http://arxiv.org/abs/1612.03929 | id:1612.03929 author:Nabiha Asghar, Pascal Poupart, Xin Jiang, Hang Li category:cs.CL cs.AI cs.NE  published:2016-12-12 summary:We propose an online, end-to-end, neural generative conversational model for open-domain dialog. It is trained using a unique combination of offline two-phase supervised learning and online human-in-the-loop active learning. While most existing research proposes offline supervision or hand-crafted reward functions for online reinforcement, we devise a novel interactive learning mechanism based on a diversity-promoting heuristic for response generation and one-character user-feedback at each step. Experiments show that our model inherently promotes the generation of meaningful, relevant and interesting responses, and can be used to train agents with customized personas, moods and conversational styles. version:3
arxiv-1612-04887 | A Data-Driven Compressive Sensing Framework Tailored For Energy-Efficient Wearable Sensing | http://arxiv.org/abs/1612.04887 | id:1612.04887 author:Kai Xu, Yixing Li, Fengbo Ren category:cs.LG cs.IT math.IT  published:2016-12-15 summary:Compressive sensing (CS) is a promising technology for realizing energy-efficient wireless sensors for long-term health monitoring. However, conventional model-driven CS frameworks suffer from limited compression ratio and reconstruction quality when dealing with physiological signals due to inaccurate models and the overlook of individual variability. In this paper, we propose a data-driven CS framework that can learn signal characteristics and personalized features from any individual recording of physiologic signals to enhance CS performance with a minimized number of measurements. Such improvements are accomplished by a co-training approach that optimizes the sensing matrix and the dictionary towards improved restricted isometry property and signal sparsity, respectively. Experimental results upon ECG signals show that the proposed method, at a compression ratio of 10x, successfully reduces the isometry constant of the trained sensing matrices by 86% against random matrices and improves the overall reconstructed signal-to-noise ratio by 15dB over conventional model-driven approaches. version:2
arxiv-1612-05203 | CSVideoNet: A Recurrent Convolutional Neural Network for Compressive Sensing Video Reconstruction | http://arxiv.org/abs/1612.05203 | id:1612.05203 author:Kai Xu, Fengbo Ren category:cs.CV cs.LG  published:2016-12-15 summary:In this paper, we develop a deep neural network architecture called "CSVideoNet" that can learn visual representations from random measurements for compressive sensing (CS) video reconstruction. CSVideoNet is an end-to-end trainable and non-iterative model that combines convolutional neural networks (CNNs) with a recurrent neural networks (RNN) to facilitate video reconstruction by leveraging temporal-spatial features. The proposed network can accept random measurements with a multi-level compression ratio (CR). The lightly and aggressively compressed measurements offer background information and object details, respectively. This is similar to the variable bit rate techniques widely used in conventional video coding approaches. The RNN employed by CSVideoNet can leverage temporal coherence that exists in adjacent video frames to extrapolate motion features and merge them with spatial visual features extracted by the CNNs to further enhance reconstruction quality, especially at high CRs. We test our CSVideoNet on the UCF-101 dataset. Experimental results show that CSVideoNet outperforms the existing video CS reconstruction approaches. The results demonstrate that our method can preserve relatively excellent visual details from original videos even at a 100x CR, which is difficult to realize with the reference approaches. Also, the non-iterative nature of CSVideoNet results in an decrease in runtime by three orders of magnitude over iterative reconstruction algorithms. Furthermore, CSVideoNet can enhance the CR of CS cameras beyond the limitation of conventional approaches, ensuring a reduction in bandwidth for data transmission. These benefits are especially favorable to high-frame-rate video applications. version:2
arxiv-1612-05614 | An MM Algorithm for Split Feasibility Problems | http://arxiv.org/abs/1612.05614 | id:1612.05614 author:Jason Xu, Eric C. Chi, Meng Yang, Kenneth Lange category:math.OC math.NA stat.CO stat.ML  published:2016-12-16 summary:The classical split feasibility problem seeks a point in the intersection of finitely many closed convex domain constraints, whose image under a linear mapping also lies in the intersection of finitely many closed convex range constraints. Split feasibility generalizes important inverse problems including convex feasibility, linear complementarity, and regression with constraint sets. When a feasible point does not exist, solution methods that proceed by minimizing a proximity function can be used to obtain optimal approximate solutions to the problem. We present an extension of the proximity function approach that generalizes the linear split feasibility problem to allow for nonlinear mappings. Our algorithm is based on the principle of majorization-minimization, is amenable to quasi-Newton acceleration, and comes complete with convergence guarantees under mild assumptions. Furthermore, we show that the Euclidean norm appearing in the proximity function of the nonlinear split feasibility problem can be replaced by arbitrary Bregman divergences. We explore several examples illustrating the merits of nonlinear formulations over the linear case, with a focus on optimization for intensity-modulated radiation therapy data. version:1
arxiv-1612-05612 | Local Asymptotics for some Stochastic Optimization Problems: Optimality, Constraint Identification, and Dual Averaging | http://arxiv.org/abs/1612.05612 | id:1612.05612 author:John Duchi, Feng Ruan category:math.ST math.OC stat.ML stat.TH  published:2016-12-16 summary:We study local complexity measures for stochastic convex optimization problems, providing a local minimax theory analogous to that of H\'ajek and Le Cam for classical statistical problems, and providing efficient procedures based on Nesterov's dual averaging that (often) adaptively achieve optimal convergence guarantees. Our results strongly leverage the geometry of the optimization problem at hand, providing function-specific lower bounds and convergence results. We show how variants of dual averaging---a stochastic gradient-based procedure---guarantee finite time identification of constraints in optimization problems, while stochastic gradient procedures provably fail. Additionally, we highlight a gap between optimization problems with linear and nonlinear constraints: all of our stochastic-gradient-based procedures are suboptimal even for the simplest nonlinear constraints. version:1
arxiv-1612-05601 | Real-Time Detection and Localisation of Fetal Standard Scan Planes in 2D Freehand Ultrasound | http://arxiv.org/abs/1612.05601 | id:1612.05601 author:Christian F. Baumgartner, Konstantinos Kamnitsas, Jacqueline Matthew, Tara P. Fletcher, Sandra Smith, Lisa M. Koch, Bernhard Kainz, Daniel Rueckert category:cs.CV  published:2016-12-16 summary:Identifying and interpreting fetal standard scan planes during 2D ultrasound mid-pregnancy examinations are highly complex tasks which require years of training. Apart from guiding the probe to the correct location, it can be equally difficult for a non-expert to identify relevant structures within the image. Automatic image processing can provide tools to help experienced as well as inexperienced operators with these tasks. In this paper, we propose a novel method based on convolutional neural networks which can automatically detect 13 fetal standard views in freehand 2D ultrasound data as well as provide a localisation of the fetal structures via a bounding box. An important contribution is that the network learns to localise the target anatomy using weak supervision only. The network architecture is designed to operate in real-time while providing optimal output for the localisation task. We present results for real-time annotation, retrospective frame retrieval from saved videos, and localisation on a very large and challenging dataset consisting of images and video recordings of full clinical anomaly screenings. The proposed method annotated video frames with an average F1-score of 0.86, and obtained a 90.09% accuracy for retrospective frame retrieval. Moreover, we achieved an accuracy of 77.8% on the localisation task. version:1
arxiv-1612-05596 | Event-driven Random Back-Propagation: Enabling Neuromorphic Deep Learning Machines | http://arxiv.org/abs/1612.05596 | id:1612.05596 author:Emre Neftci, Charles Augustine, Somnath Paul, Georgios Detorakis category:cs.NE cs.AI  published:2016-12-16 summary:An ongoing challenge in neuromorphic computing is to devise general and computationally efficient models of inference and learning which are compatible with the spatial and temporal constraints of the brain. The gradient descent backpropagation rule is a powerful algorithm that is ubiquitous in deep learning, but it relies on the immediate availability of network-wide information stored with high-precision memory. However, recent work shows that exact backpropagated weights are not essential for learning deep representations. Random backpropagation replaces feedback weights with random ones and encourages the network to adjust its feed-forward weights to learn pseudo-inverses of the (random) feedback weights. Here, we demonstrate an event-driven random backpropagation (eRBP) rule that uses an error-modulated synaptic plasticity for learning deep representations in neuromorphic computing hardware. The rule is very suitable for implementation in neuromorphic hardware using a two-compartment leaky integrate & fire neuron and a membrane-voltage modulated, spike-driven plasticity rule. Our results show that using eRBP, deep representations are rapidly learned without using backpropagated gradients, achieving nearly identical classification accuracies compared to artificial neural network simulations on GPUs, while being robust to neural and synaptic state quantizations during learning. version:1
arxiv-1612-05571 | Delta Networks for Optimized Recurrent Network Computation | http://arxiv.org/abs/1612.05571 | id:1612.05571 author:Daniel Neil, Jun Haeng Lee, Tobi Delbruck, Shih-Chii Liu category:cs.NE  published:2016-12-16 summary:Many neural networks exhibit stability in their activation patterns over time in response to inputs from sensors operating under real-world conditions. By capitalizing on this property of natural signals, we propose a Recurrent Neural Network (RNN) architecture called a delta network in which each neuron transmits its value only when the change in its activation exceeds a threshold. The execution of RNNs as delta networks is attractive because their states must be stored and fetched at every timestep, unlike in convolutional neural networks (CNNs). We show that a naive run-time delta network implementation offers modest improvements on the number of memory accesses and computes, but optimized training techniques confer higher accuracy at higher speedup. With these optimizations, we demonstrate a 9X reduction in cost with negligible loss of accuracy for the TIDIGITS audio digit recognition benchmark. Similarly, on the large Wall Street Journal speech recognition benchmark even existing networks can be greatly accelerated as delta networks, and a 5.7x improvement with negligible loss of accuracy can be obtained through training. Finally, on an end-to-end CNN trained for steering angle prediction in a driving dataset, the RNN cost can be reduced by a substantial 100X. version:1
arxiv-1612-05536 | A new cut-based genetic algorithm for graph partitioning applied to cell formation | http://arxiv.org/abs/1612.05536 | id:1612.05536 author:Boulif Menouar category:cs.DM cs.NE 90C59  published:2016-12-16 summary:Cell formation is a critical step in the design of cellular manufacturing systems. Recently, it was tackled using a cut-based-graph-partitioning model. This model meets real-life production systems requirements as it uses the actual amount of product flows, it looks for the suitable number of cells, and it takes into account the natural constraints such as operation sequences, maximum cell size, cohabitation and non-cohabitation constraints. Based on this model, we propose an original encoding representation to solve the problem by using a genetic algorithm. We discuss the performance of this new GA in comparison to some approaches taken from the literature on a set of medium sized instances. Given the results we obtained, it is reasonable to assume that the new GA will provide similar results for large real-life problems. Keywords: Group Technology, Manufacturing Cell Formation, Graph Partitioning, Graph Cuts, Genetic Algorithm, Encoding representation. version:1
arxiv-1612-05535 | Quantum Machine Learning without Measurements | http://arxiv.org/abs/1612.05535 | id:1612.05535 author:Unai Alvarez-Rodriguez, Lucas Lamata, Pablo Escandell-Montero, José D. Martín-Guerrero, Enrique Solano category:quant-ph cond-mat.mes-hall cond-mat.supr-con cs.AI stat.ML  published:2016-12-16 summary:We propose a quantum machine learning algorithm for efficiently solving a class of problems encoded in quantum controlled unitary operations. The central physical mechanism of the protocol is the iteration of a quantum time-delayed equation that introduces feedback in the dynamics and eliminates the necessity of intermediate measurements. The performance of the quantum algorithm is analyzed by comparing the results obtained in numerical simulations with the outcome of classical machine learning methods for the same problem. The use of time-delayed equations enhances the toolbox of the field of quantum machine learning, which may enable unprecedented applications in quantum technologies. version:1
arxiv-1612-05533 | Deep Reinforcement Learning with Successor Features for Navigation across Similar Environments | http://arxiv.org/abs/1612.05533 | id:1612.05533 author:Jingwei Zhang, Jost Tobias Springenberg, Joschka Boedecker, Wolfram Burgard category:cs.RO cs.AI cs.LG  published:2016-12-16 summary:In this paper we consider the problem of robot navigation in simple maze-like environments where the robot has to rely on its onboard sensors to perform the navigation task. In particular, we are interested in solutions to this navigation task that do not require mapping and localization. Additionally, we require that our solution can quickly adapt to new situations (e.g., changing navigation goals and new environments). To meet these criteria we frame this task as a sequence of reinforcement learning problems over related tasks. We propose a successor feature based deep reinforcement learning algorithm that can learn to transfer knowledge from previously mastered navigation tasks to new problem instances. Our algorithm can substantially decrease the required learning time after the first task instance has been solved, which makes it easily adaptable to changing environments. We validate our method in both simulated and real robot experiments with a Robotino and compare it to a set of baseline methods including classical planning-based navigation. version:1
arxiv-1612-05519 | Edge-exchangeable graphs and sparsity (NIPS 2016) | http://arxiv.org/abs/1612.05519 | id:1612.05519 author:Diana Cai, Trevor Campbell, Tamara Broderick category:stat.ML  published:2016-12-16 summary:Many popular network models rely on the assumption of (vertex) exchangeability, in which the distribution of the graph is invariant to relabelings of the vertices. However, the Aldous-Hoover theorem guarantees that these graphs are dense or empty with probability one, whereas many real-world graphs are sparse. We present an alternative notion of exchangeability for random graphs, which we call edge exchangeability, in which the distribution of a graph sequence is invariant to the order of the edges. We demonstrate that edge-exchangeable models, unlike models that are traditionally vertex-exchangeable, can exhibit sparsity. To do so, we outline a general framework for graph generative models; by contrast to the pioneering work of Caron and Fox (2015), models within our framework are stationary across steps of the graph sequence. In particular, our model grows the graph by instantiating more latent atoms of a single random measure as the dataset size increases, rather than adding new atoms to the measure. version:1
arxiv-1612-05515 | On the crucial impact of the coupling projector-backprojector in iterative tomographic reconstruction | http://arxiv.org/abs/1612.05515 | id:1612.05515 author:Filippo Arcadu, Marco Stampanoni, Federica Marone category:cs.CV  published:2016-12-16 summary:The performance of an iterative reconstruction algorithm for X-ray tomography is strongly determined by the features of the used forward and backprojector. For this reason, a large number of studies has focused on the to design of projectors with increasingly higher accuracy and speed. To what extent the accuracy of an iterative algorithm is affected by the mathematical affinity and the similarity between the actual implementation of the forward and backprojection, referred here as "coupling projector-backprojector", has been an overlooked aspect so far. The experimental study presented here shows that the reconstruction quality and the convergence of an iterative algorithm greatly rely on a good matching between the implementation of the tomographic operators. In comparison, other aspects like the accuracy of the standalone operators, the usage of physical constraints or the choice of stopping criteria may even play a less relevant role. version:1
arxiv-1612-05478 | Video Propagation Networks | http://arxiv.org/abs/1612.05478 | id:1612.05478 author:Varun Jampani, Raghudeep Gadde, Peter V. Gehler category:cs.CV  published:2016-12-16 summary:In this paper we propose a technique that propagates information forward through video data. The method is conceptually simple and can be applied to tasks that require the propagation of structured information, such as semantic labels, based on video content. We propose a 'Video Propagation Network' that processes video frames in an adaptive manner. The model is applied online: it propagates information forward without the need to access future frames other than the current ones. In particular, we combine two components, a temporal bilateral network for dense and video adaptive filtering, followed by a spatial network to refine features and increased flexibility. We present experiments on video object segmentation and semantic video segmentation and show increased performance comparing to the best previous task-specific methods, while having favorable runtime. Additionally we demonstrate our approach on an example regression task of propagating color in a grayscale video. version:1
arxiv-1612-05476 | A Study of Lagrangean Decompositions and Dual Ascent Solvers for Graph Matching | http://arxiv.org/abs/1612.05476 | id:1612.05476 author:Paul Swoboda, Carsten Rother, Hassan Abu Alhaija, Dagmar Kainmueller, Bogdan Savchynskyy category:cs.CV  published:2016-12-16 summary:We study the quadratic assignment problem, in computer vision also known as graph matching. Two leading solvers for this problem optimize the Lagrange decomposition duals with sub-gradient and dual ascent (also known as message passing) updates. We explore s direction further and propose several additional Lagrangean relaxations of the graph matching problem along with corresponding algorithms, which are all based on a common dual ascent framework. Our extensive empirical evaluation gives several theoretical insights and suggests a new state-of-the-art any-time solver for the considered problem. Our improvement over state-of-the-art is particularly visible on a new dataset with large-scale sparse problem instances containing more than 500 graph nodes each. version:1
arxiv-1612-05460 | A Dual Ascent Framework for Lagrangean Decomposition of Combinatorial Problems | http://arxiv.org/abs/1612.05460 | id:1612.05460 author:Paul Swoboda, Jan Kuske, Bogdan Savchynskyy category:cs.DS cs.CV  published:2016-12-16 summary:We propose a general dual ascent framework for Lagrangean decomposition of combinatorial problems. Although methods of this type have shown their efficiency for a number of problems, so far there was no general algorithm applicable to multiple problem types. In his work, we propose such a general algorithm. It depends on several parameters, which can be used to optimize its performance in each particular setting. We demonstrate efficacy of our method on graph matching and multicut problems, where it outperforms state-of-the-art solvers including those based on subgradient optimization and off-the-shelf linear programming solvers. version:1
arxiv-1612-05441 | A Message Passing Algorithm for the Minimum Cost Multicut Problem | http://arxiv.org/abs/1612.05441 | id:1612.05441 author:Paul Swoboda, Bjoern Andres category:cs.DS cs.CV  published:2016-12-16 summary:We propose a dual decomposition and linear program relaxation of the NP -hard minimum cost multicut problem. Unlike other polyhedral relaxations of the multicut polytope, it is amenable to efficient optimization by message passing. Like other polyhedral elaxations, it can be tightened efficiently by cutting planes. We define an algorithm that alternates between message passing and efficient separation of cycle- and odd-wheel inequalities. This algorithm is more efficient than state-of-the-art algorithms based on linear programming, including algorithms written in the framework of leading commercial software, as we show in experiments with large instances of the problem from applications in computer vision, biomedical image analysis and data mining. version:1
arxiv-1612-05424 | Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks | http://arxiv.org/abs/1612.05424 | id:1612.05424 author:Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, Dilip Krishnan category:cs.CV  published:2016-12-16 summary:Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks. One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically. Unfortunately, models trained purely on rendered images often fail to generalize to real images. To address this shortcoming, prior work introduced unsupervised domain adaptation algorithms that attempt to map representations between the two domains or learn to extract features that are domain-invariant. In this work, we present a new approach that learns, in an unsupervised manner, a transformation in the pixel space from one domain to the other. Our generative adversarial network (GAN)-based method adapts source-domain images to appear as if drawn from the target domain. Our approach not only produces plausible samples, but also outperforms the state-of-the-art on a number of unsupervised domain adaptation scenarios by large margins. Finally, we demonstrate that the adaptation process generalizes to object classes unseen during training. version:1
arxiv-1612-05420 | A Two-Phase Approach Towards Identifying Argument Structure in Natural Language | http://arxiv.org/abs/1612.05420 | id:1612.05420 author:Arkanath Pathak, Pawan Goyal, Plaban Bhowmick category:cs.CL  published:2016-12-16 summary:We propose a new approach for extracting argument structure from natural language texts that contain an underlying argument. Our approach comprises of two phases: Score Assignment and Structure Prediction. The Score Assignment phase trains models to classify relations between argument units (Support, Attack or Neutral). To that end, different training strategies have been explored. We identify different linguistic and lexical features for training the classifiers. Through ablation study, we observe that our novel use of word-embedding features is most effective for this task. The Structure Prediction phase makes use of the scores from the Score Assignment phase to arrive at the optimal structure. We perform experiments on three argumentation datasets, namely, AraucariaDB, Debatepedia and Wikipedia. We also propose two baselines and observe that the proposed approach outperforms baseline systems for the final task of Structure Prediction. version:1
arxiv-1612-05400 | Deep Residual Hashing | http://arxiv.org/abs/1612.05400 | id:1612.05400 author:Sailesh Conjeti, Abhijit Guha Roy, Amin Katouzian, Nassir Navab category:cs.CV  published:2016-12-16 summary:Hashing aims at generating highly compact similarity preserving code words which are well suited for large-scale image retrieval tasks. Most existing hashing methods first encode the images as a vector of hand-crafted features followed by a separate binarization step to generate hash codes. This two-stage process may produce sub-optimal encoding. In this paper, for the first time, we propose a deep architecture for supervised hashing through residual learning, termed Deep Residual Hashing (DRH), for an end-to-end simultaneous representation learning and hash coding. The DRH model constitutes four key elements: (1) a sub-network with multiple stacked residual blocks; (2) hashing layer for binarization; (3) supervised retrieval loss function based on neighbourhood component analysis for similarity preserving embedding; and (4) hashing related losses and regularisation to control the quantization error and improve the quality of hash coding. We present results of extensive experiments on a large public chest x-ray image database with co-morbidities and discuss the outcome showing substantial improvements over the latest state-of-the art methods. version:1
