arxiv-14700-1 | Convolutional Pseudo-Prior for Structured Labeling | http://arxiv.org/pdf/1511.07409v1.pdf | author:Saining Xie, Xun Huang, Zhuowen Tu category:cs.CV cs.LG published:2015-11-23 summary:Current practice in convolutional neural networks (CNN) remains largelybottom-up and the role of top-down process in CNN for pattern analysis andvisual inference is not very clear. In this paper, we propose a new method forstructured labeling by developing convolutional pseudo-prior (ConvPP) on theground-truth labels. Our method has several interesting properties: (1)compared with classical machine learning algorithms like CRFs and StructuralSVM, ConvPP automatically learns rich convolutional kernels to capture bothshort- and long- range contexts; (2) compared with cascade classifiers likeAuto-Context, ConvPP avoids the iterative steps of learning a series ofdiscriminative classifiers and automatically learns contextual configurations;(3) compared with recent efforts combing CNN models with CRFs and RNNs, ConvPPlearns convolution in the labeling space with much improved modeling capabilityand less manual specification; (4) compared with Bayesian models like MRFs,ConvPP capitalizes on the rich representation power of convolution byautomatically learning priors built on convolutional filters. We accomplish ourtask using pseudo-likelihood approximation to the prior under a novelfixed-point network structure that facilitates an end-to-end learning process.We show state-of-the-art results on sequential labeling and image labelingbenchmarks.
arxiv-14700-2 | Sparse Recovery via Partial Regularization: Models, Theory and Algorithms | http://arxiv.org/pdf/1511.07293v1.pdf | author:Zhaosong Lu, Xiaorui Li category:math.OC cs.IT cs.LG math.IT stat.ME stat.ML published:2015-11-23 summary:In the context of sparse recovery, it is known that most of existingregularizers such as $\ell_1$ suffer from some bias incurred by some leadingentries (in magnitude) of the associated vector. To neutralize this bias, wepropose a class of models with partial regularizers for recovering a sparsesolution of a linear system. We show that every local minimizer of these modelsis sufficiently sparse or the magnitude of all its nonzero entries is above auniform constant depending only on the data of the linear system. Moreover, fora class of partial regularizers, any global minimizer of these models is asparsest solution to the linear system. We also establish some sufficientconditions for local or global recovery of the sparsest solution to the linearsystem, among which one of the conditions is weaker than the best knownrestricted isometry property (RIP) condition for sparse recovery by $\ell_1$.In addition, a first-order feasible augmented Lagrangian (FAL) method isproposed for solving these models, in which each subproblem is solved by anonmonotone proximal gradient (NPG) method. Despite the complication of thepartial regularizers, we show that each proximal subproblem in NPG can besolved as a certain number of one-dimensional optimization problems, whichusually have a closed-form solution. We also show that any accumulation pointof the sequence generated by FAL is a first-order stationary point of themodels. Numerical results on compressed sensing and sparse logistic regressiondemonstrate that the proposed models substantially outperform the widely usedones in the literature in terms of solution quality.
arxiv-14700-3 | Parallel Predictive Entropy Search for Batch Global Optimization of Expensive Objective Functions | http://arxiv.org/pdf/1511.07130v1.pdf | author:Amar Shah, Zoubin Ghahramani category:cs.LG stat.ML published:2015-11-23 summary:We develop parallel predictive entropy search (PPES), a novel algorithm forBayesian optimization of expensive black-box objective functions. At eachiteration, PPES aims to select a batch of points which will maximize theinformation gain about the global maximizer of the objective. Well knownstrategies exist for suggesting a single evaluation point based on previousobservations, while far fewer are known for selecting batches of points toevaluate in parallel. The few batch selection schemes that have been studiedall resort to greedy methods to compute an optimal batch. To the best of ourknowledge, PPES is the first non-greedy batch Bayesian optimization strategy.We demonstrate the benefit of this approach in optimization performance on bothsynthetic and real world applications, including problems in machine learning,rocket science and robotics.
arxiv-14700-4 | Where To Look: Focus Regions for Visual Question Answering | http://arxiv.org/pdf/1511.07394v2.pdf | author:Kevin J. Shih, Saurabh Singh, Derek Hoiem category:cs.CV published:2015-11-23 summary:We present a method that learns to answer visual questions by selecting imageregions relevant to the text-based query. Our method exhibits significantimprovements in answering questions such as "what color," where it is necessaryto evaluate a specific location, and "what room," where it selectivelyidentifies informative image regions. Our model is tested on the VQA datasetwhich is the largest human-annotated visual question answering dataset to ourknowledge.
arxiv-14700-5 | What Happened to My Dog in That Network: Unraveling Top-down Generators in Convolutional Neural Networks | http://arxiv.org/pdf/1511.07125v1.pdf | author:Patrick W. Gallagher, Shuai Tang, Zhuowen Tu category:cs.NE cs.CV cs.LG stat.ML published:2015-11-23 summary:Top-down information plays a central role in human perception, but playsrelatively little role in many current state-of-the-art deep networks, such asConvolutional Neural Networks (CNNs). This work seeks to explore a path bywhich top-down information can have a direct impact within current deepnetworks. We explore this path by learning and using "generators" correspondingto the network internal effects of three types of transformation (each arestriction of a general affine transformation): rotation, scaling, andtranslation. We demonstrate how these learned generators can be used totransfer top-down information to novel settings, as mediated by the "featureflows" that the transformations (and the associated generators) correspond toinside the network. Specifically, we explore three aspects: 1) using generatorsas part of a method for synthesizing transformed images --- given a previouslyunseen image, produce versions of that image corresponding to one or morespecified transformations, 2) "zero-shot learning" --- when provided with afeature flow corresponding to the effect of a transformation of unknown amount,leverage learned generators as part of a method by which to perform an accuratecategorization of the amount of transformation, even for amounts never observedduring training, and 3) (inside-CNN) "data augmentation" --- improve theclassification performance of an existing network by using the learnedgenerators to directly provide additional training "inside the CNN".
arxiv-14700-6 | Learning Visual Predictive Models of Physics for Playing Billiards | http://arxiv.org/pdf/1511.07404v3.pdf | author:Katerina Fragkiadaki, Pulkit Agrawal, Sergey Levine, Jitendra Malik category:cs.CV published:2015-11-23 summary:The ability to plan and execute goal specific actions in varied, unexpectedsettings is a central requirement of intelligent agents. In this paper, weexplore how an agent can be equipped with an internal model of the dynamics ofthe external world, and how it can use this model to plan novel actions byrunning multiple internal simulations ("visual imagination"). Our modelsdirectly process raw visual input, and use a novel object-centric predictionformulation based on visual glimpses centered on objects (fixations) to enforcetranslational invariance of the learned physical laws. The agent gatherstraining data through random interaction with a collection of differentenvironments, and the resulting model can then be used to plan goal-directedactions in novel environments that the agent has not seen before. Wedemonstrate that our agent can accurately plan actions for playing a simulatedbilliards game, which requires pushing a ball into a target position or intocollision with another ball.
arxiv-14700-7 | Cascading Denoising Auto-Encoder as a Deep Directed Generative Model | http://arxiv.org/pdf/1511.07118v1.pdf | author:Dong-Hyun Lee category:cs.LG published:2015-11-23 summary:Recent work (Bengio et al., 2013) has shown howDenoising Auto-Encoders(DAE)become gener-ative models as a density estimator. However,in practice, theframework suffers from a mixingproblem in the MCMC sampling process andnodirect method to estimate the test log-likelihood.We consider a directedmodel with an stochas-tic identity mapping (simple corruption pro-cess) as aninference model and a DAE as agenerative model. By cascading these mod-els, wepropose Cascading Denoising Auto-Encoders(CDAE) which can generate samplesofdata distribution from tractable prior distributionunder the assumption thatprobabilistic distribu-tion of corrupted data approaches tractablepriordistribution as the level of corruption increases.This work tries toanswer two questions. On theone hand, can deep directed models be success-fullytrained without intractable posterior infer-ence and difficult optimization ofvery deep neu-ral networks in inference and generative mod-els? These areunavoidable when recent suc-cessful directed model like VAE (Kingma &Welling,2014) is trained on complex dataset likereal images. On the other hand, canDAEs getclean samples of data distribution from heavilycorrupted samples whichcan be considered oftractable prior distribution far from data mani-fold?so-called global denoising scheme.Our results show positive responses ofthesequestions and this work can provide fairly simpleframework for generativemodels of very com-plex dataset.
arxiv-14700-8 | On the Generalization Error Bounds of Neural Networks under Diversity-Inducing Mutual Angular Regularization | http://arxiv.org/pdf/1511.07110v1.pdf | author:Pengtao Xie, Yuntian Deng, Eric Xing category:cs.LG published:2015-11-23 summary:Recently diversity-inducing regularization methods for latent variable models(LVMs), which encourage the components in LVMs to be diverse, have been studiedto address several issues involved in latent variable modeling: (1) how tocapture long-tail patterns underlying data; (2) how to reduce model complexitywithout sacrificing expressivity; (3) how to improve the interpretability oflearned patterns. While the effectiveness of diversity-inducing regularizerssuch as the mutual angular regularizer has been demonstrated empirically, arigorous theoretical analysis of them is still missing. In this paper, we aimto bridge this gap and analyze how the mutual angular regularizer (MAR) affectsthe generalization performance of supervised LVMs. We use neural network (NN)as a model instance to carry out the study and the analysis shows thatincreasing the diversity of hidden units in NN would reduce estimation errorand increase approximation error. In addition to theoretical analysis, we alsopresent empirical study which demonstrates that the MAR can greatly improve theperformance of NN and the empirical observations are in accordance with thetheoretical analysis.
arxiv-14700-9 | Multi-Volume High Resolution RGB-D Mapping with Dynamic Volume Placement | http://arxiv.org/pdf/1511.07106v1.pdf | author:Michael Salvato, Ross Finman, John Leonard category:cs.RO cs.CV published:2015-11-23 summary:We present a novel RGB-D mapping system for generating 3D maps over spatiallyextended regions with higher resolution than current methods using multiple,dynamically placed mapping volumes. Our method takes in RGB-D frames anddynamically assigns multiple mapping volumes to the environment, exchangingmapping volumes between the CPU and GPU. Mapping volumes are added or removedas needed to allow for spatially extended, high resolution mapping. Our systemis designed to maximize the resolution possible for such volumetric methods,while working on an unbounded space.
arxiv-14700-10 | Pushing the Boundaries of Boundary Detection using Deep Learning | http://arxiv.org/pdf/1511.07386v2.pdf | author:Iasonas Kokkinos category:cs.CV cs.LG published:2015-11-23 summary:In this work we show that adapting Deep Convolutional Neural Network trainingto the task of boundary detection can result in substantial improvements overthe current state-of-the-art in boundary detection. Our contributions consist firstly in combining a careful design of the lossfor boundary detection training, a multi-resolution architecture and trainingwith external data to improve the detection accuracy of the current state ofthe art. When measured on the standard Berkeley Segmentation Dataset, weimprove theoptimal dataset scale F-measure from 0.780 to 0.808 - while humanperformance is at 0.803. We further improve performance to 0.813 by combiningdeep learning with grouping, integrating the Normalized Cuts technique within adeep network. We also examine the potential of our boundary detector in conjunction withthe task of semantic segmentation and demonstrate clear improvements overstate-of-the-art systems. Our detector is fully integrated in the popular Caffeframework and processes a 320x420 image in less than a second.
arxiv-14700-11 | GPU-based Acceleration of Deep Convolutional Neural Networks on Mobile Platforms | http://arxiv.org/pdf/1511.07376v1.pdf | author:Seyyed Salar Latifi Oskouei, Hossein Golestani, Mohamad Kachuee, Matin Hashemi, Hoda Mohammadzade, Soheil Ghiasi category:cs.DC cs.CV published:2015-11-23 summary:Mobile applications running on wearable devices and smartphones can greatlybenefit from accurate and scalable deep CNN-based machine learning algorithms.While mobile CPU performance does not match the intensive computationalrequirement of deep CNNs, the embedded GPU which already exists in many mobileplatforms can be leveraged for acceleration of CNN computations on the localdevice and without the use of a cloud service. We present a GPU-basedaccelerated deep CNN engine for mobile platforms with upto 60X speedup.
arxiv-14700-12 | Node Specificity in Convolutional Deep Nets Depends on Receptive Field Position and Size | http://arxiv.org/pdf/1511.07347v1.pdf | author:Karl Zipser category:cs.CV published:2015-11-23 summary:In convolutional deep neural networks, receptive field (RF) size increaseswith hierarchical depth. When RF size approaches full coverage of the inputimage, different RF positions result in RFs with different specificity, asportions of the RF fall out of the input space. This leads to a departure fromthe convolutional concept of positional invariance and opens the possibilityfor complex forms of context specificity.
arxiv-14700-13 | Estimating the number of unseen species: A bird in the hand is worth $\log n $ in the bush | http://arxiv.org/pdf/1511.07428v3.pdf | author:Alon Orlitsky, Ananda Theertha Suresh, Yihong Wu category:math.ST stat.ML stat.TH published:2015-11-23 summary:Estimating the number of unseen species is an important problem in manyscientific endeavors. Its most popular formulation, introduced by Fisher, uses$n$ samples to predict the number $U$ of hitherto unseen species that would beobserved if $t\cdot n$ new samples were collected. Of considerable interest isthe largest ratio $t$ between the number of new and existing samples for which$U$ can be accurately predicted. In seminal works, Good and Toulmin constructed an intriguing estimator thatpredicts $U$ for all $t\le 1$, thereby showing that the number of species canbe estimated for a population twice as large as that observed. SubsequentlyEfron and Thisted obtained a modified estimator that empirically predicts $U$even for some $t>1$, but without provable guarantees. We derive a class of estimators that $\textit{provably}$ predict $U$ not justfor constant $t>1$, but all the way up to $t$ proportional to $\log n$. Thisshows that the number of species can be estimated for a population $\log n$times larger than that observed, a factor that grows arbitrarily large as $n$increases. We also show that this range is the best possible and that theestimators' mean-square error is optimal up to constants for any $t$. Ourapproach yields the first provable guarantee for the Efron-Thisted estimatorand, in addition, a variant which achieves stronger theoretical andexperimental performance than existing methodologies on a variety of syntheticand real datasets. The estimators we derive are simple linear estimators that are computable intime proportional to $n$. The performance guarantees hold uniformly for alldistributions, and apply to all four standard sampling models commonly usedacross various scientific disciplines: multinomial, Poisson, hypergeometric,and Bernoulli product.
arxiv-14700-14 | Stochastic Parallel Block Coordinate Descent for Large-scale Saddle Point Problems | http://arxiv.org/pdf/1511.07294v1.pdf | author:Zhanxing Zhu, Amos J. Storkey category:stat.ML published:2015-11-23 summary:We consider convex-concave saddle point problems with a separable structureand non-strongly convex functions. We propose an efficient stochastic blockcoordinate descent method using adaptive primal-dual updates, which enablesflexible parallel optimization for large-scale problems. Our method shares theefficiency and flexibility of block coordinate descent methods with thesimplicity of primal-dual methods and utilizing the structure of the separableconvex-concave saddle point problem. It is capable of solving a wide range ofmachine learning applications, including robust principal component analysis,Lasso, and feature selection by group Lasso, etc. Theoretically andempirically, we demonstrate significantly better performance thanstate-of-the-art methods in all these applications.
arxiv-14700-15 | Switched Dynamical Latent Force Models for Modelling Transcriptional Regulation | http://arxiv.org/pdf/1511.07334v1.pdf | author:Andrés F. López-Lopera, Mauricio A. Álvarez category:physics.bio-ph stat.ML published:2015-11-23 summary:In order to develop statistical approaches for transcription networks,statistical community has proposed several methods to infer activity levels ofproteins, from time-series measurements of targets' expression levels. A fewnumber of approaches have been proposed in order to outperform therepresentation of fast switching time instants, but computational overheads aresignificant due to complex inference algorithms. Using the theory related tolatent force models (LFM), the development of this project provide a switcheddynamical hybrid model based on Gaussian processes (GPs). To deal withdiscontinuities in dynamical systems (or latent driving force), an extension ofthe single input motif approach is introduced, that switches between differentprotein concentrations, and different dynamical systems. This creates aversatile representation for transcription networks that can capture discretechanges and non-linearities in the dynamics. The proposed method is evaluatedon both simulated data and real data, concluding that our framework provides acomputationally efficient statistical inference module of continuous-timeconcentration profiles, and allows an easy estimation of the associated modelparameters.
arxiv-14700-16 | Modular Autoencoders for Ensemble Feature Extraction | http://arxiv.org/pdf/1511.07340v1.pdf | author:Henry W J Reeve, Gavin Brown category:cs.LG published:2015-11-23 summary:We introduce the concept of a Modular Autoencoder (MAE), capable of learninga set of diverse but complementary representations from unlabelled data, thatcan later be used for supervised tasks. The learning of the representations iscontrolled by a trade off parameter, and we show on six benchmark datasets theoptimum lies between two extremes: a set of smaller, independent autoencoderseach with low capacity, versus a single monolithic encoding, outperforming anappropriate baseline. In the present paper we explore the special case oflinear MAE, and derive an SVD-based algorithm which converges several orders ofmagnitude faster than gradient descent.
arxiv-14700-17 | Multiple--Instance Learning: Christoffel Function Approach to Distribution Regression Problem | http://arxiv.org/pdf/1511.07085v1.pdf | author:Vladislav Gennadievich Malyshkin category:cs.LG published:2015-11-22 summary:A two--step Christoffel function based solution is proposed to distributionregression problem. On the first step, to model distribution of observationsinside a bag, build Christoffel function for each bag of observations. Then, onthe second step, build outcome variable Christoffel function, but use the bag'sChristoffel function value at given point as the weight for the bag's outcome.The approach allows the result to be obtained in closed form and then to beevaluated numerically. While most of existing approaches minimize some kind anerror between outcome and prediction, the proposed approach is conceptuallydifferent, because it uses Christoffel function for knowledge representation,what is conceptually equivalent working with probabilities only. To receivepossible outcomes and their probabilities Gauss quadrature for second--stepmeasure can be built, then the nodes give possible outcomes and normalizedweights -- outcome probabilities. A library providing numerically stablepolynomial basis for these calculations is available, what make the proposedapproach practical.
arxiv-14700-18 | A Plausible Memristor Implementation of Deep Learning Neural Networks | http://arxiv.org/pdf/1511.07076v1.pdf | author:D. V. Negrov, I. M. Karandashev, V. V. Shakirov, Yu. A. Matveyev, W. L. Dunin-Barkowski, A. V. Zenkevich category:cs.NE cs.ET published:2015-11-22 summary:A possible method for hardware implementation of multilayer neural networkswith the back-propagation learning algorithm employing memristor cross-barmatrices for weight storage is modeled. The proposed approach offers anefficient way to perform both learning and recognition operations. The solutionof several arising problems, such as the representation and multiplication ofsignals as well as error propagation is proposed.
arxiv-14700-19 | Online Semi-Supervised Learning with Deep Hybrid Boltzmann Machines and Denoising Autoencoders | http://arxiv.org/pdf/1511.06964v7.pdf | author:Alexander G. Ororbia II, C. Lee Giles, David Reitter category:cs.LG published:2015-11-22 summary:Two novel deep hybrid architectures, the Deep Hybrid Boltzmann Machine andthe Deep Hybrid Denoising Auto-encoder, are proposed for handlingsemi-supervised learning problems. The models combine experts that modelrelevant distributions at different levels of abstraction to improve overallpredictive performance on discriminative tasks. Theoretical motivations andalgorithms for joint learning for each are presented. We apply the new modelsto the domain of data-streams in work towards life-long learning. The proposedarchitectures show improved performance compared to a pseudo-labeled, drop-outrectifier network.
arxiv-14700-20 | SceneNet: Understanding Real World Indoor Scenes With Synthetic Data | http://arxiv.org/pdf/1511.07041v2.pdf | author:Ankur Handa, Viorica Patraucean, Vijay Badrinarayanan, Simon Stent, Roberto Cipolla category:cs.CV published:2015-11-22 summary:Scene understanding is a prerequisite to many high level tasks for anyautomated intelligent machine operating in real world environments. Recentattempts with supervised learning have shown promise in this direction but alsohighlighted the need for enormous quantity of supervised data --- performanceincreases in proportion to the amount of data used. However, this quicklybecomes prohibitive when considering the manual labour needed to collect suchdata. In this work, we focus our attention on depth based semantic per-pixellabelling as a scene understanding problem and show the potential of computergraphics to generate virtually unlimited labelled data from synthetic 3Dscenes. By carefully synthesizing training data with appropriate noise modelswe show comparable performance to state-of-the-art RGBD systems on NYUv2dataset despite using only depth data as input and set a benchmark ondepth-based segmentation on SUN RGB-D dataset. Additionally, we offer a routeto generating synthesized frame or video data, and understanding of differentfactors influencing performance gains.
arxiv-14700-21 | Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings Using Abstract Scenes | http://arxiv.org/pdf/1511.07067v1.pdf | author:Satwik Kottur, Ramakrishna Vedantam, José M. F. Moura, Devi Parikh category:cs.CV cs.CL published:2015-11-22 summary:We propose a model to learn visually grounded word embeddings (vis-w2v) tocapture visual notions of semantic relatedness. While word embeddings trainedusing text have been extremely successful, they cannot uncover notions ofsemantic relatedness implicit in our visual world. For instance, visualgrounding can help us realize that concepts like eating and staring at arerelated, since when people are eating something, they also tend to stare at thefood. Grounding a rich variety of relations like eating and stare at in visionis a challenging task, despite recent progress in vision. We realize the visualgrounding for words depends on the semantics of our visual world, and not theliteral pixels. We thus use abstract scenes created from clipart to provide thevisual grounding. We find that the embeddings we learn capture fine-grainedvisually grounded notions of semantic relatedness. We show improvements overtext only word embeddings (word2vec) on three tasks: common-sense assertionclassification, visual paraphrasing and text-based image retrieval. Our codeand datasets will be available online.
arxiv-14700-22 | Evolutionary algorithms | http://arxiv.org/pdf/1511.06987v1.pdf | author:Anton V. Eremeev category:cs.NE published:2015-11-22 summary:This manuscript contains an outline of lectures course "EvolutionaryAlgorithms" read by the author in Omsk State University n.a. F.M.Dostoevsky.The course covers Canonic Genetic Algorithm and various other geneticalgorithms as well as evolutioanry algorithms in general. Some facts, such asthe Rotation Property of crossover, the Schemata Theorem, GA performance as alocal search and "almost surely" convergence of evolutionary algorithms aregiven with complete proofs. The text is in Russian.
arxiv-14700-23 | Ask Me Anything: Free-form Visual Question Answering Based on Knowledge from External Sources | http://arxiv.org/pdf/1511.06973v2.pdf | author:Qi Wu, Peng Wang, Chunhua Shen, Anthony Dick, Anton van den Hengel category:cs.CV published:2015-11-22 summary:We propose a method for visual question answering which combines an internalrepresentation of the content of an image with information extracted from ageneral knowledge base to answer a broad range of image-based questions. Thisallows more complex questions to be answered using the predominant neuralnetwork-based approach than has previously been possible. It particularlyallows questions to be asked about the contents of an image, even when theimage itself does not contain the whole answer. The method constructs a textualrepresentation of the semantic content of an image, and merges it with textualinformation sourced from a knowledge base, to develop a deeper understanding ofthe scene viewed. Priming a recurrent neural network with this combinedinformation, and the submitted question, leads to a very flexible visualquestion answering approach. We are specifically able to answer questions posedin natural language, that refer to information not contained in the image. Wedemonstrate the effectiveness of our model on two publicly available datasets,Toronto COCO-QA and MS COCO-VQA and show that it produces the best reportedresults in both cases.
arxiv-14700-24 | Fine-grained pose prediction, normalization, and recognition | http://arxiv.org/pdf/1511.07063v1.pdf | author:Ning Zhang, Evan Shelhamer, Yang Gao, Trevor Darrell category:cs.CV published:2015-11-22 summary:Pose variation and subtle differences in appearance are key challenges tofine-grained classification. While deep networks have markedly improved generalrecognition, many approaches to fine-grained recognition rely on anchoringnetworks to parts for better accuracy. Identifying parts to find correspondencediscounts pose variation so that features can be tuned to appearance. To thisend previous methods have examined how to find parts and extractpose-normalized features. These methods have generally separated fine-grainedrecognition into stages which first localize parts using hand-engineered andcoarsely-localized proposal features, and then separately learn deepdescriptors centered on inferred part positions. We unify these steps in anend-to-end trainable network supervised by keypoint locations and class labelsthat localizes parts by a fully convolutional network to focus the learning offeature representations for the fine-grained classification task. Experimentson the popular CUB200 dataset show that our method is state-of-the-art andsuggest a continuing role for strong supervision.
arxiv-14700-25 | Detecting Road Surface Wetness from Audio: A Deep Learning Approach | http://arxiv.org/pdf/1511.07035v2.pdf | author:Irman Abdić, Lex Fridman, Erik Marchi, Daniel E Brown, William Angell, Bryan Reimer, Björn Schuller category:cs.LG cs.NE cs.SD published:2015-11-22 summary:We introduce a recurrent neural network architecture for automated roadsurface wetness detection from audio of tire-surface interaction. Therobustness of our approach is evaluated on 785,826 bins of audio that span anextensive range of vehicle speeds, noises from the environment, road surfacetypes, and pavement conditions including international roughness index (IRI)values from 25 in/mi to 1400 in/mi. The training and evaluation of the modelare performed on different roads to minimize the impact of environmental andother external factors on the accuracy of the classification. We achieve anunweighted average recall (UAR) of 93.2% across all vehicle speeds including 0mph. The classifier still works at 0 mph because the discriminating signal ispresent in the sound of other vehicles driving by.
arxiv-14700-26 | End-to-end Learning of Action Detection from Frame Glimpses in Videos | http://arxiv.org/pdf/1511.06984v1.pdf | author:Serena Yeung, Olga Russakovsky, Greg Mori, Li Fei-Fei category:cs.CV cs.LG published:2015-11-22 summary:In this work we introduce a fully end-to-end approach for action detection invideos that learns to directly predict the temporal bounds of actions. Ourintuition is that the process of detecting actions is naturally one ofobservation and refinement: observing moments in video, and refining hypothesesabout when an action is occurring. Based on this insight, we formulate ourmodel as a recurrent neural network-based agent that interacts with a videoover time. The agent observes video frames and decides both where to look nextand when to emit a prediction. Since backpropagation is not adequate in thisnon-differentiable setting, we use REINFORCE to learn the agent's decisionpolicy. Our model achieves state-of-the-art results on the THUMOS'14 andActivityNet datasets while observing only a fraction (2% or less) of the videoframes.
arxiv-14700-27 | Anvaya: An Algorithm and Case-Study on Improving the Goodness of Software Process Models generated by Mining Event-Log Data in Issue Tracking System | http://arxiv.org/pdf/1511.07023v1.pdf | author:Prerna Juneja, Divya Kundra, Ashish Sureka category:cs.SE cs.LG published:2015-11-22 summary:Issue Tracking Systems (ITS) such as Bugzilla can be viewed as Process AwareInformation Systems (PAIS) generating event-logs during the life-cycle of a bugreport. Process Mining consists of mining event logs generated from PAIS forprocess model discovery, conformance and enhancement. We apply process mapdiscovery techniques to mine event trace data generated from ITS of open sourceFirefox browser project to generate and study process models. Bug life-cycleconsists of diversity and variance. Therefore, the process models generatedfrom the event-logs are spaghetti-like with large number of edges,inter-connections and nodes. Such models are complex to analyse and difficultto comprehend by a process analyst. We improve the Goodness (fitness andstructural complexity) of the process models by splitting the event-log intohomogeneous subsets by clustering structurally similar traces. We adapt theK-Medoid clustering algorithm with two different distance metrics: LongestCommon Subsequence (LCS) and Dynamic Time Warping (DTW). We evaluate thegoodness of the process models generated from the clusters using complexity andfitness metrics. We study back-forth \& self-loops, bug reopening, andbottleneck in the clusters obtained and show that clustering enables betteranalysis. We also propose an algorithm to automate the clustering process -thealgorithm takes as input the event log and returns the best cluster set.
arxiv-14700-28 | Analysis of a Play by Means of CHAPLIN, the Characters and Places Interaction Network Software | http://arxiv.org/pdf/1511.07001v1.pdf | author:A. C. Sparavigna, R. Marazzato category:cs.CY cs.CL cs.SI published:2015-11-22 summary:Recently, we have developed a software able of gathering information onsocial networks from written texts. This software, the CHAracters and PLacesInteraction Network (CHAPLIN) tool, is implemented in Visual Basic. By means ofit, characters and places of a literary work can be extracted from a list ofraw words. The software interface helps users to select their names out of thislist. Setting some parameters, CHAPLIN creates a network where nodes representcharacters/places and edges give their interactions. Nodes and edges arelabelled by performances. In this paper, we propose to use CHAPLIN for theanalysis a William Shakespeare's play, the famous 'Tragedy of Hamlet, Prince ofDenmark'. Performances of characters in the play as a whole and in each act ofit are given by graphs.
arxiv-14700-29 | On the Linear Algebraic Structure of Distributed Word Representations | http://arxiv.org/pdf/1511.06961v1.pdf | author:Lisa Seung-Yeon Lee category:cs.CL cs.LG published:2015-11-22 summary:In this work, we leverage the linear algebraic structure of distributed wordrepresentations to automatically extend knowledge bases and allow a machine tolearn new facts about the world. Our goal is to extract structured facts fromcorpora in a simpler manner, without applying classifiers or patterns, andusing only the co-occurrence statistics of words. We demonstrate that thelinear algebraic structure of word embeddings can be used to reduce datarequirements for methods of learning facts. In particular, we demonstrate thatwords belonging to a common category, or pairs of words satisfying a certainrelation, form a low-rank subspace in the projected space. We compute a basisfor this low-rank subspace using singular value decomposition (SVD), then usethis basis to discover new facts and to fit vectors for less frequent wordswhich we do not yet have vectors for.
arxiv-14700-30 | Learning High-level Prior with Convolutional Neural Networks for Semantic Segmentation | http://arxiv.org/pdf/1511.06988v1.pdf | author:Haitian Zheng, Yebin Liu, Mengqi Ji, Feng Wu, Lu Fang category:cs.CV published:2015-11-22 summary:This paper proposes a convolutional neural network that can fuse high-levelprior for semantic image segmentation. Motivated by humans' vision recognitionsystem, our key design is a three-layer generative structure consisting ofhigh-level coding, middle-level segmentation and low-level image to introduceglobal prior for semantic segmentation. Based on this structure, we proposed agenerative model called conditional variational auto-encoder (CVAE) that canbuild up the links behind these three layers. These important links include animage encoder that extracts high level info from image, a segmentation encoderthat extracts high level info from segmentation, and a hybrid decoder thatoutputs semantic segmentation from the high level prior and input image. Wetheoretically derive the semantic segmentation as an optimization problemparameterized by these links. Finally, the optimization problem enables us totake advantage of state-of-the-art fully convolutional network structure forthe implementation of the above encoders and decoder. Experimental results onseveral representative datasets demonstrate our supreme performance forsemantic segmentation.
arxiv-14700-31 | Gradual DropIn of Layers to Train Very Deep Neural Networks | http://arxiv.org/pdf/1511.06951v1.pdf | author:Leslie N. Smith, Emily M. Hand, Timothy Doster category:cs.NE cs.CV cs.LG published:2015-11-22 summary:We introduce the concept of dynamically growing a neural network duringtraining. In particular, an untrainable deep network starts as a trainableshallow network and newly added layers are slowly, organically added duringtraining, thereby increasing the network's depth. This is accomplished by a newlayer, which we call DropIn. The DropIn layer starts by passing the output froma previous layer (effectively skipping over the newly added layers), thenincreasingly including units from the new layers for both feedforward andbackpropagation. We show that deep networks, which are untrainable withconventional methods, will converge with DropIn layers interspersed in thearchitecture. In addition, we demonstrate that DropIn provides regularizationduring training in an analogous way as dropout. Experiments are described withthe MNIST dataset and various expanded LeNet architectures, CIFAR-10 datasetwith its architecture expanded from 3 to 11 layers, and on the ImageNet datasetwith the AlexNet architecture expanded to 13 layers and the VGG 16-layerarchitecture.
arxiv-14700-32 | Auxiliary Image Regularization for Deep CNNs with Noisy Labels | http://arxiv.org/pdf/1511.07069v2.pdf | author:Samaneh Azadi, Jiashi Feng, Stefanie Jegelka, Trevor Darrell category:cs.CV published:2015-11-22 summary:Precisely-labeled data sets with sufficient amount of samples are veryimportant for training deep convolutional neural networks (CNNs). However, manyof the available real-world data sets contain erroneously labeled samples andthose errors substantially hinder the learning of very accurate CNN models. Inthis work, we consider the problem of training a deep CNN model for imageclassification with mislabeled training samples - an issue that is common inreal image data sets with tags supplied by amateur users. To solve thisproblem, we propose an auxiliary image regularization technique, optimized bythe stochastic Alternating Direction Method of Multipliers (ADMM) algorithm,that automatically exploits the mutual context information among trainingimages and encourages the model to select reliable images to robustify thelearning process. Comprehensive experiments on benchmark data sets clearlydemonstrate our proposed regularized CNN model is resistant to label noise intraining data.
arxiv-14700-33 | Non-Sentential Utterances in Dialogue: Experiments in Classification and Interpretation | http://arxiv.org/pdf/1511.06995v1.pdf | author:Paolo Dragone category:cs.CL cs.AI published:2015-11-22 summary:Non-sentential utterances (NSUs) are utterances that lack a completesentential form but whose meaning can be inferred from the dialogue context,such as "OK", "where?", "probably at his apartment". The interpretation ofnon-sentential utterances is an important problem in computational linguisticssince they constitute a frequent phenomena in dialogue and they areintrinsically context-dependent. The interpretation of NSUs is the task ofretrieving their full semantic content from their form and the dialoguecontext. The first half of this thesis is devoted to the NSU classificationtask. Our work builds upon Fern\'andez et al. (2007) which present a series ofmachine-learning experiments on the classification of NSUs. We extended theirapproach with a combination of new features and semi-supervised learningtechniques. The empirical results presented in this thesis show a modest butsignificant improvement over the state-of-the-art classification performance.The consecutive, yet independent, problem is how to infer an appropriatesemantic representation of such NSUs on the basis of the dialogue context.Fern\'andez (2006) formalizes this task in terms of "resolution rules" built ontop of the Type Theory with Records (TTR). Our work is focused on thereimplementation of the resolution rules from Fern\'andez (2006) with aprobabilistic account of the dialogue state. The probabilistic rules formalismLison (2014) is particularly suited for this task because, similarly to theframework developed by Ginzburg (2012) and Fern\'andez (2006), it involves thespecification of update rules on the variables of the dialogue state to capturethe dynamics of the conversation. However, the probabilistic rules can alsoencode probabilistic knowledge, thereby providing a principled account ofambiguities in the NSU resolution process.
arxiv-14700-34 | ReSeg: A Recurrent Neural Network for Object Segmentation | http://arxiv.org/pdf/1511.07053v2.pdf | author:Francesco Visin, Kyle Kastner, Aaron Courville, Yoshua Bengio, Matteo Matteucci, Kyunghyun Cho category:cs.CV cs.LG published:2015-11-22 summary:We propose a structured prediction architecture for images centered arounddeep recurrent neural networks. The proposed network, called ReSeg, is based onthe recently introduced ReNet model for object classification. We modify andextend it to perform object segmentation, noting that the avoidance of poolingcan greatly simplify pixel-wise tasks for images. The ReSeg layer is composedof four recurrent neural networks that sweep the image horizontally andvertically in both directions, along with a final layer that expands theprediction back to the original image size. ReSeg combines multiple ReSeglayers with several possible input layers as well as a final layer whichexpands the prediction back to the original image size, making it suitable fora variety of structured prediction tasks. We evaluate ReSeg on the specifictask of object segmentation with three widely-used image segmentation datasets,namely Weizmann Horse, Fashionista and Oxford Flower. The results suggest thatReSeg can challenge the state of the art in object segmentation, and may havefurther applications in structured prediction at large.
arxiv-14700-35 | TransCut: Transparent Object Segmentation from a Light-Field Image | http://arxiv.org/pdf/1511.06853v1.pdf | author:Yichao Xu, Hajime Nagahara, Atsushi Shimada, Rin-ichiro Taniguchi category:cs.CV published:2015-11-21 summary:The segmentation of transparent objects can be very useful in computer visionapplications. However, because they borrow texture from their background andhave a similar appearance to their surroundings, transparent objects are nothandled well by regular image segmentation methods. We propose a method thatovercomes these problems using the consistency and distortion properties of alight-field image. Graph-cut optimization is applied for the pixel labelingproblem. The light-field linearity is used to estimate the likelihood of apixel belonging to the transparent object or Lambertian background, and theocclusion detector is used to find the occlusion boundary. We acquire a lightfield dataset for the transparent object, and use this dataset to evaluate ourmethod. The results demonstrate that the proposed method successfully segmentstransparent objects from the background.
arxiv-14700-36 | Mapping Images to Sentiment Adjective Noun Pairs with Factorized Neural Nets | http://arxiv.org/pdf/1511.06838v1.pdf | author:Takuya Narihira, Damian Borth, Stella X. Yu, Karl Ni, Trevor Darrell category:cs.CV cs.CL published:2015-11-21 summary:We consider the visual sentiment task of mapping an image to an adjectivenoun pair (ANP) such as "cute baby". To capture the two-factor structure of ourANP semantics as well as to overcome annotation noise and ambiguity, we proposea novel factorized CNN model which learns separate representations foradjectives and nouns but optimizes the classification performance over theirproduct. Our experiments on the publicly available SentiBank dataset show thatour model significantly outperforms not only independent ANP classifiers onunseen ANPs and on retrieving images of novel ANPs, but also image captioningmodels which capture word semantics from co-occurrence of natural text; thelatter turn out to be surprisingly poor at capturing the sentiment evoked bypure visual experience. That is, our factorized ANP CNN not only trains betterfrom noisy labels, generalizes better to new images, but can also expands theANP vocabulary on its own.
arxiv-14700-37 | Gaussian Process Planning with Lipschitz Continuous Reward Functions: Towards Unifying Bayesian Optimization, Active Learning, and Beyond | http://arxiv.org/pdf/1511.06890v1.pdf | author:Chun Kai Ling, Kian Hsiang Low, Patrick Jaillet category:stat.ML cs.AI cs.LG cs.RO published:2015-11-21 summary:This paper presents a novel nonmyopic adaptive Gaussian process planning(GPP) framework endowed with a general class of Lipschitz continuous rewardfunctions that can unify some active learning/sensing and Bayesian optimizationcriteria and offer practitioners some flexibility to specify their desiredchoices for defining new tasks/problems. In particular, it utilizes aprincipled Bayesian sequential decision problem framework for jointly andnaturally optimizing the exploration-exploitation trade-off. In general, theresulting induced GPP policy cannot be derived exactly due to an uncountableset of candidate observations. A key contribution of our work here thus lies inexploiting the Lipschitz continuity of the reward functions to solve for anonmyopic adaptive epsilon-optimal GPP (epsilon-GPP) policy. To plan in realtime, we further propose an asymptotically optimal, branch-and-bound anytimevariant of epsilon-GPP with performance guarantee. We empirically demonstratethe effectiveness of our epsilon-GPP policy and its anytime variant in Bayesianoptimization and an energy harvesting task.
arxiv-14700-38 | ICU Patient Deterioration prediction: a Data-Mining Approach | http://arxiv.org/pdf/1511.06910v1.pdf | author:Noura AlNuaimi, Mohammad M Masud, Farhan Mohammed category:cs.CY cs.LG published:2015-11-21 summary:A huge amount of medical data is generated every day, which presents achallenge in analysing these data. The obvious solution to this challenge is toreduce the amount of data without information loss. Dimension reduction isconsidered the most popular approach for reducing data size and also to reducenoise and redundancies in data. In this paper, we investigate the effect offeature selection in improving the prediction of patient deterioration in ICUs.We consider lab tests as features. Thus, choosing a subset of features wouldmean choosing the most important lab tests to perform. If the number of testscan be reduced by identifying the most important tests, then we could alsoidentify the redundant tests. By omitting the redundant tests, observation timecould be reduced and early treatment could be provided to avoid the risk.Additionally, unnecessary monetary cost would be avoided. Our approach usesstate-ofthe- art feature selection for predicting ICU patient deteriorationusing the medical lab results. We apply our technique on the publicly availableMIMIC-II database and show the effectiveness of the feature selection. We alsoprovide a detailed analysis of the best features identified by our approach.
arxiv-14700-39 | Zoom Better to See Clearer: Human and Object Parsing with Hierarchical Auto-Zoom Net | http://arxiv.org/pdf/1511.06881v5.pdf | author:Fangting Xia, Peng Wang, Liang-Chieh Chen, Alan L. Yuille category:cs.CV cs.LG published:2015-11-21 summary:Parsing articulated objects, e.g. humans and animals, into semantic parts(e.g. body, head and arms, etc.) from natural images is a challenging andfundamental problem for computer vision. A big difficulty is the largevariability of scale and location for objects and their corresponding parts.Even limited mistakes in estimating scale and location will degrade the parsingoutput and cause errors in boundary details. To tackle these difficulties, wepropose a "Hierarchical Auto-Zoom Net" (HAZN) for object part parsing whichadapts to the local scales of objects and parts. HAZN is a sequence of two"Auto-Zoom Net" (AZNs), each employing fully convolutional networks thatperform two tasks: (1) predict the locations and scales of object instances(the first AZN) or their parts (the second AZN); (2) estimate the part scoresfor predicted object instance or part regions. Our model can adaptively "zoom"(resize) predicted image regions into their proper scales to refine theparsing. We conduct extensive experiments over the PASCAL part datasets on humans,horses, and cows. For humans, our approach significantly outperforms thestate-of-the-arts by 5% mIOU and is especially better at segmenting smallinstances and small parts. We obtain similar improvements for parsing cows andhorses over alternative methods. In summary, our strategy of first zooming intoobjects and then zooming into parts is very effective. It also enables us toprocess different regions of the image at different scales adaptively so that,for example, we do not need to waste computational resources scaling the entireimage.
arxiv-14700-40 | Data-dependent Initializations of Convolutional Neural Networks | http://arxiv.org/pdf/1511.06856v2.pdf | author:Philipp Krähenbühl, Carl Doersch, Jeff Donahue, Trevor Darrell category:cs.CV cs.LG published:2015-11-21 summary:Convolutional Neural Networks spread through computer vision like a wildfire,impacting almost all visual tasks imaginable. Despite this, few researchersdare to train their models from scratch. Most work builds on one of a handfulof ImageNet pre-trained models, and fine-tunes or adapts these for specifictasks. This is in large part due to the difficulty of properly initializingthese networks from scratch. A small miscalibration of the initial weightsleads to vanishing or exploding gradients, as well as poor convergenceproperties. In this work we present a fast and simple data-dependentinitialization procedure, that sets the weights of a network such that allunits in the network train at roughly the same rate, avoiding vanishing orexploding gradients. Our initialization matches the current state-of-the-artunsupervised or self-supervised pre-training methods on standard computervision tasks, such as image classification and object detection, while beingroughly three orders of magnitude faster. When combined with pre-trainingmethods, our initialization significantly outperforms prior work, narrowing thegap between supervised and unsupervised pre-training.
arxiv-14700-41 | Screen Content Image Segmentation Using Sparse-Smooth Decomposition | http://arxiv.org/pdf/1511.06911v1.pdf | author:Shervin Minaee, Amirali Abdolrashidi, Yao Wang category:cs.CV published:2015-11-21 summary:Sparse decomposition has been extensively used for different applicationsincluding signal compression and denoising and document analysis. In thispaper, sparse decomposition is used for image segmentation. The proposedalgorithm separates the background and foreground using a sparse-smoothdecomposition technique such that the smooth and sparse components correspondto the background and foreground respectively. This algorithm is tested onseveral test images from HEVC test sequences and is shown to have superiorperformance over other methods, such as the hierarchical k-means clustering inDjVu. This segmentation algorithm can also be used for text extraction, videocompression and medical image segmentation.
arxiv-14700-42 | Semantic Segmentation of Colon Glands with Deep Convolutional Neural Networks and Total Variation Segmentation | http://arxiv.org/pdf/1511.06919v1.pdf | author:Philipp Kainz, Michael Pfeiffer, Martin Urschler category:cs.CV published:2015-11-21 summary:Segmentation of histopathology sections is an ubiquitous requirement indigital pathology and due to the large variability of biological tissue,machine learning techniques have shown superior performance over standard imageprocessing methods. As part of the GlaS@MICCAI2015 colon gland segmentationchallenge, we present a learning-based algorithm to segment glands in tissue ofbenign and malignant colorectal cancer. Images are preprocessed according tothe Hematoxylin-Eosin staining protocol and two deep convolutional neuralnetworks (CNN) are trained as pixel classifiers. The CNN predictions are thenregularized using a figure-ground segmentation based on weighted totalvariation to produce the final segmentation result. On two test sets, ourapproach achieves a tissue classification accuracy of 98% and 94%, making useof the inherent capability of our system to distinguish between benign andmalignant tissue.
arxiv-14700-43 | Real-Time Anomaly Detection and Localization in Crowded Scenes | http://arxiv.org/pdf/1511.06936v1.pdf | author:Mohammad Sabokrou, Mahmood Fathy, Mojtaba Hosseini, Reinhard Klette category:cs.CV published:2015-11-21 summary:In this paper, we propose a method for real-time anomaly detection andlocalization in crowded scenes. Each video is defined as a set ofnon-overlapping cubic patches, and is described using two local and globaldescriptors. These descriptors capture the video properties from differentaspects. By incorporating simple and cost-effective Gaussian classifiers, wecan distinguish normal activities and anomalies in videos. The local and globalfeatures are based on structure similarity between adjacent patches and thefeatures learned in an unsupervised way, using a sparse auto- encoder.Experimental results show that our algorithm is comparable to astate-of-the-art procedure on UCSD ped2 and UMN benchmarks, but even moretime-efficient. The experiments confirm that our system can reliably detect andlocalize anomalies as soon as they happen in a video.
arxiv-14700-44 | Adding Gradient Noise Improves Learning for Very Deep Networks | http://arxiv.org/pdf/1511.06807v1.pdf | author:Arvind Neelakantan, Luke Vilnis, Quoc V. Le, Ilya Sutskever, Lukasz Kaiser, Karol Kurach, James Martens category:stat.ML cs.LG published:2015-11-21 summary:Deep feedforward and recurrent networks have achieved impressive results inmany perception and language processing applications. This success is partiallyattributed to architectural innovations such as convolutional and longshort-term memory networks. The main motivation for these architecturalinnovations is that they capture better domain knowledge, and importantly areeasier to optimize than more basic architectures. Recently, more complexarchitectures such as Neural Turing Machines and Memory Networks have beenproposed for tasks including question answering and general computation,creating a new set of optimization challenges. In this paper, we discuss alow-overhead and easy-to-implement technique of adding gradient noise which wefind to be surprisingly effective when training these very deep architectures.The technique not only helps to avoid overfitting, but also can result in lowertraining loss. This method alone allows a fully-connected 20-layer deep networkto be trained with standard gradient descent, even starting from a poorinitialization. We see consistent improvements for many complex models,including a 72% relative reduction in error rate over a carefully-tunedbaseline on a challenging question-answering task, and a doubling of the numberof accurate binary multiplication models learned across 7,000 random restarts.We encourage further application of this technique to additional complex modernarchitectures.
arxiv-14700-45 | Fidelity-Naturalness Evaluation of Single Image Super Resolution | http://arxiv.org/pdf/1511.06834v1.pdf | author:Xuan Dong, Yu Zhu, Weixin Li, Lingxi Xie, Alex Wong, Alan Yuille category:cs.CV published:2015-11-21 summary:We study the problem of evaluating super resolution methods. Traditionalevaluation methods usually judge the quality of super resolved images based ona single measure of their difference with the original high resolution images.In this paper, we proposed to use both fidelity (the difference with originalimages) and naturalness (human visual perception of super resolved images) forevaluation. For fidelity evaluation, a new metric is proposed to solve the biasproblem of traditional evaluation. For naturalness evaluation, we let humanslabel preference of super resolution results using pair-wise comparison, andtest the correlation between human labeling results and image qualityassessment metrics' outputs. Experimental results show that ourfidelity-naturalness method is better than the traditional evaluation methodfor super resolution methods, which could help future research on single-imagesuper resolution.
arxiv-14700-46 | Semi-supervised Bootstrapping approach for Named Entity Recognition | http://arxiv.org/pdf/1511.06833v1.pdf | author:S. Thenmalar, J. Balaji, T. V. Geetha category:cs.CL cs.IR published:2015-11-21 summary:The aim of Named Entity Recognition (NER) is to identify references of namedentities in unstructured documents, and to classify them into pre-definedsemantic categories. NER often aids from added background knowledge in the formof gazetteers. However using such a collection does not deal with name variantsand cannot resolve ambiguities associated in identifying the entities incontext and associating them with predefined categories. We present asemi-supervised NER approach that starts with identifying named entities with asmall set of training data. Using the identified named entities, the word andthe context features are used to define the pattern. This pattern of each namedentity category is used as a seed pattern to identify the named entities in thetest set. Pattern scoring and tuple value score enables the generation of thenew patterns to identify the named entity categories. We have evaluated theproposed system for English language with the dataset of tagged (IEER) anduntagged (CoNLL 2003) named entity corpus and for Tamil language with thedocuments from the FIRE corpus and yield an average f-measure of 75% for boththe languages.
arxiv-14700-47 | Learning visual groups from co-occurrences in space and time | http://arxiv.org/pdf/1511.06811v1.pdf | author:Phillip Isola, Daniel Zoran, Dilip Krishnan, Edward H. Adelson category:cs.LG cs.CV published:2015-11-21 summary:We propose a self-supervised framework that learns to group visual entitiesbased on their rate of co-occurrence in space and time. To model statisticaldependencies between the entities, we set up a simple binary classificationproblem in which the goal is to predict if two visual primitives occur in thesame spatial or temporal context. We apply this framework to three domains:learning patch affinities from spatial adjacency in images, learning frameaffinities from temporal adjacency in videos, and learning photo affinitiesfrom geospatial proximity in image collections. We demonstrate that in eachcase the learned affinities uncover meaningful semantic groupings. From patchaffinities we generate object proposals that are competitive withstate-of-the-art supervised methods. From frame affinities we generate moviescene segmentations that correlate well with DVD chapter structure. Finally,from geospatial affinities we learn groups that relate well to semantic placecategories.
arxiv-14700-48 | GradNets: Dynamic Interpolation Between Neural Architectures | http://arxiv.org/pdf/1511.06827v1.pdf | author:Diogo Almeida, Nate Sauder category:cs.LG cs.NE published:2015-11-21 summary:In machine learning, there is a fundamental trade-off between ease ofoptimization and expressive power. Neural Networks, in particular, haveenormous expressive power and yet are notoriously challenging to train. Thenature of that optimization challenge changes over the course of learning.Traditionally in deep learning, one makes a static trade-off between the needsof early and late optimization. In this paper, we investigate a novelframework, GradNets, for dynamically adapting architectures during training toget the benefits of both. For example, we can gradually transition from linearto non-linear networks, deterministic to stochastic computation, shallow todeep architectures, or even simple downsampling to fully differentiableattention mechanisms. Benefits include increased accuracy, easier convergencewith more complex architectures, solutions to test-time execution of batchnormalization, and the ability to train networks of up to 200 layers.
arxiv-14700-49 | Online Sequence Training of Recurrent Neural Networks with Connectionist Temporal Classification | http://arxiv.org/pdf/1511.06841v4.pdf | author:Kyuyeon Hwang, Wonyong Sung category:cs.LG cs.NE published:2015-11-21 summary:Connectionist temporal classification (CTC) based supervised sequencetraining of recurrent neural networks (RNNs) has shown great success in manymachine learning areas including end-to-end speech and handwritten characterrecognition. For the CTC training, however, it is required to unroll (orunfold) the RNN by the length of an input sequence. This unrolling requires alot of memory and hinders a small footprint implementation of online learningor adaptation. Furthermore, the length of training sequences is usually notuniform, which makes parallel training with multiple sequences inefficient onshared memory models such as graphics processing units (GPUs). In this work, weintroduce an expectation-maximization (EM) based online CTC algorithm thatenables unidirectional RNNs to learn sequences that are longer than the amountof unrolling. The RNNs can also be trained to process an infinitely long inputsequence without pre-segmentation or external reset. Moreover, the proposedapproach allows efficient parallel training on GPUs. For evaluation, phonemerecognition and end-to-end speech recognition examples are presented on theTIMIT and Wall Street Journal (WSJ) corpora, respectively. Our online modelachieves 20.7% phoneme error rate (PER) on the very long input sequence that isgenerated by concatenating all 192 utterances in the TIMIT core test set. OnWSJ, a network can be trained with only 64 times of unrolling while sacrificing4.5% relative word error rate (WER).
arxiv-14700-50 | An Immersive Telepresence System using RGB-D Sensors and Head Mounted Display | http://arxiv.org/pdf/1511.06815v1.pdf | author:Xinzhong Lu, Ju Shen, Saverio Perugini, Jianjun Yang category:cs.CV cs.HC cs.MM published:2015-11-21 summary:We present a tele-immersive system that enables people to interact with eachother in a virtual world using body gestures in addition to verbalcommunication. Beyond the obvious applications, including general onlineconversations and gaming, we hypothesize that our proposed system would beparticularly beneficial to education by offering rich visual contents andinteractivity. One distinct feature is the integration of egocentric poserecognition that allows participants to use their gestures to demonstrate andmanipulate virtual objects simultaneously. This functionality enables theinstructor to ef- fectively and efficiently explain and illustrate complexconcepts or sophisticated problems in an intuitive manner. The highlyinteractive and flexible environment can capture and sustain more studentattention than the traditional classroom setting and, thus, delivers acompelling experience to the students. Our main focus here is to investigatepossible solutions for the system design and implementation and devisestrategies for fast, efficient computation suitable for visual data processingand network transmission. We describe the technique and experiments in detailsand provide quantitative performance results, demonstrating our system can berun comfortably and reliably for different application scenarios. Ourpreliminary results are promising and demonstrate the potential for morecompelling directions in cyberlearning.
arxiv-14700-51 | Kernel Additive Principal Components | http://arxiv.org/pdf/1511.06821v1.pdf | author:Xin Lu Tan, Andreas Buja, Zongming Ma category:stat.ME stat.ML published:2015-11-21 summary:Additive principal components (APCs for short) are a nonlinear generalizationof linear principal components. We focus on smallest APCs to describe additivenonlinear constraints that are approximately satisfied by the data. Thus APCsfit data with implicit equations that treat the variables symmetrically, asopposed to regression analyses which fit data with explicit equations thattreat the data asymmetrically by singling out a response variable. We propose aregularized data-analytic procedure for APC estimation using kernel methods. Incontrast to existing approaches to APCs that are based on regularizationthrough subspace restriction, kernel methods achieve regularization throughshrinkage and therefore grant distinctive flexibility in APC estimation byallowing the use of infinite-dimensional functions spaces for searching APCtransformation while retaining computational feasibility. To connect populationAPCs and kernelized finite-sample APCs, we study kernelized population APCs andtheir associated eigenproblems, which eventually lead to the establishment ofconsistency of the estimated APCs. Lastly, we discuss an iterative algorithmfor computing kernelized finite-sample APCs.
arxiv-14700-52 | Ground-truth dataset and baseline evaluations for image base-detail separation algorithms | http://arxiv.org/pdf/1511.06830v2.pdf | author:Xuan Dong, Boyan Bonev, Weixin Li, Weichao Qiu, Xianjie Chen, Alan Yuille category:cs.CV published:2015-11-21 summary:Base-detail separation is a fundamental computer vision problem consisting ofmodeling a smooth base layer with the coarse structures, and a detail layercontaining the texture-like structures. One of the challenges of estimating thebase is to preserve sharp boundaries between objects or parts to avoid haloartifacts. Many methods have been proposed to address this problem, but thereis no ground-truth dataset of real images for quantitative evaluation. Weproposed a procedure to construct such a dataset, and provide two datasets:Pascal Base-Detail and Fashionista Base-Detail, containing 1000 and 250 images,respectively. Our assumption is that the base is piecewise smooth and we labelthe appearance of each piece by a polynomial model. The pieces are objects andparts of objects, obtained from human annotations. Finally, we proposed a wayto evaluate methods with our base-detail ground-truth and we compared theperformances of seven state-of-the-art algorithms.
arxiv-14700-53 | Convex Sparse Spectral Clustering: Single-view to Multi-view | http://arxiv.org/pdf/1511.06860v2.pdf | author:Canyi Lu, Shuicheng Yan, Zhouchen Lin category:cs.CV published:2015-11-21 summary:Spectral Clustering (SC) is one of the most widely used methods for dataclustering. It first finds a low-dimensonal embedding $\U$ of data by computingthe eigenvectors of the normalized Laplacian matrix, and then performs k-meanson $\U^\top$ to get the final clustering result. In this work, we observe that,in the ideal case, $\U\U^\top$ should be block diagonal and thus sparse.Therefore we propose the Sparse Spectral Clustering (SSC) method which extendsSC with sparse regularization on $\U\U^\top$. To address the computationalissue of the nonconvex SSC model, we propose a novel convex relaxation of SSCbased on the convex hull of the fixed rank projection matrices. Then the convexSSC model can be efficiently solved by the Alternating Direction Method of\canyi{Multipliers} (ADMM). Furthermore, we propose the Pairwise SparseSpectral Clustering (PSSC) which extends SSC to boost the clusteringperformance by using the multi-view information of data. Experimentalcomparisons with several baselines on real-world datasets testify to theefficacy of our proposed methods.
arxiv-14700-54 | Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems | http://arxiv.org/pdf/1511.06931v6.pdf | author:Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra, Alexander Miller, Arthur Szlam, Jason Weston category:cs.CL cs.LG published:2015-11-21 summary:A long-term goal of machine learning is to build intelligent conversationalagents. One recent popular approach is to train end-to-end models on a largeamount of real dialog transcripts between humans (Sordoni et al., 2015; Vinyals& Le, 2015; Shang et al., 2015). However, this approach leaves many questionsunanswered as an understanding of the precise successes and shortcomings ofeach model is hard to assess. A contrasting recent proposal are the bAbI tasks(Weston et al., 2015b) which are synthetic data that measure the ability oflearning machines at various reasoning tasks over toy language. Unfortunately,those tests are very small and hence may encourage methods that do not scale.In this work, we propose a suite of new tasks of a much larger scale thatattempt to bridge the gap between the two regimes. Choosing the domain ofmovies, we provide tasks that test the ability of models to answer factualquestions (utilizing OMDB), provide personalization (utilizing MovieLens),carry short conversations about the two, and finally to perform on naturaldialogs from Reddit. We provide a dataset covering 75k movie entities and with3.5M training examples. We present results of various models on these tasks,and evaluate their performance.
arxiv-14700-55 | Real-Time Anomalous Behavior Detection and Localization in Crowded Scenes | http://arxiv.org/pdf/1511.07425v2.pdf | author:Mohammad Sabokrou, Mahmood Fathy, Mojtaba Hosseini category:cs.CV published:2015-11-21 summary:In this paper, we propose an accurate and real-time anomaly detection andlocalization in crowded scenes, and two descriptors for representing anomalousbehavior in video are proposed. We consider a video as being a set of cubicpatches. Based on the low likelihood of an anomaly occurrence, and theredundancy of structures in normal patches in videos, two (global and local)views are considered for modeling the video. Our algorithm has two components,for (1) representing the patches using local and global descriptors, and for(2) modeling the training patches using a new representation. We have twoGaussian models for all training patches respect to global and localdescriptors. The local and global features are based on structure similaritybetween adjacent patches and the features that are learned in an unsupervisedway. We propose a fusion strategy to combine the two descriptors as the outputof our system. Experimental results show that our algorithm performs like astate-of-the-art method on several standard datasets, but even is moretime-efficient.
arxiv-14700-56 | BlackOut: Speeding up Recurrent Neural Network Language Models With Very Large Vocabularies | http://arxiv.org/pdf/1511.06909v7.pdf | author:Shihao Ji, S. V. N. Vishwanathan, Nadathur Satish, Michael J. Anderson, Pradeep Dubey category:cs.LG cs.CL cs.NE stat.ML published:2015-11-21 summary:We propose BlackOut, an approximation algorithm to efficiently train massiverecurrent neural network language models (RNNLMs) with million wordvocabularies. BlackOut is motivated by using a discriminative loss, and wedescribe a new sampling strategy which significantly reduces computation whileimproving stability, sample efficiency, and rate of convergence. One way tounderstand BlackOut is to view it as an extension of the DropOut strategy tothe output layer, wherein we use a discriminative training loss and a weightedsampling scheme. We also establish close connections between BlackOut,importance sampling, and noise contrastive estimation (NCE). Our experiments,on the recently released one billion word language modeling benchmark,demonstrate scalability and accuracy of BlackOut; we outperform thestate-of-the art, and achieve the lowest perplexity scores on this dataset.Moreover, unlike other established methods which typically require GPUs or CPUclusters, we show that a carefully implemented version of BlackOut requiresonly 1-10 days on a single machine to train a RNNLM with a million wordvocabulary and billions of parameters on one billion words. Although wedescribe BlackOut in the context of RNNLM training, it can be used to anynetworks with large softmax output layers.
arxiv-14700-57 | Session-based Recommendations with Recurrent Neural Networks | http://arxiv.org/pdf/1511.06939v4.pdf | author:Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, Domonkos Tikk category:cs.LG cs.IR cs.NE published:2015-11-21 summary:We apply recurrent neural networks (RNN) on a new domain, namely recommendersystems. Real-life recommender systems often face the problem of having to baserecommendations only on short session-based data (e.g. a small sportswarewebsite) instead of long user histories (as in the case of Netflix). In thissituation the frequently praised matrix factorization approaches are notaccurate. This problem is usually overcome in practice by resorting toitem-to-item recommendations, i.e. recommending similar items. We argue that bymodeling the whole session, more accurate recommendations can be provided. Wetherefore propose an RNN-based approach for session-based recommendations. Ourapproach also considers practical aspects of the task and introduces severalmodifications to classic RNNs such as a ranking loss function that make it moreviable for this specific problem. Experimental results on two data-sets showmarked improvements over widely used approaches.
arxiv-14700-58 | Discovering Internal Representations from Object-CNNs Using Population Encoding | http://arxiv.org/pdf/1511.06855v2.pdf | author:Jianyu Wang, Zhishuai Zhang, Vittal Premachandran, Alan Yuille category:cs.LG cs.CV published:2015-11-21 summary:In this paper, we provide a method for understanding the internalrepresentations of Convolutional Neural Networks (CNNs) trained on objects. Wehypothesize that the information is distributed across multiple neuronalresponses and propose a simple clustering technique to extract thisinformation, which we call \emph{population encoding}. The population encodingtechnique looks into the entrails of an object-CNN at multiple layers of thenetwork and shows the implicit presence of mid-level object part semanticsdistributed in the neuronal responses. Our qualitative visualizations show thatpopulation encoding can extract mid-level image patches that are visuallytighter than the patches that produce high single-filter activations. Moreover,our comprehensive quantitative experiments using the object key pointannotations from the PASCAL3D+ dataset corroborate the visualizations bydemonstrating the superiority of population encoding over single-filterdetectors, in the task of object-part detection. We also perform somepreliminary experiments where we uncover the compositional relations betweenthe adjacent layers using the parts detected by population encoding clusters.Finally, based on the insights gained from this work, we point to various newdirections which will enable us to have a better understanding of the CNN'sinternal representations.
arxiv-14700-59 | Near-Optimal Active Learning of Multi-Output Gaussian Processes | http://arxiv.org/pdf/1511.06891v2.pdf | author:Yehong Zhang, Trong Nghia Hoang, Kian Hsiang Low, Mohan Kankanhalli category:stat.ML cs.AI cs.LG published:2015-11-21 summary:This paper addresses the problem of active learning of a multi-outputGaussian process (MOGP) model representing multiple types of coexistingcorrelated environmental phenomena. In contrast to existing works, our activelearning problem involves selecting not just the most informative samplinglocations to be observed but also the types of measurements at each selectedlocation for minimizing the predictive uncertainty (i.e., posterior jointentropy) of a target phenomenon of interest given a sampling budget.Unfortunately, such an entropy criterion scales poorly in the numbers ofcandidate sampling locations and selected observations when optimized. Toresolve this issue, we first exploit a structure common to sparse MOGP modelsfor deriving a novel active learning criterion. Then, we exploit a relaxed formof submodularity property of our new criterion for devising a polynomial-timeapproximation algorithm that guarantees a constant-factor approximation of thatachieved by the optimal set of selected observations. Empirical evaluation onreal-world datasets shows that our proposed approach outperforms existingalgorithms for active learning of MOGP and single-output GP models.
arxiv-14700-60 | A dense subgraph based algorithm for compact salient image region detection | http://arxiv.org/pdf/1511.06545v2.pdf | author:Souradeep Chakraborty, Pabitra Mitra category:cs.CV published:2015-11-20 summary:We present an algorithm for graph based saliency computation that utilizesthe underlying dense subgraphs in finding visually salient regions in an image.To compute the salient regions, the model first obtains a saliency map usingrandom walks on a Markov chain. Next, k-dense subgraphs are detected to furtherenhance the salient regions in the image. Dense subgraphs convey moreinformation about local graph structure than simple centrality measures. Togenerate the Markov chain, intensity and color features of an image in additionto region compactness is used. For evaluating the proposed model, we doextensive experiments on benchmark image data sets. The proposed methodperforms comparable to well-known algorithms in salient region detection.
arxiv-14700-61 | Data Representation and Compression Using Linear-Programming Approximations | http://arxiv.org/pdf/1511.06606v5.pdf | author:Hristo S. Paskov, John C. Mitchell, Trevor J. Hastie category:cs.LG published:2015-11-20 summary:We propose `Dracula', a new framework for unsupervised feature selection fromsequential data such as text. Dracula learns a dictionary of $n$-grams thatefficiently compresses a given corpus and recursively compresses its owndictionary; in effect, Dracula is a `deep' extension of Compressive FeatureLearning. It requires solving a binary linear program that may be relaxed to alinear program. Both problems exhibit considerable structure, their solutionpaths are well behaved, and we identify parameters which control the depth anddiversity of the dictionary. We also discuss how to derive features from thecompressed documents and show that while certain unregularized linear modelsare invariant to the structure of the compressed dictionary, this structure maybe used to regularize learning. Experiments are presented that demonstrate theefficacy of Dracula's features.
arxiv-14700-62 | Acceleration of the PDHGM on strongly convex subspaces | http://arxiv.org/pdf/1511.06566v2.pdf | author:Tuomo Valkonen, Thomas Pock category:math.OC cs.CV published:2015-11-20 summary:We propose several variants of the primal-dual method due to Chambolle andPock. Without requiring full strong convexity of the objective functions, ourmethods are accelerated on subspaces with strong convexity. This yields mixedrates, $O(1/N^2)$ with respect to initialisation and $O(1/N)$ with respect tothe dual sequence, and the residual part of the primal sequence. We demonstratethe efficacy of the proposed methods on image processing problems lackingstrong convexity, such as total generalised variation denoising and totalvariation deblurring.
arxiv-14700-63 | DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation | http://arxiv.org/pdf/1511.06645v2.pdf | author:Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, Bjoern Andres, Mykhaylo Andriluka, Peter Gehler, Bernt Schiele category:cs.CV published:2015-11-20 summary:This paper considers the task of articulated human pose estimation ofmultiple people in real world images. We propose an approach that jointlysolves the tasks of detection and pose estimation: it infers the number ofpersons in a scene, identifies occluded body parts, and disambiguates bodyparts between people in close proximity of each other. This joint formulationis in contrast to previous strategies, that address the problem by firstdetecting people and subsequently estimating their body pose. We propose apartitioning and labeling formulation of a set of body-part hypothesesgenerated with CNN-based part detectors. Our formulation, an instance of aninteger linear program, implicitly performs non-maximum suppression on the setof part candidates and groups them to form configurations of body partsrespecting geometric and appearance constraints. Experiments on four differentdatasets demonstrate state-of-the-art results for both single person and multiperson pose estimation. Models and code available athttp://pose.mpi-inf.mpg.de.
arxiv-14700-64 | Training CNNs with Low-Rank Filters for Efficient Image Classification | http://arxiv.org/pdf/1511.06744v3.pdf | author:Yani Ioannou, Duncan Robertson, Jamie Shotton, Roberto Cipolla, Antonio Criminisi category:cs.CV cs.LG cs.NE published:2015-11-20 summary:We propose a new method for creating computationally efficient convolutionalneural networks (CNNs) by using low-rank representations of convolutionalfilters. Rather than approximating filters in previously-trained networks withmore efficient versions, we learn a set of small basis filters from scratch;during training, the network learns to combine these basis filters into morecomplex filters that are discriminative for image classification. To train suchnetworks, a novel weight initialization scheme is used. This allows effectiveinitialization of connection weights in convolutional layers composed of groupsof differently-shaped filters. We validate our approach by applying it toseveral existing CNN architectures and training these networks from scratchusing the CIFAR, ILSVRC and MIT Places datasets. Our results show similar orhigher accuracy than conventional CNNs with much less compute. Applying ourmethod to an improved version of VGG-11 network using global max-pooling, weachieve comparable validation accuracy using 41% less compute and only 24% ofthe original VGG-11 model parameters; another variant of our method gives a 1percentage point increase in accuracy over our improved VGG-11 model, giving atop-5 center-crop validation accuracy of 89.7% while reducing computation by16% relative to the original VGG-11 model. Applying our method to the GoogLeNetarchitecture for ILSVRC, we achieved comparable accuracy with 26% less computeand 41% fewer model parameters. Applying our method to a near state-of-the-artnetwork for CIFAR, we achieved comparable accuracy with 46% less compute and55% fewer parameters.
arxiv-14700-65 | Scalable Gradient-Based Tuning of Continuous Regularization Hyperparameters | http://arxiv.org/pdf/1511.06727v2.pdf | author:Jelena Luketina, Mathias Berglund, Tapani Raiko category:cs.LG published:2015-11-20 summary:Hyperparameter selection generally relies on running multiple full trainingtrials, with hyperparameter selection based on validation set performance. Wepropose a gradient-based approach for locally adjusting hyperparameters on thefly in which we adjust the hyperparameters so as to make the model parametergradients, and hence updates, more advantageous for the validation cost. Weexplore the approach for tuning regularization hyperparameters and find that inexperiments on MNIST the resulting regularization levels are within the optimalregions. The method is less computationally demanding compared to similargradient-based approaches to hyperparameter selection, only requires a fewtrials, and consistently finds solid hyperparameter values which makes it auseful tool for training neural network models.
arxiv-14700-66 | Unitary Evolution Recurrent Neural Networks | http://arxiv.org/pdf/1511.06464v3.pdf | author:Martin Arjovsky, Amar Shah, Yoshua Bengio category:cs.LG cs.NE published:2015-11-20 summary:Recurrent neural networks (RNNs) are notoriously difficult to train. When theeigenvalues of the hidden to hidden weight matrix deviate from absolute value1, optimization becomes difficult due to the well studied issue of vanishingand exploding gradients, especially when trying to learn long-termdependencies. To circumvent this problem, we propose a new architecture thatlearns a unitary weight matrix, with eigenvalues of absolute value exactly 1.The challenge we address is that of parametrizing unitary matrices in a waythat does not require expensive computations (such as eigendecomposition) aftereach weight update. We construct an expressive unitary weight matrix bycomposing several structured matrices that act as building blocks withparameters to be learned. Optimization with this parameterization becomesfeasible only when considering hidden states in the complex domain. Wedemonstrate the potential of this architecture by achieving state of the artresults in several hard tasks involving very long-term dependencies.
arxiv-14700-67 | Joint Inverse Covariances Estimation with Mutual Linear Structure | http://arxiv.org/pdf/1511.06462v1.pdf | author:Ilya Soloveychik, Ami Wiesel category:stat.ML stat.AP published:2015-11-20 summary:We consider the problem of joint estimation of structured inverse covariancematrices. We perform the estimation using groups of measurements with differentcovariances of the same unknown structure. Assuming the inverse covariances tospan a low dimensional linear subspace in the space of symmetric matrices, ouraim is to determine this structure. It is then utilized to improve theestimation of the inverse covariances. We propose a novel optimizationalgorithm discovering and exploiting the underlying structure and provide itsefficient implementation. Numerical simulations are presented to illustrate theperformance benefits of the proposed algorithm.
arxiv-14700-68 | Dueling Network Architectures for Deep Reinforcement Learning | http://arxiv.org/pdf/1511.06581v3.pdf | author:Ziyu Wang, Tom Schaul, Matteo Hessel, Hado van Hasselt, Marc Lanctot, Nando de Freitas category:cs.LG published:2015-11-20 summary:In recent years there have been many successes of using deep representationsin reinforcement learning. Still, many of these applications use conventionalarchitectures, such as convolutional networks, LSTMs, or auto-encoders. In thispaper, we present a new neural network architecture for model-freereinforcement learning. Our dueling network represents two separate estimators:one for the state value function and one for the state-dependent actionadvantage function. The main benefit of this factoring is to generalizelearning across actions without imposing any change to the underlyingreinforcement learning algorithm. Our results show that this architecture leadsto better policy evaluation in the presence of many similar-valued actions.Moreover, the dueling architecture enables our RL agent to outperform thestate-of-the-art on the Atari 2600 domain.
arxiv-14700-69 | Superpixel Convolutional Networks using Bilateral Inceptions | http://arxiv.org/pdf/1511.06739v3.pdf | author:Raghudeep Gadde, Varun Jampani, Martin Kiefel, Peter V. Gehler category:cs.CV I.2.10; I.2.6 published:2015-11-20 summary:In this paper we propose a CNN architecture for image segmentation. Weintroduce a new "bilateral inception" layer that is used on top of aconvolutional architecture. The bilateral inception performs a filteringbetween superpixels in an image. This addresses two problems that arise withCNN segmentation architectures. First, this layer propagates informationbetween (super) pixels while respecting image edges, thus using the structuredinformation of the problem for improved results. Second, the layer recovers afull resolution segmentation result from the lower resolution solution of aCNN. In the experiments we replace the deconvolution networks and Dense-CRFthat have previously been proposed to address these problems with bilateralinception layers. The reduction to superpixels reduces the amount ofcomputations and simplifies the network design. Further, we report betterempirical results by replacing De-convolutional and CNN+Dense-CRF steps in fourdifferent semantic segmentation CNN architecutres, even with-out re-trainingtheir filter weights.
arxiv-14700-70 | A Simple Hierarchical Pooling Data Structure for Loop Closure | http://arxiv.org/pdf/1511.06489v1.pdf | author:Xiaohan Fei, Konstantine Tsotsos, Stefano Soatto category:cs.CV cs.RO published:2015-11-20 summary:We propose a data structure obtained by hierarchically averaging bag-of-worddescriptors during a sequence of views that achieves average speedups inlarge-scale loop closure applications ranging from 4 to 20 times on benchmarkdatasets. Although simple, the method works as well as sophisticatedagglomerative schemes at a fraction of the cost with minimal loss ofperformance.
arxiv-14700-71 | Bidirectional Warping of Active Appearance Model | http://arxiv.org/pdf/1511.06494v1.pdf | author:Ali Mollahosseini, Mohammad H. Mahoor category:cs.CV published:2015-11-20 summary:Active Appearance Model (AAM) is a commonly used method for facial imageanalysis with applications in face identification and facial expressionrecognition. This paper proposes a new approach based on image alignment forAAM fitting called bidirectional warping. Previous approaches warp either theinput image or the appearance template. We propose to warp both the inputimage, using incremental update by an affine transformation, and the appearancetemplate, using an inverse compositional approach. Our experimental results onMulti-PIE face database show that the bidirectional approach outperformsstate-of-the-art inverse compositional fitting approaches in extractinglandmark points of faces with shape and pose variations.
arxiv-14700-72 | WIDER FACE: A Face Detection Benchmark | http://arxiv.org/pdf/1511.06523v1.pdf | author:Shuo Yang, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV published:2015-11-20 summary:Face detection is one of the most studied topics in the computer visioncommunity. Much of the progresses have been made by the availability of facedetection benchmark datasets. We show that there is a gap between current facedetection performance and the real world requirements. To facilitate futureface detection research, we introduce the WIDER FACE dataset, which is 10 timeslarger than existing datasets. The dataset contains rich annotations, includingocclusions, poses, event categories, and face bounding boxes. Faces in theproposed dataset are extremely challenging due to large variations in scale,pose and occlusion, as shown in Fig. 1. Furthermore, we show that WIDER FACEdataset is an effective training source for face detection. We benchmarkseveral representative detection systems, providing an overview ofstate-of-the-art performance and propose a solution to deal with large scalevariation. Finally, we discuss common failure cases that worth to be furtherinvestigated. Dataset can be downloaded at:mmlab.ie.cuhk.edu.hk/projects/WIDERFace
arxiv-14700-73 | Crowd Behavior Analysis: A Review where Physics meets Biology | http://arxiv.org/pdf/1511.06586v1.pdf | author:Ven Jyn Kok, Mei Kuan Lim, Chee Seng Chan category:cs.CV cs.AI cs.NE published:2015-11-20 summary:Although the traits emerged in a mass gathering are often non-deliberative,the act of mass impulse may lead to irre- vocable crowd disasters. The two-foldincrease of carnage in crowd since the past two decades has spurred significantadvances in the field of computer vision, towards effective and proactive crowdsurveillance. Computer vision stud- ies related to crowd are observed toresonate with the understanding of the emergent behavior in physics (complexsystems) and biology (animal swarm). These studies, which are inspired bybiology and physics, share surprisingly common insights, and interestingcontradictions. However, this aspect of discussion has not been fully explored.Therefore, this survey provides the readers with a review of thestate-of-the-art methods in crowd behavior analysis from the physics andbiologically inspired perspectives. We provide insights and comprehensivediscussions for a broader understanding of the underlying prospect of blendingphysics and biology studies in computer vision.
arxiv-14700-74 | Polysemy in Controlled Natural Language Texts | http://arxiv.org/pdf/1511.06591v1.pdf | author:Normunds Gruzitis, Guntis Barzdins category:cs.CL published:2015-11-20 summary:Computational semantics and logic-based controlled natural languages (CNL) donot address systematically the word sense disambiguation problem of contentwords, i.e., they tend to interpret only some functional words that are crucialfor construction of discourse representation structures. We show thatmicro-ontologies and multi-word units allow integration of the rich andpolysemous multi-domain background knowledge into CNL thus providinginterpretation for the content words. The proposed approach is demonstrated byextending the Attempto Controlled English (ACE) with polysemous and proceduralconstructs resulting in a more natural CNL named PAO covering narrativemulti-domain texts.
arxiv-14700-75 | Exponential Natural Particle Filter | http://arxiv.org/pdf/1511.06603v1.pdf | author:Ghazal Zand, Mojtaba Taherkhani, Reza Safabakhsh category:cs.LG cs.NE cs.RO published:2015-11-20 summary:Particle Filter algorithm (PF) suffers from some problems such as the loss ofparticle diversity, the need for large number of particles, and the costlyselection of the importance density functions. In this paper, a novelExponential Natural Particle Filter (xNPF) is introduced to solve the aboveproblems. In this approach, a state transitional probability with the use ofnatural gradient learning is proposed which balances exploration andexploitation more robustly. The results show that xNPF converges much closer tothe true target states than the other state of the art particle filter.
arxiv-14700-76 | Towards Arbitrary-View Face Alignment by Recommendation Trees | http://arxiv.org/pdf/1511.06627v1.pdf | author:Shizhan Zhu, Cheng Li, Chen Change Loy, Xiaoou Tang category:cs.CV published:2015-11-20 summary:Learning to simultaneously handle face alignment of arbitrary views, e.g.frontal and profile views, appears to be more challenging than we thought. Thedifficulties lay in i) accommodating the complex appearance-shape relationsexhibited in different views, and ii) encompassing the varying landmark pointsets due to self-occlusion and different landmark protocols. Most existingstudies approach this problem via training multiple viewpoint-specific models,and conduct head pose estimation for model selection. This solution isintuitive but the performance is highly susceptible to inaccurate head poseestimation. In this study, we address this shortcoming through learning anEnsemble of Model Recommendation Trees (EMRT), which is capable of selectingoptimal model configuration without prior head pose estimation. The unifiedframework seamlessly handles different viewpoints and landmark protocols, andit is trained by optimising directly on landmark locations, thus yieldingsuperior results on arbitrary-view face alignment. This is the first study thatperforms face alignment on the full AFLWdataset with faces of different viewsincluding profile view. State-of-the-art performances are also reported onMultiPIE and AFW datasets containing both frontaland profile-view faces.
arxiv-14700-77 | Multi-Contrast MRI Reconstruction with Structure-Guided Total Variation | http://arxiv.org/pdf/1511.06631v1.pdf | author:Matthias J. Ehrhardt, Marta M. Betcke category:math.NA cs.CV math.OC published:2015-11-20 summary:Magnetic resonance imaging (MRI) is a versatile imaging technique that allowsdifferent contrasts depending on the acquisition parameters. Many clinicalimaging studies acquire MRI data for more than one of these contrasts---such asfor instance T1 and T2 weighted images---which makes the overall scanningprocedure very time consuming. As all of these images show the same underlyinganatomy one can try to omit unnecessary measurements by taking the similarityinto account during reconstruction. We will discuss two modifications of totalvariation---based on i) location and ii) direction---that take structural apriori knowledge into account and reduce to total variation in the degeneratecase when no structural knowledge is available. We solve the resulting convexminimization problem with the alternating direction method of multipliers thatseparates the forward operator from the prior. For both priors thecorresponding proximal operator can be implemented as an extension of the fastgradient projection method on the dual problem for total variation. We testedthe priors on six data sets that are based on phantoms and real MRI images. Inall test cases exploiting the structural information from the other contrastyields better results than separate reconstruction with total variation interms of standard metrics like peak signal-to-noise ratio and structuralsimilarity index. Furthermore, we found that exploiting the two dimensionaldirectional information results in images with well defined edges, superior tothose reconstructed solely using a priori information about the edge location.
arxiv-14700-78 | L1 logistic regression as a feature selection step for training stable classification trees for the prediction of severity criteria in imported malaria | http://arxiv.org/pdf/1511.06663v1.pdf | author:Luca Talenti, Margaux Luck, Anastasia Yartseva, Nicolas Argy, Sandrine Houzé, Cecilia Damon category:cs.LG q-bio.QM stat.AP published:2015-11-20 summary:Multivariate classification methods using explanatory and predictive modelsare necessary for characterizing subgroups of patients according to their riskprofiles. Popular methods include logistic regression and classification treeswith performances that vary according to the nature and the characteristics ofthe dataset. In the context of imported malaria, we aimed at classifyingseverity criteria based on a heterogeneous patient population. We investigatedthese approaches by implementing two different strategies: L1 logisticregression (L1LR) that models a single global solution and classification treesthat model multiple local solutions corresponding to discriminant subregions ofthe feature space. For each strategy, we built a standard model, and a sparserversion of it. As an alternative to pruning, we explore a promising approachthat first constrains the tree model with an L1LR-based feature selection, anapproach we called L1LR-Tree. The objective is to decrease its vulnerability tosmall data variations by removing variables corresponding to unstable localphenomena. Our study is twofold: i) from a methodological perspective comparingthe performances and the stability of the three previous methods, i.e L1LR,classification trees and L1LR-Tree, for the classification of severe forms ofimported malaria, and ii) from an applied perspective improving the actualclassification of severe forms of imported malaria by identifying morepersonalized profiles predictive of several clinical criteria based onvariables dismissed for the clinical definition of the disease. The mainmethodological results show that the combined method L1LR-Tree builds sparseand stable models that significantly predicts the different severity criteriaand outperforms all the other methods in terms of accuracy.
arxiv-14700-79 | Stories in the Eye: Contextual Visual Interactions for Efficient Video to Language Translation | http://arxiv.org/pdf/1511.06674v1.pdf | author:Anirudh Goyal, Marius Leordeanu category:cs.CV cs.CL published:2015-11-20 summary:Integrating higher level visual and linguistic interpretations is at theheart of human intelligence. As automatic visual category recognition in imagesis approaching human performance, the high level understanding in the dynamicspatiotemporal domain of videos and its translation into natural language isstill far from being solved. While most works on vision-to-text translationsuse pre-learned or pre-established computational linguistic models, in thispaper we present an approach that uses vision alone to efficiently learn how totranslate into language the video content. We discover, in simple form, thestory played by main actors, while using only visual cues for representingobjects and their interactions. Our method learns in a hierarchical mannerhigher level representations for recognizing subjects, actions and objectsinvolved, their relevant contextual background and their interaction to oneanother over time. We have a three stage approach: first we take inconsideration features of the individual entities at the local level ofappearance, then we consider the relationship between these objects and actionsand their video background, and third, we consider their spatiotemporalrelations as inputs to classifiers at the highest level of interpretation.Thus, our approach finds a coherent linguistic description of videos in theform of a subject, verb and object based on their role played in the overallvisual story learned directly from training data, without using a knownlanguage model. We test the efficiency of our approach on a large scale datasetcontaining YouTube clips taken in the wild and demonstrate state-of-the-artperformance, often superior to current approaches that use more complex,pre-learned linguistic knowledge.
arxiv-14700-80 | Personalizing Human Video Pose Estimation | http://arxiv.org/pdf/1511.06676v1.pdf | author:James Charles, Tomas Pfister, Derek Magee, David Hogg, Andrew Zisserman category:cs.CV published:2015-11-20 summary:We propose a personalized ConvNet pose estimator that automatically adaptsitself to the uniqueness of a person's appearance to improve pose estimation inlong videos. We make the following contributions: (i) we show that given a fewhigh-precision pose annotations, e.g. from a generic ConvNet pose estimator,additional annotations can be generated throughout the video using acombination of image-based matching for temporally distant frames, and denseoptical flow for temporally local frames; (ii) we develop an occlusion awareself-evaluation model that is able to automatically select the high-quality andreject the erroneous additional annotations; and (iii) we demonstrate thatthese high-quality annotations can be used to fine-tune a ConvNet poseestimator and thereby personalize it to lock on to key discriminative featuresof the person's appearance. The outcome is a substantial improvement in thepose estimates for the target video using the personalized ConvNet compared tothe original generic ConvNet. Our method outperforms the state of the art(including top ConvNet methods) by a large margin on two standard benchmarks,as well as on a new challenging YouTube video dataset. Furthermore, we showthat training from the automatically generated annotations can be used toimprove the performance of a generic ConvNet on other benchmarks.
arxiv-14700-81 | Direct Prediction of 3D Body Poses from Motion Compensated Sequences | http://arxiv.org/pdf/1511.06692v2.pdf | author:Bugra Tekin, Artem Rozantsev, Vincent Lepetit, Pascal Fua category:cs.CV published:2015-11-20 summary:We propose an efficient approach to exploiting motion information fromconsecutive frames of a video sequence to recover the 3D pose of people.Previous approaches typically compute candidate poses in individual frames andthen link them in a post-processing step to resolve ambiguities. By contrast,we directly regress from a spatio-temporal volume of bounding boxes to a 3Dpose in the central frame. We further show that, for this approach to achieve its full potential, it isessential to compensate for the motion in consecutive frames so that thesubject remains centered. This then allows us to effectively overcomeambiguities and improve upon the state-of-the-art by a large margin on theHuman3.6m, HumanEva, and KTH Multiview Football 3D human pose estimationbenchmarks.
arxiv-14700-82 | Deep End2End Voxel2Voxel Prediction | http://arxiv.org/pdf/1511.06681v1.pdf | author:Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, Manohar Paluri category:cs.CV published:2015-11-20 summary:Over the last few years deep learning methods have emerged as one of the mostprominent approaches for video analysis. However, so far their most successfulapplications have been in the area of video classification and detection, i.e.,problems involving the prediction of a single class label or a handful ofoutput variables per video. Furthermore, while deep networks are commonlyrecognized as the best models to use in these domains, there is a widespreadperception that in order to yield successful results they often requiretime-consuming architecture search, manual tweaking of parameters andcomputationally intensive pre-processing or post-processing methods. In this paper we challenge these views by presenting a deep 3D convolutionalarchitecture trained end to end to perform voxel-level prediction, i.e., tooutput a variable at every voxel of the video. Most importantly, we show thatthe same exact architecture can be used to achieve competitive results on threewidely different voxel-prediction tasks: video semantic segmentation, opticalflow estimation, and video coloring. The three networks learned on theseproblems are trained from raw video without any form of preprocessing and theiroutputs do not require post-processing to achieve outstanding performance.Thus, they offer an efficient alternative to traditional and much morecomputationally expensive methods in these video domains.
arxiv-14700-83 | Top-k Multiclass SVM | http://arxiv.org/pdf/1511.06683v1.pdf | author:Maksim Lapin, Matthias Hein, Bernt Schiele category:stat.ML cs.CV cs.LG published:2015-11-20 summary:Class ambiguity is typical in image classification problems with a largenumber of classes. When classes are difficult to discriminate, it makes senseto allow k guesses and evaluate classifiers based on the top-k error instead ofthe standard zero-one loss. We propose top-k multiclass SVM as a direct methodto optimize for top-k performance. Our generalization of the well-knownmulticlass SVM is based on a tight convex upper bound of the top-k error. Wepropose a fast optimization scheme based on an efficient projection onto thetop-k simplex, which is of its own interest. Experiments on five datasets showconsistent improvements in top-k accuracy compared to various baselines.
arxiv-14700-84 | Single-view to Multi-view: Reconstructing Unseen Views with a Convolutional Network | http://arxiv.org/pdf/1511.06702v1.pdf | author:Maxim Tatarchenko, Alexey Dosovitskiy, Thomas Brox category:cs.CV published:2015-11-20 summary:We present a convolutional network capable of generating images of apreviously unseen object from arbitrary viewpoints given a single image of thisobject. The input to the network is a single image and the desired newviewpoint; the output is a view of the object from this desired viewpoint. Thenetwork is trained on renderings of synthetic 3D models. It learns an implicit3D representation of the object class, which allows it to transfer shapeknowledge from training instances to a new object instance. Beside the colorimage, the network can also generate the depth map of an object from arbitraryviewpoints. This allows us to predict 3D point clouds from a single image,which can be fused into a surface mesh. We experimented with cars and chairs.Even though the network is trained on artificial data, it generalizes well toobjects in natural images without any modifications.
arxiv-14700-85 | Variance Reduction in SGD by Distributed Importance Sampling | http://arxiv.org/pdf/1511.06481v7.pdf | author:Guillaume Alain, Alex Lamb, Chinnadhurai Sankar, Aaron Courville, Yoshua Bengio category:stat.ML cs.LG published:2015-11-20 summary:Humans are able to accelerate their learning by selecting training materialsthat are the most informative and at the appropriate level of difficulty. Wepropose a framework for distributing deep learning in which one set of workerssearch for the most informative examples in parallel while a single workerupdates the model on examples selected by importance sampling. This leads themodel to update using an unbiased estimate of the gradient which also hasminimum variance when the sampling proposal is proportional to the L2-norm ofthe gradient. We show experimentally that this method reduces gradient varianceeven in a context where the cost of synchronization across machines cannot beignored, and where the factors for importance sampling are not updatedinstantly across the training set.
arxiv-14700-86 | Semantic Diversity versus Visual Diversity in Visual Dictionaries | http://arxiv.org/pdf/1511.06704v1.pdf | author:Otávio A. B. Penatti, Sandra Avila, Eduardo Valle, Ricardo da S. Torres category:cs.CV published:2015-11-20 summary:Visual dictionaries are a critical component for imageclassification/retrieval systems based on the bag-of-visual-words (BoVW) model.Dictionaries are usually learned without supervision from a training set ofimages sampled from the collection of interest. However, for large,general-purpose, dynamic image collections (e.g., the Web), obtaining arepresentative sample in terms of semantic concepts is not straightforward. Inthis paper, we evaluate the impact of semantics in the dictionary quality,aiming at verifying the importance of semantic diversity in relation visualdiversity for visual dictionaries. In the experiments, we vary the amount ofclasses used for creating the dictionary and then compute different BoVWdescriptors, using multiple codebook sizes and different coding and poolingmethods (standard BoVW and Fisher Vectors). Results for image classificationshow that as visual dictionaries are based on low-level visual appearances,visual diversity is more important than semantic diversity. Our conclusionsopen the opportunity to alleviate the burden in generating visual dictionariesas we need only a visually diverse set of images instead of the wholecollection to create a good dictionary.
arxiv-14700-87 | Top-N recommendations from expressive recommender systems | http://arxiv.org/pdf/1511.06718v1.pdf | author:Cyril Stark category:cs.LG stat.ML published:2015-11-20 summary:Normalized nonnegative models assign probability distributions to users andrandom variables to items; see [Stark, 2015]. Rating an item is regarded assampling the random variable assigned to the item with respect to thedistribution assigned to the user who rates the item. Models of that kind arehighly expressive. For instance, using normalized nonnegative models we canunderstand users' preferences as mixtures of interpretable user stereotypes,and we can arrange properties of users and items in a hierarchical manner.These features would not be useful if the predictive power of normalizednonnegative models was poor. Thus, we analyze here the performance ofnormalized nonnegative models for top-N recommendation and observe that theirperformance matches the performance of methods like PureSVD which wasintroduced in [Cremonesi et al., 2010]. We conclude that normalized nonnegativemodels not only provide accurate recommendations but they also deliver (forfree) representations that are interpretable. We deepen the discussion ofnormalized nonnegative models by providing further theoretical insights. Inparticular, we introduce total variational distance as an operationalsimilarity measure, we discover scenarios where normalized nonnegative modelsyield unique representations of users and items, we prove that the inference ofoptimal normalized nonnegative models is NP-hard and finally, we discuss therelationship between normalized nonnegative models and nonnegative matrixfactorization.
arxiv-14700-88 | Hand Pose Estimation through Weakly-Supervised Learning of a Rich Intermediate Representation | http://arxiv.org/pdf/1511.06728v1.pdf | author:Natalia Neverova, Christian Wolf, Florian Nebout, Graham Taylor category:cs.CV cs.AI cs.LG published:2015-11-20 summary:We propose a method for hand pose estimation based on a deep regressortrained on two different kinds of input. Raw depth data is fused with anintermediate representation in the form of a segmentation of the hand intoparts. This intermediate representation contains important topologicalinformation and provides useful cues for reasoning about joint locations. Themapping from raw depth to segmentation maps is learned in asemi/weakly-supervised way from two different datasets: (i) a synthetic datasetcreated through a rendering pipeline including densely labeled ground truth(pixelwise segmentations); and (ii) a dataset with real images for which groundtruth joint positions are available, but not dense segmentations. Loss fortraining on real images is generated from a patch-wise restoration process,which aligns tentative segmentation maps with a large dictionary of syntheticposes. The underlying premise is that the domain shift between synthetic andreal data is smaller in the intermediate representation, where labels carrygeometric and topological meaning, than in the raw input domain. Experiments onthe NYU dataset show that the proposed training method decreases error onjoints over direct regression of joints from depth data by 15.7%.
arxiv-14700-89 | Images Don't Lie: Transferring Deep Visual Semantic Features to Large-Scale Multimodal Learning to Rank | http://arxiv.org/pdf/1511.06746v1.pdf | author:Corey Lynch, Kamelia Aryafar, Josh Attenberg category:cs.CV cs.LG published:2015-11-20 summary:Search is at the heart of modern e-commerce. As a result, the task of rankingsearch results automatically (learning to rank) is a multibillion dollarmachine learning problem. Traditional models optimize over a fewhand-constructed features based on the item's text. In this paper, we introducea multimodal learning to rank model that combines these traditional featureswith visual semantic features transferred from a deep convolutional neuralnetwork. In a large scale experiment using data from the online marketplaceEtsy, we verify that moving to a multimodal representation significantlyimproves ranking quality. We show how image features can capture fine-grainedstyle information not available in a text-only representation. In addition, weshow concrete examples of how image information can successfully disentanglepairs of highly different items that are ranked similarly by a text-only model.
arxiv-14700-90 | Bayesian SPLDA | http://arxiv.org/pdf/1511.07318v1.pdf | author:Jesús Villalba category:stat.ML published:2015-11-20 summary:In this document we are going to derive the equations needed to implement aVariational Bayes estimation of the parameters of the simplified probabilisticlinear discriminant analysis (SPLDA) model. This can be used to adapt SPLDAfrom one database to another with few development data or to implement thefully Bayesian recipe. Our approach is similar to Bishop's VB PPCA.
arxiv-14700-91 | PLDA with Two Sources of Inter-session Variability | http://arxiv.org/pdf/1511.06772v1.pdf | author:Jesús Villalba category:stat.ML published:2015-11-20 summary:In some speaker recognition scenarios we find conversations recordedsimultaneously over multiple channels. That is the case of the interviews inthe NIST SRE dataset. To take advantage of that, we propose a modification ofthe PLDA model that considers two different inter-session variability terms.The first term is tied between all the recordings belonging to the sameconversation whereas the second is not. Thus, the former mainly intends tocapture the variability due to the phonetic content of the conversation whilethe latter tries to capture the channel variability. In this document, wederive the equations for this model. This model was applied in the paper"Handling Recordings Acquired Simultaneously over Multiple Channels with PLDA"published at Interspeech 2013.
arxiv-14700-92 | ElSe: Ellipse Selection for Robust Pupil Detection in Real-World Environments | http://arxiv.org/pdf/1511.06575v2.pdf | author:Wolfgang Fuhl, Thiago C. Santini, Thomas Kuebler, Enkelejda Kasneci category:cs.CV I.4.3; I.4.8 published:2015-11-20 summary:Fast and robust pupil detection is an essential prerequisite for video-basedeye-tracking in real-world settings. Several algorithms for image-based pupildetection have been proposed, their applicability is mostly limited tolaboratory conditions. In realworld scenarios, automated pupil detection has toface various challenges, such as illumination changes, reflections (onglasses), make-up, non-centered eye recording, and physiological eyecharacteristics. We propose ElSe, a novel algorithm based on ellipse evaluationof a filtered edge image. We aim at a robust, resource-saving approach that canbe integrated in embedded architectures e.g. driving. The proposed algorithmwas evaluated against four state-of-the-art methods on over 93,000 hand-labeledimages from which 55,000 are new images contributed by this work. On average,the proposed method achieved a 14.53% improvement on the detection raterelative to the best state-of-the-art performer.download:ftp://emmapupildata@messor.informatik.unituebingen. de(password:eyedata).
arxiv-14700-93 | Data-Dependent Path Normalization in Neural Networks | http://arxiv.org/pdf/1511.06747v4.pdf | author:Behnam Neyshabur, Ryota Tomioka, Ruslan Salakhutdinov, Nathan Srebro category:cs.LG published:2015-11-20 summary:We propose a unified framework for neural net normalization, regularizationand optimization, which includes Path-SGD and Batch-Normalization andinterpolates between them across two different dimensions. Through thisframework we investigate issue of invariance of the optimization, datadependence and the connection with natural gradients.
arxiv-14700-94 | Unsupervised Adaptation of SPLDA | http://arxiv.org/pdf/1511.07421v1.pdf | author:Jesús Villalba category:stat.ML published:2015-11-20 summary:State-of-the-art speaker recognition relays on models that need a largeamount of training data. This models are successful in tasks like NIST SREbecause there is sufficient data available. However, in real applications, weusually do not have so much data and, in many cases, the speaker labels areunknown. We present a method to adapt a PLDA model from a domain with a largeamount of labeled data to another with unlabeled data. We describe a generativemodel that produces both sets of data where the unknown labels are modeled likelatent variables. We used variational Bayes to estimate the hidden variables.Here, we derive the equations for this model. This model has been used in thepapers: "UNSUPERVISED ADAPTATION OF PLDA BY USING VARIATIONAL BAYES METHODS"publised at ICASSP 2014, "Unsupervised Training of PLDA with Variational Bayes"published at Iberspeech 2014, and "VARIATIONAL BAYESIAN PLDA FOR SPEAKERDIARIZATION IN THE MGB CHALLENGE" published at ASRU 2015.
arxiv-14700-95 | Variational Bayes Factor Analysis for i-Vector Extraction | http://arxiv.org/pdf/1511.07422v1.pdf | author:Jesús Villalba category:stat.ML published:2015-11-20 summary:In this document we are going to derive the equations needed to implement aVariational Bayes i-vector extractor. This can be used to extract longeri-vectors reducing the risk of overfittig or to adapt an i-vector extractorfrom a database to another with scarce development data. This work is based onPatrick Kenny's joint factor analysis and Christopher Bishop's variationalprincipal components.
arxiv-14700-96 | The Unreasonable Effectiveness of Noisy Data for Fine-Grained Recognition | http://arxiv.org/pdf/1511.06789v1.pdf | author:Jonathan Krause, Benjamin Sapp, Andrew Howard, Howard Zhou, Alexander Toshev, Tom Duerig, James Philbin, Li Fei-Fei category:cs.CV published:2015-11-20 summary:While models of fine-grained recognition have made great progress in recentyears, little work has focused on a key ingredient of making recognition work:data. We use publicly available, noisy data sources to train generic modelswhich vastly improve upon state-of-the-art on fine-grained benchmarks. First,we present an active learning system using non-expert human raters, and improveupon state-of-the-art performance without any text or other metadata associatedwith the images. Second, we show that training on publicly-available noisy webimage search results achieves even higher accuracies, without using anyexpert-annotated training data, while scaling to over ten thousand fine-grainedcategories. We analyze the behavior of our models and data and make a strongcase for the importance of data over special-purpose modeling: using only anoff-the-shelf CNN, we obtain top-1 accuracies of 92.8\% on CUB-200-2011 Birds,85.4\% on Birdsnap, 95.9\% on FGVC-Aircraft, and 82.6\% on Stanford Dogs.
arxiv-14700-97 | Conducting sparse feature selection on arbitrarily long phrases in text corpora with a focus on interpretability | http://arxiv.org/pdf/1511.06798v1.pdf | author:Luke Miratrix, Robin Ackerman category:cs.CL cs.IR stat.AP published:2015-11-20 summary:We propose a general framework for topic-specific summarization of large textcorpora, and illustrate how it can be used for analysis in two quite differentcontexts: an OSHA database of fatality and catastrophe reports (to facilitatesurveillance for patterns in circumstances leading to injury or death) andlegal decisions on workers' compensation claims (to explore relevant case law).Our summarization framework, built on sparse classification methods, is acompromise between simple word frequency based methods currently in wide use,and more heavyweight, model-intensive methods such as Latent DirichletAllocation (LDA). For a particular topic of interest (e.g., mental healthdisability, or chemical reactions), we regress a labeling of documents onto thehigh-dimensional counts of all the other words and phrases in the documents.The resulting small set of phrases found as predictive are then harvested asthe summary. Using a branch-and-bound approach, this method can be extended toallow for phrases of arbitrary length, which allows for potentially richsummarization. We discuss how focus on the purpose of the summaries can informchoices of regularization parameters and model constraints. We evaluate thistool by comparing computational time and summary statistics of the resultingword lists to three other methods in the literature. We also present a new Rpackage, textreg. Overall, we argue that sparse methods have much to offer textanalysis, and is a branch of research that should be considered further in thiscontext.
arxiv-14700-98 | DOC: Deep OCclusion Estimation From A Single Image | http://arxiv.org/pdf/1511.06457v3.pdf | author:Peng Wang, Alan Yuille category:cs.CV cs.LG published:2015-11-20 summary:Recovering the occlusion relationships between objects is a fundamental humanvisual ability which yields important information about the 3D world. In thispaper we propose a deep network architecture, called DOC, which acts on asingle image, detects object boundaries and estimates the border ownership(i.e. which side of the boundary is foreground and which is background). Werepresent occlusion relations by a binary edge map, to indicate the objectboundary, and an occlusion orientation variable which is tangential to theboundary and whose direction specifies border ownership by a left-hand rule,see Fig.1. We train two related deep convolutional neural networks, called DOC,which exploit local and non-local image cues to estimate this representationand hence recover occlusion relations. In order to train and test DOC weconstruct a large-scale instance occlusion boundary dataset using PASCAL VOCimages, which we call the PASCAL instance occlusion dataset (PIOD). Thiscontains 10,000 images and hence is two orders of magnitude larger thanexisting occlusion datasets for outdoor images. We test two variants of DOC onPIOD and on the BSDS occlusion dataset and show they outperformstate-of-the-art methods typically by more than 5AP. Finally, we performnumerous experiments investigating multiple settings of DOC and transferbetween BSDS and PIOD, which provides more insights for further study ofocclusion estimation.
arxiv-14700-99 | The Variational Gaussian Process | http://arxiv.org/pdf/1511.06499v4.pdf | author:Dustin Tran, Rajesh Ranganath, David M. Blei category:stat.ML cs.LG cs.NE stat.CO published:2015-11-20 summary:Variational inference is a powerful tool for approximate inference, and ithas been recently applied for representation learning with deep generativemodels. We develop the variational Gaussian process (VGP), a Bayesiannonparametric variational family, which adapts its shape to match complexposterior distributions. The VGP generates approximate posterior samples bygenerating latent inputs and warping them through random non-linear mappings;the distribution over random mappings is learned during inference, enabling thetransformed outputs to adapt to varying complexity. We prove a universalapproximation theorem for the VGP, demonstrating its representative power forlearning any model. For inference we present a variational objective inspiredby auto-encoders and perform black box inference over a wide class of models.The VGP achieves new state-of-the-art results for unsupervised learning,inferring models such as the deep latent Gaussian model and the recentlyproposed DRAW.
arxiv-14700-100 | TEMPO: Feature-Endowed Teichmüller Extremal Mappings of Point Clouds | http://arxiv.org/pdf/1511.06624v2.pdf | author:Ting Wei Meng, Gary Pui-Tung Choi, Lok Ming Lui category:cs.CG cs.CV cs.GR math.DG published:2015-11-20 summary:In recent decades, the use of 3D point clouds has been widespread in computerindustry. The development of techniques in analyzing point clouds isincreasingly important. In particular, mapping of point clouds has been achallenging problem. In this paper, we develop a discrete analogue of theTeichm\"{u}ller extremal mappings, which guarantee uniform conformalitydistortions, on point cloud surfaces. Based on the discrete analogue, wepropose a novel method called TEMPO for computing Teichm\"{u}ller extremalmappings between feature-endowed point clouds. Using our proposed method, theTeichm\"{u}ller metric is introduced for evaluating the dissimilarity of pointclouds. Consequently, our algorithm enables accurate recognition andclassification of point clouds. Experimental results demonstrate theeffectiveness of our proposed method.
arxiv-14700-101 | Using Deep Learning to Predict Demographics from Mobile Phone Metadata | http://arxiv.org/pdf/1511.06660v4.pdf | author:Bjarke Felbo, Pål Sundsøy, Alex 'Sandy' Pentland, Sune Lehmann, Yves-Alexandre de Montjoye category:cs.LG published:2015-11-20 summary:Mobile phone metadata are increasingly used to study human behavior atlarge-scale. There has recently been a growing interest in predictingdemographic information from metadata. Previous approaches relied onhand-engineered features. We here apply, for the first time, deep learningmethods to mobile phone metadata using a convolutional network. Our methodprovides high accuracy on both age and gender prediction. These results showgreat potential for deep learning approaches for prediction tasks usingstandard mobile phone metadata.
arxiv-14700-102 | Tracklet Association by Online Target-Specific Metric Learning and Coherent Dynamics Estimation | http://arxiv.org/pdf/1511.06654v2.pdf | author:Bing Wang, Gang Wang, Kap Luk Chan, Li Wang category:cs.CV published:2015-11-20 summary:In this paper, we present a novel method based on online target-specificmetric learning and coherent dynamics estimation for tracklet (track fragment)association by network flow optimization in long-term multi-person tracking.Our proposed framework aims to exploit appearance and motion cues to preventidentity switches during tracking and to recover missed detections.Furthermore, target-specific metrics (appearance cue) and motion dynamics(motion cue) are proposed to be learned and estimated online, i.e. during thetracking process. Our approach is effective even when such cues fail toidentify or follow the target due to occlusions or object-to-objectinteractions. We also propose to learn the weights of these two tracking cuesto handle the difficult situations, such as severe occlusions andobject-to-object interactions effectively. Our method has been validated onseveral public datasets and the experimental results show that it outperformsseveral state-of-the-art tracking methods.
arxiv-14700-103 | Semi-supervised Learning with Encoder-Decoder Recurrent Neural Networks: Experiments with Motion Capture Sequences | http://arxiv.org/pdf/1511.06653v2.pdf | author:Félix G. Harvey, Christopher Pal category:cs.CV cs.LG published:2015-11-20 summary:Recent work on sequence to sequence translation using Recurrent NeuralNetworks (RNNs) based on Long Short Term Memory (LSTM) architectures has showngreat potential for learning useful representations of sequential data. Aone-to-many encoder-decoder(s) scheme allows for a single encoder to providerepresentations serving multiple purposes. In our case, we present an LSTMencoder network able to produce representations used by two decoders: one thatreconstructs, and one that classifies if the training sequence has anassociated label. This allows the network to learn representations that areuseful for both discriminative and reconstructive tasks at the same time. Thisparadigm is well suited for semi-supervised learning with sequences and we testour proposed approach on an action recognition task using motion capture(MOCAP) sequences. We find that semi-supervised feature learning can improvestate-of-the-art movement classification accuracy on the HDM05 action dataset.Further, we find that even when using only labeled data and a primarilydiscriminative objective the addition of a reconstructive decoder can serve asa form of regularization that reduces over-fitting and improves test setaccuracy.
arxiv-14700-104 | Bayesian inference via rejection filtering | http://arxiv.org/pdf/1511.06458v2.pdf | author:Nathan Wiebe, Christopher Granade, Ashish Kapoor, Krysta M Svore category:cs.LG quant-ph stat.ML published:2015-11-20 summary:We provide a method for approximating Bayesian inference using rejectionsampling. We not only make the process efficient, but also dramatically reducethe memory required relative to conventional methods by combining rejectionsampling with particle filtering. We also provide an approximate form ofrejection sampling that makes rejection filtering tractable in cases whereexact rejection sampling is not efficient. Finally, we present severalnumerical examples of rejection filtering that show its ability to track timedependent parameters in online settings and also benchmark its performance onMNIST classification problems.
arxiv-14700-105 | Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications | http://arxiv.org/pdf/1511.06530v2.pdf | author:Yong-Deok Kim, Eunhyeok Park, Sungjoo Yoo, Taelim Choi, Lu Yang, Dongjun Shin category:cs.CV cs.LG published:2015-11-20 summary:Although the latest high-end smartphone has powerful CPU and GPU, runningdeeper convolutional neural networks (CNNs) for complex tasks such as ImageNetclassification on mobile devices is challenging. To deploy deep CNNs on mobiledevices, we present a simple and effective scheme to compress the entire CNN,which we call one-shot whole network compression. The proposed scheme consistsof three steps: (1) rank selection with variational Bayesian matrixfactorization, (2) Tucker decomposition on kernel tensor, and (3) fine-tuningto recover accumulated loss of accuracy, and each step can be easilyimplemented using publicly available tools. We demonstrate the effectiveness ofthe proposed scheme by testing the performance of various compressed CNNs(AlexNet, VGGS, GoogLeNet, and VGG-16) on the smartphone. Significantreductions in model size, runtime, and energy consumption are obtained, at thecost of small loss in accuracy. In addition, we address the importantimplementation level issue on 1?1 convolution, which is a key operation ofinception module of GoogLeNet as well as CNNs compressed by our proposedscheme.
arxiv-14700-106 | Sequence Level Training with Recurrent Neural Networks | http://arxiv.org/pdf/1511.06732v7.pdf | author:Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, Wojciech Zaremba category:cs.LG cs.CL published:2015-11-20 summary:Many natural language processing applications use language models to generatetext. These models are typically trained to predict the next word in asequence, given the previous words and some context such as an image. However,at test time the model is expected to generate the entire sequence fromscratch. This discrepancy makes generation brittle, as errors may accumulatealong the way. We address this issue by proposing a novel sequence leveltraining algorithm that directly optimizes the metric used at test time, suchas BLEU or ROUGE. On three different tasks, our approach outperforms severalstrong baselines for greedy generation. The method is also competitive whenthese baselines employ beam search, while being several times faster.
arxiv-14700-107 | The Effect of Gradient Noise on the Energy Landscape of Deep Networks | http://arxiv.org/pdf/1511.06485v4.pdf | author:Pratik Chaudhari, Stefano Soatto category:cs.LG published:2015-11-20 summary:We analyze the regularization properties of additive gradient noise in thetraining of deep networks by posing it as finding the ground state of theHamiltonian of a spherical spin glass in an external magnetic field. We showthat depending upon the magnitude of the magnetic field, the Hamiltonianchanges dramatically from a highly non-convex energy landscape withexponentially many critical points to a regime with polynomially many criticalpoints and finally, "trivializes"' to exactly one minimum. This phenomenon,known as topology trivialization in the physics literature, can be leveraged todevise annealing schemes for additive noise such that the training starts inthe polynomial regime but gradually morphs the energy landscape into theoriginal one as training progresses. We demonstrate through experiments onfully-connected and convolutional neural networks that annealing schemes basedon trivialization lead to accelerated training and also improve generalizationerror.
arxiv-14700-108 | On Binary Embedding using Circulant Matrices | http://arxiv.org/pdf/1511.06480v2.pdf | author:Felix X. Yu, Aditya Bhaskara, Sanjiv Kumar, Yunchao Gong, Shih-Fu Chang category:cs.DS cs.LG published:2015-11-20 summary:Binary embeddings provide efficient and powerful ways to perform operationson large scale data. However binary embedding typically requires long codes inorder to preserve the discriminative power of the input space. Thus binarycoding methods traditionally suffer from high computation and storage costs insuch a scenario. To address this problem, we propose Circulant Binary Embedding(CBE) which generates binary codes by projecting the data with a circulantmatrix. The circulant structure allows us to use Fast Fourier Transformalgorithms to speed up the computation. For obtaining $k$-bit binary codes from$d$-dimensional data, this improves the time complexity from $O(dk)$ to$O(d\log{d})$, and the space complexity from $O(dk)$ to $O(d)$. We study two settings, which differ in the way we choose the parameters ofthe circulant matrix. In the first, the parameters are chosen randomly and inthe second, the parameters are learned using the data. For randomized CBE, wegive a theoretical analysis comparing it with binary embedding using anunstructured random projection matrix. The challenge here is to show that thedependencies in the entries of the circulant matrix do not lead to a loss inperformance. In the second setting, we design a novel time-frequencyalternating optimization to learn data-dependent circulant projections, whichalternatively minimizes the objective in original and Fourier domains. In boththe settings, we show by extensive experiments that the CBE approach gives muchbetter performance than the state-of-the-art approaches if we fix a runningtime, and provides much faster computation with negligible performancedegradation if we fix the number of bits in the embedding.
arxiv-14700-109 | Recurrent Gaussian Processes | http://arxiv.org/pdf/1511.06644v6.pdf | author:César Lincoln C. Mattos, Zhenwen Dai, Andreas Damianou, Jeremy Forth, Guilherme A. Barreto, Neil D. Lawrence category:cs.LG stat.ML published:2015-11-20 summary:We define Recurrent Gaussian Processes (RGP) models, a general family ofBayesian nonparametric models with recurrent GP priors which are able to learndynamical patterns from sequential data. Similar to Recurrent Neural Networks(RNNs), RGPs can have different formulations for their internal states,distinct inference methods and be extended with deep structures. In suchcontext, we propose a novel deep RGP model whose autoregressive states arelatent, thereby performing representation and dynamical learningsimultaneously. To fully exploit the Bayesian nature of the RGP model wedevelop the Recurrent Variational Bayes (REVARB) framework, which enablesefficient inference and strong regularization through coherent propagation ofuncertainty across the RGP layers and states. We also introduce a RGP extensionwhere variational parameters are greatly reduced by being reparametrizedthrough RNN-based sequential recognition models. We apply our model to thetasks of nonlinear system identification and human motion modeling. Thepromising obtained results indicate that our RGP model maintains its highlyflexibility while being able to avoid overfitting and being applicable evenwhen larger datasets are not available.
arxiv-14700-110 | Integrating Deep Features for Material Recognition | http://arxiv.org/pdf/1511.06522v6.pdf | author:Yan Zhang, Mete Ozay, Xing Liu, Takayuki Okatani category:cs.CV cs.LG published:2015-11-20 summary:We propose a method for integration of features extracted using deeprepresentations of Convolutional Neural Networks (CNNs) each of which islearned using a different image dataset of objects and materials for materialrecognition. Given a set of representations of multiple pre-trained CNNs, wefirst compute activations of features using the representations on the imagesto select a set of samples which are best represented by the features. Then, wemeasure the uncertainty of the features by computing the entropy of classdistributions for each sample set. Finally, we compute the contribution of eachfeature to representation of classes for feature selection and integration. Weexamine the proposed method on three benchmark datasets for materialrecognition. Experimental results show that the proposed method achievesstate-of-the-art performance by integrating deep features. Additionally, weintroduce a new material dataset called EFMD by extending Flickr MaterialDatabase (FMD). By the employment of the EFMD with transfer learning forupdating the learned CNN models, we achieve 84.0%+/-1.8% accuracy on the FMDdataset which is close to human performance that is 84.9%.
arxiv-14700-111 | Improving Neural Machine Translation Models with Monolingual Data | http://arxiv.org/pdf/1511.06709v3.pdf | author:Rico Sennrich, Barry Haddow, Alexandra Birch category:cs.CL published:2015-11-20 summary:Neural Machine Translation (NMT) has obtained state-of-the art performancefor several language pairs, while only using parallel data for training.Target-side monolingual data plays an important role in boosting fluency forphrase-based statistical machine translation, and we investigate the use ofmonolingual data for NMT. In contrast to previous work, which combines NMTmodels with separately trained language models, we note that encoder-decoderNMT architectures already have the capacity to learn the same information as alanguage model, and we explore strategies to train with monolingual datawithout changing the neural network architecture. By pairing monolingualtraining data with an automatic back-translation, we can treat it as additionalparallel training data, and we obtain substantial improvements on the WMT 15task English<->German (+2.8-3.7 BLEU), and for the low-resourced IWSLT 14 taskTurkish->English (+2.1-3.4 BLEU), obtaining new state-of-the-art results. Wealso show that fine-tuning on in-domain monolingual and parallel data givessubstantial improvements for the IWSLT 15 task English->German.
arxiv-14700-112 | Recognizing Activities of Daily Living with a Wrist-mounted Camera | http://arxiv.org/pdf/1511.06783v2.pdf | author:Katsunori Ohnishi, Atsushi Kanehira, Asako Kanezaki, Tatsuya Harada category:cs.CV published:2015-11-20 summary:We present a novel dataset and a novel algorithm for recognizing activitiesof daily living (ADL) from a first-person wearable camera. Handled objects arecrucially important for egocentric ADL recognition. For specific examination ofobjects related to users' actions separately from other objects in anenvironment, many previous works have addressed the detection of handledobjects in images captured from head-mounted and chest-mounted cameras.Nevertheless, detecting handled objects is not always easy because they tend toappear small in images. They can be occluded by a user's body. As describedherein, we mount a camera on a user's wrist. A wrist-mounted camera can capturehandled objects at a large scale, and thus it enables us to skip objectdetection process. To compare a wrist-mounted camera and a head-mounted camera,we also develop a novel and publicly available dataset that includes videos andannotations of daily activities captured simultaneously by both cameras.Additionally, we propose a discriminative video representation that retainsspatial and temporal information after encoding frame descriptors extracted byConvolutional Neural Networks (CNN).
arxiv-14700-113 | Resiliency of Deep Neural Networks under Quantization | http://arxiv.org/pdf/1511.06488v3.pdf | author:Wonyong Sung, Sungho Shin, Kyuyeon Hwang category:cs.LG cs.NE published:2015-11-20 summary:The complexity of deep neural network algorithms for hardware implementationcan be much lowered by optimizing the word-length of weights and signals.Direct quantization of floating-point weights, however, does not show goodperformance when the number of bits assigned is small. Retraining of quantizednetworks has been developed to relieve this problem. In this work, the effectsof retraining are analyzed for a feedforward deep neural network (FFDNN) and aconvolutional neural network (CNN). The network complexity is controlled toknow their effects on the resiliency of quantized networks by retraining. Thecomplexity of the FFDNN is controlled by varying the unit size in each hiddenlayer and the number of layers, while that of the CNN is done by modifying thefeature map configuration. We find that the performance gap between thefloating-point and the retrain-based ternary (+1, 0, -1) weight neural networksexists with a fair amount in 'complexity limited' networks, but the discrepancyalmost vanishes in fully complex networks whose capability is limited by thetraining data, rather than by the number of connections. This research showsthat highly complex DNNs have the capability of absorbing the effects of severeweight quantization through retraining, but connection limited networks areless resilient. This paper also presents the effective compression ratio toguide the trade-off between the network size and the precision when thehardware resource is limited.
arxiv-14700-114 | Adjustable Bounded Rectifiers: Towards Deep Binary Representations | http://arxiv.org/pdf/1511.06201v1.pdf | author:Zhirong Wu, Dahua Lin, Xiaoou Tang category:cs.LG stat.ML published:2015-11-19 summary:Binary representation is desirable for its memory efficiency, computationspeed and robustness. In this paper, we propose adjustable bounded rectifiersto learn binary representations for deep neural networks. While hardconstraining representations across layers to be binary makes trainingunreasonably difficult, we softly encourage activations to diverge from realvalues to binary by approximating step functions. Our final representation iscompletely binary. We test our approach on MNIST, CIFAR10, and ILSVRC2012dataset, and systematically study the training dynamics of the binarizationprocess. Our approach can binarize the last layer representation without lossof performance and binarize all the layers with reasonably small degradations.The memory space that it saves may allow more sophisticated models to bedeployed, thus compensating the loss. To the best of our knowledge, this is thefirst work to report results on current deep network architectures usingcomplete binary middle representations. Given the learned representations, wefind that the firing or inhibition of a binary neuron is usually associatedwith a meaningful interpretation across different classes. This suggests thatthe semantic structure of a neural network may be manifested through a guidedbinarization process.
arxiv-14700-115 | Diffusion Representations | http://arxiv.org/pdf/1511.06208v1.pdf | author:Moshe Salhov, Amit Bermanis, Guy Wolf, Amir Averbuch category:stat.ML cs.LG math.SP published:2015-11-19 summary:Diffusion Maps framework is a kernel based method for manifold learning anddata analysis that defines diffusion similarities by imposing a Markovianprocess on the given dataset. Analysis by this process uncovers the intrinsicgeometric structures in the data. Recently, it was suggested to replace thestandard kernel by a measure-based kernel that incorporates information aboutthe density of the data. Thus, the manifold assumption is replaced by a moregeneral measure-based assumption. The measure-based diffusion kernel incorporates two separate independentrepresentations. The first determines a measure that correlates with a densitythat represents normal behaviors and patterns in the data. The second consistsof the analyzed multidimensional data points. In this paper, we present a representation framework for data analysis ofdatasets that is based on a closed-form decomposition of the measure-basedkernel. The proposed representation preserves pairwise diffusion distances thatdoes not depend on the data size while being invariant to scale. For astationary data, no out-of-sample extension is needed for embedding newlyarrived data points in the representation space. Several aspects of thepresented methodology are demonstrated on analytically generated data.
arxiv-14700-116 | Automatically selecting inference algorithms for discrete energy minimisation | http://arxiv.org/pdf/1511.06214v1.pdf | author:Paul Henderson, Vittorio Ferrari category:cs.CV published:2015-11-19 summary:Minimisation of discrete energies defined over factors is an importantproblem in computer vision, and a vast number of MAP inference algorithms havebeen proposed. Different inference algorithms perform better on factor graphmodels (GMs) from different underlying problem classes, and in general it isdifficult to know which algorithm will yield the lowest energy for a given GM.To mitigate this difficulty, survey papers advise the practitioner on whatalgorithms perform well on what classes of models. We take the next stepforward, and present a technique to automatically select the best inferencealgorithm for an input GM. We validate our method experimentally on an extendedversion of the OpenGM2 benchmark, containing a diverse set of vision problems.On average, our method selects an inference algorithm yielding labellings with96% of variables the same as the best available algorithm.
arxiv-14700-117 | Spherical Cap Packing Asymptotics and Rank-Extreme Detection | http://arxiv.org/pdf/1511.06198v1.pdf | author:Kai Zhang category:math.ST cs.IT math.IT stat.ME stat.ML stat.TH published:2015-11-19 summary:We study the spherical cap packing problem with a probabilistic approach.Such probabilistic considerations result in an asymptotic sharp universaluniform bound on the maximal inner product between any set of unit vectors anda stochastically independent uniformly distributed unit vector. When the set ofunit vectors are themselves independently uniformly distributed, we furtherdevelop the extreme value distribution limit of the maximal inner product,which characterizes its uncertainty around the bound. As applications of the above asymptotic results, we derive (1) an asymptoticsharp universal uniform bound on the maximal spurious correlation, as well asits uniform convergence in distribution when the explanatory variables areindependently Gaussian distributed; and (2) an asymptotic sharp universal boundon the maximum norm of a low-rank elliptically distributed vector, as well asrelated limiting distributions. With these results, we develop a fast detectionmethod for a low-rank structure in high-dimensional Gaussian data without usingthe spectrum information.
arxiv-14700-118 | Towards Open Set Deep Networks | http://arxiv.org/pdf/1511.06233v1.pdf | author:Abhijit Bendale, Terrance Boult category:cs.CV cs.LG published:2015-11-19 summary:Deep networks have produced significant gains for various visual recognitionproblems, leading to high impact academic and commercial applications. Recentwork in deep networks highlighted that it is easy to generate images thathumans would never classify as a particular object class, yet networks classifysuch images high confidence as that given class - deep network are easilyfooled with images humans do not consider meaningful. The closed set nature ofdeep networks forces them to choose from one of the known classes leading tosuch artifacts. Recognition in the real world is open set, i.e. the recognitionsystem should reject unknown/unseen classes at test time. We present amethodology to adapt deep networks for open set recognition, by introducing anew model layer, OpenMax, which estimates the probability of an input beingfrom an unknown class. A key element of estimating the unknown probability isadapting Meta-Recognition concepts to the activation patterns in thepenultimate layer of the network. OpenMax allows rejection of "fooling" andunrelated open set images presented to the system; OpenMax greatly reduces thenumber of obvious errors made by a deep network. We prove that the OpenMaxconcept provides bounded open space risk, thereby formally providing an openset recognition solution. We evaluate the resulting open set deep networksusing pre-trained networks from the Caffe Model-zoo on ImageNet 2012 validationdata, and thousands of fooling and open set images. The proposed OpenMax modelsignificantly outperforms open set recognition accuracy of basic deep networksas well as deep networks with thresholding of SoftMax probabilities.
arxiv-14700-119 | Gaussian Mixture Embeddings for Multiple Word Prototypes | http://arxiv.org/pdf/1511.06246v1.pdf | author:Xinchi Chen, Xipeng Qiu, Jingxiang Jiang, Xuanjing Huang category:cs.CL published:2015-11-19 summary:Recently, word representation has been increasingly focused on for itsexcellent properties in representing the word semantics. Previous works mainlysuffer from the problem of polysemy phenomenon. To address this problem, mostof previous models represent words as multiple distributed vectors. However, itcannot reflect the rich relations between words by representing words as pointsin the embedded space. In this paper, we propose the Gaussian mixture skip-gram(GMSG) model to learn the Gaussian mixture embeddings for words based onskip-gram framework. Each word can be regarded as a gaussian mixturedistribution in the embedded space, and each gaussian component represents aword sense. Since the number of senses varies from word to word, we furtherpropose the Dynamic GMSG (D-GMSG) model by adaptively increasing the sensenumber of words during training. Experiments on four benchmarks show theeffectiveness of our proposed model.
arxiv-14700-120 | Critical Parameters in Particle Swarm Optimisation | http://arxiv.org/pdf/1511.06248v1.pdf | author:J. Michael Herrmann, Adam Erskine, Thomas Joyce category:cs.NE published:2015-11-19 summary:Particle swarm optimisation is a metaheuristic algorithm which findsreasonable solutions in a wide range of applied problems if suitable parametersare used. We study the properties of the algorithm in the framework of randomdynamical systems which, due to the quasi-linear swarm dynamics, yieldsanalytical results for the stability properties of the particles. Suchconsiderations predict a relationship between the parameters of the algorithmthat marks the edge between convergent and divergent behaviours. Comparisonwith simulations indicates that the algorithm performs best near this margin ofinstability.
arxiv-14700-121 | Faster method for Deep Belief Network based Object classification using DWT | http://arxiv.org/pdf/1511.06276v1.pdf | author:Saurabh Sihag, Pranab Kumar Dutta category:cs.CV cs.LG published:2015-11-19 summary:A Deep Belief Network (DBN) requires large, multiple hidden layers with highnumber of hidden units to learn good features from the raw pixels of largeimages. This implies more training time as well as computational complexity. Byintegrating DBN with Discrete Wavelet Transform (DWT), both training time andcomputational complexity can be reduced. The low resolution images obtainedafter application of DWT are used to train multiple DBNs. The results obtainedfrom these DBNs are combined using a weighted voting algorithm. The performanceof this method is found to be competent and faster in comparison with that oftraditional DBNs.
arxiv-14700-122 | Good, Better, Best: Choosing Word Embedding Context | http://arxiv.org/pdf/1511.06312v1.pdf | author:James Cross, Bing Xiang, Bowen Zhou category:cs.CL published:2015-11-19 summary:We propose two methods of learning vector representations of words andphrases that each combine sentence context with structural features extractedfrom dependency trees. Using several variations of neural network classifier,we show that these combined methods lead to improved performance when used asinput features for supervised term-matching.
arxiv-14700-123 | Why M Heads are Better than One: Training a Diverse Ensemble of Deep Networks | http://arxiv.org/pdf/1511.06314v1.pdf | author:Stefan Lee, Senthil Purushwalkam, Michael Cogswell, David Crandall, Dhruv Batra category:cs.CV cs.LG cs.NE published:2015-11-19 summary:Convolutional Neural Networks have achieved state-of-the-art performance on awide range of tasks. Most benchmarks are led by ensembles of these powerfullearners, but ensembling is typically treated as a post-hoc procedureimplemented by averaging independently trained models with model variationinduced by bagging or random initialization. In this paper, we rigorously treatensembling as a first-class problem to explicitly address the question: whatare the best strategies to create an ensemble? We first compare a large numberof ensembling strategies, and then propose and evaluate novel strategies, suchas parameter sharing (through a new family of models we call TreeNets) as wellas training under ensemble-aware and diversity-encouraging losses. Wedemonstrate that TreeNets can improve ensemble performance and that diverseensembles can be trained end-to-end under a unified loss, achievingsignificantly higher "oracle" accuracies than classical ensembles.
arxiv-14700-124 | face anti-spoofing based on color texture analysis | http://arxiv.org/pdf/1511.06316v1.pdf | author:Zinelabidine Boulkenafet, Jukka Komulainen, Abdenour Hadid category:cs.CV published:2015-11-19 summary:Research on face spoofing detection has mainly been focused on analyzing theluminance of the face images, hence discarding the chrominance informationwhich can be useful for discriminating fake faces from genuine ones. In thiswork, we propose a new face anti-spoofing method based on color textureanalysis. We analyze the joint color-texture information from the luminance andthe chrominance channels using a color local binary pattern descriptor. Morespecifically, the feature histograms are extracted from each image bandseparately. Extensive experiments on two benchmark datasets, namely CASIA faceanti-spoofing and Replay-Attack databases, showed excellent results compared tothe state-of-the-art. Most importantly, our inter-database evaluation depictsthat the proposed approach showed very promising generalization capabilities.
arxiv-14700-125 | Unsupervised Deep Embedding for Clustering Analysis | http://arxiv.org/pdf/1511.06335v1.pdf | author:Junyuan Xie, Ross Girshick, Ali Farhadi category:cs.LG cs.CV published:2015-11-19 summary:Clustering is central to many data-driven application domains and has beenstudied extensively in terms of distance functions and grouping algorithms.Relatively little work has focused on learning representations for clustering.In this paper, we propose Deep Embedded Clustering (DEC), a method thatsimultaneously learns feature representations and cluster assignments usingdeep neural networks. DEC learns a mapping from the data space to alower-dimensional feature space in which it iteratively optimizes a clusteringobjective. Our experimental evaluations on image and text corpora showsignificant improvement over state-of-the-art methods.
arxiv-14700-126 | Robust Classification by Pre-conditioned LASSO and Transductive Diffusion Component Analysis | http://arxiv.org/pdf/1511.06340v1.pdf | author:Yanwei Fu, De-An Huang, Leonid Sigal category:cs.LG cs.CV math.ST stat.ML stat.TH published:2015-11-19 summary:Modern machine learning-based recognition approaches require large-scaledatasets with large number of labelled training images. However, such datasetsare inherently difficult and costly to collect and annotate. Hence there is agreat and growing interest in automatic dataset collection methods that canleverage the web. % which are collected % in a cheap, efficient and yetunreliable way. Collecting datasets in this way, however, requires robust andefficient ways for detecting and excluding outliers that are common andprevalent. % Outliers are thus a % prominent treat of using these dataset. Sofar, there have been a limited effort in machine learning community to directlydetect outliers for robust classification. Inspired by the recent work onPre-conditioned LASSO, this paper formulates the outlier detection task usingPre-conditioned LASSO and employs \red{unsupervised} transductive diffusioncomponent analysis to both integrate the topological structure of the datamanifold, from labeled and unlabeled instances, and reduce the featuredimensionality. Synthetic experiments as well as results on two real-worldclassification tasks show that our framework can robustly detect the outliersand improve classification.
arxiv-14700-127 | Learning Representations Using Complex-Valued Nets | http://arxiv.org/pdf/1511.06351v1.pdf | author:Andy M. Sarroff, Victor Shepardson, Michael A. Casey category:cs.LG cs.NE published:2015-11-19 summary:Complex-valued neural networks (CVNNs) are an emerging field of research inneural networks due to their potential representational properties for audio,image, and physiological signals. It is common in signal processing totransform sequences of real values to the complex domain via a set of complexbasis functions, such as the Fourier transform. We show how CVNNs can be usedto learn complex representations of real valued time-series data. We presentmethods and results using a framework that can compose holomorphic andnon-holomorphic functions in a multi-layer network using a theoretical resultcalled the Wirtinger derivative. We test our methods on a representationlearning task for real-valued signals, recurrent complex-valued networks andtheir real-valued counterparts. Our results show that recurrent complex-valuednetworks can perform as well as their real-valued counterparts while learningfilters that are representative of the domain of the data.
arxiv-14700-128 | Dynamic Adaptive Network Intelligence | http://arxiv.org/pdf/1511.06379v1.pdf | author:Richard Searle, Megan Bingham-Walker category:cs.CL cs.LG published:2015-11-19 summary:Accurate representational learning of both the explicit and implicitrelationships within data is critical to the ability of machines to performmore complex and abstract reasoning tasks. We describe the efficient weaklysupervised learning of such inferences by our Dynamic Adaptive NetworkIntelligence (DANI) model. We report state-of-the-art results for DANI overquestion answering tasks in the bAbI dataset that have proved difficult forcontemporary approaches to learning representation (Weston et al., 2015).
arxiv-14700-129 | A Unified Gradient Regularization Family for Adversarial Examples | http://arxiv.org/pdf/1511.06385v1.pdf | author:Chunchuan Lyu, Kaizhu Huang, Hai-Ning Liang category:cs.LG stat.ML published:2015-11-19 summary:Adversarial examples are augmented data points generated by imperceptibleperturbation of input samples. They have recently drawn much attention with themachine learning and data mining community. Being difficult to distinguish fromreal examples, such adversarial examples could change the prediction of many ofthe best learning models including the state-of-the-art deep learning models.Recent attempts have been made to build robust models that take into accountadversarial examples. However, these methods can either lead to performancedrops or lack mathematical motivations. In this paper, we propose a unifiedframework to build robust machine learning models against adversarial examples.More specifically, using the unified framework, we develop a family of gradientregularization methods that effectively penalize the gradient of loss functionw.r.t. inputs. Our proposed framework is appealing in that it offers a unifiedview to deal with adversarial examples. It incorporates anotherrecently-proposed perturbation based approach as a special case. In addition,we present some visual effects that reveals semantic meaning in thoseperturbations, and thus support our regularization method and provide anotherexplanation for generalizability of adversarial examples. By applying thistechnique to Maxout networks, we conduct a series of experiments and achieveencouraging results on two benchmark datasets. In particular,we attain the bestaccuracy on MNIST data (without data augmentation) and competitive performanceon CIFAR-10 data.
arxiv-14700-130 | sense2vec - A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings | http://arxiv.org/pdf/1511.06388v1.pdf | author:Andrew Trask, Phil Michalak, John Liu category:cs.CL cs.LG published:2015-11-19 summary:Neural word representations have proven useful in Natural Language Processing(NLP) tasks due to their ability to efficiently model complex semantic andsyntactic word relationships. However, most techniques model only onerepresentation per word, despite the fact that a single word can have multiplemeanings or "senses". Some techniques model words by using multiple vectorsthat are clustered based on context. However, recent neural approaches rarelyfocus on the application to a consuming NLP algorithm. Furthermore, thetraining process of recent word-sense models is expensive relative tosingle-sense embedding processes. This paper presents a novel approach whichaddresses these concerns by modeling multiple embeddings for each word based onsupervised disambiguation, which provides a fast and accurate way for aconsuming NLP model to select a sense-disambiguated embedding. We demonstratethat these embeddings can disambiguate both contrastive senses such as nominaland verbal senses as well as nuanced senses such as sarcasm. We furtherevaluate Part-of-Speech disambiguated embeddings on neural dependency parsing,yielding a greater than 8% average error reduction in unlabeled attachmentscores across 6 languages.
arxiv-14700-131 | Coreset-Based Adaptive Tracking | http://arxiv.org/pdf/1511.06147v1.pdf | author:Abhimanyu Dubey, Nikhil Naik, Dan Raviv, Rahul Sukthankar, Ramesh Raskar category:cs.CV cs.LG published:2015-11-19 summary:We propose a method for learning from streaming visual data using a compact,constant size representation of all the data that was seen until a givenmoment. Specifically, we construct a 'coreset' representation of streaming datausing a parallelized algorithm, which is an approximation of a set withrelation to the squared distances between this set and all other points in itsambient space. We learn an adaptive object appearance model from the coresettree in constant time and logarithmic space and use it for object tracking bydetection. Our method obtains excellent results for object tracking on threestandard datasets over more than 100 videos. The ability to summarize dataefficiently makes our method ideally suited for tracking in long videos inpresence of space and time constraints. We demonstrate this ability byoutperforming a variety of algorithms on the TLD dataset with 2685 frames onaverage. This coreset based learning approach can be applied for both real-timelearning of small, varied data and fast learning of big data.
arxiv-14700-132 | Direct Loss Minimization for Training Deep Neural Nets | http://arxiv.org/pdf/1511.06411v1.pdf | author:Yang Song, Alexander G. Schwing, Richard S. Zemel, Raquel Urtasun category:cs.LG published:2015-11-19 summary:Supervised training of deep neural nets typically relies on minimizingcross-entropy. However, in many domains, we are interested in performing wellon specific application-specific metrics. In this paper we proposed a directloss minimization approach to train deep neural networks, taking into accountthe application-specific loss functions. This can be non-trivial, when thesefunctions are non-smooth and non-decomposable. We demonstrate the effectivenessof our approach in the context of maximizing average precision for rankingproblems. Towards this goal, we propose a dynamic programming algorithm thatcan efficiently compute the weight updates. Our approach proves superior to avariety of baselines in the context of action classification and objectdetection.
arxiv-14700-133 | Fast Parallel SAME Gibbs Sampling on General Discrete Bayesian Networks | http://arxiv.org/pdf/1511.06416v1.pdf | author:Daniel Seita, Haoyu Chen, John Canny category:cs.LG stat.ML published:2015-11-19 summary:A fundamental task in machine learning and related fields is to performinference on Bayesian networks. Since exact inference takes exponential time ingeneral, a variety of approximate methods are used. Gibbs sampling is one ofthe most accurate approaches and provides unbiased samples from the posteriorbut it has historically been too expensive for large models. In this paper, wepresent an optimized, parallel Gibbs sampler augmented with state replication(SAME or State Augmented Marginal Estimation) to decrease convergence time. Wefind that SAME can improve the quality of parameter estimates whileaccelerating convergence. Experiments on both synthetic and real data show thatour Gibbs sampler is substantially faster than the state of the art sampler,JAGS, without sacrificing accuracy. Our ultimate objective is to introduce theGibbs sampler to researchers in many fields to expand their range of feasibleinference problems.
arxiv-14700-134 | Canonical Autocorrelation Analysis | http://arxiv.org/pdf/1511.06419v1.pdf | author:Maria De-Arteaga, Artur Dubrawski, Peter Huggins category:stat.ML cs.LG published:2015-11-19 summary:We present an extension of sparse Canonical Correlation Analysis (CCA)designed for finding multiple-to-multiple linear correlations within a singleset of variables. Unlike CCA, which finds correlations between two sets of datawhere the rows are matched exactly but the columns represent separate sets ofvariables, the method proposed here, Canonical Autocorrelation Analysis (CAA),finds multivariate correlations within just one set of variables. This can beuseful when we look for hidden parsimonious structures in data, each involvingonly a small subset of all features. In addition, the discovered correlationsare highly interpretable as they are formed by pairs of sparse linearcombinations of the original features. We show how CAA can be of use as a toolfor anomaly detection when the expected structure of correlations is notfollowed by anomalous data. We illustrate the utility of CAA in two applicationdomains where single-class and unsupervised learning of correlation structuresare particularly relevant: breast cancer diagnosis and radiation threatdetection. When applied to the Wisconsin Breast Cancer data, single-class CAAis competitive with supervised methods used in literature. On the radiationthreat detection task, unsupervised CAA performs significantly better than anunsupervised alternative prevalent in the domain, while providing valuableadditional insights for threat analysis.
arxiv-14700-135 | Joint Word Representation Learning using a Corpus and a Semantic Lexicon | http://arxiv.org/pdf/1511.06438v1.pdf | author:Danushka Bollegala, Alsuhaibani Mohammed, Takanori Maehara, Ken-ichi Kawarabayashi category:cs.CL cs.AI published:2015-11-19 summary:Methods for learning word representations using large text corpora havereceived much attention lately due to their impressive performance in numerousnatural language processing (NLP) tasks such as, semantic similaritymeasurement, and word analogy detection. Despite their success, thesedata-driven word representation learning methods do not consider the richsemantic relational structure between words in a co-occurring context. On theother hand, already much manual effort has gone into the construction ofsemantic lexicons such as the WordNet that represent the meanings of words bydefining the various relationships that exist among the words in a language. Weconsider the question, can we improve the word representations learnt using acorpora by integrating the knowledge from semantic lexicons?. For this purpose,we propose a joint word representation learning method that simultaneouslypredicts the co-occurrences of two words in a sentence subject to therelational constrains given by the semantic lexicon. We use relations thatexist between words in the lexicon to regularize the word representationslearnt from the corpus. Our proposed method statistically significantlyoutperforms previously proposed methods for incorporating semantic lexiconsinto word representations on several benchmark datasets for semantic similarityand word analogy.
arxiv-14700-136 | The Kernel Two-Sample Test for Brain Networks | http://arxiv.org/pdf/1511.06120v1.pdf | author:Emanuele Olivetti, Sandro Vega-Pons, Paolo Avesani category:stat.ML published:2015-11-19 summary:In clinical and neuroscientific studies, systematic differences between twopopulations of brain networks are investigated in order to characterize mentaldiseases or processes. Those networks are usually represented as graphs builtfrom neuroimaging data and studied by means of graph analysis methods. Thetypical machine learning approach to study these brain graphs creates aclassifier and tests its ability to discriminate the two populations. Incontrast to this approach, in this work we propose to directly test whether twopopulations of graphs are different or not, by using the kernel two-sample test(KTST), without creating the intermediate classifier. We claim that, ingeneral, the two approaches provides similar results and that the KTST requiresmuch less computation. Additionally, in the regime of low sample size, we claimthat the KTST has lower frequency of Type II error than the classificationapproach. Besides providing algorithmic considerations to support these claims,we show strong evidence through experiments and one simulation.
arxiv-14700-137 | Deep Metric Learning via Lifted Structured Feature Embedding | http://arxiv.org/pdf/1511.06452v1.pdf | author:Hyun Oh Song, Yu Xiang, Stefanie Jegelka, Silvio Savarese category:cs.CV cs.LG published:2015-11-19 summary:Learning the distance metric between pairs of examples is of great importancefor learning and visual recognition. With the remarkable success from the stateof the art convolutional neural networks, recent works have shown promisingresults on discriminatively training the networks to learn semantic featureembeddings where similar examples are mapped close to each other and dissimilarexamples are mapped farther apart. In this paper, we describe an algorithm fortaking full advantage of the training batches in the neural network training bylifting the vector of pairwise distances within the batch to the matrix ofpairwise distances. This step enables the algorithm to learn the state of theart feature embedding by optimizing a novel structured prediction objective onthe lifted problem. Additionally, we collected Online Products dataset: 120kimages of 23k classes of online products for metric learning. Our experimentson the CUB-200-2011, CARS196, and Online Products datasets demonstratesignificant improvement over existing deep feature embedding methods on allexperimented embedding sizes with the GoogLeNet network.
arxiv-14700-138 | Convolutional neural networks with low-rank regularization | http://arxiv.org/pdf/1511.06067v3.pdf | author:Cheng Tai, Tong Xiao, Yi Zhang, Xiaogang Wang, Weinan E category:cs.LG cs.CV stat.ML published:2015-11-19 summary:Large CNNs have delivered impressive performance in various computer visionapplications. But the storage and computation requirements make it problematicfor deploying these models on mobile devices. Recently, tensor decompositionshave been used for speeding up CNNs. In this paper, we further develop thetensor decomposition technique. We propose a new algorithm for computing thelow-rank tensor decomposition for removing the redundancy in the convolutionkernels. The algorithm finds the exact global optimizer of the decompositionand is more effective than iterative methods. Based on the decomposition, wefurther propose a new method for training low-rank constrained CNNs fromscratch. Interestingly, while achieving a significant speedup, sometimes thelow-rank constrained CNNs delivers significantly better performance than theirnon-constrained counterparts. On the CIFAR-10 dataset, the proposed low-rankNIN model achieves $91.31\%$ accuracy (without data augmentation), which alsoimproves upon state-of-the-art result. We evaluated the proposed method onCIFAR-10 and ILSVRC12 datasets for a variety of modern CNNs, including AlexNet,NIN, VGG and GoogleNet with success. For example, the forward time of VGG-16 isreduced by half while the performance is still comparable. Empirical successsuggests that low-rank tensor decompositions can be a very useful tool forspeeding up large CNNs.
arxiv-14700-139 | Better Computer Go Player with Neural Network and Long-term Prediction | http://arxiv.org/pdf/1511.06410v3.pdf | author:Yuandong Tian, Yan Zhu category:cs.LG cs.AI published:2015-11-19 summary:Competing with top human players in the ancient game of Go has been along-term goal of artificial intelligence. Go's high branching factor makestraditional search techniques ineffective, even on leading-edge hardware, andGo's evaluation function could change drastically with one stone change. Recentworks [Maddison et al. (2015); Clark & Storkey (2015)] show that search is notstrictly necessary for machine Go players. A pure pattern-matching approach,based on a Deep Convolutional Neural Network (DCNN) that predicts the nextmove, can perform as well as Monte Carlo Tree Search (MCTS)-based open sourceGo engines such as Pachi [Baudis & Gailly (2012)] if its search budget islimited. We extend this idea in our bot named darkforest, which relies on aDCNN designed for long-term predictions. Darkforest substantially improves thewin rate for pattern-matching approaches against MCTS-based approaches, evenwith looser search budgets. Against human players, the newest versions,darkfores2, achieve a stable 3d level on KGS Go Server as a ranked bot, asubstantial improvement upon the estimated 4k-5k ranks for DCNN reported inClark & Storkey (2015) based on games against other machine players. AddingMCTS to darkfores2 creates a much stronger player named darkfmcts3: with 5000rollouts, it beats Pachi with 10k rollouts in all 250 games; with 75k rolloutsit achieves a stable 5d level in KGS server, on par with state-of-the-art GoAIs (e.g., Zen, DolBaram, CrazyStone) except for AlphaGo [Silver et al.(2016)]; with 110k rollouts, it won the 3rd place in January KGS Go Tournament.
arxiv-14700-140 | Dynamics of Stochastic Gradient Algorithms | http://arxiv.org/pdf/1511.06251v2.pdf | author:Qianxiao Li, Cheng Tai, Weinan E category:cs.LG stat.ML 68W20 published:2015-11-19 summary:Stochastic gradient algorithms (SGA) are increasingly popular in machinelearning applications and have become "the algorithm" for extremely large scaleproblems. Although there are some convergence results, little is known abouttheir dynamics. In this paper, We propose the method of stochastic modifiedequations (SME) to analyze the dynamics of the SGA. Using this technique, wecan give precise characterizations for both the initial convergence speed andthe eventual oscillations, at least in some special cases. Furthermore, the SMEformalism allows us to characterize various speed-up techniques, such asintroducing momentum, adjusting the learning rate and the mini-batch sizes.Previously, these techniques relied mostly on heuristics. Besides introducingsimple examples to illustrate the SME formalism, we also apply the framework toimprove the relaxed randomized Kaczmarz method for solving linear equations.The SME framework is a precise and unifying approach to understanding andimproving the SGA, and has the potential to be applied to many more stochasticalgorithms.
arxiv-14700-141 | Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning | http://arxiv.org/pdf/1511.06342v4.pdf | author:Emilio Parisotto, Jimmy Lei Ba, Ruslan Salakhutdinov category:cs.LG published:2015-11-19 summary:The ability to act in multiple environments and transfer previous knowledgeto new situations can be considered a critical aspect of any intelligent agent.Towards this goal, we define a novel method of multitask and transfer learningthat enables an autonomous agent to learn how to behave in multiple taskssimultaneously, and then generalize its knowledge to new domains. This method,termed "Actor-Mimic", exploits the use of deep reinforcement learning and modelcompression techniques to train a single policy network that learns how to actin a set of distinct tasks by using the guidance of several expert teachers. Wethen show that the representations learnt by the deep policy network arecapable of generalizing to new tasks with no prior expert guidance, speeding uplearning in novel environments. Although our method can in general be appliedto a wide range of problems, we use Atari games as a testing environment todemonstrate these methods.
arxiv-14700-142 | Mediated Experts for Deep Convolutional Networks | http://arxiv.org/pdf/1511.06072v1.pdf | author:Sebastian Agethen, Winston H. Hsu category:cs.LG cs.NE published:2015-11-19 summary:We present a new supervised architecture termed Mediated Mixture-of-Experts(MMoE) that allows us to improve classification accuracy of Deep ConvolutionalNetworks (DCN). Our architecture achieves this with the help of expertnetworks: A network is trained on a disjoint subset of a given dataset and thenrun in parallel to other experts during deployment. A mediator is employed ifexperts contradict each other. This allows our framework to naturally supportincremental learning, as adding new classes requires (re-)training of the newexpert only. We also propose two measures to control computational complexity:An early-stopping mechanism halts experts that have low confidence in theirprediction. The system allows to trade-off accuracy and complexity withoutfurther retraining. We also suggest to share low-level convolutional layersbetween experts in an effort to avoid computation of a near-duplicate featureset. We evaluate our system on a popular dataset and report improved accuracycompared to a single model of same configuration.
arxiv-14700-143 | Density Modeling of Images using a Generalized Normalization Transformation | http://arxiv.org/pdf/1511.06281v4.pdf | author:Johannes Ballé, Valero Laparra, Eero P. Simoncelli category:cs.LG cs.CV published:2015-11-19 summary:We introduce a parametric nonlinear transformation that is well-suited forGaussianizing data from natural images. The data are linearly transformed, andeach component is then normalized by a pooled activity measure, computed byexponentiating a weighted sum of rectified and exponentiated components and aconstant. We optimize the parameters of the full transformation (lineartransform, exponents, weights, constant) over a database of natural images,directly minimizing the negentropy of the responses. The optimizedtransformation substantially Gaussianizes the data, achieving a significantlysmaller mutual information between transformed components than alternativemethods including ICA and radial Gaussianization. The transformation isdifferentiable and can be efficiently inverted, and thus induces a densitymodel on images. We show that samples of this model are visually similar tosamples of natural image patches. We demonstrate the use of the model as aprior probability density that can be used to remove additive noise. Finally,we show that the transformation can be cascaded, with each layer optimizedusing the same Gaussianization objective, thus offering an unsupervised methodof optimizing a deep network architecture.
arxiv-14700-144 | Structured Depth Prediction in Challenging Monocular Video Sequences | http://arxiv.org/pdf/1511.06070v1.pdf | author:Miaomiao Liu, Mathieu Salzmann, Xuming He category:cs.CV published:2015-11-19 summary:In this paper, we tackle the problem of estimating the depth of a scene froma monocular video sequence. In particular, we handle challenging scenarios,such as non-translational camera motion and dynamic scenes, where traditionalstructure from motion and motion stereo methods do not apply. To this end, wefirst study the problem of depth estimation from a single image. In thiscontext, we exploit the availability of a pool of images for which the depth isknown, and formulate monocular depth estimation as a discrete-continuousoptimization problem, where the continuous variables encode the depth of thesuperpixels in the input image, and the discrete ones represent relationshipsbetween neighboring superpixels. The solution to this discrete-continuousoptimization problem is obtained by performing inference in a graphical modelusing particle belief propagation. To handle video sequences, we then extendour single image model to a two-frame one that naturally encodes short-rangetemporal consistency and inherently handles dynamic objects. Based on theprediction of this model, we then introduce a fully-connected pairwise CRF thataccounts for longer range spatio-temporal interactions throughout a video. Wedemonstrate the effectiveness of our model in both the indoor and outdoorscenarios.
arxiv-14700-145 | Transfer Learning for Speech and Language Processing | http://arxiv.org/pdf/1511.06066v1.pdf | author:Dong Wang, Thomas Fang Zheng category:cs.CL cs.LG published:2015-11-19 summary:Transfer learning is a vital technique that generalizes models trained forone setting or task to other settings or tasks. For example in speechrecognition, an acoustic model trained for one language can be used torecognize speech in another language, with little or no re-training data.Transfer learning is closely related to multi-task learning (cross-lingual vs.multilingual), and is traditionally studied in the name of `model adaptation'.Recent advance in deep learning shows that transfer learning becomes mucheasier and more effective with high-level abstract features learned by deepmodels, and the `transfer' can be conducted not only between data distributionsand data types, but also between model structures (e.g., shallow nets and deepnets) or even model types (e.g., Bayesian models and neural models). Thisreview paper summarizes some recent prominent research towards this direction,particularly for speech and language processing. We also report some resultsfrom our group and highlight the potential of this very interesting researchfield.
arxiv-14700-146 | A Novel Approach for Phase Identification in Smart Grids Using Graph Theory and Principal Component Analysis | http://arxiv.org/pdf/1511.06063v1.pdf | author:Satya Jayadev P, Nirav P Bhatt, Ramkrishna Pasumarthy category:cs.LG stat.AP stat.ML published:2015-11-19 summary:In general, low load consumers like households are supplied single-phasepower by connecting their service mains to one of the phases of a distributiontransformer. Here, the distribution companies face the problem of identifyingwhich consumer is connected to which phase and many solutions have evolved inthe past years to address this problem. The exact phase connectivityinformation is important for the efficient operation and control ofdistribution system. We propose a new data driven approach to the problem basedon Graph Theory and Principal Component Analysis (PCA), using energymeasurements in short time intervals, generated from smart meters. We proposean algorithm for the noiseless case and then extend it to noisy case. Thealgorithm will be demonstrated using simulated data for phase connectivities indistribution networks.
arxiv-14700-147 | Reducing Overfitting in Deep Networks by Decorrelating Representations | http://arxiv.org/pdf/1511.06068v3.pdf | author:Michael Cogswell, Faruk Ahmed, Ross Girshick, Larry Zitnick, Dhruv Batra category:cs.LG stat.ML published:2015-11-19 summary:One major challenge in training Deep Neural Networks is preventingoverfitting. Many techniques such as data augmentation and novel regularizerssuch as Dropout have been proposed to prevent overfitting without requiring amassive amount of training data. In this work, we propose a new regularizercalled DeCov which leads to significantly reduced overfitting (as indicated bythe difference between train and val performance), and better generalization.Our regularizer encourages diverse or non-redundant representations in DeepNeural Networks by minimizing the cross-covariance of hidden activations. Thissimple intuition has been explored in a number of past works but surprisinglyhas never been applied as a regularizer in supervised learning. Experimentsacross a range of datasets and network architectures show that this loss alwaysreduces overfitting while almost always maintaining or increasinggeneralization performance and often improving performance over Dropout.
arxiv-14700-148 | What Objective Does Self-paced Learning Indeed Optimize? | http://arxiv.org/pdf/1511.06049v1.pdf | author:Deyu Meng, Qian Zhao category:cs.LG cs.CV published:2015-11-19 summary:Self-paced learning (SPL) has been attracting increasing attention in machinelearning and computer vision. Albeit empirically substantiated to be effective,the investigation on its theoretical insight is still a blank. It is evenunknown that what objective a general SPL regime converges to. To this issue,this study attempts to initially provide some new insights under this"heuristic" learning scheme. Specifically, we prove that the solving strategyon SPL exactly accords with a majorization minimization algorithm, a well knowntechnique in optimization and machine learning, implemented on a latentobjective. A more interesting finding is that, the loss function contained inthis latent objective has a similar configuration with non-convex regularizedpenalty, an attractive topic in statistics and machine learning. In particular,we show that the previous hard and linear self-paced regularizers areequivalent to the capped norm and minimax concave plus penalties, respectively,both being widely investigated in statistics. Such connections between SPL andprevious known researches enhance new insightful comprehension on SPL, likeconvergence and parameter setting rationality. The correctness of the proposedtheory is substantiated by experimental results on synthetic and UCI data sets.
arxiv-14700-149 | Learning Deep Structure-Preserving Image-Text Embeddings | http://arxiv.org/pdf/1511.06078v2.pdf | author:Liwei Wang, Yin Li, Svetlana Lazebnik category:cs.CV cs.CL cs.LG published:2015-11-19 summary:This paper proposes a method for learning joint embeddings of images and textusing a two-branch neural network with multiple layers of linear projectionsfollowed by nonlinearities. The network is trained using a large marginobjective that combines cross-view ranking constraints with within-viewneighborhood structure preservation constraints inspired by metric learningliterature. Extensive experiments show that our approach gains significantimprovements in accuracy for image-to-text and text-to-image retrieval. Ourmethod achieves new state-of-the-art results on the Flickr30K and MSCOCOimage-sentence datasets and shows promise on the new task of phraselocalization on the Flickr30K Entities dataset.
arxiv-14700-150 | Learning to decompose for object detection and instance segmentation | http://arxiv.org/pdf/1511.06449v3.pdf | author:Eunbyung Park, Alexander C. Berg category:cs.CV cs.LG published:2015-11-19 summary:Although deep convolutional neural networks(CNNs) have achieved remarkableresults on object detection and segmentation, pre- and post-processing stepssuch as region proposals and non-maximum suppression(NMS), have been required.These steps result in high computational complexity and sensitivity tohyperparameters, e.g. thresholds for NMS. In this work, we propose a novelend-to-end trainable deep neural network architecture, which consists ofconvolutional and recurrent layers, that generates the correct number of objectinstances and their bounding boxes (or segmentation masks) given an image,using only a single network evaluation without any pre- or post-processingsteps. We have tested on detecting digits in multi-digit images synthesizedusing MNIST, automatically segmenting digits in these images, and detectingcars in the KITTI benchmark dataset. The proposed approach outperforms a strongCNN baseline on the synthesized digits datasets and shows promising results onKITTI car detection.
arxiv-14700-151 | Order Matters: Sequence to sequence for sets | http://arxiv.org/pdf/1511.06391v4.pdf | author:Oriol Vinyals, Samy Bengio, Manjunath Kudlur category:stat.ML cs.CL cs.LG published:2015-11-19 summary:Sequences have become first class citizens in supervised learning thanks tothe resurgence of recurrent neural networks. Many complex tasks that requiremapping from or to a sequence of observations can now be formulated with thesequence-to-sequence (seq2seq) framework which employs the chain rule toefficiently represent the joint probability of sequences. In many cases,however, variable sized inputs and/or outputs might not be naturally expressedas sequences. For instance, it is not clear how to input a set of numbers intoa model where the task is to sort them; similarly, we do not know how toorganize outputs when they correspond to random variables and the task is tomodel their unknown joint probability. In this paper, we first show usingvarious examples that the order in which we organize input and/or output datamatters significantly when learning an underlying model. We then discuss anextension of the seq2seq framework that goes beyond sequences and handles inputsets in a principled way. In addition, we propose a loss which, by searchingover possible orders during training, deals with the lack of structure ofoutput sets. We show empirical evidence of our claims regarding ordering, andon the modifications to the seq2seq framework on benchmark language modelingand parsing tasks, as well as two artificial tasks -- sorting numbers andestimating the joint probability of unknown graphical models.
arxiv-14700-152 | Stochastic gradient method with accelerated stochastic dynamics | http://arxiv.org/pdf/1511.06036v1.pdf | author:Masayuki Ohzeki category:stat.ML cs.CV published:2015-11-19 summary:In this paper, we propose a novel technique to implement stochastic gradientmethods, which are beneficial for learning from large datasets, throughaccelerated stochastic dynamics. A stochastic gradient method is based onmini-batch learning for reducing the computational cost when the amount of datais large. The stochasticity of the gradient can be mitigated by the injectionof Gaussian noise, which yields the stochastic Langevin gradient method; thismethod can be used for Bayesian posterior sampling. However, the performance ofthe stochastic Langevin gradient method depends on the mixing rate of thestochastic dynamics. In this study, we propose violating the detailed balancecondition to enhance the mixing rate. Recent studies have revealed thatviolating the detailed balance condition accelerates the convergence to astationary state and reduces the correlation time between the samplings. Weimplement this violation of the detailed balance condition in the stochasticgradient Langevin method and test our method for a simple model to demonstrateits performance.
arxiv-14700-153 | Neural Programmer-Interpreters | http://arxiv.org/pdf/1511.06279v4.pdf | author:Scott Reed, Nando de Freitas category:cs.LG cs.NE published:2015-11-19 summary:We propose the neural programmer-interpreter (NPI): a recurrent andcompositional neural network that learns to represent and execute programs. NPIhas three learnable components: a task-agnostic recurrent core, a persistentkey-value program memory, and domain-specific encoders that enable a single NPIto operate in multiple perceptually diverse environments with distinctaffordances. By learning to compose lower-level programs to expresshigher-level programs, NPI reduces sample complexity and increasesgeneralization ability compared to sequence-to-sequence LSTMs. The programmemory allows efficient learning of additional tasks by building on existingprograms. NPI can also harness the environment (e.g. a scratch pad withread-write pointers) to cache intermediate results of computation, lesseningthe long-term memory burden on recurrent hidden units. In this work we trainthe NPI with fully-supervised execution traces; each program has examplesequences of calls to the immediate subprograms conditioned on the input.Rather than training on a huge number of relatively weak labels, NPI learnsfrom a small number of rich examples. We demonstrate the capability of ourmodel to learn several types of compositional programs: addition, sorting, andcanonicalizing 3D models. Furthermore, a single NPI learns to execute theseprograms and all 21 associated subprograms.
arxiv-14700-154 | Communicating Semantics: Reference by Description | http://arxiv.org/pdf/1511.06341v4.pdf | author:Ramanathan V Guha, Vineet Gupta category:cs.CL published:2015-11-19 summary:Messages often refer to entities such as people, places and events. Correctidentification of the intended reference is an essential part of communication.Lack of shared unique names often complicates entity reference. Sharedknowledge can be used to construct uniquely identifying descriptive referencesfor entities with ambiguous names. We introduce a mathematical model for`Reference by Description', derive results on the conditions under which, withhigh probability, programs can construct unambiguous references to mostentities in the domain of discourse and provide empirical validation of theseresults.
arxiv-14700-155 | Online Batch Selection for Faster Training of Neural Networks | http://arxiv.org/pdf/1511.06343v4.pdf | author:Ilya Loshchilov, Frank Hutter category:cs.LG cs.NE math.OC published:2015-11-19 summary:Deep neural networks are commonly trained using stochastic non-convexoptimization procedures, which are driven by gradient information estimated onfractions (batches) of the dataset. While it is commonly accepted that batchsize is an important parameter for offline tuning, the benefits of onlineselection of batches remain poorly understood. We investigate online batchselection strategies for two state-of-the-art methods of stochasticgradient-based optimization, AdaDelta and Adam. As the loss function to beminimized for the whole dataset is an aggregation of loss functions ofindividual datapoints, intuitively, datapoints with the greatest loss should beconsidered (selected in a batch) more frequently. However, the limitations ofthis intuition and the proper control of the selection pressure over time areopen questions. We propose a simple strategy where all datapoints are rankedw.r.t. their latest known loss value and the probability to be selected decaysexponentially as a function of rank. Our experimental results on the MNISTdataset suggest that selecting batches speeds up both AdaDelta and Adam by afactor of about 5.
arxiv-14700-156 | FRIST - Flipping and Rotation Invariant Sparsifying Transform Learning and Applications to Inverse Problems | http://arxiv.org/pdf/1511.06359v3.pdf | author:Bihan Wen, Saiprasad Ravishankar, Yoram Bresler category:cs.LG cs.CV published:2015-11-19 summary:Features based on sparse representation, especially using the synthesisdictionary model, have been heavily exploited in signal processing and computervision. However, synthesis dictionary learning typically involves NP-hardsparse coding and expensive learning steps. Recently, sparsifying transformlearning received interest for its cheap computation and its optimal updates inthe alternating algorithms. In this work, we develop a methodology for learningof Flipping and Rotation Invariant Sparsifying Transforms, dubbed FRIST, tobetter represent natural images that contain textures with various geometricaldirections. The proposed alternating learning algorithm involves efficientoptimal updates. We provide a convergence guarantee, and demonstrate theempirical convergence behavior of the proposed FRIST learning algorithm.Preliminary experiments show the usefulness of adaptive sparse representationby FRIST for image sparse representation, segmentation, denoising, robustinpainting, and MRI reconstruction with promising performances.
arxiv-14700-157 | Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks | http://arxiv.org/pdf/1511.06448v3.pdf | author:Pouya Bashivan, Irina Rish, Mohammed Yeasin, Noel Codella category:cs.LG cs.CV published:2015-11-19 summary:One of the challenges in modeling cognitive events from electroencephalogram(EEG) data is finding representations that are invariant to inter- andintra-subject differences, as well as to inherent noise associated with suchdata. Herein, we propose a novel approach for learning such representationsfrom multi-channel EEG time-series, and demonstrate its advantages in thecontext of mental load classification task. First, we transform EEG activitiesinto a sequence of topology-preserving multi-spectral images, as opposed tostandard EEG analysis techniques that ignore such spatial information. Next, wetrain a deep recurrent-convolutional network inspired by state-of-the-art videoclassification to learn robust representations from the sequence of images. Theproposed approach is designed to preserve the spatial, spectral, and temporalstructure of EEG which leads to finding features that are less sensitive tovariations and distortions within each dimension. Empirical evaluation on thecognitive load classification task demonstrated significant improvements inclassification accuracy over current state-of-the-art approaches in this field.
arxiv-14700-158 | SparkNet: Training Deep Networks in Spark | http://arxiv.org/pdf/1511.06051v4.pdf | author:Philipp Moritz, Robert Nishihara, Ion Stoica, Michael I. Jordan category:stat.ML cs.DC cs.LG cs.NE math.OC published:2015-11-19 summary:Training deep networks is a time-consuming process, with networks for objectrecognition often requiring multiple days to train. For this reason, leveragingthe resources of a cluster to speed up training is an important area of work.However, widely-popular batch-processing computational frameworks likeMapReduce and Spark were not designed to support the asynchronous andcommunication-intensive workloads of existing distributed deep learningsystems. We introduce SparkNet, a framework for training deep networks inSpark. Our implementation includes a convenient interface for reading data fromSpark RDDs, a Scala interface to the Caffe deep learning framework, and alightweight multi-dimensional tensor library. Using a simple parallelizationscheme for stochastic gradient descent, SparkNet scales well with the clustersize and tolerates very high-latency communication. Furthermore, it is easy todeploy and use with no parameter tuning, and it is compatible with existingCaffe models. We quantify the dependence of the speedup obtained by SparkNet onthe number of machines, the communication frequency, and the cluster'scommunication overhead, and we benchmark our system's performance on theImageNet dataset.
arxiv-14700-159 | Knowledge Base Population using Semantic Label Propagation | http://arxiv.org/pdf/1511.06219v2.pdf | author:Lucas Sterckx, Thomas Demeester, Johannes Deleu, Chris Develder category:cs.CL cs.LG published:2015-11-19 summary:A crucial aspect of a knowledge base population system that extracts newfacts from text corpora, is the generation of training data for its relationextractors. In this paper, we present a method that maximizes the effectivenessof newly trained relation extractors at a minimal annotation cost. Manuallabeling can be significantly reduced by Distant Supervision, which is a methodto construct training data automatically by aligning a large text corpus withan existing knowledge base of known facts. For example, all sentencesmentioning both 'Barack Obama' and 'US' may serve as positive traininginstances for the relation born_in(subject,object). However, distantsupervision typically results in a highly noisy training set: many trainingsentences do not really express the intended relation. We propose to combinedistant supervision with minimal manual supervision in a technique calledfeature labeling, to eliminate noise from the large and noisy initial trainingset, resulting in a significant increase of precision. We further improve onthis approach by introducing the Semantic Label Propagation method, which usesthe similarity between low-dimensional representations of candidate traininginstances, to extend the training set in order to increase recall whilemaintaining high precision. Our proposed strategy for generating training datais studied and evaluated on an established test collection designed forknowledge base population tasks. The experimental results show that theSemantic Label Propagation strategy leads to substantial performance gains whencompared to existing approaches, while requiring an almost negligible manualannotation effort.
arxiv-14700-160 | Compressing Word Embeddings | http://arxiv.org/pdf/1511.06397v2.pdf | author:Martin Andrews category:cs.CL cs.LG published:2015-11-19 summary:Recent methods for learning vector space representations of words havesucceeded in capturing fine-grained semantic and syntactic regularities usingvector arithmetic. However, these vector space representations (created throughlarge-scale text analysis) are typically stored verbatim, since their internalstructure is opaque. Using word-analogy tests to monitor the level of detailstored in compressed re-representations of the same vector space, thetrade-offs between the reduction in memory usage and expressiveness areinvestigated. A simple scheme is outlined that can reduce the memory footprintof a state-of-the-art embedding by a factor of 10, with only minimal impact onperformance. Then, using the same `bit budget', a binary (approximate)factorisation of the same space is also explored, with the aim of creating anequivalent representation with better interpretability.
arxiv-14700-161 | What Players do with the Ball: A Physically Constrained Interaction Modeling | http://arxiv.org/pdf/1511.06181v2.pdf | author:Andrii Maksai, Xinchao Wang, Pascal Fua category:cs.CV published:2015-11-19 summary:Tracking the ball is critical for video-based analysis of team sports.However, it is difficult, especially in low-resolution images, due to the smallsize of the ball, its speed that creates motion blur, and its often beingoccluded by players. In this paper, we propose a generic and principledapproach to modeling the interaction between the ball and the players whilealso imposing appropriate physical constraints on the ball's trajectory. Weshow that our approach, formulated in terms of a Mixed Integer Program, is morerobust and more accurate than several state-of-the-art approaches on real-lifevolleyball, basketball, and soccer sequences.
arxiv-14700-162 | A convnet for non-maximum suppression | http://arxiv.org/pdf/1511.06437v3.pdf | author:Jan Hosang, Rodrigo Benenson, Bernt Schiele category:cs.CV cs.LG published:2015-11-19 summary:Non-maximum suppression (NMS) is used in virtually all state-of-the-artobject detection pipelines. While essential object detection ingredients suchas features, classifiers, and proposal methods have been extensively researchedsurprisingly little work has aimed to systematically address NMS. The de-factostandard for NMS is based on greedy clustering with a fixed distance threshold,which forces to trade-off recall versus precision. We propose a convnetdesigned to perform NMS of a given set of detections. We report experiments ona synthetic setup, and results on crowded pedestrian detection scenes. Ourapproach overcomes the intrinsic limitations of greedy NMS, obtaining betterrecall and precision.
arxiv-14700-163 | Multimodal sparse representation learning and applications | http://arxiv.org/pdf/1511.06238v3.pdf | author:Miriam Cha, Youngjune Gwon, H. T. Kung category:cs.LG cs.CV stat.ML published:2015-11-19 summary:Unsupervised methods have proven effective for discriminative tasks in asingle-modality scenario. In this paper, we present a multimodal framework forlearning sparse representations that can capture semantic correlation betweenmodalities. The framework can model relationships at a higher level by forcingthe shared sparse representation. In particular, we propose the use of jointdictionary learning technique for sparse coding and formulate the jointrepresentation for concision, cross-modal representations (in case of a missingmodality), and union of the cross-modal representations. Given the acceleratedgrowth of multimodal data posted on the Web such as YouTube, Wikipedia, andTwitter, learning good multimodal features is becoming increasingly important.We show that the shared representations enabled by our framework substantiallyimprove the classification performance under both unimodal and multimodalsettings. We further show how deep architectures built on the proposedframework are effective for the case of highly nonlinear correlations betweenmodalities. The effectiveness of our approach is demonstrated experimentally inimage denoising, multimedia event detection and retrieval on the TRECVIDdataset (audio-video), category classification on the Wikipedia dataset(image-text), and sentiment classification on PhotoTweet (image-text).
arxiv-14700-164 | Policy Distillation | http://arxiv.org/pdf/1511.06295v2.pdf | author:Andrei A. Rusu, Sergio Gomez Colmenarejo, Caglar Gulcehre, Guillaume Desjardins, James Kirkpatrick, Razvan Pascanu, Volodymyr Mnih, Koray Kavukcuoglu, Raia Hadsell category:cs.LG published:2015-11-19 summary:Policies for complex visual tasks have been successfully learned with deepreinforcement learning, using an approach called deep Q-networks (DQN), butrelatively large (task-specific) networks and extensive training are needed toachieve good performance. In this work, we present a novel method called policydistillation that can be used to extract the policy of a reinforcement learningagent and train a new network that performs at the expert level while beingdramatically smaller and more efficient. Furthermore, the same method can beused to consolidate multiple task-specific policies into a single policy. Wedemonstrate these claims using the Atari domain and show that the multi-taskdistilled agent outperforms the single-task teachers as well as ajointly-trained DQN agent.
arxiv-14700-165 | Spatio-temporal video autoencoder with differentiable memory | http://arxiv.org/pdf/1511.06309v2.pdf | author:Viorica Patraucean, Ankur Handa, Roberto Cipolla category:cs.LG cs.CV published:2015-11-19 summary:We describe a new spatio-temporal video autoencoder, based on a classicspatial image autoencoder and a novel nested temporal autoencoder. The temporalencoder is represented by a differentiable visual memory composed ofconvolutional long short-term memory (LSTM) cells that integrate changes overtime. Here we target motion changes and use as temporal decoder a robustoptical flow prediction module together with an image sampler serving asbuilt-in feedback loop. The architecture is end-to-end differentiable. At eachtime step, the system receives as input a video frame, predicts the opticalflow based on the current observation and the LSTM memory state as a densetransformation map, and applies it to the current frame to generate the nextframe. By minimising the reconstruction error between the predicted next frameand the corresponding ground truth next frame, we train the whole system toextract features useful for motion estimation without any supervision effort.We believe these features can in turn facilitate learning high-level tasks suchas path planning, semantic segmentation, or action recognition, reducing theoverall supervision effort.
arxiv-14700-166 | Blending LSTMs into CNNs | http://arxiv.org/pdf/1511.06433v2.pdf | author:Krzysztof J. Geras, Abdel-rahman Mohamed, Rich Caruana, Gregor Urban, Shengjie Wang, Ozlem Aslan, Matthai Philipose, Matthew Richardson, Charles Sutton category:cs.LG published:2015-11-19 summary:We consider whether deep convolutional networks (CNNs) can represent decisionfunctions with similar accuracy as recurrent networks such as LSTMs. First, weshow that a deep CNN with an architecture inspired by the models recentlyintroduced in image recognition can yield better accuracy than previousconvolutional and LSTM networks on the standard 309h Switchboard automaticspeech recognition task. Then we show that even more accurate CNNs can betrained under the guidance of LSTMs using a variant of model compression, whichwe call model blending because the teacher and student models are similar incomplexity but different in inductive bias. Blending further improves theaccuracy of our CNN, yielding a computationally efficient model of accuracyhigher than any of the other individual models. Examining the effect of "darkknowledge" in this model compression task, we find that less than 1% of thehighest probability labels are needed for accurate model compression.
arxiv-14700-167 | Efficient Sum of Sparse Outer Products Dictionary Learning (SOUP-DIL) | http://arxiv.org/pdf/1511.06333v3.pdf | author:Saiprasad Ravishankar, Raj Rao Nadakuditi, Jeffrey A. Fessler category:cs.LG published:2015-11-19 summary:The sparsity of natural signals in a transform domain or dictionary has beenextensively exploited in several applications. More recently, the data-drivenadaptation of synthesis dictionaries has shown promise in many applicationscompared to fixed or analytical dictionaries. However, dictionary learningproblems are typically non-convex and NP-hard, and the usual alternatingminimization approaches for these problems are often computationally expensive,with the computations dominated by the NP-hard synthesis sparse coding step. Inthis work, we investigate an efficient method for $\ell_{0}$ "norm"-baseddictionary learning by first approximating the training data set with a sum ofsparse rank-one matrices and then using a block coordinate descent approach toestimate the rank-one terms. The proposed algorithm involves efficientclosed-form solutions. In particular, the sparse coding step involves a simpleform of thresholding. We provide a convergence analysis for the proposed blockcoordinate descent method. Our experiments show the promising performance andsignificant speed-ups provided by our method over the classical K-SVD scheme insparse signal representation and image denoising.
arxiv-14700-168 | Putting Things in Context: Community-specific Embedding Projections for Sentiment Analysis | http://arxiv.org/pdf/1511.06052v2.pdf | author:Yi Yang, Jacob Eisenstein category:cs.CL cs.AI cs.SI published:2015-11-19 summary:Variation in language is ubiquitous, and is particularly evident in newerforms of writing such as social media. Fortunately, variation is not random,but is usually linked to social factors. By exploiting linguistic homophily ---the tendency of socially linked individuals to use language similarly --- it ispossible to build models that are more robust to variation. In this paper, wefocus on social network communities, which make it possible to generalizesociolinguistic properties from authors in the training set to authors in thetest sets, without requiring demographic author metadata. We detect communitiesvia standard graph clustering algorithms, and then exploit these communities bylearning community-specific projections of word embeddings. These projectionscapture shifts in word meaning in different social groups; by modeling them, weare able to improve the overall accuracy of Twitter sentiment analysis by asignificant margin over competitive prior work.
arxiv-14700-169 | Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks | http://arxiv.org/pdf/1511.06434v2.pdf | author:Alec Radford, Luke Metz, Soumith Chintala category:cs.LG cs.CV published:2015-11-19 summary:In recent years, supervised learning with convolutional networks (CNNs) hasseen huge adoption in computer vision applications. Comparatively, unsupervisedlearning with CNNs has received less attention. In this work we hope to helpbridge the gap between the success of CNNs for supervised learning andunsupervised learning. We introduce a class of CNNs called deep convolutionalgenerative adversarial networks (DCGANs), that have certain architecturalconstraints, and demonstrate that they are a strong candidate for unsupervisedlearning. Training on various image datasets, we show convincing evidence thatour deep convolutional adversarial pair learns a hierarchy of representationsfrom object parts to scenes in both the generator and discriminator.Additionally, we use the learned features for novel tasks - demonstrating theirapplicability as general image representations.
arxiv-14700-170 | An Information Retrieval Approach to Finding Dependent Subspaces of Multiple Views | http://arxiv.org/pdf/1511.06423v2.pdf | author:Ziyuan Lin, Jaakko Peltonen category:stat.ML cs.LG published:2015-11-19 summary:Finding relationships between multiple views of data is essential both forexploratory analysis and as pre-processing for predictive tasks. A prominentapproach is to apply variants of Canonical Correlation Analysis (CCA), aclassical method seeking correlated components between views. The basic CCA isrestricted to maximizing a simple dependency criterion, correlation, measureddirectly between data coordinates. We introduce a new method that findsdependent subspaces of views directly optimized for the data analysis task of\textit{neighbor retrieval between multiple views}. We optimize mappings foreach view such as linear transformations to maximize cross-view similaritybetween neighborhoods of data samples. The criterion arises directly from thewell-defined retrieval task, detects nonlinear and local similarities, is ableto measure dependency of data relationships rather than only individual datacoordinates, and is related to well understood measures of informationretrieval quality. In experiments we show the proposed method outperformsalternatives in preserving cross-view neighborhood similarities, and yieldsinsights into local dependencies between multiple views.
arxiv-14700-171 | Conditional Computation in Neural Networks for faster models | http://arxiv.org/pdf/1511.06297v2.pdf | author:Emmanuel Bengio, Pierre-Luc Bacon, Joelle Pineau, Doina Precup category:cs.LG published:2015-11-19 summary:Deep learning has become the state-of-art tool in many applications, but theevaluation and training of deep models can be time-consuming andcomputationally expensive. The conditional computation approach has beenproposed to tackle this problem (Bengio et al., 2013; Davis & Arel, 2013). Itoperates by selectively activating only parts of the network at a time. In thispaper, we use reinforcement learning as a tool to optimize conditionalcomputation policies. More specifically, we cast the problem of learningactivation-dependent policies for dropping out blocks of units as areinforcement learning problem. We propose a learning scheme motivated bycomputation speed, capturing the idea of wanting to have parsimoniousactivations while maintaining prediction accuracy. We apply a policy gradientalgorithm for learning policies that optimize this loss function and propose aregularization mechanism that encourages diversification of the dropout policy.We present encouraging empirical results showing that this approach improvesthe speed of computation without impacting the quality of the approximation.
arxiv-14700-172 | Generating Sentences from a Continuous Space | http://arxiv.org/pdf/1511.06349v4.pdf | author:Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew M. Dai, Rafal Jozefowicz, Samy Bengio category:cs.LG cs.CL published:2015-11-19 summary:The standard recurrent neural network language model (RNNLM) generatessentences one word at a time and does not work from an explicit global sentencerepresentation. In this work, we introduce and study an RNN-based variationalautoencoder generative model that incorporates distributed latentrepresentations of entire sentences. This factorization allows it to explicitlymodel holistic properties of sentences such as style, topic, and high-levelsyntactic features. Samples from the prior over these sentence representationsremarkably produce diverse and well-formed sentences through simpledeterministic decoding. By examining paths through this latent space, we areable to generate coherent novel sentences that interpolate between knownsentences. We present techniques for solving the difficult learning problempresented by this model, demonstrate its effectiveness in imputing missingwords, explore many interesting properties of the model's latent sentencespace, and present negative results on the use of the model in languagemodeling.
arxiv-14700-173 | Fixed Point Quantization of Deep Convolutional Networks | http://arxiv.org/pdf/1511.06393v2.pdf | author:Darryl D. Lin, Sachin S. Talathi, V. Sreekanth Annapureddy category:cs.LG published:2015-11-19 summary:In recent years increasingly complex architectures for deep convolutionnetworks (DCNs) have been proposed to boost the performance on imagerecognition tasks. However, the gains in performance have come at a cost ofsubstantial increase in compute resources, the model size and processing speedof the network for training and evaluation. Fixed point implementation of thesenetworks has the potential to alleviate some of the burden of these additionalcomplexities. In this paper, we propose a quantizer design for fixed pointimplementation for DCNs. We then formulate an optimization problem to identifyoptimal fixed point bit-width allocation across DCN layers. We performexperiments on a recently proposed DCN architecture for CIFAR-10 benchmark thatgenerates test error of less than 7%. We evaluate the effectiveness of ourproposed fixed point bit-width allocation for this DCN. Our experiments showthat in comparison to equal bit-width settings, the fixed point DCNs withoptimized bit width allocation offer >20% reduction in the model size withoutany loss in performance. We also demonstrate that fine tuning can furtherenhance the accuracy of fixed point DCNs beyond that of the original floatingpoint model. In doing so, we report a new state-of-the-art fixed pointperformance of 6.78% error-rate on CIFAR-10 benchmark.
arxiv-14700-174 | Principled Parallel Mean-Field Inference for Discrete Random Fields | http://arxiv.org/pdf/1511.06103v2.pdf | author:Pierre Baqué, Timur Bagautdinov, François Fleuret, Pascal Fua category:cs.CV cs.LG published:2015-11-19 summary:Mean-field variational inference is one of the most popular approaches toinference in discrete random fields. Standard mean-field optimization is basedon coordinate descent and in many situations can be impractical. Thus, inpractice, various parallel techniques are used, which either rely on ad-hocsmoothing with heuristically set parameters, or put strong constraints on thetype of models. In this paper, we propose a novel proximal gradient-basedapproach to optimizing the variational objective. It is naturallyparallelizable and easy to implement. We prove its convergence, and thendemonstrate that, in practice, it yields faster convergence and often findsbetter optima than more traditional mean-field optimization techniques.Moreover, our method is less sensitive to the choice of parameters.
arxiv-14700-175 | Binding via Reconstruction Clustering | http://arxiv.org/pdf/1511.06418v4.pdf | author:Klaus Greff, Rupesh Kumar Srivastava, Jürgen Schmidhuber category:cs.LG cs.NE published:2015-11-19 summary:Disentangled distributed representations of data are desirable for machinelearning, since they are more expressive and can generalize from fewerexamples. However, for complex data, the distributed representations ofmultiple objects present in the same input can interfere and lead toambiguities, which is commonly referred to as the binding problem. We argue forthe importance of the binding problem to the field of representation learning,and develop a probabilistic framework that explicitly models inputs as acomposition of multiple objects. We propose an unsupervised algorithm that usesdenoising autoencoders to dynamically bind features together in multi-objectinputs through an Expectation-Maximization-like clustering process. Theeffectiveness of this method is demonstrated on artificially generated datasetsof binary images, showing that it can even generalize to bind together newobjects never seen by the autoencoder during training.
arxiv-14700-176 | Structured Prediction Energy Networks | http://arxiv.org/pdf/1511.06350v2.pdf | author:David Belanger, Andrew McCallum category:cs.LG published:2015-11-19 summary:We introduce structured prediction energy networks (SPENs), a flexibleframework for structured prediction. A deep architecture is used to define anenergy function of candidate labels, and then predictions are produced by usingback-propagation to iteratively optimize the energy with respect to the labels.This deep architecture captures dependencies between labels that would lead tointractable graphical models, and performs structure learning by automaticallylearning discriminative features of the structured output. One naturalapplication of our technique is multi-label classification, which traditionallyhas required strict prior assumptions about the interactions between labels toensure tractable learning and prediction problems. We are able to apply SPENsto multi-label problems with substantially larger label sets than previousapplications of structured prediction, while modeling high-order interactionsusing minimal structural assumptions. Overall, deep learning providesremarkable tools for learning features of the inputs to a prediction problem,and this work extends these techniques to learning features of structuredoutputs. Our experiments provide impressive performance on a variety ofbenchmark multi-label classification tasks, demonstrate that our technique canbe used to provide interpretable structure learning, and illuminate fundamentaltrade-offs between feed-forward and iterative structured prediction techniques.
arxiv-14700-177 | Recurrent Models for Auditory Attention in Multi-Microphone Distance Speech Recognition | http://arxiv.org/pdf/1511.06407v2.pdf | author:Suyoun Kim, Ian Lane category:cs.LG cs.CL published:2015-11-19 summary:Integration of multiple microphone data is one of the key ways to achieverobust speech recognition in noisy environments or when the speaker is locatedat some distance from the input device. Signal processing techniques such asbeamforming are widely used to extract a speech signal of interest frombackground noise. These techniques, however, are highly dependent on priorspatial information about the microphones and the environment in which thesystem is being used. In this work, we present a neural attention network thatdirectly combines multi-channel audio to generate phonetic states withoutrequiring any prior knowledge of the microphone layout or any explicit signalpreprocessing for speech enhancement. We embed an attention mechanism within aRecurrent Neural Network (RNN) based acoustic model to automatically tune itsattention to a more reliable input source. Unlike traditional multi-channelpreprocessing, our system can be optimized towards the desired output in onestep. Although attention-based models have recently achieved impressive resultson sequence-to-sequence learning, no attention mechanisms have previously beenapplied to learn potentially asynchronous and non-stationary multiple inputs.We evaluate our neural attention model on the CHiME-3 challenge task, and showthat the model achieves comparable performance to beamforming using a purelydata-driven method.
arxiv-14700-178 | Alternative structures for character-level RNNs | http://arxiv.org/pdf/1511.06303v2.pdf | author:Piotr Bojanowski, Armand Joulin, Tomas Mikolov category:cs.LG cs.CL published:2015-11-19 summary:Recurrent neural networks are convenient and efficient models for languagemodeling. However, when applied on the level of characters instead of words,they suffer from several problems. In order to successfully model long-termdependencies, the hidden representation needs to be large. This in turn implieshigher computational costs, which can become prohibitive in practice. Wepropose two alternative structural modifications to the classical RNN model.The first one consists on conditioning the character level representation onthe previous word representation. The other one uses the character history tocondition the output probability. We evaluate the performance of the twoproposed modifications on challenging, multi-lingual real world data.
arxiv-14700-179 | Manifold Regularized Discriminative Neural Networks | http://arxiv.org/pdf/1511.06328v3.pdf | author:Shuangfei Zhai, Zhongfei Zhang category:cs.LG published:2015-11-19 summary:Unregularized deep neural networks (DNNs) can be easily overfit with alimited sample size. We argue that this is mostly due to the disriminativenature of DNNs which directly model the conditional probability (or score) oflabels given the input. The ignorance of input distribution makes DNNsdifficult to generalize to unseen data. Recent advances in regularizationtechniques, such as pretraining and dropout, indicate that modeling input datadistribution (either explicitly or implicitly) greatly improves thegeneralization ability of a DNN. In this work, we explore the manifoldhypothesis which assumes that instances within the same class lie in a smoothmanifold. We accordingly propose two simple regularizers to a standarddiscriminative DNN. The first one, named Label-Aware Manifold Regularization,assumes the availability of labels and penalizes large norms of the lossfunction w.r.t. data points. The second one, named Label-Independent ManifoldRegularization, does not use label information and instead penalizes theFrobenius norm of the Jacobian matrix of prediction scores w.r.t. data points,which makes semi-supervised learning possible. We perform extensive controlexperiments on fully supervised and semi-supervised tasks using the MNIST,CIFAR10 and SVHN datasets and achieve excellent results.
arxiv-14700-180 | Reasoning in Vector Space: An Exploratory Study of Question Answering | http://arxiv.org/pdf/1511.06426v4.pdf | author:Moontae Lee, Xiaodong He, Wen-tau Yih, Jianfeng Gao, Li Deng, Paul Smolensky category:cs.CL published:2015-11-19 summary:Question answering tasks have shown remarkable progress with distributedvector representation. In this paper, we investigate the recently proposedFacebook bAbI tasks which consist of twenty different categories of questionsthat require complex reasoning. Because the previous work on bAbI are allend-to-end models, errors could come from either an imperfect understanding ofsemantics or in certain steps of the reasoning. For clearer analysis, wepropose two vector space models inspired by Tensor Product Representation (TPR)to perform knowledge encoding and logical reasoning based on common-senseinference. They together achieve near-perfect accuracy on all categoriesincluding positional reasoning and path finding that have proved difficult formost of the previous approaches. We hypothesize that the difficulties in thesecategories are due to the multi-relations in contrast to uni-relationalcharacteristic of other categories. Our exploration sheds light on designingmore sophisticated dataset and moving one step toward integrating transparentand interpretable formalism of TPR into existing learning paradigms.
arxiv-14700-181 | Deconstructing the Ladder Network Architecture | http://arxiv.org/pdf/1511.06430v3.pdf | author:Mohammad Pezeshki, Linxi Fan, Philemon Brakel, Aaron Courville, Yoshua Bengio category:cs.LG published:2015-11-19 summary:The Manual labeling of data is and will remain a costly endeavor. For thisreason, semi-supervised learning remains a topic of practical importance. Therecently proposed Ladder Network is one such approach that has proven to bevery successful. In addition to the supervised objective, the Ladder Networkalso adds an unsupervised objective corresponding to the reconstruction costsof a stack of denoising autoencoders. Although the empirical results areimpressive, the Ladder Network has many components intertwined, whosecontributions are not obvious in such a complex architecture. In order to helpelucidate and disentangle the different ingredients in the Ladder Networkrecipe, this paper presents an extensive experimental investigation of variantsof the Ladder Network in which we replace or remove individual components togain more insight into their relative importance. We find that all of thecomponents are necessary for achieving optimal performance, but they do notcontribute equally. For semi-supervised tasks, we conclude that the mostimportant contribution is made by the lateral connection, followed by theapplication of noise, and finally the choice of what we refer to as the`combinator function' in the decoder path. We also find that as the number oflabeled training examples increases, the lateral connections and reconstructioncriterion become less important, with most of the improvement in generalizationbeing due to the injection of noise in each layer. Furthermore, we present anew type of combinator function that outperforms the original design in bothfully- and semi-supervised tasks, reducing record test error rates onPermutation-Invariant MNIST to 0.57% for the supervised setting, and to 0.97%and 1.0% for semi-supervised settings with 1000 and 100 labeled examplesrespectively.
arxiv-14700-182 | Deep Manifold Traversal: Changing Labels with Convolutional Features | http://arxiv.org/pdf/1511.06421v3.pdf | author:Jacob R. Gardner, Paul Upchurch, Matt J. Kusner, Yixuan Li, Kilian Q. Weinberger, Kavita Bala, John E. Hopcroft category:cs.LG cs.CV stat.ML published:2015-11-19 summary:Many tasks in computer vision can be cast as a "label changing" problem,where the goal is to make a semantic change to the appearance of an image orsome subject in an image in order to alter the class membership. Althoughsuccessful task-specific methods have been developed for some label changingapplications, to date no general purpose method exists. Motivated by this wepropose deep manifold traversal, a method that addresses the problem in itsmost general form: it first approximates the manifold of natural images thenmorphs a test image along a traversal path away from a source class and towardsa target class while staying near the manifold throughout. The resultingalgorithm is surprisingly effective and versatile. It is completely datadriven, requiring only an example set of images from the desired source andtarget domains. We demonstrate deep manifold traversal on highly diverse labelchanging tasks: changing an individual's appearance (age and hair color),changing the season of an outdoor image, and transforming a city skylinetowards nighttime.
arxiv-14700-183 | Towards Principled Unsupervised Learning | http://arxiv.org/pdf/1511.06440v2.pdf | author:Ilya Sutskever, Rafal Jozefowicz, Karol Gregor, Danilo Rezende, Tim Lillicrap, Oriol Vinyals category:cs.LG published:2015-11-19 summary:General unsupervised learning is a long-standing conceptual problem inmachine learning. Supervised learning is successful because it can be solved bythe minimization of the training error cost function. Unsupervised learning isnot as successful, because the unsupervised objective may be unrelated to thesupervised task of interest. For an example, density modelling andreconstruction have often been used for unsupervised learning, but they did notproduced the sought-after performance gains, because they have no knowledge ofthe supervised tasks. In this paper, we present an unsupervised cost function which we name theOutput Distribution Matching (ODM) cost, which measures a divergence betweenthe distribution of predictions and distributions of labels. The ODM cost isappealing because it is consistent with the supervised cost in the followingsense: a perfect supervised classifier is also perfect according to the ODMcost. Therefore, by aggressively optimizing the ODM cost, we are almostguaranteed to improve our supervised performance whenever the space of possiblepredictions is exponentially large. We demonstrate that the ODM cost works well on number of small andsemi-artificial datasets using no (or almost no) labelled training cases.Finally, we show that the ODM cost can be used for one-shot domain adaptation,which allows the model to classify inputs that differ from the inputdistribution in significant ways without the need for prior exposure to the newdomain.
arxiv-14700-184 | Variable Rate Image Compression with Recurrent Neural Networks | http://arxiv.org/pdf/1511.06085v5.pdf | author:George Toderici, Sean M. O'Malley, Sung Jin Hwang, Damien Vincent, David Minnen, Shumeet Baluja, Michele Covell, Rahul Sukthankar category:cs.CV cs.LG cs.NE published:2015-11-19 summary:A large fraction of Internet traffic is now driven by requests from mobiledevices with relatively small screens and often stringent bandwidthrequirements. Due to these factors, it has become the norm for moderngraphics-heavy websites to transmit low-resolution, low-bytecount imagepreviews (thumbnails) as part of the initial page load process to improveapparent page responsiveness. Increasing thumbnail compression beyond thecapabilities of existing codecs is therefore a current research focus, as anybyte savings will significantly enhance the experience of mobile device users.Toward this end, we propose a general framework for variable-rate imagecompression and a novel architecture based on convolutional and deconvolutionalLSTM recurrent networks. Our models address the main issues that have preventedautoencoder neural networks from competing with existing image compressionalgorithms: (1) our networks only need to be trained once (not per-image),regardless of input image dimensions and the desired compression rate; (2) ournetworks are progressive, meaning that the more bits are sent, the moreaccurate the image reconstruction; and (3) the proposed architecture is atleast as efficient as a standard purpose-trained autoencoder for a given numberof bits. On a large-scale benchmark of 32$\times$32 thumbnails, our LSTM-basedapproaches provide better visual quality than (headerless) JPEG, JPEG2000 andWebP, with a storage size that is reduced by 10% or more.
arxiv-14700-185 | Learning to Generate Images with Perceptual Similarity Metrics | http://arxiv.org/pdf/1511.06409v2.pdf | author:Karl Ridgeway, Jake Snell, Brett D. Roads, Richard S. Zemel, Michael C. Mozer category:cs.LG cs.CV published:2015-11-19 summary:Deep networks are increasingly being applied to problems involving imagesynthesis, e.g., generating images from textual descriptions and reconstructingan input image from a compact representation. Supervised training ofimage-synthesis networks typically uses a pixel-wise loss (PL) to indicate themismatch between a generated image and its corresponding target image. Wepropose instead to use a loss function that is better calibrated to humanperceptual judgments of image quality: the multiscale structural-similarityscore (MS-SSIM). Because MS-SSIM is differentiable, it is easily incorporatedinto gradient-descent learning. We compare the consequences of using MS-SSIMversus PL loss on training deterministic and stochastic autoencoders. For threedifferent architectures, we collected human judgments of the quality of imagereconstructions. Observers reliably prefer images synthesized byMS-SSIM-optimized models over those synthesized by PL-optimized models, for twodistinct PL measures ($\ell_1$ and $\ell_2$ distances). We also explore theeffect of training objective on image encoding and analyze conditions underwhich perceptually-optimized representations yield better performance on imageclassification. Just as computer vision has advanced through the use ofconvolutional architectures that mimic the structure of the mammalian visualsystem, we argue that significant additional advances can be made in modelingimages through the use of training objectives that are well aligned tocharacteristics of human perception.
arxiv-14700-186 | Universality in halting time and its applications in optimization | http://arxiv.org/pdf/1511.06444v2.pdf | author:Levent Sagun, Thomas Trogdon, Yann LeCun category:cs.LG math.NA math.PR published:2015-11-19 summary:The authors present empirical universal distributions for the halting time(measured by the number of iterations to reach a given accuracy) ofoptimization algorithms applied to two random systems: spin glasses and deeplearning. Given an algorithm, which we take to be both the optimization routineand the form of the random landscape, the fluctuations of the halting timefollow a distribution that remains unchanged even when the input is changeddrastically. We observe two main universality classes, a Gumbel-likedistribution that appears in Google searches, human decision times, QRfactorization and spin glasses, and a Gaussian-like distribution that appearsin conjugate gradient method, deep network with MNIST input data and deepnetwork with random input data.
arxiv-14700-187 | Robust Convolutional Neural Networks under Adversarial Noise | http://arxiv.org/pdf/1511.06306v2.pdf | author:Jonghoon Jin, Aysegul Dundar, Eugenio Culurciello category:cs.LG cs.CV published:2015-11-19 summary:Recent studies have shown that Convolutional Neural Networks (CNNs) arevulnerable to a small perturbation of input called "adversarial examples". Inthis work, we propose a new feedforward CNN that improves robustness in thepresence of adversarial noise. Our model uses stochastic additive noise addedto the input image and to the CNN models. The proposed model operates inconjunction with a CNN trained with either standard or adversarial objectivefunction. In particular, convolution, max-pooling, and ReLU layers are modifiedto benefit from the noise model. Our feedforward model is parameterized by onlya mean and variance per pixel which simplifies computations and makes ourmethod scalable to a deep architecture. From CIFAR-10 and ImageNet test, theproposed model outperforms other methods and the improvement is more evidentfor difficult classification tasks or stronger adversarial noise.
arxiv-14700-188 | Efficient inference in occlusion-aware generative models of images | http://arxiv.org/pdf/1511.06362v2.pdf | author:Jonathan Huang, Kevin Murphy category:cs.LG cs.CV published:2015-11-19 summary:We present a generative model of images based on layering, in which imagelayers are individually generated, then composited from front to back. We arethus able to factor the appearance of an image into the appearance ofindividual objects within the image --- and additionally for each individualobject, we can factor content from pose. Unlike prior work on layered models,we learn a shape prior for each object/layer, allowing the model to tease outwhich object is in front by looking for a consistent shape, without needingaccess to motion cues or any labeled data. We show that ordinary stochasticgradient variational bayes (SGVB), which optimizes our fully differentiablelower-bound on the log-likelihood, is sufficient to learn an interpretablerepresentation of images. Finally we present experiments demonstrating theeffectiveness of the model for inferring foreground and background objects inimages.
arxiv-14700-189 | Compact Bilinear Pooling | http://arxiv.org/pdf/1511.06062v2.pdf | author:Yang Gao, Oscar Beijbom, Ning Zhang, Trevor Darrell category:cs.CV published:2015-11-19 summary:Bilinear models has been shown to achieve impressive performance on a widerange of visual tasks, such as semantic segmentation, fine grained recognitionand face recognition. However, bilinear features are high dimensional,typically on the order of hundreds of thousands to a few million, which makesthem impractical for subsequent analysis. We propose two compact bilinearrepresentations with the same discriminative power as the full bilinearrepresentation but with only a few thousand dimensions. Our compactrepresentations allow back-propagation of classification errors enabling anend-to-end optimization of the visual recognition system. The compact bilinearrepresentations are derived through a novel kernelized analysis of bilinearpooling which provide insights into the discriminative power of bilinearpooling, and a platform for further research in compact pooling methods.Experimentation illustrate the utility of the proposed representations forimage classification and few-shot learning across several datasets.
arxiv-14700-190 | Quantitative Analysis of Particles Segregation | http://arxiv.org/pdf/1511.06106v2.pdf | author:Ting Peng, Aiping Qu, Xiaoling Wang category:cs.CV published:2015-11-19 summary:Segregation is a popular phenomenon. It has considerable effects on materialperformance. To the author's knowledge, there is still no automated objectivequantitative indicator for segregation. In order to full fill this task,segregation of particles is analyzed. Edges of the particles are extracted fromthe digital picture. Then, the whole picture of particles is splintered tosmall rectangles with the same shape. Statistical index of the edges in eachrectangle is calculated. Accordingly, segregation between the indexescorresponding to the rectangles is evaluated. The results show coincident withsubjective evaluated results. Further more, it can be implemented as anautomated system, which would facilitate the materials quality controlmechanism during production process.
arxiv-14700-191 | Feature-based Attention in Convolutional Neural Networks | http://arxiv.org/pdf/1511.06408v2.pdf | author:Grace W. Lindsay category:cs.CV published:2015-11-19 summary:Convolutional neural networks (CNNs) have proven effective for imageprocessing tasks, such as object recognition and classification. Recently, CNNshave been enhanced with concepts of attention, similar to those found inbiology. Much of this work on attention has focused on effective serial spatialprocessing. In this paper, I introduce a simple procedure for applyingfeature-based attention (FBA) to CNNs and compare multiple implementationoptions. FBA is a top-down signal applied globally to an input image whichaides in detecting chosen objects in cluttered or noisy settings. The conceptof FBA and the implementation details tested here were derived from what isknown (and debated) about biological object- and feature-based attention. Theimplementations of FBA described here increase performance on challengingobject detection tasks using a procedure that is simple, fast, and does notrequire additional iterative training. Furthermore, the comparisons performedhere suggest that a proposed model of biological FBA (the "feature similaritygain model") is effective in increasing performance.
arxiv-14700-192 | Denoising Criterion for Variational Auto-Encoding Framework | http://arxiv.org/pdf/1511.06406v2.pdf | author:Daniel Jiwoong Im, Sungjin Ahn, Roland Memisevic, Yoshua Bengio category:cs.LG published:2015-11-19 summary:Denoising autoencoders (DAE) are trained to reconstruct their clean inputswith noise injected at the input level, while variational autoencoders (VAE)are trained with noise injected in their stochastic hidden layer, with aregularizer that encourages this noise injection. In this paper, we show thatinjecting noise both in input and in the stochastic hidden layer can beadvantageous and we propose a modified variational lower bound as an improvedobjective function in this setup. When input is corrupted, then the standardVAE lower bound involves marginalizing the encoder conditional distributionover the input noise, which makes the training criterion intractable. Instead,we propose a modified training criterion which corresponds to a tractable boundwhen input is corrupted. Experimentally, we find that the proposed denoisingvariational autoencoder (DVAE) yields better average log-likelihood than theVAE and the importance weighted autoencoder on the MNIST and Frey Facedatasets.
arxiv-14700-193 | Patterns for Learning with Side Information | http://arxiv.org/pdf/1511.06429v5.pdf | author:Rico Jonschkowski, Sebastian Höfer, Oliver Brock category:cs.LG stat.ML published:2015-11-19 summary:Supervised, semi-supervised, and unsupervised learning estimate a functiongiven input/output samples. Generalization of the learned function to unseendata can be improved by incorporating side information into learning. Sideinformation are data that are neither from the input space nor from the outputspace of the function, but include useful information for learning it. In thispaper we show that learning with side information subsumes a variety of relatedapproaches, e.g. multi-task learning, multi-view learning and learning usingprivileged information. Our main contributions are (i) a new perspective thatconnects these previously isolated approaches, (ii) insights about how thesemethods incorporate different types of prior knowledge, and hence implementdifferent patterns, (iii) facilitating the application of these methods innovel tasks, as well as (iv) a systematic experimental evaluation of thesepatterns in two supervised learning tasks.
arxiv-14700-194 | Neural Network Matrix Factorization | http://arxiv.org/pdf/1511.06443v2.pdf | author:Gintare Karolina Dziugaite, Daniel M. Roy category:cs.LG stat.ML published:2015-11-19 summary:Data often comes in the form of an array or matrix. Matrix factorizationtechniques attempt to recover missing or corrupted entries by assuming that thematrix can be written as the product of two low-rank matrices. In other words,matrix factorization approximates the entries of the matrix by a simple, fixedfunction---namely, the inner product---acting on the latent feature vectors forthe corresponding row and column. Here we consider replacing the inner productby an arbitrary function that we learn from the data at the same time as welearn the latent feature vectors. In particular, we replace the inner productby a multi-layer feed-forward neural network, and learn by alternating betweenoptimizing the network for fixed latent features, and optimizing the latentfeatures for a fixed network. The resulting approach---which we call neuralnetwork matrix factorization or NNMF, for short---dominates standard low-ranktechniques on a suite of benchmark but is dominated by some recent proposalsthat take advantage of the graph features. Given the vast range ofarchitectures, activation functions, regularizers, and optimization techniquesthat could be used within the NNMF framework, it seems likely the truepotential of the approach has yet to be reached.
arxiv-14700-195 | Multilingual Relation Extraction using Compositional Universal Schema | http://arxiv.org/pdf/1511.06396v2.pdf | author:Patrick Verga, David Belanger, Emma Strubell, Benjamin Roth, Andrew McCallum category:cs.CL cs.LG published:2015-11-19 summary:Universal schema builds a knowledge base (KB) of entities and relations byjointly embedding all relation types from input KBs as well as textual patternsexpressing relations from raw text. In most previous applications of universalschema, each textual pattern is represented as a single embedding, preventinggeneralization to unseen patterns. Recent work employs a neural network tocapture patterns' compositional semantics, providing generalization to allpossible input text. In response, this paper introduces significant furtherimprovements to the coverage and flexibility of universal schema relationextraction: predictions for entities unseen in training and multilingualtransfer learning to domains with no annotation. We evaluate our model throughextensive experiments on the English and Spanish TAC KBP benchmark,outperforming the top system from TAC 2013 slot-filling using no handwrittenpatterns or additional annotation. We also consider a multilingual setting inwhich English training data entities overlap with the seed KB, but Spanish textdoes not. Despite having no annotation for Spanish data, we train an accuratepredictor, with additional improvements obtained by tying word embeddingsacross languages. Furthermore, we find that multilingual training improvesEnglish relation extraction accuracy. Our approach is thus suited tobroad-coverage automated knowledge base construction in a variety of languagesand domains.
arxiv-14700-196 | Manifold Regularized Deep Neural Networks using Adversarial Examples | http://arxiv.org/pdf/1511.06381v2.pdf | author:Taehoon Lee, Minsuk Choi, Sungroh Yoon category:cs.LG cs.CV published:2015-11-19 summary:Learning meaningful representations using deep neural networks involvesdesigning efficient training schemes and well-structured networks. Currently,the method of stochastic gradient descent that has a momentum with dropout isone of the most popular training protocols. Based on that, more advancedmethods (i.e., Maxout and Batch Normalization) have been proposed in recentyears, but most still suffer from performance degradation caused by smallperturbations, also known as adversarial examples. To address this issue, wepropose manifold regularized networks (MRnet) that utilize a novel trainingobjective function that minimizes the difference between multi-layer embeddingresults of samples and those adversarial. Our experimental results demonstratedthat MRnet is more resilient to adversarial examples and helps us to generalizerepresentations on manifolds. Furthermore, combining MRnet and dropout allowedus to achieve competitive classification performances for three well-knownbenchmarks: MNIST, CIFAR-10, and SVHN.
arxiv-14700-197 | Neural Random-Access Machines | http://arxiv.org/pdf/1511.06392v3.pdf | author:Karol Kurach, Marcin Andrychowicz, Ilya Sutskever category:cs.LG cs.NE published:2015-11-19 summary:In this paper, we propose and investigate a new neural network architecturecalled Neural Random Access Machine. It can manipulate and dereference pointersto an external variable-size random-access memory. The model is trained frompure input-output examples using backpropagation. We evaluate the new model on a number of simple algorithmic tasks whosesolutions require pointer manipulation and dereferencing. Our results show thatthe proposed model can learn to solve algorithmic tasks of such type and iscapable of operating on simple data structures like linked-lists and binarytrees. For easier tasks, the learned solutions generalize to sequences ofarbitrary length. Moreover, memory access during inference can be done in aconstant time under some assumptions.
arxiv-14700-198 | A Controller-Recognizer Framework: How necessary is recognition for control? | http://arxiv.org/pdf/1511.06428v4.pdf | author:Marcin Moczulski, Kelvin Xu, Aaron Courville, Kyunghyun Cho category:cs.LG cs.CV published:2015-11-19 summary:Recently there has been growing interest in building active visual objectrecognizers, as opposed to the usual passive recognizers which classifies agiven static image into a predefined set of object categories. In this paper wepropose to generalize these recently proposed end-to-end active visualrecognizers into a controller-recognizer framework. A model in thecontroller-recognizer framework consists of a controller, which interfaces withan external manipulator, and a recognizer which classifies the visual inputadjusted by the manipulator. We describe two most recently proposedcontroller-recognizer models: recurrent attention model and spatial transformernetwork as representative examples of controller-recognizer models. Based onthis description we observe that most existing end-to-endcontroller-recognizers tightly, or completely, couple a controller andrecognizer. We ask a question whether this tight coupling is necessary, and tryto answer this empirically by building a controller-recognizer model with adecoupled controller and recognizer. Our experiments revealed that it is notalways necessary to tightly couple them and that by decoupling a controller andrecognizer, there is a possibility of building a generic controller that ispretrained and works together with any subsequent recognizer.
arxiv-14700-199 | Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks | http://arxiv.org/pdf/1511.06390v2.pdf | author:Jost Tobias Springenberg category:stat.ML cs.LG published:2015-11-19 summary:In this paper we present a method for learning a discriminative classifierfrom unlabeled or partially labeled data. Our approach is based on an objectivefunction that trades-off mutual information between observed examples and theirpredicted categorical class distribution, against robustness of the classifierto an adversarial generative model. The resulting algorithm can either beinterpreted as a natural generalization of the generative adversarial networks(GAN) framework or as an extension of the regularized information maximization(RIM) framework to robust classification against an optimal adversary. Weempirically evaluate our method - which we dub categorical generativeadversarial networks (or CatGAN) - on synthetic data as well as on challengingimage classification tasks, demonstrating the robustness of the learnedclassifiers. We further qualitatively assess the fidelity of samples generatedby the adversarial generator that is learned alongside the discriminativeclassifier, and identify links between the CatGAN objective and discriminativeclustering algorithms (such as RIM).
arxiv-14700-200 | Geodesics of learned representations | http://arxiv.org/pdf/1511.06394v4.pdf | author:Olivier J. Hénaff, Eero P. Simoncelli category:cs.CV cs.LG published:2015-11-19 summary:We develop a new method for visualizing and refining the invariances oflearned representations. Specifically, we test for a general form ofinvariance, linearization, in which the action of a transformation is confinedto a low-dimensional subspace. Given two reference images (typically, differingby some transformation), we synthesize a sequence of images lying on a pathbetween them that is of minimal length in the space of the representation (a"representational geodesic"). If the transformation relating the two referenceimages is linearized by the representation, this sequence should follow thegradual evolution of this transformation. We use this method to assess theinvariance properties of a state-of-the-art image classification network andfind that geodesics generated for image pairs differing by translation,rotation, and dilation do not evolve according to their associatedtransformations. Our method also suggests a remedy for these failures, andfollowing this prescription, we show that the modified representation is ableto linearize a variety of geometric image transformations.
arxiv-14700-201 | Delving Deeper into Convolutional Networks for Learning Video Representations | http://arxiv.org/pdf/1511.06432v4.pdf | author:Nicolas Ballas, Li Yao, Chris Pal, Aaron Courville category:cs.CV cs.LG cs.NE published:2015-11-19 summary:We propose an approach to learn spatio-temporal features in videos fromintermediate visual representations we call "percepts" usingGated-Recurrent-Unit Recurrent Networks (GRUs).Our method relies on perceptsthat are extracted from all level of a deep convolutional network trained onthe large ImageNet dataset. While high-level percepts contain highlydiscriminative information, they tend to have a low-spatial resolution.Low-level percepts, on the other hand, preserve a higher spatial resolutionfrom which we can model finer motion patterns. Using low-level percepts canleads to high-dimensionality video representations. To mitigate this effect andcontrol the model number of parameters, we introduce a variant of the GRU modelthat leverages the convolution operations to enforce sparse connectivity of themodel units and share parameters across the input spatial locations. We empirically validate our approach on both Human Action Recognition andVideo Captioning tasks. In particular, we achieve results equivalent tostate-of-art on the YouTube2Text dataset using a simpler text-decoder model andwithout extra 3D CNN features.
arxiv-14700-202 | All you need is a good init | http://arxiv.org/pdf/1511.06422v7.pdf | author:Dmytro Mishkin, Jiri Matas category:cs.LG published:2015-11-19 summary:Layer-sequential unit-variance (LSUV) initialization - a simple method forweight initialization for deep net learning - is proposed. The method consistsof the two steps. First, pre-initialize weights of each convolution orinner-product layer with orthonormal matrices. Second, proceed from the firstto the final layer, normalizing the variance of the output of each layer to beequal to one. Experiment with different activation functions (maxout, ReLU-family, tanh)show that the proposed initialization leads to learning of very deep nets that(i) produces networks with test accuracy better or equal to standard methodsand (ii) is at least as fast as the complex schemes proposed specifically forvery deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastavaet al. (2015)). Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual netsand the state-of-the-art, or very close to it, is achieved on the MNIST,CIFAR-10/100 and ImageNet datasets.
arxiv-14700-203 | Skip-Thought Memory Networks | http://arxiv.org/pdf/1511.06420v2.pdf | author:Ethan Caballero category:cs.NE cs.CL cs.LG published:2015-11-19 summary:Question Answering (QA) is fundamental to natural language processing in thatmost nlp problems can be phrased as QA (Kumar et al., 2015). Current weaklysupervised memory network models that have been proposed so far struggle atanswering questions that involve relations among multiple entities (such asfacebook's bAbi qa5-three-arg-relations in (Weston et al., 2015)). To addressthis problem of learning multi-argument multi-hop semantic relations for thepurpose of QA, we propose a method that combines the jointly learned long-termread-write memory and attentive inference components of end-to-end memorynetworks (MemN2N) (Sukhbaatar et al., 2015) with distributed sentence vectorrepresentations encoded by a Skip-Thought model (Kiros et al., 2015). Thischoice to append Skip-Thought Vectors to the existing MemN2N framework ismotivated by the fact that Skip-Thought Vectors have been shown to accuratelymodel multi-argument semantic relations (Kiros et al., 2015).
arxiv-14700-204 | Fast Metric Learning For Deep Neural Networks | http://arxiv.org/pdf/1511.06442v5.pdf | author:Henry Gouk, Bernhard Pfahringer, Michael Cree category:cs.LG cs.CV stat.ML published:2015-11-19 summary:Similarity metrics are a core component of many information retrieval andmachine learning systems. In this work we propose a method capable of learninga similarity metric from data equipped with a binary relation. By consideringonly the similarity constraints, and initially ignoring the features, we areable to learn target vectors for each instance using one of severalappropriately designed loss functions. A regression model can then beconstructed that maps novel feature vectors to the same target vector space,resulting in a feature extractor that computes vectors for which a predefinedmetric is a meaningful measure of similarity. We present results on bothmulticlass and multi-label classification datasets that demonstrateconsiderably faster convergence, as well as higher accuracy on the majority ofthe intrinsic evaluation tasks and all extrinsic evaluation tasks.
arxiv-14700-205 | How much data is needed to train a medical image deep learning system to achieve necessary high accuracy? | http://arxiv.org/pdf/1511.06348v2.pdf | author:Junghwan Cho, Kyewook Lee, Ellie Shin, Garry Choy, Synho Do category:cs.LG cs.CV cs.NE published:2015-11-19 summary:The use of Convolutional Neural Networks (CNN) in natural imageclassification systems has produced very impressive results. Combined with theinherent nature of medical images that make them ideal for deep-learning,further application of such systems to medical image classification holds muchpromise. However, the usefulness and potential impact of such a system can becompletely negated if it does not reach a target accuracy. In this paper, wepresent a study on determining the optimum size of the training data setnecessary to achieve high classification accuracy with low variance in medicalimage classification systems. The CNN was applied to classify axial ComputedTomography (CT) images into six anatomical classes. We trained the CNN usingsix different sizes of training data set (5, 10, 20, 50, 100, and 200) and thentested the resulting system with a total of 6000 CT images. All images wereacquired from the Massachusetts General Hospital (MGH) Picture Archiving andCommunication System (PACS). Using this data, we employ the learning curveapproach to predict classification accuracy at a given training sample size.Our research will present a general methodology for determining the trainingdata set size necessary to achieve a certain target classification accuracythat can be easily applied to other problems within such systems.
arxiv-14700-206 | QBDC: Query by dropout committee for training deep supervised architecture | http://arxiv.org/pdf/1511.06412v2.pdf | author:Melanie Ducoffe, Frederic Precioso category:cs.LG cs.CV published:2015-11-19 summary:While the current trend is to increase the depth of neural networks toincrease their performance, the size of their training database has to growaccordingly. We notice an emergence of tremendous databases, although providinglabels to build a training set still remains a very expensive task. We tacklethe problem of selecting the samples to be labelled in an online fashion. Inthis paper, we present an active learning strategy based on query by committeeand dropout technique to train a Convolutional Neural Network (CNN). We derivea commmittee of partial CNNs resulting from batchwise dropout runs on theinitial CNN. We evaluate our active learning strategy for CNN on MNISTbenchmark, showing in particular that selecting less than 30 % from theannotated database is enough to get similar error rate as using the fulltraining set on MNIST. We also studied the robustness of our method againstadversarial examples.
arxiv-14700-207 | Variational Auto-encoded Deep Gaussian Processes | http://arxiv.org/pdf/1511.06455v2.pdf | author:Zhenwen Dai, Andreas Damianou, Javier González, Neil Lawrence category:cs.LG stat.ML published:2015-11-19 summary:We develop a scalable deep non-parametric generative model by augmenting deepGaussian processes with a recognition model. Inference is performed in a novelscalable variational framework where the variational posterior distributionsare reparametrized through a multilayer perceptron. The key aspect of thisreformulation is that it prevents the proliferation of variational parameterswhich otherwise grow linearly in proportion to the sample size. We derive a newformulation of the variational lower bound that allows us to distribute most ofthe computation in a way that enables to handle datasets of the size ofmainstream deep learning tasks. We show the efficacy of the method on a varietyof challenges including deep unsupervised learning and deep Bayesianoptimization.
arxiv-14700-208 | A Hierarchical Deep Temporal Model for Group Activity Recognition | http://arxiv.org/pdf/1511.06040v2.pdf | author:Moustafa Ibrahim, Srikanth Muralidharan, Zhiwei Deng, Arash Vahdat, Greg Mori category:cs.CV published:2015-11-19 summary:In group activity recognition, the temporal dynamics of the whole activitycan be inferred based on the dynamics of the individual people representing theactivity. We build a deep model to capture these dynamics based on LSTM(long-short term memory) models. To make use of these ob- servations, wepresent a 2-stage deep temporal model for the group activity recognitionproblem. In our model, a LSTM model is designed to represent action dynamics ofin- dividual people in a sequence and another LSTM model is designed toaggregate human-level information for whole activity understanding. We evaluateour model over two datasets: the collective activity dataset and a new volley-ball dataset. Experimental results demonstrate that our proposed model improvesgroup activity recognition perfor- mance with compared to baseline methods.
arxiv-14700-209 | Deep Learning for Tactile Understanding From Visual and Haptic Data | http://arxiv.org/pdf/1511.06065v2.pdf | author:Yang Gao, Lisa Anne Hendricks, Katherine J. Kuchenbecker, Trevor Darrell category:cs.RO cs.CV cs.LG published:2015-11-19 summary:Robots which interact with the physical world will benefit from afine-grained tactile understanding of objects and surfaces. Additionally, forcertain tasks, robots may need to know the haptic properties of an objectbefore touching it. To enable better tactile understanding for robots, wepropose a method of classifying surfaces with haptic adjectives (e.g.,compressible or smooth) from both visual and physical interaction data. Humanstypically combine visual predictions and feedback from physical interactions toaccurately predict haptic properties and interact with the world. Inspired bythis cognitive pattern, we propose and explore a purely visual hapticprediction model. Purely visual models enable a robot to "feel" withoutphysical interaction. Furthermore, we demonstrate that using both visual andphysical interaction signals together yields more accurate hapticclassification. Our models take advantage of recent advances in deep neuralnetworks by employing a unified approach to learning features for physicalinteraction and visual observations. Even though we employ little domainspecific knowledge, our model still achieves better results than methods basedon hand-designed features.
arxiv-14700-210 | Asymmetrically Weighted CCA And Hierarchical Kernel Sentence Embedding For Multimodal Retrieval | http://arxiv.org/pdf/1511.06267v4.pdf | author:Youssef Mroueh, Etienne Marcheret, Vaibhava Goel category:cs.LG published:2015-11-19 summary:Joint modeling of language and vision has been drawing increasing interest. Amultimodal data representation allowing for bidirectional retrieval of imagesby sentences and vice versa is a key aspect. In this paper we present threecontributions in canonical correlation analysis (CCA) based multimodalretrieval. Firstly, we show that an asymmetric weighting of the canonicalweights, while achieving a cross-view mapping from the search to the queryspace, it improves the retrieval performance. Secondly, we devise acomputationally efficient model selection - crucial to generalization andstability - in the framework of the Bjork Golub algorithm for regularized CCAvia spectral filtering. Finally, we introduce a Hierarchical Kernel SentenceEmbedding (HKSE) that approximates Kernel CCA for a special similarity kernelbetween words distributions. State of the art results are obtained on MSCOCOand Flickr benchmarks when these three techniques are used in conjunction.
arxiv-14700-211 | Semi-supervised Learning for Convolutional Neural Networks via Online Graph Construction | http://arxiv.org/pdf/1511.06104v2.pdf | author:Sheng-Yi Bai, Sebastian Agethen, Ting-Hsuan Chao, Winston Hsu category:cs.NE cs.CV cs.LG published:2015-11-19 summary:The recent promising achievements of deep learning rely on the large amountof labeled data. Considering the abundance of data on the web, most of them donot have labels at all. Therefore, it is important to improve generalizationperformance using unlabeled data on supervised tasks with few labeledinstances. In this work, we revisit graph-based semi-supervised learningalgorithms and propose an online graph construction technique which suits deepconvolutional neural network better. We consider an EM-like algorithm forsemi-supervised learning on deep neural networks: In forward pass, the graph isconstructed based on the network output, and the graph is then used for losscalculation to help update the network by back propagation in the backwardpass. We demonstrate the strength of our online approach compared to theconventional ones whose graph is constructed on static but not robust enoughfeature representations beforehand.
arxiv-14700-212 | Comparative Study of Deep Learning Software Frameworks | http://arxiv.org/pdf/1511.06435v3.pdf | author:Soheil Bahrampour, Naveen Ramakrishnan, Lukas Schott, Mohak Shah category:cs.LG published:2015-11-19 summary:Deep learning methods have resulted in significant performance improvementsin several application domains and as such several software frameworks havebeen developed to facilitate their implementation. This paper presents acomparative study of five deep learning frameworks, namely Caffe, Neon,TensorFlow, Theano, and Torch, on three aspects: extensibility, hardwareutilization, and speed. The study is performed on several types of deeplearning architectures and we evaluate the performance of the above frameworkswhen employed on a single machine for both (multi-threaded) CPU and GPU (NvidiaTitan X) settings. The speed performance metrics used here include the gradientcomputation time, which is important during the training phase of deepnetworks, and the forward time, which is important from the deploymentperspective of trained networks. For convolutional networks, we also report howeach of these frameworks support various convolutional algorithms and theircorresponding performance. From our experiments, we observe that Theano andTorch are the most easily extensible frameworks. We observe that Torch is bestsuited for any deep architecture on CPU, followed by Theano. It also achievesthe best performance on the GPU for large convolutional and fully connectednetworks, followed closely by Neon. Theano achieves the best performance on GPUfor training and deployment of LSTM networks. Caffe is the easiest forevaluating the performance of standard deep architectures. Finally, TensorFlowis a very flexible framework, similar to Theano, but its performance iscurrently not competitive compared to the other studied frameworks.
arxiv-14700-213 | Iterative Refinement of Approximate Posterior for Training Directed Belief Networks | http://arxiv.org/pdf/1511.06382v4.pdf | author:R Devon Hjelm, Kyunghyun Cho, Junyoung Chung, Russ Salakhutdinov, Vince Calhoun, Nebojsa Jojic category:cs.LG stat.ML published:2015-11-19 summary:Recent advances in variational inference that make use of an inference orrecognition network for training and evaluating deep directed graphical modelshave advanced well beyond traditional variational inference and Markov chainMonte Carlo methods. These techniques offer higher flexibility with simpler andfaster inference; yet training and evaluation still remains a challenge. Wepropose a method for improving the per-example approximate posterior byiterative refinement, which can provide notable gains in maximizing thevariational lower bound of the log likelihood and works with both continuousand discrete latent variables. We evaluate our approach as a method of trainingand evaluating directed graphical models. We show that, when used for training,iterative refinement improves the variational lower bound and can also improvethe log-likelihood over related methods. We also show that iterative refinementcan be used to get a better estimate of the log-likelihood in any directedmodel trained with mean-field inference.
arxiv-14700-214 | Neural network-based clustering using pairwise constraints | http://arxiv.org/pdf/1511.06321v5.pdf | author:Yen-Chang Hsu, Zsolt Kira category:cs.LG stat.ML published:2015-11-19 summary:This paper presents a neural network-based end-to-end clustering framework.We design a novel strategy to utilize the contrastive criteria for pushingdata-forming clusters directly from raw data, in addition to learning a featureembedding suitable for such clustering. The network is trained with weaklabels, specifically partial pairwise relationships between data instances. Thecluster assignments and their probabilities are then obtained at the outputlayer by feed-forwarding the data. The framework has the interestingcharacteristic that no cluster centers need to be explicitly specified, thusthe resulting cluster distribution is purely data-driven and no distancemetrics need to be predefined. The experiments show that the proposed approachbeats the conventional two-stage method (feature embedding with k-means) by asignificant margin. It also compares favorably to the performance of thestandard cross entropy loss for classification. Robustness analysis also showsthat the method is largely insensitive to the number of clusters. Specifically,we show that the number of dominant clusters is close to the true number ofclusters even when a large k is used for clustering.
arxiv-14700-215 | Unsupervised Learning of Visual Structure using Predictive Generative Networks | http://arxiv.org/pdf/1511.06380v2.pdf | author:William Lotter, Gabriel Kreiman, David Cox category:cs.LG cs.AI cs.CV q-bio.NC published:2015-11-19 summary:The ability to predict future states of the environment is a central pillarof intelligence. At its core, effective prediction requires an internal modelof the world and an understanding of the rules by which the world changes.Here, we explore the internal models developed by deep neural networks trainedusing a loss based on predicting future frames in synthetic video sequences,using a CNN-LSTM-deCNN framework. We first show that this architecture canachieve excellent performance in visual sequence prediction tasks, includingstate-of-the-art performance in a standard 'bouncing balls' dataset (Sutskeveret al., 2009). Using a weighted mean-squared error and adversarial loss(Goodfellow et al., 2014), the same architecture successfully extrapolatesout-of-the-plane rotations of computer-generated faces. Furthermore, despitebeing trained end-to-end to predict only pixel-level information, ourPredictive Generative Networks learn a representation of the latent structureof the underlying three-dimensional objects themselves. Importantly, we findthat this representation is naturally tolerant to object transformations, andgeneralizes well to new tasks, such as classification of static images. Similarmodels trained solely with a reconstruction loss fail to generalize aseffectively. We argue that prediction can serve as a powerful unsupervised lossfor learning rich internal representations of high-level object features.
arxiv-14700-216 | Multi-task Sequence to Sequence Learning | http://arxiv.org/pdf/1511.06114v4.pdf | author:Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, Lukasz Kaiser category:cs.LG cs.CL stat.ML published:2015-11-19 summary:Sequence to sequence learning has recently emerged as a new paradigm insupervised learning. To date, most of its applications focused on only one taskand not much work explored this framework for multiple tasks. This paperexamines three multi-task learning (MTL) settings for sequence to sequencemodels: (a) the oneto-many setting - where the encoder is shared betweenseveral tasks such as machine translation and syntactic parsing, (b) themany-to-one setting - useful when only the decoder can be shared, as in thecase of translation and image caption generation, and (c) the many-to-manysetting - where multiple encoders and decoders are shared, which is the casewith unsupervised objectives and translation. Our results show that training ona small amount of parsing and image caption data can improve the translationquality between English and German by up to 1.5 BLEU points over strongsingle-task baselines on the WMT benchmarks. Furthermore, we have established anew state-of-the-art result in constituent parsing with 93.0 F1. Lastly, wereveal interesting properties of the two unsupervised learning objectives,autoencoder and skip-thought, in the MTL context: autoencoder helps less interms of perplexities but more on BLEU scores compared to skip-thought.
arxiv-14700-217 | Neural Variational Inference for Text Processing | http://arxiv.org/pdf/1511.06038v3.pdf | author:Yishu Miao, Lei Yu, Phil Blunsom category:cs.CL cs.LG stat.ML published:2015-11-19 summary:Recent advances in neural variational inference have spawned a renaissance indeep latent variable models. In this paper we introduce a generic variationalinference framework for generative and conditional models of text. Whiletraditional variational methods derive an analytic approximation for theintractable distributions over latent variables, here we construct an inferencenetwork conditioned on the discrete text input to provide the variationaldistribution. We validate this framework on two very different text modellingapplications, generative document modelling and supervised question answering.Our neural variational document model combines a continuous stochastic documentrepresentation with a bag-of-words generative model and achieves the lowestreported perplexities on two standard test corpora. The neural answer selectionmodel employs a stochastic representation layer within an attention mechanismto extract the semantics between a question and answer pair. On two questionanswering benchmarks this model exceeds all previous published benchmarks.
arxiv-14700-218 | Predicting online user behaviour using deep learning algorithms | http://arxiv.org/pdf/1511.06247v2.pdf | author:Armando Vieira category:cs.LG stat.ML published:2015-11-19 summary:We propose a robust classifier to predict buying intentions based on userbehaviour within a large e-commerce website. In this work we comparetraditional machine learning techniques with the most advanced deep learningapproaches. We show that both Deep Belief Networks and Stacked Denoisingauto-Encoders achieved a substantial improvement by extracting features fromhigh dimensional data during the pre-train phase. They prove also to be moreconvenient to deal with severe class imbalance.
arxiv-14700-219 | Convolutional Clustering for Unsupervised Learning | http://arxiv.org/pdf/1511.06241v2.pdf | author:Aysegul Dundar, Jonghoon Jin, Eugenio Culurciello category:cs.LG cs.CV published:2015-11-19 summary:The task of labeling data for training deep neural networks is daunting andtedious, requiring millions of labels to achieve the current state-of-the-artresults. Such reliance on large amounts of labeled data can be relaxed byexploiting hierarchical features via unsupervised learning techniques. In thiswork, we propose to train a deep convolutional network based on an enhancedversion of the k-means clustering algorithm, which reduces the number ofcorrelated parameters in the form of similar filters, and thus increases testcategorization accuracy. We call our algorithm convolutional k-meansclustering. We further show that learning the connection between the layers ofa deep convolutional neural network improves its ability to be trained on asmaller amount of labeled data. Our experiments show that the proposedalgorithm outperforms other techniques that learn filters unsupervised.Specifically, we obtained a test accuracy of 74.1% on STL-10 and a test errorof 0.5% on MNIST.
arxiv-14700-220 | First Step toward Model-Free, Anonymous Object Tracking with Recurrent Neural Networks | http://arxiv.org/pdf/1511.06425v2.pdf | author:Quan Gan, Qipeng Guo, Zheng Zhang, Kyunghyun Cho category:cs.CV cs.LG published:2015-11-19 summary:In this paper, we propose and study a novel visual object tracking approachbased on convolutional networks and recurrent networks. The proposed approachis distinct from the existing approaches to visual object tracking, such asfiltering-based ones and tracking-by-detection ones, in the sense that thetracking system is explicitly trained off-line to track anonymous objects in anoisy environment. The proposed visual tracking model is end-to-end trainable,minimizing any adversarial effect from mismatches in object representation andbetween the true underlying dynamics and learning dynamics. We empirically showthat the proposed tracking approach works well in various scenarios bygenerating artificial video sequences with varying conditions; the number ofobjects, amount of noise and the match between the training shapes and testshapes.
arxiv-14700-221 | Foveation-based Mechanisms Alleviate Adversarial Examples | http://arxiv.org/pdf/1511.06292v3.pdf | author:Yan Luo, Xavier Boix, Gemma Roig, Tomaso Poggio, Qi Zhao category:cs.LG cs.CV published:2015-11-19 summary:We show that adversarial examples, i.e., the visually imperceptibleperturbations that result in Convolutional Neural Networks (CNNs) fail, can bealleviated with a mechanism based on foveations---applying the CNN in differentimage regions. To see this, first, we report results in ImageNet that lead to arevision of the hypothesis that adversarial perturbations are a consequence ofCNNs acting as a linear classifier: CNNs act locally linearly to changes in theimage regions with objects recognized by the CNN, and in other regions the CNNmay act non-linearly. Then, we corroborate that when the neural responses arelinear, applying the foveation mechanism to the adversarial example tends tosignificantly reduce the effect of the perturbation. This is because,hypothetically, the CNNs for ImageNet are robust to changes of scale andtranslation of the object produced by the foveation, but this property does notgeneralize to transformations of the perturbation. As a result, the accuracyafter a foveation is almost the same as the accuracy of the CNN without theadversarial perturbation, even if the adversarial perturbation is calculatedtaking into account a foveation.
arxiv-14700-222 | Order-Embeddings of Images and Language | http://arxiv.org/pdf/1511.06361v6.pdf | author:Ivan Vendrov, Ryan Kiros, Sanja Fidler, Raquel Urtasun category:cs.LG cs.CL cs.CV published:2015-11-19 summary:Hypernymy, textual entailment, and image captioning can be seen as specialcases of a single visual-semantic hierarchy over words, sentences, and images.In this paper we advocate for explicitly modeling the partial order structureof this hierarchy. Towards this goal, we introduce a general method forlearning ordered representations, and show how it can be applied to a varietyof tasks involving images and language. We show that the resultingrepresentations improve performance over current approaches for hypernymprediction and image-caption retrieval.
arxiv-14700-223 | Task Loss Estimation for Sequence Prediction | http://arxiv.org/pdf/1511.06456v4.pdf | author:Dzmitry Bahdanau, Dmitriy Serdyuk, Philémon Brakel, Nan Rosemary Ke, Jan Chorowski, Aaron Courville, Yoshua Bengio category:cs.LG published:2015-11-19 summary:Often, the performance on a supervised machine learning task is evaluatedwith a emph{task loss} function that cannot be optimized directly. Examples ofsuch loss functions include the classification error, the edit distance and theBLEU score. A common workaround for this problem is to instead optimize aemph{surrogate loss} function, such as for instance cross-entropy or hingeloss. In order for this remedy to be effective, it is important to ensure thatminimization of the surrogate loss results in minimization of the task loss, acondition that we call emph{consistency with the task loss}. In this work, wepropose another method for deriving differentiable surrogate losses thatprovably meet this requirement. We focus on the broad class of models thatdefine a score for every input-output pair. Our idea is that this score can beinterpreted as an estimate of the task loss, and that the estimation error maybe used as a consistent surrogate loss. A distinct feature of such an approachis that it defines the desirable value of the score for every input-outputpair. We use this property to design specialized surrogate losses forEncoder-Decoder models often used for sequence prediction tasks. In ourexperiment, we benchmark on the task of speech recognition. Using a newsurrogate loss instead of cross-entropy to train an Encoder-Decoder speechrecognizer brings a significant ~13% relative improvement in terms of CharacterError Rate (CER) in the case when no extra corpora are used for languagemodeling.
arxiv-14700-224 | Active Object Localization with Deep Reinforcement Learning | http://arxiv.org/pdf/1511.06015v1.pdf | author:Juan C. Caicedo, Svetlana Lazebnik category:cs.CV published:2015-11-18 summary:We present an active detection model for localizing objects in scenes. Themodel is class-specific and allows an agent to focus attention on candidateregions for identifying the correct location of a target object. This agentlearns to deform a bounding box using simple transformation actions, with thegoal of determining the most specific location of target objects followingtop-down reasoning. The proposed localization agent is trained using deepreinforcement learning, and evaluated on the Pascal VOC 2007 dataset. We showthat agents guided by the proposed model are able to localize a single instanceof an object after analyzing only between 11 and 25 regions in an image, andobtain the best detection results among systems that do not use objectproposals for object localization.
arxiv-14700-225 | Wishart Mechanism for Differentially Private Principal Components Analysis | http://arxiv.org/pdf/1511.05680v2.pdf | author:Wuxuan Jiang, Cong Xie, Zhihua Zhang category:cs.CR cs.DS stat.ML published:2015-11-18 summary:We propose a new input perturbation mechanism for publishing a covariancematrix to achieve $(\epsilon,0)$-differential privacy. Our mechanism uses aWishart distribution to generate matrix noise. In particular, We apply thismechanism to principal component analysis. Our mechanism is able to keep thepositive semi-definiteness of the published covariance matrix. Thus, ourapproach gives rise to a general publishing framework for input perturbation ofa symmetric positive semidefinite matrix. Moreover, compared with the classicLaplace mechanism, our method has better utility guarantee. To the best of ourknowledge, Wishart mechanism is the best input perturbation approach for$(\epsilon,0)$-differentially private PCA. We also compare our work withprevious exponential mechanism algorithms in the literature and provide nearoptimal bound while having more flexibility and less computationalintractability.
arxiv-14700-226 | Studying the control of non invasive prosthetic hands over large time spans | http://arxiv.org/pdf/1511.06004v1.pdf | author:Mara Graziani category:cs.LG cs.HC published:2015-11-18 summary:The electromyography (EMG) signal is the electrical manifestation of aneuromuscular activation that provides access to physiological processes whichcause the muscle to generate force and produce movement. Non invasiveprostheses use such signals detected by the electrodes placed on the user'sstump, as input to generate hand posture movements according to the intentionsof the prosthesis wearer. The aim of this pilot study is to explore therepeatability issue, i.e. the ability to classify 17 different hand postures,represented by EMG signal, across a time span of days by a control algorithm.Data collection experiments lasted four days and signals were collected fromthe forearm of a single subject. We find that Support Vector Machine (SVM)classification results are high enough to guarantee a correct classification ofmore than 10 postures in each moment of the considered time span.
arxiv-14700-227 | Unitary-Group Invariant Kernels and Features from Transformed Unlabeled Data | http://arxiv.org/pdf/1511.05943v1.pdf | author:Dipan K. Pal, Marios Savvides category:cs.LG published:2015-11-18 summary:The study of representations invariant to common transformations of the datais important to learning. Most techniques have focused on local approximateinvariance implemented within expensive optimization frameworks lackingexplicit theoretical guarantees. In this paper, we study kernels that areinvariant to the unitary group while having theoretical guarantees inaddressing practical issues such as (1) unavailability of transformed versionsof labelled data and (2) not observing all transformations. We present atheoretically motivated alternate approach to the invariant kernel SVM. Unlikeprevious approaches to the invariant SVM, the proposed formulation solves bothissues mentioned. We also present a kernel extension of a recent technique toextract linear unitary-group invariant features addressing both issues andextend some guarantees regarding invariance and stability. We presentexperiments on the UCI ML datasets to illustrate and validate our methods.
arxiv-14700-228 | On the Global Linear Convergence of Frank-Wolfe Optimization Variants | http://arxiv.org/pdf/1511.05932v1.pdf | author:Simon Lacoste-Julien, Martin Jaggi category:math.OC cs.LG stat.ML G.1.6; I.2.6 published:2015-11-18 summary:The Frank-Wolfe (FW) optimization algorithm has lately re-gained popularitythanks in particular to its ability to nicely handle the structured constraintsappearing in machine learning applications. However, its convergence rate isknown to be slow (sublinear) when the solution lies at the boundary. A simpleless-known fix is to add the possibility to take 'away steps' duringoptimization, an operation that importantly does not require a feasibilityoracle. In this paper, we highlight and clarify several variants of theFrank-Wolfe optimization algorithm that have been successfully applied inpractice: away-steps FW, pairwise FW, fully-corrective FW and Wolfe's minimumnorm point algorithm, and prove for the first time that they all enjoy globallinear convergence, under a weaker condition than strong convexity of theobjective. The constant in the convergence rate has an elegant interpretationas the product of the (classical) condition number of the function with a novelgeometric quantity that plays the role of a 'condition number' of theconstraint set. We provide pointers to where these algorithms have made adifference in practice, in particular with the flow polytope, the marginalpolytope and the base polytope for submodular optimization.
arxiv-14700-229 | Combining Neural Networks and Log-linear Models to Improve Relation Extraction | http://arxiv.org/pdf/1511.05926v1.pdf | author:Thien Huu Nguyen, Ralph Grishman category:cs.CL cs.LG published:2015-11-18 summary:The last decade has witnessed the success of the traditional feature-basedmethod on exploiting the discrete structures such as words or lexical patternsto extract relations from text. Recently, convolutional and recurrent neuralnetworks has provided very effective mechanisms to capture the hiddenstructures within sentences via continuous representations, therebysignificantly advancing the performance of relation extraction. The advantageof convolutional neural networks is their capacity to generalize theconsecutive k-grams in the sentences while recurrent neural networks areeffective to encode long ranges of sentence context. This paper proposes tocombine the traditional feature-based method, the convolutional and recurrentneural networks to simultaneously benefit from their advantages. Our systematicevaluation of different network architectures and combination methodsdemonstrates the effectiveness of this approach and results in thestate-of-the-art performance on the ACE 2005 and SemEval dataset.
arxiv-14700-230 | From Pose to Activity: Surveying Datasets and Introducing CONVERSE | http://arxiv.org/pdf/1511.05788v2.pdf | author:Michael Edwards, Jingjing Deng, Xianghua Xie category:cs.CV published:2015-11-18 summary:We present a review on the current state of publicly available datasetswithin the human action recognition community; highlighting the revival of posebased methods and recent progress of understanding person-person interactionmodeling. We categorize datasets regarding several key properties for usage asa benchmark dataset; including the number of class labels, ground truthsprovided, and application domain they occupy. We also consider the level ofabstraction of each dataset; grouping those that present actions, interactionsand higher level semantic activities. The survey identifies key appearance andpose based datasets, noting a tendency for simplistic, emphasized, or scriptedaction classes that are often readily definable by a stable collection ofsub-action gestures. There is a clear lack of datasets that provide closelyrelated actions, those that are not implicitly identified via a series of posesand gestures, but rather a dynamic set of interactions. We therefore propose anovel dataset that represents complex conversational interactions between twoindividuals via 3D pose. 8 pairwise interactions describing 7 separateconversation based scenarios were collected using two Kinect depth sensors. Theintention is to provide events that are constructed from numerous primitiveactions, interactions and motions, over a period of time; providing a set ofsubtle action classes that are more representative of the real world, and achallenge to currently developed recognition methodologies. We believe this isamong one of the first datasets devoted to conversational interactionclassification using 3D pose features and the attributed papers show this taskis indeed possible. The full dataset is made publicly available to the researchcommunity at www.csvision.swansea.ac.uk/converse.
arxiv-14700-231 | Why are deep nets reversible: A simple theory, with implications for training | http://arxiv.org/pdf/1511.05653v2.pdf | author:Sanjeev Arora, Yingyu Liang, Tengyu Ma category:cs.LG published:2015-11-18 summary:Generative models for deep learning are promising both to improveunderstanding of the model, and yield training methods requiring fewer labeledsamples. Recent works use generative model approaches to produce the deep net's inputgiven the value of a hidden layer several levels above. However, there is noaccompanying "proof of correctness" for the generative model, showing that thefeedforward deep net is the correct inference method for recovering the hiddenlayer given the input. Furthermore, these models are complicated. The current paper takes a more theoretical tack. It presents a very simplegenerative model for RELU deep nets, with the following characteristics: (i)The generative model is just the reverse of the feedforward net: if the forwardtransformation at a layer is $A$ then the reverse transformation is $A^T$.(This can be seen as an explanation of the old weight tying idea for denoisingautoencoders.) (ii) Its correctness can be proven under a clean theoreticalassumption: the edge weights in real-life deep nets behave like random numbers.Under this assumption ---which is experimentally tested on real-life nets likeAlexNet--- it is formally proved that feed forward net is a correct inferencemethod for recovering the hidden layer. The generative model suggests a simple modification for training: use thegenerative model to produce synthetic data with labels and include it in thetraining set. Experiments are shown to support this theory of random-like deepnets; and that it helps the training.
arxiv-14700-232 | Collecting and Annotating the Large Continuous Action Dataset | http://arxiv.org/pdf/1511.05914v1.pdf | author:Daniel Paul Barrett, Ran Xu, Haonan Yu, Jeffrey Mark Siskind category:cs.CV published:2015-11-18 summary:We make available to the community a new dataset to supportaction-recognition research. This dataset is different from prior datasets inseveral key ways. It is significantly larger. It contains streaming video withlong segments containing multiple action occurrences that often overlap inspace and/or time. All actions were filmed in the same collection ofbackgrounds so that background gives little clue as to action class. We hadfive humans replicate the annotation of temporal extent of action occurrenceslabeled with their class and measured a surprisingly low level of intercoderagreement. A baseline experiment shows that recent state-of-the-art methodsperform poorly on this dataset. This suggests that this will be a challengingdataset to foster advances in action-recognition research. This manuscriptserves to describe the novel content and characteristics of the LCA dataset,present the design decisions made when filming the dataset, and document thenovel methods employed to annotate the dataset.
arxiv-14700-233 | Dense Human Body Correspondences Using Convolutional Networks | http://arxiv.org/pdf/1511.05904v1.pdf | author:Lingyu Wei, Qixing Huang, Duygu Ceylan, Etienne Vouga, Hao Li category:cs.CV cs.GR published:2015-11-18 summary:We propose a deep learning approach for finding dense correspondences between3D scans of people. Our method requires only partial geometric information inthe form of two depth maps or partial reconstructed surfaces, works for humansin arbitrary poses and wearing any clothing, does not require the two people tobe scanned from similar viewpoints, and runs in real time. We use a deepconvolutional neural network to train a feature descriptor on depth map pixels,but crucially, rather than training the network to solve the shapecorrespondence problem directly, we train it to solve a body regionclassification problem, modified to increase the smoothness of the learneddescriptors near region boundaries. This approach ensures that nearby points onthe human body are nearby in feature space, and vice versa, rendering thefeature descriptor suitable for computing dense correspondences between thescans. We validate our method on real and synthetic data for both clothed andunclothed humans, and show that our correspondences are more robust than ispossible with state-of-the-art unsupervised methods, and more accurate thanthose found using methods that require full watertight 3D geometry.
arxiv-14700-234 | Metric learning approach for graph-based label propagation | http://arxiv.org/pdf/1511.05789v6.pdf | author:Pauline Wauquier, Mikaela Keller category:cs.LG published:2015-11-18 summary:The efficiency of graph-based semi-supervised algorithms depends on the graphof instances on which they are applied. The instances are often in a vectorialform before a graph linking them is built. The construction of the graph relieson a metric over the vectorial space that help define the weight of theconnection between entities. The classic choice for this metric is usually adistance measure or a similarity measure based on the euclidean norm. We claimthat in some cases the euclidean norm on the initial vectorial space might notbe the more appropriate to solve the task efficiently. We propose an algorithmthat aims at learning the most appropriate vectorial representation forbuilding a graph on which the task at hand is solved efficiently.
arxiv-14700-235 | Eigenspectra optoacoustic tomography achieves quantitative blood oxygenation imaging deep in tissues | http://arxiv.org/pdf/1511.05846v1.pdf | author:Stratis Tzoumas, Antonio Nunes, Ivan Olefir, Stefan Stangl, Panagiotis Symvoulidis, Sarah Glasl, Christine Bayer, Gabriele Multhoff, Vasilis Ntziachristos category:physics.med-ph cs.CV physics.optics q-bio.QM published:2015-11-18 summary:Light propagating in tissue attains a spectrum that varies with location dueto wavelength-dependent fluence attenuation by tissue optical properties, aneffect that causes spectral corruption. Predictions of the spectral variationsof light fluence in tissue are challenging since the spatial distribution ofoptical properties in tissue cannot be resolved in high resolution or with highaccuracy by current methods. Spectral corruption has fundamentally limited thequantification accuracy of optical and optoacoustic methods and impeded thelong sought-after goal of imaging blood oxygen saturation (sO2) deep intissues; a critical but still unattainable target for the assessment ofoxygenation in physiological processes and disease. We discover a new principleunderlying light fluence in tissues, which describes the wavelength dependenceof light fluence as an affine function of a few reference base spectra,independently of the specific distribution of tissue optical properties. Thisfinding enables the introduction of a previously undocumented concept termedeigenspectra Multispectral Optoacoustic Tomography (eMSOT) that can effectivelyaccount for wavelength dependent light attenuation without explicit knowledgeof the tissue optical properties. We validate eMSOT in more than 2000simulations and with phantom and animal measurements. We find that eMSOT canquantitatively image tissue sO2 reaching in many occasions a better than10-fold improved accuracy over conventional spectral optoacoustic methods.Then, we show that eMSOT can spatially resolve sO2 in muscle and tumor;revealing so far unattainable tissue physiology patterns. Last, we relatedeMSOT readings to cancer hypoxia and found congruence between eMSOT tumor sO2images and tissue perfusion and hypoxia maps obtained by correlativehistological analysis.
arxiv-14700-236 | Using Machine Learning to Predict the Outcome of English County twenty over Cricket Matches | http://arxiv.org/pdf/1511.05837v1.pdf | author:Stylianos Kampakis, William Thomas category:stat.ML stat.AP published:2015-11-18 summary:Cricket betting is a multi-billion dollar market. Therefore, there is astrong incentive for models that can predict the outcomes of games and beat theodds provided by bookers. The aim of this study was to investigate to whatdegree it is possible to predict the outcome of cricket matches. The targetcompetition was the English twenty over county cricket cup. The originalfeatures alongside engineered features gave rise to more than 500 team andplayer statistics. The models were optimized firstly with team features onlyand then both team and player features. The performance of the models wastested over individual seasons from 2009 to 2014 having been trained overprevious season data in each case. The optimal model was a simple predictionmethod combined with complex hierarchical features and was shown tosignificantly outperform a gambling industry benchmark.
arxiv-14700-237 | Enhancements in statistical spoken language translation by de-normalization of ASR results | http://arxiv.org/pdf/1511.09392v1.pdf | author:Agnieszka Wołk, Krzysztof Wołk, Krzysztof Marasek category:cs.CL stat.ML published:2015-11-18 summary:Spoken language translation (SLT) has become very important in anincreasingly globalized world. Machine translation (MT) for automatic speechrecognition (ASR) systems is a major challenge of great interest. This researchinvestigates that automatic sentence segmentation of speech that is importantfor enriching speech recognition output and for aiding downstream languageprocessing. This article focuses on the automatic sentence segmentation ofspeech and improving MT results. We explore the problem of identifying sentenceboundaries in the transcriptions produced by automatic speech recognitionsystems in the Polish language. We also experiment with reverse normalizationof the recognized speech samples.
arxiv-14700-238 | Harvesting comparable corpora and mining them for equivalent bilingual sentences using statistical classification and analogy- based heuristics | http://arxiv.org/pdf/1511.06285v1.pdf | author:Krzysztof Wołk, Emilia Rejmund, Krzysztof Marasek category:cs.CL stat.ML published:2015-11-18 summary:Parallel sentences are a relatively scarce but extremely useful resource formany applications including cross-lingual retrieval and statistical machinetranslation. This research explores our new methodologies for mining such datafrom previously obtained comparable corpora. The task is highly practical sincenon-parallel multilingual data exist in far greater quantities than parallelcorpora, but parallel sentences are a much more useful resource. Here wepropose a web crawling method for building subject-aligned comparable corporafrom e.g. Wikipedia dumps and Euronews web page. The improvements in machinetranslation are shown on Polish-English language pair for various text domains.We also tested another method of building parallel corpora based on comparablecorpora data. It lets automatically broad existing corpus of sentences fromsubject of corpora based on analogies between them.
arxiv-14700-239 | Labeled pupils in the wild: A dataset for studying pupil detection in unconstrained environments | http://arxiv.org/pdf/1511.05768v1.pdf | author:Marc Tonsen, Xucong Zhang, Yusuke Sugano, Andreas Bulling category:cs.CV published:2015-11-18 summary:We present labelled pupils in the wild (LPW), a novel dataset of 66high-quality, high-speed eye region videos for the development and evaluationof pupil detection algorithms. The videos in our dataset were recorded from 22participants in everyday locations at about 95 FPS using a state-of-the-artdark-pupil head-mounted eye tracker. They cover people with differentethnicities, a diverse set of everyday indoor and outdoor illuminationenvironments, as well as natural gaze direction distributions. The dataset alsoincludes participants wearing glasses, contact lenses, as well as make-up. Webenchmark five state-of-the-art pupil detection algorithms on our dataset withrespect to robustness and accuracy. We further study the influence of imageresolution, vision aids, as well as recording location (indoor, outdoor) onpupil detection performance. Our evaluations provide valuable insights into thegeneral pupil detection problem and allow us to identify key challenges forrobust pupil detection on head-mounted eye trackers.
arxiv-14700-240 | Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction | http://arxiv.org/pdf/1511.05756v1.pdf | author:Hyeonwoo Noh, Paul Hongsuck Seo, Bohyung Han category:cs.CV cs.CL cs.LG published:2015-11-18 summary:We tackle image question answering (ImageQA) problem by learning aconvolutional neural network (CNN) with a dynamic parameter layer whose weightsare determined adaptively based on questions. For the adaptive parameterprediction, we employ a separate parameter prediction network, which consistsof gated recurrent unit (GRU) taking a question as its input and afully-connected layer generating a set of candidate weights as its output.However, it is challenging to construct a parameter prediction network for alarge number of parameters in the fully-connected dynamic parameter layer ofthe CNN. We reduce the complexity of this problem by incorporating a hashingtechnique, where the candidate weights given by the parameter predictionnetwork are selected using a predefined hash function to determine individualweights in the dynamic parameter layer. The proposed network---joint networkwith the CNN for ImageQA and the parameter prediction network---is trainedend-to-end through back-propagation, where its weights are initialized using apre-trained CNN and GRU. The proposed algorithm illustrates thestate-of-the-art performance on all available public ImageQA benchmarks.
arxiv-14700-241 | Sparse learning of maximum likelihood model for optimization of complex loss function | http://arxiv.org/pdf/1511.05743v1.pdf | author:Ning Zhang, Prathamesh Chandrasekar category:cs.LG published:2015-11-18 summary:Traditional machine learning methods usually minimize a simple loss functionto learn a predictive model, and then use a complex performance measure tomeasure the prediction performance. However, minimizing a simple loss functioncannot guarantee that an optimal performance. In this paper, we study theproblem of optimizing the complex performance measure directly to obtain apredictive model. We proposed to construct a maximum likelihood model for thisproblem, and to learn the model parameter, we minimize a com- plex lossfunction corresponding to the desired complex performance measure. To optimizethe loss function, we approximate the upper bound of the complex loss. We alsopropose impose the sparsity to the model parameter to obtain a sparse model. Anobjective is constructed by combining the upper bound of the loss function andthe sparsity of the model parameter, and we develop an iterative algorithm tominimize it by using the fast iterative shrinkage- thresholding algorithmframework. The experiments on optimization on three different complexperformance measures, including F-score, receiver operating characteristiccurve, and recall precision curve break even point, over three real-worldapplications, aircraft event recognition of civil aviation safety, in- trusiondetection in wireless mesh networks, and image classification, show theadvantages of the proposed method over state-of-the-art methods.
arxiv-14700-242 | A Random Forest Guided Tour | http://arxiv.org/pdf/1511.05741v1.pdf | author:Gérard Biau, Erwan Scornet category:math.ST stat.ML stat.TH published:2015-11-18 summary:The random forest algorithm, proposed by L. Breiman in 2001, has beenextremely successful as a general-purpose classification and regression method.The approach, which combines several randomized decision trees and aggregatestheir predictions by averaging, has shown excellent performance in settingswhere the number of variables is much larger than the number of observations.Moreover, it is versatile enough to be applied to large-scale problems, iseasily adapted to various ad-hoc learning tasks, and returns measures ofvariable importance. The present article reviews the most recent theoreticaland methodological developments for random forests. Emphasis is placed on themathematical forces driving the algorithm, with special attention given to theselection of parameters, the resampling mechanism, and variable importancemeasures. This review is intended to provide non-experts easy access to themain ideas.
arxiv-14700-243 | Online learning in repeated auctions | http://arxiv.org/pdf/1511.05720v1.pdf | author:Jonathan Weed, Vianney Perchet, Philippe Rigollet category:cs.GT cs.LG stat.ML published:2015-11-18 summary:Motivated by online advertising auctions, we consider repeated Vickreyauctions where goods of unknown value are sold sequentially and bidders onlylearn (potentially noisy) information about a good's value once it ispurchased. We adopt an online learning approach with bandit feedback to modelthis problem and derive bidding strategies for two models: stochastic andadversarial. In the stochastic model, the observed values of the goods arerandom variables centered around the true value of the good. In this case,logarithmic regret is achievable when competing against well behavedadversaries. In the adversarial model, the goods need not be identical and wesimply compare our performance against that of the best fixed bid in hindsight.We show that sublinear regret is also achievable in this case and provematching minimax lower bounds. To our knowledge, this is the first complete setof strategies for bidders participating in auctions of this type.
arxiv-14700-244 | Complex-Valued Gaussian Processes for Regression: A Widely Non-Linear Approach | http://arxiv.org/pdf/1511.05710v1.pdf | author:Rafael Boloix-Tortosa, Eva Arias-de-Reyna, F. Javier Payan-Somet, Juan J. Murillo-Fuentes category:cs.LG published:2015-11-18 summary:In this paper we propose a novel Bayesian kernel based solution forregression in complex fields. We develop the formulation of the Gaussianprocess for regression (GPR) to deal with complex-valued outputs. Previoussolutions for kernels methods usually assume a complexification approach, wherethe real-valued kernel is replaced by a complex-valued one. However, based onthe results in complex-valued linear theory, we prove that both a kernel and apseudo-kernel are to be included in the solution. This is the starting point todevelop the new formulation for the complex-valued GPR. The obtainedformulation resembles the one of the widely linear minimum mean-squared(WLMMSE) approach. Just in the particular case where the outputs are proper,the pseudo-kernel cancels and the solution simplifies to a real-valued GPRstructure, as the WLMMSE does into a strictly linear solution. We include somenumerical experiments to show that the novel solution, denoted as widelynon-linear complex GPR (WCGPR), outperforms a strictly complex GPR where apseudo-kernel is not included.
arxiv-14700-245 | Efficient Output Kernel Learning for Multiple Tasks | http://arxiv.org/pdf/1511.05706v1.pdf | author:Pratik Jawanpuria, Maksim Lapin, Matthias Hein, Bernt Schiele category:stat.ML cs.LG published:2015-11-18 summary:The paradigm of multi-task learning is that one can achieve bettergeneralization by learning tasks jointly and thus exploiting the similaritybetween the tasks rather than learning them independently of each other. Whilepreviously the relationship between tasks had to be user-defined in the form ofan output kernel, recent approaches jointly learn the tasks and the outputkernel. As the output kernel is a positive semidefinite matrix, the resultingoptimization problems are not scalable in the number of tasks as aneigendecomposition is required in each step. \mbox{Using} the theory ofpositive semidefinite kernels we show in this paper that for a certain class ofregularizers on the output kernel, the constraint of being positivesemidefinite can be dropped as it is automatically satisfied for the relaxedproblem. This leads to an unconstrained dual problem which can be solvedefficiently. Experiments on several multi-task and multi-class data setsillustrate the efficacy of our approach in terms of computational efficiency aswell as generalization performance.
arxiv-14700-246 | A Distribution Adaptive Framework for Prediction Interval Estimation Using Nominal Variables | http://arxiv.org/pdf/1511.05688v2.pdf | author:Ameen Eetemadi, Ilias Tagkopoulos category:cs.LG published:2015-11-18 summary:Proposed methods for prediction interval estimation so far focus on caseswhere input variables are numerical. In datasets with solely nominal inputvariables, we observe records with the exact same input $x^u$, but differentreal valued outputs due to the inherent noise in the system. Existingprediction interval estimation methods do not use representations that canaccurately model such inherent noise in the case of nominal inputs. We proposea new prediction interval estimation method tailored for this type of data,which is prevalent in biology and medicine. We call this method DistributionAdaptive Prediction Interval Estimation given Nominal inputs (DAPIEN) and hasfour main phases. First, we select a distribution function that can bestrepresent the inherent noise of the system for all unique inputs. Then we inferthe parameters $\theta_i$ (e.g. $\theta_i=[mean_i, variance_i]$) of theselected distribution function for all unique input vectors $x^u_i$ andgenerate a new corresponding training set using pairs of $x^u_i, \theta_i$.III). Then, we train a model to predict $\theta$ given a new $x_u$. Finally, wecalculate the prediction interval for a new sample using the inverse of thecumulative distribution function once the parameters $\theta$ is predicted bythe trained model. We compared DAPIEN to the commonly used Bootstrap method onthree synthetic datasets. Our results show that DAPIEN provides tighterprediction intervals while preserving the requested coverage when compared toBootstrap. This work can facilitate broader usage of regression methods inmedicine and biology where it is necessary to provide tight predictionintervals while preserving coverage when input variables are nominal.
arxiv-14700-247 | Metric Learning with Adaptive Density Discrimination | http://arxiv.org/pdf/1511.05939v2.pdf | author:Oren Rippel, Manohar Paluri, Piotr Dollar, Lubomir Bourdev category:stat.ML cs.LG published:2015-11-18 summary:Distance metric learning (DML) approaches learn a transformation to arepresentation space where distance is in correspondence with a predefinednotion of similarity. While such models offer a number of compelling benefits,it has been difficult for these to compete with modern classificationalgorithms in performance and even in feature extraction. In this work, we propose a novel approach explicitly designed to address anumber of subtle yet important issues which have stymied earlier DMLalgorithms. It maintains an explicit model of the distributions of thedifferent classes in representation space. It then employs this knowledge toadaptively assess similarity, and achieve local discrimination by penalizingclass distribution overlap. We demonstrate the effectiveness of this idea on several tasks. Our approachachieves state-of-the-art classification results on a number of fine-grainedvisual recognition datasets, surpassing the standard softmax classifier andoutperforming triplet loss by a relative margin of 30-40%. In terms ofcomputational performance, it alleviates training inefficiencies in thetraditional triplet loss, reaching the same error in 5-30 times feweriterations. Beyond classification, we further validate the saliency of thelearnt representations via their attribute concentration and hierarchy recoveryproperties, achieving 10-25% relative gains on the softmax classifier and25-50% on triplet loss in these tasks.
arxiv-14700-248 | Local entropy as a measure for sampling solutions in Constraint Satisfaction Problems | http://arxiv.org/pdf/1511.05634v2.pdf | author:Carlo Baldassi, Alessandro Ingrosso, Carlo Lucibello, Luca Saglietti, Riccardo Zecchina category:stat.ML G.1.6; I.2.M published:2015-11-18 summary:We introduce a novel Entropy-driven Monte Carlo (EdMC) strategy toefficiently sample solutions of random Constraint Satisfaction Problems (CSPs).First, we extend a recent result that, using a large-deviation analysis, showsthat the geometry of the space of solutions of the Binary Perceptron LearningProblem (a prototypical CSP), contains regions of very high-density ofsolutions. Despite being sub-dominant, these regions can be found by optimizinga local entropy measure. Building on these results, we construct a fast solverthat relies exclusively on a local entropy estimate, and can be applied togeneral CSPs. We describe its performance not only for the Perceptron LearningProblem but also for the random $K$-Satisfiabilty Problem (another prototypicalCSP with a radically different structure), and show numerically that a simplezero-temperature Metropolis search in the smooth local entropy landscape canreach sub-dominant clusters of optimal solutions in a small number of steps,while standard Simulated Annealing either requires extremely long coolingprocedures or just fails. We also discuss how the EdMC can heuristically bemade even more efficient for the cases we studied.
arxiv-14700-249 | Staleness-aware Async-SGD for Distributed Deep Learning | http://arxiv.org/pdf/1511.05950v5.pdf | author:Wei Zhang, Suyog Gupta, Xiangru Lian, Ji Liu category:cs.LG published:2015-11-18 summary:Deep neural networks have been shown to achieve state-of-the-art performancein several machine learning tasks. Stochastic Gradient Descent (SGD) is thepreferred optimization algorithm for training these networks and asynchronousSGD (ASGD) has been widely adopted for accelerating the training of large-scaledeep networks in a distributed computing environment. However, in practice itis quite challenging to tune the training hyperparameters (such as learningrate) when using ASGD so as achieve convergence and linear speedup, since thestability of the optimization algorithm is strongly influenced by theasynchronous nature of parameter updates. In this paper, we propose a variantof the ASGD algorithm in which the learning rate is modulated according to thegradient staleness and provide theoretical guarantees for convergence of thisalgorithm. Experimental verification is performed on commonly-used imageclassification benchmarks: CIFAR10 and Imagenet to demonstrate the superioreffectiveness of the proposed approach, compared to SSGD (Synchronous SGD) andthe conventional ASGD algorithm.
arxiv-14700-250 | Compositional Memory for Visual Question Answering | http://arxiv.org/pdf/1511.05676v1.pdf | author:Aiwen Jiang, Fang Wang, Fatih Porikli, Yi Li category:cs.CV published:2015-11-18 summary:Visual Question Answering (VQA) emerges as one of the most fascinating topicsin computer vision recently. Many state of the art methods naively use holisticvisual features with language features into a Long Short-Term Memory (LSTM)module, neglecting the sophisticated interaction between them. This coarsemodeling also blocks the possibilities of exploring finer-grained localfeatures that contribute to the question answering dynamically over time. This paper addresses this fundamental problem by directly modeling thetemporal dynamics between language and all possible local image patches. Whentraversing the question words sequentially, our end-to-end approach explicitlyfuses the features associated to the words and the ones available at multiplelocal patches in an attention mechanism, and further combines the fusedinformation to generate dynamic messages, which we call episode. We then feedthe episodes to a standard question answering module together with thecontextual visual information and linguistic information. Motivated by recentpractices in deep learning, we use auxiliary loss functions during training toimprove the performance. Our experiments on two latest public datasets suggestthat our method has a superior performance. Notably, on the DARQUAR dataset weadvanced the state of the art by 6$\%$, and we also evaluated our approach onthe most recent MSCOCO-VQA dataset.
arxiv-14700-251 | Towards O(1) Seeding of K-Means | http://arxiv.org/pdf/1511.05933v5.pdf | author:Sayantan Dasgupta category:cs.LG published:2015-11-18 summary:K-means is one of the most widely used algorithms for clustering in DataMining applications, which attempts to minimize the sum of Euclidean distanceof the points in the clusters from the respective means of the clusters. Thesimplicity and scalability of K-means makes it very appealing. However, K-meanssuffers from local minima problem, and comes with no guarantee to converge tothe optimal cost. K-means++ tries to address the problem by seeding the meansusing a distance based sampling scheme. However, seeding the means in K-means++needs O(K) passes through the entire dataset, which could be very costly inlarge amount of dataset. Here we propose a method of seeding initial meansbased on higher order moments of the data, which takes O(1) passes through theentire dataset to extract the initial set of means. Our method yieldscompetitive performance with respect to all the existing K-means algorithms,whilst avoiding the expensive mean selection steps of K-means++ and otherheuristics. We demonstrate the performance of our algorithm in comparison withthe existing algorithms on various benchmark datasets.
arxiv-14700-252 | Net2Net: Accelerating Learning via Knowledge Transfer | http://arxiv.org/pdf/1511.05641v4.pdf | author:Tianqi Chen, Ian Goodfellow, Jonathon Shlens category:cs.LG published:2015-11-18 summary:We introduce techniques for rapidly transferring the information stored inone neural net into another neural net. The main purpose is to accelerate thetraining of a significantly larger neural net. During real-world workflows, oneoften trains very many different neural networks during the experimentation anddesign process. This is a wasteful process in which each new model is trainedfrom scratch. Our Net2Net technique accelerates the experimentation process byinstantaneously transferring the knowledge from a previous network to each newdeeper or wider network. Our techniques are based on the concept offunction-preserving transformations between neural network specifications. Thisdiffers from previous approaches to pre-training that altered the functionrepresented by a neural net when adding layers to it. Using our knowledgetransfer mechanism to add depth to Inception modules, we demonstrate a newstate of the art accuracy rating on the ImageNet dataset.
arxiv-14700-253 | ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering | http://arxiv.org/pdf/1511.05960v2.pdf | author:Kan Chen, Jiang Wang, Liang-Chieh Chen, Haoyuan Gao, Wei Xu, Ram Nevatia category:cs.CV published:2015-11-18 summary:We propose a novel attention based deep learning architecture for visualquestion answering task (VQA). Given an image and an image related naturallanguage question, VQA generates the natural language answer for the question.Generating the correct answers requires the model's attention to focus on theregions corresponding to the question, because different questions inquireabout the attributes of different image regions. We introduce an attentionbased configurable convolutional neural network (ABC-CNN) to learn suchquestion-guided attention. ABC-CNN determines an attention map for animage-question pair by convolving the image feature map with configurableconvolutional kernels derived from the question's semantics. We evaluate theABC-CNN architecture on three benchmark VQA datasets: Toronto COCO-QA, DAQUAR,and VQA dataset. ABC-CNN model achieves significant improvements overstate-of-the-art methods on these datasets. The question-guided attentiongenerated by ABC-CNN is also shown to reflect the regions that are highlyrelevant to the questions.
arxiv-14700-254 | Prioritized Experience Replay | http://arxiv.org/pdf/1511.05952v4.pdf | author:Tom Schaul, John Quan, Ioannis Antonoglou, David Silver category:cs.LG published:2015-11-18 summary:Experience replay lets online reinforcement learning agents remember andreuse experiences from the past. In prior work, experience transitions wereuniformly sampled from a replay memory. However, this approach simply replaystransitions at the same frequency that they were originally experienced,regardless of their significance. In this paper we develop a framework forprioritizing experience, so as to replay important transitions more frequently,and therefore learn more efficiently. We use prioritized experience replay inDeep Q-Networks (DQN), a reinforcement learning algorithm that achievedhuman-level performance across many Atari games. DQN with prioritizedexperience replay achieves a new state-of-the-art, outperforming DQN withuniform replay on 41 out of 49 games.
arxiv-14700-255 | Bayesian hypothesis testing for one bit compressed sensing with sensing matrix perturbation | http://arxiv.org/pdf/1511.05660v1.pdf | author:H. Zayyani, M. Korki, F. Marvasti category:stat.ML cs.IT math.IT published:2015-11-18 summary:This letter proposes a low-computational Bayesian algorithm for noisy sparserecovery in the context of one bit compressed sensing with sensing matrixperturbation. The proposed algorithm which is called BHT-MLE comprises a sparsesupport detector and an amplitude estimator. The support detector utilizesBayesian hypothesis test, while the amplitude estimator uses an ML estimatorwhich is obtained by solving a convex optimization problem. Simulation resultsshow that BHT-MLE algorithm offers more reconstruction accuracy than that of anML estimator (MLE) at a low computational cost.
arxiv-14700-256 | Alternative Markov and Causal Properties for Acyclic Directed Mixed Graphs | http://arxiv.org/pdf/1511.05835v4.pdf | author:Jose M. Peña category:stat.ML cs.AI published:2015-11-18 summary:We extend Andersson-Madigan-Perlman chain graphs by (i) relaxing thesemidirected acyclity constraint so that only directed cycles are forbidden,and (ii) allowing up to two edges between any pair of nodes. We introduceglobal, and ordered local and pairwise Markov properties for the new models. Weshow the equivalence of these properties for strictly positive probabilitydistributions. We also show that when the random variables are continuous, thenew models can be interpreted as systems of structural equations withcorrelated errors. This enables us to adapt Pearl's do-calculus to them.Finally, we describe an exact algorithm for learning the new models fromobservational and interventional data via answer set programming.
arxiv-14700-257 | Tree-Guided MCMC Inference for Normalized Random Measure Mixture Models | http://arxiv.org/pdf/1511.05650v1.pdf | author:Juho Lee, Seungjin Choi category:stat.ML cs.LG published:2015-11-18 summary:Normalized random measures (NRMs) provide a broad class of discrete randommeasures that are often used as priors for Bayesian nonparametric models.Dirichlet process is a well-known example of NRMs. Most of posterior inferencemethods for NRM mixture models rely on MCMC methods since they are easy toimplement and their convergence is well studied. However, MCMC often suffersfrom slow convergence when the acceptance rate is low. Tree-based inference isan alternative deterministic posterior inference method, where Bayesianhierarchical clustering (BHC) or incremental Bayesian hierarchical clustering(IBHC) have been developed for DP or NRM mixture (NRMM) models, respectively.Although IBHC is a promising method for posterior inference for NRMM models dueto its efficiency and applicability to online inference, its convergence is notguaranteed since it uses heuristics that simply selects the best solution aftermultiple trials are made. In this paper, we present a hybrid inferencealgorithm for NRMM models, which combines the merits of both MCMC and IBHC.Trees built by IBHC outlines partitions of data, which guidesMetropolis-Hastings procedure to employ appropriate proposals. Inheriting thenature of MCMC, our tree-guided MCMC (tgMCMC) is guaranteed to converge, andenjoys the fast convergence thanks to the effective proposals guided by trees.Experiments on both synthetic and real-world datasets demonstrate the benefitof our method.
arxiv-14700-258 | Adversarial Autoencoders | http://arxiv.org/pdf/1511.05644v1.pdf | author:Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow category:cs.LG published:2015-11-18 summary:In this paper we propose a new method for regularizing autoencoders byimposing an arbitrary prior on the latent representation of the autoencoder.Our method, named "adversarial autoencoder", uses the recently proposedgenerative adversarial networks (GAN) in order to match the aggregatedposterior of the hidden code vector of the autoencoder with an arbitrary prior.Matching the aggregated posterior to the prior ensures that there are no"holes" in the prior, and generating from any part of prior space results inmeaningful samples. As a result, the decoder of the adversarial autoencoderlearns a deep generative model that maps the imposed prior to the datadistribution. We show how adversarial autoencoders can be used to disentanglestyle and content of images and achieve competitive generative performance onMNIST, Street View House Numbers and Toronto Face datasets.
arxiv-14700-259 | A pilot study on the daily control capability of s-EMG prosthetic hands by amputees | http://arxiv.org/pdf/1511.06001v2.pdf | author:Francesca Giordaniello category:cs.LG cs.HC published:2015-11-18 summary:Surface electromyography is a valid tool to gather muscular contractionsignals from intact and amputated subjects. Electromyographic signals can beused to control prosthetic devices in a noninvasive way distinguishing themovements performed by the particular EMG electrodes activity. According to theliterature, several algorithms have been used to control prosthetic handsthrough s-EMG signals. The main issue is to correctly classify the signalsacquired as the movement actually performed. This work presents a study on theSupport Vector Machine's performance in a short-time period, gained using twodifferent feature representation (Mean Absolute Value and Waveform Length) ofthe sEMG signals. In particular, we paid close attention to the repeatabilityproblem, that is the capability to achieve a stable and satisfactory level ofaccuracy in repeated experiments. Results on a limited setting are encouraging,as they show an average accuracy above 73% even in the worst case scenario.
arxiv-14700-260 | ACDC: A Structured Efficient Linear Layer | http://arxiv.org/pdf/1511.05946v5.pdf | author:Marcin Moczulski, Misha Denil, Jeremy Appleyard, Nando de Freitas category:cs.LG cs.NE published:2015-11-18 summary:The linear layer is one of the most pervasive modules in deep learningrepresentations. However, it requires $O(N^2)$ parameters and $O(N^2)$operations. These costs can be prohibitive in mobile applications or preventscaling in many domains. Here, we introduce a deep, differentiable,fully-connected neural network module composed of diagonal matrices ofparameters, $\mathbf{A}$ and $\mathbf{D}$, and the discrete cosine transform$\mathbf{C}$. The core module, structured as $\mathbf{ACDC^{-1}}$, has $O(N)$parameters and incurs $O(N log N )$ operations. We present theoretical resultsshowing how deep cascades of ACDC layers approximate linear layers. ACDC is,however, a stand-alone module and can be used in combination with any othertypes of module. In our experiments, we show that it can indeed be successfullyinterleaved with ReLU modules in convolutional neural networks for imagerecognition. Our experiments also study critical factors in the training ofthese structured modules, including initialization and depth. Finally, thispaper also provides a connection between structured linear transforms used indeep learning and the field of Fourier optics, illustrating how ACDC could inprinciple be implemented with lenses and diffractive elements.
arxiv-14700-261 | A New Smooth Approximation to the Zero One Loss with a Probabilistic Interpretation | http://arxiv.org/pdf/1511.05643v1.pdf | author:Md Kamrul Hasan, Christopher J. Pal category:cs.CV cs.AI cs.IR cs.LG published:2015-11-18 summary:We examine a new form of smooth approximation to the zero one loss in whichlearning is performed using a reformulation of the widely used logisticfunction. Our approach is based on using the posterior mean of a novelgeneralized Beta-Bernoulli formulation. This leads to a generalized logisticfunction that approximates the zero one loss, but retains a probabilisticformulation conferring a number of useful properties. The approach is easilygeneralized to kernel logistic regression and easily integrated into methodsfor structured prediction. We present experiments in which we learn such modelsusing an optimization method consisting of a combination of gradient descentand coordinate descent using localized grid search so as to escape from localminima. Our experiments indicate that optimization quality is improved whenlearning meta-parameters are themselves optimized using a validation set. Ourexperiments show improved performance relative to widely used logistic andhinge loss methods on a wide variety of problems ranging from standard UCIrvine and libSVM evaluation datasets to product review predictions and avisual information extraction task. We observe that the approach: 1) is morerobust to outliers compared to the logistic and hinge losses; 2) outperformscomparable logistic and max margin models on larger scale benchmark problems;3) when combined with Gaussian- Laplacian mixture prior on parameters thekernelized version of our formulation yields sparser solutions than SupportVector Machine classifiers; and 4) when integrated into a probabilisticstructured prediction technique our approach provides more accurateprobabilities yielding improved inference and increasing information extractionperformance.
arxiv-14700-262 | Competitive Multi-scale Convolution | http://arxiv.org/pdf/1511.05635v1.pdf | author:Zhibin Liao, Gustavo Carneiro category:cs.CV cs.LG cs.NE published:2015-11-18 summary:In this paper, we introduce a new deep convolutional neural network (ConvNet)module that promotes competition among a set of multi-scale convolutionalfilters. This new module is inspired by the inception module, where we replacethe original collaborative pooling stage (consisting of a concatenation of themulti-scale filter outputs) by a competitive pooling represented by a maxoutactivation unit. This extension has the following two objectives: 1) theselection of the maximum response among the multi-scale filters prevents filterco-adaptation and allows the formation of multiple sub-networks within the samemodel, which has been shown to facilitate the training of complex learningproblems; and 2) the maxout unit reduces the dimensionality of the outputs fromthe multi-scale filters. We show that the use of our proposed module in typicaldeep ConvNets produces classification results that are either better than orcomparable to the state of the art on the following benchmark datasets: MNIST,CIFAR-10, CIFAR-100 and SVHN.
arxiv-14700-263 | MOEA/D-GM: Using probabilistic graphical models in MOEA/D for solving combinatorial optimization problems | http://arxiv.org/pdf/1511.05625v1.pdf | author:Murilo Zangari de Souza, Roberto Santana, Aurora Trinidad Ramirez Pozo, Alexander Mendiburu category:cs.NE published:2015-11-18 summary:Evolutionary algorithms based on modeling the statistical dependencies(interactions) between the variables have been proposed to solve a wide rangeof complex problems. These algorithms learn and sample probabilistic graphicalmodels able to encode and exploit the regularities of the problem. This paperinvestigates the effect of using probabilistic modeling techniques as a way toenhance the behavior of MOEA/D framework. MOEA/D is a decomposition basedevolutionary algorithm that decomposes a multi-objective optimization problem(MOP) in a number of scalar single-objective subproblems and optimizes them ina collaborative manner. MOEA/D framework has been widely used to solve severalMOPs. The proposed algorithm, MOEA/D using probabilistic Graphical Models(MOEA/D-GM) is able to instantiate both univariate and multi-variateprobabilistic models for each subproblem. To validate the introduced frameworkalgorithm, an experimental study is conducted on a multi-objective version ofthe deceptive function Trap5. The results show that the variant of theframework (MOEA/D-Tree), where tree models are learned from the matrices of themutual information between the variables, is able to capture the structure ofthe problem. MOEA/D-Tree is able to achieve significantly better results thanboth MOEA/D using genetic operators and MOEA/D using univariate probabilitymodels, in terms of the approximation to the true Pareto front.
arxiv-14700-264 | Censoring Representations with an Adversary | http://arxiv.org/pdf/1511.05897v3.pdf | author:Harrison Edwards, Amos Storkey category:cs.LG cs.AI stat.ML published:2015-11-18 summary:In practice, there are often explicit constraints on what representations ordecisions are acceptable in an application of machine learning. For example itmay be a legal requirement that a decision must not favour a particular group.Alternatively it can be that that representation of data must not haveidentifying information. We address these two related issues by learningflexible representations that minimize the capability of an adversarial critic.This adversary is trying to predict the relevant sensitive variable from therepresentation, and so minimizing the performance of the adversary ensuresthere is little or no information in the representation about the sensitivevariable. We demonstrate this adversarial approach on two problems: makingdecisions free from discrimination and removing private information fromimages. We formulate the adversarial model as a minimax problem, and optimizethat minimax objective using a stochastic gradient alternate min-max optimizer.We demonstrate the ability to provide discriminant free representations forstandard test problems, and compare with previous state of the art methods forfairness, showing statistically significant improvement across most cases. Theflexibility of this method is shown via a novel problem: removing annotationsfrom images, from unaligned training examples of annotated and unannotatedimages, and with no a priori knowledge of the form of annotation provided tothe model.
arxiv-14700-265 | Doctor AI: Predicting Clinical Events via Recurrent Neural Networks | http://arxiv.org/pdf/1511.05942v8.pdf | author:Edward Choi, Mohammad Taha Bahadori, Andy Schuetz, Walter F. Stewart, Jimeng Sun category:cs.LG published:2015-11-18 summary:Large amount of Electronic Health Record (EHR) data have been collected overmillions of patients over multiple years. The rich longitudinal EHR datadocumented the collective experiences of physicians including diagnosis,medication prescription and procedures. We argue it is possible now to leveragethe EHR data to model how physicians behave, and we call our model Doctor AI.Towards this direction of modeling clinical behavior of physicians, we developa successful application of Recurrent Neural Networks (RNN) to jointly forecastthe future disease diagnosis and medication prescription along with theirtiming. Unlike traditional classification models where a single target is ofinterest, our model can assess the entire history of patients and makecontinuous and multilabel predictions based on patients' historical data. Weevaluate the performance of the proposed method on a large real-world EHR dataover 260K patients over 8 years. We observed Doctor AI can perform differentialdiagnosis with similar accuracy to physicians. In particular, Doctor AIachieves up to 79% recall@30, significantly higher than several baselines.Moreover, we demonstrate great generalizability of Doctor AI by applying theresulting models on data from a completely different medication institutionachieving comparable performance.
arxiv-14700-266 | Segmental Recurrent Neural Networks | http://arxiv.org/pdf/1511.06018v2.pdf | author:Lingpeng Kong, Chris Dyer, Noah A. Smith category:cs.CL cs.LG published:2015-11-18 summary:We introduce segmental recurrent neural networks (SRNNs) which define, givenan input sequence, a joint probability distribution over segmentations of theinput and labelings of the segments. Representations of the input segments(i.e., contiguous subsequences of the input) are computed by encoding theirconstituent tokens using bidirectional recurrent neural nets, and these"segment embeddings" are used to define compatibility scores with outputlabels. These local compatibility scores are integrated using a globalsemi-Markov conditional random field. Both fully supervised training -- inwhich segment boundaries and labels are observed -- as well as partiallysupervised training -- in which segment boundaries are latent -- arestraightforward. Experiments on handwriting recognition and joint Chinese wordsegmentation/POS tagging show that, compared to models that do not explicitlyrepresent segments such as BIO tagging schemes and connectionist temporalclassification (CTC), SRNNs obtain substantially higher accuracies.
arxiv-14700-267 | Particular object retrieval with integral max-pooling of CNN activations | http://arxiv.org/pdf/1511.05879v2.pdf | author:Giorgos Tolias, Ronan Sicre, Hervé Jégou category:cs.CV published:2015-11-18 summary:Recently, image representation built upon Convolutional Neural Network (CNN)has been shown to provide effective descriptors for image search, outperformingpre-CNN features as short-vector representations. Yet such models are notcompatible with geometry-aware re-ranking methods and still outperformed, onsome particular object retrieval benchmarks, by traditional image searchsystems relying on precise descriptor matching, geometric re-ranking, or queryexpansion. This work revisits both retrieval stages, namely initial search andre-ranking, by employing the same primitive information derived from the CNN.We build compact feature vectors that encode several image regions without theneed to feed multiple inputs to the network. Furthermore, we extend integralimages to handle max-pooling on convolutional layer activations, allowing us toefficiently localize matching objects. The resulting bounding box is finallyused for image re-ranking. As a result, this paper significantly improvesexisting CNN-based recognition pipeline: We report for the first time resultscompeting with traditional methods on the challenging Oxford5k and Paris6kdatasets.
arxiv-14700-268 | Expressiveness of Rectifier Networks | http://arxiv.org/pdf/1511.05678v2.pdf | author:Xingyuan Pan, Vivek Srikumar category:cs.LG published:2015-11-18 summary:Rectified Linear Units (ReLUs) have been shown to ameliorate the vanishinggradient problem, allow for efficient backpropagation, and empirically promotesparsity in the learned parameters. Their use has led to state-of-the-artresults in a variety of applications. In this paper, we characterize theexpressiveness of ReLU networks. From this perspective, unlike the sign(threshold) and sigmoid activations, ReLU networks are less explored. We showthat, while the decision boundary of a two-layer ReLU network can be capturedby a sign network, the sign network can require an exponentially larger numberof hidden units. Furthermore, we formulate sufficient conditions for acorresponding logarithmic reduction in the number of hidden units to representa sign network as a ReLU network. Finally, using synthetic data, weexperimentally demonstrate that back propagation can recover the much smallerReLU networks as predicted by the theory.
arxiv-14700-269 | Fast Saddle-Point Algorithm for Generalized Dantzig Selector and FDR Control with the Ordered l1-Norm | http://arxiv.org/pdf/1511.05864v2.pdf | author:Sangkyun Lee, Damian Brzyski, Malgorzata Bogdan category:stat.ML math.OC published:2015-11-18 summary:In this paper we propose a primal-dual proximal extragradient algorithm tosolve the generalized Dantzig selector (GDS) estimation problem, based on a newconvex-concave saddle-point (SP) reformulation. Our new formulation makes itpossible to adopt recent developments in saddle-point optimization, to achievethe optimal $O(1/k)$ rate of convergence. Compared to the optimal non-SPalgorithms, ours do not require specification of sensitive parameters thataffect algorithm performance or solution quality. We also provide a newanalysis showing a possibility of local acceleration to achieve the rate of$O(1/k^2)$ in special cases even without strong convexity or strong smoothness.As an application, we propose a GDS equipped with the ordered $\ell_1$-norm,showing its false discovery rate control properties in variable selection.Algorithm performance is compared between ours and other alternatives,including the linearized ADMM, Nesterov's smoothing, Nemirovski's mirror-prox,and the accelerated hybrid proximal extragradient techniques.
arxiv-14700-270 | Super-Resolution with Deep Convolutional Sufficient Statistics | http://arxiv.org/pdf/1511.05666v4.pdf | author:Joan Bruna, Pablo Sprechmann, Yann LeCun category:cs.CV published:2015-11-18 summary:Inverse problems in image and audio, and super-resolution in particular, canbe seen as high-dimensional structured prediction problems, where the goal isto characterize the conditional distribution of a high-resolution output givenits low-resolution corrupted observation. When the scaling ratio is small,point estimates achieve impressive performance, but soon they suffer from theregression-to-the-mean problem, result of their inability to capture themulti-modality of this conditional distribution. Modeling high-dimensionalimage and audio distributions is a hard task, requiring both the ability tomodel complex geometrical structures and textured regions. In this paper, wepropose to use as conditional model a Gibbs distribution, where its sufficientstatistics are given by deep convolutional neural networks. The featurescomputed by the network are stable to local deformation, and have reducedvariance when the input is a stationary texture. These properties imply thatthe resulting sufficient statistics minimize the uncertainty of the targetsignals given the degraded observations, while being highly informative. Thefilters of the CNN are initialized by multiscale complex wavelets, and then wepropose an algorithm to fine-tune them by estimating the gradient of theconditional log-likelihood, which bears some similarities with GenerativeAdversarial Networks. We evaluate experimentally the proposed approach in theimage super-resolution task, but the approach is general and could be used inother challenging ill-posed problems such as audio bandwidth extension.
arxiv-14700-271 | Regret Analysis of the Finite-Horizon Gittins Index Strategy for Multi-Armed Bandits | http://arxiv.org/pdf/1511.06014v2.pdf | author:Tor Lattimore category:cs.LG math.ST stat.ML stat.TH published:2015-11-18 summary:I analyse the frequentist regret of the famous Gittins index strategy formulti-armed bandits with Gaussian noise and a finite horizon. Remarkably itturns out that this approach leads to finite-time regret guarantees comparableto those available for the popular UCB algorithm. Along the way I derivefinite-time bounds on the Gittins index that are asymptotically exact and maybe of independent interest. I also discuss some computational issues andpresent experimental results suggesting that a particular version of theGittins index strategy is a modest improvement on existing algorithms withfinite-time regret guarantees such as UCB and Thompson sampling.
arxiv-14700-272 | Learning the Architecture of Deep Neural Networks | http://arxiv.org/pdf/1511.05497v1.pdf | author:Suraj Srinivas, R. Venkatesh Babu category:cs.LG cs.CV cs.NE published:2015-11-17 summary:Deep neural networks with millions of parameters are at the heart of manystate of the art machine learning models today. However, recent works haveshown that models with much smaller number of parameters can also perform justas well. In this work, we introduce the problem of architecture-learning, i.e;learning the architecture of a neural network along with weights. We introducea new trainable parameter called tri-state ReLU, which helps in eliminatingunnecessary neurons. We also propose a smooth regularizer which encourages thetotal number of neurons after elimination to be small. The resulting objectiveis differentiable and simple to optimize. We experimentally validate our methodon both small and large networks, and show that it can learn models with aconsiderably small number of parameters without affecting prediction accuracy.
arxiv-14700-273 | Accelerating pseudo-marginal Metropolis-Hastings by correlating auxiliary variables | http://arxiv.org/pdf/1511.05483v1.pdf | author:Johan Dahlin, Fredrik Lindsten, Joel Kronander, Thomas B. Schön category:stat.CO stat.ML published:2015-11-17 summary:Pseudo-marginal Metropolis-Hastings (pmMH) is a powerful method for Bayesianinference in models where the posterior distribution is analytical intractableor computationally costly to evaluate directly. It operates by introducingadditional auxiliary variables into the model and form an extended targetdistribution, which then can be evaluated point-wise. In many cases, thestandard Metropolis-Hastings is then applied to sample from the extended targetand the sought posterior can be obtained by marginalisation. However, in someimplementations this approach suffers from poor mixing as the auxiliaryvariables are sampled from an independent proposal. We propose a modificationto the pmMH algorithm in which a Crank-Nicolson (CN) proposal is used instead.This results in that we introduce a positive correlation in the auxiliaryvariables. We investigate how to tune the CN proposal and its impact on themixing of the resulting pmMH sampler. The conclusion is that the proposedmodification can have a beneficial effect on both the mixing of the Markovchain and the computational cost for each iteration of the pmMH algorithm.
arxiv-14700-274 | A Block Regression Model for Short-Term Mobile Traffic Forecasting | http://arxiv.org/pdf/1511.05612v1.pdf | author:Huimin Pan, Jingchu Liu, Sheng Zhou, Zhisheng Niu category:cs.NI cs.LG published:2015-11-17 summary:Accurate mobile traffic forecast is important for efficient network planningand operations. However, existing traffic forecasting models have highcomplexity, making the forecasting process slow and costly. In this paper, weanalyze some characteristics of mobile traffic such as periodicity, spatialsimilarity and short term relativity. Based on these characteristics, wepropose a \emph{Block Regression} ({BR}) model for mobile traffic forecasting.This model employs seasonal differentiation so as to take into account of thetemporally repetitive nature of mobile traffic. One of the key features of our{BR} model lies in its low complexity since it constructs a single model forall base stations. We evaluate the accuracy of {BR} model based on real trafficdata and compare it with the existing models. Results show that our {BR} modeloffers equal accuracy to the existing models but has much less complexity.
arxiv-14700-275 | Extending Gossip Algorithms to Distributed Estimation of U-Statistics | http://arxiv.org/pdf/1511.05464v1.pdf | author:Igor Colin, Aurélien Bellet, Joseph Salmon, Stéphan Clémençon category:stat.ML cs.DC cs.LG cs.SY published:2015-11-17 summary:Efficient and robust algorithms for decentralized estimation in networks areessential to many distributed systems. Whereas distributed estimation of samplemean statistics has been the subject of a good deal of attention, computationof $U$-statistics, relying on more expensive averaging over pairs ofobservations, is a less investigated area. Yet, such data functionals areessential to describe global properties of a statistical population, withimportant examples including Area Under the Curve, empirical variance, Ginimean difference and within-cluster point scatter. This paper proposes newsynchronous and asynchronous randomized gossip algorithms which simultaneouslypropagate data across the network and maintain local estimates of the$U$-statistic of interest. We establish convergence rate bounds of $O(1/t)$ and$O(\log t / t)$ for the synchronous and asynchronous cases respectively, where$t$ is the number of iterations, with explicit data and network dependentterms. Beyond favorable comparisons in terms of rate analysis, numericalexperiments provide empirical evidence the proposed algorithms surpasses thepreviously introduced approach.
arxiv-14700-276 | Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering | http://arxiv.org/pdf/1511.05234v2.pdf | author:Huijuan Xu, Kate Saenko category:cs.CV cs.AI cs.CL cs.NE published:2015-11-17 summary:We address the problem of Visual Question Answering (VQA), which requiresjoint image and language understanding to answer a question about a givenphotograph. Recent approaches have applied deep image captioning methods basedon convolutional-recurrent networks to this problem, but have failed to modelspatial inference. To remedy this, we propose a model we call the SpatialMemory Network and apply it to the VQA task. Memory networks are recurrentneural networks with an explicit attention mechanism that selects certain partsof the information stored in memory. Our Spatial Memory Network stores neuronactivations from different spatial regions of the image in its memory, and usesthe question to choose relevant regions for computing the answer, a process ofwhich constitutes a single "hop" in the network. We propose a novel spatialattention architecture that aligns words with image patches in the first hop,and obtain improved results by adding a second attention hop which considersthe whole question to choose visual evidence based on the results of the firsthop. To better understand the inference process learned by the network, wedesign synthetic questions that specifically require spatial inference andvisualize the attention weights. We evaluate our model on two published visualquestion answering datasets, DAQUAR [1] and VQA [2], and obtain improvedresults compared to a strong deep baseline model (iBOWIMG) which concatenatesimage and question features to predict the answer [3].
arxiv-14700-277 | Recurrent Neural Networks Hardware Implementation on FPGA | http://arxiv.org/pdf/1511.05552v4.pdf | author:Andre Xian Ming Chang, Berin Martini, Eugenio Culurciello category:cs.NE published:2015-11-17 summary:Recurrent Neural Networks (RNNs) have the ability to retain memory and learndata sequences. Due to the recurrent nature of RNNs, it is sometimes hard toparallelize all its computations on conventional hardware. CPUs do notcurrently offer large parallelism, while GPUs offer limited parallelism due tosequential components of RNN models. In this paper we present a hardwareimplementation of Long-Short Term Memory (LSTM) recurrent network on theprogrammable logic Zynq 7020 FPGA from Xilinx. We implemented a RNN with $2$layers and $128$ hidden units in hardware and it has been tested using acharacter level language model. The implementation is more than $21\times$faster than the ARM CPU embedded on the Zynq 7020 FPGA. This work canpotentially evolve to a RNN co-processor for future mobile devices.
arxiv-14700-278 | Reduced-Precision Strategies for Bounded Memory in Deep Neural Nets | http://arxiv.org/pdf/1511.05236v4.pdf | author:Patrick Judd, Jorge Albericio, Tayler Hetherington, Tor Aamodt, Natalie Enright Jerger, Raquel Urtasun, Andreas Moshovos category:cs.LG cs.NE published:2015-11-17 summary:This work investigates how using reduced precision data in ConvolutionalNeural Networks (CNNs) affects network accuracy during classification. Morespecifically, this study considers networks where each layer may use differentprecision data. Our key result is the observation that the tolerance of CNNs toreduced precision data not only varies across networks, a well establishedobservation, but also within networks. Tuning precision per layer is appealingas it could enable energy and performance improvements. In this paper we studyhow error tolerance across layers varies and propose a method for finding a lowprecision configuration for a network while maintaining high accuracy. Adiverse set of CNNs is analyzed showing that compared to a conventionalimplementation using a 32-bit floating-point representation for all layers, andwith less than 1% loss in relative accuracy, the data footprint required bythese networks can be reduced by an average of 74% and up to 92%.
arxiv-14700-279 | Simple, Fast and Accurate Photometric Estimation of Specific Star Formation Rate | http://arxiv.org/pdf/1511.05424v1.pdf | author:Kristoffer Stensbo-Smidt, Fabian Gieseke, Christian Igel, Andrew Zirm, Kim Steenstrup Pedersen category:astro-ph.IM stat.ML published:2015-11-17 summary:Large-scale surveys make huge amounts of photometric data available. Becauseof the sheer amount of objects, spectral data cannot be obtained for all ofthem. Therefore it is important to devise techniques for reliably estimatingphysical properties of objects from photometric information alone. Theseestimates are needed to automatically identify interesting objects worth afollow-up investigation as well as to produce the required data for astatistical analysis of the space covered by a survey. We argue that machinelearning techniques are suitable to compute these estimates accurately andefficiently. This study considers the task of estimating the specific starformation rate (sSFR) of galaxies. It is shown that a nearest neighboursalgorithm can produce better sSFR estimates than traditional SED fitting. Weshow that we can obtain accurate estimates of the sSFR even at high redshiftsusing only broad-band photometry based on the u, g, r, i and z filters fromSloan Digital Sky Survey (SDSS). We addtionally demonstrate that combiningmagnitudes estimated with different methods from the same photometry can leadto a further improvement in accuracy. The study highlights the generalimportance of performing proper model selection to improve the results ofmachine learning systems and how feature selection can provide insights intothe predictive relevance of particular input features. Furthermore, the use ofmassively parallel computation on graphics processing units (GPUs) for handlinglarge amounts of astronomical data is advocated.
arxiv-14700-280 | Learning Structured Inference Neural Networks with Label Relations | http://arxiv.org/pdf/1511.05616v3.pdf | author:Hexiang Hu, Guang-Tong Zhou, Zhiwei Deng, Zicheng Liao, Greg Mori category:cs.CV cs.LG published:2015-11-17 summary:Images of scenes have various objects as well as abundant attributes, anddiverse levels of visual categorization are possible. A natural image could beassigned with fine-grained labels that describe major components,coarse-grained labels that depict high level abstraction or a set of labelsthat reveal attributes. Such categorization at different concept layers can bemodeled with label graphs encoding label information. In this paper, we exploitthis rich information with a state-of-art deep learning framework, and proposea generic structured model that leverages diverse label relations to improveimage classification performance. Our approach employs a novel stacked labelprediction neural network, capturing both inter-level and intra-level labelsemantics. We evaluate our method on benchmark image datasets, and empiricalresults illustrate the efficacy of our model.
arxiv-14700-281 | Structural-RNN: Deep Learning on Spatio-Temporal Graphs | http://arxiv.org/pdf/1511.05298v3.pdf | author:Ashesh Jain, Amir R. Zamir, Silvio Savarese, Ashutosh Saxena category:cs.CV cs.LG cs.NE cs.RO published:2015-11-17 summary:Deep Recurrent Neural Network architectures, though remarkably capable atmodeling sequences, lack an intuitive high-level spatio-temporal structure.That is while many problems in computer vision inherently have an underlyinghigh-level structure and can benefit from it. Spatio-temporal graphs are apopular tool for imposing such high-level intuitions in the formulation of realworld problems. In this paper, we propose an approach for combining the powerof high-level spatio-temporal graphs and sequence learning success of RecurrentNeural Networks~(RNNs). We develop a scalable method for casting an arbitraryspatio-temporal graph as a rich RNN mixture that is feedforward, fullydifferentiable, and jointly trainable. The proposed method is generic andprincipled as it can be used for transforming any spatio-temporal graph throughemploying a certain set of well defined steps. The evaluations of the proposedapproach on a diverse set of problems, ranging from modeling human motion toobject interactions, shows improvement over the state-of-the-art with a largemargin. We expect this method to empower new approaches to problem formulationthrough high-level spatio-temporal graphs and Recurrent Neural Networks.
arxiv-14700-282 | Hierarchical Spatial Sum-Product Networks for action recognition in Still Images | http://arxiv.org/pdf/1511.05292v2.pdf | author:Jinghua Wang, Gang Wang category:cs.CV published:2015-11-17 summary:Recognizing actions from still images is popularly studied recently. In thispaper, we model an action class as a flexible number of spatial configurationsof body parts by proposing a new spatial SPN (Sum-Product Networks). First, wediscover a set of parts in image collections via unsupervised learning. Then,our new spatial SPN is applied to model the spatial relationship and also thehigh-order correlations of parts. To learn robust networks, we further developa hierarchical spatial SPN method, which models pairwise spatial relationshipbetween parts inside sub-images and models the correlation of sub-images viaextra layers of SPN. Our method is shown to be effective on two benchmarkdatasets.
arxiv-14700-283 | Towards Predicting the Likeability of Fashion Images | http://arxiv.org/pdf/1511.05296v2.pdf | author:Jinghua Wang, Abrar Abdul Nabi, Gang Wang, Chengde Wan, Tian-Tsong Ng category:cs.CV published:2015-11-17 summary:In this paper, we propose a method for ranking fashion images to find theones which might be liked by more people. We collect two new datasets fromimage sharing websites (Pinterest and Polyvore). We represent fashion imagesbased on attributes: semantic attributes and data-driven attributes. To learnsemantic attributes from limited training data, we use an algorithm onmulti-task convolutional neural networks to share visual knowledge amongdifferent semantic attribute categories. To discover data-driven attributesunsupervisedly, we propose an algorithm to simultaneously discover visualclusters and learn fashion-specific feature representations. Given attributesas representations, we propose to learn a ranking SPN (sum product networks) torank pairs of fashion images. The proposed ranking SPN can capture thehigh-order correlations of the attributes. We show the effectiveness of ourmethod on our two newly collected datasets.
arxiv-14700-284 | Bayesian Optimization with Dimension Scheduling: Application to Biological Systems | http://arxiv.org/pdf/1511.05385v1.pdf | author:Doniyor Ulmasov, Caroline Baroukh, Benoit Chachuat, Marc Peter Deisenroth, Ruth Misener category:stat.ML cs.LG math.OC published:2015-11-17 summary:Bayesian Optimization (BO) is a data-efficient method for global black-boxoptimization of an expensive-to-evaluate fitness function. BO typically assumesthat computation cost of BO is cheap, but experiments are time consuming orcostly. In practice, this allows us to optimize ten or fewer criticalparameters in up to 1,000 experiments. But experiments may be less expensivethan BO methods assume: In some simulation models, we may be able to conductmultiple thousands of experiments in a few hours, and the computational burdenof BO is no longer negligible compared to experimentation time. To address thischallenge we introduce a new Dimension Scheduling Algorithm (DSA), whichreduces the computational burden of BO for many experiments. The key idea isthat DSA optimizes the fitness function only along a small set of dimensions ateach iteration. This DSA strategy (1) reduces the necessary computation time,(2) finds good solutions faster than the traditional BO method, and (3) can beparallelized straightforwardly. We evaluate the DSA in the context ofoptimizing parameters of dynamic models of microalgae metabolism and showfaster convergence than traditional BO.
arxiv-14700-285 | AUC-maximized Deep Convolutional Neural Fields for Sequence Labeling | http://arxiv.org/pdf/1511.05265v2.pdf | author:Sheng Wang, Siqi Sun, Jinbo Xu category:stat.ML cs.LG published:2015-11-17 summary:Deep Convolutional Neural Networks (DCNN) has shown excellent performance ina variety of machine learning tasks. This manuscript presents DeepConvolutional Neural Fields (DeepCNF), a combination of DCNN with ConditionalRandom Field (CRF), for sequence labeling with highly imbalanced labeldistribution. The widely-used training methods, such as maximum-likelihood andmaximum labelwise accuracy, do not work well on highly imbalanced data. Tohandle this, we present a new training algorithm called maximum-AUC forDeepCNF. That is, we train DeepCNF by directly maximizing the empirical AreaUnder the ROC Curve (AUC), which is an unbiased measurement for imbalanceddata. To fulfill this, we formulate AUC in a pairwise ranking framework,approximate it by a polynomial function and then apply a gradient-basedprocedure to optimize it. We then test our AUC-maximized DeepCNF on three verydifferent protein sequence labeling tasks: solvent accessibility prediction,8-state secondary structure prediction, and disorder prediction. Ourexperimental results confirm that maximum-AUC greatly outperforms the other twotraining methods on 8-state secondary structure prediction and disorderprediction since their label distributions are highly imbalanced and also havesimilar performance as the other two training methods on the solventaccessibility prediction problem which has three equally-distributed labels.Furthermore, our experimental results also show that our AUC-trained DeepCNFmodels greatly outperform existing popular predictors of these three tasks.
arxiv-14700-286 | Infinite Dimensional Word Embeddings | http://arxiv.org/pdf/1511.05392v2.pdf | author:Eric Nalisnick, Sachin Ravi category:stat.ML cs.CL cs.LG published:2015-11-17 summary:We describe a method for learning word embeddings with stochasticdimensionality. Our Infinite Skip-Gram (iSG) model specifies an energy-basedjoint distribution over a word vector, a context vector, and theirdimensionality. By employing the same techniques used to make the InfiniteRestricted Boltzmann Machine (Cote & Larochelle, 2015) tractable, we definevector dimensionality over a countably infinite domain, allowing vectors togrow as needed during training. After training, we find that the distributionover embedding dimensionality for a given word is highly interpretable andleads to an elegant probabilistic mechanism for word sense induction. We showqualitatively and quantitatively that the iSG produces parameter-efficientrepresentations that are robust to language's inherent ambiguity.
arxiv-14700-287 | Learning to retrieve out-of-vocabulary words in speech recognition | http://arxiv.org/pdf/1511.05389v4.pdf | author:Imran Sheikh, Irina Illina, Dominique Fohr, Georges Linarès category:cs.CL published:2015-11-17 summary:Many Proper Names (PNs) are Out-Of-Vocabulary (OOV) words for speechrecognition systems used to process diachronic audio data. To help recovery ofthe PNs missed by the system, relevant OOV PNs can be retrieved out of the manyOOVs by exploiting semantic context of the spoken content. In this paper, wepropose two neural network models targeted to retrieve OOV PNs relevant to anaudio document: (a) Document level Continuous Bag of Words (D-CBOW), (b)Document level Continuous Bag of Weighted Words (D-CBOW2). Both these modelstake document words as input and learn with an objective to maximise theretrieval of co-occurring OOV PNs. With the D-CBOW2 model we propose a newapproach in which the input embedding layer is augmented with a context anchorlayer. This layer learns to assign importance to input words and has theability to capture (task specific) key-words in a bag-of-word neural networkmodel. With experiments on French broadcast news videos we show that these twomodels outperform the baseline methods based on raw embeddings from LDA,Skip-gram and Paragraph Vectors. Combining the D-CBOW and D-CBOW2 models givesfaster convergence during training.
arxiv-14700-288 | Identifying the Absorption Bump with Deep Learning | http://arxiv.org/pdf/1511.05607v2.pdf | author:Min Li, Sudeep Gaddam, Xiaolin Li, Yinan Zhao, Jingzhe Ma, Jian Ge category:cs.CV cs.LG cs.NE published:2015-11-17 summary:The pervasive interstellar dust grains provide significant insights tounderstand the formation and evolution of the stars, planetary systems, and thegalaxies, and may harbor the building blocks of life. One of the most effectiveway to analyze the dust is via their interaction with the light from backgroundsources. The observed extinction curves and spectral features carry the sizeand composition information of dust. The broad absorption bump at 2175 Angstromis the most prominent feature in the extinction curves. Traditionally,statistical methods are applied to detect the existence of the absorption bump.These methods require heavy preprocessing and the co-existence of otherreference features to alleviate the influence from the noises. In this paper,we apply Deep Learning techniques to detect the broad absorption bump. Wedemonstrate the key steps for training the selected models and their results.The success of Deep Learning based method inspires us to generalize a commonmethodology for broader science discovery problems. We present our on-goingwork to build the DeepDis system for such kind of applications.
arxiv-14700-289 | Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization | http://arxiv.org/pdf/1511.05432v3.pdf | author:Uri Shaham, Yutaro Yamada, Sahand Negahban category:stat.ML cs.LG cs.NE published:2015-11-17 summary:We propose a general framework for increasing local stability of ArtificialNeural Nets (ANNs) using Robust Optimization (RO). We achieve this through analternating minimization-maximization procedure, in which the loss of thenetwork is minimized over perturbed examples that are generated at eachparameter update. We show that adversarial training of ANNs is in factrobustification of the network optimization, and that our proposed frameworkgeneralizes previous approaches for increasing local stability of ANNs.Experimental results reveal that our approach increases the robustness of thenetwork to existing adversarial examples, while making it harder to generatenew ones. Furthermore, our algorithm improves the accuracy of the network alsoon the original test data.
arxiv-14700-290 | Moral Lineage Tracing | http://arxiv.org/pdf/1511.05512v1.pdf | author:Florian Jug, Evgeny Levinkov, Corinna Blasse, Eugene W. Myers, Bjoern Andres category:cs.CV cs.DM published:2015-11-17 summary:Lineage tracing, the tracking of living cells as they move and divide, is acentral problem in biological image analysis. Solutions, called lineageforests, are key to understanding how the structure of multicellular organismsemerges. We propose an integer linear program (ILP) whose feasible solutionsdefine a decomposition of each image in a sequence into cells (segmentation),and a lineage forest of cells across images (tracing). Unlike previousformulations, we do not constrain the set of decompositions, except bycontracting pixels to superpixels. The main challenge, as we show, is toenforce the morality of lineages, i.e., the constraint that cells do not merge.To enforce morality, we introduce path-cut inequalities. To find feasiblesolutions of the NP-hard ILP, with certified bounds to the global optimum, wedefine efficient separation procedures and apply these as part of abranch-and-cut algorithm. We show the effectiveness of this approach byanalyzing feasible solutions for real microscopy data in terms of bounds andrun-time, and by their weighted edit distance to ground truth lineage foreststraced by humans.
arxiv-14700-291 | Gated Graph Sequence Neural Networks | http://arxiv.org/pdf/1511.05493v3.pdf | author:Yujia Li, Daniel Tarlow, Marc Brockschmidt, Richard Zemel category:cs.LG cs.AI cs.NE stat.ML published:2015-11-17 summary:Graph-structured data appears frequently in domains including chemistry,natural language semantics, social networks, and knowledge bases. In this work,we study feature learning techniques for graph-structured inputs. Our startingpoint is previous work on Graph Neural Networks (Scarselli et al., 2009), whichwe modify to use gated recurrent units and modern optimization techniques andthen extend to output sequences. The result is a flexible and broadly usefulclass of neural network models that has favorable inductive biases relative topurely sequence-based models (e.g., LSTMs) when the problem isgraph-structured. We demonstrate the capabilities on some simple AI (bAbI) andgraph algorithm learning tasks. We then show it achieves state-of-the-artperformance on a problem from program verification, in which subgraphs need tobe matched to abstract data structures.
arxiv-14700-292 | Deep multi-scale video prediction beyond mean square error | http://arxiv.org/pdf/1511.05440v6.pdf | author:Michael Mathieu, Camille Couprie, Yann LeCun category:cs.LG cs.CV stat.ML published:2015-11-17 summary:Learning to predict future images from a video sequence involves theconstruction of an internal representation that models the image evolutionaccurately, and therefore, to some degree, its content and dynamics. This iswhy pixel-space video prediction may be viewed as a promising avenue forunsupervised feature learning. In addition, while optical flow has been a verystudied problem in computer vision for a long time, future frame prediction israrely approached. Still, many vision applications could benefit from theknowledge of the next frames of videos, that does not require the complexity oftracking every pixel trajectories. In this work, we train a convolutionalnetwork to generate future frames given an input sequence. To deal with theinherently blurry predictions obtained from the standard Mean Squared Error(MSE) loss function, we propose three different and complementary featurelearning strategies: a multi-scale architecture, an adversarial trainingmethod, and an image gradient difference loss function. We compare ourpredictions to different published results based on recurrent neural networkson the UCF101 dataset
arxiv-14700-293 | Constant Time EXPected Similarity Estimation using Stochastic Optimization | http://arxiv.org/pdf/1511.05371v1.pdf | author:Markus Schneider, Wolfgang Ertel, Günther Palm category:cs.LG published:2015-11-17 summary:A new algorithm named EXPected Similarity Estimation (EXPoSE) was recentlyproposed to solve the problem of large-scale anomaly detection. It is anon-parametric and distribution free kernel method based on the Hilbert spaceembedding of probability measures. Given a dataset of $n$ samples, EXPoSE needsonly $\mathcal{O}(n)$ (linear time) to build a model and $\mathcal{O}(1)$(constant time) to make a prediction. In this work we improve the linearcomputational complexity and show that an $\epsilon$-accurate model can beestimated in constant time, which has significant implications for large-scalelearning problems. To achieve this goal, we cast the original EXPoSEformulation into a stochastic optimization problem. It is crucial that thisapproach allows us to determine the number of iteration based on a desiredaccuracy $\epsilon$, independent of the dataset size $n$. We will show that theproposed stochastic gradient descent algorithm works in general (possibleinfinite-dimensional) Hilbert spaces, is easy to implement and requires noadditional step-size parameters.
arxiv-14700-294 | Automatic Instrument Recognition in Polyphonic Music Using Convolutional Neural Networks | http://arxiv.org/pdf/1511.05520v1.pdf | author:Peter Li, Jiyuan Qian, Tian Wang category:cs.SD cs.IR cs.LG cs.NE published:2015-11-17 summary:Traditional methods to tackle many music information retrieval taskstypically follow a two-step architecture: feature engineering followed by asimple learning algorithm. In these "shallow" architectures, featureengineering and learning are typically disjoint and unrelated. Additionally,feature engineering is difficult, and typically depends on extensive domainexpertise. In this paper, we present an application of convolutional neural networks forthe task of automatic musical instrument identification. In this model, featureextraction and learning algorithms are trained together in an end-to-endfashion. We show that a convolutional neural network trained on raw audio canachieve performance surpassing traditional methods that rely on hand-craftedfeatures.
arxiv-14700-295 | Predicting distributions with Linearizing Belief Networks | http://arxiv.org/pdf/1511.05622v4.pdf | author:Yann N. Dauphin, David Grangier category:cs.LG cs.CV published:2015-11-17 summary:Conditional belief networks introduce stochastic binary variables in neuralnetworks. Contrary to a classical neural network, a belief network can predictmore than the expected value of the output $Y$ given the input $X$. It canpredict a distribution of outputs $Y$ which is useful when an input can admitmultiple outputs whose average is not necessarily a valid answer. Such networksare particularly relevant to inverse problems such as image prediction fordenoising, or text to speech. However, traditional sigmoid belief networks arehard to train and are not suited to continuous problems. This work introduces anew family of networks called linearizing belief nets or LBNs. A LBN decomposesinto a deep linear network where each linear unit can be turned on or off bynon-deterministic binary latent units. It is a universal approximator ofreal-valued conditional distributions and can be trained using gradientdescent. Moreover, the linear pathways efficiently propagate continuousinformation and they act as multiplicative skip-connections that helpoptimization by removing gradient diffusion. This yields a model which trainsefficiently and improves the state-of-the-art on image denoising and facialexpression generation with the Toronto faces dataset.
arxiv-14700-296 | Articulated Motion Learning via Visual and Lingual Signals | http://arxiv.org/pdf/1511.05526v1.pdf | author:Zhengyang Wu, Mohit Bansal, Matthew R. Walter category:cs.RO cs.CL cs.CV published:2015-11-17 summary:In order for robots to operate effectively in homes and workplaces, they mustbe able to manipulate the articulated objects common to environments built forand by humans. Previous work learns kinematic models that prescribe thismanipulation from visual demonstrations. Lingual signals, such as naturallanguage descriptions and instructions, offer a complementary means ofconveying knowledge of such manipulation models and are suitable to a widerange of interactions (e.g., remote manipulation). In this paper, we present amultimodal learning framework that incorporates both visual and lingualinformation to estimate the structure and parameters that define kinematicmodels of articulated objects. The visual signal takes the form of an RGB-Dimage stream that opportunistically captures object motion in an unpreparedscene. Accompanying natural language descriptions of the motion constitute thelingual signal. We present a probabilistic language model that uses wordembeddings to associate lingual verbs with their corresponding kinematicstructures. By exploiting the complementary nature of the visual and lingualinput, our method infers correct kinematic structures for various multiple-partobjects on which the previous state-of-the-art, visual-only system fails. Weevaluate our multimodal learning framework on a dataset comprised of a varietyof household objects, and demonstrate a 36% improvement in model accuracy overthe vision-only baseline.
arxiv-14700-297 | Predictive Entropy Search for Multi-objective Bayesian Optimization | http://arxiv.org/pdf/1511.05467v3.pdf | author:Daniel Hernández-Lobato, José Miguel Hernández-Lobato, Amar Shah, Ryan P. Adams category:stat.ML published:2015-11-17 summary:We present PESMO, a Bayesian method for identifying the Pareto set ofmulti-objective optimization problems, when the functions are expensive toevaluate. The central idea of PESMO is to choose evaluation points so as tomaximally reduce the entropy of the posterior distribution over the Pareto set.Critically, the PESMO multi-objective acquisition function can be decomposed asa sum of objective-specific acquisition functions, which enables the algorithmto be used in \emph{decoupled} scenarios in which the objectives can beevaluated separately and perhaps with different costs. This decouplingcapability also makes it possible to identify difficult objectives that requiremore evaluations. PESMO also offers gains in efficiency, as its cost scaleslinearly with the number of objectives, in comparison to the exponential costof other methods. We compare PESMO with other related methods formulti-objective Bayesian optimization on synthetic and real-world problems. Theresults show that PESMO produces better recommendations with a smaller numberof evaluations of the objectives, and that a decoupled evaluation can lead toimprovements in performance, particularly when the number of objectives islarge.
arxiv-14700-298 | Robust PCA via Nonconvex Rank Approximation | http://arxiv.org/pdf/1511.05261v1.pdf | author:Zhao Kang, Chong Peng, Qiang Cheng category:cs.CV cs.LG cs.NA stat.ML published:2015-11-17 summary:Numerous applications in data mining and machine learning require recoveringa matrix of minimal rank. Robust principal component analysis (RPCA) is ageneral framework for handling this kind of problems. Nuclear norm based convexsurrogate of the rank function in RPCA is widely investigated. Under certainassumptions, it can recover the underlying true low rank matrix with highprobability. However, those assumptions may not hold in real-worldapplications. Since the nuclear norm approximates the rank by adding allsingular values together, which is essentially a $\ell_1$-norm of the singularvalues, the resulting approximation error is not trivial and thus the resultingmatrix estimator can be significantly biased. To seek a closer approximationand to alleviate the above-mentioned limitations of the nuclear norm, wepropose a nonconvex rank approximation. This approximation to the matrix rankis tighter than the nuclear norm. To solve the associated nonconvexminimization problem, we develop an efficient augmented Lagrange multiplierbased optimization algorithm. Experimental results demonstrate that our methodoutperforms current state-of-the-art algorithms in both accuracy andefficiency.
arxiv-14700-299 | Model-based Dashboards for Customer Analytics | http://arxiv.org/pdf/1511.05614v3.pdf | author:Ryan Dew, Asim Ansari category:stat.AP stat.ML published:2015-11-17 summary:Automating the customer analytics process is crucial for companies thatmanage distinct customer bases. In such data-rich and dynamic environments,visualization plays a key role in understanding events of interest. These ideashave led to the popularity of analytics dashboards, yet academic research haspaid scant attention to these managerial needs. We develop a probabilistic,nonparametric framework for understanding and predicting individual-levelspending using Gaussian process priors over latent functions that describecustomer spending along calendar time, interpurchase time, and customerlifetime dimensions. These curves form a dashboard that provides a visualmodel-based representation of purchasing dynamics that is easilycomprehensible. The model flexibly and automatically captures the form andduration of the impact of events that influence spend propensity, even whensuch events are unknown a-priori. We illustrate the use of our Gaussian ProcessPropensity Model (GPPM) on data from two popular mobile games. We show that theGPPM generalizes hazard and buy-till-you-die models by incorporating calendartime dynamics while simultaneously accounting for recency and lifetime effects.It therefore provides insights about spending propensity beyond those availablefrom these models. Finally, we show that the GPPM outperforms these benchmarksboth in fitting and forecasting real and simulated spend data.
arxiv-14700-300 | An extension of McDiarmid's inequality | http://arxiv.org/pdf/1511.05240v1.pdf | author:Richard Combes category:cs.LG math.PR math.ST stat.TH published:2015-11-17 summary:We derive an extension of McDiarmid's inequality for functions $f$ withbounded differences on a high probability set ${\cal Y}$ (instead of almostsurely). The behavior of $f$ outside ${\cal Y}$ may be arbitrary. The proof isshort and elementary, and relies on an extension argument similar toKirszbraun's theorem.
