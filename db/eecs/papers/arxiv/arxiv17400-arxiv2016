arxiv-1604-03348 | Optimal Margin Distribution Machine |  http://arxiv.org/abs/1604.03348  | author:Teng Zhang, Zhi-Hua Zhou category:cs.LG published:2016-04-12 summary:Support vector machine (SVM) has been one of the most popular learningalgorithms, with the central idea of maximizing the minimum margin, i.e., thesmallest distance from the instances to the classification boundary. Recenttheoretical results, however, disclosed that maximizing the minimum margin doesnot necessarily lead to better generalization performances, and instead, themargin distribution has been proven to be more crucial. Based on this idea, wepropose a new method, named Optimal margin Distribution Machine (ODM), whichtries to achieve a better generalization performance by optimizing the margindistribution. We characterize the margin distribution by the first- andsecond-order statistics, i.e., the margin mean and variance. The proposedmethod is a general learning approach which can be used in any place where SVMcan be applied, and their superiority is verified both theoretically andempirically in this paper.
arxiv-1604-03257 | Unified Convergence Analysis of Stochastic Momentum Methods for Convex and Non-convex Optimization |  http://arxiv.org/abs/1604.03257  | author:Tianbao Yang, Qihang Lin, Zhe Li category:math.OC stat.ML published:2016-04-12 summary:Recently, {\it stochastic momentum} methods have been widely adopted intraining deep neural networks. However, their convergence analysis is stillunderexplored at the moment, in particular for non-convex optimization. Thispaper fills the gap between practice and theory by developing a basicconvergence analysis of two stochastic momentum methods, namely stochasticheavy-ball method and the stochastic variant of Nesterov's accelerated gradientmethod. We hope that the basic convergence results developed in this paper canserve the reference to the convergence of stochastic momentum methods and alsoserve the baselines for comparison in future development of stochastic momentummethods. The novelty of convergence analysis presented in this paper is aunified framework, revealing more insights about the similarities anddifferences between different stochastic momentum methods and stochasticgradient method. The unified framework exhibits a continuous change from thegradient method to Nesterov's accelerated gradient method and finally theheavy-ball method incurred by a free parameter, which can help explain asimilar change observed in the testing error convergence behavior for deeplearning. Furthermore, our empirical results for optimizing deep neuralnetworks demonstrate that the stochastic variant of Nesterov's acceleratedgradient method achieves a good tradeoff (between speed of convergence intraining error and robustness of convergence in testing error) among the threestochastic methods.
arxiv-1604-03351 | Orientation-boosted Voxel Nets for 3D Object Recognition |  http://arxiv.org/abs/1604.03351  | author:Nima Sedaghat, Mohammadreza Zolfaghari, Thomas Brox category:cs.CV cs.NE published:2016-04-12 summary:Recent work has shown good recognition results in 3D data using 3Dconvolutional networks. In this paper, we argue that the object orientationplays an important role in 3D recognition. To this end, we approach thecategory-level classification task as a multi-task problem, in which thenetwork is forced to predict the pose of the object in addition to the classlabel. We show that this yields significant improvements in the classificationresults. We implemented different network architectures for this purpose andtested them on different datasets representing various 3D data sources: LiDARdata, CAD models and RGBD images. We report state-of-the-art results onclassification, and analyze the effects of orientation-boosting on the dominantsignal paths in the network.
arxiv-1604-03357 | Improving sentence compression by learning to predict gaze |  http://arxiv.org/abs/1604.03357  | author:Sigrid Klerke, Yoav Goldberg, Anders Søgaard category:cs.CL published:2016-04-12 summary:We show how eye-tracking corpora can be used to improve sentence compressionmodels, presenting a novel multi-task learning algorithm based on multi-layerLSTMs. We obtain performance competitive with or better than state-of-the-artapproaches.
arxiv-1604-03373 | A Convex Surrogate Operator for General Non-Modular Loss Functions |  http://arxiv.org/abs/1604.03373  | author:Jiaqian Yu, Matthew Blaschko category:stat.ML cs.LG published:2016-04-12 summary:Empirical risk minimization frequently employs convex surrogates tounderlying discrete loss functions in order to achieve computationaltractability during optimization. However, classical convex surrogates can onlytightly bound modular loss functions, sub-modular functions or supermodularfunctions separately while maintaining polynomial time computation. In thiswork, a novel generic convex surrogate for general non-modular loss functionsis introduced, which provides for the first time a tractable solution for lossfunctions that are neither super-modular nor submodular. This convex surro-gateis based on a submodular-supermodular decomposition for which the existence anduniqueness is proven in this paper. It takes the sum of two convex surrogatesthat separately bound the supermodular component and the submodular componentusing slack-rescaling and the Lov{\'a}sz hinge, respectively. It is furtherproven that this surrogate is convex , piecewise linear, an extension of theloss function, and for which subgradient computation is polynomial time.Empirical results are reported on a non-submodular loss based on theS{{\o}}rensen-Dice difference function, and a real-world face track datasetwith tens of thousands of frames, demonstrating the improved performance,efficiency, and scalabil-ity of the novel convex surrogate.
arxiv-1604-03390 | Video Description using Bidirectional Recurrent Neural Networks |  http://arxiv.org/abs/1604.03390  | author:Álvaro Peris, Marc Bolaños, Petia Radeva, Francisco Casacuberta category:cs.CV cs.CL cs.LG published:2016-04-12 summary:Although traditionally used in the machine translation field, theencoder-decoder framework has been recently applied for the generation of videoand image descriptions. The combination of Convolutional and Recurrent NeuralNetworks in these models has proven to outperform the previous state of theart, obtaining more accurate video descriptions. In this work we proposepushing further this model by introducing two contributions into the encodingstage. First, producing richer image representations by combining object andlocation information from Convolutional Neural Networks and second, introducingBidirectional Recurrent Neural Networks for capturing both forward and backwardtemporal relationships in the input frames.
arxiv-1604-03443 | Multi-modal Fusion for Diabetes Mellitus and Impaired Glucose Regulation Detection |  http://arxiv.org/abs/1604.03443  | author:Jinxing Li, David Zhang, Yongcheng Li, Jian Wu category:cs.CV published:2016-04-12 summary:Effective and accurate diagnosis of Diabetes Mellitus (DM), as well as itsearly stage Impaired Glucose Regulation (IGR), has attracted much attentionrecently. Traditional Chinese Medicine (TCM) [3], [5] etc. has proved thattongue, face and sublingual diagnosis as a noninvasive method is a reasonableway for disease detection. However, most previous works only focus on a singlemodality (tongue, face or sublingual) for diagnosis, although differentmodalities may provide complementary information for the diagnosis of DM andIGR. In this paper, we propose a novel multi-modal classification method todiscriminate between DM (or IGR) and healthy controls. Specially, the tongue,facial and sublingual images are first collected by using a non-invasivecapture device. The color, texture and geometry features of these three typesof images are then extracted, respectively. Finally, our so-called multi-modalsimilar and specific learning (MMSSL) approach is proposed to combine featuresof tongue, face and sublingual, which not only exploits the correlation butalso extracts individual components among them. Experimental results on adataset consisting of 192 Healthy, 198 DM and 114 IGR samples (all samples wereobtained from Guangdong Provincial Hospital of Traditional Chinese Medicine)substantiate the effectiveness and superiority of our proposed method for thediagnosis of DM and IGR, compared to the case of using a single modality.
arxiv-1604-03463 | The Matrix Generalized Inverse Gaussian Distribution: Properties and Applications |  http://arxiv.org/abs/1604.03463  | author:Farideh Fazayeli, Arindam Banerjee category:stat.ML published:2016-04-12 summary:While the Matrix Generalized Inverse Gaussian ($\mathcal{MGIG}$) distributionarises naturally in some settings as a distribution over symmetric positivesemi-definite matrices, certain key properties of the distribution andeffective ways of sampling from the distribution have not been carefullystudied. In this paper, we show that the $\mathcal{MGIG}$ is unimodal, and themode can be obtained by solving an Algebraic Riccati Equation (ARE) equation[7]. Based on the property, we propose an importance sampling method for the$\mathcal{MGIG}$ where the mode of the proposal distribution matches that ofthe target. The proposed sampling method is more efficient than existingapproaches [32, 33], which use proposal distributions that may have the modefar from the $\mathcal{MGIG}$'s mode. Further, we illustrate that the theposterior distribution in latent factor models, such as probabilistic matrixfactorization (PMF) [25], when marginalized over one latent factor has the$\mathcal{MGIG}$ distribution. The characterization leads to a novel CollapsedMonte Carlo (CMC) inference algorithm for such latent factor models. Weillustrate that CMC has a lower log loss or perplexity than MCMC, and needsfewer samples.
arxiv-1604-03489 | From Pixels to Sentiment: Fine-tuning CNNs for Visual Sentiment Prediction |  http://arxiv.org/abs/1604.03489  | author:Victor Campos, Brendan Jou, Xavier Giro-i-Nieto category:cs.CV cs.MM published:2016-04-12 summary:Visual media have become a crucial part of our social lives. The throughputof generated multimedia content, together with its richness for conveyingsentiments and feelings, highlights the need of automated visual sentimentanalysis tools. We explore how Convolutional Neural Networks (CNNs), acomputational learning paradigm that has shown outstanding performance inseveral vision tasks, can be applied to the task of visual sentiment predictionby fine-tuning a state-of-the-art CNN. We analyze its architecture, studyingseveral performance boosting techniques, which led to a network tuned toachieve a 6.1 % absolute accuracy improvement over the previousstate-of-the-art on a dataset of images from a popular social media platform.Finally, we present visualizations of local patterns that the networkassociates to each image's sentiment.
arxiv-1604-03492 | Structured Matrix Recovery via the Generalized Dantzig Selector |  http://arxiv.org/abs/1604.03492  | author:Sheng Chen, Arindam Banerjee category:stat.ML published:2016-04-12 summary:In recent years, structured matrix recovery problems have gained considerableattention for its real world applications, such as recommender systems andcomputer vision. Much of the existing work has focused on matrices withlow-rank structure, and limited progress has been made matrices with othertypes of structure. In this paper we present non-asymptotic analysis forestimation of generally structured matrices via the generalized Dantzigselector under generic sub-Gaussian measurements. We show that the estimationerror can always be succinctly expressed in terms of a few geometric measuresof suitable sets which only depend on the structure of the underlying truematrix. In addition, we derive the general bounds on these geometric measuresfor structures characterized by unitarily invariant norms, which is a largefamily covering most matrix norms of practical interest. Examples are providedto illustrate the utility of our theoretical development.
arxiv-1604-03498 | GPU-FV: Realtime Fisher Vector and Its Applications in Video Monitoring |  http://arxiv.org/abs/1604.03498  | author:Wenying Ma, Liangliang Cao, Lei Yu, Guoping Long, Yucheng Li category:cs.CV published:2016-04-12 summary:Fisher vector has been widely used in many multimedia retrieval and visualrecognition applications with good performance. However, the computationcomplexity prevents its usage in real-time video monitoring. In this work, weproposed and implemented GPU-FV, a fast Fisher vector extraction method withthe help of modern GPUs. The challenge of implementing Fisher vector on GPUslies in the data dependency in feature extraction and expensive memory accessin Fisher vector computing. To handle these challenges, we carefully designedGPU-FV in a way that utilizes the computing power of GPU as much as possible,and applied optimizations such as loop tiling to boost the performance. GPU-FVis about 12 times faster than the CPU version, and 50\% faster than anon-optimized GPU implementation. For standard video input (320*240), GPU-FVcan process each frame within 34ms on a model GPU. Our experiments show thatGPU-FV obtains a similar recognition accuracy as traditional FV on VOC 2007 andCaltech 256 image sets. We also applied GPU-FV for realtime video monitoringtasks and found that GPU-FV outperforms a number of previous works. Especially,when the number of training examples are small, GPU-FV outperforms the recentpopular deep CNN features borrowed from ImageNet. The code can be downloadedfrom the following link https://bitbucket.org/mawenjing/gpu-fv.
arxiv-1604-03605 | What do different evaluation metrics tell us about saliency models? |  http://arxiv.org/abs/1604.03605  | author:Zoya Bylinskii, Tilke Judd, Aude Oliva, Antonio Torralba, Frédo Durand category:cs.CV published:2016-04-12 summary:How best to evaluate a saliency model's ability to predict where humans lookin images is an open research question. The choice of evaluation metric dependson how saliency is defined and how the ground truth is represented. Metricsdiffer in how they rank saliency models, and this results from how falsepositives and false negatives are treated, whether viewing biases are accountedfor, whether spatial deviations are factored in, and how the saliency maps arepre-processed. In this paper, we provide an analysis of 8 different evaluationmetrics and their properties. With the help of systematic experiments andvisualizations of metric computations, we add interpretability to saliencyscores and more transparency to the evaluation of saliency models. Building offthe differences in metric properties and behaviors, we make recommendations formetric selections under specific assumptions and for specific applications.
arxiv-1604-03601 | Community Detection with Node Attributes and its Generalization |  http://arxiv.org/abs/1604.03601  | author:Yuan Li category:cs.SI physics.soc-ph stat.ML published:2016-04-12 summary:Community detection algorithms are fundamental tools to understandorganizational principles in social networks. With the increasing power ofsocial media platforms, when detecting communities there are two possi- blesources of information one can use: the structure of social network and nodeattributes. However structure of social networks and node attributes are ofteninterpreted separately in the research of community detection. When these twosources are interpreted simultaneously, one common as- sumption shared byprevious studies is that nodes attributes are correlated with communities. Inthis paper, we present a model that is capable of combining topologyinformation and nodes attributes information with- out assuming correlation.This new model can recover communities with higher accuracy even when nodeattributes and communities are uncorre- lated. We derive the detectabilitythreshold for this model and use Belief Propagation (BP) to make inference.This algorithm is optimal in the sense that it can recover community all theway down to the threshold. This new model is also with the potential to handleedge content and dynamic settings.
arxiv-1604-03540 | Training Region-based Object Detectors with Online Hard Example Mining |  http://arxiv.org/abs/1604.03540  | author:Abhinav Shrivastava, Abhinav Gupta, Ross Girshick category:cs.CV cs.LG published:2016-04-12 summary:The field of object detection has made significant advances riding on thewave of region-based ConvNets, but their training procedure still includes manyheuristics and hyperparameters that are costly to tune. We present a simple yetsurprisingly effective online hard example mining (OHEM) algorithm for trainingregion-based ConvNet detectors. Our motivation is the same as it has alwaysbeen -- detection datasets contain an overwhelming number of easy examples anda small number of hard examples. Automatic selection of these hard examples canmake training more effective and efficient. OHEM is a simple and intuitivealgorithm that eliminates several heuristics and hyperparameters in common use.But more importantly, it yields consistent and significant boosts in detectionperformance on benchmarks like PASCAL VOC 2007 and 2012. Its effectivenessincreases as datasets become larger and more difficult, as demonstrated by theresults on the MS COCO dataset. Moreover, combined with complementary advancesin the field, OHEM leads to state-of-the-art results of 78.9% and 76.3% mAP onPASCAL VOC 2007 and 2012 respectively.
arxiv-1604-03539 | Cross-stitch Networks for Multi-task Learning |  http://arxiv.org/abs/1604.03539  | author:Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, Martial Hebert category:cs.CV cs.LG published:2016-04-12 summary:Multi-task learning in Convolutional Networks has displayed remarkablesuccess in the field of recognition. This success can be largely attributed tolearning shared representations from multiple supervisory tasks. However,existing multi-task approaches rely on enumerating multiple networkarchitectures specific to the tasks at hand, that do not generalize. In thispaper, we propose a principled approach to learn shared representations inConvNets using multi-task learning. Specifically, we propose a new sharingunit: "cross-stitch" unit. These units combine the activations from multiplenetworks and can be trained end-to-end. A network with cross-stitch units canlearn an optimal combination of shared and task-specific representations. Ourproposed method generalizes across multiple tasks and shows dramaticallyimproved performance over baseline methods for categories with few trainingexamples.
arxiv-1604-03505 | Counting Everyday Objects in Everyday Scenes |  http://arxiv.org/abs/1604.03505  | author:Prithvijit Chattopadhyay, Ramakrishna Vedantam, Ramprasaath RS, Dhruv Batra, Devi Parikh category:cs.CV published:2016-04-12 summary:We introduce the problem of counting everyday objects in everyday scenes.While previous works have studied specific counting problems such as pedestriancounting in surveillance videos, or biological cell counting, we are interestedin counting common objects in natural scenes. We study this problem in a setupsimilar to traditional scene understanding problems. Given an image, weconsider the task of predicting the counts (or the numerosity) of categories ofinterest. We study some simple approaches and applications for this countingproblem. Our detect approach adapts an object detector to perform counting,while our glance approach regresses to ground truth counts. Our associativesubitizing (aso-sub) approach divides an image into regions and regresses tofractional object counts in each region. We create an ensemble (ens) of thesecounting methods which improves performance. We demonstrate countingperformance on the PASCAL and MS COCO datasets. We show proof-of-conceptapplications of our automatic counting methods to 1) improve object detectionperformance, and 2) visual question answering (on VQA and COCO-QA). Our codeand datasets will be publicly available.
arxiv-1604-03519 | Contextual Deep CNN Based Hyperspectral Classification |  http://arxiv.org/abs/1604.03519  | author:Hyungtae Lee, Heesung Kwon category:cs.CV cs.LG published:2016-04-12 summary:In this paper, we describe a novel deep convolutional neural networks (CNN)based approach called contextual deep CNN that can jointly exploit spatial andspectral features for hyperspectral image classification. The contextual deepCNN first concurrently applies multiple 3-dimensional local convolutionalfilters with different sizes jointly exploiting spatial and spectral featuresof a hyperspectral image. The initial spatial and spectral feature mapsobtained from applying the variable size convolutional filters are thencombined together to form a joint spatio-spectral feature map. The jointfeature map representing rich spectral and spatial properties of thehyperspectral image is then fed through fully convolutional layers thateventually predict the corresponding label of each pixel vector. The proposedapproach is tested on the Indian Pines data and performance comparison showsenhanced classification performance of the proposed approach over the currentstate of the art.
arxiv-1604-03518 | DTM: Deformable Template Matching |  http://arxiv.org/abs/1604.03518  | author:Hyungtae Lee, Heesung Kwon, Ryan M. Robinson, William D. Nothwang category:cs.CV published:2016-04-12 summary:A novel template matching algorithm that can incorporate the concept ofdeformable parts, is presented in this paper. Unlike the deformable part model(DPM) employed in object recognition, the proposed template-matching approachcalled Deformable Template Matching (DTM) does not require a training step.Instead, deformation is achieved by a set of predefined basic rules (e.g. theleft sub-patch cannot pass across the right patch). Experimental evaluation ofthis new method using the PASCAL VOC 07 dataset demonstrated substantialperformance improvement over conventional template matching algorithms.Additionally, to confirm the applicability of DTM, the concept is applied tothe generation of a rotation-invariant SIFT descriptor. Experimental evaluationemploying deformable matching of SIFT features shows an increased number ofmatching features compared to a conventional SIFT matching.
arxiv-1604-03517 | Fast Object Localization Using a CNN Feature Map Based Multi-Scale Search |  http://arxiv.org/abs/1604.03517  | author:Hyungtae Lee, Heesung Kwon, Archith J. Bency, William D. Nothwang category:cs.CV published:2016-04-12 summary:Object localization is an important task in computer vision but requires alarge amount of computational power due mainly to an exhaustive multiscalesearch on the input image. In this paper, we describe a near real-timemultiscale search on a deep CNN feature map that does not use region proposals.The proposed approach effectively exploits local semantic information preservedin the feature map of the outermost convolutional layer. A multi-scale searchis performed on the feature map by processing all the sub-regions of differentsizes using separate expert units of fully connected layers. Each expert unitreceives as input local semantic features only from the correspondingsub-regions of a specific geometric shape. Therefore, it contains more nearlyoptimal parameters tailored to the corresponding shape. This multi-scale andmulti-aspect ratio scanning strategy can effectively localize a potentialobject of an arbitrary size. The proposed approach is fast and able to localizeobjects of interest with a frame rate of 4 fps while providing improveddetection performance over the state-of-the art on the PASCAL VOC 12 and MSCOCOdata sets.
arxiv-1604-03513 | Full Flow: Optical Flow Estimation By Global Optimization over Regular Grids |  http://arxiv.org/abs/1604.03513  | author:Qifeng Chen, Vladlen Koltun category:cs.CV published:2016-04-12 summary:We present a global optimization approach to optical flow estimation. Theapproach optimizes a classical optical flow objective over the full space ofmappings between discrete grids. No descriptor matching is used. The highlyregular structure of the space of mappings enables optimizations that reducethe computational complexity of the algorithm's inner loop from quadratic tolinear and support efficient matching of tens of thousands of nodes to tens ofthousands of displacements. We show that one-shot global optimization of aclassical Horn-Schunck-type objective over regular grids at a single resolutionis sufficient to initialize continuous interpolation and achievestate-of-the-art performance on challenging modern benchmarks.
arxiv-1604-03506 | An Unbiased Data Collection and Content Exploitation/Exploration Strategy for Personalization |  http://arxiv.org/abs/1604.03506  | author:Liangjie Hong, Adnan Boz category:cs.IR cs.LG published:2016-04-12 summary:One of missions for personalization systems and recommender systems is toshow content items according to users' personal interests. In order to achievesuch goal, these systems are learning user interests over time and trying topresent content items tailoring to user profiles. Recommending items accordingto users' preferences has been investigated extensively in the past few years,mainly thanks for the popularity of Netflix competition. In a real setting,users may be attracted by a subset of those items and interact with them, onlyleaving partial feedbacks to the system to learn in the next cycle, which leadsto significant biases into systems and hence results in a situation where userengagement metrics cannot be improved over time. The problem is not just forone component of the system. The data collected from users is usually used inmany different tasks, including learning ranking functions, building userprofiles and constructing content classifiers. Once the data is biased, allthese downstream use cases would be impacted as well. Therefore, it would bebeneficial to gather unbiased data through user interactions. Traditionally,unbiased data collection is done through showing items uniformly sampling fromthe content pool. However, this simple scheme is not feasible as it risks userengagement metrics and it takes long time to gather user feedbacks. In thispaper, we introduce a user-friendly unbiased data collection framework, byutilizing methods developed in the exploitation and exploration literature. Wediscuss how the framework is different from normal multi-armed bandit problemsand why such method is needed. We layout a novel Thompson sampling forBernoulli ranked-list to effectively balance user experiences and datacollection. The proposed method is validated from a real bucket test and weshow strong results comparing to old algorithms
arxiv-1604-03278 | Confidence Decision Trees via Online and Active Learning for Streaming (BIG) Data |  http://arxiv.org/abs/1604.03278  | author:Rocco De Rosa category:stat.ML cs.LG published:2016-04-12 summary:Decision tree classifiers are a widely used tool in data stream mining. Theuse of confidence intervals to estimate the gain associated with each splitleads to very effective methods, like the popular Hoeffding tree algorithm.From a statistical viewpoint, the analysis of decision tree classifiers in astreaming setting requires knowing when enough new information has beencollected to justify splitting a leaf. Although some of the issues in thestatistical analysis of Hoeffding trees have been already clarified, a generaland rigorous study of confidence intervals for splitting criteria is missing.We fill this gap by deriving accurate confidence intervals to estimate thesplitting gain in decision tree learning with respect to three criteria:entropy, Gini index, and a third index proposed by Kearns and Mansour. Ourconfidence intervals depend in a more detailed way on the tree parameters. Wealso extend our confidence analysis to a selective sampling setting, in whichthe decision tree learner adaptively decides which labels to query in thestream. We furnish theoretical guarantee bounding the probability that theclassification is non-optimal learning the decision tree via our selectivesampling strategy. Experiments on real and synthetic data in a streamingsetting show that our trees are indeed more accurate than trees with the samenumber of leaves generated by other techniques and our active learning modulepermits to save labeling cost. In addition, comparing our labeling strategywith recent methods, we show that our approach is more robust and consistentrespect all the other techniques applied to incremental decision trees.
arxiv-1604-03247 | Thesis: Multiple Kernel Learning for Object Categorization |  http://arxiv.org/abs/1604.03247  | author:Dinesh Govindaraj category:cs.CV cs.LG published:2016-04-12 summary:Object Categorization is a challenging problem, especially when the imageshave clutter background, occlusions or different lighting conditions. In thepast, many descriptors have been proposed which aid object categorization evenin such adverse conditions. Each descriptor has its own merits and de-merits.Some descriptors are invariant to transformations while the others are morediscriminative. Past research has shown that, employing multiple descriptorsrather than any single descriptor leads to better recognition. The problem oflearning the optimal combination of the available descriptors for a particularclassification task is studied. Multiple Kernel Learning (MKL) framework hasbeen developed for learning an optimal combination of descriptors for objectcategorization. Existing MKL formulations often employ block l-1 normregularization which is equivalent to selecting a single kernel from a libraryof kernels. Since essentially a single descriptor is selected, the existingformulations maybe sub- optimal for object categorization. A MKL formulationbased on block l-infinity norm regularization has been developed, which choosesan optimal combination of kernels as opposed to selecting a single kernel. AComposite Multiple Kernel Learning(CKL) formulation based on mixed l-infinityand l-1 norm regularization has been developed. These formulations end inSecond Order Cone Programs(SOCP). Other efficient alter- native algorithms forthese formulation have been implemented. Empirical results on benchmarkdatasets show significant improvement using these new MKL formulations.
arxiv-1604-03200 | Efficient Classification of Multi-Labelled Text Streams by Clashing |  http://arxiv.org/abs/1604.03200  | author:Ricardo Ñanculef, Ilias Flaounas, Nello Cristianini category:cs.AI cs.LG published:2016-04-12 summary:We present a method for the classification of multi-labelled text documentsexplicitly designed for data stream applications that require to process avirtually infinite sequence of data using constant memory and constantprocessing time. Our method is composed of an online procedure used toefficiently map text into a low-dimensional feature space and a partition ofthis space into a set of regions for which the system extracts and keepsstatistics used to predict multi-label text annotations. Documents are fed intothe system as a sequence of words, mapped to a region of the partition, andannotated using the statistics computed from the labelled instances collidingin the same region. This approach is referred to as clashing. We illustrate themethod in real-world text data, comparing the results with those obtained usingother text classifiers. In addition, we provide an analysis about the effect ofthe representation space dimensionality on the predictive performance of thesystem. Our results show that the online embedding indeed approximates thegeometry of the full corpus-wise TF and TF-IDF space. The model obtainscompetitive F measures with respect to the most accurate methods, usingsignificantly fewer computational resources. In addition, the method achieves ahigher macro-averaged F measure than methods with similar running time.Furthermore, the system is able to learn faster than the other methods frompartially labelled streams.
arxiv-1604-03196 | Privacy-Preserving Egocentric Activity Recognition from Extreme Low Resolution |  http://arxiv.org/abs/1604.03196  | author:Michael S. Ryoo, Brandon Rothrock, Charles Fleming category:cs.CV published:2016-04-12 summary:Privacy protection from video taken by wearable cameras is an importantsocietal challenge. We desire a wearable vision system that can recognize humanactivities, yet not disclose the identity of the participants. Videoanonymization is typically handled by decimating the image to a very lowresolution. Activity recognition, however, generally requires resolution highenough that features such as faces are identifiable. In this paper, we proposea new approach to address such contradicting objectives: human activityrecognition while only using extreme low-resolution (e.g., 16x12) anonymizedvideos. We introduce the paradigm of inverse super resolution (ISR), theconcept of learning the optimal set of image transformations to generatemultiple low-resolution videos from a single video. Our ISR learns differenttypes of sub-pixel transformations optimized for the activity classification,allowing the classifier to best take advantage of existing high-resolutionvideos (e.g., YouTube videos) by generating multiple LR training videostailored for the problem. We experimentally confirm that the paradigm ofinverse super resolution is able to benefit activity recognition from extremelow-resolution videos (e.g., 16x12 and 32x24), particularly in first-personscenarios.
arxiv-1604-03209 | Disfluency Detection using a Bidirectional LSTM |  http://arxiv.org/abs/1604.03209  | author:Vicky Zayats, Mari Ostendorf, Hannaneh Hajishirzi category:cs.CL published:2016-04-12 summary:We introduce a new approach for disfluency detection using a BidirectionalLong-Short Term Memory neural network (BLSTM). In addition to the wordsequence, the model takes as input pattern match features that were developedto reduce sensitivity to vocabulary size in training, which lead to improvedperformance over the word sequence alone. The BLSTM takes advantage of explicitrepair states in addition to the standard reparandum states. The final outputleverages integer linear programming to incorporate constraints of disfluencystructure. In experiments on the Switchboard corpus, the model achievesstate-of-the-art performance for both the standard disfluency detection taskand the correction detection task. Analysis shows that the model has betterdetection of non-repetition disfluencies, which tend to be much harder todetect.
arxiv-1604-03225 | Geometric Feature-Based Facial Expression Recognition in Image Sequences Using Multi-Class AdaBoost and Support Vector Machines |  http://arxiv.org/abs/1604.03225  | author:Deepak Ghimire, Joonwhoan Lee category:cs.CV 68T01 I.4; I.5 published:2016-04-12 summary:Facial expressions are widely used in the behavioral interpretation ofemotions, cognitive science, and social interactions. In this paper, we presenta novel method for fully automatic facial expression recognition in facialimage sequences. As the facial expression evolves over time facial landmarksare automatically tracked in consecutive video frames, using displacementsbased on elastic bunch graph matching displacement estimation. Feature vectorsfrom individual landmarks, as well as pairs of landmarks tracking results areextracted, and normalized, with respect to the first frame in the sequence. Theprototypical expression sequence for each class of facial expression is formed,by taking the median of the landmark tracking results from the training facialexpression sequences. Multi-class AdaBoost with dynamic time warping similaritydistance between the feature vector of input facial expression and prototypicalfacial expression, is used as a weak classifier to select the subset ofdiscriminative feature vectors. Finally, two methods for facial expressionrecognition are presented, either by using multi-class AdaBoost with dynamictime warping, or by using support vector machine on the boosted featurevectors. The results on the Cohn-Kanade (CK+) facial expression database show arecognition accuracy of 95.17% and 97.35% using multi-class AdaBoost andsupport vector machines, respectively.
arxiv-1604-03193 | Application of the Second-Order Statistics for Estimation of the Pure Spectra of Individual Components from the Visible Hyperspectral Images of Their Mixture |  http://arxiv.org/abs/1604.03193  | author:Sung-Ho Jong, Yong-U Ri, Kye-Ryong Sin category:cs.CV published:2016-04-12 summary:The second-order statistics (SOS) can be applied in estimation of the purespectra of chemical components from the spectrum of their mixture, when SOSseems to be good at estimation of spectral patterns, but their peak directionsare opposite in some cases. In this paper, one method for judgment of the peakdirection of the pure spectra was proposed, where the base line of the purespectra was drawn by using their histograms and the peak directions were chosenso as to make all of the pure spectra located upwards over the base line.Results of the SOS analysis on the visible hyperspectral images of the mixturecomposed of two or three chemical components showed that the present methodoffered the reasonable shape and direction of the pure spectra of itscomponents.
arxiv-1604-03265 | Volumetric and Multi-View CNNs for Object Classification on 3D Data |  http://arxiv.org/abs/1604.03265  | author:Charles R. Qi, Hao Su, Matthias Niessner, Angela Dai, Mengyuan Yan, Leonidas J. Guibas category:cs.CV cs.AI published:2016-04-12 summary:3D shape models are becoming widely available and easier to capture, makingavailable 3D information crucial for progress in object classification. Currentstate-of-the-art methods rely on CNNs to address this problem. Recently, wewitness two types of CNNs being developed: CNNs based upon volumetricrepresentations versus CNNs based upon multi-view representations. Empiricalresults from these two types of CNNs exhibit a large gap, indicating thatexisting volumetric CNN architectures and approaches are unable to fullyexploit the power of 3D representations. In this paper, we aim to improve bothvolumetric CNNs and multi-view CNNs according to extensive analysis of existingapproaches. To this end, we introduce two distinct network architectures ofvolumetric CNNs. In addition, we examine multi-view CNNs, where we introducemulti-resolution filtering in 3D. Overall, we are able to outperform currentstate-of-the-art methods for both volumetric CNNs and multi-view CNNs. Weprovide extensive experiments designed to evaluate underlying design choices,thus providing a better understanding of the space of methods available forobject classification on 3D data.
arxiv-1604-03227 | Recurrent Attentional Networks for Saliency Detection |  http://arxiv.org/abs/1604.03227  | author:Jason Kuen, Zhenhua Wang, Gang Wang category:cs.CV cs.LG stat.ML published:2016-04-12 summary:Convolutional-deconvolution networks can be adopted to perform end-to-endsaliency detection. But, they do not work well with objects of multiple scales.To overcome such a limitation, in this work, we propose a recurrent attentionalconvolutional-deconvolution network (RACDNN). Using spatial transformer andrecurrent network units, RACDNN is able to iteratively attend to selected imagesub-regions to perform saliency refinement progressively. Besides tackling thescale problem, RACDNN can also learn context-aware features from pastiterations to enhance saliency refinement in future iterations. Experiments onseveral challenging saliency detection datasets validate the effectiveness ofRACDNN, and show that RACDNN outperforms state-of-the-art saliency detectionmethods.
arxiv-1604-03239 | CRAFT Objects from Images |  http://arxiv.org/abs/1604.03239  | author:Bin Yang, Junjie Yan, Zhen Lei, Stan Z. Li category:cs.CV published:2016-04-12 summary:Object detection is a fundamental problem in image understanding. One popularsolution is the R-CNN framework and its fast versions. They decompose theobject detection problem into two cascaded easier tasks: 1) generating objectproposals from images, 2) classifying proposals into various object categories.Despite that we are handling with two relatively easier tasks, they are notsolved perfectly and there's still room for improvement. In this paper, we pushthe "divide and conquer" solution even further by dividing each task into twosub-tasks. We call the proposed method "CRAFT" (Cascade Region-proposal-networkAnd FasT-rcnn), which tackles each task with a carefully designed networkcascade. We show that the cascade structure helps in both tasks: in proposalgeneration, it provides more compact and better localized object proposals; inobject classification, it reduces false positives (mainly between ambiguouscategories) by capturing both inter- and intra-category variances. CRAFTachieves consistent and considerable improvement over the state-of-the-art onobject detection benchmarks like PASCAL VOC 07/12 and ILSVRC.
arxiv-1604-03286 | Scan, Attend and Read: End-to-End Handwritten Paragraph Recognition with MDLSTM Attention |  http://arxiv.org/abs/1604.03286  | author:Théodore Bluche, Jérôme Louradour, Ronaldo Messina category:cs.CV published:2016-04-12 summary:We present an attention-based model for end-to-end handwriting recognition.Our system does not require any segmentation of the input paragraph. The modelis inspired by the differentiable attention models presented recently forspeech recognition, image captioning or translation. The main difference is thecovert and overt attention, implemented as a multi-dimensional LSTM network.Our principal contribution towards handwriting recognition lies in theautomatic transcription without a prior segmentation into lines, which wascrucial in previous approaches. To the best of our knowledge this is the firstsuccessful attempt of end-to-end multi-line handwriting recognition. We carriedout experiments on the well-known IAM Database. The results are encouraging andbring hope to perform full paragraph transcription in the near future.
arxiv-1604-03169 | Using Deep Learning for Image-Based Plant Disease Detection |  http://arxiv.org/abs/1604.03169  | author:Sharada Prasanna Mohanty, David Hughes, Marcel Salathe category:cs.CV published:2016-04-11 summary:Crop diseases are a major threat to food security, but their rapididentification remains difficult in many parts of the world due to the lack ofthe necessary infrastructure. The combination of increasing global smartphonepenetration and recent advances in computer vision made possible by deeplearning has paved the way for smartphone-assisted disease diagnosis. Using apublic dataset of 54,306 images of diseased and healthy plant leaves collectedunder controlled conditions, we train a deep convolutional neural network toidentify 14 crop species and 26 diseases (or absence thereof). The trainedmodel achieves an accuracy of 99.35% on a held-out test set, demonstrating thefeasibility of this approach. When testing the model on a set of imagescollected from trusted online sources - i.e. taken under conditions differentfrom the images used for training - the model still achieves an accuracy of31.4%. While this accuracy is much higher than the one based on randomselection (2.6%), a more diverse set of training data is needed to improve thegeneral accuracy. Overall, the approach of training deep learning models onincreasingly large and publicly available image datasets presents a clear pathtowards smartphone-assisted crop disease diagnosis on a massive global scale.
arxiv-1604-03159 | Phase Transitions and a Model Order Selection Criterion for Spectral Graph Clustering |  http://arxiv.org/abs/1604.03159  | author:Pin-Yu Chen, Alfred O. Hero category:cs.SI stat.ML published:2016-04-11 summary:One of the longstanding open problems in spectral graph clustering (SGC) isthe so-called model order selection problem: automated selection of the correctnumber of clusters. This is equivalent to the problem of finding the number ofconnected components or communities in an undirected graph. We propose asolution to the SGC model selection problem under a random interconnectionmodel (RIM) using a novel selection criterion that is based on an asymptoticphase transition analysis. Our solution can more generally be applied todiscovering hidden block diagonal structure in symmetric non-negative matrices.Numerical experiments on simulated graphs validate the phase transitionanalysis, and real-world network data is used to validate the performance ofthe proposed model selection procedure.
arxiv-1604-02993 | Using Sentence-Level LSTM Language Models for Script Inference |  http://arxiv.org/abs/1604.02993  | author:Karl Pichotta, Raymond J. Mooney category:cs.CL published:2016-04-11 summary:There is a small but growing body of research on statistical scripts, modelsof event sequences that allow probabilistic inference of implicit events fromdocuments. These systems operate on structured verb-argument events produced byan NLP pipeline. We compare these systems with recent Recurrent Neural Netmodels that directly operate on raw tokens to predict sentences, finding thelatter to be roughly comparable to the former in terms of predicting missingevents in documents.
arxiv-1604-02975 | CP-mtML: Coupled Projection multi-task Metric Learning for Large Scale Face Retrieval |  http://arxiv.org/abs/1604.02975  | author:Binod Bhattarai, Gaurav Sharma, Frederic Jurie category:cs.CV published:2016-04-11 summary:We propose a novel Coupled Projection multi-task Metric Learning (CP-mtML)method for large scale face retrieval. In contrast to previous works which werelimited to low dimensional features and small datasets, the proposed methodscales to large datasets with high dimensional face descriptors. It utilisespairwise (dis-)similarity constraints as supervision and hence does not requireexhaustive class annotation for every training image. While, traditionally,multi-task learning methods have been validated on same dataset but differenttasks, we work on the more challenging setting with heterogeneous datasets anddifferent tasks. We show empirical validation on multiple face image datasetsof different facial traits, e.g. identity, age and expression. We use classicLocal Binary Pattern (LBP) descriptors along with the recent Deep ConvolutionalNeural Network (CNN) features. The experiments clearly demonstrate thescalability and improved performance of the proposed method on the tasks ofidentity and age based face image retrieval compared to competitive existingmethods, on the standard datasets and with the presence of a million distractorface images.
arxiv-1604-03053 | Variational Latent Gaussian Process for Recovering Single-Trial Dynamics from Population Spike Trains |  http://arxiv.org/abs/1604.03053  | author:Yuan Zhao, Il Memming Park category:stat.ML q-bio.NC published:2016-04-11 summary:A small number of common factors often explain most of the interdependenceamong simultaneously recorded neurons, a signature of underlyinglow-dimensional dynamics. We posit that simple neural coding and computationmanifest as low-dimensional nonlinear dynamics implemented redundantly within alarge population of neurons. Recovering the latent dynamics from observationscan offer a deeper understanding of neural computation. We improve uponpreviously-proposed methods for recovering latent dynamics, which assume eitheran inappropriate observation model or linear dynamics. We propose a practicaland efficient inference method for a generative model with explicit pointprocess observations and an assumption of smooth nonlinear dynamics. Wevalidate our method on both simulated data and population recording fromprimary visual cortex.
arxiv-1604-02946 | Kernel-based Sensor Fusion with Application to Audio-Visual Voice Activity Detection |  http://arxiv.org/abs/1604.02946  | author:David Dov, Ronen Talmon, Israel Cohen category:cs.CV published:2016-04-11 summary:In this paper, we address the problem of multiple view data fusion in thepresence of noise and interferences. Recent studies have approached thisproblem using kernel methods, by relying particularly on a product of kernelsconstructed separately for each view. From a graph theory point of view, weanalyze this fusion approach in a discrete setting. More specifically, based ona statistical model for the connectivity between data points, we propose analgorithm for the selection of the kernel bandwidth, a parameter, which, as weshow, has important implications on the robustness of this fusion approach tointerferences. Then, we consider the fusion of audio-visual speech signalsmeasured by a single microphone and by a video camera pointed to the face ofthe speaker. Specifically, we address the task of voice activity detection,i.e., the detection of speech and non-speech segments, in the presence ofstructured interferences such as keyboard taps and office noise. We propose analgorithm for voice activity detection based on the audio-visual signal.Simulation results show that the proposed algorithm outperforms competingfusion and voice activity detection approaches. In addition, we demonstratethat a proper selection of the kernel bandwidth indeed leads to improvedperformance.
arxiv-1604-02843 | Method of Tibetan Person Knowledge Extraction |  http://arxiv.org/abs/1604.02843  | author:Yuan Sun, Zhen Zhu category:cs.CL published:2016-04-11 summary:Person knowledge extraction is the foundation of the Tibetan knowledge graphconstruction, which provides support for Tibetan question answering system,information retrieval, information extraction and other researches, andpromotes national unity and social stability. This paper proposes a SVM andtemplate based approach to Tibetan person knowledge extraction. Throughconstructing the training corpus, we build the templates based the shallowparsing analysis of Tibetan syntactic, semantic features and verbs. Using thetraining corpus, we design a hierarchical SVM classifier to realize the entityknowledge extraction. Finally, experimental results prove the method hasgreater improvement in Tibetan person knowledge extraction.
arxiv-1604-02855 | Active Learning for Online Recognition of Human Activities from Streaming Videos |  http://arxiv.org/abs/1604.02855  | author:Rocco De Rosa, Ilaria Gori, Fabio Cuzzolin, Barbara Caputo, Nicolò Cesa-Bianchi category:stat.ML cs.CV cs.LG published:2016-04-11 summary:Recognising human activities from streaming videos poses unique challenges tolearning algorithms: predictive models need to be scalable, incrementallytrainable, and must remain bounded in size even when the data stream isarbitrarily long. Furthermore, as parameter tuning is problematic in astreaming setting, suitable approaches should be parameterless, and make noassumptions on what class labels may occur in the stream. We present here anapproach to the recognition of human actions from streaming data which meetsall these requirements by: (1) incrementally learning a model which adaptivelycovers the feature space with simple local classifiers; (2) employing an activelearning strategy to reduce annotation requests; (3) achieving promisingaccuracy within a fixed model size. Extensive experiments on standardbenchmarks show that our approach is competitive with state-of-the-artnon-incremental methods, and outperforms the existing active incrementalbaselines.
arxiv-1604-02878 | Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks |  http://arxiv.org/abs/1604.02878  | author:Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, Yu Qiao category:cs.CV published:2016-04-11 summary:Face detection and alignment in unconstrained environment are challenging dueto various poses, illuminations and occlusions. Recent studies show that deeplearning approaches can achieve impressive performance on these two tasks. Inthis paper, we propose a deep cascaded multi-task framework which exploits theinherent correlation between them to boost up their performance. In particular,our framework adopts a cascaded structure with three stages of carefullydesigned deep convolutional networks that predict face and landmark location ina coarse-to-fine manner. In addition, in the learning process, we propose a newonline hard sample mining strategy that can improve the performanceautomatically without manual sample selection. Our method achieves superioraccuracy over the state-of-the-art techniques on the challenging FDDB and WIDERFACE benchmark for face detection, and AFLW benchmark for face alignment, whilekeeps real time performance.
arxiv-1604-02885 | Semantic 3D Reconstruction with Continuous Regularization and Ray Potentials Using a Visibility Consistency Constraint |  http://arxiv.org/abs/1604.02885  | author:Nikolay Savinov, Christian Haene, Lubor Ladicky, Marc Pollefeys category:cs.CV published:2016-04-11 summary:We propose an approach for dense semantic 3D reconstruction which uses a dataterm that is defined as potentials over viewing rays, combined with continuoussurface area penalization. Our formulation is a convex relaxation which weaugment with a crucial non-convex constraint that ensures exact handling ofvisibility. To tackle the non-convex minimization problem, we propose amajorize-minimize type strategy which converges to a critical point. Wedemonstrate the benefits of using the non-convex constraint experimentally. Forthe geometry-only case, we set a new state of the art on two datasets of thecommonly used Middlebury multi-view stereo benchmark. Moreover, ourgeneral-purpose formulation directly reconstructs thin objects, which areusually treated with specialized algorithms. A qualitative evaluation on thedense semantic 3D reconstruction task shows that we improve significantly overprevious methods.
arxiv-1604-02910 | Deep Gate Recurrent Neural Network |  http://arxiv.org/abs/1604.02910  | author:Yuan Gao, Dorota Glowacka category:cs.NE published:2016-04-11 summary:This paper introduces two recurrent neural network structures called SimpleGated Unit (SGU) and Deep Simple Gated Unit (DSGU), which are generalstructures for learning long term dependencies. Compared to traditional LongShort-Term Memory (LSTM) and Gated Recurrent Unit (GRU), both structuresrequire fewer parameters and less computation time in sequence classificationtasks. Unlike GRU and LSTM, which require more than one gates to controlinformation flow in the network, SGU and DSGU only use one multiplicative gateto control the flow of information. We show that this difference can acceleratethe learning speed in tasks that require long dependency information. We alsoshow that DSGU is more numerically stable than SGU. In addition, we alsopropose a standard way of representing inner structure of RNN called RNNConventional Graph (RCG), which helps analyzing the relationship between inputunits and hidden units of RNN.
arxiv-1604-03392 | A statistical learning strategy for closed-loop control of fluid flows |  http://arxiv.org/abs/1604.03392  | author:Florimond Guéniat, Lionel Mathelin, M. Yousuff Hussaini category:stat.ML math.OC published:2016-04-11 summary:This work discusses a closed-loop control strategy for complex systemsutilizing scarce and streaming data. A discrete embedding space is first builtusing hash functions applied to the sensor measurements from which a Markovprocess model is derived, approximating the complex system's dynamics. Acontrol strategy is then learned using reinforcement learning once rewardsrelevant with respect to the control objective are identified. This method isdesigned for experimental configurations, requiring no computations nor priorknowledge of the system, and enjoys intrinsic robustness. It is illustrated ontwo systems: the control of the transitions of a Lorenz 63 dynamical system,and the control of the drag of a cylinder flow. The method is shown to performwell.
arxiv-1604-02898 | Sparse Coding for Alpha Matting |  http://arxiv.org/abs/1604.02898  | author:Jubin Johnson, Ehsan Shahrian Varnousfaderani, Hisham Cholakkal, Deepu Rajan category:cs.CV published:2016-04-11 summary:Existing color sampling based alpha matting methods use the compositingequation to estimate alpha at a pixel from pairs of foreground (F) andbackground (B) samples. The quality of the matte depends on the selected (F,B)pairs. In this paper, the matting problem is reinterpreted as a sparse codingof pixel features, wherein the sum of the codes gives the estimate of the alphamatte from a set of unpaired F and B samples. A non-parametric probabilisticsegmentation provides a certainty measure on the pixel belonging to foregroundor background, based on which a dictionary is formed for use in sparse coding.By removing the restriction to conform to (F,B) pairs, this method allows forbetter alpha estimation from multiple F and B samples. The same framework isextended to videos, where the requirement of temporal coherence is handledeffectively. Here, the dictionary is formed by samples from multiple frames. Amulti-frame graph model, as opposed to a single image as for image matting, isproposed that can be solved efficiently in closed form. Quantitative andqualitative evaluations on a benchmark dataset are provided to show that theproposed method outperforms current state-of-the-art in image and videomatting.
arxiv-1604-03427 | In the mood: the dynamics of collective sentiments on Twitter |  http://arxiv.org/abs/1604.03427  | author:Nathaniel Charlton, Colin Singleton, Danica Vukadinović Greetham category:cs.SI stat.ML published:2016-04-11 summary:We study the relationship between the sentiment levels of Twitter users andthe evolving network structure that the users created by @-mentioning eachother. We use a large dataset of tweets to which we apply three sentimentscoring algorithms, including the open source SentiStrength program.Specifically we make three contributions. Firstly we find that people who havepotentially the largest communication reach (according to a dynamic centralitymeasure) use sentiment differently than the average user: for example they usepositive sentiment more often and negative sentiment less often. Secondly wefind that when we follow structurally stable Twitter communities over a periodof months, their sentiment levels are also stable, and sudden changes incommunity sentiment from one day to the next can in most cases be traced toexternal events affecting the community. Thirdly, based on our findings, wecreate and calibrate a simple agent-based model that is capable of reproducingmeasures of emotive response comparable to those obtained from our empiricaldataset.
arxiv-1604-02902 | Statistics of RGBD Images |  http://arxiv.org/abs/1604.02902  | author:Dan Rosenbaum, Yair Weiss category:cs.CV published:2016-04-11 summary:Cameras that can measure the depth of each pixel in addition to its colorhave become easily available and are used in many consumer products worldwide.Often the depth channel is captured at lower quality compared to the RGBchannels and different algorithms have been proposed to improve the quality ofthe D channel given the RGB channels. Typically these approaches work byassuming that edges in RGB are correlated with edges in D. In this paper we approach this problem from the standpoint of natural imagestatistics. We obtain examples of high quality RGBD images from a computergraphics generated movie (MPI-Sintel) and we use these examples to comparedifferent probabilistic generative models of RGBD image patches. We then usethe generative models together with a degradation model and obtain a BayesLeast Squares (BLS) estimator of the D channel given the RGB channels. Ourresults show that learned generative models outperform the state-of-the-art inimproving the quality of depth channels given the color channels in naturalimages even when training is performed on artificially generated images.
arxiv-1604-03035 | Learning Global Features for Coreference Resolution |  http://arxiv.org/abs/1604.03035  | author:Sam Wiseman, Alexander M. Rush, Stuart M. Shieber category:cs.CL published:2016-04-11 summary:There is compelling evidence that coreference prediction would benefit frommodeling global information about entity-clusters. Yet, state-of-the-artperformance can be achieved with systems treating each mention predictionindependently, which we attribute to the inherent difficulty of craftinginformative cluster-level features. We instead propose to use recurrent neuralnetworks (RNNs) to learn latent, global representations of entity clustersdirectly from their mentions. We show that such representations are especiallyuseful for the prediction of pronominal mentions, and can be incorporated intoan end-to-end coreference system that outperforms the state of the art withoutrequiring any additional search.
arxiv-1604-03075 | Fully-Automatic Synapse Prediction and Validation on a Large Data Set |  http://arxiv.org/abs/1604.03075  | author:Gary B. Huang, Louis K. Scheffer, Stephen M. Plaza category:cs.CV published:2016-04-11 summary:Extracting a connectome from an electron microscopy (EM) data set requiresidentification of neurons and determination of synapses between neurons. Asmanual extraction of this information is very time-consuming, there has beenextensive research effort to automatically segment the neurons to help guideand eventually replace manual tracing. Until recently, there has beencomparatively less research on automatically detecting the actual synapsesbetween neurons. This discrepancy can, in part, be attributed to severalfactors: obtaining neuronal shapes is a prerequisite first step in extracting aconnectome, manual tracing is much more time-consuming than annotatingsynapses, and neuronal contact area can be used as a proxy for synapses indetermining connections. However, recent research has demonstrated that contact area alone is not asufficient predictor of synaptic connection. Moreover, as segmentation hasimproved, we have observed that synapse annotation is consuming a moresignificant fraction of overall reconstruction time. This ratio will only getworse as segmentation improves, gating overall possible speed-up. Therefore, weaddress this problem by developing algorithms that automatically detectpre-synaptic neurons and their post-synaptic partners. In particular,pre-synaptic structures are detected using a Deep and Wide Multiscale RecursiveNetwork, and post-synaptic partners are detected using a MLP with featuresconditioned on the local segmentation. This work is novel because it requires minimal amount of training, leveragesadvances in image segmentation directly, and provides a complete solution forpolyadic synapse detection. We further introduce novel metrics to evaluate ouralgorithm on connectomes of meaningful size. These metrics demonstrate thatcomplete automatic prediction can be used to effectively characterize mostconnectivity correctly.
arxiv-1604-03114 | Conversational flow in Oxford-style debates |  http://arxiv.org/abs/1604.03114  | author:Justine Zhang, Ravi Kumar, Sujith Ravi, Cristian Danescu-Niculescu-Mizil category:cs.CL cs.AI cs.SI physics.soc-ph stat.ML published:2016-04-11 summary:Public debates are a common platform for presenting and juxtaposing divergingviews on important issues. In this work we propose a methodology for trackinghow ideas flow between participants throughout a debate. We use this approachin a case study of Oxford-style debates---a competitive format where the winneris determined by audience votes---and show how the outcome of a debate dependson aspects of conversational flow. In particular, we find that winners tend tomake better use of a debate's interactive component than losers, by activelypursuing their opponents' points rather than promoting their own ideas over thecourse of the conversation.
arxiv-1604-03136 | Shallow Parsing Pipeline for Hindi-English Code-Mixed Social Media Text |  http://arxiv.org/abs/1604.03136  | author:Arnav Sharma, Sakshi Gupta, Raveesh Motlani, Piyush Bansal, Manish Srivastava, Radhika Mamidi, Dipti M. Sharma category:cs.CL published:2016-04-11 summary:In this study, the problem of shallow parsing of Hindi-English code-mixedsocial media text (CSMT) has been addressed. We have annotated the data,developed a language identifier, a normalizer, a part-of-speech tagger and ashallow parser. To the best of our knowledge, we are the first to attemptshallow parsing on CSMT. The pipeline developed has been made available to theresearch community with the goal of enabling better text analysis of HindiEnglish CSMT. The pipeline is accessible at http://bit.ly/csmt-parser-api .
arxiv-1604-03171 | Learning Simple Auctions |  http://arxiv.org/abs/1604.03171  | author:Jamie Morgenstern, Tim Roughgarden category:cs.LG cs.GT published:2016-04-11 summary:We present a general framework for proving polynomial sample complexitybounds for the problem of learning from samples the best auction in a class of"simple" auctions. Our framework captures all of the most prominent examples of"simple" auctions, including anonymous and non-anonymous item and bundlepricings, with either a single or multiple buyers. The technique we propose isto break the analysis of auctions into two natural pieces. First, one showsthat the set of allocation rules have large amounts of structure; second,fixing an allocation on a sample, one shows that the set of auctions agreeingwith this allocation on that sample have revenue functions with lowdimensionality. Our results effectively imply that whenever it's possible tocompute a near-optimal simple auction with a known prior, it is also possibleto compute such an auction with an unknown prior (given a polynomial number ofsamples).
arxiv-1604-03073 | Reservoir computing for spatiotemporal signal classification without trained output weights |  http://arxiv.org/abs/1604.03073  | author:Ashley Prater category:cs.NE cs.CV cs.LG published:2016-04-11 summary:Reservoir computing is a recently introduced machine learning paradigm thathas been shown to be well-suited for the processing of spatiotemporal data.Rather than training the network node connections and weights viabackpropagation in traditional recurrent neural networks, reservoirs insteadhave fixed connections and weights among the `hidden layer' nodes, andtraditionally only the weights to the output layer of neurons are trained usinglinear regression. We claim that for signal classification tasks, one may forgothe weight training step entirely and instead use a simple supervisedclustering method. The proposed method is analyzed theoretically and exploredthrough numerical experiments on real-world data. The examples demonstrate thatthe proposed clustering method outperforms the traditional trained outputweight approach in terms of speed, accuracy, and sensitivity to reservoirparameters.
arxiv-1604-03034 | M3: Scaling Up Machine Learning via Memory Mapping |  http://arxiv.org/abs/1604.03034  | author:Dezhi Fang, Duen Horng Chau category:cs.LG cs.DC published:2016-04-11 summary:To process data that do not fit in RAM, conventional wisdom would suggestusing distributed approaches. However, recent research has demonstrated virtualmemory's strong potential in scaling up graph mining algorithms on a singlemachine. We propose to use a similar approach for general machine learning. Wecontribute: (1) our latest finding that memory mapping is also a feasibletechnique for scaling up general machine learning algorithms like logisticregression and k-means, when data fits in or exceeds RAM (we tested datasets upto 190GB); (2) an approach, called M3, that enables existing machine learningalgorithms to work with out-of-core datasets through memory mapping, achievinga speed that is significantly faster than a 4-instance Spark cluster, andcomparable to an 8-instance cluster.
arxiv-1604-03058 | High Performance Binarized Neural Networks trained on the ImageNet Classification Task |  http://arxiv.org/abs/1604.03058  | author:Xundong Wu category:cs.CV cs.LG cs.NE published:2016-04-11 summary:We trained Binarized Neural Networks (BNNs) on the high resolution ImageNetLSVRC-2102 dataset classification task and achieved a good performance. With amoderate size network of 10 layers, we obtained top-5 classification accuracyrate of 81 percent on validation set which is much better than previouspublished results. We expect training networks of a much better performancethrough increase network depth would be straight forward by following ourcurrent strategies. A detailed discussion on strategies used in the networktraining is included as well as preliminary analysis.
arxiv-1604-02815 | Beyond Brightness Constancy: Learning Noise Models for Optical Flow |  http://arxiv.org/abs/1604.02815  | author:Dan Rosenbaum, Yair Weiss category:cs.CV published:2016-04-11 summary:Optical flow is typically estimated by minimizing a "data cost" and anoptional regularizer. While there has been much work on different regularizersmany modern algorithms still use a data cost that is not very different fromthe ones used over 30 years ago: a robust version of brightness constancy orgradient constancy. In this paper we leverage the recent availability ofground-truth optical flow databases in order to learn a data cost. Specificallywe take a generative approach in which the data cost models the distribution ofnoise after warping an image according to the flow and we measure the"goodness" of a data cost by how well it matches the true distribution of flowwarp error. Consistent with current practice, we find that robust versions ofgradient constancy are better models than simple brightness constancy but alearned GMM that models the density of patches of warp error gives a muchbetter fit than any existing assumption of constancy. This significantadvantage of the GMM is due to an explicit modeling of the spatial structure ofwarp errors, a feature which is missing from almost all existing data costs inoptical flow. Finally, we show how a good density model of warp error patchescan be used for optical flow estimation on whole images. We replace the datacost by the expected patch log-likelihood (EPLL), and show how this cost can beoptimized iteratively using an additional step of denoising the warp errorimage. The results of our experiments are promising and show that patch modelswith higher likelihood lead to better optical flow estimation.
arxiv-1604-02808 | NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis |  http://arxiv.org/abs/1604.02808  | author:Amir Shahroudy, Jun Liu, Tian-Tsong Ng, Gang Wang category:cs.CV published:2016-04-11 summary:Recent approaches in depth-based human activity analysis achieved outstandingperformance and proved the effectiveness of 3D representation forclassification of action classes. Currently available depth-based andRGB+D-based action recognition benchmarks have a number of limitations,including the lack of training samples, distinct class labels, camera views andvariety of subjects. In this paper we introduce a large-scale dataset for RGB+Dhuman action recognition with more than 56 thousand video samples and 4 millionframes, collected from 40 distinct subjects. Our dataset contains 60 differentaction classes including daily, mutual, and health-related actions. Inaddition, we propose a new recurrent neural network structure to model thelong-term temporal correlation of the features for each body part, and utilizethem for better action classification. Experimental results show the advantagesof applying deep learning methods over state-of-the-art hand-crafted featureson the suggested cross-subject and cross-view evaluation criteria for ourdataset. The introduction of this large scale dataset will enable the communityto apply, develop and adapt various data-hungry learning techniques for thetask of depth-based and RGB+D-based human activity analysis.
arxiv-1604-02801 | Capturing Dynamic Textured Surfaces of Moving Targets |  http://arxiv.org/abs/1604.02801  | author:Ruizhe Wang, Lingyu Wei, Etienne Vouga, Qixing Huang, Duygu Ceylan, Gerard Medioni, Hao Li category:cs.CV published:2016-04-11 summary:We present an end-to-end system for reconstructing complete watertight andtextured models of moving subjects such as clothed humans and animals, usingonly three or four handheld sensors. The heart of our framework is a newpairwise registration algorithm that minimizes, using a particle swarmstrategy, an alignment error metric based on mutual visibility and occlusion.We show that this algorithm reliably registers partial scans with as little as15% overlap without requiring any initial correspondences, and outperformsalternative global registration algorithms. This registration algorithm allowsus to reconstruct moving subjects from free-viewpoint video produced byconsumer-grade sensors, without extensive sensor calibration, constrainedcapture volume, expensive arrays of cameras, or templates of the subjectgeometry.
arxiv-1604-03099 | Symbolic Knowledge Extraction using Łukasiewicz Logics |  http://arxiv.org/abs/1604.03099  | author:Carlos Leandro category:cs.AI cs.LG published:2016-04-11 summary:This work describes a methodology that combines logic-based systems andconnectionist systems. Our approach uses finite truth-valued {\L}ukasiewiczlogic, wherein every connective can be defined by a neuron in an artificialnetwork. This allowed the injection of first-order formulas into a networkarchitecture, and also simplified symbolic rule extraction. For that we traineda neural networks using the Levenderg-Marquardt algorithm, where we restrictedthe knowledge dissemination in the network structure. This procedure reducesneural network plasticity without drastically damaging the learningperformance, thus making the descriptive power of produced neural networkssimilar to the descriptive power of {\L}ukasiewicz logic language andsimplifying the translation between symbolic and connectionist structures. Weused this method for reverse engineering truth table and in extraction offormulas from real data sets.
arxiv-1604-02917 | Gaussian Process Domain Experts for Model Adaptation in Facial Behavior Analysis |  http://arxiv.org/abs/1604.02917  | author:Stefanos Eleftheriadis, Ognjen Rudovic, Marc P. Deisenroth, Maja Pantic category:stat.ML cs.CV cs.LG published:2016-04-11 summary:We present a novel approach for supervised domain adaptation that is basedupon the probabilistic framework of Gaussian processes (GPs). Specifically, weintroduce domain-specific GPs as local experts for facial expressionclassification from face images. The adaptation of the classifier isfacilitated in probabilistic fashion by conditioning the target expert onmultiple source experts. Furthermore, in contrast to existing adaptationapproaches, we also learn a target expert from available target data solely.Then, a single and confident classifier is obtained by combining thepredictions from multiple experts based on their confidence. Learning of themodel is efficient and requires no retraining/reweighting of the sourceclassifiers. We evaluate the proposed approach on two publicly availabledatasets for multi-class (MultiPIE) and multi-label (DISFA) facial expressionclassification. To this end, we perform adaptation of two contextual factors:'where' (view) and 'who' (subject). We show in our experiments that theproposed approach consistently outperforms both source and target classifiers,while using as few as 30 target examples. It also outperforms thestate-of-the-art approaches for supervised domain adaptation.
arxiv-1604-02774 | Reverse Engineering and Symbolic Knowledge Extraction on Łukasiewicz Fuzzy Logics using Linear Neural Networks |  http://arxiv.org/abs/1604.02774  | author:Carlos Leandro category:cs.AI cs.NE 94D04 published:2016-04-11 summary:This work describes a methodology to combine logic-based systems andconnectionist systems. Our approach uses finite truth valued {\L}ukasiewiczlogic, where we take advantage of fact what in this type of logics everyconnective can be define by a neuron in an artificial network having byactivation function the identity truncated to zero and one. This allowed theinjection of first-order formulas in a network architecture, and alsosimplified symbolic rule extraction. Our method trains a neural network using Levenderg-Marquardt algorithm, wherewe restrict the knowledge dissemination in the network structure. We show howthis reduces neural networks plasticity without damage drastically the learningperformance. Making the descriptive power of produced neural networks similarto the descriptive power of {\L}ukasiewicz logic language, simplifying thetranslation between symbolic and connectionist structures. This method is used in the reverse engineering problem of finding the formulaused on generation of a truth table for a multi-valued {\L}ukasiewicz logic.For real data sets the method is particularly useful for attribute selection,on binary classification problems defined using nominal attribute. Afterattribute selection and possible data set completion in the resultingconnectionist model: neurons are directly representable using a disjunctive orconjunctive formulas, in the {\L}ukasiewicz logic, or neurons areinterpretations which can be approximated by symbolic rules. This fact isexemplified, extracting symbolic knowledge from connectionist models generatedfor the data set Mushroom from UCI Machine Learning Repository.
arxiv-1604-03006 | Demystifying Fixed k-Nearest Neighbor Information Estimators |  http://arxiv.org/abs/1604.03006  | author:Weihao Gao, Sewoong Oh, Pramod Viswanath category:cs.LG cs.IT math.IT stat.ML published:2016-04-11 summary:Estimating mutual information from i.i.d. samples drawn from an unknown jointdensity function is a basic statistical problem of broad interest withmultitudinous applications. The most popular estimator is one proposed byKraskov and St\"ogbauer and Grassberger (KSG) in 2004, and is nonparametric andbased on the distances of each sample to its $k^{\rm th}$ nearest neighboringsample, where $k$ is a fixed small integer. Despite its widespread use (part ofscientific software packages), theoretical properties of this estimator havebeen largely unexplored. In this paper we demonstrate that the estimator isconsistent and also identify an upper bound on the rate of convergence of thebias as a function of number of samples. We argue that the superior performancebenefits of the KSG estimator stems from a curious "correlation boosting"effect and build on this intuition to modify the KSG estimator in novel ways toconstruct a superior estimator. As a byproduct of our investigations, we obtainnearly tight rates of convergence of the $\ell_2$ error of the well known fixed$k$ nearest neighbor estimator of differential entropy by Kozachenko andLeonenko.
arxiv-1604-03168 | Hardware-oriented Approximation of Convolutional Neural Networks |  http://arxiv.org/abs/1604.03168  | author:Philipp Gysel, Mohammad Motamedi, Soheil Ghiasi category:cs.CV published:2016-04-11 summary:High computational complexity hinders the widespread usage of ConvolutionalNeural Networks (CNNs), especially in mobile devices. Hardware accelerators arearguably the most promising approach for reducing both execution time and powerconsumption. One of the most important steps in accelerator development ishardware-oriented model approximation. In this paper we present Ristretto, amodel approximation framework that analyzes a given CNN with respect tonumerical resolution used in representing weights and outputs of convolutionaland fully connected layers. Ristretto can condense models by using fixed pointarithmetic and representation instead of floating point. Moreover, Ristrettofine-tunes the resulting fixed point network. Given a maximum error toleranceof 1%, Ristretto can successfully condense CaffeNet and SqueezeNet to 8-bit.The code for Ristretto is available.
arxiv-1604-03010 | Semi-supervised learning of local structured output predictors |  http://arxiv.org/abs/1604.03010  | author:Xin Du category:cs.LG cs.CV published:2016-04-11 summary:In this paper, we study the problem of semi-supervised structured outputprediction, which aims to learn predictors for structured outputs, such assequences, tree nodes, vectors, etc., from a set of data points of bothinput-output pairs and single inputs without outputs. The traditional methodsto solve this problem usually learns one single predictor for all the datapoints, and ignores the variety of the different data points. Different partsof the data set may have different local distributions, and requires differentoptimal local predictors. To overcome this disadvantage of existing methods, wepropose to learn different local predictors for neighborhoods of different datapoints, and the missing structured outputs simultaneously. In the neighborhoodof each data point, we proposed to learn a linear predictor by minimizing boththe complexity of the predictor and the upper bound of the structuredprediction loss. The minimization is conducted by gradient descent algorithms.Experiments over four benchmark data sets, including DDSM mammography medicalimages, SUN natural image data set, Cora research paper data set, and Spanishnews wire article sentence data set, show the advantages of the proposedmethod.
arxiv-1604-02737 | Correlated Equilibria for Approximate Variational Inference in MRFs |  http://arxiv.org/abs/1604.02737  | author:Luis E. Ortiz, Ze Gong category:cs.AI cs.GT stat.ML published:2016-04-10 summary:Almost all of the work in graphical models for game theory has mirroredprevious work in probabilistic graphical models. Our work considers theopposite direction: Taking advantage of recent advances in equilibriumcomputation for belief inference. In particular, we present formulations ofinference problems in Markov random fields (MRFs) as computation of equilibriain a certain class of game-theoretic graphical models. While some previous workexplores this direction, none of that work concretely establishes the preciseconnection between variational probabilistic inference in MRFs and correlatedequilibria. There is no work that exploits recent theoretical and empiricalresults from the literature on algorithmic and computational game theory on thetractable, polynomial-time computation of exact or approximate correlatedequilibria in graphical games with arbitrary, loopy graph structure. Our workdiscusses how to design new algorithms with equally tractable guarantees forthe computation of approximate variational inference in MRFs. In addition,inspired by a previously stated game-theoretic view of state-of-the-arttree-reweighed (TRW) message-passing techniques for belief inference aszero-sum game, we propose a different, general-sum potential game to designapproximate fictitious-play techniques. We perform synthetic experimentsevaluating our proposed approximation algorithms with standard methods and TRWon several classes of classical Ising models. Our experiments show that ourglobal approach is competitive, particularly shinning in a class of Isingmodels with constant, "highly attractive" edge-weights, in which it is oftenbetter than all other alternatives we evaluated. While our local approach wasnot as effective as our global approach or TRW, almost all of the alternativesare often no better than a simple baseline: estimate the marginal probabilityto be 0.5.
arxiv-1604-02752 | Performance Trade-Offs in Multi-Processor Approximate Message Passing |  http://arxiv.org/abs/1604.02752  | author:Junan Zhu, Ahmad Beirami, Dror Baron category:cs.IT cs.DC cs.LG math.IT published:2016-04-10 summary:We consider large-scale linear inverse problems in Bayesian settings. Ourgeneral approach follows a recent line of work that applies the approximatemessage passing (AMP) framework in multi-processor (MP) computational systemsby storing and processing a subset of rows of the measurement matrix along withcorresponding measurements at each MP node. In each MP-AMP iteration, nodes ofthe MP system and its fusion center exchange lossily compressed messagespertaining to their estimates of the input. There is a trade-off between thephysical costs of the reconstruction process including computation time,communication loads, and the reconstruction quality, and it is impossible tosimultaneously minimize all the costs. We pose this minimization as amulti-objective optimization problem (MOP), and study the properties of thebest trade-offs (Pareto optimality) in this MOP. We prove that the achievableregion of this MOP is convex, and conjecture how the combined cost ofcomputation and communication scales with the desired mean squared error. Theseproperties are verified numerically.
arxiv-1604-02703 | Synthesizing Training Images for Boosting Human 3D Pose Estimation |  http://arxiv.org/abs/1604.02703  | author:Wenzheng Chen, Huan Wang, Yangyan Li, Hao Su, Changhe Tu, Dani Lischinski, Daniel Cohen-Or, Baoquan Chen category:cs.CV published:2016-04-10 summary:Human 3D pose estimation from a single image is a challenging task withnumerous applications. Convolutional Neural Networks (CNNs) have recentlyachieved superior performance on the task of 2D pose estimation from a singleimage, by training on images with 2D annotations collected by crowd sourcing.This suggests that similar success could be achieved for direct estimation of3D poses. However, 3D poses are much harder to annotate, and the lack ofsuitable annotated training images hinders attempts towards end-to-endsolutions. To address this issue, we opt to automatically synthesize training imageswith ground truth pose annotations. We find that pose space coverage andtexture diversity are the key ingredients for the effectiveness of synthetictraining data. We present a fully automatic, scalable approach that samples thehuman pose space for guiding the synthesis procedure and extracts clothingtextures from real images. We demonstrate that CNNs trained with our syntheticimages out-perform those trained with real photos on 3D pose estimation tasks.
arxiv-1604-02619 | TextProposals: a Text-specific Selective Search Algorithm for Word Spotting in the Wild |  http://arxiv.org/abs/1604.02619  | author:Lluis Gomez-Bigorda, Dimosthenis Karatzas category:cs.CV published:2016-04-10 summary:The use of object proposals in scene text understanding tasks is innovative.Motivated by the success of powerful while expensive techniques to recognizewords in a holistic way, object proposals techniques emerge as an alternativeto the traditional text detectors. In this paper we introduce a novel objectproposals method that is specifically designed for text. We rely on asimilarity based region grouping algorithm that generates a hierarchy of wordhypotheses. Over the nodes of this hierarchy it is possible to apply a holisticword recognition method in an efficient way. Our experiments demonstrate that the presented method is superior in itsability of producing good quality word proposals when compared withclass-independent algorithms. We show impressive recall rates with a fewthousand proposals in different standard benchmarks, including focused orincidental text datasets, and multi-language scenarios. Moreover, thecombination of our object proposals with existing whole-word recognizers showcompetitive performance in end-to-end word spotting, and, in some benchmarks,outperforms previously published results. Concretely, in the challengingICDAR2015 Incidental Text dataset, we overcome in more than 10 percent f-scorethe best-performing method in the last ICDAR Robust Reading Competition. Sourcecode of the complete end-to-end system is available athttps://github.com/lluisgomez/TextProposals.
arxiv-1604-02715 | Soccer Field Localization from a Single Image |  http://arxiv.org/abs/1604.02715  | author:Namdar Homayounfar, Sanja Fidler, Raquel Urtasun category:cs.CV published:2016-04-10 summary:In this work, we propose a novel way of efficiently localizing a soccer fieldfrom a single broadcast image of the game. Related work in this area relies onmanually annotating a few key frames and extending the localization to similarimages, or installing fixed specialized cameras in the stadium from which thelayout of the field can be obtained. In contrast, we formulate this problem asa branch and bound inference in a Markov random field where an energy functionis defined in terms of field cues such as grass, lines and circles. Moreover,our approach is fully automatic and depends only on single images from thebroadcast video of the game. We demonstrate the effectiveness of our method byapplying it to various games and obtain promising results. Finally, we positthat our approach can be applied easily to other sports such as hockey andbasketball.
arxiv-1604-02646 | Visualization Regularizers for Neural Network based Image Recognition |  http://arxiv.org/abs/1604.02646  | author:Biswajit Paria, Anirban Santara, Pabitra Mitra category:cs.LG cs.CV cs.NE published:2016-04-10 summary:The success of deep neural networks is mostly due their ability to learnmeaningful features from the data. Features learned in the hidden layers ofdeep neural networks trained in computer vision tasks have been shown to besimilar to mid-level vision features. We leverage this fact in this work andpropose the visualization regularizer for image tasks. The proposedregularization technique enforces smoothness of the features learned by hiddennodes and turns out to be a special case of Tikhonov regularization. We achievehigher classification accuracy as compared to existing regularizers such as theL2 norm regularizer and dropout, on benchmark datasets with no change in thetraining computational complexity.
arxiv-1604-02677 | DCAN: Deep Contour-Aware Networks for Accurate Gland Segmentation |  http://arxiv.org/abs/1604.02677  | author:Hao Chen, Xiaojuan Qi, Lequan Yu, Pheng-Ann Heng category:cs.CV published:2016-04-10 summary:The morphology of glands has been used routinely by pathologists to assessthe malignancy degree of adenocarcinomas. Accurate segmentation of glands fromhistology images is a crucial step to obtain reliable morphological statisticsfor quantitative diagnosis. In this paper, we proposed an efficient deepcontour-aware network (DCAN) to solve this challenging problem under a unifiedmulti-task learning framework. In the proposed network, multi-level contextualfeatures from the hierarchical architecture are explored with auxiliarysupervision for accurate gland segmentation. When incorporated with multi-taskregularization during the training, the discriminative capability ofintermediate features can be further improved. Moreover, our network can notonly output accurate probability maps of glands, but also depict clear contourssimultaneously for separating clustered objects, which further boosts the glandsegmentation performance. This unified framework can be efficient when appliedto large-scale histopathological data without resorting to additional steps togenerate contours based on low-level cues for post-separating. Our method wonthe 2015 MICCAI Gland Segmentation Challenge out of 13 competitive teams,surpassing all the other methods by a significant margin.
arxiv-1604-02668 | Distance for Functional Data Clustering Based on Smoothing Parameter Commutation |  http://arxiv.org/abs/1604.02668  | author:ShengLi Tzeng, Christian Hennig, Yu-Fen Li, Chien-Ju Lin category:stat.ME stat.AP stat.ML published:2016-04-10 summary:We propose a novel method to determine the dissimilarity between subjects forfunctional data clustering. Spline smoothing or interpolation is common to dealwith data of such type. Instead of estimating the best-representing curve foreach subject as fixed during clustering, we measure the dissimilarity betweensubjects based on varying curve estimates with commutation of smoothingparameters pair-by-pair (of subjects). The intuitions are that smoothingparameters of smoothing splines reflect inverse signal-to-noise ratios and thatapplying an identical smoothing parameter the smoothed curves for two similarsubjects are expected to be close. The effectiveness of our proposal is shownthrough simulations comparing to other dissimilarity measures. It also hasseveral pragmatic advantages. First, missing values or irregular time pointscan be handled directly, thanks to the nature of smoothing splines. Second,conventional clustering method based on dissimilarity can be employedstraightforward, and the dissimilarity also serves as a useful tool for outlierdetection. Third, the implementation is almost handy since subroutines forsmoothing splines and numerical integration are widely available. Fourth, thecomputational complexity does not increase and is parallel with that incalculating Euclidean distance between curves estimated by smoothing splines.
arxiv-1604-02631 | Grid Based Nonlinear Filtering Revisited: Recursive Estimation & Asymptotic Optimality |  http://arxiv.org/abs/1604.02631  | author:Dionysios S. Kalogerias, Athina P. Petropulu category:math.ST cs.IT math.IT math.OC stat.ME stat.ML stat.TH published:2016-04-10 summary:We revisit the development of grid based recursive approximate filtering ofgeneral Markov processes in discrete time, partially observed in conditionallyGaussian noise. The grid based filters considered rely on two types of statequantization: The \textit{Markovian} type and the \textit{marginal} type. Wepropose a set of novel, relaxed sufficient conditions, ensuring strong andfully characterized pathwise convergence of these filters to the respectiveMMSE state estimator. In particular, for marginal state quantizations, weintroduce the notion of \textit{conditional regularity of stochastic kernels},which, to the best of our knowledge, constitutes the most relaxed conditionproposed, under which asymptotic optimality of the respective grid basedfilters is guaranteed. Further, we extend our convergence results, includingfiltering of bounded and continuous functionals of the state, as well asrecursive approximate state prediction. For both Markovian and marginalquantizations, the whole development of the respective grid based filtersrelies more on linear-algebraic techniques and less on measure theoreticarguments, making the presentation considerably shorter and technicallysimpler.
arxiv-1604-02634 | Online Nonnegative Matrix Factorization with Outliers |  http://arxiv.org/abs/1604.02634  | author:Renbo Zhao, Vincent Y. F. Tan category:stat.ML cs.LG math.OC stat.ME published:2016-04-10 summary:We propose a unified and systematic framework for performing onlinenonnegative matrix factorization in the presence of outliers that isparticularly suited to large datasets. Within this framework, we propose twosolvers based on proximal gradient descent and alternating direction method ofmultipliers. We prove that the objective function converges almost surely byappealing to the quasi-martingale convergence theorem. We also show the learnedbasis matrix converges to the set of local minimizers of the objective functionalmost surely. In addition, we extend our basic problem formulation to varioussettings with different constraints and regularizers, and adapt the solvers andanalyses to each setting. We perform extensive experiments on both syntheticand image datasets. These experiments demonstrate the efficiency and efficacyof our algorithm on tasks such as basis learning, image denoising and shadowremoval.
arxiv-1604-02657 | Direction matters: hand pose estimation from local surface normals |  http://arxiv.org/abs/1604.02657  | author:Chengde Wan, Angela Yao, Luc Van Gool category:cs.CV published:2016-04-10 summary:We present a hierarchical regression framework for estimating hand jointpositions from single depth images based on local surface normals. Thehierarchical regression follows the tree structured topology of hand from wristto finger tips. We propose a conditional regression forest, i.e., the FrameConditioned Regression Forest (FCRF) which uses a new normal differencefeature. At each stage of the regression, the frame of reference is establishedfrom either the local surface normal or previously estimated hand joints. Bymaking the regression with respect to the local frame, the pose estimation ismore robust to rigid transformations. We also introduce a new efficientapproximation to estimate surface normals. We verify the effectiveness of ourmethod by conducting experiments on two challenging real-world datasets andshow consistent improvements over previous discriminative pose estimationmethods.
arxiv-1604-02647 | Real-Time Facial Segmentation and Performance Capture from RGB Input |  http://arxiv.org/abs/1604.02647  | author:Shunsuke Saito, Tianye Li, Hao Li category:cs.CV published:2016-04-10 summary:We introduce the concept of unconstrained real-time 3D facial performancecapture through explicit semantic segmentation in the RGB input. To ensurerobustness, cutting edge supervised learning approaches rely on large trainingdatasets of face images captured in the wild. While impressive tracking qualityhas been demonstrated for faces that are largely visible, any occlusion due tohair, accessories, or hand-to-face gestures would result in significant visualartifacts and loss of tracking accuracy. The modeling of occlusions has beenmostly avoided due to its immense space of appearance variability. To addressthis curse of high dimensionality, we perform tracking in unconstrained imagesassuming non-face regions can be fully masked out. Along with recentbreakthroughs in deep learning, we demonstrate that pixel-level facialsegmentation is possible in real-time by repurposing convolutional neuralnetworks designed originally for general semantic segmentation. We develop anefficient architecture based on a two-stream deconvolution network withcomplementary characteristics, and introduce carefully designed trainingsamples and data augmentation strategies for improved segmentation accuracy androbustness. We adopt a state-of-the-art regression-based facial trackingframework with segmented face images as training, and demonstrate accurate anduninterrupted facial performance capture in the presence of extreme occlusionand even side views. Furthermore, the resulting segmentation can be directlyused to composite partial 3D face models on the input images and enableseamless facial manipulation tasks, such as virtual make-up or facereplacement.
arxiv-1604-02748 | TGIF: A New Dataset and Benchmark on Animated GIF Description |  http://arxiv.org/abs/1604.02748  | author:Yuncheng Li, Yale Song, Liangliang Cao, Joel Tetreault, Larry Goldberg, Alejandro Jaimes, Jiebo Luo category:cs.CV published:2016-04-10 summary:With the recent popularity of animated GIFs on social media, there is needfor ways to index them with rich metadata. To advance research on animated GIFunderstanding, we collected a new dataset, Tumblr GIF (TGIF), with 100Kanimated GIFs from Tumblr and 120K natural language descriptions obtained viacrowdsourcing. The motivation for this work is to develop a testbed for imagesequence description systems, where the task is to generate natural languagedescriptions for animated GIFs or video clips. To ensure a high qualitydataset, we developed a series of novel quality controls to validate free-formtext input from crowdworkers. We show that there is unambiguous associationbetween visual content and natural language descriptions in our dataset, makingit an ideal benchmark for the visual content captioning task. We performextensive statistical analyses to compare our dataset to existing image andvideo description datasets. Next, we provide baseline results on the animatedGIF description task, using three representative techniques: nearest neighbor,statistical machine translation, and recurrent neural networks. Finally, weshow that models fine-tuned from our animated GIF description dataset can behelpful for automatic movie description.
arxiv-1604-02546 | Scene-driven Retrieval in Edited Videos using Aesthetic and Semantic Deep Features |  http://arxiv.org/abs/1604.02546  | author:Lorenzo Baraldi, Costantino Grana, Rita Cucchiara category:cs.CV cs.IR cs.MM published:2016-04-09 summary:This paper presents a novel retrieval pipeline for video collections, whichaims to retrieve the most significant parts of an edited video for a givenquery, and represent them with thumbnails which are at the same timesemantically meaningful and aesthetically remarkable. Videos are firstsegmented into coherent and story-telling scenes, then a retrieval algorithmbased on deep learning is proposed to retrieve the most significant scenes fora textual query. A ranking strategy based on deep features is finally used totackle the problem of visualizing the best thumbnail. Qualitative andquantitative experiments are conducted on a collection of edited videos todemonstrate the effectiveness of our approach.
arxiv-1604-02531 | Person Re-identification in the Wild |  http://arxiv.org/abs/1604.02531  | author:Liang Zheng, Hengheng Zhang, Shaoyan Sun, Manmohan Chandraker, Qi Tian category:cs.CV published:2016-04-09 summary:We present a novel large-scale dataset and comprehensive baselines forend-to-end pedestrian detection and person recognition in raw video frames. Ourbaselines address three issues: the performance of various combinations ofdetectors and recognizers, mechanisms for pedestrian detection to help improveoverall re-identification accuracy and assessing the effectiveness of differentdetectors for re-identification. We make three distinct contributions. First, anew dataset, PRW, is introduced to evaluate Person Re-identification in theWild, using videos acquired through six synchronized cameras. It contains 932identities and 11,816 frames in which pedestrians are annotated with theirbounding box positions and identities. Extensive benchmarking results arepresented on this dataset. Second, we show that pedestrian detection aidsre-identification through two simple yet effective improvements: adiscriminatively trained ID-discriminative Embedding (IDE) in the personsubspace using convolutional neural network (CNN) features and a ConfidenceWeighted Similarity (CWS) metric that incorporates detection scores intosimilarity measurement. Third, we derive insights in evaluating detectorperformance for the particular scenario of accurate person re-identification.
arxiv-1604-02612 | Fusing Audio, Textual and Visual Features for Sentiment Analysis of News Videos |  http://arxiv.org/abs/1604.02612  | author:Moisés H. R. Pereira, Flávio L. C. Pádua, Adriano C. M. Pereira, Fabrício Benevenuto, Daniel H. Dalip category:cs.CL published:2016-04-09 summary:This paper presents a novel approach to perform sentiment analysis of newsvideos, based on the fusion of audio, textual and visual clues extracted fromtheir contents. The proposed approach aims at contributing to thesemiodiscoursive study regarding the construction of the ethos (identity) ofthis media universe, which has become a central part of the modern-day lives ofmillions of people. To achieve this goal, we apply state-of-the-artcomputational methods for (1) automatic emotion recognition from facialexpressions, (2) extraction of modulations in the participants' speeches and(3) sentiment analysis from the closed caption associated to the videos ofinterest. More specifically, we compute features, such as, visual intensitiesof recognized emotions, field sizes of participants, voicing probability, soundloudness, speech fundamental frequencies and the sentiment scores (polarities)from text sentences in the closed caption. Experimental results with a datasetcontaining 520 annotated news videos from three Brazilian and one Americanpopular TV newscasts show that our approach achieves an accuracy of up to 84%in the sentiments (tension levels) classification task, thus demonstrating itshigh potential to be used by media analysts in several applications,especially, in the journalistic domain.
arxiv-1604-02606 | A General Retraining Framework for Scalable Adversarial Classification |  http://arxiv.org/abs/1604.02606  | author:Bo Li, Yevgeniy Vorobeychik, Xinyun Chen category:cs.GT cs.LG stat.ML published:2016-04-09 summary:Traditional classification algorithms assume that training and test data comefrom the same or similar distribution. This assumption is violated inadversarial settings, where malicious actors modify instances to evadedetection. A number of custom methods have been developed for both adversarialevasion attacks and robust learning. We propose the first systematic andgeneral-purpose retraining framework which can: a) boost robustness of anarbitrary learning algorithm, and b) incorporate a broad class of adversarialmodels. We show that, under natural conditions, the retraining frameworkminimizes an upper bound on optimal adversarial risk, and show how to extendthis result to account for approximations of evasion attacks. We also offer avery general adversarial evasion model and algorithmic framework based oncoordinate greedy local search. Extensive experimental evaluation demonstratesthat our retraining methods are nearly indistinguishable from state-of-the-artalgorithms for optimizing adversarial risk, but far more scalable and general.The experiments also confirm that without retraining, our adversarial frameworkis extremely effective in dramatically reducing the effectiveness of learning.In contrast, retraining significantly boosts robustness to evasion attackswithout compromising much overall accuracy.
arxiv-1604-02506 | Higher order features and recurrent neural networks based on Long-Short Term Memory nodes in supervised biomedical word sense disambiguation |  http://arxiv.org/abs/1604.02506  | author:Antonio Jimeno Yepes category:cs.CL cs.LG published:2016-04-09 summary:Word sense disambiguation helps identifying the proper sense of ambiguouswords in text. With large terminologies such as the UMLS Metathesaurusambiguities appear and highly effective disambiguation methods are required.Supervised learning algorithm methods are used as one of the approaches toperform disambiguation. Features extracted from the context of an ambiguousword are used to identify the proper sense of such a word. The type of featureshave an impact on machine learning methods, thus affect disambiguationperformance. In this work, we have evaluated several types of features derivedfrom the context of the ambiguous word and we have explored as well more globalfeatures derived from MEDLINE using word embeddings. Results show that wordembeddings improve the performance of more traditional features and allow aswell using recurrent neural networks based on Long-Short Term Memory (LSTM)nodes, which further improve the disambiguation performance. The combination ofunigrams and word embeddings set a new state of the art performance with anaccuracy of 95.97 in the MSH WSD data set.
arxiv-1604-02594 | Learning Compact Recurrent Neural Networks |  http://arxiv.org/abs/1604.02594  | author:Zhiyun Lu, Vikas Sindhwani, Tara N. Sainath category:cs.LG cs.CL cs.NE published:2016-04-09 summary:Recurrent neural networks (RNNs), including long short-term memory (LSTM)RNNs, have produced state-of-the-art results on a variety of speech recognitiontasks. However, these models are often too large in size for deployment onmobile devices with memory and latency constraints. In this work, we studymechanisms for learning compact RNNs and LSTMs via low-rank factorizations andparameter sharing schemes. Our goal is to investigate redundancies in recurrentarchitectures where compression can be admitted without losing performance. Ahybrid strategy of using structured matrices in the bottom layers and sharedlow-rank factors on the top layers is found to be particularly effective,reducing the parameters of a standard LSTM by 75%, at a small cost of 0.3%increase in WER, on a 2,000-hr English Voice Search task.
arxiv-1604-02532 | T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos |  http://arxiv.org/abs/1604.02532  | author:Kai Kang, Hongsheng Li, Junjie Yan, Xingyu Zeng, Bin Yang, Tong Xiao, Cong Zhang, Zhe Wang, Ruohui Wang, Xiaogang Wang, Wanli Ouyang category:cs.CV published:2016-04-09 summary:The state-of-the-art performance for object detection has been significantlyimproved over the past two years. Besides the introduction of powerful deepneural networks such as GoogleNet and VGG, novel object detection frameworkssuch as R-CNN and its successors, Fast R-CNN and Faster R-CNN, play anessential role in improving the state-of-the-art. Despite their effectivenesson still images, those frameworks are not specifically designed for objectdetection from videos. Temporal and contextual information of videos are notfully investigated and utilized. In this work, we propose a deep learningframework that incorporates temporal and contextual information from tubeletsobtained in videos, which dramatically improves the baseline performance ofexisting still-image detection frameworks when they are applied to videos. Itis called T-CNN, i.e. tubelets with convolutional neueral networks. Theproposed framework won the recently introduced object-detection-from-video(VID) task with provided data in the ImageNet Large-Scale Visual RecognitionChallenge 2015 (ILSVRC2015).
arxiv-1604-02264 | Probabilistic classifiers with low rank indefinite kernels |  http://arxiv.org/abs/1604.02264  | author:Frank-Michael Schleif, Andrej Gisbrecht, Peter Tino category:cs.LG published:2016-04-08 summary:Indefinite similarity measures can be frequently found in bio-informatics bymeans of alignment scores, but are also common in other fields like shapemeasures in image retrieval. Lacking an underlying vector space, the data aregiven as pairwise similarities only. The few algorithms available for such datado not scale to larger datasets. Focusing on probabilistic batch classifiers,the Indefinite Kernel Fisher Discriminant (iKFD) and the ProbabilisticClassification Vector Machine (PCVM) are both effective algorithms for thistype of data but, with cubic complexity. Here we propose an extension of iKFDand PCVM such that linear runtime and memory complexity is achieved for lowrank indefinite kernels. Employing the Nystr\"om approximation for indefinitekernels, we also propose a new almost parameter free approach to identify thelandmarks, restricted to a supervised learning problem. Evaluations at severallarger similarity data from various domains show that the proposed methodsprovides similar generalization capabilities while being easier to parametrizeand substantially faster for large scale data.
arxiv-1604-02270 | Single-Molecule Protein Identification by Sub-Nanopore Sensors |  http://arxiv.org/abs/1604.02270  | author:Mikhail Kolmogorov, Eamonn Kennedy, Zhuxin Dong, Gregory Timp, Pavel Pevzner category:q-bio.QM cs.LG published:2016-04-08 summary:Recent advances in top-down mass spectrometry enabled identification ofintact proteins, but this technology still faces challenges. For example,top-down mass spectrometry suffers from a lack of sensitivity since the ioncounts for a single fragmentation event are often low. In contrast, nanoporetechnology is exquisitely sensitive to single intact molecules, but it has onlybeen successfully applied to DNA sequencing, so far. Here, we explore thepotential of sub-nanopores for single-molecule protein identification (SMPI)and describe an algorithm for analyzing the electrical current blockade signal(nanospectrum) resulting from the translocation of a denaturated, linearlycharged protein through a sub-nanopore. We further describe the first SMPIalgorithm, compute the p-values of Protein-Nanospectrum Matches, and discussthe promise and computational limitations of the current SMPI technology.
arxiv-1604-02271 | Deep Structured Scene Parsing by Learning with Image Descriptions |  http://arxiv.org/abs/1604.02271  | author:Liang Lin, Guangrun Wang, Rui Zhang, Ruimao Zhang, Xiaodan Liang, Wangmeng Zuo category:cs.CV 68U10 I.4.8; I.5 published:2016-04-08 summary:This paper addresses a fundamental problem of scene understanding: How toparse the scene image into a structured configuration (i.e., a semantic objecthierarchy with object interaction relations) that finely accords with humanperception. We propose a deep architecture consisting of two networks: i) aconvolutional neural network (CNN) extracting the image representation forpixelwise object labeling and ii) a recursive neural network (RNN) discoveringthe hierarchical object structure and the inter-object relations. Rather thanrelying on elaborative user annotations (e.g., manually labeling semantic mapsand relations), we train our deep model in a weakly-supervised manner byleveraging the descriptive sentences of the training images. Specifically, wedecompose each sentence into a semantic tree consisting of nouns and verbphrases, and facilitate these trees discovering the configurations of thetraining images. Once these scene configurations are determined, then theparameters of both the CNN and RNN are updated accordingly by back propagation.The entire model training is accomplished through an Expectation-Maximizationmethod. Extensive experiments suggest that our model is capable of producingmeaningful and structured scene configurations and achieving more favorablescene labeling performance on PASCAL VOC 2012 over other state-of-the-artweakly-supervised methods.
arxiv-1604-02388 | RGBD Semantic Segmentation Using Spatio-Temporal Data-Driven Pooling |  http://arxiv.org/abs/1604.02388  | author:Yang He, Wei-Chen Chiu, Margret Keuper, Mario Fritz category:cs.CV published:2016-04-08 summary:Beyond the success in classification, neural networks have recently shownstrong results on pixel-wise prediction tasks like image semantic segmentationon RGBD data. However, the commonly used deconvolutional layers for upsamplingintermediate representations to the full-resolution output still showsdifferent failure modes, like imprecise segmentation boundaries and labelmistakes particular on large, weakly textured objects (e.g. fridge, whiteboard,door). We attribute these errors in part to the rigid way, current networkaggregate information, that can be either too local (missing context) or tooglobal (inaccurate boundaries). Therefore we propose a data-driven poolinglayer that integrates with fully convolutional architectures and utilizesboundary detection from RGBD image segmentation approaches. We extend ourapproach to leverage region-level correspondence across images with anadditional temporal pooling stage. We evaluate our approach on the NYU-Depth-V2dataset comprised of indoor RGBD video sequences and make comparison withrespect to various state-of-the-art baselines. We improve on thestate-of-the-art and in particular in accuracy of the predicted boundaries andpreviously problematic classes.
arxiv-1604-02355 | The (1+1) Elitist Black-Box Complexity of LeadingOnes |  http://arxiv.org/abs/1604.02355  | author:Carola Doerr, Johannes Lengler category:cs.NE cs.CC F.2.2 published:2016-04-08 summary:One important goal of black-box complexity theory is the development ofcomplexity models allowing to derive meaningful lower bounds for whole classesof randomized search heuristics. Complementing classical runtime analysis,black-box models help us understand how algorithmic choices such as thepopulation size, the variation operators, or the selection rules influence theoptimization time. One example for such a result is the $\Omega(n \log n)$lower bound for unary unbiased algorithms on functions with a unique globaloptimum [Lehre/Witt, GECCO 2010], which tells us that higher arity operators orbiased sampling strategies are needed when trying to beat this bound. In lackof analyzing techniques, almost no non-trivial bounds are known for otherrestricted models. Proving such bounds therefore remains to be one of the mainchallenges in black-box complexity theory. With this paper we contribute to our technical toolbox for lower boundcomputations by proposing a new type of information-theoretic argument. Weregard the permutation- and bit-invariant version of \textsc{LeadingOnes} andprove that its (1+1) elitist black-box complexity is $\Omega(n^2)$, a boundthat is matched by (1+1)-type evolutionary algorithms. The (1+1) elitistcomplexity of \textsc{LeadingOnes} is thus considerably larger than itsunrestricted one, which is known to be of order $n\log\log n$ [Afshani et al.,2013].
arxiv-1604-02354 | Bayesian Neighbourhood Component Analysis |  http://arxiv.org/abs/1604.02354  | author:Dong Wang, Xiaoyang Tan category:cs.CV cs.LG published:2016-04-08 summary:Learning a good distance metric in feature space potentially improves theperformance of the KNN classifier and is useful in many real-worldapplications. Many metric learning algorithms are however based on the pointestimation of a quadratic optimization problem, which is time-consuming,susceptible to overfitting, and lack a natural mechanism to reason withparameter uncertainty, an important property useful especially when thetraining set is small and/or noisy. To deal with these issues, we present anovel Bayesian metric learning method, called Bayesian NCA, based on thewell-known Neighbourhood Component Analysis method, in which the metricposterior is characterized by the local label consistency constraints ofobservations, encoded with a similarity graph instead of independent pairwiseconstraints. For efficient Bayesian optimization, we explore the variationallower bound over the log-likelihood of the original NCA objective. Experimentson several publicly available datasets demonstrate that the proposed method isable to learn robust metric measures from small size dataset and/or fromchallenging training set with labels contaminated by errors. The proposedmethod is also shown to outperform a previous pairwise constrained Bayesianmetric learning method.
arxiv-1604-02336 | Back to the Basics: Bayesian extensions of IRT outperform neural networks for proficiency estimation |  http://arxiv.org/abs/1604.02336  | author:Kevin H. Wilson, Yan Karklin, Bojian Han, Chaitanya Ekanadham category:cs.AI cs.LG published:2016-04-08 summary:Estimating student proficiency is an important task for computer-basedlearning systems. We compare a family of IRT-based proficiency estimationmethods with a recently proposed approach using recurrent neural networks(RNNs) on two publicly available and one proprietary data set, evaluating eachmodel according to how well a student's future response is predicted givenprevious responses. IRT-based methods consistently matched or outperformed theRNN-based method across all data sets at the finest level of contentgranularity that was tractable for them to be trained on. A hierarchicalextension of IRT that captured item grouping structure performed best overall.When data sets included non-trivial autocorrelations in student responsepatterns, a temporal extension of IRT improved performance over standard IRTwhile the RNN-based method did not. We conclude that IRT-based models provide asimpler, better-performing alternative to the current generation of RNN-basedmodels while also affording more interpretability and guarantees due to theirformulation as Bayesian probabilistic models.
arxiv-1604-02316 | Free-Space Detection with Self-Supervised and Online Trained Fully Convolutional Networks |  http://arxiv.org/abs/1604.02316  | author:Willem P. Sanberg, Gijs Dubbelman, Peter H. N. de With category:cs.CV published:2016-04-08 summary:Recently, vision-based Advanced Driver Assist Systems have gained broadinterest. In this work, we investigate free-space detection, for which wepropose to employ a Fully Convolutional Network (FCN). We show that this FCNcan be trained in a self-supervised manner and achieve similar results comparedto training on manually annotated data, thereby reducing the need for largemanually annotated training sets. To this end, our self-supervised trainingrelies on a stereo-vision disparity system, to automatically generate (weak)training labels for the color-based FCN. Additionally, our self-supervisedtraining facilitates online training of the FCN instead of offline.Consequently, given that the applied FCN is relatively small, the free-spaceanalysis becomes highly adaptive to any traffic scene that the vehicleencounters. We have validated our algorithm using publicly available data andon a new challenging benchmark dataset that is released with this paper.Experiments show that the online training boosts performance with 5% whencompared to offline training, both for Fmax and AP.
arxiv-1604-02275 | Online Open World Recognition |  http://arxiv.org/abs/1604.02275  | author:Rocco De Rosa, Thomas Mensink, Barbara Caputo category:cs.CV cs.LG stat.ML published:2016-04-08 summary:As we enter into the big data age and an avalanche of images have becomereadily available, recognition systems face the need to move from close, labsettings where the number of classes and training data are fixed, to dynamicscenarios where the number of categories to be recognized grows continuouslyover time, as well as new data providing useful information to update thesystem. Recent attempts, like the open world recognition framework, tried toinject dynamics into the system by detecting new unknown classes and addingthem incrementally, while at the same time continuously updating the models forthe known classes. incrementally adding new classes and detecting instancesfrom unknown classes, while at the same time continuously updating the modelsfor the known classes. In this paper we argue that to properly capture theintrinsic dynamic of open world recognition, it is necessary to add to theseaspects (a) the incremental learning of the underlying metric, (b) theincremental estimate of confidence thresholds for the unknown classes, and (c)the use of local learning to precisely describe the space of classes. We extendthree existing metric learning algorithms towards these goals by using onlinemetric learning. Experimentally we validate our approach on two large-scaledatasets in different learning scenarios. For all these scenarios our proposedmethods outperform their non-online counterparts. We conclude that local andonline learning is important to capture the full dynamics of open worldrecognition.
arxiv-1604-02313 | Norm-preserving Orthogonal Permutation Linear Unit Activation Functions (OPLU) |  http://arxiv.org/abs/1604.02313  | author:Artem Chernodub, Dimitri Nowicki category:cs.NE published:2016-04-08 summary:We propose a novel activation function that implements piece-wise orthogonalnon-linear mappings based on permutations. It is straightforward to implement,and very computationally efficient, also it has little memory requirements. Wetested it on two toy problems for feedforward and recurrent networks, it showssimilar performance to tanh and ReLU. OPLU activation function ensures normpreservance of the backpropagated gradients, therefore it is potentially goodfor the training of deep, extra deep, and recurrent neural networks.
arxiv-1604-02292 | A method for locally approximating regularized iterative tomographic reconstruction methods |  http://arxiv.org/abs/1604.02292  | author:D. M. Pelt, K. J. Batenburg category:math.NA cs.CV published:2016-04-08 summary:In many applications of tomography, the acquired projections are eitherlimited in number or contain a significant amount of noise. In these cases,standard reconstruction methods tend to produce artifacts that can make furtheranalysis difficult. Advanced regularized iterative methods, such as totalvariation minimization, are often able to achieve a higher reconstructionquality by exploiting prior knowledge about the scanned object. In practice,however, these methods often have prohibitively long computation times or largememory requirements. Furthermore, since they are based on minimizing a globalobjective function, regularized iterative methods need to reconstruct theentire scanned object, even when one is only interested in a (small) region ofthe reconstructed image. In this paper, we present a method to approximate regularized iterativereconstruction methods inside a (small) region of the scanned object. Themethod only performs computations inside the region of interest, ensuring lowcomputational requirements. Reconstruction results for different phantom imagesand types of regularization are given, showing that reconstructions of theproposed local method are almost identical to those of the global regularizediterative methods that are approximated, even for relatively small regions ofinterest. Furthermore, we show that larger regions can be reconstructedefficiently by reconstructing several small regions in parallel and combiningthem into a single reconstruction afterwards.
arxiv-1604-02201 | Transfer Learning for Low-Resource Neural Machine Translation |  http://arxiv.org/abs/1604.02201  | author:Barret Zoph, Deniz Yuret, Jonathan May, Kevin Knight category:cs.CL published:2016-04-08 summary:The encoder-decoder framework for neural machine translation (NMT) has beenshown effective in large data scenarios, but is much less effective forlow-resource languages. We present a transfer learning method thatsignificantly improves Bleu scores across a range of low-resource languages.Our key idea is to first train a high-resource language pair (the parentmodel), then transfer some of the learned parameters to the low-resource pair(the child model) to initialize and constrain training. Using our transferlearning method we improve baseline NMT models by an average of 5.6 Bleu onfour low-resource language pairs. Ensembling and unknown word replacement addanother 2 Bleu which brings the NMT performance on low-resource machinetranslation close to a strong syntax based machine translation (SBMT) system,exceeding its performance on one language pair. Additionally, using thetransfer learning model for re-scoring, we can improve the SBMT system by anaverage of 1.3 Bleu, improving the state-of-the-art on low-resource machinetranslation.
arxiv-1604-02426 | CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples |  http://arxiv.org/abs/1604.02426  | author:Filip Radenović, Giorgos Tolias, Ondřej Chum category:cs.CV published:2016-04-08 summary:Convolutional Neural Networks (CNNs) achieve state-of-the-art performance inmany computer vision tasks. However, this achievement is preceded by extrememanual annotation in order to perform either training from scratch orfine-tuning for the target task. In this work, we propose to fine-tune CNN forimage retrieval from a large collection of unordered images in a fullyautomated manner. We employ state-of-the-art retrieval andStructure-from-Motion (SfM) methods to obtain 3D models, which are used toguide the selection of the training data for CNN fine-tuning. We show that bothhard positive and hard negative examples enhance the final performance inparticular object retrieval with compact codes.
arxiv-1604-02469 | Image segmentation of cross-country scenes captured in IR spectrum |  http://arxiv.org/abs/1604.02469  | author:Artem Lenskiy category:cs.CV 68T10 published:2016-04-08 summary:Computer vision has become a major source of information for autonomousnavigation of robots of various types, self-driving cars, military robots andmars/lunar rovers are some examples. Nevertheless, the majority of methodsfocus on analysing images captured in visible spectrum. In this manuscript weelaborate on the problem of segmenting cross-country scenes captured in IRspectrum. For this purpose we proposed employing salient features. Salientfeatures are robust to variations in scale, brightness and view angle. Wesuggest the Speeded-Up Robust Features as a basis for our salient features fora number of reasons discussed in the paper. We also provide a comparison of twoSURF implementations. The SURF features are extracted from images of differentterrain types. For every feature we estimate a terrain class membershipfunction. The membership values are obtained by means of either the multi-layerperceptron or nearest neighbours. The features' class membership values andtheir spatial positions are then applied to estimate class membership valuesfor all pixels in the image. To decrease the effect of segmentation blinkingthat is caused by rapid switching between different terrain types and to speedup segmentation, we are tracking camera position and predict features'positions. The comparison of the multi-layer perception and the nearestneighbour classifiers is presented in the paper. The error rate of the terrainsegmentation using the nearest neighbours obtained on the testing set is16.6+-9.17%.
arxiv-1604-02376 | Finding Optimal Combination of Kernels using Genetic Programming |  http://arxiv.org/abs/1604.02376  | author:Jyothi Korra category:cs.CV cs.LG cs.NE published:2016-04-08 summary:In Computer Vision, problem of identifying or classifying the objects presentin an image is called Object Categorization. It is a challenging problem,especially when the images have clutter background, occlusions or differentlighting conditions. Many vision features have been proposed which aid objectcategorization even in such adverse conditions. Past research has shown that,employing multiple features rather than any single features leads to betterrecognition. Multiple Kernel Learning (MKL) framework has been developed forlearning an optimal combination of features for object categorization. ExistingMKL methods use linear combination of base kernels which may not be optimal forobject categorization. Real-world object categorization may need to considercomplex combination of kernels(non-linear) and not only linear combination.Evolving non-linear functions of base kernels using Genetic Programming isproposed in this report. Experiment results show that non-kernel generatedusing genetic programming gives good accuracy as compared to linear combinationof kernels.
arxiv-1604-02245 | Infrared Colorization Using Deep Convolutional Neural Networks |  http://arxiv.org/abs/1604.02245  | author:Matthias Limmer, Hendrik P. A. Lensch category:cs.CV cs.GR published:2016-04-08 summary:This paper proposes a method for transferring the RGB color spectrum tonear-infrared (NIR) images using deep multi-scale convolutional neuralnetworks. A direct and integrated transfer between NIR and RGB pixels istrained. The trained model does not require any user guidance or a referenceimage database in the recall phase to produce images with a natural appearance.To preserve the rich details of the NIR image, its high frequency features aretransferred to the estimated RGB image. The presented approach is trained andevaluated on a real-world dataset containing a large amount of road sceneimages in summer. The dataset was captured by a multi-CCD NIR/RGB camera, whichensures a perfect pixel to pixel registration.
arxiv-1604-02488 | Application of Multifractal Analysis to Segmentation of Water Bodies in Optical and Synthetic Aperture Radar Satellite Images |  http://arxiv.org/abs/1604.02488  | author:Victor Manuel San Martin, Alejandra Figliola category:cs.CV published:2016-04-08 summary:A method for segmenting water bodies in optical and synthetic aperture radar(SAR) satellite images is proposed. It makes use of the textural features ofthe different regions in the image for segmentation. The method consists in amultiscale analysis of the images, which allows us to study the imagesregularity both, locally and globally. As results of the analysis, coarsemultifractal spectra of studied images and a group of images that associateseach position (pixel) with its corresponding value of local regularity (orsingularity) spectrum are obtained. Thresholds are then applied to themultifractal spectra of the images for the classification. These thresholds areselected after studying the characteristics of the spectra under the assumptionthat water bodies have larger local regularity than other soil types.Classifications obtained by the multifractal method are compared quantitativelywith those obtained by neural networks trained to classify the pixels of theimages in covered against uncovered by water. In optical images, theclassifications are also compared with those derived using the so-calledNormalized Differential Water Index (NDWI).
arxiv-1604-02477 | One-class classifiers based on entropic spanning graphs |  http://arxiv.org/abs/1604.02477  | author:Lorenzo Livi, Cesare Alippi category:cs.LG cs.CV cs.IT math.IT published:2016-04-08 summary:One-class classifiers offer valuable tools to assess the presence of outliersin data. In this paper, we propose a design methodology for one-classclassifiers based on entropic spanning graphs. The spanning graph is learned onthe embedded input data, with the aim to generate a partition of the vertices.The final partition is derived by exploiting a criterion based on mutualinformation minimization. Here, we compute the mutual information by using aconvenient formulation provided in terms of the $\alpha$-Jensen difference.Once training is completed, in order to associate a confidence level with theclassifier decision, a graph-based fuzzy model is constructed. Thefuzzification process is based only on topological information of the verticesof the entropic spanning graph. As such, the proposed one-class classifier issuitable also for datasets with complex geometric structures. We provideexperiments on well-known benchmarking datasets containing both feature vectorsand labeled graphs. In addition, we apply the method on the problem of proteinsolubility recognition by considering several data representations for thesamples. Experimental results demonstrate the effectiveness and versatility ofthe proposed method with respect to other state-of-the-art approaches.
arxiv-1604-03221 | Leveraging Network Dynamics for Improved Link Prediction |  http://arxiv.org/abs/1604.03221  | author:Alireza Hajibagheri, Gita Sukthankar, Kiran Lakkaraju category:cs.SI cs.LG published:2016-04-08 summary:The aim of link prediction is to forecast connections that are most likely tooccur in the future, based on examples of previously observed links. A keyinsight is that it is useful to explicitly model network dynamics, howfrequently links are created or destroyed when doing link prediction. In thispaper, we introduce a new supervised link prediction framework, RPM (RatePrediction Model). In addition to network similarity measures, RPM uses thepredicted rate of link modifications, modeled using time series data; it isimplemented in Spark-ML and trained with the original link distribution, ratherthan a small balanced subset. We compare the use of this network dynamics modelto directly creating time series of network similarity measures. Ourexperiments show that RPM, which leverages predicted rates, outperforms the useof network similarity measures, either individually or within a time series.
arxiv-1604-02492 | Challenges in Bayesian Adaptive Data Analysis |  http://arxiv.org/abs/1604.02492  | author:Sam Elder category:cs.LG stat.ML published:2016-04-08 summary:Traditional statistical analysis requires that the analysis process and dataare independent. By contrast, the new field of adaptive data analysis hopes tounderstand and provide algorithms and accuracy guarantees for research as it iscommonly performed in practice, as an iterative process of proposing hypothesesand interacting with the data set. Previous work has established a model with arather strong lower bound on sample complexity in terms of the number ofqueries, $n\sim\sqrt q$, arguing that adaptive data analysis is much harderthan static data analysis, where $n\sim\log q$ is possible. Instead, we arguethat those strong lower bounds point to a shortcoming in the model, aninformational asymmetry with no basis in applications. In its place, we propose a new Bayesian version of the problem without thisunnecessary asymmetry. The previous lower bounds are no longer valid, whichoffers the possibility for stronger results. However, we show that a largefamily of methods, including all previously proposed algorithms, cannot achievethe static dependence of $n\sim\log q$ even in this regime, establishingpolylogarithmic lower bounds with a new family of lower bounds. Thesepreliminary results suggest that adaptive data analysis is harder than staticdata analysis even without this information asymmetry, but still leave wideopen the possibility that new algorithms can be developed to work with fewersamples than the previous best known algorithms.
arxiv-1604-02485 | Machine Learning for Visual Navigation of Unmanned Ground Vehicles |  http://arxiv.org/abs/1604.02485  | author:Artem A. Lenskiy, Jong-Soo Lee category:cs.CV published:2016-04-08 summary:The use of visual information for the navigation of unmanned ground vehiclesin a cross-country environment recently received great attention. However,until now, the use of textural information has been somewhat less effectivethan color or laser range information. This manuscript reviews the recentachievements in cross-country scene segmentation and addresses theirshortcomings. It then describes a problem related to classification of highdimensional texture features. Finally, it compares three machine learningalgorithms aimed at resolving this problem. The experimental results for eachmachine learning algorithm with the discussion of comparisons are given at theend of the manuscript.
arxiv-1604-01854 | Building Ensembles of Adaptive Nested Dichotomies with Random-Pair Selection |  http://arxiv.org/abs/1604.01854  | author:Tim Leathart, Bernhard Pfahringer, Eibe Frank category:stat.ML cs.LG published:2016-04-07 summary:A system of nested dichotomies is a method of decomposing a multi-classproblem into a collection of binary problems. Such a system recursively splitsthe set of classes into two subsets, and trains a binary classifier todistinguish between each subset. Even though ensembles of nested dichotomieswith random structure have been shown to perform well in practice, using a moresophisticated class subset selection method can be used to improveclassification accuracy. We investigate an approach to this problem calledrandom-pair selection, and evaluate its effectiveness compared to otherpublished methods of subset selection. We show that our method outperformsother methods in many cases, and is at least on par in almost all other cases.
arxiv-1604-01870 | Efficient Globally Convergent Stochastic Optimization for Canonical Correlation Analysis |  http://arxiv.org/abs/1604.01870  | author:Weiran Wang, Jialei Wang, Dan Garber, Nathan Srebro category:cs.LG published:2016-04-07 summary:We study the stochastic optimization of canonical correlation analysis (CCA),whose objective is nonconvex and does not decouple over training samples.Although several stochastic gradient based optimization algorithms have beenrecently proposed to solve this problem, no global convergence guarantee wasprovided by any of them. Inspired by the alternating least squares/poweriterations formulation of CCA, and the shift-and-invert preconditioning methodfor PCA, we propose two globally convergent meta-algorithms for CCA, both ofwhich transform the original problem into sequences of least squares problemsthat need only be solved approximately. We instantiate the meta-algorithms withstate-of-the-art SGD methods and obtain time complexities that significantlyimprove upon that of previous work. Experimental results demonstrate theirsuperior performance.
arxiv-1604-01850 | End-to-End Deep Learning for Person Search |  http://arxiv.org/abs/1604.01850  | author:Tong Xiao, Shuang Li, Bochao Wang, Liang Lin, Xiaogang Wang category:cs.CV published:2016-04-07 summary:Existing person re-identification (re-id) benchmarks and algorithms mainlyfocus on matching cropped pedestrian images between queries and candidates.However, it is different from real-world scenarios where the annotations ofpedestrian bounding boxes are unavailable and the target person needs to befound from whole images. To close the gap, we investigate how to localize andmatch query persons from the scene images without relying on the annotations ofcandidate boxes. Instead of breaking it down into two separatetasks---pedestrian detection and person re-id, we propose an end-to-end deeplearning framework to jointly handle both tasks. A random sampling softmax lossis proposed to effectively train the model under the supervision of sparse andunbalanced labels. On the other hand, existing benchmarks are small in scaleand the samples are collected from a few fixed camera views with low scenediversities. To address this issue, we collect a large-scale andscene-diversified person search dataset, which contains 18,184 images, 8,432persons, and 99,809 annotated boundingboxes\footnote{\url{http://www.ee.cuhk.edu.hk/~xgwang/PS/dataset.html}}. Weevaluate our approach and other baselines on the proposed dataset, and studythe influence of various factors. Experiments show that our method achieves thebest result.
arxiv-1604-01841 | A Classification Leveraged Object Detector |  http://arxiv.org/abs/1604.01841  | author:Miao Sun, Tony X. Han, Zhihai He category:cs.CV published:2016-04-07 summary:Currently, the state-of-the-art image classification algorithms outperformthe best available object detector by a big margin in terms of averageprecision. We, therefore, propose a simple yet principled approach that allowsus to leverage object detection through image classification on supportingregions specified by a preliminary object detector. Using a simple bag-of-words model based image classification algorithm, we leveraged the performanceof the deformable model objector from 35.9% to 39.5% in average precision over20 categories on standard PASCAL VOC 2007 detection dataset.
arxiv-1604-01839 | Clustering Via Crowdsourcing |  http://arxiv.org/abs/1604.01839  | author:Arya Mazumdar, Barna Saha category:cs.DS cs.IT cs.LG math.IT published:2016-04-07 summary:In recent years, crowdsourcing, aka human aided computation has emerged as aneffective platform for solving problems that are considered complex formachines alone. Using human is time-consuming and costly due to monetarycompensations. Therefore, a crowd based algorithm must judiciously use anyinformation computed through an automated process, and ask minimum number ofquestions to the crowd adaptively. One such problem which has received significant attention is {\em entityresolution}. Formally, we are given a graph $G=(V,E)$ with unknown edge set $E$where $G$ is a union of $k$ (again unknown, but typically large $O(n^\alpha)$,for $\alpha>0$) disjoint cliques $G_i(V_i, E_i)$, $i =1, \dots, k$. The goal isto retrieve the sets $V_i$s by making minimum number of pair-wise queries $V\times V\to\{\pm1\}$ to an oracle (the crowd). When the answer to each query iscorrect, e.g. via resampling, then this reduces to finding connected componentsin a graph. On the other hand, when crowd answers may be incorrect, itcorresponds to clustering over minimum number of noisy inputs. Even, withperfect answers, a simple lower and upper bound of $\Theta(nk)$ on querycomplexity can be shown. A major contribution of this paper is to reduce thequery complexity to linear or even sublinear in $n$ when mild side informationis provided by a machine, and even in presence of crowd errors which are notcorrectable via resampling. We develop new information theoretic lower boundson the query complexity of clustering with side information and errors, and ourupper bounds closely match with them. Our algorithms are naturallyparallelizable, and also give near-optimal bounds on the number of adaptiverounds required to match the query complexity.
arxiv-1604-02027 | Combinatorial Topic Models using Small-Variance Asymptotics |  http://arxiv.org/abs/1604.02027  | author:Ke Jiang, Suvrit Sra, Brian Kulis category:cs.LG cs.CL stat.ML published:2016-04-07 summary:Topic models have emerged as fundamental tools in unsupervised machinelearning. Most modern topic modeling algorithms take a probabilistic view andderive inference algorithms based on Latent Dirichlet Allocation (LDA) or itsvariants. In contrast, we study topic modeling as a combinatorial optimizationproblem, and derive its objective function from LDA by passing to thesmall-variance limit. We minimize the derived objective by using ideas fromcombinatorial optimization, which results in a new, fast, and high-qualitytopic modeling algorithm. In particular, we show the surprising result that ouralgorithm can outperform all major LDA-based topic modeling approaches, evenwhen the data are sampled from an LDA model and true hyper-parameters areprovided to these competitors. These results make a strong case that topicmodels need not be limited to a probabilistic view.
arxiv-1604-01904 | Neural Headline Generation with Minimum Risk Training |  http://arxiv.org/abs/1604.01904  | author:Ayana, Shiqi Shen, Zhiyuan Liu, Maosong Sun category:cs.CL published:2016-04-07 summary:Automatic headline generation is an important research area within textsummarization and sentence compression. Recently, neural headline generationmodels have been proposed to take advantage of well-trained neural networks inlearning sentence representations and mapping sequence to sequence.Nevertheless, traditional neural network encoder utilizes maximum likelihoodestimation for parameter optimization, which essentially constraints theexpected training objective within word level instead of sentence level.Moreover, the performance of model prediction significantly relies on trainingdata distribution. To overcome these drawbacks, we employ minimum risk trainingstrategy in this paper, which directly optimizes model parameters with respectto evaluation metrics and statistically leads to significant improvements forheadline generation. Experiment results show that our approach outperformsstate-of-the-art systems on both English and Chinese headline generation tasks.
arxiv-1604-01952 | Deep Online Convex Optimization with Gated Games |  http://arxiv.org/abs/1604.01952  | author:David Balduzzi category:cs.LG cs.GT cs.NE stat.ML published:2016-04-07 summary:Methods from convex optimization are widely used as building blocks for deeplearning algorithms. However, the reasons for their empirical success areunclear, since modern convolutional networks (convnets), incorporatingrectifier units and max-pooling, are neither smooth nor convex. Standardguarantees therefore do not apply. This paper provides the first convergencerates for gradient descent on rectifier convnets. The proof utilizes theparticular structure of rectifier networks which consists in binaryactive/inactive gates applied on top of an underlying linear network. Theapproach generalizes to max-pooling, dropout and maxout. In other words, toprecisely the neural networks that perform best empirically. The key step is tointroduce gated games, an extension of convex games with similar convergenceproperties that capture the gating function of rectifiers. The main result isthat rectifier convnets converge to a critical point at a rate controlled bythe gated-regret of the units in the network. Corollaries of the main resultinclude: (i) a game-theoretic description of the representations learned by aneural network; (ii) a logarithmic-regret algorithm for training neural nets;and (iii) a formal setting for analyzing conditional computation in neural netsthat can be applied to recently developed models of attention.
arxiv-1604-02181 | A Unified Bayesian Framework for Sparse Non-negative Matrix Factorization |  http://arxiv.org/abs/1604.02181  | author:Igor Fedorov, Alican Nalci, Ritwik Giri, Bhaskar D. Rao, Truong Q. Nguyen, H. Garudadri category:stat.ML published:2016-04-07 summary:In this work, we study the sparse non-negative matrix factorization (SparseNMF or S-NMF) problem. NMF and S-NMF are popular machine learning tools whichdecompose a given non-negative dataset into a dictionary and an activationmatrix, where both are constrained to be non-negative. We review how commonconcave sparsity measures from the compressed sensing literature can beextended to the S-NMF problem. Furthermore, we show that these sparsitymeasures have a Bayesian interpretation and each one corresponds to a specificprior on the activations. We present a comprehensive Sparse Bayesian Learning(SBL) framework for modeling non-negative data and provide details for Type Iand Type II inference procedures. We show that efficient multiplicative updaterules can be employed to solve the S-NMF problem for the penalty functionsdiscussed and present experimental results validating our assertions.
arxiv-1604-01955 | Monitoring Chinese Population Migration in Consecutive Weekly Basis from Intra-city scale to Inter-province scale by Didi's Bigdata |  http://arxiv.org/abs/1604.01955  | author:Renyu Zhao category:stat.ML published:2016-04-07 summary:Population migration is valuable information which leads to proper decisionin urban-planning strategy, massive investment, and many other fields. Forinstance, inter-city migration is a posterior evidence to see if thegovernment's constrain of population works, and inter-community immigrationmight be a prior evidence of real estate price hike. With timely data, it isalso impossible to compare which city is more favorable for the people, supposethe cities release different new regulations, we could also compare thecustomers of different real estate development groups, where they come from,where they probably will go. Unfortunately these data was not available. In this paper, leveraging the data generated by positioning team in Didi, wepropose a novel approach that timely monitoring population migration fromcommunity scale to provincial scale. Migration can be detected as soon as in aweek. It could be faster, the setting of a week is for statistical purpose. Amonitoring system is developed, then applied nation wide in China, someobservations derived from the system will be presented in this paper. This new method of migration perception is origin from the insight thatnowadays people mostly moving with their personal Access Point (AP), also knownas WiFi hotspot. Assume that the ratio of AP moving to the migration ofpopulation is constant, analysis of comparative population migration would befeasible. More exact quantitative research would also be done with few sampleresearch and model regression. The procedures of processing data includes many steps: eliminating the impactof pseudo-migration AP, for instance pocket WiFi, and second-hand tradedrouter; distinguishing moving of population with moving of companies;identifying shifting of AP by the finger print clusters, etc..
arxiv-1604-01894 | A Novel Scene Text Detection Algorithm Based On Convolutional Neural Network |  http://arxiv.org/abs/1604.01894  | author:Xiaohang Ren, Kai Chen, Jun Sun category:cs.CV published:2016-04-07 summary:Candidate text region extraction plays a critical role in convolutionalneural network (CNN) based text detection from natural images. In this paper,we propose a CNN based scene text detection algorithm with a new text regionextractor. The so called candidate text region extractor I-MSER is based onMaximally Stable Extremal Region (MSER), which can improve the independency andcompleteness of the extracted candidate text regions. Design of I-MSER ismotivated by the observation that text MSERs have high similarity and are closeto each other. The independency of candidate text regions obtained by I-MSER isguaranteed by selecting the most representative regions from a MSER tree whichis generated according to the spatial overlapping relationship among the MSERs.A multi-layer CNN model is trained to score the confidence value of theextracted regions extracted by the I-MSER for text detection. The new textdetection algorithm based on I-MSER is evaluated with wide-used ICDAR 2011 and2013 datasets and shows improved detection performance compared to the existingalgorithms.
arxiv-1604-02135 | A MultiPath Network for Object Detection |  http://arxiv.org/abs/1604.02135  | author:Sergey Zagoruyko, Adam Lerer, Tsung-Yi Lin, Pedro O. Pinheiro, Sam Gross, Soumith Chintala, Piotr Dollár category:cs.CV published:2016-04-07 summary:The recent MS COCO object detection dataset presents several new challengesfor object detection. In particular, it contains objects at a broad range ofscales, less prototypical images, and requires more precise localization. Toaddress these challenges, we test three modifications to the standard FastR-CNN object detector: (1) skip connections that give the detector access tofeatures at multiple network layers, (2) a foveal structure to exploit objectcontext at multiple object resolutions, and (3) an integral loss function andcorresponding network adjustment that improve localization. The result of thesemodifications is that information can flow along multiple paths in our network,including through features from multiple network layers and from multipleobject views. We refer to our modified classifier as a "MultiPath" network. Wecouple our MultiPath network with DeepMask object proposals, which are wellsuited for localization and small objects, and adapt our pipeline to predictsegmentation masks in addition to bounding boxes. The combined system improvesresults over the baseline Fast R-CNN detector with Selective Search by 66%overall and by 4x on small objects. It placed second in both the COCO 2015detection and segmentation challenges.
arxiv-1604-02153 | A Semi-Lagrangian two-level preconditioned Newton-Krylov solver for constrained diffeomorphic image registration |  http://arxiv.org/abs/1604.02153  | author:Andreas Mang, George Biros category:math.OC cs.CV published:2016-04-07 summary:We propose an efficient numerical algorithm for the solution of diffeomorphicimage registration problems. We use an optimization formulation constrained bya partial differential equation (PDE), where the constraints are a scalartransport equation. We use a pseudospectral discretization in space and second-order accuratesemi-Lagrangian time stepping scheme for the transport PDE. We solve for astationary velocity field using a preconditioned, globalized, matrix-freeNewton-Krylov scheme. We propose and test a two-level Hessian preconditioner.We consider two strategies for inverting the preconditioner on the coarse grid:a nested preconditioned conjugate gradient method (exact solve) and a nestedChebyshev iterative method (inexact solve) with a fixed number of iterations. We test the performance of our solver in different synthetic and real-worldtwo-dimensional application scenarios. We study grid convergence andcomputational efficiency of our new scheme. We compare the performance of oursolver against our initial implementation that uses the same spatialdiscretization but a standard, explicit, second-order Runge-Kutta scheme forthe numerical time integration of the transport equations and a single-levelpreconditioner. Our improved scheme delivers significant speedups over ouroriginal implementation. As a highlight, we observe a 20$\times$ speedup for atwo dimensional, real world multi-subject medical image registration problem.
arxiv-1604-02182 | Family in the Wild (FIW): A Large-scale Kinship Recognition Database |  http://arxiv.org/abs/1604.02182  | author:Joseph P Robinson, Ming Shao, Yue Wu, Yun Fu category:cs.CV published:2016-04-07 summary:We introduce a large-scale dataset for visual kin-based problems, the Familyin the Wild (FIW) dataset. Motivated by the lack of a single, unified imagedataset available for kinship tasks, our goal is to provide a dataset thatcaptivates the interest of the research community, i.e., large enough tosupport multiple tasks for evaluation. For this, we collected and labelled thelargest set of family images to date, with only a small team and an efficientlabelling tool that was designed to optimize the process of marking complexhierarchical relationships, attributes, and local label information in familyphotos. We experimentally compare our dataset the existing kinship imagedatasets, and demonstrate the practical value of the newly collected FIWdataset. We also demonstrate that using a pre-trained convolutional neuralnetwork (CNN) as an off-the-shelf feature extractor as performing better thantraditional feature types used for kinship based tasks in the visual domain. Wealso measure human performance and show their performance does not match up tothat of machine vision algorithms.
arxiv-1604-02129 | Horizon Lines in the Wild |  http://arxiv.org/abs/1604.02129  | author:Scott Workman, Menghua Zhai, Nathan Jacobs category:cs.CV published:2016-04-07 summary:The horizon line is an important property for a wide variety of imageunderstanding tasks. As such, many methods have been introduced to estimate thehorizon line from a single image, primarily geometric methods which assume thepresence of specific cues in the scene (e.g., vanishing points). These purelygeometric methods are limited in their real-world capability, require extensivetuning, and are tested on benchmark datasets designed to showcase theirability. We introduce a large, realistic evaluation dataset, Horizon Lines inthe Wild (HLW), containing natural images with labeled horizon lines.
arxiv-1604-02123 | Multilevel Weighted Support Vector Machine for Classification on Healthcare Data with Missing Values |  http://arxiv.org/abs/1604.02123  | author:Talayeh Razzaghi, Oleg Roderick, Ilya Safro, Nicholas Marko category:stat.ML cs.LG stat.AP published:2016-04-07 summary:This work is motivated by the needs of predictive analytics on healthcaredata as represented by Electronic Medical Records. Such data is invariablyproblematic: noisy, with missing entries, with imbalance in classes ofinterests, leading to serious bias in predictive modeling. Since standard datamining methods often produce poor performance measures, we argue fordevelopment of specialized techniques of data-preprocessing and classification.In this paper, we propose a new method to simultaneously classify largedatasets and reduce the effects of missing values. It is based on a multilevelframework of the cost-sensitive SVM and the expected maximization imputationmethod for missing values, which relies on iterated regression analyses. Wecompare classification results of multilevel SVM-based algorithms on publicbenchmark datasets with imbalanced classes and missing values as well as realdata in health applications, and show that our multilevel SVM-based methodproduces fast, and more accurate and robust classification results.
arxiv-1604-02030 | Edge Detection Based Shape Identification |  http://arxiv.org/abs/1604.02030  | author:Vivek Kumar, Sumit Pandey, Amrindra Pal, Sandeep Sharma category:cs.CV published:2016-04-07 summary:Image recognition is the need of the hour. In order to be able to recognizean image, it is of immense importance that the image should be distinguishablefrom the background. In the present work, an approach is presented forautomatic detection and recognition of regular 2D shapes in low noiseenvironments. The work has a large number of direct applications in the realworld. The algorithm proposed is based on locating the edges and thus, in turncalculating the area of the object helps in identification of a specifiedshape. The results were simulated using MATLAB tool are encouraging andvalidate the proposed algorithm. Index Terms: Edge Detection, Area Calculation, Shape Detection, ObjectRecognition
arxiv-1604-02115 | Trajectory Aligned Features For First Person Action Recognition |  http://arxiv.org/abs/1604.02115  | author:Suriya Singh, Chetan Arora, C. V. Jawahar category:cs.CV published:2016-04-07 summary:Egocentric videos are characterised by their ability to have the first personview. With the popularity of Google Glass and GoPro, use of egocentric videosis on the rise. Recognizing action of the wearer from egocentric videos is animportant problem. Unstructured movement of the camera due to natural headmotion of the wearer causes sharp changes in the visual field of the egocentriccamera causing many standard third person action recognition techniques toperform poorly on such videos. Objects present in the scene and hand gesturesof the wearer are the most important cues for first person action recognitionbut are difficult to segment and recognize in an egocentric video. We propose anovel representation of the first person actions derived from featuretrajectories. The features are simple to compute using standard point trackingand does not assume segmentation of hand/objects or recognizing object or handpose unlike in many previous approaches. We train a bag of words classifierwith the proposed features and report a performance improvement of more than11% on publicly available datasets. Although not designed for the particularcase, we show that our technique can also recognize wearer's actions when handsor objects are not visible.
arxiv-1604-02032 | 3-D Hand Pose Estimation from Kinect's Point Cloud Using Appearance Matching |  http://arxiv.org/abs/1604.02032  | author:Pasquale Coscia, Francesco A. N. Palmieri, Francesco Castaldo, Alberto Cavallo category:cs.CV published:2016-04-07 summary:We present a novel appearance-based approach for pose estimation of a humanhand using the point clouds provided by the low-cost Microsoft Kinect sensor.Both the free-hand case, in which the hand is isolated from the surroundingenvironment, and the hand-object case, in which the different types ofinteractions are classified, have been considered. The hand-object case isclearly the most challenging task having to deal with multiple tracks. Theapproach proposed here belongs to the class of partial pose estimation wherethe estimated pose in a frame is used for the initialization of the next one.The pose estimation is obtained by applying a modified version of the IterativeClosest Point (ICP) algorithm to synthetic models to obtain the rigidtransformation that aligns each model with respect to the input data. Theproposed framework uses a "pure" point cloud as provided by the Kinect sensorwithout any other information such as RGB values or normal vector components.For this reason, the proposed method can also be applied to data obtained fromother types of depth sensor, or RGB-D camera.
arxiv-1604-02929 | Solving Optimization Problems by the Spatial Public Goods Game |  http://arxiv.org/abs/1604.02929  | author:Marco Alberto Javarone category:physics.soc-ph cs.GT cs.NE published:2016-04-07 summary:We introduce a method based on the spatial Public Goods Game for solvingoptimization tasks. In particular, we focus on the Traveling Salesman Problem,i.e., a problem whose search space exponentially grows increasing the number ofcities, then becoming NP-hard. The proposed method considers a population whoseagents are provided with a random solution to the given problem. Then, agentsinteract by playing the Public Goods Game using the fitness of their solutionas currency of the game. In doing so, agents with better solutions providehigher contributions, while agents with lower ones tend to imitate the solutionof richer agents to increase their fitness. Numerical simulations show that theproposed method allows to compute exact solutions, and suboptimal ones, in theconsidered search spaces. As result, beyond to propose a new heuristic forcombinatorial optimization tasks, our work aims to highlight the potentialityof evolutionary game theory outside its current horizons.
arxiv-1604-02085 | A robust autoassociative memory with coupled networks of Kuramoto-type oscillators |  http://arxiv.org/abs/1604.02085  | author:Daniel Heger, Katharina Krischer category:nlin.AO cs.CV cs.NE published:2016-04-07 summary:Uncertain recognition success, unfavorable scaling of connection complexityor dependence on complex external input impair the usefulness of currentoscillatory neural networks for pattern recognition or restrict technicalrealizations to small networks. We propose a new network architecture ofcoupled oscillators for pattern recognition which shows none of the mentionedaws. Furthermore we illustrate the recognition process with simulation resultsand analyze the new dynamics analytically: Possible output patterns areisolated attractors of the system. Additionally, simple criteria forrecognition success are derived from a lower bound on the basins of attraction.
arxiv-1604-02038 | Sentence Level Recurrent Topic Model: Letting Topics Speak for Themselves |  http://arxiv.org/abs/1604.02038  | author:Fei Tian, Bin Gao, Di He, Tie-Yan Liu category:cs.LG cs.CL cs.IR published:2016-04-07 summary:We propose Sentence Level Recurrent Topic Model (SLRTM), a new topic modelthat assumes the generation of each word within a sentence to depend on boththe topic of the sentence and the whole history of its preceding words in thesentence. Different from conventional topic models that largely ignore thesequential order of words or their topic coherence, SLRTM gives fullcharacterization to them by using a Recurrent Neural Networks (RNN) basedframework. Experimental results have shown that SLRTM outperforms severalstrong baselines on various tasks. Furthermore, SLRTM can automaticallygenerate sentences given a topic (i.e., topics to sentences), which is a keytechnology for real world applications such as personalized short textconversation.
arxiv-1604-01931 | Geometric Scene Parsing with Hierarchical LSTM |  http://arxiv.org/abs/1604.01931  | author:Zhanglin Peng, Ruimao Zhang, Xiaodan Liang, Xiaobai Liu, Liang Lin category:cs.CV published:2016-04-07 summary:This paper addresses the problem of geometric scene parsing, i.e.simultaneously labeling geometric surfaces (e.g. sky, ground and verticalplane) and determining the interaction relations (e.g. layering, supporting,siding and affinity) between main regions. This problem is more challengingthan the traditional semantic scene labeling, as recovering geometricstructures necessarily requires the rich and diverse contextual information. Toachieve these goals, we propose a novel recurrent neural network model, namedHierarchical Long Short-Term Memory (H-LSTM). It contains two coupledsub-networks: the Pixel LSTM (P-LSTM) and the Multi-scale Super-pixel LSTM(MS-LSTM) for handling the surface labeling and relation prediction,respectively. The two sub-networks provide complementary information to eachother to exploit hierarchical scene contexts, and they are jointly optimizedfor boosting the performance. Our extensive experiments show that our model iscapable of parsing scene geometric structures and outperforming severalstate-of-the-art methods by large margins. In addition, we show promising 3Dreconstruction results from the still images based on the geometric parsing.
arxiv-1604-01980 | Sublabel-Accurate Convex Relaxation of Vectorial Multilabel Energies |  http://arxiv.org/abs/1604.01980  | author:Emanuel Laude, Thomas Möllenhoff, Michael Moeller, Jan Lellmann, Daniel Cremers category:cs.CV math.OC published:2016-04-07 summary:Convex relaxations of nonconvex multilabel problems have been demonstrated toproduce superior (provably optimal or near-optimal) solutions to a variety ofclassical computer vision problems. Yet, they are of limited practical use asthey require a fine discretization of the label space, entailing a huge demandin memory and runtime. In this work, we propose the first sublabel accurateconvex relaxation for vectorial multilabel problems. The key idea is that weapproximate the dataterm of the vectorial labeling problem in a piecewiseconvex (rather than piecewise linear) manner. As a result we have a morefaithful approximation of the original cost function that provides a meaningfulinterpretation for the fractional solutions of the relaxed convex problem. Innumerous experiments on large-displacement optical flow estimation and on colorimage denoising we demonstrate that the computed solutions have superiorquality while requiring much lower memory and runtime.
arxiv-1604-02125 | Resolving Language and Vision Ambiguities Together: Joint Segmentation & Prepositional Attachment Resolution in Captioned Scenes |  http://arxiv.org/abs/1604.02125  | author:Gordon Christie, Ankit Laddha, Aishwarya Agrawal, Stanislaw Antol, Yash Goyal, Kevin Kochersberger, Dhruv Batra category:cs.CV cs.CL cs.LG published:2016-04-07 summary:We present an approach to simultaneously perform semantic segmentation andprepositional phrase attachment resolution for captioned images. The motivationfor this work comes from the fact that some ambiguities in language simplycannot be resolved without simultaneously reasoning about an associated image.If we consider the sentence "I shot an elephant in my pajamas", looking at thelanguage alone (and not reasoning about common sense), it is unclear if it isthe person or the elephant that is wearing the pajamas or both. Our approachinvolves producing a diverse set of plausible hypotheses for both semanticsegmentation and prepositional phrase attachment resolution that are thenjointly re-ranked to select the most consistent pair. We show that our semanticsegmentation and prepositional phrase attachment resolution modules havecomplementary strengths, and that joint reasoning produces more accurateresults than any module operating in isolation. We also show that multiplehypotheses are crucial to improved multiple-module reasoning. Our vision andlanguage approach significantly outperforms a state-of-the-art NLP system(Stanford Parser [16,27]) by 17.91% (28.69% relative) in one experiment, and by12.83% (25.28% relative) in another. We also make small improvements over astate-of-the-art vision system (DeepLab-CRF [13]).
arxiv-1604-01891 | A CNN Based Scene Chinese Text Recognition Algorithm With Synthetic Data Engine |  http://arxiv.org/abs/1604.01891  | author:Xiaohang Ren, Kai Chen, Jun Sun category:cs.CV published:2016-04-07 summary:Scene text recognition plays an important role in many computer visionapplications. The small size of available public available scene text datasetsis the main challenge when training a text recognition CNN model. In thispaper, we propose a CNN based Chinese text recognition algorithm. To enlargethe dataset for training the CNN model, we design a synthetic data engine forChinese scene character generation, which generates representative characterimages according to the fonts use frequency of Chinese texts. As the Chinesetext is more complex, the English text recognition CNN architecture is modifiedfor Chinese text. To ensure the small size nature character dataset and thelarge size artificial character dataset are comparable in training, the CNNmodel are trained progressively. The proposed Chinese text recognitionalgorithm is evaluated with two Chinese text datasets. The algorithm achievesbetter recognize accuracy compared to the baseline methods.
arxiv-1604-01871 | When is Nontrivial Estimation Possible for Graphons and Stochastic Block Models? |  http://arxiv.org/abs/1604.01871  | author:Audra McMillan, Adam Smith category:math.ST cs.LG stat.TH published:2016-04-07 summary:Block graphons (also called stochastic block models) are an important andwidely-studied class of models for random networks. We provide a lower bound onthe accuracy of estimators for block graphons with a large number of blocks. Weshow that, given only the number $k$ of blocks and an upper bound $\rho$ on thevalues (connection probabilities) of the graphon, every estimator incurs errorat least on the order of $\min(\rho, \sqrt{\rho k^2/n^2})$ in the $\delta_2$metric with constant probability, in the worst case over graphons. Inparticular, our bound rules out any nontrivial estimation (that is, with$\delta_2$ error substantially less than $\rho$) when $k\geq n\sqrt{\rho}$.Combined with previous upper and lower bounds, our results characterize, up tologarithmic terms, the minimax accuracy of graphon estimation in the $\delta_2$metric. A similar lower bound to ours was obtained independently by Klopp,Tsybakov and Verzelen (2016).
arxiv-1604-01889 | Reinterpreting the Transformation Posterior in Probabilistic Image Registration |  http://arxiv.org/abs/1604.01889  | author:Jie Luo, Karteek Popuri, Dana Cobzas, Hongyi Ding, Masashi Sugiyama category:cs.CV published:2016-04-07 summary:Probabilistic image registration methods estimate the posterior distributionof transformation. The conventional way of interpreting the transformationposterior is to use the mode as the most likely transformation and assign itscorresponding intensity to the registered voxel. Meanwhile, summary statisticsof the posterior are employed to evaluate the registration uncertainty, that isthe trustworthiness of the registered image. Despite the wide acceptance, thisconvention has never been justified. In this paper, based on illustrativeexamples, we question the correctness and usefulness of conventional methods.In order to faithfully translate the transformation posterior, we propose toencode the variability of values into a novel data type called ensemble fields.Ensemble fields can serve as a complement to the registered image and afoundation for developing advanced methods to characterize the uncertainty inregistration-based tasks. We demonstrate the potential of ensemble fields bypilot examples
arxiv-1604-01972 | An Adaptive Resample-Move Algorithm for Estimating Normalizing Constants |  http://arxiv.org/abs/1604.01972  | author:Marco Fraccaro, Ulrich Paquet, Ole Winther category:stat.ML published:2016-04-07 summary:The estimation of normalizing constants is a fundamental step inprobabilistic model comparison. Sequential Monte Carlo methods may be used forthis task and have the advantage of being inherently parallelizable. However,the standard choice of using a fixed number of particles at each iteration issuboptimal because some steps will contribute disproportionately to thevariance of the estimate. We introduce an adaptive version of the Resample-Movealgorithm, in which the particle set is adaptively expanded whenever a betterapproximation of an intermediate distribution is needed. The algorithm buildson the expression for the optimal number of particles and the correspondingminimum variance found under ideal conditions. Benchmark results on challengingGaussian Process Classification and Restricted Boltzmann Machine applicationsshow that Adaptive Resample-Move (ARM) estimates the normalizing constant witha smaller variance, using less computational resources, than eitherResample-Move with a fixed number of particles or Annealed Importance Sampling.A further advantage over Annealed Importance Sampling is that ARM is easier totune.
arxiv-1604-01946 | Optimizing Performance of Recurrent Neural Networks on GPUs |  http://arxiv.org/abs/1604.01946  | author:Jeremy Appleyard, Tomas Kocisky, Phil Blunsom category:cs.LG cs.NE published:2016-04-07 summary:As recurrent neural networks become larger and deeper, training times forsingle networks are rising into weeks or even months. As such there is asignificant incentive to improve the performance and scalability of thesenetworks. While GPUs have become the hardware of choice for training anddeploying recurrent models, the implementations employed often make use of onlybasic optimizations for these architectures. In this article we demonstratethat by exposing parallelism between operations within the network, an order ofmagnitude speedup across a range of network sizes can be achieved over a naiveimplementation. We describe three stages of optimization that have beenincorporated into the fifth release of NVIDIA's cuDNN: firstly optimizing asingle cell, secondly a single layer, and thirdly the entire network.
arxiv-1604-01962 | Automatic Content-aware Non-Photorealistic Rendering of Images |  http://arxiv.org/abs/1604.01962  | author:Akshay Gadi Patil, Shanmuganathan Raman category:cs.CV published:2016-04-07 summary:Non-photorealistic rendering techniques work on image features and oftenmanipulate a set of characteristics such as edges and texture to achieve adesired depiction of the scene. Most computational photography methodsdecompose an image using edge preserving filters and work on the resulting baseand detail layers independently to achieve desired visual effects. We propose anew approach for content-aware non-photorealistic rendering of images where wemanipulate the visually salient and the non-salient regions separately. Wepropose a novel content-aware framework in order to render an image forapplications such as detail exaggeration, artificial blurring and imageabstraction. The processed regions of the image are blended seamlessly for allthese applications. We demonstrate that content awareness of the proposedmethod leads to automatic generation of non-photorealistic rendering of thesame image for the different applications mentioned above.
arxiv-1604-01879 | GIFT: A Real-time and Scalable 3D Shape Search Engine |  http://arxiv.org/abs/1604.01879  | author:Song Bai, Xiang Bai, Zhichao Zhou, Zhaoxiang Zhang, Longin Jan Latecki category:cs.CV published:2016-04-07 summary:Projective analysis is an important solution for 3D shape retrieval, sincehuman visual perceptions of 3D shapes rely on various 2D observations fromdifferent view points. Although multiple informative and discriminative viewsare utilized, most projection-based retrieval systems suffer from heavycomputational cost, thus cannot satisfy the basic requirement of scalabilityfor search engines. In this paper, we present a real-time 3D shape searchengine based on the projective images of 3D shapes. The real-time property ofour search engine results from the following aspects: (1) efficient projectionand view feature extraction using GPU acceleration; (2) the first invertedfile, referred as F-IF, is utilized to speed up the procedure of multi-viewmatching; (3) the second inverted file (S-IF), which captures a localdistribution of 3D shapes in the feature manifold, is adopted for efficientcontext-based re-ranking. As a result, for each query the retrieval task can befinished within one second despite the necessary cost of IO overhead. We namethe proposed 3D shape search engine, which combines GPU acceleration andInverted File Twice, as GIFT. Besides its high efficiency, GIFT alsooutperforms the state-of-the-art methods significantly in retrieval accuracy onvarious shape benchmarks and competitions.
arxiv-1604-01999 | Online Optimization of Smoothed Piecewise Constant Functions |  http://arxiv.org/abs/1604.01999  | author:Vincent Cohen-Addad, Varun Kanade category:cs.LG stat.ML published:2016-04-07 summary:We study online optimization of smoothed piecewise constant functions overthe domain [0, 1). This is motivated by the problem of adaptively pickingparameters of learning algorithms as in the recently introduced framework byGupta and Roughgarden (2016). Majority of the machine learning literature hasfocused on Lipschitz-continuous functions or functions with bounded gradients.1 This is with good reason---any learning algorithm suffers linear regret evenagainst piecewise constant functions that are chosen adversarially, arguablythe simplest of non-Lipschitz continuous functions. The smoothed setting weconsider is inspired by the seminal work of Spielman and Teng (2004) and therecent work of Gupta and Roughgarden---in this setting, the sequence offunctions may be chosen by an adversary, however, with some uncertainty in thelocation of discontinuities. We give algorithms that achieve sublinear regretin the full information and bandit settings.
arxiv-1604-01545 | Training Constrained Deconvolutional Networks for Road Scene Semantic Segmentation |  http://arxiv.org/abs/1604.01545  | author:German Ros, Simon Stent, Pablo F. Alcantarilla, Tomoki Watanabe category:cs.CV published:2016-04-06 summary:In this work we investigate the problem of road scene semantic segmentationusing Deconvolutional Networks (DNs). Several constraints limit the practicalperformance of DNs in this context: firstly, the paucity of existing pixel-wiselabelled training data, and secondly, the memory constraints of embeddedhardware, which rule out the practical use of state-of-the-art DN architecturessuch as fully convolutional networks (FCN). To address the first constraint, weintroduce a Multi-Domain Road Scene Semantic Segmentation (MDRS3) dataset,aggregating data from six existing densely and sparsely labelled datasets fortraining our models, and two existing, separate datasets for testing theirgeneralisation performance. We show that, while MDRS3 offers a greater volumeand variety of data, end-to-end training of a memory efficient DN does notyield satisfactory performance. We propose a new training strategy to overcomethis, based on (i) the creation of a best-possible source network (S-Net) fromthe aggregated data, ignoring time and memory constraints; and (ii) thetransfer of knowledge from S-Net to the memory-efficient target network(T-Net). We evaluate different techniques for S-Net creation and T-Nettransferral, and demonstrate that training a constrained deconvolutionalnetwork in this manner can unlock better performance than existing trainingapproaches. Specifically, we show that a target network can be trained toachieve improved accuracy versus an FCN despite using less than 1\% of thememory. We believe that our approach can be useful beyond automotive scenarioswhere labelled data is similarly scarce or fragmented and where practicalconstraints exist on the desired model size. We make available our networkmodels and aggregated multi-domain dataset for reproducibility.
arxiv-1604-01592 | Fast $(1+ε)$-approximation of the Löwner extremal matrices of high-dimensional symmetric matrices |  http://arxiv.org/abs/1604.01592  | author:Frank Nielsen, Richard Nock category:cs.CG cs.CV published:2016-04-06 summary:Matrix data sets are common nowadays like in biomedical imaging where theDiffusion Tensor Magnetic Resonance Imaging (DT-MRI) modality produces datasets of 3D symmetric positive definite matrices anchored at voxel positions capturingthe anisotropic diffusion properties of water molecules in biological tissues.The space of symmetric matrices can be partially ordered using the L\"ownerordering, and computing extremal matrices dominating a given set of matrices isa basic primitive used in matrix-valued signal processing. In this letter, wedesign a fast and easy-to-implement iterative algorithm to approximatearbitrarily finely these extremal matrices. Finally, we discuss on extensionsto matrix clustering.
arxiv-1604-02100 | Hankel Matrix Nuclear Norm Regularized Tensor Completion for N-dimensional Exponential Signals |  http://arxiv.org/abs/1604.02100  | author:Jiaxi Ying, Hengfa Lu, Qingtao Wei, Jian-Feng Cai, Di Guo, Jihui Wu, Zhong Chen, Xiaobo Qu category:stat.ML cs.NA published:2016-04-06 summary:Signals are usually modeled as a superposition of exponential functions inspectroscopy of chemistry, biology and medical imaging. However, for fast dataacquisition or other inevitable reasons, only a small amount of samples may beacquired. How to recover the full signal is then of great interest. Existingapproaches can not efficiently recover N-dimensional exponential signals withN>=3. This paper studies the problem of recovering N-dimensional (particularly$N\geq 3$) exponential signals from partial observations, and we formulate thisproblem as a low-rank tensor completion problem with exponential factors. Thefull signal is reconstructed by simultaneously exploiting the CANDECOMP/PARAFAC(CP) tensor decomposition and the exponential structure of the associatedfactors, of which the latter is promoted by minimizing an objective functioninvolving the nuclear norm of Hankel matrices. Experimental results onsimulated and real magnetic resonance spectroscopy data show that the proposedapproach can successfully recover full signals from very limited samples and isrobust to the estimated tensor rank.
arxiv-1604-01696 | A Corpus and Evaluation Framework for Deeper Understanding of Commonsense Stories |  http://arxiv.org/abs/1604.01696  | author:Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong He, Devi Parikh, Dhruv Batra, Lucy Vanderwende, Pushmeet Kohli, James Allen category:cs.CL cs.AI published:2016-04-06 summary:Representation and learning of commonsense knowledge is one of thefoundational problems in the quest to enable deep language understanding. Thisissue is particularly challenging for understanding casual and correlationalrelationships between events. While this topic has received a lot of interestin the NLP community, research has been hindered by the lack of a properevaluation framework. This paper attempts to address this problem with a newframework for evaluating story understanding and script learning: the 'StoryCloze Test'. This test requires a system to choose the correct ending to afour-sentence story. We created a new corpus of ~50k five-sentence commonsensestories, ROCStories, to enable this evaluation. This corpus is unique in twoways: (1) it captures a rich set of causal and temporal commonsense relationsbetween daily events, and (2) it is a high quality collection of everyday lifestories that can also be used for story generation. Experimental evaluationshows that a host of baselines and state-of-the-art models based on shallowlanguage understanding struggle to achieve a high score on the Story ClozeTest. We discuss these implications for script and story learning, and offersuggestions for deeper language understanding.
arxiv-1604-01720 | Reading Between the Pixels: Photographic Steganography for Camera Display Messaging |  http://arxiv.org/abs/1604.01720  | author:Eric Wengrowski, Kristin Dana, Marco Gruteser, Narayan Mandayam category:cs.CV cs.GR cs.MM cs.NI I.4.8 published:2016-04-06 summary:We exploit human color metamers to send light-modulated messages less visibleto the human eye, but recoverable by cameras. These messages are a keycomponent to camera-display messaging, such as handheld smartphones capturinginformation from electronic signage. Each color pixel in the display image ismodified by a particular color gradient vector. The challenge is to find thecolor gradient that maximizes camera response, while minimizing human response.The mismatch in human spectral and camera sensitivity curves creates anopportunity for hidden messaging. Our approach does not require knowledge ofthese sensitivity curves, instead we employ a data-driven method. We learn anellipsoidal partitioning of the six-dimensional space of colors and colorgradients. This partitioning creates metamer sets defined by the base color atthe display pixel and the color gradient direction for message encoding. Wesample from the resulting metamer sets to find color steps for each base colorto embed a binary message into an arbitrary image with reduced visibleartifacts. Unlike previous methods that rely on visually obtrusive intensitymodulation, we embed with color so that the message is more hidden. Ordinarydisplays and cameras are used without the need for expensive LEDs or high speeddevices. The primary contribution of this work is a framework to map the pixelsin an arbitrary image to a metamer pair for steganographic photo messaging.
arxiv-1604-01643 | Information Utilization Ratio in Heuristic Optimization Algorithms |  http://arxiv.org/abs/1604.01643  | author:Junzhi Li, Ying Tan category:cs.NE published:2016-04-06 summary:Heuristic algorithms are able to optimize objective functions efficientlybecause they use intelligently the information of the objective functions. Thusinformation utilization is vital to the performance of heuristics. However, theconcept of information utilization has remained vague and abstract becausethere is no reliable metric to reflect the extent to which the information ofthe objective function is utilized in heuristic algorithms. In this paper, themetric of information utilization ratio (IUR) is defined, which is the ratiobetween the utilized information quantity and the acquired information quantityin the searching process. IUR proves to be well-defined. Several examples oftypical heuristic algorithms are given to demonstrate the procedure ofcalculating IUR. The results also reveal that elevating IUR is the potentialcause of many algorithmic improving works. IUR can be an index of how exquisitean algorithm is designed and guide the design of new heuristics and theimprovement of existing ones.
arxiv-1604-01729 | Improving LSTM-based Video Description with Linguistic Knowledge Mined from Text |  http://arxiv.org/abs/1604.01729  | author:Subhashini Venugopalan, Lisa Anne Hendricks, Raymond Mooney, Kate Saenko category:cs.CL cs.CV published:2016-04-06 summary:This paper investigates how linguistic knowledge mined from large textcorpora can aid the generation of natural language descriptions of videos.Specifically, we integrate both a neural language model and distributionalsemantics trained on large text corpora into a recent LSTM-based architecturefor video description. We evaluate our approach on a collection of Youtubevideos as well as two large movie description datasets showing significantimprovements in grammaticality while maintaining or modestly improvingdescriptive quality. Further, we show that such techniques can be beneficialfor describing unseen object classes with no paired training data (zeroshotcaptioning).
arxiv-1604-01733 | A U-statistic Approach to Hypothesis Testing for Structure Discovery in Undirected Graphical Models |  http://arxiv.org/abs/1604.01733  | author:Wacha Bounliphone, Matthew Blaschko category:stat.ML math.ST stat.TH published:2016-04-06 summary:Structure discovery in graphical models is the determination of the topologyof a graph that encodes conditional independence properties of the jointdistribution of all variables in the model. For some class of probabilitydistributions, an edge between two variables is present if and only if thecorresponding entry in the precision matrix is non-zero. For a finite sampleestimate of the precision matrix, entries close to zero may be due to lowsample effects, or due to an actual association between variables; these twocases are not readily distinguishable. %Fisher provided a hypothesis test basedon a parametric approximation to the distribution of an entry in the precisionmatrix of a Gaussian distribution, but this may not provide valid upper boundson $p$-values for non-Gaussian distributions. Many related works on this topicconsider potentially restrictive distributional or sparsity assumptions thatmay not apply to a data sample of interest, and direct estimation of theuncertainty of an estimate of the precision matrix for general distributionsremains challenging. Consequently, we make use of results for $U$-statisticsand apply them to the covariance matrix. By probabilistically bounding thedistortion of the covariance matrix, we can apply Weyl's theorem to bound thedistortion of the precision matrix, yielding a conservative, but sound testthreshold for a much wider class of distributions than considered in previousworks. The resulting test enables one to answer with statistical significancewhether an edge is present in the graph, and convergence results are known fora wide range of distributions. The computational complexities is linear in thesample size enabling the application of the test to large data samples forwhich computation time becomes a limiting factor. We experimentally validatethe correctness and scalability of the test on multivariate distributions forwhich the distributional assumptions of competing tests result inunderestimates of the false positive ratio. By contrast, the proposed testremains sound, promising to be a useful tool for hypothesis testing for diversereal-world problems.
arxiv-1604-01686 | Equivalence Among Different Variants of One-Class Nearest Neighbours and Creating Their Accurate Ensembles |  http://arxiv.org/abs/1604.01686  | author:Shehroz S. Khan, Amir Ahmad category:cs.LG published:2016-04-06 summary:In one-class classification (OCC) problems, only the data for the targetclass is available, whereas the data for the non-target class may be completelyabsent. In this paper, we study one-class nearest neighbour (OCNN) classifiersand their different variants for the OCC problem. We present a theoreticalanalysis to show the equivalence among different variants of OCNN that may usedifferent neighbours or thresholds to identify unseen examples of thenon-target class. We also present a method based on inter-quartile range foroptimizing parameters used in OCNN in the absence of non-target data duringtraining. Then, we propose to use two ensemble approaches based on randomsub-space and random projection approaches to create accurate ensemble thatsignificantly outperforms the baseline OCNN. We tested the proposed methods onvarious benchmark and real word domain-specific datasets to show their superiorperformance. The results give strong evidence that the random projectionensemble of the proposed OCNN with optimized parameters variants performsignificantly and consistently better than the single OCC on all the testeddatasets.
arxiv-1604-01692 | An Ensemble Method to Produce High-Quality Word Embeddings |  http://arxiv.org/abs/1604.01692  | author:Robert Speer, Joshua Chin category:cs.CL I.2.7 published:2016-04-06 summary:A currently successful approach to computational semantics is to representwords as embeddings in a machine-learned vector space. We present an ensemblemethod that combines embeddings produced by GloVe (Pennington et al., 2014) andword2vec (Mikolov et al., 2013) with structured knowledge from the semanticnetworks ConceptNet (Speer and Havasi, 2012) and PPDB (Ganitkevitch et al.,2013), merging their information into a common representation with a large,multilingual vocabulary. The embeddings it produces achieve state-of-the-artperformance on many word-similarity evaluations. Its score of $\rho = .596$ onan evaluation of rare words (Luong et al., 2013) is 16% higher than theprevious best known system.
arxiv-1604-01475 | Learning A Deep $\ell_\infty$ Encoder for Hashing |  http://arxiv.org/abs/1604.01475  | author:Zhangyang Wang, Yingzhen Yang, Shiyu Chang, Qing Ling, Thomas S. Huang category:cs.LG cs.CV published:2016-04-06 summary:We investigate the $\ell_\infty$-constrained representation whichdemonstrates robustness to quantization errors, utilizing the tool of deeplearning. Based on the Alternating Direction Method of Multipliers (ADMM), weformulate the original convex minimization problem as a feed-forward neuralnetwork, named \textit{Deep $\ell_\infty$ Encoder}, by introducing the novelBounded Linear Unit (BLU) neuron and modeling the Lagrange multipliers asnetwork biases. Such a structural prior acts as an effective networkregularization, and facilitates the model initialization. We then investigatethe effective use of the proposed model in the application of hashing, bycoupling the proposed encoders under a supervised pairwise loss, to develop a\textit{Deep Siamese $\ell_\infty$ Network}, which can be optimized from end toend. Extensive experiments demonstrate the impressive performances of theproposed model. We also provide an in-depth analysis of its behaviors againstthe competitors.
arxiv-1604-01806 | Generalising the Discriminative Restricted Boltzmann Machine |  http://arxiv.org/abs/1604.01806  | author:Srikanth Cherla, Son N Tran, Tillman Weyde, Artur d'Avila Garcez category:cs.LG published:2016-04-06 summary:We present a novel theoretical result that generalises the DiscriminativeRestricted Boltzmann Machine (DRBM). While originally the DRBM was definedassuming the {0, 1}-Bernoulli distribution in each of its hidden units, thisresult makes it possible to derive cost functions for variants of the DRBM thatutilise other distributions, including some that are often encountered in theliterature. This is illustrated with the Binomial and {-1, +1}-Bernoullidistributions here. We evaluate these two DRBM variants and compare them withthe original one on three benchmark datasets, namely the MNIST and USPS digitclassification datasets, and the 20 Newsgroups document classification dataset.Results show that each of the three compared models outperforms the remainingtwo in one of the three datasets, thus indicating that the proposed theoreticalgeneralisation of the DRBM may be valuable in practice.
arxiv-1604-01753 | Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding |  http://arxiv.org/abs/1604.01753  | author:Gunnar A. Sigurdsson, Gül Varol, Xiaolong Wang, Ali Farhadi, Ivan Laptev, Abhinav Gupta category:cs.CV published:2016-04-06 summary:Computer vision has a great potential to help our daily lives by searchingfor lost keys, watering flowers or reminding us to take a pill. To succeed withsuch tasks, computer vision methods need to be trained from real and diverseexamples of our daily dynamic scenes. While most of such scenes are notparticularly exciting, they typically do not appear on YouTube, in movies or TVbroadcasts. So how do we collect sufficiently many diverse but boring samplesrepresenting our lives? We propose a novel Hollywood in Homes approach tocollect such data. Instead of shooting videos in the lab, we ensure diversityby distributing and crowdsourcing the whole process of video creation fromscript writing to video recording and annotation. Following this procedure wecollect a new dataset, Charades, with hundreds of people recording videos intheir own homes, acting out casual everyday activities. The dataset is composedof 9,850 annotated videos with an average length of 30 seconds, showingactivities of 267 people from three continents. Each video is annotated bymultiple free-text descriptions, action labels, action intervals and classes ofinteracted objects. In total, Charades provides 27,847 video descriptions,37,972 temporally localized intervals for 160 action classes and 24,623 labelsfor 40 object classes. Using this rich data, we evaluate and provide baselineresults for several tasks including action recognition and automaticdescription generation. We believe that the realism, diversity, and casualnature of this dataset will present unique challenges and new opportunities forcomputer vision community.
arxiv-1604-01474 | Self-Paced Multi-Task Learning |  http://arxiv.org/abs/1604.01474  | author:Changsheng Li, Fan Wei, Junchi Yan, Weishan Dong, Qingshan Liu, Hongyuan Zha category:cs.LG published:2016-04-06 summary:In this paper, we propose a novel multi-task learning (MTL) framework, calledSelf-Paced Multi-Task Learning (SPMTL). Different from previous works treatingall tasks and instances equally when training, SPMTL attempts to jointly learnthe tasks by taking into consideration the complexities of both tasks andinstances. This is inspired by the cognitive process of human brain that oftenlearns from the easy to the hard. We construct a compact SPMTL formulation byproposing a new task-oriented regularizer that can jointly prioritize the tasksand the instances. Thus it can be interpreted as a self-paced learner for MTL.A simple yet effective algorithm is designed for optimizing the proposedobjective function. An error bound for a simplified formulation is alsoanalyzed theoretically. Experimental results on toy and real-world datasetsdemonstrate the effectiveness of the proposed approach, compared to thestate-of-the-art methods.
arxiv-1604-01818 | R-FUSE: Robust Fast Fusion of Multi-Band Images Based on Solving a Sylvester Equation |  http://arxiv.org/abs/1604.01818  | author:Qi Wei, Nicolas Dobigeon, Jean-Yves Tourneret, Jose Bioucas-Dias, Simon Godsill category:cs.CV published:2016-04-06 summary:This paper proposes a robust fast multi-band image fusion method to merge ahigh-spatial low-spectral resolution image and a low-spatial high-spectralresolution image. Following the method recently developed in [1], thegeneralized Sylvester matrix equation associated with the multi-band imagefusion problem is solved in a more robust and efficient way by exploiting theWoodbury formula, avoiding any permutation operation in the frequency domain aswell as the blurring kernel invertibility assumption required in [1]. Thanks tothis improvement, the proposed algorithm requires fewer computationaloperations and is also more robust with respect to the blurring kernel comparedwith the one in [1]. The proposed new algorithm is tested with different priorsconsidered in [1]. Our conclusion is that the proposed fusion algorithm is morerobust than the one in [1] with a reduced computational cost.
arxiv-1604-01785 | Safe Probability |  http://arxiv.org/abs/1604.01785  | author:Peter Grünwald category:stat.ME cs.AI cs.LG math.ST stat.TH 62A01 published:2016-04-06 summary:We formalize the idea of probability distributions that lead to reliablepredictions about some, but not all aspects of a domain. The resulting notionof `safety' provides a fresh perspective on foundational issues in statistics,providing a middle ground between imprecise probability and multiple-priormodels on the one hand and strictly Bayesian approaches on the other. It alsoallows us to formalize fiducial distributions in terms of the set of randomvariables that they can safely predict, thus taking some of the sting out ofthe fiducial idea. By restricting probabilistic inference to safe uses, onealso automatically avoids paradoxes such as the Monty Hall problem. Safetycomes in a variety of degrees, such as "validity" (the strongest notion),"calibration", "confidence safety" and "unbiasedness" (almost the weakestnotion).
arxiv-1604-01787 | A Subpath Kernel for Learning Hierarchical Image Representations |  http://arxiv.org/abs/1604.01787  | author:Yanwei Cui, Laetitia Chapel, Sébastien Lefèvre category:cs.CV published:2016-04-06 summary:Tree kernels have demonstrated their ability to deal with hierarchical data,as the intrinsic tree structure often plays a discriminative role. While suchkernels have been successfully applied to various domains such as naturelanguage processing and bioinformatics, they mostly concentrate on orderedtrees and whose nodes are described by symbolic data. Meanwhile, hierarchicalrepresentations have gained increasing interest to describe image content. Thisis particularly true in remote sensing, where such representations allow forrevealing different objects of interest at various scales through a treestructure. However, the induced trees are unordered and the nodes are equippedwith numerical features. In this paper, we propose a new structured kernel forhierarchical image representations which is built on the concept of subpathkernel. Experimental results on both artificial and remote sensing datasetsshow that the proposed kernel manages to deal with the hierarchical nature ofthe data, leading to better classification rates.
arxiv-1604-01792 | Advances in Very Deep Convolutional Neural Networks for LVCSR |  http://arxiv.org/abs/1604.01792  | author:Tom Sercu, Vaibhava Goel category:cs.CL cs.LG cs.NE published:2016-04-06 summary:Very deep CNNs with small 3x3 kernels have recently been shown to achievevery strong performance as acoustic models in hybrid NN-HMM speech recognitionsystems. In this paper, we demonstrate that the accuracy gains of these deepCNNs are retained both on larger scale data, and after sequence training. Weshow this by carrying out sequence training on both the 300h switchboard-1 andthe 2000h switchboard dataset. Furthermore, we investigate how pooling andpadding in time influences performance, both in terms of word error rate andcomputational cost. We argue that designing CNNs without timepadding andwithout timepooling, though slightly suboptimal for accuracy, has twosignificant consequences. Firstly, the proposed design allows for efficientevaluation at sequence training and test (deployment) time. Secondly, thisdesign principle allows for batch normalization to be adopted to CNNs onsequence data. Our very deep CNN model sequence trained on the 2000hswitchboard dataset obtains 9.4 word error rate on the Hub5 test-set, matchingwith a single model the performance of 2015 IBM system combination, which wasthe previous best published result.
arxiv-1604-01827 | Deep Semantic Matching for Optical Flow |  http://arxiv.org/abs/1604.01827  | author:Min Bai, Wenjie Luo, Kaustav Kundu, Raquel Urtasun category:cs.CV published:2016-04-06 summary:We tackle the problem of estimating optical flow from a monocular camera inthe context of autonomous driving. We build on the observation that the sceneis typically composed of a static background, as well as a relatively smallnumber of traffic participants which move rigidly in 3D. We propose to estimatethe traffic participants using instance-level segmentation. For each trafficparticipant, we use the epipolar constraints that govern each independentmotion for faster and more accurate estimation. Our second contribution is anew convolutional net that learns to perform flow matching, and is able toestimate the uncertainty of its matches. This is a core element of our flowestimation pipeline. We demonstrate the effectiveness of our approach in thechallenging KITTI 2015 flow benchmark, and show that our approach outperformspublished approaches by a large margin.
arxiv-1604-01662 | Towards Bayesian Deep Learning: A Survey |  http://arxiv.org/abs/1604.01662  | author:Hao Wang, Dit-Yan Yeung category:stat.ML cs.AI cs.CV cs.LG cs.NE published:2016-04-06 summary:While perception tasks such as visual object recognition and textunderstanding play an important role in human intelligence, the subsequenttasks that involve inference, reasoning and planning require an even higherlevel of intelligence. The past few years have seen major advances in manyperception tasks using deep learning models. For higher-level inference,however, probabilistic graphical models with their Bayesian nature are stillmore powerful and flexible. To achieve integrated intelligence that involvesboth perception and inference, it is naturally desirable to tightly integratedeep learning and Bayesian models within a principled probabilistic framework,which we call Bayesian deep learning. In this unified framework, the perceptionof text or images using deep learning can boost the performance of higher-levelinference and in return, the feedback from the inference process is able toenhance the perception of text or images. This survey provides a generalintroduction to Bayesian deep learning and reviews its recent applications onrecommender systems, topic models, and control. In this survey, we also discussthe relationship and differences between Bayesian deep learning and otherrelated topics like Bayesian treatment of neural networks.
arxiv-1604-01655 | Correlated and Individual Multi-Modal Deep Learning for RGB-D Object Recognition |  http://arxiv.org/abs/1604.01655  | author:Ziyan Wang, Ruogu Lin, Jiwen Lu, Jianjiang Feng, Jie zhou category:cs.CV published:2016-04-06 summary:In this paper, we propose a new correlated and individual multi-modal deeplearning (CIMDL) method for RGB-D object recognition. Unlike most conventionalRGB-D object recognition methods which extract features from the RGB and depthchannels individually, our CIMDL jointly learns feature representations fromraw RGB-D data with a pair of deep neural networks, so that the sharable andmodal-specific information can be simultaneously exploited. Specifically, weconstruct a pair of deep convolutional neural networks (CNNs) for the RGB anddepth data, and concatenate them at the top layer of the network with a lossfunction which learns a new feature space where both correlated part and theindividual part of the RGB-D information are well modelled. The parameters ofthe whole networks are updated by using the back-propagation criterion.Experimental results on two widely used RGB-D object image benchmark datasetsclearly show that our method outperforms state-of-the-arts.
arxiv-1604-01828 | Differential TD Learning for Value Function Approximation |  http://arxiv.org/abs/1604.01828  | author:Adithya M. Devraj, Sean P. Meyn category:cs.SY cs.LG math.OC published:2016-04-06 summary:Value functions arise as a component of algorithms as well as performancemetrics in statistics and engineering applications. Computation of theassociated Bellman equations is numerically challenging in all but a fewspecial cases. A popular approximation technique is known as TemporalDifference (TD) learning. The algorithm introduced in this paper is intended toresolve two well-known problems with this approach:In the discounted-costsetting, the variance of the algorithm diverges as the discount factorapproaches unity. Second, for the average cost setting, unbiased algorithmsexist only in special cases. It is shown that the gradient of any of these value functions admits arepresentation that lends itself to algorithm design. Based on this result, thenew differential TD method is obtained for Markovian models on Euclidean spacewith smooth dynamics. Numerical examples show remarkable improvements in performance. Inapplication to speed scaling, variance is reduced by two orders of magnitude.
arxiv-1604-01685 | The Cityscapes Dataset for Semantic Urban Scene Understanding |  http://arxiv.org/abs/1604.01685  | author:Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, Bernt Schiele category:cs.CV published:2016-04-06 summary:Visual understanding of complex urban street scenes is an enabling factor fora wide range of applications. Object detection has benefited enormously fromlarge-scale datasets, especially in the context of deep learning. For semanticurban scene understanding, however, no current dataset adequately captures thecomplexity of real-world urban scenes. To address this, we introduce Cityscapes, a benchmark suite and large-scaledataset to train and test approaches for pixel-level and instance-levelsemantic labeling. Cityscapes is comprised of a large, diverse set of stereovideo sequences recorded in streets from 50 different cities. 5000 of theseimages have high quality pixel-level annotations; 20000 additional images havecoarse annotations to enable methods that leverage large volumes ofweakly-labeled data. Crucially, our effort exceeds previous attempts in termsof dataset size, annotation richness, scene variability, and complexity. Ouraccompanying empirical study provides an in-depth analysis of the datasetcharacteristics, as well as a performance evaluation of severalstate-of-the-art approaches based on our benchmark.
arxiv-1604-01537 | Generating Chinese Classical Poems with RNN Encoder-Decoder |  http://arxiv.org/abs/1604.01537  | author:Xiaoyuan Yi, Ruoyu Li, Maosong Sun category:cs.CL cs.NE published:2016-04-06 summary:We take the generation of Chinese classical poem lines as asequence-to-sequence learning problem, and build a novel system based on theRNN Encoder-Decoder structure to generate quatrains (Jueju in Chinese), with atopic word as input. Our system can jointly learn semantic meaning within asingle line, semantic relevance among lines in a poem, and the use ofstructural, rhythmical and tonal patterns, without utilizing any constrainttemplates. Experimental results show that our system outperforms othercompetitive systems. We also find that the attention mechanism can capture theword associations in Chinese classical poetry and inverting target lines intraining can improve performance.
arxiv-1604-01802 | Learning to Track at 100 FPS with Deep Regression Networks |  http://arxiv.org/abs/1604.01802  | author:David Held, Sebastian Thrun, Silvio Savarese category:cs.CV cs.AI cs.LG cs.RO published:2016-04-06 summary:Machine learning techniques are often used in computer vision due to theirability to leverage large amounts of training data to improve performance.Unfortunately, most generic object trackers are still trained from scratchonline and do not benefit from the large number of videos that are readilyavailable for offline training. We propose a method for using neural networksto track generic objects in a way that allows them to improve performance bytraining on labeled videos. Previous attempts to use neural networks fortracking are very slow to run and not practical for real-time applications. Incontrast, our tracker uses a simple feed-forward network with no onlinetraining required, allowing our tracker to run at 100 fps during test time. Ourtracker trains from both labeled video as well as a large collection of images,which helps prevent overfitting. The tracker learns generic object motion andcan be used to track novel objects that do not appear in the training set. Wetest our network on a standard tracking benchmark to demonstrate our tracker'sstate-of-the-art performance. Our network learns to track generic objects inreal-time as they move throughout the world.
arxiv-1604-01602 | Manifold unwrapping using density ridges |  http://arxiv.org/abs/1604.01602  | author:Jonas Nordhaug Myhre, Matineh Shaker, Devrim Kaba, Robert Jenssen, Deniz Erdogmus category:stat.ML published:2016-04-06 summary:Research on manifold learning within a density ridge estimation framework hasshown great potential in recent work for both estimation and de-noising ofmanifolds, building on the intuitive and well-defined notion of principalcurves and surfaces. However, the problem of unwrapping or unfolding manifoldshas received relatively little attention within the density ridge approach,despite being an integral part of manifold learning in general. This paperproposes two novel algorithms for unwrapping manifolds based on estimatedprincipal curves and surfaces for one- and multi-dimensional manifoldsrespectively. The methods of unwrapping are founded in the realization thatboth principal curves and principal surfaces will have inherent local maxima ofthe probability density function. Following this observation, coordinatesystems that follow the shape of the manifold can be computed by following theintegral curves of the gradient flow of a kernel density estimate on themanifold. Furthermore, since integral curves of the gradient flow of a kerneldensity estimate is inherently local, we propose to stitch together localcoordinate systems using parallel transport along the manifold. We providenumerical experiments on both real and synthetic data that illustrates clearand intuitive unwrapping results comparable to state-of-the-art manifoldlearning algorithms.
arxiv-1604-01518 | Simple and Efficient Learning using Privileged Information |  http://arxiv.org/abs/1604.01518  | author:Xinxing Xu, Joey Tianyi Zhou, IvorW. Tsang, Zheng Qin, Rick Siow Mong Goh, Yong Liu category:cs.LG published:2016-04-06 summary:The Support Vector Machine using Privileged Information (SVM+) has beenproposed to train a classifier to utilize the additional privileged informationthat is only available in the training phase but not available in the testphase. In this work, we propose an efficient solution for SVM+ by simplyutilizing the squared hinge loss instead of the hinge loss as in the existingSVM+ formulation, which interestingly leads to a dual form with less variablesand in the same form with the dual of the standard SVM. The proposed algorithmis utilized to leverage the additional web knowledge that is only availableduring training for the image categorization tasks. The extensive experimentalresults on both Caltech101 andWebQueries datasets show that our proposed methodcan achieve a factor of up to hundred times speedup with the comparableaccuracy when compared with the existing SVM+ method.
arxiv-1604-01515 | Comments on: "A Random Forest Guided Tour" by G. Biau and E. Scornet |  http://arxiv.org/abs/1604.01515  | author:Sylvain Arlot, Robin Genuer category:math.ST stat.ME stat.ML stat.TH published:2016-04-06 summary:This paper is a comment on the survey paper by Biau and Scornet (2016) aboutrandom forests. We focus on the problem of quantifying the impact of eachingredient of random forests on their performance. We show that such aquantification is possible for a simple pure forest , leading to conclusionsthat could apply more generally. Then, we consider "hold-out" random forests,which are a good middle point between "toy" pure forests and Breiman's originalrandom forests.
arxiv-1604-01500 | LOMo: Latent Ordinal Model for Facial Analysis in Videos |  http://arxiv.org/abs/1604.01500  | author:Karan Sikka, Gaurav Sharma, Marian Bartlett category:cs.CV published:2016-04-06 summary:We study the problem of facial analysis in videos. We propose a novel weaklysupervised learning method that models the video event (expression, pain etc.)as a sequence of automatically mined, discriminative sub-events (eg. onset andoffset phase for smile, brow lower and cheek raise for pain). The proposedmodel is inspired by the recent works on Multiple Instance Learning and latentSVM/HCRF- it extends such frameworks to model the ordinal or temporal aspect inthe videos, approximately. We obtain consistent improvements over relevantcompetitive baselines on four challenging and publicly available video basedfacial analysis datasets for prediction of expression, clinical pain and intentin dyadic conversations. In combination with complimentary features, we reportstate-of-the-art results on these datasets.
arxiv-1604-01497 | How does the Low-Rank Matrix Completion Help Internal and External Learnings for Super-Resolution |  http://arxiv.org/abs/1604.01497  | author:Shuang Wang, Bo Yue, Xuefeng Liang, Peiyuan Ji, Licheng Jiao category:cs.CV published:2016-04-06 summary:A new challenge in Super-resolution (SR) problem is how to utilize the prosof internal and external learnings to further enhance the result. To addressthis issue, we analyze the attributes of these two kinds of methods, and findthey are complementary in the feature space and image plan, meanwhile, havesparse estimation error. This finding inspires us to propose a low-ranksolution which effectively integrates them together. We then tailor an internalprior learning and an external dictionary learning to fit the solution. With atheoretical analysis on the algorithm, we also prove that the low-rank solutiondoes not require massive input to guarantee the performance. This simplifiesthe design of the internal and external learning methods for the solution, andreduces the computation cost. Unlike other methods, the proposed solution is aparameter free integration, and can be generalized with more recent internaland external learning methods. Intensive experiments show the proposed solutionreconstructs image details effectively, also outperforms state-of-the-arts inboth visual and quantitative assessments, especially for the noisy images.
arxiv-1604-01495 | Parameterized Analysis of Multi-objective Evolutionary Algorithms and the Weighted Vertex Cover Problem |  http://arxiv.org/abs/1604.01495  | author:Mojgan Pourhassan, Feng Shi, Frank Neumann category:cs.NE cs.DS published:2016-04-06 summary:A rigorous runtime analysis of evolutionary multi-objective optimization forthe classical vertex cover problem in the context of parameterized complexityanalysis has been presented by Kratsch and Neumann (2013). In this paper, weextend the analysis to the weighted vertex cover problem and provide a fixedparameter evolutionary algorithm with respect to OPT, the cost of the theoptimal solution for the problem. Moreover, using a diversity mechanisms, wepresent a multi-objective evolutionary algorithm that finds a 2-approximationin expected polynomial time and introduce a population-based evolutionaryalgorithm which finds a $(1+\varepsilon)$-approximation in expected time$O(n\cdot 2^{\min \{n,2(1- \varepsilon)OPT \}} + n^3)$.
arxiv-1604-02013 | Keyboard Based Control of Four Dimensional Rotations |  http://arxiv.org/abs/1604.02013  | author:Akira Kageyama category:cs.GR cs.CV published:2016-04-06 summary:Aiming at applications to the scientific visualization of three dimensionalsimulations with time evolution, a keyboard based control method to specifyrotations in four dimensions is proposed. It is known that four dimensionalrotations are generally so-called double rotations, and a double rotation is acombination of simultaneously applied two simple rotations. The proposed methodcan specify both the simple and double rotations by single key typings of thekeyboard. The method is tested in visualizations of a regular pentachoron infour dimensional space by a hyperplane slicing.
arxiv-1604-01485 | A Focused Dynamic Attention Model for Visual Question Answering |  http://arxiv.org/abs/1604.01485  | author:Ilija Ilievski, Shuicheng Yan, Jiashi Feng category:cs.CV cs.CL cs.NE published:2016-04-06 summary:Visual Question and Answering (VQA) problems are attracting increasinginterest from multiple research disciplines. Solving VQA problems requirestechniques from both computer vision for understanding the visual contents of apresented image or video, as well as the ones from natural language processingfor understanding semantics of the question and generating the answers.Regarding visual content modeling, most of existing VQA methods adopt thestrategy of extracting global features from the image or video, whichinevitably fails in capturing fine-grained information such as spatialconfiguration of multiple objects. Extracting features from auto-generatedregions -- as some region-based image recognition methods do -- cannotessentially address this problem and may introduce some overwhelming irrelevantfeatures with the question. In this work, we propose a novel Focused DynamicAttention (FDA) model to provide better aligned image content representationwith proposed questions. Being aware of the key words in the question, FDAemploys off-the-shelf object detector to identify important regions and fusethe information from the regions and global features via an LSTM unit. Suchquestion-driven representations are then combined with question representationand fed into a reasoning unit for generating the answers. Extensive evaluationon a large-scale benchmark dataset, VQA, clearly demonstrate the superiorperformance of FDA over well-established baselines.
arxiv-1604-01444 | A Convolutional Neural Network Neutrino Event Classifier |  http://arxiv.org/abs/1604.01444  | author:A. Aurisano, A. Radovic, D. Rocco, A. Himmel, M. D. Messier, E. Niner, G. Pawloski, F. Psihas, A. Sousa, P. Vahle category:hep-ex cs.CV published:2016-04-05 summary:Convolutional neural networks (CNNs) have been widely applied in the computervision community to solve complex problems in image recognition and analysis.We describe an application of the CNN technology to the problem of identifyingparticle interactions in sampling calorimeters used commonly in high energyphysics and high energy neutrino physics in particular. Following a discussionof the core concepts of CNNs and recent innovations in CNN architecturesrelated to the field of deep learning, we outline a specific application to theNOvA neutrino detector. This algorithm, CVN (Convolutional Visual Network)identifies neutrino interactions based on their topology without the need fordetailed reconstruction and outperforms algorithms currently in use by the NOvAcollaboration.
arxiv-1604-01416 | dMath: A Scalable Linear Algebra and Math Library for Heterogeneous GP-GPU Architectures |  http://arxiv.org/abs/1604.01416  | author:Steven Eliuk, Cameron Upright, Anthony Skjellum category:cs.NE cs.DC cs.MS published:2016-04-05 summary:A new scalable parallel math library, dMath, is presented in this paper thatdemonstrates leading scaling when using intranode, or internode,hybrid-parallelism for deep-learning. dMath provides easy-to-use distributedbase primitives and a variety of domain-specific algorithms. These includematrix multiplication, convolutions, and others allowing for rapid developmentof highly scalable applications, including Deep Neural Networks (DNN), whereaspreviously one was restricted to libraries that provided effective primitivesfor only a single GPU, like Nvidia cublas and cudnn or DNN primitives fromNervana neon framework. Development of HPC software is difficult,labor-intensive work, requiring a unique skill set. dMath allows a wide rangeof developers to utilize parallel and distributed hardware easily. Onecontribution of this approach is that data is stored persistently on the GPUhardware, avoiding costly transfers between host and device. Advanced memorymanagement techniques are utilized, including caching of transferred data andmemory reuse through pooling. A key contribution of dMath is that it deliversperformance, portability, and productivity to its specific domain of support.It enables algorithm and application programmers to quickly solve problemswithout managing the significant complexity associated with multi-levelparallelism.
arxiv-1604-01420 | Highly accurate gaze estimation using a consumer RGB-depth sensor |  http://arxiv.org/abs/1604.01420  | author:Reza Shoja Ghiass, Ognjen Arandjelovic category:cs.CV published:2016-04-05 summary:Determining the direction in which a person is looking is an importantproblem in a wide range of HCI applications. In this paper we describe a highlyaccurate algorithm that performs gaze estimation using an affordable and widelyavailable device such as Kinect. The method we propose starts by performingaccurate head pose estimation achieved by fitting a person specific morphablemodel of the face to depth data. The ordinarily competing requirements of highaccuracy and high speed are met concurrently by formulating the fittingobjective function as a combination of terms which excel either in accurate orfast fitting, and then by adaptively adjusting their relative contributionsthroughout fitting. Following pose estimation, pose normalization is done byre-rendering the fitted model as a frontal face. Finally gaze estimates areobtained through regression from the appearance of the eyes in synthetic,normalized images. Using EYEDIAP, the standard public dataset for theevaluation of gaze estimation algorithms from RGB-D data, we demonstrate thatour method greatly outperforms the state of the art.
arxiv-1604-01350 | Bounded Optimal Exploration in MDP |  http://arxiv.org/abs/1604.01350  | author:Kenji Kawaguchi category:cs.AI cs.LG published:2016-04-05 summary:Within the framework of probably approximately correct Markov decisionprocesses (PAC-MDP), much theoretical work has focused on methods to attainnear optimality after a relatively long period of learning and exploration.However, practical concerns require the attainment of satisfactory behaviorwithin a short period of time. In this paper, we relax the PAC-MDP conditionsto reconcile theoretically driven exploration methods and practical needs. Wepropose simple algorithms for discrete and continuous state spaces, andillustrate the benefits of our proposed relaxation via theoretical analyses andnumerical examples. Our algorithms also maintain anytime error bounds andaverage loss bounds. Our approach accommodates both Bayesian and non-Bayesianmethods.
arxiv-1604-01433 | Collaborative Representation Learning |  http://arxiv.org/abs/1604.01433  | author:Matías Vera, Leonardo Rey Vega, Pablo Piantanida category:cs.IT math.IT stat.ML published:2016-04-05 summary:This paper investigates an information-theoretic approach to the problem ofcollaborative representation learning: how to extract salient features ofstatistical relationships in order to build cooperatively meaningfulrepresentations of some relevant content. Modeling the structure of data andits hidden representations by independently identically distributed samples,our goal is to study fundamental limits of the so-called Two-way CollaborativeRepresentation Learning (TW-CRL) and the Collaborative DistributedRepresentation Learning (CDRL) problems. The TW-CRL problem consists of twodistant encoders that separately observe marginal (dependent) components $X_1$and $X_2$ and can cooperate through multiple exchanges of limited informationwith the aim of learning hidden representations $(Y_1,Y_2)$, which can bearbitrarily dependent on $(X_1,X_2)$. On the other hand, in CDRL there are twocooperating encoders and the learner of the hidden representation $Y$ is athird node which can listen the exchanges between the two encoders. Therelevance (figure-of-merit) of such learned representations is measured interms of a normalized (per-sample) multi-letter mutual information metric.Inner and outer bounds to the complexity-relevance region of these problems arederived from which optimality is characterized for several cases of interest.Our resulting complexity-relevance regions are finally evaluated for binarysymmetric and Gaussian statistical models showing how to identify comparativelyrandom features that represent complexity-constrained statistics for theinference of the hidden representations.
arxiv-1604-01243 | Mental Lexicon Growth Modelling Reveals the Multiplexity of the English Language |  http://arxiv.org/abs/1604.01243  | author:Massimo Stella, Markus Brede category:physics.soc-ph cs.CL cs.SI published:2016-04-05 summary:In this work we extend previous analyses of linguistic networks by adopting amulti-layer network framework for modelling the human mental lexicon, i.e. anabstract mental repository where words and concepts are stored together withtheir linguistic patterns. Across a three-layer linguistic multiplex, we modelEnglish words as nodes and connect them according to (i) phonologicalsimilarities, (ii) synonym relationships and (iii) free word associations. Ourmain aim is to exploit this multi-layered structure to explore the influence ofphonological and semantic relationships on lexicon assembly over time. Wepropose a model of lexicon growth which is driven by the phonological layer:words are suggested according to different orderings of insertion (e.g. shorterword length, highest frequency, semantic multiplex features) and accepted orrejected subject to constraints. We then measure times of network assembly andcompare these to empirical data about the age of acquisition of words. Inagreement with empirical studies in psycholinguistics, our results providequantitative evidence for the hypothesis that word acquisition is driven byfeatures at multiple levels of organisation within language.
arxiv-1604-01348 | Bayesian Optimization with Exponential Convergence |  http://arxiv.org/abs/1604.01348  | author:Kenji Kawaguchi, Leslie Pack Kaelbling, Tomás Lozano-Pérez category:stat.ML cs.LG published:2016-04-05 summary:This paper presents a Bayesian optimization method with exponentialconvergence without the need of auxiliary optimization and without thedelta-cover sampling. Most Bayesian optimization methods require auxiliaryoptimization: an additional non-convex global optimization problem, which canbe time-consuming and hard to implement in practice. Also, the existingBayesian optimization method with exponential convergence requires access tothe delta-cover sampling, which was considered to be impractical. Our approacheliminates both requirements and achieves an exponential convergence rate.
arxiv-1604-01235 | A new TAG Formalism for Tamil and Parser Analytics |  http://arxiv.org/abs/1604.01235  | author:Vijay Krishna Menon, S. Rajendran, M. Anand Kumar, K. P. Soman category:cs.CL published:2016-04-05 summary:Tree adjoining grammar (TAG) is specifically suited for morph rich andagglutinated languages like Tamil due to its psycho linguistic features andparse time dependency and morph resolution. Though TAG and LTAG formalisms havebeen known for about 3 decades, efforts on designing TAG Syntax for Tamil havenot been entirely successful due to the complexity of its specification and therich morphology of Tamil language. In this paper we present a minimalistic TAGfor Tamil without much morphological considerations and also introduce a parserimplementation with some obvious variations from the XTAG system
arxiv-1604-01221 | Character-Level Neural Translation for Multilingual Media Monitoring in the SUMMA Project |  http://arxiv.org/abs/1604.01221  | author:Guntis Barzdins, Steve Renals, Didzis Gosko category:cs.CL published:2016-04-05 summary:The paper steps outside the comfort-zone of the traditional NLP tasks likeautomatic speech recognition (ASR) and machine translation (MT) to addressestwo novel problems arising in the automated multilingual news monitoring:segmentation of the TV and radio program ASR transcripts into individualstories, and clustering of the individual stories coming from various sourcesand languages into storylines. Storyline clustering of stories covering thesame events is an essential task for inquisitorial media monitoring. We addressthese two problems jointly by engaging the low-dimensional semanticrepresentation capabilities of the sequence to sequence neural translationmodels. To enable joint multi-task learning for multilingual neural translationof morphologically rich languages we replace the attention mechanism with thesliding-window mechanism and operate the sequence to sequence neuraltranslation model on the character-level rather than on the word-level. Thestory segmentation and storyline clustering problem is tackled by examining thelow-dimensional vectors produced as a side-product of the neural translationprocess. The results of this paper describe a novel approach to the automaticstory segmentation and storyline clustering problem.
arxiv-1604-01347 | Marr Revisited: 2D-3D Alignment via Surface Normal Prediction |  http://arxiv.org/abs/1604.01347  | author:Aayush Bansal, Bryan Russell, Abhinav Gupta category:cs.CV published:2016-04-05 summary:We introduce an approach that leverages surface normal predictions, alongwith appearance cues, to retrieve 3D models for objects depicted in 2D stillimages from a large CAD object library. Critical to the success of our approachis the ability to recover accurate surface normals for objects in the depictedscene. We introduce a skip-network model built on the pre-trained Oxford VGGconvolutional neural network (CNN) for surface normal prediction. Our modelachieves state-of-the-art accuracy on the NYUv2 RGB-D dataset for surfacenormal prediction, and recovers fine object detail compared to previousmethods. Furthermore, we develop a two-stream network over the input image andpredicted surface normals that jointly learns pose and style for CAD modelretrieval. When using the predicted surface normals, our two-stream networkmatches prior work using surface normals computed from RGB-D images on the taskof pose prediction, and achieves state of the art when using RGB-D input.Finally, our two-stream network allows us to retrieve CAD models that bettermatch the style and pose of a depicted object compared with baselineapproaches.
arxiv-1604-01219 | Learning to Generate Posters of Scientific Papers |  http://arxiv.org/abs/1604.01219  | author:Yuting Qiang, Yanwei Fu, Yanwen Guo, Zhi-Hua Zhou, Leonid Sigal category:cs.AI cs.CL cs.HC cs.MM stat.ML published:2016-04-05 summary:Researchers often summarize their work in the form of posters. Postersprovide a coherent and efficient way to convey core ideas from scientificpapers. Generating a good scientific poster, however, is a complex and timeconsuming cognitive task, since such posters need to be readable, informative,and visually aesthetic. In this paper, for the first time, we study thechallenging problem of learning to generate posters from scientific papers. Tothis end, a data-driven framework, that utilizes graphical models, is proposed.Specifically, given content to display, the key elements of a good poster,including panel layout and attributes of each panel, are learned and inferredfrom data. Then, given inferred layout and attributes, composition of graphicalelements within each panel is synthesized. To learn and validate our model, wecollect and make public a Poster-Paper dataset, which consists of scientificpapers and corresponding posters with exhaustively labelled panels andattributes. Qualitative and quantitative results indicate the effectiveness ofour approach.
arxiv-1604-01178 | Modeling Relational Information in Question-Answer Pairs with Convolutional Neural Networks |  http://arxiv.org/abs/1604.01178  | author:Aliaksei Severyn, Alessandro Moschitti category:cs.CL published:2016-04-05 summary:In this paper, we propose convolutional neural networks for learning anoptimal representation of question and answer sentences. Their main aspect isthe use of relational information given by the matches between words from thetwo members of the pair. The matches are encoded as embeddings with additionalparameters (dimensions), which are tuned by the network. These allows forbetter capturing interactions between questions and answers, resulting in asignificant boost in accuracy. We test our models on two widely used answersentence selection benchmarks. The results clearly show the effectiveness ofour relational information, which allows our relatively simple network toapproach the state of the art.
arxiv-1604-01250 | Fast methods for training Gaussian processes on large data sets |  http://arxiv.org/abs/1604.01250  | author:Christopher J. Moore, Alvin J. K. Chua, Christopher P. L. Berry, Jonathan R. Gair category:stat.ML stat.CO stat.ME published:2016-04-05 summary:Gaussian process regression (GPR) is a non-parametric Bayesian technique forinterpolating or fitting data. The main barrier to further uptake of thispowerful tool rests in the computational costs associated with the matriceswhich arise when dealing with large data sets. Here, we derive some simpleresults which we have found useful for speeding up the learning stage in theGPR algorithm, and especially for performing Bayesian model comparison betweendifferent covariance functions. We apply our techniques to both synthetic andreal data and quantify the speed-up relative to using nested sampling tonumerically evaluate model evidences.
arxiv-1604-01272 | Feature extraction using Latent Dirichlet Allocation and Neural Networks: A case study on movie synopses |  http://arxiv.org/abs/1604.01272  | author:Despoina Christou category:cs.CL cs.AI cs.IR cs.LG stat.ML published:2016-04-05 summary:Feature extraction has gained increasing attention in the field of machinelearning, as in order to detect patterns, extract information, or predictfuture observations from big data, the urge of informative features is crucial.The process of extracting features is highly linked to dimensionality reductionas it implies the transformation of the data from a sparse high-dimensionalspace, to higher level meaningful abstractions. This dissertation employsNeural Networks for distributed paragraph representations, and Latent DirichletAllocation to capture higher level features of paragraph vectors. AlthoughNeural Networks for distributed paragraph representations are considered thestate of the art for extracting paragraph vectors, we show that a quick topicanalysis model such as Latent Dirichlet Allocation can provide meaningfulfeatures too. We evaluate the two methods on the CMU Movie Summary Corpus, acollection of 25,203 movie plot summaries extracted from Wikipedia. Finally,for both approaches, we use K-Nearest Neighbors to discover similar movies, andplot the projected representations using T-Distributed Stochastic NeighborEmbedding to depict the context similarities. These similarities, expressed asmovie distances, can be used for movies recommendation. The recommended moviesof this approach are compared with the recommended movies from IMDB, which usea collaborative filtering recommendation approach, to show that our two modelscould constitute either an alternative or a supplementary recommendationapproach.
arxiv-1604-01170 | Accurate and scalable social recommendation using mixed-membership stochastic block models |  http://arxiv.org/abs/1604.01170  | author:Antonia Godoy-Lorite, Roger Guimera, Cristopher Moore, Marta Sales-Pardo category:cs.SI cs.IR cs.LG physics.soc-ph published:2016-04-05 summary:With ever-increasing amounts of online information available, modeling andpredicting individual preferences-for books or articles, for example-isbecoming more and more important. Good predictions enable us to improve adviceto users, and obtain a better understanding of the socio-psychologicalprocesses that determine those preferences. We have developed a collaborativefiltering model, with an associated scalable algorithm, that makes accuratepredictions of individuals' preferences. Our approach is based on the explicitassumption that there are groups of individuals and of items, and that thepreferences of an individual for an item are determined only by their groupmemberships. Importantly, we allow each individual and each item to belongsimultaneously to mixtures of different groups and, unlike many popularapproaches, such as matrix factorization, we do not assume implicitly orexplicitly that individuals in each group prefer items in a single group ofitems. The resulting overlapping groups and the predicted preferences can beinferred with a expectation-maximization algorithm whose running time scaleslinearly (per iteration). Our approach enables us to predict individualpreferences in large datasets, and is considerably more accurate than thecurrent algorithms for such large datasets.
arxiv-1604-01351 | Nonparametric Detection of Geometric Structures over Networks |  http://arxiv.org/abs/1604.01351  | author:Shaofeng Zou, Yingbin Liang, H. Vincent Poor category:stat.ML published:2016-04-05 summary:Nonparametric detection of existence of an anomalous structure over a networkis investigated. Nodes corresponding to the anomalous structure (if one exists)receive samples generated by a distribution q, which is different from adistribution p generating samples for other nodes. If an anomalous structuredoes not exist, all nodes receive samples generated by p. It is assumed thatthe distributions p and q are arbitrary and unknown. The goal is to designstatistically consistent tests with probability of errors converging to zero asthe network size becomes asymptotically large. Kernel-based tests are proposedbased on maximum mean discrepancy that measures the distance between meanembeddings of distributions into a reproducing kernel Hilbert space. Detectionof an anomalous interval over a line network is first studied. Sufficientconditions on minimum and maximum sizes of candidate anomalous intervals arecharacterized in order to guarantee the proposed test to be consistent. It isalso shown that certain necessary conditions must hold to guarantee any test tobe universally consistent. Comparison of sufficient and necessary conditionsyields that the proposed test is order-level optimal and nearly optimalrespectively in terms of minimum and maximum sizes of candidate anomalousintervals. Generalization of the results to other networks is furtherdeveloped. Numerical results are provided to demonstrate the performance of theproposed tests.
arxiv-1604-01171 | Restricted Isometry Constants for Gaussian and Rademacher matrices |  http://arxiv.org/abs/1604.01171  | author:Sandrine Dallaporta, Yohann de Castro category:math.ST cs.IT math.IT math.PR stat.ML stat.TH published:2016-04-05 summary:Restricted Isometry Constants (RICs) are a pivotal notion in CompressedSensing (CS) as these constants finely assess how a linear operator isconditioned on the set of sparse vectors and hence how it performs in stableand robust sparse regression (SRSR). While it is an open problem to constructdeterministic matrices with apposite RICs, one can prove that such matricesexist using random matrices models. One of the most popular model may be thesub-Gaussian matrices since it encompasses random matrices with Gaussian orRademacher i.i.d. entries. In this paper, we provide a description of the phasetransition on SRSR for those matrices using state-of-the-art (small) deviationestimates on their extreme eigenvalues. In particular, we show new upper boundson RICs for Gaussian and Rademacher matrices. This allows us to derive a newlower bound on the probability of getting SRSR. One of the benefit of thisnovel approach is to broaden the scope of phase transition on RICs and SRSR tothe quest of universality results in Random Matrix Theory.
arxiv-1604-01146 | Less is more: zero-shot learning from online textual documents with noise suppression |  http://arxiv.org/abs/1604.01146  | author:Ruizhi Qiao, Lingqiao Liu, Chunhua Shen, Anton van den Hengel category:cs.CV published:2016-04-05 summary:Classifying a visual concept merely from its associated online textualsource, such as a Wikipedia article, is an attractive research topic inzero-shot learning because it alleviates the burden of manually collectingsemantic attributes. Several recent works have pursued this approach byexploring various ways of connecting the visual and text domains. This paperrevisits this idea by stepping further to consider one important factor: thetextual representation is usually too noisy for the zero-shot learningapplication. This consideration motivates us to design a simple-but-effectivezero-shot learning method capable of suppressing noise in the text. More specifically, we propose an $l_{2,1}$-norm based objective functionwhich can simultaneously suppress the noisy signal in the text and learn afunction to match the text document and visual features. We also develop anoptimization algorithm to efficiently solve the resulting problem. Byconducting experiments on two large datasets, we demonstrate that the proposedmethod significantly outperforms the competing methods which rely on onlineinformation sources but without explicit noise suppression. We further make anin-depth analysis of the proposed method and provide insight as to what kind ofinformation in documents is useful for zero-shot learning.
arxiv-1604-01431 | A Game-Theoretic Approach to Multi-Pedestrian Activity Forecasting |  http://arxiv.org/abs/1604.01431  | author:Wei-Chiu Ma, De-An Huang, Namhoon Lee, Kris M. Kitani category:cs.CV published:2016-04-05 summary:We develop predictive models of pedestrian dynamics by encoding the couplednature of multi-pedestrian interaction using game theory, and deeplearning-based visual analysis to estimate person-specific behavior parameters.Building predictive models for multi-pedestrian interactions however, is verychallenging due to two reasons: (1) the dynamics of interaction are complexinterdependent processes, where the predicted behavior of one pedestrian canaffect the actions taken by others and (2) dynamics are variable depending onan individuals physical characteristics (e.g., an older person may walk slowlywhile the younger person may walk faster). To address these challenges, we (1)utilize concepts from game theory to model the interdependent decision makingprocess of multiple pedestrians and (2) use visual classifiers to learn amapping from pedestrian appearance to behavior parameters. We evaluate ourproposed model on several public multiple pedestrian interaction videodatasets. Results show that our strategic planning model explains humaninteractions 25% better when compared to state-of-the-art methods.
arxiv-1604-01109 | Counting Grid Aggregation for Event Retrieval and Recognition |  http://arxiv.org/abs/1604.01109  | author:Zhanning Gao, Gang Hua, Dongqing Zhang, Jianru Xue, Nanning Zheng category:cs.CV published:2016-04-05 summary:Event retrieval and recognition in a large corpus of videos necessitates aholistic fixed-size visual representation at the video clip level that iscomprehensive, compact, and yet discriminative. It shall comprehensivelyaggregate information across relevant video frames, while suppress redundantinformation, leading to a compact representation that can effectivelydifferentiate among different visual events. In search for such arepresentation, we propose to build a spatially consistent counting grid modelto aggregate together deep features extracted from different video frames. Thespatial consistency of the counting grid model is achieved by introducing aprior model estimated from a large corpus of video data. The counting gridmodel produces an intermediate tensor representation for each video, whichautomatically identifies and removes the feature redundancy across thedifferent frames. The tensor representation is subsequently reduced to afixed-size vector representation by averaging over the counting grid. Whencompared to existing methods on both event retrieval and event classificationbenchmarks, we achieve significantly better accuracy with much more compactrepresentation.
arxiv-1604-01093 | BundleFusion: Real-time Globally Consistent 3D Reconstruction using On-the-fly Surface Re-integration |  http://arxiv.org/abs/1604.01093  | author:Angela Dai, Matthias Nießner, Michael Zollhöfer, Shahram Izadi, Christian Theobalt category:cs.GR cs.CV published:2016-04-05 summary:Real-time, high-quality, 3D scanning of large-scale scenes is key to mixedreality and robotic applications. However, scalability brings challenges ofdrift in pose estimation, introducing significant errors in the accumulatedmodel. Approaches often require hours of offline processing to globally correctmodel errors. Recent online methods demonstrate compelling results, but sufferfrom: (1) needing minutes to perform online correction preventing truereal-time use; (2) brittle frame-to-frame (or frame-to-model) pose estimationresulting in many tracking failures; or (3) supporting only unstructuredpoint-based representations, which limit scan quality and applicability. Wesystematically address these issues with a novel, real-time, end-to-endreconstruction framework. At its core is a robust pose estimation strategy,optimizing per frame for a global set of camera poses by considering thecomplete history of RGB-D input with an efficient hierarchical approach. Weremove the heavy reliance on temporal tracking, and continually localize to theglobally optimized frames instead. We contribute a parallelizable optimizationframework, which employs correspondences based on sparse features and densegeometric and photometric matching. Our approach estimates globally optimized(i.e., bundle adjusted) poses in real-time, supports robust tracking withrecovery from gross tracking failures (i.e., relocalization), and re-estimatesthe 3D model in real-time to ensure global consistency; all within a singleframework. Our approach outperforms state-of-the-art online systems withquality on par to offline methods, but with unprecedented speed and scancompleteness. Our framework leads to a comprehensive online scanning solutionfor large indoor environments, enabling ease of use and high-quality results.
arxiv-1604-01278 | RIGA at SemEval-2016 Task 8: Impact of Smatch Extensions and Character-Level Neural Translation on AMR Parsing Accuracy |  http://arxiv.org/abs/1604.01278  | author:Guntis Barzdins, Didzis Gosko category:cs.CL published:2016-04-05 summary:Two extensions to the AMR smatch scoring script are presented. The firstextension com-bines the smatch scoring script with the C6.0 rule-basedclassifier to produce a human-readable report on the error patterns frequencyobserved in the scored AMR graphs. This first extension results in 4% gain overthe state-of-art CAMR baseline parser by adding to it a manually craftedwrapper fixing the identified CAMR parser errors. The second extension combinesa per-sentence smatch with an en-semble method for selecting the best AMR graphamong the set of AMR graphs for the same sentence. This second modificationau-tomatically yields further 0.4% gain when ap-plied to outputs of twonondeterministic AMR parsers: a CAMR+wrapper parser and a novel character-levelneural translation AMR parser. For AMR parsing task the character-level neuraltranslation attains surprising 7% gain over the carefully optimized word-levelneural translation. Overall, we achieve smatch F1=62% on the SemEval-2016official scor-ing set and F1=67% on the LDC2015E86 test set.
arxiv-1604-01304 | Towards Label Imbalance in Multi-label Classification with Many Labels |  http://arxiv.org/abs/1604.01304  | author:Li Li, Houfeng Wang category:cs.LG published:2016-04-05 summary:In multi-label classification, an instance may be associated with a set oflabels simultaneously. Recently, the research on multi-label classification haslargely shifted its focus to the other end of the spectrum where the number oflabels is assumed to be extremely large. The existing works focus on how todesign scalable algorithms that offer fast training procedures and have a smallmemory footprint. However they ignore and even compound another challenge - thelabel imbalance problem. To address this drawback, we propose a novelRepresentation-based Multi-label Learning with Sampling (RMLS) approach. To thebest of our knowledge, we are the first to tackle the imbalance problem inmulti-label classification with many labels. Our experimentations withreal-world datasets demonstrate the effectiveness of the proposed approach.
arxiv-1604-01319 | Cohomology of Cryo-Electron Microscopy |  http://arxiv.org/abs/1604.01319  | author:Ke Ye, Lek-Heng Lim category:cs.CV math.AT published:2016-04-05 summary:The goal of cryo-electron microscopy (EM) is to reconstruct the 3-dimensionalstructure of a molecule from a collection of its 2-dimensional projectedimages. In this article, we show that the basic premise of cryo-EM --- patchingtogether 2-dimensional projections to reconstruct a 3-dimensional object --- isnaturally one of Cech cohomology with SO(2)-coefficients. We deduce that everycryo-EM reconstruction problem corresponds to an oriented circle bundle on asimplicial complex, allowing us to classify cryo-EM problems via principalbundles. In practice, the 2-dimensional images are noisy and a main task incryo-EM is to denoise them. We will see how the aforementioned insights can beused towards this end.
arxiv-1604-01345 | Discovering Perceptual Attributes in a Deep Local Material Recognition Network |  http://arxiv.org/abs/1604.01345  | author:Gabriel Schwartz, Ko Nishino category:cs.CV published:2016-04-05 summary:Perceptual material attributes, intrinsic visual properties of materials, arebeing studied in parallel in computer vision and human vision. In neuroscience,perceptual attributes are shown to be an integral part of the human neuralresponse during material recognition. In computer vision, however, they aremerely an intermediate representation of materials and not integrated into therecognition process. In this paper, we show that perceptual material attributescan indeed be found inside a framework for local, patch-based,object-independent material recognition. We introduce a new CNN architecture,the material attribute-category CNN (MAC-CNN), that uses deep weak supervisionto simultaneously classify materials and discover per-pixel perceptualattributes. We show that these attributes conform with past semantic materialattributes and enhance recognition of novel materials. We also introduce anextensive new database for local material recognition. Our results show thatthe internal representation of the MAC-CNN generalizes well and agrees withhuman perception, which has potential implications for our understanding ofhuman material perception as well as applications in object recognition.
arxiv-1604-01325 | Deep Image Retrieval: Learning global representations for image search |  http://arxiv.org/abs/1604.01325  | author:Albert Gordo, Jon Almazan, Jerome Revaud, Diane Larlus category:cs.CV published:2016-04-05 summary:We propose a novel approach for instance-level image retrieval. It produces aglobal and compact fixed-length representation for each image by aggregatingmany region-wise descriptors. In contrast to previous works employingpre-trained deep networks as a black box to produce features, our methodleverages a deep architecture trained for the specific task of image retrieval.Our contribution is twofold: (i) we introduce a ranking framework to learnconvolution and projection weights that are used to build the region features;and (ii) we employ a region proposal network to learn which regions should bepooled to form the final global descriptor. We show that using clean trainingdata is key to the success of our approach. To that aim, we leverage a largescale but noisy landmark dataset and develop an automatic cleaning approach.The proposed architecture produces a global image representation in a singleforward pass. Our approach significantly outperforms previous approaches basedon global descriptors on standard datasets. It even surpasses most prior worksbased on costly local descriptor indexing and spatial verification. We intendto release our pre-trained model.
arxiv-1604-01360 | The Curious Robot: Learning Visual Representations via Physical Interactions |  http://arxiv.org/abs/1604.01360  | author:Lerrel Pinto, Dhiraj Gandhi, Yuanfeng Han, Yong-Lae Park, Abhinav Gupta category:cs.CV cs.AI cs.RO published:2016-04-05 summary:What is the right supervisory signal to train visual representations? Currentapproaches in computer vision use category labels from datasets such asImageNet to train ConvNets. However, in case of biological agents, visualrepresentation learning does not require semantic labels. In fact, we arguethat biological agents use active exploration and physical interactions withthe world to learn visual representations unlike current vision systems whichjust use passive observations (images and videos downloaded from web). Forexample, babies push objects, poke them, put them in their mouth and throw themto learn representations. Towards this goal, we build one of the first systemson a Baxter platform that pushes, pokes, grasps and actively observes objectsin a tabletop environment. It uses four different types of physicalinteractions to collect more than 130K datapoints, with each datapointproviding backprops to a shared ConvNet architecture allowing us to learnvisual representations. We show the quality of learned representations byobserving neuron activations and performing nearest neighbor retrieval on thislearned representation. Finally, we evaluate our learned ConvNet on differentimage classification tasks and show improvements compared to learning withoutexternal data.
arxiv-1604-01252 | Comparative Deep Learning of Hybrid Representations for Image Recommendations |  http://arxiv.org/abs/1604.01252  | author:Chenyi Lei, Dong Liu, Weiping Li, Zheng-Jun Zha, Houqiang Li category:cs.CV published:2016-04-05 summary:In many image-related tasks, learning expressive and discriminativerepresentations of images is essential, and deep learning has been studied forautomating the learning of such representations. Some user-centric tasks, suchas image recommendations, call for effective representations of not only imagesbut also preferences and intents of users over images. Such representations aretermed \emph{hybrid} and addressed via a deep learning approach in this paper.We design a dual-net deep network, in which the two sub-networks map inputimages and preferences of users into a same latent semantic space, and then thedistances between images and users in the latent space are calculated to makedecisions. We further propose a comparative deep learning (CDL) method to trainthe deep network, using a pair of images compared against one user to learn thepattern of their relative distances. The CDL embraces much more training datathan naive deep learning, and thus achieves superior performance than thelatter, with no cost of increasing network complexity. Experimental resultswith real-world data sets for image recommendations have shown the proposeddual-net network and CDL greatly outperform other state-of-the-art imagerecommendation solutions.
arxiv-1604-01357 | Heavy hitters via cluster-preserving clustering |  http://arxiv.org/abs/1604.01357  | author:Kasper Green Larsen, Jelani Nelson, Huy L. Nguyen, Mikkel Thorup category:cs.DS cs.LG published:2016-04-05 summary:In turnstile $\ell_p$ $\varepsilon$-heavy hitters, one maintains ahigh-dimensional $x\in\mathbb{R}^n$ subject to $\texttt{update}(i,\Delta)$causing $x_i\leftarrow x_i + \Delta$, where $i\in[n]$, $\Delta\in\mathbb{R}$.Upon receiving a query, the goal is to report a small list $L\subset[n]$, $L= O(1/\varepsilon^p)$, containing every "heavy hitter" $i\in[n]$ with $x_i\ge \varepsilon \x_{\overline{1/\varepsilon^p}}\_p$, where $x_{\overline{k}}$denotes the vector obtained by zeroing out the largest $k$ entries of $x$ inmagnitude. For any $p\in(0,2]$ the CountSketch solves $\ell_p$ heavy hitters using$O(\varepsilon^{-p}\log n)$ words of space with $O(\log n)$ update time,$O(n\log n)$ query time to output $L$, and whose output after any query iscorrect with high probability (whp) $1 - 1/poly(n)$. Unfortunately the querytime is very slow. To remedy this, the work [CM05] proposed for $p=1$ in thestrict turnstile model, a whp correct algorithm achieving suboptimal space$O(\varepsilon^{-1}\log^2 n)$, worse update time $O(\log^2 n)$, but much betterquery time $O(\varepsilon^{-1}poly(\log n))$. We show this tradeoff between space and update time versus query time isunnecessary. We provide a new algorithm, ExpanderSketch, which in the mostgeneral turnstile model achieves optimal $O(\varepsilon^{-p}\log n)$ space,$O(\log n)$ update time, and fast $O(\varepsilon^{-p}poly(\log n))$ query time,and whp correctness. Our main innovation is an efficient reduction from theheavy hitters to a clustering problem in which each heavy hitter is encoded assome form of noisy spectral cluster in a much bigger graph, and the goal is toidentify every cluster. Since every heavy hitter must be found, correctnessrequires that every cluster be found. We then develop a "cluster-preservingclustering" algorithm, partitioning the graph into clusters without destroyingany original cluster.
arxiv-1604-01354 | Radiometric Scene Decomposition: Scene Reflectance, Illumination, and Geometry from RGB-D Images |  http://arxiv.org/abs/1604.01354  | author:Stephen Lombardi, Ko Nishino category:cs.CV published:2016-04-05 summary:Recovering the radiometric properties of a scene (i.e., the reflectance,illumination, and geometry) is a long-sought ability of computer vision thatcan provide invaluable information for a wide range of applications.Deciphering the radiometric ingredients from the appearance of a real-worldscene, as opposed to a single isolated object, is particularly challenging asit generally consists of various objects with different material compositionsexhibiting complex reflectance and light interactions that are also part of theillumination. We introduce the first method for radiometric scene decompositionthat handles those intricacies. We use RGB-D images to bootstrap geometryrecovery and simultaneously recover the complex reflectance and naturalillumination while refining the noisy initial geometry and segmenting the sceneinto different material regions. Most important, we handle real-world scenesconsisting of multiple objects of unknown materials, which necessitates themodeling of spatially-varying complex reflectance, natural illumination,texture, interreflection and shadows. We systematically evaluate theeffectiveness of our method on synthetic scenes and demonstrate its applicationto real-world scenes. The results show that rich radiometric information can berecovered from RGB-D images and demonstrate a new role RGB-D sensors can playfor general scene understanding tasks.
arxiv-1604-01335 | Deep Cross Residual Learning for Multitask Visual Recognition |  http://arxiv.org/abs/1604.01335  | author:Brendan Jou, Shih-Fu Chang category:cs.CV cs.AI cs.MM published:2016-04-05 summary:Residual learning has recently surfaced as an effective means of constructingvery deep neural networks for object recognition. However, current incarnationsof residual networks do not allow for the modeling and integration of complexrelations between closely coupled recognition tasks or across domains. Suchproblems are often encountered in multimedia and vision applications involvinglarge-scale content recognition. We propose a novel extension of residuallearning for deep networks that enables intuitive learning across multiplerelated tasks using cross-connections called cross-residuals. Thesecross-residuals connections can be viewed as a form of in-networkregularization and enables greater network generalization. We show howcross-residual learning (CRL) can be integrated in multitask networks tojointly train and detect visual concepts across several tasks. We present asingle multitask cross-residual network with >40% less parameters that is ableto achieve competitive, or even better, detection performance on a visualsentiment concept detection problem normally requiring multiple specializedsingle-task networks. The resulting multitask cross-residual network alsoachieves better detection performance by about 10.4% over a standard multitaskresidual network without cross-residuals with even a small amount of cross-taskweighting.
arxiv-1604-00990 | Direct Visual Odometry using Bit-Planes |  http://arxiv.org/abs/1604.00990  | author:Hatem Alismail, Brett Browning, Simon Lucey category:cs.RO cs.CV published:2016-04-04 summary:Feature descriptors, such as SIFT and ORB, are well-known for theirrobustness to illumination changes, which has made them popular forfeature-based VSLAM\@. However, in degraded imaging conditions such as lowlight, low texture, blur and specular reflections, feature extraction is oftenunreliable. In contrast, direct VSLAM methods which estimate the camera pose byminimizing the photometric error using raw pixel intensities are often morerobust to low textured environments and blur. Nonetheless, at the core ofdirect VSLAM is the reliance on a consistent photometric appearance acrossimages, otherwise known as the brightness constancy assumption. Unfortunately,brightness constancy seldom holds in real world applications. In this work, we overcome brightness constancy by incorporating featuredescriptors into a direct visual odometry framework. This combination resultsin an efficient algorithm that combines the strength of both feature-basedalgorithms and direct methods. Namely, we achieve robustness to arbitraryphotometric variations while operating in low-textured and poorly litenvironments. Our approach utilizes an efficient binary descriptor, which wecall Bit-Planes, and show how it can be used in the gradient-based optimizationrequired by direct methods. Moreover, we show that the squared Euclideandistance between Bit-Planes is equivalent to the Hamming distance. Hence, thedescriptor may be used in least squares optimization without sacrificing itsphotometric invariance. Finally, we present empirical results that demonstratethe robustness of the approach in poorly lit underground environments.
arxiv-1604-00825 | Layer-wise Relevance Propagation for Neural Networks with Local Renormalization Layers |  http://arxiv.org/abs/1604.00825  | author:Alexander Binder, Grégoire Montavon, Sebastian Bach, Klaus-Robert Müller, Wojciech Samek category:cs.CV published:2016-04-04 summary:Layer-wise relevance propagation is a framework which allows to decompose theprediction of a deep neural network computed over a sample, e.g. an image, downto relevance scores for the single input dimensions of the sample such assubpixels of an image. While this approach can be applied directly togeneralized linear mappings, product type non-linearities are not covered. Thispaper proposes an approach to extend layer-wise relevance propagation to neuralnetworks with local renormalization layers, which is a very common product-typenon-linearity in convolutional neural networks. We evaluate the proposed methodfor local renormalization layers on the CIFAR-10, Imagenet and MIT Placesdatasets.
arxiv-1604-00790 | Image Captioning with Deep Bidirectional LSTMs |  http://arxiv.org/abs/1604.00790  | author:Cheng Wang, Haojin Yang, Christian Bartz, Christoph Meinel category:cs.CV cs.CL cs.MM published:2016-04-04 summary:This work presents an end-to-end trainable deep bidirectional LSTM(Long-Short Term Memory) model for image captioning. Our model builds on a deepconvolutional neural network (CNN) and two separate LSTM networks. It iscapable of learning long term visual-language interactions by making use ofhistory and future context information at high level semantic space. Two noveldeep bidirectional variant models, in which we increase the depth ofnonlinearity transition in different way, are proposed to learn hierarchicalvisual-language embeddings. Data augmentation techniques such as multi-crop,multi-scale and vertical mirror are proposed to prevent overfitting in trainingdeep models. We visualize the evolution of bidirectional LSTM internal statesover time and qualitatively analyze how our models "translate" image tosentence. Our proposed models are evaluated on caption generation andimage-sentence retrieval tasks with three benchmark datasets: Flickr8K,Flickr30K and MSCOCO datasets. We demonstrate that bidirectional LSTM modelsachieve highly competitive performance to the state-of-the-art results oncaption generation even without integrating additional mechanism (e.g. objectdetection, attention model etc.) and significantly outperform recent methods onretrieval task.
arxiv-1604-00989 | Clustering Millions of Faces by Identity |  http://arxiv.org/abs/1604.00989  | author:Charles Otto, Dayong Wang, Anil K. Jain category:cs.CV published:2016-04-04 summary:In this work, we attempt to address the following problem: Given a largenumber of unlabeled face images, cluster them into the individual identitiespresent in this data. We consider this a relevant problem in differentapplication scenarios ranging from social media to law enforcement. Inlarge-scale scenarios the number of faces in the collection can be of the orderof hundreds of million, while the number of clusters can range from a fewthousand to millions--leading to difficulties in terms of both run-timecomplexity and evaluating clustering and per-cluster quality. An efficient andeffective Rank-Order clustering algorithm is developed to achieve the desiredscalability, and better clustering accuracy than other well-known algorithmssuch as k-means and spectral clustering. We cluster up to 123 million faceimages into over 10 million clusters, and analyze the results in terms of bothexternal cluster quality measures (known face labels) and internal clusterquality measures (unknown face labels) and run-time. Our algorithm achieves anF-measure of 0.87 on a benchmark unconstrained face dataset (LFW, consisting of13K faces), and 0.27 on the largest dataset considered (13K images in LFW, plus123M distractor images). Additionally, we present preliminary work on videoframe clustering (achieving 0.71 F-measure when clustering all frames in thebenchmark YouTube Faces dataset). A per-cluster quality measure is developedwhich can be used to rank individual clusters and to automatically identify asubset of good quality clusters for manual exploration.
arxiv-1604-01088 | Optimal Parameter Settings for the $(1+(λ, λ))$ Genetic Algorithm |  http://arxiv.org/abs/1604.01088  | author:Benjamin Doerr category:cs.NE cs.DS published:2016-04-04 summary:The $(1+(\lambda,\lambda))$ genetic algorithm is one of the few algorithmsfor which a super-constant speed-up through the use of crossover could beproven. So far, this algorithm has been used with parameters based also onintuitive considerations. In this work, we rigorously regard the wholeparameter space and show that the asymptotic time complexity proven by Doerrand Doerr (GECCO 2015) for the intuitive choice is best possible among allsettings for population size, mutation probability, and crossover bias.
arxiv-1604-00974 | Writer-independent Feature Learning for Offline Signature Verification using Deep Convolutional Neural Networks |  http://arxiv.org/abs/1604.00974  | author:Luiz G. Hafemann, Robert Sabourin, Luiz S. Oliveira category:cs.CV stat.ML published:2016-04-04 summary:Automatic Offline Handwritten Signature Verification has been researched overthe last few decades from several perspectives, using insights from graphology,computer vision, signal processing, among others. In spite of the advancementson the field, building classifiers that can separate between genuine signaturesand skilled forgeries (forgeries made targeting a particular signature) isstill hard. We propose approaching the problem from a feature learningperspective. Our hypothesis is that, in the absence of a good model of the datageneration process, it is better to learn the features from data, instead ofusing hand-crafted features that have no resemblance to the signaturegeneration process. To this end, we use Deep Convolutional Neural Networks tolearn features in a writer-independent format, and use this model to obtain afeature representation on another set of users, where we train writer-dependentclassifiers. We tested our method in two datasets: GPDS-960 and BrazilianPUC-PR. Our experimental results show that the features learned in a subset ofthe users are discriminative for the other users, including across differentdatasets, reaching close to the state-of-the-art in the GPDS dataset, andimproving the state-of-the-art in the Brazilian PUC-PR dataset.
arxiv-1604-00938 | Multi-Field Structural Decomposition for Question Answering |  http://arxiv.org/abs/1604.00938  | author:Tomasz Jurczyk, Jinho D. Choi category:cs.CL published:2016-04-04 summary:This paper presents a precursory yet novel approach to the question answeringtask using structural decomposition. Our system first generates linguisticstructures such as syntactic and semantic trees from text, decomposes them intomultiple fields, then indexes the terms in each field. For each question, itdecomposes the question into multiple fields, measures the relevance score ofeach field to the indexed ones, then ranks all documents by their relevancescores and weights associated with the fields, where the weights are learnedthrough statistical modeling. Our final model gives an absolute improvement ofover 40% to the baseline approach using simple search for detecting documentscontaining answers.
arxiv-1604-00788 | Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models |  http://arxiv.org/abs/1604.00788  | author:Minh-Thang Luong, Christopher D. Manning category:cs.CL cs.LG published:2016-04-04 summary:Nearly all previous work in neural machine translation (NMT) has used quiterestricted vocabularies, perhaps with a subsequent method to patch in unknownwords. This paper presents a novel word-character solution to achieving openvocabulary NMT. We build hybrid systems that translate mostly at the word leveland consult the character components for rare words. Our character-levelrecurrent neural networks compute source word representations and recoverunknown target words when needed. The two-fold advantage of such a hybridapproach is that it is much faster and easier to train than character-basedones; at the same time, it never produces unknown words as in the case ofword-based models. On the WMT'15 English to Czech translation task, this hybridapproach offers a boost of up to +7.9 BLEU points over models that do nothandle unknown words. Our best hybrid system has established a newstate-of-the-art result with 19.9 BLEU score. We demonstrate that our charactermodels can successfully learn to not only generate well-formed words for Czech,a highly-inflected language with a very complex vocabulary, but also buildcorrect representations for English source words.
arxiv-1604-00730 | Waterdrop Stereo |  http://arxiv.org/abs/1604.00730  | author:Shaodi You, Robby T. Tan, Rei Kawakami, Yasuhiro Mukaigawa, Katsushi Ikeuchi category:cs.CV published:2016-04-04 summary:This paper introduces depth estimation from water drops. The key idea is thata single water drop adhered to window glass is totally transparent and convex,and thus optically acts like a fisheye lens. If we have more than one waterdrop in a single image, then through each of them we can see the environmentwith different view points, similar to stereo. To realize this idea, we need torectify every water drop imagery to make radially distorted planar surfaceslook flat. For this rectification, we consider two physical properties of waterdrops: (1) A static water drop has constant volume, and its geometric convexshape is determined by the balance between the tension force and gravity. Thisimplies that the 3D geometric shape can be obtained by minimizing the overallpotential energy, which is the sum of the tension energy and the gravitationalpotential energy. (2) The imagery inside a water-drop is determined by thewater-drop 3D shape and total reflection at the boundary. This total reflectiongenerates a dark band commonly observed in any adherent water drops. Hence,once the 3D shape of water drops are recovered, we can rectify the water dropimages through backward raytracing. Subsequently, we can compute depth usingstereo. In addition to depth estimation, we can also apply image refocusing.Experiments on real images and a quantitative evaluation show the effectivenessof our proposed method. To our best knowledge, never before have adherent waterdrops been used to estimate depth.
arxiv-1604-00933 | Entity Type Recognition using an Ensemble of Distributional Semantic Models to Enhance Query Understanding |  http://arxiv.org/abs/1604.00933  | author:Walid Shalaby, Khalifeh Al Jadda, Mohammed Korayem, Trey Grainger category:cs.CL cs.IR published:2016-04-04 summary:We present an ensemble approach for categorizing search query entities in therecruitment domain. Understanding the types of entities expressed in a searchquery (Company, Skill, Job Title, etc.) enables more intelligent informationretrieval based upon those entities compared to a traditional keyword-basedsearch. Because search queries are typically very short, leveraging atraditional bag-of-words model to identify entity types would be inappropriatedue to the lack of contextual information. Our approach instead combines cluesfrom different sources of varying complexity in order to collect real-worldknowledge about query entities. We employ distributional semanticrepresentations of query entities through two models: 1) contextual vectorsgenerated from encyclopedic corpora like Wikipedia, and 2) high dimensionalword embedding vectors generated from millions of job postings using word2vec.Additionally, our approach utilizes both entity linguistic properties obtainedfrom WordNet and ontological properties extracted from DBpedia. We evaluate ourapproach on a data set created at CareerBuilder; the largest job board in theUS. The data set contains entities extracted from millions of jobseekers/recruiters search queries, job postings, and resume documents. Afterconstructing the distributional vectors of search entities, we use supervisedmachine learning to infer search entity types. Empirical results show that ourapproach outperforms the state-of-the-art word2vec distributional semanticsmodel trained on Wikipedia. Moreover, we achieve micro-averaged F 1 score of97% using the proposed distributional representations ensemble.
arxiv-1604-00734 | Capturing Semantic Similarity for Entity Linking with Convolutional Neural Networks |  http://arxiv.org/abs/1604.00734  | author:Matthew Francis-Landau, Greg Durrett, Dan Klein category:cs.CL published:2016-04-04 summary:A key challenge in entity linking is making effective use of contextualinformation to disambiguate mentions that might refer to different entities indifferent contexts. We present a model that uses convolutional neural networksto capture semantic correspondence between a mention's context and a proposedtarget entity. These convolutional networks operate at multiple granularitiesto exploit various kinds of topic information, and their rich parameterizationgives them the capacity to learn which n-grams characterize different topics.We combine these networks with a sparse linear model to achievestate-of-the-art performance on multiple entity linking datasets, outperformingthe prior systems of Durrett and Klein (2014) and Nguyen et al. (2014).
arxiv-1604-00772 | The CMA Evolution Strategy: A Tutorial |  http://arxiv.org/abs/1604.00772  | author:Nikolaus Hansen category:cs.LG stat.ML published:2016-04-04 summary:This tutorial introduces the CMA Evolution Strategy (ES), where CMA standsfor Covariance Matrix Adaptation. The CMA-ES is a stochastic, or randomized,method for real-parameter (continuous domain) optimization of non-linear,non-convex functions. We try to motivate and derive the algorithm fromintuitive concepts and from requirements of non-linear, non-convex search incontinuous domain.
arxiv-1604-00783 | Topic Model Based Multi-Label Classification from the Crowd |  http://arxiv.org/abs/1604.00783  | author:Divya Padmanabhan, Satyanath Bhat, Shirish Shevade, Y. Narahari category:cs.LG published:2016-04-04 summary:Multi-label classification is a common supervised machine learning problemwhere each instance is associated with multiple classes. The key challenge inthis problem is learning the correlations between the classes. An additionalchallenge arises when the labels of the training instances are provided bynoisy, heterogeneous crowdworkers with unknown qualities. We first assumelabels from a perfect source and propose a novel topic model where the presentas well as the absent classes generate the latent topics and hence the words.We non-trivially extend our topic model to the scenario where the labels areprovided by noisy crowdworkers. Extensive experimentation on real worlddatasets reveals the superior performance of the proposed model. The proposedmodel learns the qualities of the annotators as well, even with minimaltraining data.
arxiv-1604-00834 | In narrative texts punctuation marks obey the same statistics as words |  http://arxiv.org/abs/1604.00834  | author:Andrzej Kulig, Jaroslaw Kwapien, Tomasz Stanisz, Stanislaw Drozdz category:cs.CL published:2016-04-04 summary:From a grammar point of view, the role of punctuation marks in a sentence isformally defined and well understood. In semantic analysis punctuation playsalso a crucial role as a method of avoiding ambiguity of the meaning. Adifferent situation can be observed in the statistical analyses of languagesamples, where the decision on whether the punctuation marks should beconsidered or should be neglected is seen rather as arbitrary and at present itbelongs to a researcher's preference. An objective of this work is to shed somelight onto this problem by providing us with an answer to the question whetherthe punctuation marks may be treated as ordinary words and whether they shouldbe included in any analysis of the word co-occurences. We already know from ourprevious study \cite{drozdz2016} that full stops that determine the length ofsentences are the main carrier of long-range correlations. Now we extend thatstudy and analyze statistical properties of the most common punctuation marksin a few Indo-European languages, investigate their frequencies, and locatethem accordingly in the Zipf rank-frequency plots as well as study their rolein the word-adjacency networks. We show that, from a statistical viewpoint, thepunctuation marks reveal properties that are qualitatively similar to theproperties of the most frequent words like articles, conjunctions, pronouns,and prepositions. This refers to both the Zipfian analysis and the networkanalysis. Our results can be exploited in the computer-based analyses of largetext corpora and be incorporated in the related automated systems. As a sideresult, we propose an efficient method of sampling the language corpora for aword-adjacency network analysis.
arxiv-1604-01376 | Lipschitz Continuity of Mahalanobis Distances and Bilinear Forms |  http://arxiv.org/abs/1604.01376  | author:Valentina Zantedeschi, Rémi Emonet, Marc Sebban category:cs.NA cs.LG published:2016-04-04 summary:Many theoretical results in the machine learning domain stand only forfunctions that are Lipschitz continuous. Lipschitz continuity is a strong formof continuity that linearly bounds the variations of a function. In this paper,we derive tight Lipschitz constants for two families of metrics: Mahalanobisdistances and bounded-space bilinear forms. To our knowledge, this is the firsttime the Mahalanobis distance is formally proved to be Lipschitz continuous andthat such tight Lipschitz constants are derived.
arxiv-1604-00923 | Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning |  http://arxiv.org/abs/1604.00923  | author:Philip S. Thomas, Emma Brunskill category:cs.LG cs.AI published:2016-04-04 summary:In this paper we present a new way of predicting the performance of areinforcement learning policy given historical data that may have beengenerated by a different policy. The ability to evaluate a policy fromhistorical data is important for applications where the deployment of a badpolicy can be dangerous or costly. We show empirically that our algorithmproduces estimates that often have orders of magnitude lower mean squared errorthan existing methods---it makes more efficient use of the available data. Ournew estimator is based on two advances: an extension of the doubly robustestimator (Jiang and Li, 2015), and a new way to mix between model basedestimates and importance sampling based estimates.
arxiv-1604-00895 | HDRFusion: HDR SLAM using a low-cost auto-exposure RGB-D sensor |  http://arxiv.org/abs/1604.00895  | author:Shuda Li, Ankur Handa, Yang Zhang, Andrew Calway category:cs.CV published:2016-04-04 summary:We describe a new method for comparing frame appearance in a frame-to-model3-D mapping and tracking system using an low dynamic range (LDR) RGB-D camerawhich is robust to brightness changes caused by auto exposure. It is based on anormalised radiance measure which is invariant to exposure changes and not onlyrobustifies the tracking under changing lighting conditions, but also enablesthe following exposure compensation perform accurately to allow online buildingof high dynamic range (HDR) maps. The latter facilitates the frame-to-modeltracking to minimise drift as well as better capturing light variation withinthe scene. Results from experiments with synthetic and real data demonstratethat the method provides both improved tracking and maps with far greaterdynamic range of luminosity.
arxiv-1604-00861 | Recurrent Neural Networks for Polyphonic Sound Event Detection in Real Life Recordings |  http://arxiv.org/abs/1604.00861  | author:Giambattista Parascandolo, Heikki Huttunen, Tuomas Virtanen category:cs.SD cs.LG cs.NE published:2016-04-04 summary:In this paper we present an approach to polyphonic sound event detection inreal life recordings based on bi-directional long short term memory (BLSTM)recurrent neural networks (RNNs). A single multilabel BLSTM RNN is trained tomap acoustic features of a mixture signal consisting of sounds from multipleclasses, to binary activity indicators of each event class. Our method istested on a large database of real-life recordings, with 61 classes (e.g.music, car, speech) from 10 different everyday contexts. The proposed methodoutperforms previous approaches by a large margin, and the results are furtherimproved using data augmentation techniques. Overall, our system reports anaverage F1-score of 65.5% on 1 second blocks and 64.7% on single frames, arelative improvement over previous state-of-the-art approach of 6.8% and 15.1%respectively.
arxiv-1604-00906 | Detecting Engagement in Egocentric Video |  http://arxiv.org/abs/1604.00906  | author:Yu-Chuan Su, Kristen Grauman category:cs.CV published:2016-04-04 summary:In a wearable camera video, we see what the camera wearer sees. While thismakes it easy to know roughly what he chose to look at, it does not immediatelyreveal when he was engaged with the environment. Specifically, at what momentsdid his focus linger, as he paused to gather more information about somethinghe saw? Knowing this answer would benefit various applications in videosummarization and augmented reality, yet prior work focuses solely on the"what" question (estimating saliency, gaze) without considering the "when"(engagement). We propose a learning-based approach that uses long-termegomotion cues to detect engagement, specifically in browsing scenarios whereone frequently takes in new visual information (e.g., shopping, touring). Weintroduce a large, richly annotated dataset for ego-engagement that is thefirst of its kind. Our approach outperforms a wide array of existing methods.We show engagement can be detected well independent of both scene appearanceand the camera wearer's identity.
arxiv-1604-01075 | A Dynamic Bayesian Network Model for Inventory Level Estimation in Retail Marketing |  http://arxiv.org/abs/1604.01075  | author:Luis I. Reyes-Castro, Andres G. Abad category:stat.ML published:2016-04-04 summary:Many retailers today employ inventory management systems based on Re-OrderPoint Policies, most of which rely on the assumption that all decreases inproduct inventory levels result from product sales. Unfortunately, it usuallyhappens that small but random quantities of the product get lost, stolen orbroken without record as time passes, e.g., as a consequence of shoplifting.This is usual for retailers handling large varieties of inexpensive products,e.g., grocery stores. In turn, over time these discrepancies lead to stockfreezing problems, i.e., situations where the system believes the stock isabove the re-order point but the actual stock is at zero, and so noreplenishments or sales occur. Motivated by these issues, we model theinteraction between sales, losses, replenishments and inventory levels as aDynamic Bayesian Network (DBN), where the inventory levels are unobserved(i.e., hidden) variables we wish to estimate. We present anExpectation-Maximization (EM) algorithm to estimate the parameters of the saleand loss distributions, which relies on solving a one-dimensional dynamicprogram for the E-step and on solving two separate one-dimensional nonlinearprograms for the M-step.
arxiv-1604-00999 | RGBD Datasets: Past, Present and Future |  http://arxiv.org/abs/1604.00999  | author:Michael Firman category:cs.CV cs.RO published:2016-04-04 summary:Since the launch of the Microsoft Kinect, scores of RGBD datasets have beenreleased. These have propelled advances in areas from reconstruction to gesturerecognition. In this paper we explore the field, reviewing datasets acrosseight categories: semantics, object pose estimation, camera tracking, scenereconstruction, object tracking, human actions, faces and identification. Byextracting relevant information in each category we help researchers to findappropriate data for their needs, and we consider which datasets have succeededin driving computer vision forward and why. Finally, we examine the future of RGBD datasets. We identify key areas whichare currently underexplored, and suggest that future directions may includesynthetic data and dense reconstructions of static and dynamic scenes.
arxiv-1604-00727 | Character-Level Question Answering with Attention |  http://arxiv.org/abs/1604.00727  | author:David Golub, Xiaodong He category:cs.CL cs.AI cs.LG published:2016-04-04 summary:We show that an encoder-decoder framework can be successfully applied toquestion-answering with a structured knowledge base. In addition, we propose anew character-level modeling approach for this task, which we use to make ourmodel robust to unseen entities and predicates. We use our model forsingle-relation question answering, and demonstrate the effectiveness of ournovel approach on the SimpleQuestions dataset, where we improvestate-of-the-art accuracy by 2% for both Freebase2M and Freebase5M subsetsproposed. Importantly, we achieve these results even though our character-levelmodel has 16x less parameters than an equivalent word-embedding model, usessignificantly less training data than previous work which relies on dataaugmentation, and encounters only 1.18% of the entities seen during trainingwhen testing.
arxiv-1604-00981 | Revisiting Distributed Synchronous SGD |  http://arxiv.org/abs/1604.00981  | author:Jianmin Chen, Rajat Monga, Samy Bengio, Rafal Jozefowicz category:cs.LG cs.DC cs.NE published:2016-04-04 summary:The recent success of deep learning approaches for domains like speechrecognition (Hinton et al., 2012) and computer vision (Ioffe & Szegedy, 2015)stems from many algorithmic improvements but also from the fact that the sizeof available training data has grown significantly over the years, togetherwith the computing power, in terms of both CPUs and GPUs. While a single GPUoften provides algorithmic simplicity and speed up to a given scale of data andmodel, there exist an operating point where a distributed implementation oftraining algorithms for deep architectures becomes necessary. Previous works have been focusing on asynchronous SGD training, which workswell up to a few dozens of workers for some models. In this work, we show thatsynchronous SGD training, with the help of backup workers, can not only achievebetter accuracy, but also reach convergence faster with respect to wall time,i.e. use more workers more efficiently.
arxiv-1604-00600 | HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection |  http://arxiv.org/abs/1604.00600  | author:Tao Kong, Anbang Yao, Yurong Chen, Fuchun Sun category:cs.CV published:2016-04-03 summary:Almost all of the current top-performing object detection networks employregion proposals to guide the search for object instances. State-of-the-artregion proposal methods usually need several thousand proposals to get highrecall, thus hurting the detection efficiency. Although the latest RegionProposal Network method gets promising detection accuracy with several hundredproposals, it still struggles in small-size object detection and preciselocalization (e.g., large IoU thresholds), mainly due to the coarseness of itsfeature maps. In this paper, we present a deep hierarchical network, namelyHyperNet, for handling region proposal generation and object detection jointly.Our HyperNet is primarily based on an elaborately designed Hyper Feature whichaggregates hierarchical feature maps first and then compresses them into auniform space. The Hyper Features well incorporate deep but highly semantic,intermediate but really complementary, and shallow but naturallyhigh-resolution features of the image, thus enabling us to construct HyperNetby sharing them both in generating proposals and detecting objects via anend-to-end joint training strategy. For the deep VGG16 model, our methodachieves completely leading recall and state-of-the-art object detectionaccuracy on PASCAL VOC 2007 and 2012 using only 100 proposals per image. Itruns with a speed of 5 fps (including all steps) on a GPU, thus having thepotential for real-time processing.
arxiv-1604-00606 | GAL: A Global-Attributes Assisted Labeling System for Outdoor Scenes |  http://arxiv.org/abs/1604.00606  | author:Yuzhuo Ren, Chen Chen, Shangwen Li, C. -C. Jay Kuo category:cs.CV published:2016-04-03 summary:An approach that extracts global attributes from outdoor images to facilitategeometric layout labeling is investigated in this work. The proposedGlobal-attributes Assisted Labeling (GAL) system exploits both local featuresand global attributes. First, by following a classical method, we use localfeatures to provide initial labels for all super-pixels. Then, we develop a setof techniques to extract global attributes from 2D outdoor images. They includesky lines, ground lines, vanishing lines, etc. Finally, we propose the GALsystem that integrates global attributes in the conditional random field (CRF)framework to improve initial labels so as to offer a more robust labelingresult. The performance of the proposed GAL system is demonstrated andbenchmarked with several state-of-the-art algorithms against a popular outdoorscene layout dataset.
arxiv-1604-00642 | Multi-objective design of quantum circuits using genetic programming |  http://arxiv.org/abs/1604.00642  | author:Moein Sarvaghad-Moghaddam category:cs.ET cs.NE published:2016-04-03 summary:Quantum computing is a new way of data processing based on the concept ofquantum mechanics. Quantum circuit design is a process of converting a quantumgate to a series of basic gates and is divided into two general categoriesbased on the decomposition and composition. In the second group, usingevolutionary algorithms and especially genetic algorithms, multiplication ofmatrix gates was used to achieve the final characteristic of quantum circuit.Genetic programming is a subfield of evolutionary computing in which computerprograms evolve to solve studied problems. In past research that has been donein the field of quantum circuits design, only one cost metrics (usually quantumcost) has been investigated. In this paper for the first time, amulti-objective approach has been provided to design quantum circuits usinggenetic programming that considers the depth and the cost of nearest neighbormetrics in addition to quantum cost metric. Another innovation of this articleis the use of two-step fitness function and taking into account the equivalenceof global phase in quantum gates. The results show that the proposed method isable to find a good answer in a short time.
arxiv-1604-00647 | Multi-Relational Learning at Scale with ADMM |  http://arxiv.org/abs/1604.00647  | author:Lucas Drumond, Ernesto Diaz-Aviles, Lars Schmidt-Thieme category:stat.ML cs.AI cs.LG published:2016-04-03 summary:Learning from multiple-relational data which contains noise, ambiguities, orduplicate entities is essential to a wide range of applications such asstatistical inference based on Web Linked Data, recommender systems,computational biology, and natural language processing. These tasks usuallyrequire working with very large and complex datasets - e.g., the Web graph -however, current approaches to multi-relational learning are not practical forsuch scenarios due to their high computational complexity and poor scalabilityon large data. In this paper, we propose a novel and scalable approach for multi-relationalfactorization based on consensus optimization. Our model, called ConsMRF, isbased on the Alternating Direction Method of Multipliers (ADMM) framework,which enables us to optimize each target relation using a smaller set ofparameters than the state-of-the-art competitors in this task. Due to ADMM's nature, ConsMRF can be easily parallelized which makes itsuitable for large multi-relational data. Experiments on large Web datasets -derived from DBpedia, Wikipedia and YAGO - show the efficiency and performanceimprovement of ConsMRF over strong competitors. In addition, ConsMRFnear-linear scalability indicates great potential to tackle Web-scale problemsizes.
arxiv-1604-00653 | A Characterization of the Non-Uniqueness of Nonnegative Matrix Factorizations |  http://arxiv.org/abs/1604.00653  | author:W. Pan, F. Doshi-Velez category:cs.LG stat.ML published:2016-04-03 summary:Nonnegative matrix factorization (NMF) is a popular dimension reductiontechnique that produces interpretable decomposition of the data into parts.However, this decompostion is not generally identifiable (even up topermutation and scaling). While other studies have provide criteria under whichNMF is identifiable, we present the first (to our knowledge) characterizationof the non-identifiability of NMF. We describe exactly when and hownon-uniqueness can occur, which has important implications for algorithms toefficiently discover alternate solutions, if they exist.
arxiv-1604-00644 | An electronic-game framework for evaluating coevolutionary algorithms |  http://arxiv.org/abs/1604.00644  | author:Karine da Silva Miras de Araújo, Fabrício Olivetti de França category:cs.NE cs.AI published:2016-04-03 summary:One of the common artificial intelligence applications in electronic gamesconsists of making an artificial agent learn how to execute some determinedtask successfully in a game environment. One way to perform this task isthrough machine learning algorithms capable of learning the sequence of actionsrequired to win in a given game environment. There are several supervisedlearning techniques able to learn the correct answer for a problem throughexamples. However, when learning how to play electronic games, the correctanswer might only be known by the end of the game, after all the actions werealready taken. Thus, not being possible to measure the accuracy of eachindividual action to be taken at each time step. A way for dealing with thisproblem is through Neuroevolution, a method which trains Artificial NeuralNetworks using evolutionary algorithms. In this article, we introduce aframework for testing optimization algorithms with artificial agent controllersin electronic games, called EvoMan, which is inspired in the action-platformergame Mega Man II. The environment can be configured to run in differentexperiment modes, as single evolution, coevolution and others. To demonstratesome challenges regarding the proposed platform, as initial experiments weapplied Neuroevolution using Genetic Algorithms and the NEAT algorithm, in thecontext of competitively coevolving two distinct agents in this game.
arxiv-1604-00676 | Multi-Bias Non-linear Activation in Deep Neural Networks |  http://arxiv.org/abs/1604.00676  | author:Hongyang Li, Wanli Ouyang, Xiaogang Wang category:cs.CV published:2016-04-03 summary:As a widely used non-linear activation, Rectified Linear Unit (ReLU)separates noise and signal in a feature map by learning a threshold or bias.However, we argue that the classification of noise and signal not only dependson the magnitude of responses, but also the context of how the featureresponses would be used to detect more abstract patterns in higher layers. Inorder to output multiple response maps with magnitude in different ranges for aparticular visual pattern, existing networks employing ReLU and its variantshave to learn a large number of redundant filters. In this paper, we propose amulti-bias non-linear activation (MBA) layer to explore the information hiddenin the magnitudes of responses. It is placed after the convolution layer todecouple the responses to a convolution kernel into multiple maps bymulti-thresholding magnitudes, thus generating more patterns in the featurespace at a low computational cost. It provides great flexibility of selectingresponses to different visual patterns in different magnitude ranges to formrich representations in higher layers. Such a simple and yet effective schemeachieves the state-of-the-art performance on several benchmarks.
arxiv-1604-00697 | A New Learning Method for Inference Accuracy, Core Occupation, and Performance Co-optimization on TrueNorth Chip |  http://arxiv.org/abs/1604.00697  | author:Wei Wen, Chunpeng Wu, Yandan Wang, Kent Nixon, Qing Wu, Mark Barnell, Hai Li, Yiran Chen category:cs.NE cs.AI published:2016-04-03 summary:IBM TrueNorth chip uses digital spikes to perform neuromorphic computing andachieves ultrahigh execution parallelism and power efficiency. However, inTrueNorth chip, low quantization resolution of the synaptic weights and spikessignificantly limits the inference (e.g., classification) accuracy of thedeployed neural network model. Existing workaround, i.e., averaging the resultsover multiple copies instantiated in spatial and temporal domains, rapidlyexhausts the hardware resources and slows down the computation. In this work,we propose a novel learning method on TrueNorth platform that constrains therandom variance of each computation copy and reduces the number of neededcopies. Compared to the existing learning method, our method can achieve up to68.8% reduction of the required neuro-synaptic cores or 6.5X speedup, with evenslightly improved inference accuracy.
arxiv-1604-00470 | Overlay Text Extraction From TV News Broadcast |  http://arxiv.org/abs/1604.00470  | author:Raghvendra Kannao, Prithwijit Guha category:cs.CV published:2016-04-02 summary:The text data present in overlaid bands convey brief descriptions of newsevents in broadcast videos. The process of text extraction becomes challengingas overlay text is presented in widely varying formats and often with animationeffects. We note that existing edge density based methods are well suited forour application on account of their simplicity and speed of operation. However,these methods are sensitive to thresholds and have high false positive rates.In this paper, we present a contrast enhancement based preprocessing stage foroverlay text detection and a parameter free edge density based scheme forefficient text band detection. The second contribution of this paper is a novelapproach for multiple text region tracking with a formal identification of allpossible detection failure cases. The tracking stage enables us to establishthe temporal presence of text bands and their linking over time. The thirdcontribution is the adoption of Tesseract OCR for the specific task of overlaytext recognition using web news articles. The proposed approach is tested andfound superior on news videos acquired from three Indian English televisionnews channels along with benchmark datasets.
arxiv-1604-00462 | Centralized and Decentralized Global Outer-synchronization of Asymmetric Recurrent Time-varying Neural Network by Data-sampling |  http://arxiv.org/abs/1604.00462  | author:Wenlian Lu, Ren Zheng, Tianping Chen category:cs.NE cs.SY math.CA published:2016-04-02 summary:In this paper, we discuss the outer-synchronization of the asymmetricallyconnected recurrent time-varying neural networks. By both centralized anddecentralized discretization data sampling principles, we derive severalsufficient conditions based on diverse vector norms that guarantee that any twotrajectories from different initial values of the identical neural networksystem converge together. The lower bounds of the common time intervals betweendata samples in centralized and decentralized principles are proved to bepositive, which guarantees exclusion of Zeno behavior. A numerical example isprovided to illustrate the efficiency of the theoretical results.
arxiv-1604-00461 | Embedding Lexical Features via Low-Rank Tensors |  http://arxiv.org/abs/1604.00461  | author:Mo Yu, Mark Dredze, Raman Arora, Matthew Gormley category:cs.CL cs.AI cs.LG published:2016-04-02 summary:Modern NLP models rely heavily on engineered features, which often combineword and contextual information into complex lexical features. Such combinationresults in large numbers of features, which can lead to over-fitting. Wepresent a new model that represents complex lexical features---comprised ofparts for words, contextual information and labels---in a tensor that capturesconjunction information among these parts. We apply low-rank tensorapproximations to the corresponding parameter tensors to reduce the parameterspace and improve prediction speed. Furthermore, we investigate two methods forhandling features that include $n$-grams of mixed lengths. Our model achievesstate-of-the-art results on tasks in relation extraction, PP-attachment, andpreposition disambiguation.
arxiv-1604-00457 | Stability of Analytic Neural Networks with Event-triggered Synaptic Feedbacks |  http://arxiv.org/abs/1604.00457  | author:Ren Zheng, Xinlei Yi, Wenlian Lu, Tianping Chen category:cs.NE math.DS nlin.AO published:2016-04-02 summary:In this paper, we investigate stability of a class of analytic neuralnetworks with the synaptic feedback via event-triggered rules. This model isgeneral and include Hopfield neural network as a special case. Theseevent-trigger rules can efficiently reduces loads of computation andinformation transmission at synapses of the neurons. The synaptic feedback ofeach neuron keeps a constant value based on the outputs of the other neurons atits latest triggering time but changes at its next triggering time, which isdetermined by certain criterion. It is proved that every trajectory of theanalytic neural network converges to certain equilibrium under thisevent-triggered rule for all initial values except a set of zero measure. Themain technique of the proof is the Lojasiewicz inequality to prove thefiniteness of trajectory length. The realization of this event-triggered ruleis verified by the exclusion of Zeno behaviors. Numerical examples are providedto illustrate the efficiency of the theoretical results.
arxiv-1604-00562 | Reasoning About Pragmatics with Neural Listeners and Speakers |  http://arxiv.org/abs/1604.00562  | author:Jacob Andreas, Dan Klein category:cs.CL cs.NE published:2016-04-02 summary:We present a model for pragmatically describing scenes, in which contrastivebehavior results from a combination of inference-driven pragmatics and learnedsemantics. Like previous learned approaches to language generation, our modeluses a simple feature-driven architecture (here a pair of neural "listener" and"speaker" models) to ground language in the world. Like inference-drivenapproaches to pragmatics, our model actively reasons about listener behaviorwhen selecting utterances. For training, our approach requires only ordinarycaptions, annotated _without_ demonstration of the pragmatic behavior the modelultimately exhibits. In human evaluations on a referring expression game, ourapproach succeeds 81% of the time, compared to a 64% success rate usingexisting techniques.
arxiv-1604-00449 | 3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction |  http://arxiv.org/abs/1604.00449  | author:Christopher B. Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, Silvio Savarese category:cs.CV cs.AI published:2016-04-02 summary:Inspired by the recent success of methods that employ shape priors to achieverobust 3D reconstructions, we propose a novel recurrent neural networkarchitecture that we call the 3D Recurrent Reconstruction Neural Network(3D-R2N2). The network learns a mapping from images of objects to theirunderlying 3D shapes from a large collection of synthetic data. Our networktakes in one or more images of an object instance from arbitrary viewpoints andoutputs a reconstruction of the object in the form of a 3D occupancy grid.Unlike most of the previous works, our network does not require any imageannotations or object class labels for training or testing. Our extensiveexperimental analysis shows that our reconstruction framework i) outperformsthe state-of-the-art methods for single view reconstruction, and ii) enablesthe 3D reconstruction of objects in situations when traditional SFM/SLAMmethods fail (because of lack of texture and/or wide baseline).
arxiv-1604-00475 | Robust video object tracking via Bayesian model averaging based feature fusion |  http://arxiv.org/abs/1604.00475  | author:Yi Dai, Bin Liu category:cs.CV published:2016-04-02 summary:In this article, we are concerned with tracking an object of interest invideo stream. We propose an algorithm that is robust against occlusion, thepresence of confusing colors, abrupt changes in the object feature space andchanges in object size. We develop the algorithm within a Bayesian modelingframework. The state space model is used for capturing the temporal correlationin the sequence of frame images by modeling the underlying dynamics of thetracking system. The Bayesian model averaging (BMA) strategy is proposed forfusing multi-clue information in the observations. Any number of objectfeatures are allowed to be involved in the proposed framework. Every featurerepresents one source of information to be fused and is associated with anobservation model. The state inference is performed by employing the particlefilter methods. In comparison with related approaches, the BMA based tracker isshown to have robustness, expressivity, and comprehensibility.
arxiv-1604-00466 | Automatic Annotation of Structured Facts in Images |  http://arxiv.org/abs/1604.00466  | author:Mohamed Elhoseiny, Scott Cohen, Walter Chang, Brian Price, Ahmed Elgammal category:cs.CL cs.CV published:2016-04-02 summary:Motivated by the application of fact-level image understanding, we present anautomatic method for data collection of structured visual facts from imageswith captions. Example structured facts include attributed objects (e.g.,<flower, red>), actions (e.g., <baby, smile>), interactions (e.g., <man,walking, dog>), and positional information (e.g., <vase, on, table>). Thecollected annotations are in the form of fact-image pairs (e.g.,<man, walking,dog> and an image region containing this fact). With a language approach, theproposed method is able to collect hundreds of thousands of visual factannotations with accuracy of 83% according to human judgment. Our methodautomatically collected more than 380,000 visual fact annotations and more than110,000 unique visual facts from images with captions and localized them inimages in less than one day of processing time on standard CPU platforms.
arxiv-1604-00557 | SAM: Support Vector Machine Based Active Queue Management |  http://arxiv.org/abs/1604.00557  | author:Muhammad Saleh Shah, Asim Imdad Wagan, Mukhtiar Ali Unar category:cs.NI cs.LG published:2016-04-02 summary:Recent years have seen an increasing interest in the design of AQM (ActiveQueue Management) controllers. The purpose of these controllers is to managethe network congestion under varying loads, link delays and bandwidth. In thispaper, a new AQM controller is proposed which is trained by using the SVM(Support Vector Machine) with the RBF (Radial Basis Function) kernal. Theproposed controller is called the support vector based AQM (SAM) controller.The performance of the proposed controller has been compared with threeconventional AQM controllers, namely the Random Early Detection, Blue andProportional Plus Integral Controller. The preliminary simulation studies showthat the performance of the proposed controller is comparable to theconventional controllers. However, the proposed controller is more efficient incontrolling the queue size than the conventional controllers.
arxiv-1604-00558 | Channel Equalization Using Multilayer Perceptron Networks |  http://arxiv.org/abs/1604.00558  | author:Saba Baloch, Javed Ali Baloch, Mukhtiar Ali Unar category:cs.NE published:2016-04-02 summary:In most digital communication systems, bandwidth limited channel along withmultipath propagation causes ISI (Inter Symbol Interference) to occur. Thisphenomenon causes distortion of the given transmitted symbol due to othertransmitted symbols. With the help of equalization ISI can be reduced. Thispaper presents a solution to the ISI problem by performing blind equalizationusing ANN (Artificial Neural Networks). The simulated network is a multilayerfeedforward Perceptron ANN, which has been trained by utilizing the errorback-propagation algorithm. The weights of the network are updated inaccordance with training of the network. This paper presents a very effectivemethod for blind channel equalization, being more efficient than thepre-existing algorithms. The obtained results show a visible reduction in thenoise content.
arxiv-1604-00552 | pH Prediction by Artificial Neural Networks for the Drinking Water of the Distribution System of Hyderabad City |  http://arxiv.org/abs/1604.00552  | author:Niaz Ahmed Memon, Mukhtiar Ali Unar, Abdul Khalique Ansari category:cs.NE published:2016-04-02 summary:In this research, feedforward ANN (Artificial Neural Network) model isdeveloped and validated for predicting the pH at 10 different locations of thedistribution system of drinking water of Hyderabad city. The developed model isMLP (Multilayer Perceptron) with back propagation algorithm.The data for thetraining and testing of the model are collected through an experimentalanalysis on weekly basis in a routine examination for maintaining the qualityof drinking water in the city. 17 parameters are taken into considerationincluding pH. These all parameters are taken as input variables for the modeland then pH is predicted for 03 phases;raw water of river Indus,treated waterin the treatment plants and then treated water in the distribution system ofdrinking water. The training and testing results of this model reveal that MLPneural networks are exceedingly extrapolative for predicting the pH of riverwater, untreated and treated water at all locations of the distribution systemof drinking water of Hyderabad city. The optimum input and output weights aregenerated with minimum MSE (Mean Square Error) < 5%.Experimental, predicted andtested values of pH are plotted and the effectiveness of the model isdetermined by calculating the coefficient of correlation (R2=0.999) of trainedand tested results.
arxiv-1604-00546 | Image Quality Assessment for Performance Evaluation of Focus Measure Operators |  http://arxiv.org/abs/1604.00546  | author:Farida Memon, Mukhtiar Ali Unar, Sheeraz Memon category:cs.CV published:2016-04-02 summary:This paper presents the performance evaluation of eight focus measureoperators namely Image CURV (Curvature), GRAE (Gradient Energy), HISE(Histogram Entropy), LAPM (Modified Laplacian), LAPV (Variance of Laplacian),LAPD (Diagonal Laplacian), LAP3 (Laplacian in 3D Window) and WAVS (Sum ofWavelet Coefficients). Statistical matrics such as MSE (Mean Squared Error),PNSR (Peak Signal to Noise Ratio), SC (Structural Content), NCC (NormalizedCross Correlation), MD (Maximum Difference) and NAE (Normalized Absolute Error)are used to evaluate stated focus measures in this research. . FR (FullReference) method of the image quality assessment is utilized in this paper.Results indicate that LAPD method is comparatively better than other sevenfocus operators at typical imaging conditions.
arxiv-1604-00533 | Voronoi Region-Based Adaptive Unsupervised Color Image Segmentation |  http://arxiv.org/abs/1604.00533  | author:R. Hettiarachchi, J. F. Peters category:cs.CV published:2016-04-02 summary:Color image segmentation is a crucial step in many computer vision andpattern recognition applications. This article introduces an adaptive andunsupervised clustering approach based on Voronoi regions, which can be appliedto solve the color image segmentation problem. The proposed method performsregion splitting and merging within Voronoi regions of the DirichletTessellated image (also called a Voronoi diagram) , which improves theefficiency and the accuracy of the number of clusters and cluster centroidsestimation process. Furthermore, the proposed method uses cluster centroidproximity to merge proximal clusters in order to find the final number ofclusters and cluster centroids. In contrast to the existing adaptiveunsupervised cluster-based image segmentation algorithms, the proposed methoduses K-means clustering algorithm in place of the Fuzzy C-means algorithm tofind the final segmented image. The proposed method was evaluated on threedifferent unsupervised image segmentation evaluation benchmarks and its resultswere compared with two other adaptive unsupervised cluster-based imagesegmentation algorithms. The experimental results reported in this articleconfirm that the proposed method outperforms the existing algorithms in termsof the quality of image segmentation results. Also, the proposed method resultsin the lowest average execution time per image compared to the existing methodsreported in this article.
arxiv-1604-00503 | Discriminative Phrase Embedding for Paraphrase Identification |  http://arxiv.org/abs/1604.00503  | author:Wenpeng Yin, Hinrich Schütze category:cs.CL published:2016-04-02 summary:This work, concerning paraphrase identification task, on one hand contributesto expanding deep learning embeddings to include continuous and discontinuouslinguistic phrases. On the other hand, it comes up with a new scheme TF-KLD-KNNto learn the discriminative weights of words and phrases specific to paraphrasetask, so that a weighted sum of embeddings can represent sentences moreeffectively. Based on these two innovations we get competitive state-of-the-artperformance on paraphrase identification.
arxiv-1604-00502 | Online Updating of Word Representations for Part-of-Speech Tagging |  http://arxiv.org/abs/1604.00502  | author:Wenpeng Yin, Tobias Schnabel, Hinrich Schütze category:cs.CL published:2016-04-02 summary:We propose online unsupervised domain adaptation (DA), which is performedincrementally as data comes in and is applicable when batch DA is not possible.In a part-of-speech (POS) tagging evaluation, we find that online unsupervisedDA performs as well as batch DA.
arxiv-1604-00494 | A Fully Convolutional Neural Network for Cardiac Segmentation in Short-Axis MRI |  http://arxiv.org/abs/1604.00494  | author:Phi Vu Tran category:cs.CV published:2016-04-02 summary:Automated cardiac segmentation from magnetic resonance imaging datasets is anessential step in the timely diagnosis and management of cardiac pathologies.We propose to tackle the problem of automated left and right ventriclesegmentation through the application of a deep fully convolutional neuralnetwork architecture. Our model is efficiently trained end-to-end in a singlelearning stage from whole-image inputs and ground truths to make inference atevery pixel. To our knowledge, this is the first application of a fullyconvolutional neural network architecture for pixel-wise labeling in cardiacmagnetic resonance imaging. Numerical experiments demonstrate that our model isrobust to outperform previous fully automated methods across multipleevaluation measures on a range of cardiac datasets. It is equally noteworthythat our model leverages commodity compute resources such as the graphicsprocessing unit to enable fast, state-of-the-art cardiac segmentation atmassive scales. The models and code will be released open-source in the nearfuture.
arxiv-1604-00187 | PHOCNet: A Deep Convolutional Neural Network for Word Spotting in Handwritten Documents |  http://arxiv.org/abs/1604.00187  | author:Sebastian Sudholt, Gernot A. Fink category:cs.CV published:2016-04-01 summary:In recent years, deep convolutional neural networks have achieved state ofthe art performance in various computer vision task such as classification,detection or segmentation. Due to their outstanding performance, CNNs are moreand more used in the field of document image analysis as well. In this work, wepresent a CNN architecture that is trained with the recently proposed PHOCrepresentation. We show empirically that our CNN architecture is able tooutperform state of the art results for various word spotting benchmarks whileexhibiting short training and test times.
arxiv-1604-00136 | It's Moving! A Probabilistic Model for Causal Motion Segmentation in Moving Camera Videos |  http://arxiv.org/abs/1604.00136  | author:Pia Bideau, Erik Learned-Miller category:cs.CV published:2016-04-01 summary:The human ability to detect and segment moving objects works in the presenceof multiple objects, complex background geometry, motion of the observer, andeven camouflage. In addition to all of this, the ability to detect motion isnearly instantaneous. While there has been much recent progress in motionsegmentation, it still appears we are far from human capabilities. In thiswork, we derive from first principles a new likelihood function for assessingthe probability of an optical flow vector given the 3D motion direction of anobject. This likelihood uses a novel combination of the angle and magnitude ofthe optical flow to maximize the information about the true motions of objects.Using this new likelihood and several innovations in initialization, we developa motion segmentation algorithm that beats current state-of-the-art methods bya large margin. We compare to five state-of-the-art methods on two establishedbenchmarks, and a third new data set of camouflaged animals, which we introduceto push motion segmentation to the next level.
arxiv-1604-00119 | Semi-supervised and Unsupervised Methods for Categorizing Posts in Web Discussion Forums |  http://arxiv.org/abs/1604.00119  | author:Krish Perumal category:cs.CL cs.IR cs.LG cs.SI published:2016-04-01 summary:Web discussion forums are used by millions of people worldwide to shareinformation belonging to a variety of domains such as automotive vehicles,pets, sports, etc. They typically contain posts that fall into differentcategories such as problem, solution, feedback, spam, etc. Automaticidentification of these categories can aid information retrieval that istailored for specific user requirements. Previously, a number of supervisedmethods have attempted to solve this problem; however, these depend on theavailability of abundant training data. A few existing unsupervised andsemi-supervised approaches are either focused on identifying a single categoryor do not report category-specific performance. In contrast, this work proposesunsupervised and semi-supervised methods that require no or minimal trainingdata to achieve this objective without compromising on performance. Afine-grained analysis is also carried out to discuss their limitations. Theproposed methods are based on sequence models (specifically, Hidden MarkovModels) that can model language for each category using word and part-of-speechprobability distributions, and manually specified features. Empiricalevaluations across domains demonstrate that the proposed methods are bettersuited for this task than existing ones.
arxiv-1604-00133 | Good Practice in CNN Feature Transfer |  http://arxiv.org/abs/1604.00133  | author:Liang Zheng, Yali Zhao, Shengjin Wang, Jingdong Wang, Qi Tian category:cs.CV published:2016-04-01 summary:The objective of this paper is the effective transfer of the ConvolutionalNeural Network (CNN) feature in image search and classification.Systematically, we study three facts in CNN transfer. 1) We demonstrate theadvantage of using images with a properly large size as input to CNN instead ofthe conventionally resized one. 2) We benchmark the performance of differentCNN layers improved by average/max pooling on the feature maps. Our observationsuggests that the Conv5 feature yields very competitive accuracy under suchpooling step. 3) We find that the simple combination of pooled featuresextracted across various CNN layers is effective in collecting evidences fromboth low and high level descriptors. Following these good practices, we arecapable of improving the state of the art on a number of benchmarks to a largemargin.
arxiv-1604-00126 | Nonparametric Spherical Topic Modeling with Word Embeddings |  http://arxiv.org/abs/1604.00126  | author:Kayhan Batmanghelich, Ardavan Saeedi, Karthik Narasimhan, Sam Gershman category:cs.CL cs.IR cs.LG stat.ML published:2016-04-01 summary:Traditional topic models do not account for semantic regularities inlanguage. Recent distributional representations of words exhibit semanticconsistency over directional metrics such as cosine similarity. However,neither categorical nor Gaussian observational distributions used in existingtopic models are appropriate to leverage such correlations. In this paper, wepropose to use the von Mises-Fisher distribution to model the density of wordsover a unit sphere. Such a representation is well-suited for directional data.We use a Hierarchical Dirichlet Process for our base topic model and propose anefficient inference algorithm based on Stochastic Variational Inference. Thismodel enables us to naturally exploit the semantic structures of wordembeddings while flexibly discovering the number of topics. Experimentsdemonstrate that our method outperforms competitive approaches in terms oftopic coherence on two different text corpora while offering efficientinference.
arxiv-1604-00125 | AttSum: Joint Learning of Focusing and Summarization with Neural Attention |  http://arxiv.org/abs/1604.00125  | author:Ziqiang Cao, Wenjie Li, Sujian Li, Furu Wei category:cs.IR cs.CL published:2016-04-01 summary:Query relevance ranking and sentence saliency ranking are the two main tasksin extractive query-focused summarization. Previous supervised summarizationsystems often perform the two tasks in isolation. However, since referencesummaries are the trade-off between relevance and saliency, using them assupervision, neither of the two rankers could be trained well. This paperproposes a novel summarization system called AttSum, which tackles the twotasks jointly. It automatically learns distributed representations forsentences as well as the document cluster. Meanwhile, it applies the attentionmechanism to simulate the attentive reading of human behavior when a query isgiven. Extensive experiments are conducted on DUC query-focused summarizationbenchmark datasets. Without using any hand-crafted features, AttSum achievescompetitive performance. It is also observed that the sentences recognized tofocus on the query indeed meet the query need.
arxiv-1604-00117 | Domain Adaptation of Recurrent Neural Networks for Natural Language Understanding |  http://arxiv.org/abs/1604.00117  | author:Aaron Jaech, Larry Heck, Mari Ostendorf category:cs.CL published:2016-04-01 summary:The goal of this paper is to use multi-task learning to efficiently scaleslot filling models for natural language understanding to handle multipletarget tasks or domains. The key to scalability is reducing the amount oftraining data needed to learn a model for a new task. The proposed multi-taskmodel delivers better performance with less data by leveraging patterns that itlearns from the other tasks. The approach supports an open vocabulary, whichallows the models to generalize to unseen words, which is particularlyimportant when very little training data is used. A newly collectedcrowd-sourced data set, covering four different domains, is used to demonstratethe effectiveness of the domain adaptation and open vocabulary techniques.
arxiv-1604-00092 | Variational reaction-diffusion systems for semantic segmentation |  http://arxiv.org/abs/1604.00092  | author:Paul Vernaza category:cs.CV cs.LG published:2016-04-01 summary:A novel global energy model for multi-class semantic image segmentation isproposed that admits very efficient exact inference and derivative calculationsfor learning. Inference in this model is equivalent to MAP inference in aparticular kind of vector-valued Gaussian Markov random field, and ultimatelyreduces to solving a linear system of linear PDEs known as a reaction-diffusionsystem. Solving this system can be achieved in time scaling near-linearly inthe number of image pixels by reducing it to sequential FFTs, after a linearchange of basis. The efficiency and differentiability of the model make itespecially well-suited for integration with convolutional neural networks, evenallowing it to be used in interior, feature-generating layers and stackedmultiple times. Experimental results are shown demonstrating that the model canbe employed profitably in conjunction with different convolutional netarchitectures, and that doing so compares favorably to joint training of afully-connected CRF with a convolutional net.
arxiv-1604-00100 | A Compositional Approach to Language Modeling |  http://arxiv.org/abs/1604.00100  | author:Kushal Arora, Anand Rangarajan category:cs.CL published:2016-04-01 summary:Traditional language models treat language as a finite state automaton on aprobability space over words. This is a very strong assumption when modelingsomething inherently complex such as language. In this paper, we challenge thisby showing how the linear chain assumption inherent in previous work can betranslated into a sequential composition tree. We then propose a new model thatmarginalizes over all possible composition trees thereby removing anyunderlying structural assumptions. As the partition function of this new modelis intractable, we use a recently proposed sentence level evaluation metricContrastive Entropy to evaluate our model. Given this new evaluation metric, wereport more than 100% improvement across distortion levels over current stateof the art recurrent neural network based language models.
arxiv-1604-00147 | Learning a Pose Lexicon for Semantic Action Recognition |  http://arxiv.org/abs/1604.00147  | author:Lijuan Zhou, Wanqing Li, Philip Ogunbona category:cs.CV published:2016-04-01 summary:This paper presents a novel method for learning a pose lexicon comprisingsemantic poses defined by textual instructions and their associated visualposes defined by visual features. The proposed method simultaneously takes twoinput streams, semantic poses and visual pose candidates, and statisticallylearns a mapping between them to construct the lexicon. With the learnedlexicon, action recognition can be cast as the problem of finding the maximumtranslation probability of a sequence of semantic poses given a stream ofvisual pose candidates. Experiments evaluating pre-trained and zero-shot actionrecognition conducted on MSRC-12 gesture and WorkoutSu-10 exercise datasetswere used to verify the efficacy of the proposed method.
arxiv-1604-00433 | Cross Quality Distillation |  http://arxiv.org/abs/1604.00433  | author:Jong-Chyi Su, Subhransu Maji category:cs.CV published:2016-04-01 summary:We propose a technique for training recognition models when high-quality datais available at training time but not at testing time. Our approach, calledCross Quality Distillation (CQD), first trains a model on the high-quality dataand encourages a second model trained on the low-quality data to generalize inthe same way as the first. The technique is fairly general and only requiresthe ability to generate low-quality data from the high-quality data. We applythis to learn models for recognizing low-resolution images using labeledhigh-resolution images, non-localized objects using labeled localized objects,edge images using labeled color images, etc. Experiments on variousfine-grained recognition datasets demonstrate that the technique leads to largeimprovements in recognition accuracy on the low-quality data. We also establishconnections of CQD to other areas of machine learning such as domainadaptation, model compression, and learning using privileged information, andshow that the technique is general and can be applied to other settings.Finally, we present further insights into why the technique works throughvisualizations and establishing its relationship to curriculum learning.
arxiv-1604-00289 | Building Machines That Learn and Think Like People |  http://arxiv.org/abs/1604.00289  | author:Brenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, Samuel J. Gershman category:cs.AI cs.CV cs.LG cs.NE stat.ML published:2016-04-01 summary:Recent progress in artificial intelligence (AI) has renewed interest inbuilding systems that learn and think like people. Many advances have come fromusing deep neural networks trained end-to-end in tasks such as objectrecognition, video games, and board games, achieving performance that equals oreven beats humans in some respects. Despite their biological inspiration andperformance achievements, these systems differ from human intelligence incrucial ways. We review progress in cognitive science suggesting that trulyhuman-like learning and thinking machines will have to reach beyond currentengineering trends in both what they learn, and how they learn it.Specifically, we argue that these machines should (a) build causal models ofthe world that support explanation and understanding, rather than merelysolving pattern recognition problems; (b) ground learning in intuitive theoriesof physics and psychology, to support and enrich the knowledge that is learned;and (c) harness compositionality and learning-to-learn to rapidly acquire andgeneralize knowledge to new tasks and situations. We suggest concretechallenges and promising routes towards these goals that can combine thestrengths of recent neural network advances with more structured cognitivemodels.
arxiv-1604-00427 | Leaving Some Stones Unturned: Dynamic Feature Prioritization for Activity Detection in Streaming Video |  http://arxiv.org/abs/1604.00427  | author:Yu-Chuan Su, Kristen Grauman category:cs.CV published:2016-04-01 summary:Current approaches for activity recognition often ignore constraints oncomputational resources: 1) they rely on extensive feature computation toobtain rich descriptors on all frames, and 2) they assume batch-mode access tothe entire test video at once. We propose a new active approach to activityrecognition that prioritizes "what to compute when" in order to make timelypredictions. The main idea is to learn a policy that dynamically schedules thesequence of features to compute on selected frames of a given test video. Incontrast to traditional static feature selection, our approach continuallyre-prioritizes computation based on the accumulated history of observations andaccounts for the transience of those observations in ongoing video. We developvariants to handle both the batch and streaming settings. On two challengingdatasets, our method provides significantly better accuracy than alternativetechniques for a wide range of computational budgets.
arxiv-1604-00151 | Gradient-based learning algorithms with constant-error estimators: stability and convergence |  http://arxiv.org/abs/1604.00151  | author:Arunselvan Ramaswamy, Shalabh Bhatnagar category:cs.SY stat.ML 93E15, 93E35 published:2016-04-01 summary:Implementations of stochastic gradient search algorithms such as backpropagation typically rely on finite difference ($FD$) approximation methods.These methods are used to approximate the objective function gradient insteepest descent algorithms as well as the gradient and Hessian inverse inNewton based schemes. The convergence analyses of such schemes criticallyrequire that perturbation parameters in the estimators of the gradient/Hessianapproach zero. However, in practice, the perturbation parameter is often heldfixed to a `small' constant resulting in constant-error estimates. We presentin this paper a theoretical framework based on set-valued dynamical systems toanalyze the aforementioned. Easily verifiable conditions are presented forstability and convergence when using such $FD$ estimators for thegradient/Hessian. In addition, our framework dispenses with a criticalrestriction on the step-sizes (learning rate) when using FD estimators.
arxiv-1604-00169 | Gaussian process optimization through sampling from the maximum distribution |  http://arxiv.org/abs/1604.00169  | author:Hildo Bijl, Thomas B. Schön, Jan-Willem van Wingerden, Michel Verhaegen category:stat.ML cs.SY published:2016-04-01 summary:This paper first presents a novel algorithm approximating the distribution ofthe maximum (both its position and its value) of a Gaussian process. Thisalgorithm uses particles in a similar way as Sequential Monte Carlo samplers.It is subsequently applied to the problem of Gaussian Process Optimization(GPO). The resulting GPO algorithm does not use an acquisition function, whichmakes it different from other GPO algorithms. Through various example problems,including a wind turbine load mitigation example, we find that the resultingalgorithm on average outperforms existing GPO algorithms. In addition, becauseno acquisition function has to be optimized, the algorithm can easily andefficiently be applied to problems with high-dimensional input spaces.
arxiv-1604-00239 | Tensor Representations via Kernel Linearization for Action Recognition from 3D Skeletons |  http://arxiv.org/abs/1604.00239  | author:Piotr Koniusz, Anoop Cherian, Fatih Porikli category:cs.CV published:2016-04-01 summary:In this paper, we explore tensor representations that can compactly capturehigher-order relationships between skeleton joints for 3D action recognition.We first define RBF kernels on 3D joint sequences, which are then linearized toform kernel descriptors. The higher-order outer-products of these kerneldescriptors form our tensor representations. We present two different kernelsfor action recognition, namely (i) a sequence compatibility kernel thatcaptures the spatio-temporal compatibility of joints in one sequence againstthose in the other, and (ii) a dynamics compatibility kernel that explicitlymodels the action dynamics of a sequence. Tensors formed from these kernels arethen used to train an SVM. We present experiments on several benchmark datasetsand demonstrate state of the art results, substantiating the effectiveness ofour representations.
arxiv-1604-00255 | Network structure, metadata and the prediction of missing nodes |  http://arxiv.org/abs/1604.00255  | author:Darko Hric, Tiago P. Peixoto, Santo Fortunato category:physics.soc-ph cs.SI stat.ML published:2016-04-01 summary:The empirical validation of community detection methods is often based onavailable annotations on the nodes that serve as putative indicators of thelarge-scale network structure. Most often, the suitability of the annotationsas topological descriptors itself is not assessed, and without this it is notpossible to ultimately distinguish between actual shortcomings of the communitydetection algorithms on one hand, and the incompleteness, inaccuracy orstructured nature of the data annotations themselves on the other. In this workwe present a principled method to access both aspects simultaneously. Weconstruct a joint generative model for the data and metadata, and anon-parametric Bayesian framework to infer its parameters from annotateddatasets. We assess the quality of the metadata not according to its directalignment with the network communities, but rather in its capacity to predictthe placement of edges in the network. We also show how this feature can beused to predict the connections to missing nodes when only the metadata isavailable. By investigating a wide range of datasets, we show that while thereare seldom exact agreements between metadata tokens and the inferred datagroups, the metadata is often informative of the network structurenevertheless, and can improve the prediction of missing nodes. This shows thatthe method uncovers meaningful patterns in both the data and metadata, withoutrequiring or expecting a perfect agreement between the two.
arxiv-1604-00279 | Using Recurrent Neural Networks to Optimize Dynamical Decoupling for Quantum Memory |  http://arxiv.org/abs/1604.00279  | author:Moritz August, Xiaotong Ni category:quant-ph cs.LG cs.NE published:2016-04-01 summary:We utilize machine learning models which are based on recurrent neuralnetworks to optimize dynamical decoupling (DD) sequences. DD is a relativelysimple technique for suppressing the errors in quantum memory for certain noisemodels. In numerical simulations, we show that with minimum use of priorknowledge and starting from random sequences, the models are able to improveover time and eventually output DD-sequences with performance better than thatof the well known DD-families. Furthermore, our algorithm is easy to implementin experiments to find solutions tailored to the specific hardware, as ittreats the figure of merit as a black box.
arxiv-1604-00312 | Automated Alertness and Emotion Detection for Empathic Feedback During E-Learning |  http://arxiv.org/abs/1604.00312  | author:S L Happy, A. Dasgupta, P. Patnaik, A. Routray category:cs.CV cs.CY cs.HC published:2016-04-01 summary:In the context of education technology, empathic interaction with the userand feedback by the learning system using multiple inputs such as video, voiceand text inputs is an important area of research. In this paper, anonintrusive, standalone model for intelligent assessment of alertness andemotional state as well as generation of appropriate feedback has beenproposed. Using the non-intrusive visual cues, the system classifies emotionand alertness state of the user, and provides appropriate feedback according tothe detected cognitive state using facial expressions, ocular parameters,postures, and gestures. Assessment of alertness level using ocular parameterssuch as PERCLOS and saccadic parameters, emotional state from facial expressionanalysis, and detection of both relevant cognitive and emotional states fromupper body gestures and postures has been proposed. Integration of such asystem in e-learning environment is expected to enhance students performancethrough interaction, feedback, and positive mood induction.
arxiv-1604-00425 | Cross-lingual Models of Word Embeddings: An Empirical Comparison |  http://arxiv.org/abs/1604.00425  | author:Shyam Upadhyay, Manaal Faruqui, Chris Dyer, Dan Roth category:cs.CL published:2016-04-01 summary:Despite interest in using cross-lingual knowledge to learn word embeddingsfor various tasks, a systematic comparison of the possible approaches islacking in the literature. We perform an extensive evaluation of four popularapproaches of inducing cross-lingual embeddings, each requiring a differentform of supervision, on four typographically different language pairs. Ourevaluation setup spans four different tasks, including intrinsic evaluation onmono-lingual and cross-lingual similarity, and extrinsic evaluation ondownstream semantic and syntactic applications. We show that models whichrequire expensive cross-lingual knowledge almost always perform better, butcheaply supervised models often prove competitive on certain tasks.
arxiv-1604-00409 | Structure from Motion on a Sphere |  http://arxiv.org/abs/1604.00409  | author:Jonathan Ventura category:cs.CV published:2016-04-01 summary:We describe a special case of structure from motion where the camera rotateson a sphere. The camera's optical axis lies normal to the sphere's surface. Inthis case, the camera's pose is minimally represented by three rotationparameters. From analysis of the epipolar geometry we derive a novel andefficient solution for the essential matrix relating two images, requiring onlythree point correspondences in the minimal case. We apply this solver in astructure-from-motion pipeline that aggregates pairwise relations by rotationaveraging followed by bundle adjustment with an inverse depth parameterization.Our methods enable scene modeling with an outward-facing camera and objectscanning with an inward-facing camera.
arxiv-1604-00317 | A Semisupervised Approach for Language Identification based on Ladder Networks |  http://arxiv.org/abs/1604.00317  | author:Ehud Ben-Reuven, Jacob Goldberger category:cs.CL cs.LG cs.NE published:2016-04-01 summary:In this study we address the problem of training a neuralnetwork for languageidentification using both labeled and unlabeled speech samples in the form ofi-vectors. We propose a neural network architecture that can also handleout-of-set languages. We utilize a modified version of the recently proposedLadder Network semisupervised training procedure that optimizes thereconstruction costs of a stack of denoising autoencoders. We show that thisapproach can be successfully applied to the case where the training dataset iscomposed of both labeled and unlabeled acoustic data. The results show enhancedlanguage identification on the NIST 2015 language identification dataset.
arxiv-1604-00400 | Revisiting Summarization Evaluation for Scientific Articles |  http://arxiv.org/abs/1604.00400  | author:Arman Cohan, Nazli Goharian category:cs.CL published:2016-04-01 summary:Evaluation of text summarization approaches have been mostly based on metricsthat measure similarities of system generated summaries with a set of humanwritten gold-standard summaries. The most widely used metric in summarizationevaluation has been the ROUGE family. ROUGE solely relies on lexical overlapsbetween the terms and phrases in the sentences; therefore, in cases ofterminology variations and paraphrasing, ROUGE is not as effective. Scientificarticle summarization is one such case that is different from general domainsummarization (e.g. newswire data). We provide an extensive analysis of ROUGE'seffectiveness as an evaluation metric for scientific summarization; we showthat, contrary to the common belief, ROUGE is not much reliable in evaluatingscientific summaries. We furthermore show how different variants of ROUGEresult in very different correlations with the manual Pyramid scores. Finally,we propose an alternative metric for summarization evaluation which is based onthe content relevance between a system generated summary and the correspondinghuman written summaries. We call our metric SERA (Summarization Evaluation byRelevance Analysis). Unlike ROUGE, SERA consistently achieves high correlationswith manual scores which shows its effectiveness in evaluation of scientificarticle summarization.
arxiv-1604-00326 | How to Transfer? Zero-Shot Object Recognition via Hierarchical Transfer of Semantic Attributes |  http://arxiv.org/abs/1604.00326  | author:Ziad Al-Halah, Rainer Stiefelhagen category:cs.CV published:2016-04-01 summary:Attribute based knowledge transfer has proven very successful in visualobject analysis and learning previously unseen classes. However, the commonapproach learns and transfers attributes without taking into consideration theembedded structure between the categories in the source set. Such informationprovides important cues on the intra-attribute variations. We propose tocapture these variations in a hierarchical model that expands the knowledgesource with additional abstraction levels of attributes. We also provide anovel transfer approach that can choose the appropriate attributes to be sharedwith an unseen class. We evaluate our approach on three public datasets:aPascal, Animals with Attributes and CUB-200-2011 Birds. The experimentsdemonstrate the effectiveness of our model with significant improvement overstate-of-the-art.
arxiv-1604-00359 | COCO: The Bi-objective Black Box Optimization Benchmarking (bbob-biobj) Test Suite |  http://arxiv.org/abs/1604.00359  | author:Tea Tusar, Dimo Brockhoff, Nikolaus Hansen, Anne Auger category:cs.AI cs.NE published:2016-04-01 summary:The bbob-biobj test suite contains 55 bi-objective functions in continuousdomain which are derived from combining functions of the well-knownsingle-objective noiseless bbob test suite. Besides giving the actual functiondefinitions and presenting their (known) properties, this documentation alsoaims at giving the rationale behind our approach in terms of function groups,instances, and potential objective space normalization.
arxiv-1604-00385 | Large-Scale Electron Microscopy Image Segmentation in Spark |  http://arxiv.org/abs/1604.00385  | author:Stephen M. Plaza, Stuart E. Berg category:q-bio.QM cs.CV published:2016-04-01 summary:The emerging field of connectomics aims to unlock the mysteries of the brainby understanding the connectivity between neurons. To map this connectivity, weacquire thousands of electron microscopy (EM) images with nanometer-scaleresolution. After aligning these images, the resulting dataset has thepotential to reveal the shapes of neurons and the synaptic connections betweenthem. However, imaging the brain of even a tiny organism like the fruit flyyields terabytes of data. It can take years of manual effort to examine suchimage volumes and trace their neuronal connections. One solution is to applyimage segmentation algorithms to help automate the tracing tasks. In thispaper, we propose a novel strategy to apply such segmentation on very largedatasets that exceed the capacity of a single machine. Our solution is robustto potential segmentation errors which could otherwise severely compromise thequality of the overall segmentation, for example those due to poor classifiergeneralizability or anomalies in the image dataset. We implement our algorithmsin a Spark application which minimizes disk I/O, and apply them to a few largeEM datasets, revealing both their effectiveness and scalability. We hope thiswork will encourage external contributions to EM segmentation by providing 1) aflexible plugin architecture that deploys easily on different clusterenvironments and 2) an in-memory representation of segmentation that could beconducive to new advances.
arxiv-1604-00367 | Person Re-identification in Appearance Impaired Scenarios |  http://arxiv.org/abs/1604.00367  | author:Mengran Gou, Xikang Zhang, Angels Rates-Borras, Sadjad Asghari-Esfeden, Mario Sznaier, Octavia Camps category:cs.CV published:2016-04-01 summary:Person re-identification is critical in surveillance applications. Currentapproaches rely on appearance based features extracted from a single ormultiple shots of the target and candidate matches. These approaches are at adisadvantage when trying to distinguish between candidates dressed in similarcolors or when targets change their clothing. In this paper we propose adynamics-based feature to overcome this limitation. The main idea is to capturesoft biometrics from gait and motion patterns by gathering dense shorttrajectories (tracklets) which are Fisher vector encoded. To illustrate themerits of the proposed features we introduce three new "appearance-impaired"datasets. Our experiments on the original and the appearance impaired datasetsdemonstrate the benefits of incorporating dynamics-based information withappearance-based information to re-identification algorithms.
arxiv-1604-00066 | To Fall Or Not To Fall: A Visual Approach to Physical Stability Prediction |  http://arxiv.org/abs/1604.00066  | author:Wenbin Li, Seyedmajid Azimi, Aleš Leonardis, Mario Fritz category:cs.CV cs.AI cs.RO published:2016-03-31 summary:Understanding physical phenomena is a key competence that enables humans andanimals to act and interact under uncertain perception in previously unseenenvironments containing novel object and their configurations. Developmentalpsychology has shown that such skills are acquired by infants from observationsat a very early stage. In this paper, we contrast a more traditional approach of taking amodel-based route with explicit 3D representations and physical simulation byan end-to-end approach that directly predicts stability and related quantitiesfrom appearance. We ask the question if and to what extent and quality such askill can directly be acquired in a data-driven way bypassing the need for anexplicit simulation. We present a learning-based approach based on simulated data that predictsstability of towers comprised of wooden blocks under different conditions andquantities related to the potential fall of the towers. The evaluation iscarried out on synthetic data and compared to human judgments on the samestimuli.
arxiv-1603-09454 | Exemplar-AMMs: Recognizing Crowd Movements from Pedestrian Trajectories |  http://arxiv.org/abs/1603.09454  | author:Wenxi Liu, Rynson W. H. Lau, Xiaogang Wang, Dinesh Manocha category:cs.CV published:2016-03-31 summary:In this paper, we present a novel method to recognize the types of crowdmovement from crowd trajectories using agent-based motion models (AMMs). Ouridea is to apply a number of AMMs, referred to as exemplar-AMMs, to describethe crowd movement. Specifically, we propose an optimization framework thatfilters out the unknown noise in the crowd trajectories and measures theirsimilarity to the exemplar-AMMs to produce a crowd motion feature. We thenaddress our real-world crowd movement recognition problem as a multi-labelclassification problem. Our experiments show that the proposed featureoutperforms the state-of-the-art methods in recognizing both simulated andreal-world crowd movements from their trajectories. Finally, we have created asynthetic dataset, SynCrowd, which contains 2D crowd trajectories in variousscenarios, generated by various crowd simulators. This dataset can serve as atraining set or benchmark for crowd analysis work.
arxiv-1603-09599 | Total Variation Applications in Computer Vision |  http://arxiv.org/abs/1603.09599  | author:Vania V. Estrela, Hermes Aguiar Magalhaes, Osamu Saotome category:cs.CV published:2016-03-31 summary:The objectives of this chapter are: (i) to introduce a concise overview ofregularization; (ii) to define and to explain the role of a particular type ofregularization called total variation norm (TV-norm) in computer vision tasks;(iii) to set up a brief discussion on the mathematical background of TVmethods; and (iv) to establish a relationship between models and a few existingmethods to solve problems cast as TV-norm. For the most part, image-processingalgorithms blur the edges of the estimated images, however TV regularizationpreserves the edges with no prior information on the observed and the originalimages. The regularization scalar parameter {\lambda} controls the amount ofregularization allowed and it is an essential to obtain a high-qualityregularized output. A wide-ranging review of several ways to put into practiceTV regularization as well as its advantages and limitations are discussed.
arxiv-1603-09457 | LSTM based Conversation Models |  http://arxiv.org/abs/1603.09457  | author:Yi Luan, Yangfeng Ji, Mari Ostendorf category:cs.CL published:2016-03-31 summary:In this paper, we present a conversational model that incorporates bothcontext and participant role for two-party conversations. Differentarchitectures are explored for integrating participant role and contextinformation into a Long Short-term Memory (LSTM) language model. Theconversational model can function as a language model or a language generationmodel. Experiments on the Ubuntu Dialog Corpus show that our model can capturemultiple turn interaction between participants. The proposed method outperformsa traditional LSTM model as measured by language model perplexity and responseranking. Generated responses show characteristic differences between the twoparticipant roles.
arxiv-1603-09558 | Sub-pixel accuracy edge fitting by means of B-spline |  http://arxiv.org/abs/1603.09558  | author:R. L. B. Breder, Vania V. Estrela, J. T. de Assis category:cs.CV published:2016-03-31 summary:Local perturbations around contours strongly disturb the final result ofcomputer vision tasks. It is common to introduce a priori information in theestimation process. Improvement can be achieved via a deformable model such asthe snake model. In recent works, the deformable contour is modeled by means ofB-spline snakes which allows local control, concise representation, and the useof fewer parameters. The estimation of the sub-pixel edges using a globalB-spline model relies on the contour global determination according to amaximum likelihood framework and using the observed data likelihood. Thisprocedure guarantees that the noisiest data will be filtered out. The datalikelihood is computed as a consequence of the observation model which includesboth orientation and position information. Comparative experiments of thisalgorithm and the classical spline interpolation have shown that the proposedalgorithm outperforms the classical approach for Gaussian and Salt & Peppernoise.
arxiv-1603-09687 | Large Scale Deep Convolutional Neural Network Features Search with Lucene |  http://arxiv.org/abs/1603.09687  | author:Claudio Gennaro category:cs.CV cs.IR published:2016-03-31 summary:In this work, we propose an approach to index Deep Convolutional NeuralNetwork Features to support efficient content-based retrieval on large imagedatabases. To this aim, we have converted the these features into a textualform, to index them into an inverted index by means of Lucene. In this way, wewere able to set up a robust retrieval system that combines full-text searchwith content-based image retrieval capabilities. We evaluated differentstrategies of textual representation in order to optimize the index occupationand the query response time. In order to show that our approach is able tohandle large datasets, we have developed a web-based prototype that provides aninterface for combined textual and visual searching into a dataset of about 100million of images.
arxiv-1603-09460 | System Combination for Short Utterance Speaker Recognition |  http://arxiv.org/abs/1603.09460  | author:Lantian Li, Dong Wang, Thomas Fang Zheng category:cs.CL cs.NE published:2016-03-31 summary:Noticeable performance degradation is often observed in text-independentspeaker recognition with short test utterances. This paper presents acombination approach to improve short utterance speaker recognition (SUSR),where two phonetic-aware systems are combined together: one is the DNN-basedi-vector system and the other is the subregion-based GMM-UBM system proposed byus recently. The former employs phone posteriors to construct an i-vector modelin which the shared statistics offer stronger robustness against limited testdata. The latter establishes a phone-dependent GMM-UBM system which representsspeaker characteristics with more details. A scorelevel system combinationapproach is proposed to integrate the respective advantages of the two systems.Experimental results confirm that on the text-independent SUSR task, both theDNN-based i-vector system and the subregion-based GMM-UBM system outperformtheir respective baselines, and the score-level system combination deliverssignificant performance improvement.
arxiv-1603-09473 | Monomer: Non-Metric Mixtures-of-Embeddings for Learning Visual Compatibility Across Categories |  http://arxiv.org/abs/1603.09473  | author:Ruining He, Charles Packer, Julian McAuley category:cs.IR cs.CV cs.LG published:2016-03-31 summary:Identifying relationships between items is a key task of an onlinerecommender system, in order to help users discover items that are functionallycomplementary or visually compatible. In domains like clothing recommendation,this task is particularly challenging since a successful system should becapable of handling a large corpus of items, a huge amount of relationshipsamong them, as well as the high-dimensional and semantically complicatedfeatures involved. Furthermore, the human notion of "compatibility" that weneed to capture goes beyond mere similarity: For two items to becompatible---whether jeans and a t-shirt, or a laptop and a charger---theyshould be similar in some ways, but systematically different in others. In this paper we develop a method, Monomer, to uncover complicated andheterogeneous of relationships between items. Recently, scalable methods havebeen developed that address this task by learning embeddings of the visual andtextual characteristics of the products involved, but which ultimately dependon a nearest-neighbor assumption between the learned embeddings. Here we showthat richer notions of compatibility can be learned, principally by relaxingthe metricity assumption inherent in previous work, so as to uncover ways inwhich related items should be systematically similar, and systematicallydifferent. Quantitatively, we show that our system achieves state-of-the-artperformance on large-scale compatibility prediction tasks, especially in caseswhere there is substantial heterogeneity between related items.
arxiv-1603-09462 | Robust Uncalibrated Stereo Rectification with Constrained Geometric Distortions (USR-CGD) |  http://arxiv.org/abs/1603.09462  | author:Hyunsuk Ko, Han Suk Shim, Ouk Choi, C. -C. Jay Kuo category:cs.CV published:2016-03-31 summary:A novel algorithm for uncalibrated stereo image-pair rectification under theconstraint of geometric distortion, called USR-CGD, is presented in this work.Although it is straightforward to define a rectifying transformation (orhomography) given the epipolar geometry, many existing algorithms have unwantedgeometric distortions as a side effect. To obtain rectified images with reducedgeometric distortions while maintaining a small rectification error, weparameterize the homography by considering the influence of various kinds ofgeometric distortions. Next, we define several geometric measures andincorporate them into a new cost function for parameter optimization. Finally,we propose a constrained adaptive optimization scheme to allow a balancedperformance between the rectification error and the geometric error. Extensiveexperimental results are provided to demonstrate the superb performance of theproposed USR-CGD method, which outperforms existing algorithms by a significantmargin.
arxiv-1603-09742 | Object Boundary Guided Semantic Segmentation |  http://arxiv.org/abs/1603.09742  | author:Qin Huang, Chunyang Xia, Wenchao Zheng, Yuhang Song, Hao Xu, C. -C. Jay Kuo category:cs.CV published:2016-03-31 summary:Semantic segmentation is crucial for understanding image contents and objectlocalizations. Recent development in fully-convolutional neural network (FCN)has enabled accurate pixel-level labeling with finer results. Althoughdifferent constraints have been applied to help delineate segmentation details,previous methods majorly focus on differentiating the surface patterns ofdifferent object classes and merge those with similar properties, whichconsequently deprive the FCN based segmentation of its ability to understandand recognize the object. To tackle with this major shortage, we introduce adouble branch network, which not only learns about the object class for eachregion, but also acquires the knowledge to set up object boundaries so that amore accurate segmentation of object class and finer details could be achieved. To this end, we relabel the object contours based on ground truth of objectlabeling and use the FCN network to specially learn a three-class branch, whichis later used as a mask layer combing with original 21-class FCN. This network,called object boundary guided FCN (OBG-FCN) is then going through an end-to-endtraining, which refines the details of segmentation boundaries and classaccuracies. We apply the proposed method in the PASCAL VOC segmentation benchmark, andhave achieved state-of-the-art performance. Our pre-trained edge model hasshown to be stable and accurate even at accuracy level of FCN-2s.
arxiv-1603-09469 | A ParaBoost Stereoscopic Image Quality Assessment (PBSIQA) System |  http://arxiv.org/abs/1603.09469  | author:Hyunsuk Ko, Rui Song, C. -C. Jay Kuo category:cs.CV cs.LG published:2016-03-31 summary:The problem of stereoscopic image quality assessment, which findsapplications in 3D visual content delivery such as 3DTV, is investigated inthis work. Specifically, we propose a new ParaBoost (parallel-boosting)stereoscopic image quality assessment (PBSIQA) system. The system consists oftwo stages. In the first stage, various distortions are classified into a fewtypes, and individual quality scorers targeting at a specific distortion typeare developed. These scorers offer complementary performance in face of adatabase consisting of heterogeneous distortion types. In the second stage,scores from multiple quality scorers are fused to achieve the best overallperformance, where the fuser is designed based on the parallel boosting ideaborrowed from machine learning. Extensive experimental results are conducted tocompare the performance of the proposed PBSIQA system with those of existingstereo image quality assessment (SIQA) metrics. The developed quality metriccan serve as an objective function to optimize the performance of a 3D contentdelivery system.
arxiv-1603-09423 | Accurate Text Localization in Natural Image with Cascaded Convolutional Text Network |  http://arxiv.org/abs/1603.09423  | author:Tong He, Weilin Huang, Yu Qiao, Jian Yao category:cs.CV published:2016-03-31 summary:We introduce a new top-down pipeline for scene text detection. We propose anovel Cascaded Convolutional Text Network (CCTN) that joints two customizedconvolutional networks for coarse-to-fine text localization. The CCTN fastdetects text regions roughly from a low-resolution image, and then accuratelylocalizes text lines from each enlarged region. We cast previous characterbased detection into direct text region estimation, avoiding multiple bottom-up post-processing steps. It exhibits surprising robustness and discriminativepower by considering whole text region as detection object which providesstrong semantic information. We customize convolutional network by develop- ingrectangle convolutions and multiple in-network fusions. This enables it tohandle multi-shape and multi-scale text efficiently. Furthermore, the CCTN iscomputationally efficient by sharing convolutional computations, and high-levelproperty allows it to be invariant to various languages and multipleorientations. It achieves 0.84 and 0.86 F-measures on the ICDAR 2011 and ICDAR2013, delivering substantial improvements over state-of-the-art results [23,1].
arxiv-1603-09738 | Pessimistic Uplift Modeling |  http://arxiv.org/abs/1603.09738  | author:Atef Shaar, Talel Abdessalem, Olivier Segard category:cs.LG published:2016-03-31 summary:Uplift modeling is a machine learning technique that aims to model treatmenteffects heterogeneity. It has been used in business and health sectors topredict the effect of a specific action on a given individual. Despite itsadvantages, uplift models show high sensitivity to noise and disturbance, whichleads to unreliable results. In this paper we show different approaches toaddress the problem of uplift modeling, we demonstrate how disturbance in datacan affect uplift measurement. We propose a new approach, we call itPessimistic Uplift Modeling, that minimizes disturbance effects. We comparedour approach with the existing uplift methods, on simulated and real data-sets.The experiments show that our approach outperforms the existing approaches,especially in the case of high noise data environment.
arxiv-1603-09739 | Hierarchical Quickest Change Detection via Surrogates |  http://arxiv.org/abs/1603.09739  | author:Prithwish Chakraborty, Sathappan Muthiah, Ravi Tandon, Naren Ramakrishnan category:cs.LG cs.IT math.IT stat.ML published:2016-03-31 summary:Change detection (CD) in time series data is a critical problem as it revealchanges in the underlying generative processes driving the time series. Despitehaving received significant attention, one important unexplored aspect is howto efficiently utilize additional correlated information to improve thedetection and the understanding of changepoints. We propose hierarchicalquickest change detection (HQCD), a framework that formalizes the process ofincorporating additional correlated sources for early changepoint detection.The core ideas behind HQCD are rooted in the theory of quickest detection andHQCD can be regarded as its novel generalization to a hierarchical setting. Thesources are classified into targets and surrogates, and HQCD leverages thisstructure to systematically assimilate observed data to update changepointstatistics across layers. The decision on actual changepoints are provided byminimizing the delay while still maintaining reliability bounds. In addition,HQCD also uncovers interesting relations between changes at targets fromchanges across surrogates. We validate HQCD for reliability and performanceagainst several state-of-the-art methods for both synthetic dataset (knownchangepoints) and several real-life examples (unknown changepoints). Ourexperiments indicate that we gain significant robustness without loss ofdetection delay through HQCD. Our real-life experiments also showcase theusefulness of the hierarchical setting by connecting the surrogate sources(such as Twitter chatter) to target sources (such as Employment relatedprotests that ultimately lead to major uprisings).
arxiv-1603-09620 | Online Optimization with Costly and Noisy Measurements using Random Fourier Expansions |  http://arxiv.org/abs/1603.09620  | author:Laurens Bliek, Hans R. G. W. Verstraete, Michel Verhaegen, Sander Wahls category:cs.LG math.OC stat.ML published:2016-03-31 summary:This paper analyzes DONE, an online optimization algorithm that iterativelyminimizes an unknown function with costly and noisy measurements. The algorithmmaintains a surrogate of the unknown function in the form of a random Fourierexpansion (RFE). The surrogate is updated whenever a new measurement isavailable, and then used to determine the next measurement point. The algorithmis comparable to Bayesian optimization algorithms, but its computationalcomplexity per iteration does not depend on the number of measurements. Wederive several theoretical results that provide insight on how thehyperparameters of the algorithm should be chosen. The algorithm is compared toa Bayesian optimization algorithm for a benchmark problem and two opticsapplications, namely, optical coherence tomography and optical beam-formingnetwork tuning. It is found that the DONE algorithm is significantly fasterthan Bayesian optimization in all three discussed problems, while keeping asimilar or better performance.
arxiv-1604-00036 | Modeling Visual Compatibility through Hierarchical Mid-level Elements |  http://arxiv.org/abs/1604.00036  | author:Jose Oramas, Tinne Tuytelaars category:cs.CV published:2016-03-31 summary:In this paper we present a hierarchical method to discover mid-level elementswith the objective of modeling visual compatibility between objects. At thebase-level, our method identifies patterns of CNN activations with the aim ofmodeling different variations/styles in which objects of the classes ofinterest may occur. At the top-level, the proposed method discovers patterns ofco-occurring activations of base-level elements that define visualcompatibility between pairs of object classes. Experiments on the massiveAmazon dataset show the strength of our method at describing object classes andthe characteristics that drive the compatibility between them.
arxiv-1603-09638 | Building Better Detection with Privileged Information |  http://arxiv.org/abs/1603.09638  | author:Z. Berkay Celik, Patrick McDaniel, Rauf Izmailov, Nicolas Papernot, Ananthram Swami category:cs.CR cs.LG stat.ML published:2016-03-31 summary:Modern detection systems use sensor outputs available in the deploymentenvironment to probabilistically identify attacks. These systems are trained onpast or synthetic feature vectors to create a model of anomalous or normalbehavior. Thereafter, run-time collected sensor outputs are compared to themodel to identify attacks (or the lack of attack). While this approach todetection has been proven to be effective in many environments, it is limitedto training on only features that can be reliably collected at test-time.Hence, they fail to leverage the often vast amount of ancillary informationavailable from past forensic analysis and post-mortem data. In short, detectionsystems don't train (and thus don't learn from) features that are unavailableor too costly to collect at run-time. In this paper, we leverage recentadvances in machine learning to integrate privileged information --featuresavailable at training time, but not at run-time-- into detection algorithms. Weapply three different approaches to model training with privileged information;knowledge transfer, model influence, and distillation, and empirically validatetheir performance in a range of detection domains. Our evaluation shows thatprivileged information can increase detector precision and recall: we observean average of 4.8% decrease in detection error for malware traffic detectionover a system with no privileged information, 3.53% for fast-flux domain botdetection, 3.33% for malware classification, 11.2% for facial userauthentication. We conclude by exploring the limitations and applications ofdifferent privileged information techniques in detection systems.
arxiv-1603-09446 | Object Skeleton Extraction in Natural Images by Fusing Scale-associated Deep Side Outputs |  http://arxiv.org/abs/1603.09446  | author:Wei Shen, Kai Zhao, Yuan Jiang, Yan Wang, Zhijiang Zhang, Xiang Bai category:cs.CV published:2016-03-31 summary:Object skeleton is a useful cue for object detection, complementary to theobject contour, as it provides a structural representation to describe therelationship among object parts. While object skeleton extraction in naturalimages is a very challenging problem, as it requires the extractor to be ableto capture both local and global image context to determine the intrinsic scaleof each skeleton pixel. Existing methods rely on per-pixel based multi-scalefeature computation, which results in difficult modeling and high timeconsumption. In this paper, we present a fully convolutional network withmultiple scale-associated side outputs to address this problem. By observingthe relationship between the receptive field sizes of the sequential stages inthe network and the skeleton scales they can capture, we introduce ascale-associated side output to each stage. We impose supervision to differentstages by guiding the scale-associated side outputs toward groundtruthskeletons of different scales. The responses of the multiple scale-associatedside outputs are then fused in a scale-specific way to localize skeleton pixelswith multiple scales effectively. Our method achieves promising results on twoskeleton extraction datasets, and significantly outperforms other competitors.
arxiv-1604-00077 | Neural Attention Models for Sequence Classification: Analysis and Application to Key Term Extraction and Dialogue Act Detection |  http://arxiv.org/abs/1604.00077  | author:Sheng-syun Shen, Hung-yi Lee category:cs.CL published:2016-03-31 summary:Recurrent neural network architectures combining with attention mechanism, orneural attention model, have shown promising performance recently for the tasksincluding speech recognition, image caption generation, visual questionanswering and machine translation. In this paper, neural attention model isapplied on two sequence classification tasks, dialogue act detection and keyterm extraction. In the sequence labeling tasks, the model input is a sequence,and the output is the label of the input sequence. The major difficulty ofsequence labeling is that when the input sequence is long, it can include manynoisy or irrelevant part. If the information in the whole sequence is treatedequally, the noisy or irrelevant part may degrade the classificationperformance. The attention mechanism is helpful for sequence classificationtask because it is capable of highlighting important part among the entiresequence for the classification task. The experimental results show that withthe attention mechanism, discernible improvements were achieved in the sequencelabeling task considered here. The roles of the attention mechanism in thetasks are further analyzed and visualized in this paper.
arxiv-1603-09630 | Differentiable Pooling for Unsupervised Acoustic Model Adaptation |  http://arxiv.org/abs/1603.09630  | author:Pawel Swietojanski, Steve Renals category:cs.CL cs.LG published:2016-03-31 summary:We present a deep neural network (DNN) acoustic model including parametrisedand differentiable pooling operators. Unsupervised acoustic model adaptation iscast as the problem of updating the decision boundaries implemented by eachpooling operator. In particular, we experiment with two types of poolingparametrisations: learned $L_p$-norm pooling and weighted Gaussian pooling, inwhich the weights of both operators are treated as speaker-dependent. Weperform investigations using three different large vocabulary speechrecognition corpora: AMI meetings, TED talks and Switchboard conversationaltelephone speech. We demonstrate that differentiable pooling operators providea robust and relatively low-dimensional way to adapt acoustic models, with worderror rates reductions ranging from 5--20\% with respect to unadapted systems,which themselves are better than the baseline fully-connected DNN-basedacoustic models. We also investigate how the proposed techniques work undervarious adaptation conditions including the quality of adaptation data andcomplementarity to other feature- and model-space adaptation methods, as wellas providing an analysis of the characteristics of each of the proposedapproaches.
arxiv-1603-09584 | Sparse Representation of Multivariate Extremes with Applications to Anomaly Ranking |  http://arxiv.org/abs/1603.09584  | author:Nicolas Goix, Anne Sabourin, Stéphan Clémençon category:stat.ML published:2016-03-31 summary:Extremes play a special role in Anomaly Detection. Beyond inference andsimulation purposes, probabilistic tools borrowed from Extreme Value Theory(EVT), such as the angular measure, can also be used to design novelstatistical learning methods for Anomaly Detection/ranking. This paper proposesa new algorithm based on multivariate EVT to learn how to rank observations ina high dimensional space with respect to their degree of 'abnormality'. Theprocedure relies on an original dimension-reduction technique in the extremedomain that possibly produces a sparse representation of multivariate extremesand allows to gain insight into the dependence structure thereof, escaping thecurse of dimensionality. The representation output by the unsupervisedmethodology we propose here can be combined with any Anomaly Detectiontechnique tailored to non-extreme data. As it performs linearly with thedimension and almost linearly in the data (in O(dn log n)), it fits to largescale problems. The approach in this paper is novel in that EVT has never beenused in its multivariate version in the field of Anomaly Detection.Illustrative experimental results provide strong empirical evidence of therelevance of our approach.
arxiv-1603-09439 | The Open World of Micro-Videos |  http://arxiv.org/abs/1603.09439  | author:Phuc Xuan Nguyen, Gregory Rogez, Charless Fowlkes, Deva Ramanan category:cs.CV published:2016-03-31 summary:Micro-videos are six-second videos popular on social media networks withseveral unique properties. Firstly, because of the authoring process, theycontain significantly more diversity and narrative structure than existingcollections of video "snippets". Secondly, because they are often captured byhand-held mobile cameras, they contain specialized viewpoints includingthird-person, egocentric, and self-facing views seldom seen in traditionalproduced video. Thirdly, due to to their continuous production and publicationon social networks, aggregate micro-video content contains interestingopen-world dynamics that reflects the temporal evolution of tag topics. Theseaspects make micro-videos an appealing well of visual data for developinglarge-scale models for video understanding. We analyze a novel dataset ofmicro-videos labeled with 58 thousand tags. To analyze this data, we introduceviewpoint-specific and temporally-evolving models for video understanding,defined over state-of-the-art motion and deep visual features. We conclude thatour dataset opens up new research opportunities for large-scale video analysis,novel viewpoints, and open-world dynamics.
arxiv-1603-09643 | Multi-task Recurrent Model for Speech and Speaker Recognition |  http://arxiv.org/abs/1603.09643  | author:Zhiyuan Tang, Lantian Li, Dong Wang category:cs.CL cs.LG cs.NE stat.ML published:2016-03-31 summary:Although highly correlated, speech and speaker recognition have been regardedas two independent tasks and studied by two communities. This is certainly notthe way that people behave: we decipher both speech content and speaker traitsat the same time. This paper presents a unified model to perform speech andspeaker recognition simultaneously and altogether. The model is based on aunified neural network where the output of one task is fed to the input of theother, leading to a multi-task recurrent network. Experiments show that thejoint model outperforms the task-specific models on both the two tasks.
arxiv-1603-09441 | A Stratified Analysis of Bayesian Optimization Methods |  http://arxiv.org/abs/1603.09441  | author:Ian Dewancker, Michael McCourt, Scott Clark, Patrick Hayes, Alexandra Johnson, George Ke category:cs.LG stat.ML published:2016-03-31 summary:Empirical analysis serves as an important complement to theoretical analysisfor studying practical Bayesian optimization. Often empirical insights exposestrengths and weaknesses inaccessible to theoretical analysis. We define twometrics for comparing the performance of Bayesian optimization methods andpropose a ranking mechanism for summarizing performance within various genresor strata of test functions. These test functions serve to mimic the complexityof hyperparameter optimization problems, the most prominent application ofBayesian optimization, but with a closed form which allows for rapid evaluationand more predictable behavior. This offers a flexible and efficient way toinvestigate functions with specific properties of interest, such as oscillatorybehavior or an optimum on the domain boundary.
