arxiv-9600-1 | An Improvement to the Domain Adaptation Bound in a PAC-Bayesian context | http://arxiv.org/pdf/1501.03002v1.pdf | author:Pascal Germain, Amaury Habrard, Francois Laviolette, Emilie Morvant category:stat.ML cs.LG published:2015-01-13 summary:This paper provides a theoretical analysis of domain adaptation based on thePAC-Bayesian theory. We propose an improvement of the previous domainadaptation bound obtained by Germain et al. in two ways. We first give anothergeneralization bound tighter and easier to interpret. Moreover, we provide anew analysis of the constant term appearing in the bound that can be of highinterest for developing new algorithmic solutions.
arxiv-9600-2 | Neural Implementation of Probabilistic Models of Cognition | http://arxiv.org/pdf/1501.03209v2.pdf | author:Milad Kharratzadeh, Thomas R. Shultz category:cs.NE q-bio.NC published:2015-01-13 summary:Bayesian models of cognition hypothesize that human brains make sense of databy representing probability distributions and applying Bayes' rule to find thebest explanation for available data. Understanding the neural mechanismsunderlying probabilistic models remains important because Bayesian modelsprovide a computational framework, rather than specifying mechanisticprocesses. Here, we propose a deterministic neural-network model whichestimates and represents probability distributions from observable events --- aphenomenon related to the concept of probability matching. Our model learns torepresent probabilities without receiving any representation of them from theexternal world, but rather by experiencing the occurrence patterns ofindividual events. Our neural implementation of probability matching is pairedwith a neural module applying Bayes' rule, forming a comprehensive neuralscheme to simulate human Bayesian learning and inference. Our model alsoprovides novel explanations of base-rate neglect, a notable deviation fromBayes.
arxiv-9600-3 | $\ell_0$ Sparsifying Transform Learning with Efficient Optimal Updates and Convergence Guarantees | http://arxiv.org/pdf/1501.02859v1.pdf | author:Saiprasad Ravishankar, Yoram Bresler category:stat.ML cs.LG published:2015-01-13 summary:Many applications in signal processing benefit from the sparsity of signalsin a certain transform domain or dictionary. Synthesis sparsifying dictionariesthat are directly adapted to data have been popular in applications such asimage denoising, inpainting, and medical image reconstruction. In this work, wefocus instead on the sparsifying transform model, and study the learning ofwell-conditioned square sparsifying transforms. The proposed algorithmsalternate between a $\ell_0$ "norm"-based sparse coding step, and a non-convextransform update step. We derive the exact analytical solution for each ofthese steps. The proposed solution for the transform update step achieves theglobal minimum in that step, and also provides speedups over iterativesolutions involving conjugate gradients. We establish that our alternatingalgorithms are globally convergent to the set of local minimizers of thenon-convex transform learning problems. In practice, the algorithms areinsensitive to initialization. We present results illustrating the promisingperformance and significant speed-ups of transform learning over synthesisK-SVD in image denoising.
arxiv-9600-4 | A Modified No Search Algorithm for Fractal Image Compression | http://arxiv.org/pdf/1501.02894v2.pdf | author:Mehdi. Salarian, Babak. Mohamadinia, Jalil Rasekhi category:cs.CV cs.MM published:2015-01-13 summary:Fractal image compression has some desirable properties like high quality athigh compression ratio, fast decoding, and resolution independence. Thereforeit can be used for many applications such as texture mapping and patternrecognition and image watermarking. But it suffers from long encoding time dueto its need to find the best match between sub blocks. This time is related tothe approach that is used. In this paper we present a fast encoding Algorithmbased on no search method. Our goal is that more blocks are covered in initialstep of quad tree algorithm. Experimental result has been compared with othernew fast fractal coding methods, showing it is better in term of bit rate insame condition while the other parameters are fixed.
arxiv-9600-5 | On Generalizing the C-Bound to the Multiclass and Multi-label Settings | http://arxiv.org/pdf/1501.03001v1.pdf | author:Francois Laviolette, Emilie Morvant, Liva Ralaivola, Jean-Francis Roy category:stat.ML cs.LG published:2015-01-13 summary:The C-bound, introduced in Lacasse et al., gives a tight upper bound on therisk of a binary majority vote classifier. In this work, we present a firststep towards extending this work to more complex outputs, by providinggeneralizations of the C-bound to the multiclass and multi-label settings.
arxiv-9600-6 | Random Bits Regression: a Strong General Predictor for Big Data | http://arxiv.org/pdf/1501.02990v1.pdf | author:Yi Wang, Yi Li, Momiao Xiong, Li Jin category:stat.ML cs.LG published:2015-01-13 summary:To improve accuracy and speed of regressions and classifications, we presenta data-based prediction method, Random Bits Regression (RBR). This method firstgenerates a large number of random binary intermediate/derived features basedon the original input matrix, and then performs regularized linear/logisticregression on those intermediate/derived features to predict the outcome.Benchmark analyses on a simulated dataset, UCI machine learning repositorydatasets and a GWAS dataset showed that RBR outperforms other popular methodsin accuracy and robustness. RBR (available onhttps://sourceforge.net/projects/rbr/) is very fast and requires reasonablememories, therefore, provides a strong, robust and fast predictor in the bigdata era.
arxiv-9600-7 | Improved 8-point Approximate DCT for Image and Video Compression Requiring Only 14 Additions | http://arxiv.org/pdf/1501.02995v1.pdf | author:U. S. Potluri, A. Madanayake, R. J. Cintra, F. M. Bayer, S. Kulasekera, A. Edirisuriya category:cs.MM cs.CV cs.NA stat.ME published:2015-01-13 summary:Video processing systems such as HEVC requiring low energy consumption neededfor the multimedia market has lead to extensive development in fast algorithmsfor the efficient approximation of 2-D DCT transforms. The DCT is employed in amultitude of compression standards due to its remarkable energy compactionproperties. Multiplier-free approximate DCT transforms have been proposed thatoffer superior compression performance at very low circuit complexity. Suchapproximations can be realized in digital VLSI hardware using additions andsubtractions only, leading to significant reductions in chip area and powerconsumption compared to conventional DCTs and integer transforms. In thispaper, we introduce a novel 8-point DCT approximation that requires only 14addition operations and no multiplications. The proposed transform possesseslow computational complexity and is compared to state-of-the-art DCTapproximations in terms of both algorithm complexity and peak signal-to-noiseratio. The proposed DCT approximation is a candidate for reconfigurable videostandards such as HEVC. The proposed transform and several other DCTapproximations are mapped to systolic-array digital architectures andphysically realized as digital prototype circuits using FPGA technology andmapped to 45 nm CMOS technology.
arxiv-9600-8 | Combining Language and Vision with a Multimodal Skip-gram Model | http://arxiv.org/pdf/1501.02598v3.pdf | author:Angeliki Lazaridou, Nghia The Pham, Marco Baroni category:cs.CL cs.CV cs.LG published:2015-01-12 summary:We extend the SKIP-GRAM model of Mikolov et al. (2013a) by taking visualinformation into account. Like SKIP-GRAM, our multimodal models (MMSKIP-GRAM)build vector-based word representations by learning to predict linguisticcontexts in text corpora. However, for a restricted set of words, the modelsare also exposed to visual representations of the objects they denote(extracted from natural images), and must predict linguistic and visualfeatures jointly. The MMSKIP-GRAM models achieve good performance on a varietyof semantic benchmarks. Moreover, since they propagate visual information toall words, we use them to improve image labeling and retrieval in the zero-shotsetup, where the test concepts are never seen during model training. Finally,the MMSKIP-GRAM models discover intriguing visual properties of abstract words,paving the way to realistic implementations of embodied theories of meaning.
arxiv-9600-9 | From Visual Attributes to Adjectives through Decompositional Distributional Semantics | http://arxiv.org/pdf/1501.02714v2.pdf | author:Angeliki Lazaridou, Georgiana Dinu, Adam Liska, Marco Baroni category:cs.CL cs.CV published:2015-01-12 summary:As automated image analysis progresses, there is increasing interest inricher linguistic annotation of pictures, with attributes of objects (e.g.,furry, brown...) attracting most attention. By building on the recent"zero-shot learning" approach, and paying attention to the linguistic nature ofattributes as noun modifiers, and specifically adjectives, we show that it ispossible to tag images with attribute-denoting adjectives even when no trainingdata containing the relevant annotation are available. Our approach relies ontwo key observations. First, objects can be seen as bundles of attributes,typically expressed as adjectival modifiers (a dog is something furry, brown,etc.), and thus a function trained to map visual representations of objects tonominal labels can implicitly learn to map attributes to adjectives. Second,objects and attributes come together in pictures (the same thing is a dog andit is brown). We can thus achieve better attribute (and object) label retrievalby treating images as "visual phrases", and decomposing their linguisticrepresentation into an attribute-denoting adjective and an object-denotingnoun. Our approach performs comparably to a method exploiting manual attributeannotation, it outperforms various competitive alternatives in both attributeand object annotation, and it automatically constructs attribute-centricrepresentations that significantly improve performance in supervised objectrecognition.
arxiv-9600-10 | Scaling-up Empirical Risk Minimization: Optimization of Incomplete U-statistics | http://arxiv.org/pdf/1501.02629v4.pdf | author:Stéphan Clémençon, Aurélien Bellet, Igor Colin category:stat.ML cs.LG published:2015-01-12 summary:In a wide range of statistical learning problems such as ranking, clusteringor metric learning among others, the risk is accurately estimated by$U$-statistics of degree $d\geq 1$, i.e. functionals of the training data withlow variance that take the form of averages over $k$-tuples. From acomputational perspective, the calculation of such statistics is highlyexpensive even for a moderate sample size $n$, as it requires averaging$O(n^d)$ terms. This makes learning procedures relying on the optimization ofsuch data functionals hardly feasible in practice. It is the major goal of thispaper to show that, strikingly, such empirical risks can be replaced bydrastically computationally simpler Monte-Carlo estimates based on $O(n)$ termsonly, usually referred to as incomplete $U$-statistics, without damaging the$O_{\mathbb{P}}(1/\sqrt{n})$ learning rate of Empirical Risk Minimization (ERM)procedures. For this purpose, we establish uniform deviation results describingthe error made when approximating a $U$-process by its incomplete version underappropriate complexity assumptions. Extensions to model selection, fast ratesituations and various sampling techniques are also considered, as well as anapplication to stochastic gradient descent for ERM. Finally, numerical examplesare displayed in order to provide strong empirical evidence that the approachwe promote largely surpasses more naive subsampling techniques.
arxiv-9600-11 | A fast numerical method for max-convolution and the application to efficient max-product inference in Bayesian networks | http://arxiv.org/pdf/1501.02627v2.pdf | author:Oliver Serang category:cs.NA math.NA stat.CO stat.ME stat.ML published:2015-01-12 summary:Observations depending on sums of random variables are common throughout manyfields; however, no efficient solution is currently known for performingmax-product inference on these sums of general discrete distributions(max-product inference can be used to obtain maximum a posteriori estimates).The limiting step to max-product inference is the max-convolution problem(sometimes presented in log-transformed form and denoted as "infimalconvolution", "min-convolution", or "convolution on the tropical semiring"),for which no O(k log(k)) method is currently known. Here I present a O(klog(k)) numerical method for estimating the max-convolution of two nonnegativevectors (e.g., two probability mass functions), where k is the length of thelarger vector. This numerical max-convolution method is then demonstrated byperforming fast max-product inference on a convolution tree, a data structurefor performing fast inference given information on the sum of n discrete randomvariables in O(n k log(n k) log(n) ) steps (where each random variable has anarbitrary prior distribution on k contiguous possible states). The numericalmax-convolution method can be applied to specialized classes of hidden Markovmodels to reduce the runtime of computing the Viterbi path from n k^2 to n klog(k), and has potential application to the all-pairs shortest paths problem.
arxiv-9600-12 | EpicFlow: Edge-Preserving Interpolation of Correspondences for Optical Flow | http://arxiv.org/pdf/1501.02565v2.pdf | author:Jerome Revaud, Philippe Weinzaepfel, Zaid Harchaoui, Cordelia Schmid category:cs.CV published:2015-01-12 summary:We propose a novel approach for optical flow estimation , targeted at largedisplacements with significant oc-clusions. It consists of two steps: i) densematching by edge-preserving interpolation from a sparse set of matches; ii)variational energy minimization initialized with the dense matches. Thesparse-to-dense interpolation relies on an appropriate choice of the distance,namely an edge-aware geodesic distance. This distance is tailored to handleocclusions and motion boundaries -- two common and difficult issues for opticalflow computation. We also propose an approximation scheme for the geodesicdistance to allow fast computation without loss of performance. Subsequent tothe dense interpolation step, standard one-level variational energyminimization is carried out on the dense matches to obtain the final flowestimation. The proposed approach, called Edge-Preserving Interpolation ofCorrespondences (EpicFlow) is fast and robust to large displacements. Itsignificantly outperforms the state of the art on MPI-Sintel and performs onpar on Kitti and Middlebury.
arxiv-9600-13 | Tri-Subject Kinship Verification: Understanding the Core of A Family | http://arxiv.org/pdf/1501.02555v3.pdf | author:Xiaoqian Qin, Xiaoyang Tan, Songcan Chen category:cs.CV published:2015-01-12 summary:One major challenge in computer vision is to go beyond the modeling ofindividual objects and to investigate the bi- (one-versus-one) or tri-(one-versus-two) relationship among multiple visual entities, answering suchquestions as whether a child in a photo belongs to given parents. Thechild-parents relationship plays a core role in a family and understanding suchkin relationship would have fundamental impact on the behavior of an artificialintelligent agent working in the human world. In this work, we tackle theproblem of one-versus-two (tri-subject) kinship verification and ourcontributions are three folds: 1) a novel relative symmetric bilinear model(RSBM) introduced to model the similarity between the child and the parents, byincorporating the prior knowledge that a child may resemble a particular parentmore than the other; 2) a spatially voted method for feature selection, whichjointly selects the most discriminative features for the child-parents pair,while taking local spatial information into account; 3) a large scaletri-subject kinship database characterized by over 1,000 child-parentsfamilies. Extensive experiments on KinFaceW, Family101 and our newly releasedkinship database show that the proposed method outperforms several previousstate of the art methods, while could also be used to significantly boost theperformance of one-versus-one kinship verification when the information aboutboth parents are available.
arxiv-9600-14 | Combined modeling of sparse and dense noise for improvement of Relevance Vector Machine | http://arxiv.org/pdf/1501.02579v1.pdf | author:Martin Sundin, Saikat Chatterjee, Magnus Jansson category:stat.ML published:2015-01-12 summary:Using a Bayesian approach, we consider the problem of recovering sparsesignals under additive sparse and dense noise. Typically, sparse noise modelsoutliers, impulse bursts or data loss. To handle sparse noise, existing methodssimultaneously estimate the sparse signal of interest and the sparse noise ofno interest. For estimating the sparse signal, without the need of estimatingthe sparse noise, we construct a robust Relevance Vector Machine (RVM). In theRVM, sparse noise and ever present dense noise are treated through a combinednoise model. The precision of combined noise is modeled by a diagonal matrix.We show that the new RVM update equations correspond to a non-symmetricsparsity inducing cost function. Further, the combined modeling is found to becomputationally more efficient. We also extend the method to block-sparsesignals and noise with known and unknown block structures. Through simulations,we show the performance and computation efficiency of the new RVM in severalapplications: recovery of sparse and block sparse signals, housing priceprediction and image denoising.
arxiv-9600-15 | SPRITE: A Response Model For Multiple Choice Testing | http://arxiv.org/pdf/1501.02844v1.pdf | author:Ryan Ning, Andrew E. Waters, Christoph Studer, Richard G. Baraniuk category:stat.ML published:2015-01-12 summary:Item response theory (IRT) models for categorical response data are widelyused in the analysis of educational data, computerized adaptive testing, andpsychological surveys. However, most IRT models rely on both the assumptionthat categories are strictly ordered and the assumption that this ordering isknown a priori. These assumptions are impractical in many real-world scenarios,such as multiple-choice exams where the levels of incorrectness for thedistractor categories are often unknown. While a number of results exist on IRTmodels for unordered categorical data, they tend to have restrictive modelingassumptions that lead to poor data fitting performance in practice.Furthermore, existing unordered categorical models have parameters that aredifficult to interpret. In this work, we propose a novel methodology forunordered categorical IRT that we call SPRITE (short for stochastic polytomousresponse item model) that: (i) analyzes both ordered and unordered categories,(ii) offers interpretable outputs, and (iii) provides improved data fittingcompared to existing models. We compare SPRITE to existing item response modelsand demonstrate its efficacy on both synthetic and real-world educationaldatasets.
arxiv-9600-16 | A Dataset for Movie Description | http://arxiv.org/pdf/1501.02530v1.pdf | author:Anna Rohrbach, Marcus Rohrbach, Niket Tandon, Bernt Schiele category:cs.CV cs.CL cs.IR published:2015-01-12 summary:Descriptive video service (DVS) provides linguistic descriptions of moviesand allows visually impaired people to follow a movie along with their peers.Such descriptions are by design mainly visual and thus naturally form aninteresting data source for computer vision and computational linguistics. Inthis work we propose a novel dataset which contains transcribed DVS, which istemporally aligned to full length HD movies. In addition we also collected thealigned movie scripts which have been used in prior work and compare the twodifferent sources of descriptions. In total the Movie Description datasetcontains a parallel corpus of over 54,000 sentences and video snippets from 72HD movies. We characterize the dataset by benchmarking different approaches forgenerating video descriptions. Comparing DVS to scripts, we find that DVS isfar more visual and describes precisely what is shown rather than what shouldhappen according to the scripts created prior to movie production.
arxiv-9600-17 | Photonic Delay Systems as Machine Learning Implementations | http://arxiv.org/pdf/1501.02592v1.pdf | author:Michiel Hermans, Miguel Soriano, Joni Dambre, Peter Bienstman, Ingo Fischer category:cs.NE cs.LG published:2015-01-12 summary:Nonlinear photonic delay systems present interesting implementation platformsfor machine learning models. They can be extremely fast, offer great degrees ofparallelism and potentially consume far less power than digital processors. Sofar they have been successfully employed for signal processing using theReservoir Computing paradigm. In this paper we show that their range ofapplicability can be greatly extended if we use gradient descent withbackpropagation through time on a model of the system to optimize the inputencoding of such systems. We perform physical experiments that demonstrate thatthe obtained input encodings work well in reality, and we show that optimizedsystems perform significantly better than the common Reservoir Computingapproach. The results presented here demonstrate that common gradient descenttechniques from machine learning may well be applicable on physicalneuro-inspired analog computers.
arxiv-9600-18 | Autodetection and Classification of Hidden Cultural City Districts from Yelp Reviews | http://arxiv.org/pdf/1501.02527v1.pdf | author:Harini Suresh, Nicholas Locascio category:cs.CL cs.AI cs.IR published:2015-01-12 summary:Topic models are a way to discover underlying themes in an otherwiseunstructured collection of documents. In this study, we specifically used theLatent Dirichlet Allocation (LDA) topic model on a dataset of Yelp reviews toclassify restaurants based off of their reviews. Furthermore, we hypothesizethat within a city, restaurants can be grouped into similar "clusters" based onboth location and similarity. We used several different clustering methods,including K-means Clustering and a Probabilistic Mixture Model, in order touncover and classify districts, both well-known and hidden (i.e. cultural areaslike Chinatown or hearsay like "the best street for Italian restaurants")within a city. We use these models to display and label different clusters on amap. We also introduce a topic similarity heatmap that displays the similaritydistribution in a city to a new restaurant.
arxiv-9600-19 | Max-Cost Discrete Function Evaluation Problem under a Budget | http://arxiv.org/pdf/1501.02702v1.pdf | author:Feng Nan, Joseph Wang, Venkatesh Saligrama category:cs.LG published:2015-01-12 summary:We propose novel methods for max-cost Discrete Function Evaluation Problem(DFEP) under budget constraints. We are motivated by applications such asclinical diagnosis where a patient is subjected to a sequence of (possiblyexpensive) tests before a decision is made. Our goal is to develop strategiesfor minimizing max-costs. The problem is known to be NP hard and greedy methodsbased on specialized impurity functions have been proposed. We develop a broadclass of \emph{admissible} impurity functions that admit monomials, classes ofpolynomials, and hinge-loss functions that allow for flexible impurity designwith provably optimal approximation bounds. This flexibility is important fordatasets when max-cost can be overly sensitive to "outliers." Outliers biasmax-cost to a few examples that require a large number of tests forclassification. We design admissible functions that allow for accuracy-costtrade-off and result in $O(\log n)$ guarantees of the optimal cost among treeswith corresponding classification accuracy levels.
arxiv-9600-20 | A Survey on Recent Advances of Computer Vision Algorithms for Egocentric Video | http://arxiv.org/pdf/1501.02825v1.pdf | author:Sven Bambach category:cs.CV published:2015-01-12 summary:Recent technological advances have made lightweight, head mounted camerasboth practical and affordable and products like Google Glass show firstapproaches to introduce the idea of egocentric (first-person) video to themainstream. Interestingly, the computer vision community has only recentlystarted to explore this new domain of egocentric vision, where research canroughly be categorized into three areas: Object recognition, activitydetection/recognition, video summarization. In this paper, we try to give abroad overview about the different problems that have been addressed andcollect and compare evaluation results. Moreover, along with the emergence ofthis new domain came the introduction of numerous new and versatile benchmarkdatasets, which we summarize and compare as well.
arxiv-9600-21 | Texture Retrieval via the Scattering Transform | http://arxiv.org/pdf/1501.02655v4.pdf | author:Alexander Sagel, Dominik Meyer, Hao Shen category:cs.IR cs.CV published:2015-01-12 summary:This work studies the problem of content-based image retrieval, specifically,texture retrieval. It focuses on feature extraction and similarity measure fortexture images. Our approach employs a recently developed method, the so-calledScattering transform, for the process of feature extraction in textureretrieval. It shares a distinctive property of providing a robustrepresentation, which is stable with respect to spatial deformations. Recentwork has demonstrated its capability for texture classification, and hence as apromising candidate for the problem of texture retrieval. Moreover, we adopt a common approach of measuring the similarity of texturesby comparing the subband histograms of a filterbank transform. To this end wederive a similarity measure based on the popular Bhattacharyya Kernel. Despitethe popularity of describing histograms using parametrized probability densityfunctions, such as the Generalized Gaussian Distribution, it is unfortunatelynot applicable for describing most of the Scattering transform subbands, due tothe complex modulus performed on each one of them. In this work, we propose touse the Weibull distribution to model the Scattering subbands of descendantlayers. Our numerical experiments demonstrated the effectiveness of the proposedapproach, in comparison with several state of the arts.
arxiv-9600-22 | Navigating the Semantic Horizon using Relative Neighborhood Graphs | http://arxiv.org/pdf/1501.02670v1.pdf | author:Amaru Cuba Gyllensten, Magnus Sahlgren category:cs.CL published:2015-01-12 summary:This paper is concerned with nearest neighbor search in distributionalsemantic models. A normal nearest neighbor search only returns a ranked list ofneighbors, with no information about the structure or topology of the localneighborhood. This is a potentially serious shortcoming of the mode of queryinga distributional semantic model, since a ranked list of neighbors may conflateseveral different senses. We argue that the topology of neighborhoods insemantic space provides important information about the different senses ofterms, and that such topological structures can be used for word-senseinduction. We also argue that the topology of the neighborhoods in semanticspace can be used to determine the semantic horizon of a point, which we defineas the set of neighbors that have a direct connection to the point. Weintroduce relative neighborhood graphs as method to uncover the topologicalproperties of neighborhoods in semantic models. We also provide examples ofrelative neighborhood graphs for three well-known semantic models; the PMImodel, the GloVe model, and the skipgram model.
arxiv-9600-23 | Crowd-ML: A Privacy-Preserving Learning Framework for a Crowd of Smart Devices | http://arxiv.org/pdf/1501.02484v1.pdf | author:Jihun Hamm, Adam Champion, Guoxing Chen, Mikhail Belkin, Dong Xuan category:cs.LG cs.CR cs.DC cs.NI published:2015-01-11 summary:Smart devices with built-in sensors, computational capabilities, and networkconnectivity have become increasingly pervasive. The crowds of smart devicesoffer opportunities to collectively sense and perform computing tasks in anunprecedented scale. This paper presents Crowd-ML, a privacy-preserving machinelearning framework for a crowd of smart devices, which can solve a wide rangeof learning problems for crowdsensing data with differential privacyguarantees. Crowd-ML endows a crowdsensing system with an ability to learnclassifiers or predictors online from crowdsensing data privately with minimalcomputational overheads on devices and servers, suitable for a practical andlarge-scale employment of the framework. We analyze the performance and thescalability of Crowd-ML, and implement the system with off-the-shelfsmartphones as a proof of concept. We demonstrate the advantages of Crowd-MLwith real and simulated experiments under various conditions.
arxiv-9600-24 | Identifiability and optimal rates of convergence for parameters of multiple types in finite mixtures | http://arxiv.org/pdf/1501.02497v1.pdf | author:Nhat Ho, XuanLong Nguyen category:math.ST stat.ML stat.TH published:2015-01-11 summary:This paper studies identifiability and convergence behaviors for parametersof multiple types in finite mixtures, and the effects of model fitting withextra mixing components. First, we present a general theory for strongidentifiability, which extends from the previous work of Nguyen [2013] and Chen[1995] to address a broad range of mixture models and to handle matrix-variateparameters. These models are shown to share the same Wasserstein distance basedoptimal rates of convergence for the space of mixing distributions ---$n^{-1/2}$ under $W_1$ for the exact-fitted and $n^{-1/4}$ under $W_2$ for theover-fitted setting, where $n$ is the sample size. This theory, however, is notapplicable to several important model classes, including location-scalemultivariate Gaussian mixtures, shape-scale Gamma mixtures andlocation-scale-shape skew-normal mixtures. The second part of this work isdevoted to demonstrating that for these "weakly identifiable" classes,algebraic structures of the density family play a fundamental role indetermining convergence rates of the model parameters, which display a veryrich spectrum of behaviors. For instance, the optimal rate of parameterestimation in an over-fitted location-covariance Gaussian mixture is preciselydetermined by the order of a solvable system of polynomial equations --- theserates deteriorate rapidly as more extra components are added to the model. Theestablished rates for a variety of settings are illustrated by a simulationstudy.
arxiv-9600-25 | A Gaussian Particle Filter Approach for Sensors to Track Multiple Moving Targets | http://arxiv.org/pdf/1501.02411v1.pdf | author:Haojun Li category:cs.LG published:2015-01-11 summary:In a variety of problems, the number and state of multiple moving targets areunknown and are subject to be inferred from their measurements obtained by asensor with limited sensing ability. This type of problems is raised in avariety of applications, including monitoring of endangered species, cleaning,and surveillance. Particle filters are widely used to estimate target statefrom its prior information and its measurements that recently become available,especially for the cases when the measurement model and the prior distributionof state of interest are non-Gaussian. However, the problem of estimatingnumber of total targets and their state becomes intractable when the number oftotal targets and the measurement-target association are unknown. This paperpresents a novel Gaussian particle filter technique that combines Kalman filterand particle filter for estimating the number and state of total targets basedon the measurement obtained online. The estimation is represented by a set ofweighted particles, different from classical particle filter, where eachparticle is a Gaussian distribution instead of a point mass.
arxiv-9600-26 | Online Handwritten Devanagari Stroke Recognition Using Extended Directional Features | http://arxiv.org/pdf/1501.02887v1.pdf | author:Lajish VL, Sunil Kumar Kopparapu category:cs.CV published:2015-01-11 summary:This paper describes a new feature set, called the extended directionalfeatures (EDF) for use in the recognition of online handwritten strokes. We useEDF specifically to recognize strokes that form a basis for producingDevanagari script, which is the most widely used Indian language script. Itshould be noted that stroke recognition in handwritten script is equivalent tophoneme recognition in speech signals and is generally very poor and of theorder of 20% for singing voice. Experiments are conducted for the automaticrecognition of isolated handwritten strokes. Initially we describe the proposedfeature set, namely EDF and then show how this feature can be effectivelyutilized for writer independent script recognition through stroke recognition.Experimental results show that the extended directional feature set performswell with about 65+% stroke level recognition accuracy for writer independentdata set.
arxiv-9600-27 | Fast and optimal nonparametric sequential design for astronomical observations | http://arxiv.org/pdf/1501.02467v1.pdf | author:Justin J. Yang, Xufei Wang, Pavlos Protopapas, Luke Bornn category:stat.ME stat.AP stat.ML published:2015-01-11 summary:The spectral energy distribution (SED) is a relatively easy way forastronomers to distinguish between different astronomical objects such asgalaxies, black holes, and stellar objects. By comparing the observations froma source at different frequencies with template models, astronomers are able toinfer the type of this observed object. In this paper, we take a Bayesian modelaveraging perspective to learn astronomical objects, employing a Bayesiannonparametric approach to accommodate the deviation from convex combinations ofknown log-SEDs. To effectively use telescope time for observations, we thenstudy Bayesian nonparametric sequential experimental design without conjugacy,in which we use sequential Monte Carlo as an efficient tool to maximize thevolume of information stored in the posterior distribution of the parameters ofinterest. A new technique for performing inferences in log-Gaussian Coxprocesses called the Poisson log-normal approximation is also proposed.Simulations show the speed, accuracy, and usefulness of our method. While thestrategy we propose in this paper is brand new in the astronomy literature, theinferential techniques developed apply to more general nonparametric sequentialexperimental design problems.
arxiv-9600-28 | Learning a Fuzzy Hyperplane Fat Margin Classifier with Minimum VC dimension | http://arxiv.org/pdf/1501.02432v1.pdf | author:Jayadeva, Sanjit Singh Batra, Siddarth Sabharwal category:cs.LG I.5.1; I.5.2 published:2015-01-11 summary:The Vapnik-Chervonenkis (VC) dimension measures the complexity of a learningmachine, and a low VC dimension leads to good generalization. The recentlyproposed Minimal Complexity Machine (MCM) learns a hyperplane classifier byminimizing an exact bound on the VC dimension. This paper extends the MCMclassifier to the fuzzy domain. The use of a fuzzy membership is known toreduce the effect of outliers, and to reduce the effect of noise on learning.Experimental results show, that on a number of benchmark datasets, the thefuzzy MCM classifier outperforms SVMs and the conventional MCM in terms ofgeneralization, and that the fuzzy MCM uses fewer support vectors. On severalbenchmark datasets, the fuzzy MCM classifier yields excellent test setaccuracies while using one-tenth the number of support vectors used by SVMs.
arxiv-9600-29 | Simplified vision based automatic navigation for wheat harvesting in low income economies | http://arxiv.org/pdf/1501.02376v1.pdf | author:Muhammad Zubair Ahmad, Ayyaz Akhtar, Abdul Qadeer Khan, Amir A. Khan category:cs.RO cs.CV cs.CY published:2015-01-10 summary:Recent developments in the domain of agricultural robotics have resulted indevelopment of complex and efficient systems. Most of the land owners in theSouth Asian region are low income farmers. The agricultural experience for themis still a completely manual process. However, the extreme weather conditions,heat and flooding, often combine to put a lot of stress on these small landowners and the associated labor. In this paper, we propose a prototype for anautomated power reaper for the wheat crop. This automated vehicle is navigatedusing a simple vision based approach employing the low-cost camera and assistedGPS. The mechanical platform is driven by three motors controlled through aninterface between the proposed vision algorithm and the electrical drive. Theproposed methodology is applied on some real field scenarios to demonstrate theefficiency of the vision based algorithm.
arxiv-9600-30 | On the Distribution of Salient Objects in Web Images and its Influence on Salient Object Detection | http://arxiv.org/pdf/1501.03383v1.pdf | author:Boris Schauerte, Rainer Stiefelhagen category:cs.CV published:2015-01-10 summary:It has become apparent that a Gaussian center bias can serve as an importantprior for visual saliency detection, which has been demonstrated for predictinghuman eye fixations and salient object detection. Tseng et al. have shown thatthe photographer's tendency to place interesting objects in the center is alikely cause for the center bias of eye fixations. We investigate the influenceof the photographer's center bias on salient object detection, extending ourprevious work. We show that the centroid locations of salient objects inphotographs of Achanta and Liu's data set in fact correlate strongly with aGaussian model. This is an important insight, because it provides an empiricalmotivation and justification for the integration of such a center bias insalient object detection algorithms and helps to understand why Gaussian modelsare so effective. To assess the influence of the center bias on salient objectdetection, we integrate an explicit Gaussian center bias model into twostate-of-the-art salient object detection algorithms. This way, first, wequantify the influence of the Gaussian center bias on pixel- and segment-basedsalient object detection. Second, we improve the performance in terms of F1score, Fb score, area under the recall-precision curve, area under the receiveroperating characteristic curve, and hit-rate on the well-known data set byAchanta and Liu. Third, by debiasing Cheng et al.'s region contrast model, weexemplarily demonstrate that implicit center biases are partially responsiblefor the outstanding performance of state-of-the-art algorithms. Last but notleast, as a result of debiasing Cheng et al.'s algorithm, we introduce anon-biased salient object detection method, which is of interest forapplications in which the image data is not likely to have a photographer'scenter bias (e.g., image data of surveillance cameras or autonomous robots).
arxiv-9600-31 | Low Cost Semi-Autonomous Agricultural Robots In Pakistan-Vision Based Navigation Scalable methodology for wheat harvesting | http://arxiv.org/pdf/1501.02378v1.pdf | author:Muhammad Zubair Ahmad, Ayyaz Akhtar, Abdul Qadeer Khan, Amir Ali Khan, Muhammad Murtaza Khan category:cs.RO cs.CV cs.CY published:2015-01-10 summary:Robots have revolutionized our way of life in recent years.One of the domainsthat has not yet completely benefited from the robotic automation is theagricultural sector. Agricultural Robotics should complement humans in thearduous tasks during different sub-domains of this sector. Extensive researchin Agricultural Robotics has been carried out in Japan, USA, Australia andGermany focusing mainly on the heavy agricultural machinery. Pakistan is anagricultural rich country and its economy and food security are closely tiedwith agriculture in general and wheat in particular. However, agriculturalresearch in Pakistan is still carried out using the conventional methodologies.This paper is an attempt to trigger the research in this modern domain so thatwe can benefit from cost effective and resource efficient autonomousagricultural methodologies. This paper focuses on a scalable low costsemi-autonomous technique for wheat harvest which primarily focuses on thefarmers with small land holdings. The main focus will be on the vision part ofthe navigation system deployed by the proposed robot.
arxiv-9600-32 | Riemannian Metric Learning for Symmetric Positive Definite Matrices | http://arxiv.org/pdf/1501.02393v1.pdf | author:Raviteja Vemulapalli, David W. Jacobs category:cs.CV cs.LG published:2015-01-10 summary:Over the past few years, symmetric positive definite (SPD) matrices have beenreceiving considerable attention from computer vision community. Though variousdistance measures have been proposed in the past for comparing SPD matrices,the two most widely-used measures are affine-invariant distance andlog-Euclidean distance. This is because these two measures are true geodesicdistances induced by Riemannian geometry. In this work, we focus on thelog-Euclidean Riemannian geometry and propose a data-driven approach forlearning Riemannian metrics/geodesic distances for SPD matrices. We show thatthe geodesic distance learned using the proposed approach performs better thanvarious existing distance measures when evaluated on face matching andclustering tasks.
arxiv-9600-33 | Efficient Rotation-Scaling-Translation Parameters Estimation Based on Fractal Image Model | http://arxiv.org/pdf/1501.02372v2.pdf | author:M. Uss, B. Vozel, V. Lukin, K. Chehdi category:cs.CV published:2015-01-10 summary:This paper deals with area-based subpixel image registration underrotation-isometric scaling-translation transformation hypothesis. Our approachis based on a parametrical modeling of geometrically transformed textural imagefragments and maximum likelihood estimation of transformation vector betweenthem. Due to the parametrical approach based on the fractional Brownian motionmodeling of the local fragments texture, the proposed estimator MLfBm (MLstands for "Maximum Likelihood" and fBm for "Fractal Brownian motion") has theability to better adapt to real image texture content compared to other methodsrelying on universal similarity measures like mutual information or normalizedcorrelation. The main benefits are observed when assumptions underlying the fBmmodel are fully satisfied, e.g. for isotropic normally distributed textureswith stationary increments. Experiments on both simulated and real images andfor high and weak correlation between registered images show that the MLfBmestimator offers significant improvement compared to other state-of-the-artmethods. It reduces translation vector, rotation angle and scaling factorestimation errors by a factor of about 1.75...2 and it decreases probability offalse match by up to 5 times. Besides, an accurate confidence interval forMLfBm estimates can be obtained from the Cramer-Rao lower bound onrotation-scaling-translation parameters estimation error. This bound depends ontexture roughness, noise level in reference and template images, correlationbetween these images and geometrical transformation parameters.
arxiv-9600-34 | Autonomous Farm Vehicles: Prototype of Power Reaper | http://arxiv.org/pdf/1501.02379v1.pdf | author:Abdul Qadeer Khan, Ayyaz Akhtar, Muhammad Zubair Ahmad category:cs.RO cs.CV cs.CY published:2015-01-10 summary:Chapter 2 will begin with introduction of Agricultural Robotics. There willbe a literature review of the mechanical structure, vision and controlalgorithms. In chapter 3 we will discuss the methodology in detail using blockdiagrams and flowcharts. The results of the tested and the proposed algorithmswill also be displayed. In chapter 4 we will discuss the results in detail andhow they are of significance in our work. In chapter 5 we will conclude ourwork and discuss some future perspectives. In appendices we will provide somebackground information necessary regarding this project.
arxiv-9600-35 | On model misspecification and KL separation for Gaussian graphical models | http://arxiv.org/pdf/1501.02320v2.pdf | author:Varun Jog, Po-Ling Loh category:cs.IT math.IT math.ST stat.ML stat.TH 62B10 published:2015-01-10 summary:We establish bounds on the KL divergence between two multivariate Gaussiandistributions in terms of the Hamming distance between the edge sets of thecorresponding graphical models. We show that the KL divergence is bounded belowby a constant when the graphs differ by at least one edge; this is essentiallythe tightest possible bound, since classes of graphs exist for which the edgediscrepancy increases but the KL divergence remains bounded above by aconstant. As a natural corollary to our KL lower bound, we also establish asample size requirement for correct model selection via maximum likelihoodestimation. Our results rigorize the notion that it is essential to estimatethe edge structure of a Gaussian graphical model accurately in order toapproximate the true distribution to close precision.
arxiv-9600-36 | HOG based Fast Human Detection | http://arxiv.org/pdf/1501.02058v1.pdf | author:M. Kachouane, S. Sahki, M. Lakrouf, N. Ouadah category:cs.RO cs.CV cs.LG published:2015-01-09 summary:Objects recognition in image is one of the most difficult problems incomputer vision. It is also an important step for the implementation of severalexisting applications that require high-level image interpretation. Therefore,there is a growing interest in this research area during the last years. Inthis paper, we present an algorithm for human detection and recognition inreal-time, from images taken by a CCD camera mounted on a car-like mobilerobot. The proposed technique is based on Histograms of Oriented Gradient (HOG)and SVM classifier. The implementation of our detector has provided goodresults, and can be used in robotics tasks.
arxiv-9600-37 | Survey schemes for stochastic gradient descent with applications to M-estimation | http://arxiv.org/pdf/1501.02218v1.pdf | author:Stéphan Clémençon, Patrice Bertail, Emilie Chautru, Guillaume Papa category:stat.ML published:2015-01-09 summary:In certain situations that shall be undoubtedly more and more common in theBig Data era, the datasets available are so massive that computing statisticsover the full sample is hardly feasible, if not unfeasible. A natural approachin this context consists in using survey schemes and substituting the "fulldata" statistics with their counterparts based on the resulting random samples,of manageable size. It is the main purpose of this paper to investigate theimpact of survey sampling with unequal inclusion probabilities on stochasticgradient descent-based M-estimation methods in large-scale statistical andmachine-learning problems. Precisely, we prove that, in presence of some apriori information, one may significantly increase asymptotic accuracy whenchoosing appropriate first order inclusion probabilities, without affectingcomplexity. These striking results are described here by limit theorems and arealso illustrated by numerical experiments.
arxiv-9600-38 | Investigation of a chaotic spiking neuron model | http://arxiv.org/pdf/1501.02192v1.pdf | author:M. Alhawarat, T. Olde Scheper, N. T. Crook category:cs.NE cs.AI published:2015-01-09 summary:Chaos provides many interesting properties that can be used to achievecomputational tasks. Such properties are sensitivity to initial conditions,space filling, control and synchronization. Chaotic neural models have beendevised to exploit such properties. In this paper, a chaotic spiking neuronmodel is investigated experimentally. This investigation is performed tounderstand the dynamic behaviours of the model. The aim of this research is to investigate the dynamics of the nonlineardynamic state neuron (NDS) experimentally. The experimental approach hasrevealed some quantitative and qualitative properties of the NDS model such asthe control mechanism, the reset mechanism, and the way the model may exhibitdynamic behaviours in phase space. It is shown experimentally in this paperthat both the reset mechanism and the self-feed back control mechanism areimportant for the NDS model to work and to stabilise to one of the large numberof available unstable periodic orbits (UPOs) that are embedded in itsattractor. The experimental investigation suggests that the internal dynamicsof the NDS neuron provide a rich set of dynamic behaviours that can becontrolled and stabilised. These wide range of dynamic behaviours may beexploited to carry out information processing tasks.
arxiv-9600-39 | Introduction and Ranking Results of the ICSI 2014 Competition on Single Objective Optimization | http://arxiv.org/pdf/1501.02128v1.pdf | author:Ying Tan, Junzhi Li, Zhongyang Zheng category:cs.NE published:2015-01-09 summary:This technical report includes the introduction and ranking results of theICSI 2014 Competition on Single Objective Optimization.
arxiv-9600-40 | Filter Design and Performance Evaluation for Fingerprint Image Segmentation | http://arxiv.org/pdf/1501.02113v1.pdf | author:Duy Hoang Thai, Stephan Huckemann, Carsten Gottschlich category:cs.CV published:2015-01-09 summary:Fingerprint recognition plays an important role in many commercialapplications and is used by millions of people every day, e.g. for unlockingmobile phones. Fingerprint image segmentation is typically the first processingstep of most fingerprint algorithms and it divides an image into foreground,the region of interest, and background. Two types of error can occur duringthis step which both have a negative impact on the recognition performance:'true' foreground can be labeled as background and features like minutiae canbe lost, or conversely 'true' background can be misclassified as foreground andspurious features can be introduced. The contribution of this paper isthreefold: firstly, we propose a novel factorized directional bandpass (FDB)segmentation method for texture extraction based on the directional Hilberttransform of a Butterworth bandpass (DHBB) filter interwoven withsoft-thresholding. Secondly, we provide a manually marked ground truthsegmentation for 10560 images as an evaluation benchmark. Thirdly, we conduct asystematic performance comparison between the FDB method and four of the mostoften cited fingerprint segmentation algorithms showing that the FDBsegmentation method clearly outperforms these four widely used methods. Thebenchmark and the implementation of the FDB method are made publicly available.
arxiv-9600-41 | Equitability of Dependence Measure | http://arxiv.org/pdf/1501.02102v2.pdf | author:Hangjin Jiang, Kan Liu, Yiming Ding category:stat.ML published:2015-01-09 summary:A measure of dependence is said to be equitable if it gives similar scores toequally noisy relationship of different types. In practice, we do not know whatkind of functional relationship is underlying two given observations, Hence theequitability of dependence measure is critical in analysis and by scoringrelationships according to an equitable measure one hopes to find importantpatterns of any type of further examination. In this paper, we introduce ourdefinition of equitability of a dependence measure, which is naturally fromthis initial description, and Further more power-equitable(weak-equitable) isintroduced which is of the most practical meaning in evaluating the equitablityof a dependence measure.
arxiv-9600-42 | Sequential Kernel Herding: Frank-Wolfe Optimization for Particle Filtering | http://arxiv.org/pdf/1501.02056v2.pdf | author:Simon Lacoste-Julien, Fredrik Lindsten, Francis Bach category:stat.ML cs.LG published:2015-01-09 summary:Recently, the Frank-Wolfe optimization algorithm was suggested as a procedureto obtain adaptive quadrature rules for integrals of functions in a reproducingkernel Hilbert space (RKHS) with a potentially faster rate of convergence thanMonte Carlo integration (and "kernel herding" was shown to be a special case ofthis procedure). In this paper, we propose to replace the random sampling stepin a particle filter by Frank-Wolfe optimization. By optimizing the position ofthe particles, we can obtain better accuracy than random or quasi-Monte Carlosampling. In applications where the evaluation of the emission probabilities isexpensive (such as in robot localization), the additional computational cost togenerate the particles through optimization can be justified. Experiments onstandard synthetic examples as well as on a robot localization task indicateindeed an improvement of accuracy over random and quasi-Monte Carlo sampling.
arxiv-9600-43 | Margins of discrete Bayesian networks | http://arxiv.org/pdf/1501.02103v1.pdf | author:Robin J. Evans category:math.ST stat.ML stat.TH published:2015-01-09 summary:In this paper we provide a complete algebraic characterization of the modelimplied by a Bayesian network with latent variables when the observed variablesare discrete. We show that it is algebraically equivalent to the so-callednested Markov model, meaning that the two are the same up to inequalityconstraints on the joint probabilities. The nested Markov model is thereforethe best possible approximation to the latent variable model whilst avoidinginequalities, which are extremely complicated in general. Latent variablemodels also suffer from difficulties of unidentifiable parameters andnon-regular asymptotics; in contrast the nested Markov model is fullyidentifiable, represents a curved exponential family of known dimension, andcan easily be fitted using an explicit parameterization.
arxiv-9600-44 | Less is More: Building Selective Anomaly Ensembles | http://arxiv.org/pdf/1501.01924v1.pdf | author:Shebuti Rayana, Leman Akoglu category:cs.DB cs.LG published:2015-01-08 summary:Ensemble techniques for classification and clustering have long proveneffective, yet anomaly ensembles have been barely studied. In this work, we tapinto this gap and propose a new ensemble approach for anomaly mining, withapplication to event detection in temporal graphs. Our method aims to combineresults from heterogeneous detectors with varying outputs, and leverage theevidence from multiple sources to yield better performance. However, trustingall the results may deteriorate the overall ensemble accuracy, as somedetectors may fall short and provide inaccurate results depending on the natureof the data in hand. This suggests that being selective in which results tocombine is vital in building effective ensembles---hence "less is more". In this paper we propose SELECT; an ensemble approach for anomaly mining thatemploys novel techniques to automatically and systematically select the resultsto assemble in a fully unsupervised fashion. We apply our method to eventdetection in temporal graphs, where SELECT successfully utilizes five basedetectors and seven consensus methods under a unified ensemble framework. Weprovide extensive quantitative evaluation of our approach on five real-worlddatasets (four with ground truth), including Enron email communications, NewYork Times news corpus, and World Cup 2014 Twitter news feed. Thanks to itsselection mechanism, SELECT yields superior performance compared to individualdetectors alone, the full ensemble (naively combining all results), and anexisting diversity-based ensemble.
arxiv-9600-45 | Quantifying Scripts: Defining metrics of characters for quantitative and descriptive analysis | http://arxiv.org/pdf/1501.01894v1.pdf | author:Vinodh Rajan category:cs.CL published:2015-01-08 summary:Analysis of scripts plays an important role in paleography and inquantitative linguistics. Especially in the field of digital paleographyquantitative features are much needed to differentiate glyphs. We describe anelaborate set of metrics that quantify qualitative information contained incharacters and hence indirectly also quantify the scribal features. We broadlydivide the metrics into several categories and describe each individual metricwith its underlying qualitative significance. The metrics are largely derivedfrom the related area of gesture design and recognition. We also proposeseveral novel metrics. The proposed metrics are soundly grounded on theprinciples of handwriting production and handwriting analysis. These computedmetrics could serve as descriptors for scripts and also be used for comparingand analyzing scripts. We illustrate some quantitative analysis based on theproposed metrics by applying it to the paleographic evolution of the medievalTamil script from Brahmi. We also outline future work.
arxiv-9600-46 | The Hebrew Bible as Data: Laboratory - Sharing - Experiences | http://arxiv.org/pdf/1501.01866v1.pdf | author:Dirk Roorda category:cs.CL cs.DL published:2015-01-08 summary:The systematic study of ancient texts including their production,transmission and interpretation is greatly aided by the digital methods thatstarted taking off in the 1970s. But how is that research in turn transmittedto new generations of researchers? We tell a story of Bible and computer acrossthe decades and then point out the current challenges: (1) finding a stabledata representation for changing methods of computation; (2) sharing results ininter- and intra-disciplinary ways, for reproducibility andcross-fertilization. We report recent developments in meeting these challenges.The scene is the text database of the Hebrew Bible, constructed by the EepTalstra Centre for Bible and Computer (ETCBC), which is still growing in detailand sophistication. We show how a subtle mix of computational ingredientsenable scholars to research the transmission and interpretation of the HebrewBible in new ways: (1) a standard data format, Linguistic Annotation Framework(LAF); (2) the methods of scientific computing, made accessible by(interactive) Python and its associated ecosystem. Additionally, we show howthese efforts have culminated in the construction of a new, publicly accessiblesearch engine SHEBANQ, where the text of the Hebrew Bible and its underlyingdata can be queried in a simple, yet powerful query language MQL, and wherethose queries can be saved and shared.
arxiv-9600-47 | Optimal Radiometric Calibration for Camera-Display Communication | http://arxiv.org/pdf/1501.01744v1.pdf | author:Wenjia Yuan, Eric Wengrowski, Kristin J. Dana, Ashwin Ashok, Marco Gruteser, Narayan Mandayam category:cs.CV published:2015-01-08 summary:We present a novel method for communicating between a camera and display byembedding and recovering hidden and dynamic information within a displayedimage. A handheld camera pointed at the display can receive not only thedisplay image, but also the underlying message. These active scenes arefundamentally different from traditional passive scenes like QR codes becauseimage formation is based on display emittance, not surface reflectance.Detecting and decoding the message requires careful photometric modeling forcomputational message recovery. Unlike standard watermarking and steganographymethods that lie outside the domain of computer vision, our message recoveryalgorithm uses illumination to optically communicate hidden messages in realworld scenes. The key innovation of our approach is an algorithm that performssimultaneous radiometric calibration and message recovery in one convexoptimization problem. By modeling the photometry of the system using acamera-display transfer function (CDTF), we derive a physics-based kernelfunction for support vector machine classification. We demonstrate that ourmethod of optimal online radiometric calibration (OORC) leads to an efficientand robust algorithm for computational messaging between nine commercialcameras and displays.
arxiv-9600-48 | An Effective Image Feature Classiffication using an improved SOM | http://arxiv.org/pdf/1501.01723v1.pdf | author:M. Abdelsamea, Marghny H. Mohamed, Mohamed Bamatraf category:cs.CV published:2015-01-08 summary:Image feature classification is a challenging problem in many computer visionapplications, specifically, in the fields of remote sensing, image analysis andpattern recognition. In this paper, a novel Self Organizing Map, termedimproved SOM (iSOM), is proposed with the aim of effectively classifyingMammographic images based on their texture feature representation. The maincontribution of the iSOM is to introduce a new node structure for the maprepresentation and adopting a learning technique based on Kohonen SOMaccordingly. The main idea is to control, in an unsupervised fashion, theweight updating procedure depending on the class reliability of the node,during the weight update time. Experiments held on a real Mammographic images.Results showed high accuracy compared to classical SOM and other state-of-artclassifiers.
arxiv-9600-49 | Super-resolution MRI Using Finite Rate of Innovation Curves | http://arxiv.org/pdf/1501.01697v2.pdf | author:Greg Ongie, Mathews Jacob category:cs.CV published:2015-01-08 summary:We propose a two-stage algorithm for the super-resolution of MR images fromtheir low-frequency k-space samples. In the first stage we estimate aresolution-independent mask whose zeros represent the edges of the image. Thisbuilds off recent work extending the theory of sampling signals of finite rateof innovation (FRI) to two-dimensional curves. We enable its application to MRIby proposing extensions of the signal models allowed by FRI theory, and bydeveloping a more robust and efficient means to determine the edge mask. In thesecond stage of the scheme, we recover the super-resolved MR image using thediscretized edge mask as an image prior. We evaluate our scheme on simulatedsingle-coil MR data obtained from analytical phantoms, and compare againsttotal variation reconstructions. Our experiments show improved performance inboth noiseless and noisy settings.
arxiv-9600-50 | Weighted Schatten $p$-Norm Minimization for Image Denoising with Local and Nonlocal Regularization | http://arxiv.org/pdf/1501.01372v4.pdf | author:Yuan Xie category:cs.CV published:2015-01-07 summary:This paper presents a patch-wise low-rank based image denoising method withconstrained variational model involving local and nonlocal regularization. Onone hand, recent patch-wise methods can be represented as a low-rank matrixapproximation problem whose convex relaxation usually depends on nuclear normminimization (NNM). Here, we extend the NNM to the nonconvex schatten p-normminimization with additional weights assigned to different singular values,which is referred to as the Weighted Schatten p-Norm Minimization (WSNM). Anefficient algorithm is also proposed to solve the WSNM problem. The proposedWSNM not only gives better approximation to the original low-rank assumption,but also considers physical meanings of different data components. On the otherhand, due to the naive aggregation schema which integrates all the denoisedpatches into a whole image, current patch-wise denoising methods always producevarious degree of artifacts in denoised results. Therefore, to further reduceartifacts, a data-driven regularizer called Steering Total Variation (STV)combined with nonlocal TV is derived for a variational model, which imposeslocal and nonlocal consistency constraints on the patch-wise denoised image. Ahighly simple but efficient algorithm is proposed to solve this variationalmodel with convergence guarantee. Both WSNM and local \& nonlocal consistentregularization are integrated into an iterative restoration framework toproduce final results. Extensive experimental testing shows, both qualitativelyand quantitatively, that the proposed method can effectively remove noise, aswell as reduce artifacts compared with state-of-the-art methods.
arxiv-9600-51 | Sparse Solutions to Nonnegative Linear Systems and Applications | http://arxiv.org/pdf/1501.01689v1.pdf | author:Aditya Bhaskara, Ananda Theertha Suresh, Morteza Zadimoghaddam category:cs.DS cs.IT cs.LG math.IT published:2015-01-07 summary:We give an efficient algorithm for finding sparse approximate solutions tolinear systems of equations with nonnegative coefficients. Unlike most knownresults for sparse recovery, we do not require {\em any} assumption on thematrix other than non-negativity. Our algorithm is combinatorial in nature,inspired by techniques for the set cover problem, as well as the multiplicativeweight update method. We then present a natural application to learning mixture models in the PACframework. For learning a mixture of $k$ axis-aligned Gaussians in $d$dimensions, we give an algorithm that outputs a mixture of $O(k/\epsilon^3)$Gaussians that is $\epsilon$-close in statistical distance to the truedistribution, without any separation assumptions. The time and samplecomplexity is roughly $O(kd/\epsilon^3)^{d}$. This is polynomial when $d$ isconstant -- precisely the regime in which known methods fail to identify thecomponents efficiently. Given that non-negativity is a natural assumption, we believe that our resultmay find use in other settings in which we wish to approximately explain datausing a small number of a (large) candidate set of components.
arxiv-9600-52 | An Introduction to Matrix Concentration Inequalities | http://arxiv.org/pdf/1501.01571v1.pdf | author:Joel A. Tropp category:math.PR cs.DS cs.IT cs.NA math.IT stat.ML published:2015-01-07 summary:In recent years, random matrices have come to play a major role incomputational mathematics, but most of the classical areas of random matrixtheory remain the province of experts. Over the last decade, with the advent ofmatrix concentration inequalities, research has advanced to the point where wecan conquer many (formerly) challenging problems with a page or two ofarithmetic. The aim of this monograph is to describe the most successfulmethods from this area along with some interesting examples that thesetechniques can illuminate.
arxiv-9600-53 | Comparison of Selection Methods in On-line Distributed Evolutionary Robotics | http://arxiv.org/pdf/1501.01457v1.pdf | author:Iñaki Fernández Pérez, Amine Boumaza, François Charpillet category:cs.AI cs.MA cs.NE cs.RO published:2015-01-07 summary:In this paper, we study the impact of selection methods in the context ofon-line on-board distributed evolutionary algorithms. We propose a variant ofthe mEDEA algorithm in which we add a selection operator, and we apply it in ataskdriven scenario. We evaluate four selection methods that induce differentintensity of selection pressure in a multi-robot navigation with obstacleavoidance task and a collective foraging task. Experiments show that a smallintensity of selection pressure is sufficient to rapidly obtain goodperformances on the tasks at hand. We introduce different measures to comparethe selection methods, and show that the higher the selection pressure, thebetter the performances obtained, especially for the more challenging foodforaging task.
arxiv-9600-54 | Implementation of Auto Monitoring and Short-Message-Service System via GSM Modem | http://arxiv.org/pdf/1501.01548v2.pdf | author:Akilan Thangarajah, Buddhapala Wongkaew, Mongkol Ekpanyapong category:cs.CV published:2015-01-07 summary:Auto-Monitoring and Short-Messaging-Service System is a real-time monitoringsystem for any critical operational environments. It detects an undesired eventoccurring in the environment, generates an alert with detailed message andsends it to the user to prevent hazards. This system employs a Friendly ARM asmain controller while, sensors and terminals to interact with the real world. AGSM network is utilized to bridge the communication between monitoring systemand user. This paper presents details of prototyping the system.
arxiv-9600-55 | Roman Urdu Opinion Mining System (RUOMiS) | http://arxiv.org/pdf/1501.01386v1.pdf | author:Misbah Daud, Rafiullah Khan, Mohibullah, Aitazaz Daud category:cs.CL cs.IR published:2015-01-07 summary:Convincing a customer is always considered as a challenging task in everybusiness. But when it comes to online business, this task becomes even moredifficult. Online retailers try everything possible to gain the trust of thecustomer. One of the solutions is to provide an area for existing users toleave their comments. This service can effectively develop the trust of thecustomer however normally the customer comments about the product in theirnative language using Roman script. If there are hundreds of comments thismakes difficulty even for the native customers to make a buying decision. Thisresearch proposes a system which extracts the comments posted in Roman Urdu,translate them, find their polarity and then gives us the rating of theproduct. This rating will help the native and non-native customers to makebuying decision efficiently from the comments posted in Roman Urdu.
arxiv-9600-56 | Leader Follower Formation Control of Ground Vehicles Using Camshift Based Guidance | http://arxiv.org/pdf/1501.01364v1.pdf | author:S. M. Vaitheeswaran, Bharath M. K., Gokul M category:cs.CV published:2015-01-07 summary:Autonomous ground vehicles have been designed for the purpose of that relieson ranging and bearing information received from forward looking camera on theFormation control . A visual guidance control algorithm is designed where realtime image processing is used to provide feedback signals. The vision subsystemand control subsystem work in parallel to accomplish formation control. Aproportional navigation and line of sight guidance laws are used to estimatethe range and bearing information from the leader vehicle using the visionsubsystem. The algorithms for vision detection and localization used here aresimilar to approaches for many computer vision tasks such as face tracking anddetection that are based color-and texture based features, and non-parametricContinuously Adaptive Mean-shift algorithms to keep track of the leader. Thisis being proposed for the first time in the leader follower framework. Thealgorithms are simple but effective for real time and provide an alternateapproach to traditional based approaches like the Viola Jones algorithm.Further to stabilize the follower to the leader trajectory, the sliding modecontroller is used to dynamically track the leader. The performance of theresults is demonstrated in simulation and in practical experiments.
arxiv-9600-57 | Deep Autoencoders for Dimensionality Reduction of High-Content Screening Data | http://arxiv.org/pdf/1501.01348v1.pdf | author:Lee Zamparo, Zhaolei Zhang category:cs.LG published:2015-01-07 summary:High-content screening uses large collections of unlabeled cell image data toreason about genetics or cell biology. Two important tasks are to identifythose cells which bear interesting phenotypes, and to identify sub-populationsenriched for these phenotypes. This exploratory data analysis usually involvesdimensionality reduction followed by clustering, in the hope that clustersrepresent a phenotype. We propose the use of stacked de-noising auto-encodersto perform dimensionality reduction for high-content screening. We demonstratethe superior performance of our approach over PCA, Local Linear Embedding,Kernel PCA and Isomap.
arxiv-9600-58 | A Conditional Dependence Measure with Applications to Undirected Graphical Models | http://arxiv.org/pdf/1501.01617v2.pdf | author:Jianqing Fan, Yang Feng, Lucy Xia category:stat.ME math.ST stat.AP stat.ML stat.TH published:2015-01-07 summary:Measuring conditional dependence is an important topic in statistics withbroad applications including graphical models. Under a factor model setting, anew conditional dependence measure is proposed. The measure is derived by usingdistance covariance after adjusting the common observable factors orcovariates. The corresponding conditional independence test is given with theasymptotic null distribution unveiled. The latter gives a somewhat surprisingresult: the estimating errors in factor loading matrices, while of root$-n$order, do not have material impact on the asymptotic null distribution of thetest statistic, which is also in the root$-n$ domain. It is also shown that thenew test has strict control over the asymptotic significance level and can becalculated efficiently. A generic method for building dependency graphs usingthe new test is elaborated. Numerical results and real data analysis show thesuperiority of the new method.
arxiv-9600-59 | Analog Signal Processing Approach for Coarse and Fine Depth Estimation | http://arxiv.org/pdf/1603.09712v1.pdf | author:Nihar Athreyas, Zhiguo Lai, Jai Gupta, Dev Gupta category:cs.CV published:2015-01-06 summary:Imaging and Image sensors is a field that is continuously evolving. There arenew products coming into the market every day. Some of these have very severeSize, Weight and Power constraints whereas other devices have to handle veryhigh computational loads. Some require both these conditions to be metsimultaneously. Current imaging architectures and digital image processingsolutions will not be able to meet these ever increasing demands. There is aneed to develop novel imaging architectures and image processing solutions toaddress these requirements. In this work we propose analog signal processing asa solution to this problem. The analog processor is not suggested as areplacement to a digital processor but it will be used as an augmentationdevice which works in parallel with the digital processor, making the systemfaster and more efficient. In order to show the merits of analog processing twostereo correspondence algorithms are implemented. We propose novelmodifications to the algorithms and new imaging architectures which,significantly reduces the computation time.
arxiv-9600-60 | On the Relationship between Sum-Product Networks and Bayesian Networks | http://arxiv.org/pdf/1501.01239v2.pdf | author:Han Zhao, Mazen Melibari, Pascal Poupart category:cs.AI stat.ML published:2015-01-06 summary:In this paper, we establish some theoretical connections between Sum-ProductNetworks (SPNs) and Bayesian Networks (BNs). We prove that every SPN can beconverted into a BN in linear time and space in terms of the network size. Thekey insight is to use Algebraic Decision Diagrams (ADDs) to compactly representthe local conditional probability distributions at each node in the resultingBN by exploiting context-specific independence (CSI). The generated BN has asimple directed bipartite graphical structure. We show that by applying theVariable Elimination algorithm (VE) to the generated BN with ADDrepresentations, we can recover the original SPN where the SPN can be viewed asa history record or caching of the VE inference process. To help state theproof clearly, we introduce the notion of {\em normal} SPN and present atheoretical analysis of the consistency and decomposability properties. Weconclude the paper with some discussion of the implications of the proof andestablish a connection between the depth of an SPN and a lower bound of thetree-width of its corresponding BN.
arxiv-9600-61 | Object localization in ImageNet by looking out of the window | http://arxiv.org/pdf/1501.01181v2.pdf | author:Alexander Vezhnevets, Vittorio Ferrari category:cs.CV published:2015-01-06 summary:We propose a method for annotating the location of objects in ImageNet.Traditionally, this is cast as an image window classification problem, whereeach window is considered independently and scored based on its appearancealone. Instead, we propose a method which scores each candidate window in thecontext of all other windows in the image, taking into account their similarityin appearance space as well as their spatial relations in the image plane. Wedevise a fast and exact procedure to optimize our scoring function over allcandidate windows in an image, and we learn its parameters using structuredoutput regression. We demonstrate on 92000 images from ImageNet that thissignificantly improves localization over recent techniques that score windowsin isolation.
arxiv-9600-62 | Analysing domain shift factors between videos and images for object detection | http://arxiv.org/pdf/1501.01186v3.pdf | author:Vicky Kalogeiton, Vittorio Ferrari, Cordelia Schmid category:cs.CV published:2015-01-06 summary:Object detection is one of the most important challenges in computer vision.Object detectors are usually trained on bounding-boxes from still images.Recently, video has been used as an alternative source of data. Yet, for agiven test domain (image or video), the performance of the detector depends onthe domain it was trained on. In this paper, we examine the reasons behind thisperformance gap. We define and evaluate different domain shift factors: spatiallocation accuracy, appearance diversity, image quality and aspect distribution.We examine the impact of these factors by comparing performance before andafter factoring them out. The results show that all four factors affect theperformance of the detectors and their combined effect explains nearly thewhole performance gap.
arxiv-9600-63 | The Quadrifocal Variety | http://arxiv.org/pdf/1501.01266v2.pdf | author:Luke Oeding category:math.AG cs.CV published:2015-01-06 summary:Multi-view Geometry is reviewed from an Algebraic Geometry perspective andmulti-focal tensors are constructed as equivariant projections of theGrassmannian. A connection to the principal minor assignment problem is made byconsidering several flatlander cameras. The ideal of the quadrifocal variety iscomputed up to degree 8 (and partially in degree 9) using the representationsof $\operatorname{GL}(3)^{\times 4}$ in the polynomial ring on the space of $3\times 3 \times 3 \times 3$ tensors. Further representation-theoretic analysisgives a lower bound for the number of minimal generators. We conjecture thatthe ideal of the quadrifocal variety is minimally generated in degree at most9.
arxiv-9600-64 | The Effect of Wedge Tip Angles on Stress Intensity Factors in the Contact Problem between Tilted Wedge and a Half Plane with an Edge Crack Using Digital Image Correlation | http://arxiv.org/pdf/1501.02246v1.pdf | author:Seyedmeysam Khaleghian, Anahita Emami, Mohammad Yadegari, Nasser Soltani category:cs.CV physics.optics published:2015-01-06 summary:The first and second mode stress intensity factors (SIFs) of a contactproblem between a half-plane with an edge crack and an asymmetric tilted wedgewere obtained using experimental method of Digital Image Correlation (DIC). Inthis technique, displacement and strain fields can be measured using twodigital images of the same sample at different stages of loading. However,several images were taken consequently in each stage of this experiment toavoid the noise effect. A pair of images of each stage was compared to eachother. Then, the correlation coefficients between them were studied using acomputer code. The pairs with the correlation coefficient higher than 0.8 wereselected as the acceptable match for displacement measurements near the cracktip. Subsequently, the SIFs of specimens were calculated using displacementfields obtained from DIC method. The effect of wedge tips angle on their SIFswas also studied. Moreover, the results of DIC method were compared with theresults of photoelasticity method and a close agreement between them wasobserved.
arxiv-9600-65 | Un résumeur à base de graphes, indépéndant de la langue | http://arxiv.org/pdf/1501.01243v1.pdf | author:Juan-Manuel Torres-Moreno, Javier Ramirez, Iria da Cunha category:cs.CL published:2015-01-06 summary:In this paper we present REG, a graph-based approach for study a fundamentalproblem of Natural Language Processing (NLP): the automatic text summarization.The algorithm maps a document as a graph, then it computes the weight of theirsentences. We have applied this approach to summarize documents in threelanguages.
arxiv-9600-66 | Efficient Online Relative Comparison Kernel Learning | http://arxiv.org/pdf/1501.01242v2.pdf | author:Eric Heim, Matthew Berger, Lee M. Seversky, Milos Hauskrecht category:cs.LG published:2015-01-06 summary:Learning a kernel matrix from relative comparison human feedback is animportant problem with applications in collaborative filtering, objectretrieval, and search. For learning a kernel over a large number of objects,existing methods face significant scalability issues inhibiting the applicationof these methods to settings where a kernel is learned in an online and timelyfashion. In this paper we propose a novel framework called Efficient onlineRelative comparison Kernel LEarning (ERKLE), for efficiently learning thesimilarity of a large set of objects in an online manner. We learn a kernelfrom relative comparisons via stochastic gradient descent, one query responseat a time, by taking advantage of the sparse and low-rank properties of thegradient to efficiently restrict the kernel to lie in the space of positivesemidefinite matrices. In addition, we derive a passive-aggressive onlineupdate for minimally satisfying new relative comparisons as to not disrupt theinfluence of previously obtained comparisons. Experimentally, we demonstrate aconsiderable improvement in speed while obtaining improved or comparableaccuracy compared to current methods in the online learning setting.
arxiv-9600-67 | Optimisation using Natural Language Processing: Personalized Tour Recommendation for Museums | http://arxiv.org/pdf/1501.01252v1.pdf | author:Mayeul Mathias, Assema Moussa, Fen Zhou, Juan-Manuel Torres-Moreno, Marie-Sylvie Poli, Didier Josselin, Marc El-Bèze, Andréa Carneiro Linhares, Francoise Rigat category:cs.AI cs.CL published:2015-01-06 summary:This paper proposes a new method to provide personalized tour recommendationfor museum visits. It combines an optimization of preference criteria ofvisitors with an automatic extraction of artwork importance from museuminformation based on Natural Language Processing using textual energy. Thisproject includes researchers from computer and social sciences. Some resultsare obtained with numerical experiments. They show that our model clearlyimproves the satisfaction of the visitor who follows the proposed tour. Thiswork foreshadows some interesting outcomes and applications about on-demandpersonalized visit of museums in a very near future.
arxiv-9600-68 | Unknown Words Analysis in POS tagging of Sinhala Language | http://arxiv.org/pdf/1501.01254v1.pdf | author:A. J. P. M. P. Jayaweera, N. G. J. Dias category:cs.CL I.2.7 published:2015-01-06 summary:Part of Speech (POS) is a very vital topic in Natural Language Processing(NLP) task in any language, which involves analysing the construction of thelanguage, behaviours and the dynamics of the language, the knowledge that couldbe utilized in computational linguistics analysis and automation applications.In this context, dealing with unknown words (words do not appear in the lexiconreferred as unknown words) is also an important task, since growing NLP systemsare used in more and more new applications. One aid of predicting lexicalcategories of unknown words is the use of syntactical knowledge of thelanguage. The distinction between open class words and closed class wordstogether with syntactical features of the language used in this research topredict lexical categories of unknown words in the tagging process. Anexperiment is performed to investigate the ability of the approach to parseunknown words using syntactical knowledge without human intervention. Thisexperiment shows that the performance of the tagging process is enhanced whenword class distinction is used together with syntactic rules to parse sentencescontaining unknown words in Sinhala language.
arxiv-9600-69 | Arabic Text Categorization Algorithm using Vector Evaluation Method | http://arxiv.org/pdf/1501.01318v1.pdf | author:Ashraf Odeh, Aymen Abu-Errub, Qusai Shambour, Nidal Turab category:cs.IR cs.CL published:2015-01-06 summary:Text categorization is the process of grouping documents into categoriesbased on their contents. This process is important to make informationretrieval easier, and it became more important due to the huge textualinformation available online. The main problem in text categorization is how toimprove the classification accuracy. Although Arabic text categorization is anew promising field, there are a few researches in this field. This paperproposes a new method for Arabic text categorization using vector evaluation.The proposed method uses a categorized Arabic documents corpus, and then theweights of the tested document's words are calculated to determine the documentkeywords which will be compared with the keywords of the corpus categorizes todetermine the tested document's best category.
arxiv-9600-70 | A Study on Clustering for Clustering Based Image De-Noising | http://arxiv.org/pdf/1501.01106v1.pdf | author:Hossein Bakhshi Golestani, Mohsen Joneidi, Mostafa Sadeghi category:cs.CV published:2015-01-06 summary:In this paper, the problem of de-noising of an image contaminated withAdditive White Gaussian Noise (AWGN) is studied. This subject is an openproblem in signal processing for more than 50 years. Local methods suggested inrecent years, have obtained better results than global methods. However by moreintelligent training in such a way that first, important data is more effectivefor training, second, clustering in such way that training blocks lie inlow-rank subspaces, we can design a dictionary applicable for image de-noisingand obtain results near the state of the art local methods. In the presentpaper, we suggest a method based on global clustering of image constructingblocks. As the type of clustering plays an important role in clustering-basedde-noising methods, we address two questions about the clustering. The first,which parts of the data should be considered for clustering? and the second,what data clustering method is suitable for de-noising.? Then clustering isexploited to learn an over complete dictionary. By obtaining sparsedecomposition of the noisy image blocks in terms of the dictionary atoms, thede-noised version is achieved. In addition to our framework, 7 populardictionary learning methods are simulated and compared. The results arecompared based on two major factors: (1) de-noising performance and (2)execution time. Experimental results show that our dictionary learningframework outperforms its competitors in terms of both factors.
arxiv-9600-71 | A Novel Technique for Grading of Dates using Shape and Texture Features | http://arxiv.org/pdf/1501.01090v1.pdf | author:S. H. Mohana, C. J. Prabhakar category:cs.CV published:2015-01-06 summary:This paper presents a novel method to grade the date fruits based on thecombination of shape and texture features. The method begins with reducing thespecular reflection and small noise using a bilateral filter. Threshold basedsegmentation is performed for background removal and fruit part selection fromthe given image. Shape features is extracted using the contour of the datefruit and texture features are extracted using Curvelet transform and LocalBinary Pattern (LBP) from the selected date fruit region. Finally, combinationsof shape and texture features are fused to grade the dates into six grades.k-Nearest Neighbour(k-NN) classifier yields the best grading rate compared toother two classifiers such as Support Vector Machine (SVM) and LinearDiscriminant(LDA) classifiers. The experiment result shows that our techniqueachieves highest accuracy.
arxiv-9600-72 | Skincure: An Innovative Smart Phone-Based Application To Assist In Melanoma Early Detection And Prevention | http://arxiv.org/pdf/1501.01075v1.pdf | author:Omar Abuzaghleh, Miad Faezipour, Buket D. Barkana category:cs.CV cs.CY published:2015-01-06 summary:Melanoma spreads through metastasis, and therefore it has been proven to bevery fatal. Statistical evidence has revealed that the majority of deathsresulting from skin cancer are as a result of melanoma. Further investigationshave shown that the survival rates in patients depend on the stage of theinfection; early detection and intervention of melanoma implicates higherchances of cure. Clinical diagnosis and prognosis of melanoma is challengingsince the processes are prone to misdiagnosis and inaccuracies due to doctorssubjectivity. This paper proposes an innovative and fully functionalsmart-phone based application to assist in melanoma early detection andprevention. The application has two major components; the first component is areal-time alert to help users prevent skin burn caused by sunlight; a novelequation to compute the time for skin to burn is thereby introduced. The secondcomponent is an automated image analysis module which contains imageacquisition, hair detection and exclusion, lesion segmentation, featureextraction, and classification. The proposed system exploits PH2 Dermoscopyimage database from Pedro Hispano Hospital for development and testingpurposes. The image database contains a total of 200 dermoscopy images oflesions, including normal, atypical, and melanoma cases. The experimentalresults show that the proposed system is efficient, achieving classification ofthe normal, atypical and melanoma images with accuracy of 96.3%, 95.7% and97.5%, respectively.
arxiv-9600-73 | Stem-Calyx Recognition of an Apple using Shape Descriptors | http://arxiv.org/pdf/1501.01083v1.pdf | author:S. H. Mohana, C. J. Prabhakar category:cs.CV published:2015-01-06 summary:This paper presents a novel method to recognize stem - calyx of an appleusing shape descriptors. The main drawback of existing apple grading techniquesis that stem - calyx part of an apple is treated as defects, this leads to poorgrading of apples. In order to overcome this drawback, we proposed an approachto recognize stem-calyx and differentiated from true defects based on shapefeatures. Our method comprises of steps such as segmentation of apple usinggrow-cut method, candidate objects such as stem-calyx and small defects aredetected using multi-threshold segmentation. The shape features are extractedfrom detected objects using Multifractal, Fourier and Radon descriptor andfinally stem-calyx regions are recognized and differentiated from true defectsusing SVM classifier. The proposed algorithm is evaluated using experimentsconducted on apple image dataset and results exhibit considerable improvementin recognition of stem-calyx region compared to other techniques.
arxiv-9600-74 | ITCM: A Real Time Internet Traffic Classifier Monitor | http://arxiv.org/pdf/1501.01321v1.pdf | author:Silas Santiago Lopes Pereira, José Everardo Bessa Maia, Jorge Luiz de Castro e Silva category:cs.NI cs.LG published:2015-01-06 summary:The continual growth of high speed networks is a challenge for real-timenetwork analysis systems. The real time traffic classification is an issue forcorporations and ISPs (Internet Service Providers). This work presents thedesign and implementation of a real time flow-based network trafficclassification system. The classifier monitor acts as a pipeline consisting ofthree modules: packet capture and pre-processing, flow reassembly, andclassification with Machine Learning (ML). The modules are built as concurrentprocesses with well defined data interfaces between them so that any module canbe improved and updated independently. In this pipeline, the flow reassemblyfunction becomes the bottleneck of the performance. In this implementation, wasused a efficient method of reassembly which results in a average delivery delayof 0.49 seconds, approximately. For the classification module, the performancesof the K-Nearest Neighbor (KNN), C4.5 Decision Tree, Naive Bayes (NB), FlexibleNaive Bayes (FNB) and AdaBoost Ensemble Learning Algorithm are compared inorder to validate our approach.
arxiv-9600-75 | A Deep-structured Conditional Random Field Model for Object Silhouette Tracking | http://arxiv.org/pdf/1501.00752v2.pdf | author:Mohammad Shafiee, Zohreh Azimifar, Alexander Wong category:cs.CV cs.LG stat.ML published:2015-01-05 summary:In this work, we introduce a deep-structured conditional random field(DS-CRF) model for the purpose of state-based object silhouette tracking. Theproposed DS-CRF model consists of a series of state layers, where each statelayer spatially characterizes the object silhouette at a particular point intime. The interactions between adjacent state layers are established byinter-layer connectivity dynamically determined based on inter-frame opticalflow. By incorporate both spatial and temporal context in a dynamic fashionwithin such a deep-structured probabilistic graphical model, the proposedDS-CRF model allows us to develop a framework that can accurately andefficiently track object silhouettes that can change greatly over time, as wellas under different situations such as occlusion and multiple targets within thescene. Experiment results using video surveillance datasets containingdifferent scenarios such as occlusion and multiple targets showed that theproposed DS-CRF approach provides strong object silhouette tracking performancewhen compared to baseline methods such as mean-shift tracking, as well asstate-of-the-art methods such as context tracking and boosted particlefiltering.
arxiv-9600-76 | Sparse Deep Stacking Network for Image Classification | http://arxiv.org/pdf/1501.00777v1.pdf | author:Jun Li, Heyou Chang, Jian Yang category:cs.CV cs.LG cs.NE published:2015-01-05 summary:Sparse coding can learn good robust representation to noise and model morehigher-order representation for image classification. However, the inferencealgorithm is computationally expensive even though the supervised signals areused to learn compact and discriminative dictionaries in sparse codingtechniques. Luckily, a simplified neural network module (SNNM) has beenproposed to directly learn the discriminative dictionaries for avoiding theexpensive inference. But the SNNM module ignores the sparse representations.Therefore, we propose a sparse SNNM module by adding the mixed-normregularization (l1/l2 norm). The sparse SNNM modules are further stacked tobuild a sparse deep stacking network (S-DSN). In the experiments, we evaluateS-DSN with four databases, including Extended YaleB, AR, 15 scene andCaltech101. Experimental results show that our model outperforms relatedclassification methods with only a linear classifier. It is worth noting thatwe reach 98.8% recognition accuracy on 15 scene.
arxiv-9600-77 | Salient Object Detection: A Benchmark | http://arxiv.org/pdf/1501.02741v1.pdf | author:Ali Borji, Ming-Ming Cheng, Huaizu Jiang, Jia Li category:cs.CV published:2015-01-05 summary:We extensively compare, qualitatively and quantitatively, 40 state-of-the-artmodels (28 salient object detection, 10 fixation prediction, 1 objectness, and1 baseline) over 6 challenging datasets for the purpose of benchmarking salientobject detection and segmentation methods. From the results obtained so far,our evaluation shows a consistent rapid progress over the last few years interms of both accuracy and running time. The top contenders in this benchmarksignificantly outperform the models identified as the best in the previousbenchmark conducted just two years ago. We find that the models designedspecifically for salient object detection generally work better than models inclosely related areas, which in turn provides a precise definition and suggestsan appropriate treatment of this problem that distinguishes it from otherproblems. In particular, we analyze the influences of center bias and scenecomplexity in model performance, which, along with the hard cases forstate-of-the-art models, provide useful hints towards constructing morechallenging large scale datasets and better saliency models. Finally, wepropose probable solutions for tackling several open problems such asevaluation scores and dataset bias, which also suggest future researchdirections in the rapidly-growing field of salient object detection.
arxiv-9600-78 | Group $K$-Means | http://arxiv.org/pdf/1501.00825v1.pdf | author:Jianfeng Wang, Shuicheng Yan, Yi Yang, Mohan S Kankanhalli, Shipeng Li, Jingdong Wang category:cs.CV published:2015-01-05 summary:We study how to learn multiple dictionaries from a dataset, and approximateany data point by the sum of the codewords each chosen from the correspondingdictionary. Although theoretically low approximation errors can be achieved bythe global solution, an effective solution has not been well studied inpractice. To solve the problem, we propose a simple yet effective algorithm\textit{Group $K$-Means}. Specifically, we take each dictionary, or any twoselected dictionaries, as a group of $K$-means cluster centers, and then dealwith the approximation issue by minimizing the approximation errors. Besides,we propose a hierarchical initialization for such a non-convex problem.Experimental results well validate the effectiveness of the approach.
arxiv-9600-79 | Inverse Renormalization Group Transformation in Bayesian Image Segmentations | http://arxiv.org/pdf/1501.00834v1.pdf | author:Kazuyuki Tanaka, Shun Kataoka, Muneki Yasuda, Masayuki Ohzeki category:cs.CV stat.ML published:2015-01-05 summary:A new Bayesian image segmentation algorithm is proposed by combining a loopybelief propagation with an inverse real space renormalization grouptransformation to reduce the computational time. In results of our experiment,we observe that the proposed method can reduce the computational time to lessthan one-tenth of that taken by conventional Bayesian approaches.
arxiv-9600-80 | Chasing the Ghosts of Ibsen: A computational stylistic analysis of drama in translation | http://arxiv.org/pdf/1501.00841v1.pdf | author:Gerard Lynch, Carl Vogel category:cs.CL published:2015-01-05 summary:Research into the stylistic properties of translations is an issue which hasreceived some attention in computational stylistics. Previous work by Rybicki(2006) on the distinguishing of character idiolects in the work of Polishauthor Henryk Sienkiewicz and two corresponding English translations usingBurrow's Delta method concluded that idiolectal differences could be observedin the source texts and this variation was preserved to a large degree in bothtranslations. This study also found that the two translations were also highlydistinguishable from one another. Burrows (2002) examined English translationsof Juvenal also using the Delta method, results of this work suggest that sometranslators are more adept at concealing their own style when translating theworks of another author whereas other authors tend to imprint their own styleto a greater extent on the work they translate. Our work examines the writingof a single author, Norwegian playwright Henrik Ibsen, and these writingstranslated into both German and English from Norwegian, in an attempt toinvestigate the preservation of characterization, defined here as thedistinctiveness of textual contributions of characters.
arxiv-9600-81 | Innovated interaction screening for high-dimensional nonlinear classification | http://arxiv.org/pdf/1501.01029v2.pdf | author:Yingying Fan, Yinfei Kong, Daoji Li, Zemin Zheng category:stat.ML published:2015-01-05 summary:This paper is concerned with the problems of interaction screening andnonlinear classification in a high-dimensional setting. We propose a two-stepprocedure, IIS-SQDA, where in the first step an innovated interaction screening(IIS) approach based on transforming the original $p$-dimensional featurevector is proposed, and in the second step a sparse quadratic discriminantanalysis (SQDA) is proposed for further selecting important interactions andmain effects and simultaneously conducting classification. Our IIS approachscreens important interactions by examining only $p$ features instead of alltwo-way interactions of order $O(p^2)$. Our theory shows that the proposedmethod enjoys sure screening property in interaction selection in thehigh-dimensional setting of $p$ growing exponentially with the sample size. Inthe selection and classification step, we establish a sparse inequality on theestimated coefficient vector for QDA and prove that the classification error ofour procedure can be upper-bounded by the oracle classification error plus somesmaller order term. Extensive simulation studies and real data analysis showthat our proposal compares favorably with existing methods in interactionselection and high-dimensional classification.
arxiv-9600-82 | Adaptive Objectness for Object Tracking | http://arxiv.org/pdf/1501.00909v1.pdf | author:Pengpeng Liang, Chunyuan Liao, Xue Mei, Haibin Ling category:cs.CV published:2015-01-05 summary:Object tracking is a long standing problem in vision. While great effortshave been spent to improve tracking performance, a simple yet reliable priorknowledge is left unexploited: the target object in tracking must be an objectother than non-object. The recently proposed and popularized objectness measureprovides a natural way to model such prior in visual tracking. Thus motivated,in this paper we propose to adapt objectness for visual object tracking.Instead of directly applying an existing objectness measure that is generic andhandles various objects and environments, we adapt it to be compatible to thespecific tracking sequence and object. More specifically, we use the newlyproposed BING objectness as the base, and then train an object-adaptiveobjectness for each tracking task. The training is implemented by using anadaptive support vector machine that integrates information from the specifictracking target into the BING measure. We emphasize that the benefit of theproposed adaptive objectness, named ADOBING, is generic. To show this, wecombine ADOBING with seven top performed trackers in recent evaluations. We runthe ADOBING-enhanced trackers with their base trackers on two popularbenchmarks, the CVPR2013 benchmark (50 sequences) and the Princeton TrackingBenchmark (100 sequences). On both benchmarks, our methods not onlyconsistently improve the base trackers, but also achieve the best knownperformances. Noting that the way we integrate objectness in visual tracking isgeneric and straightforward, we expect even more improvement by usingtracker-specific objectness.
arxiv-9600-83 | Characterizing the Google Books corpus: Strong limits to inferences of socio-cultural and linguistic evolution | http://arxiv.org/pdf/1501.00960v2.pdf | author:Eitan Adam Pechenick, Christopher M. Danforth, Peter Sheridan Dodds category:physics.soc-ph cs.CL stat.AP published:2015-01-05 summary:It is tempting to treat frequency trends from the Google Books data sets asindicators of the "true" popularity of various words and phrases. Doing soallows us to draw quantitatively strong conclusions about the evolution ofcultural perception of a given topic, such as time or gender. However, theGoogle Books corpus suffers from a number of limitations which make it anobscure mask of cultural popularity. A primary issue is that the corpus is ineffect a library, containing one of each book. A single, prolific author isthereby able to noticeably insert new phrases into the Google Books lexicon,whether the author is widely read or not. With this understood, the GoogleBooks corpus remains an important data set to be considered more lexicon-likethan text-like. Here, we show that a distinct problematic feature arises fromthe inclusion of scientific texts, which have become an increasinglysubstantive portion of the corpus throughout the 1900s. The result is a surgeof phrases typical to academic articles but less common in general, such asreferences to time in the form of citations. We highlight these dynamics byexamining and comparing major contributions to the statistical divergence ofEnglish data sets between decades in the period 1800--2000. We find that onlythe English Fiction data set from the second version of the corpus is notheavily affected by professional texts, in clear contrast to the first versionof the fiction data set and both unfiltered English data sets. Our findingsemphasize the need to fully characterize the dynamics of the Google Bookscorpus before using these data sets to draw broad conclusions about culturaland linguistic evolution.
arxiv-9600-84 | Hashing with binary autoencoders | http://arxiv.org/pdf/1501.00756v1.pdf | author:Miguel Á. Carreira-Perpiñán, Ramin Raziperchikolaei category:cs.LG cs.CV math.OC stat.ML published:2015-01-05 summary:An attractive approach for fast search in image databases is binary hashing,where each high-dimensional, real-valued image is mapped onto alow-dimensional, binary vector and the search is done in this binary space.Finding the optimal hash function is difficult because it involves binaryconstraints, and most approaches approximate the optimization by relaxing theconstraints and then binarizing the result. Here, we focus on the binaryautoencoder model, which seeks to reconstruct an image from the binary codeproduced by the hash function. We show that the optimization can be simplifiedwith the method of auxiliary coordinates. This reformulates the optimization asalternating two easier steps: one that learns the encoder and decoderseparately, and one that optimizes the code for each image. Image retrievalexperiments, using precision/recall and a measure of code utilization, show theresulting hash function outperforms or is competitive with state-of-the-artmethods for binary hashing.
arxiv-9600-85 | Learning to Recognize Pedestrian Attribute | http://arxiv.org/pdf/1501.00901v2.pdf | author:Yubin Deng, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV published:2015-01-05 summary:Learning to recognize pedestrian attributes at far distance is a challengingproblem in visual surveillance since face and body close-shots are hardlyavailable; instead, only far-view image frames of pedestrian are given. In thisstudy, we present an alternative approach that exploits the context ofneighboring pedestrian images for improved attribute inference compared to theconventional SVM-based method. In addition, we conduct extensive experiments toevaluate the informativeness of background and foreground features forattribute recognition. Experiments are based on our newly released pedestrianattribute dataset, which is by far the largest and most diverse of its kind.
arxiv-9600-86 | Fast forward feature selection for the nonlinear classification of hyperspectral images | http://arxiv.org/pdf/1501.00857v1.pdf | author:Mathieu Fauvel, Clement Dechesne, Anthony Zullo, Frédéric Ferraty category:cs.CV published:2015-01-05 summary:A fast forward feature selection algorithm is presented in this paper. It isbased on a Gaussian mixture model (GMM) classifier. GMM are used forclassifying hyperspectral images. The algorithm selects iteratively spectralfeatures that maximizes an estimation of the classification rate. Theestimation is done using the k-fold cross validation. In order to perform fastin terms of computing time, an efficient implementation is proposed. First, theGMM can be updated when the estimation of the classification rate is computed,rather than re-estimate the full model. Secondly, using marginalization of theGMM, sub models can be directly obtained from the full model learned with allthe spectral features. Experimental results for two real hyperspectral datasets show that the method performs very well in terms of classificationaccuracy and processing time. Furthermore, the extracted model contains veryfew spectral channels.
arxiv-9600-87 | A New Method for Signal and Image Analysis: The Square Wave Method | http://arxiv.org/pdf/1501.00680v1.pdf | author:Osvaldo Skliar, Ricardo E. Monge, Sherry Gapper category:cs.NA cs.CV math.NA 94A12, 65F99 published:2015-01-04 summary:A brief review is provided of the use of the Square Wave Method (SWM) in thefield of signal and image analysis and it is specified how results thusobtained are expressed using the Square Wave Transform (SWT), in the frequencydomain. To illustrate the new approach introduced in this field, the results oftwo cases are analyzed: a) a sequence of samples (that is, measured values) ofan electromyographic recording; and b) the classic image of Lenna.
arxiv-9600-88 | Differential Search Algorithm-based Parametric Optimization of Fuzzy Generalized Eigenvalue Proximal Support Vector Machine | http://arxiv.org/pdf/1501.00728v1.pdf | author:M. H. Marghny, Rasha M. Abd ElAziz, Ahmed I. Taloba category:cs.LG published:2015-01-04 summary:Support Vector Machine (SVM) is an effective model for many classificationproblems. However, SVM needs the solution of a quadratic program which requirespecialized code. In addition, SVM has many parameters, which affects theperformance of SVM classifier. Recently, the Generalized Eigenvalue ProximalSVM (GEPSVM) has been presented to solve the SVM complexity. In real worldapplications data may affected by error or noise, working with this data is achallenging problem. In this paper, an approach has been proposed to overcomethis problem. This method is called DSA-GEPSVM. The main improvements arecarried out based on the following: 1) a novel fuzzy values in the linear case.2) A new Kernel function in the nonlinear case. 3) Differential SearchAlgorithm (DSA) is reformulated to find near optimal values of the GEPSVMparameters and its kernel parameters. The experimental results show that theproposed approach is able to find the suitable parameter values, and has higherclassification accuracy compared with some other algorithms.
arxiv-9600-89 | On Enhancing The Performance Of Nearest Neighbour Classifiers Using Hassanat Distance Metric | http://arxiv.org/pdf/1501.00687v1.pdf | author:Mouhammd Alkasassbeh, Ghada A. Altarawneh, Ahmad B. A. Hassanat category:cs.LG published:2015-01-04 summary:We showed in this work how the Hassanat distance metric enhances theperformance of the nearest neighbour classifiers. The results demonstrate thesuperiority of this distance metric over the traditional and most-useddistances, such as Manhattan distance and Euclidian distance. Moreover, weproved that the Hassanat distance metric is invariant to data scale, noise andoutliers. Throughout this work, it is clearly notable that both ENN and IINCperformed very well with the distance investigated, as their accuracy increasedsignificantly by 3.3% and 3.1% respectively, with no significant advantage ofthe ENN over the IINC in terms of accuracy. Correspondingly, it can be notedfrom our results that there is no optimal algorithm that can solve allreal-life problems perfectly; this is supported by the no-free-lunch theorem
arxiv-9600-90 | Understanding Trajectory Behavior: A Motion Pattern Approach | http://arxiv.org/pdf/1501.00614v1.pdf | author:Mahdi M. Kalayeh, Stephen Mussmann, Alla Petrakova, Niels da Vitoria Lobo, Mubarak Shah category:cs.CV published:2015-01-04 summary:Mining the underlying patterns in gigantic and complex data is of greatimportance to data analysts. In this paper, we propose a motion patternapproach to mine frequent behaviors in trajectory data. Motion patterns,defined by a set of highly similar flow vector groups in a spatial locality,have been shown to be very effective in extracting dominant motion behaviors invideo sequences. Inspired by applications and properties of motion patterns, wehave designed a framework that successfully solves the general task oftrajectory clustering. Our proposed algorithm consists of four phases: flowvector computation, motion component extraction, motion component'sreachability set creation, and motion pattern formation. For the first phase,we break down trajectories into flow vectors that indicate instantaneousmovements. In the second phase, via a Kmeans clustering approach, we createmotion components by clustering the flow vectors with respect to their locationand velocity. Next, we create motion components' reachability set in terms ofspatial proximity and motion similarity. Finally, for the fourth phase, wecluster motion components using agglomerative clustering with the weightedJaccard distance between the motion components' signatures, a set created usingpath reachability. We have evaluated the effectiveness of our proposed methodin an extensive set of experiments on diverse datasets. Further, we have shownhow our proposed method handles difficulties in the general task of trajectoryclustering that challenge the existing state-of-the-art methods.
arxiv-9600-91 | A generalization error bound for sparse and low-rank multivariate Hawkes processes | http://arxiv.org/pdf/1501.00725v1.pdf | author:Emmanuel Bacry, Stéphane Gaïffas, Jean-François Muzy category:stat.ML published:2015-01-04 summary:We consider the problem of unveiling the implicit network structure of userinteractions in a social network, based only on high-frequency timestamps. Ourinference is based on the minimization of the least-squares loss associatedwith a multivariate Hawkes model, penalized by $\ell_1$ and trace norms. Weprovide a first theoretical analysis of the generalization error for thisproblem, that includes sparsity and low-rank inducing priors. This resultinvolves a new data-driven concentration inequality for matrix martingales incontinuous time with observable variance, which is a result of independentinterest. A consequence of our analysis is the construction of sharply tuned$\ell_1$ and trace-norm penalizations, that leads to a data-driven scaling ofthe variability of information available for each users. Numerical experimentsillustrate the strong improvements achieved by the use of such data-drivenpenalizations.
arxiv-9600-92 | Hostile Intent Identification by Movement Pattern Analysis: Using Artificial Neural Networks | http://arxiv.org/pdf/1501.00653v1.pdf | author:Souham Biswas, Manisha J. Nene category:cs.AI cs.NE published:2015-01-04 summary:In the recent years, the problem of identifying suspicious behavior hasgained importance and identifying this behavior using computational systems andautonomous algorithms is highly desirable in a tactical scenario. So far, thesolutions have been primarily manual which elicit human observation of entitiesto discern the hostility of the situation. To cater to this problem statement,a number of fully automated and partially automated solutions exist. But, thesesolutions lack the capability of learning from experiences and work inconjunction with human supervision which is extremely prone to error. In thispaper, a generalized methodology to predict the hostility of a given objectbased on its movement patterns is proposed which has the ability to learn andis based upon the mechanism of humans of learning from experiences. Themethodology so proposed has been implemented in a computer simulation. Theresults show that the posited methodology has the potential to be applied inreal world tactical scenarios.
arxiv-9600-93 | Unsupervised Feature Learning for Dense Correspondences across Scenes | http://arxiv.org/pdf/1501.00642v2.pdf | author:Chao Zhang, Chunhua Shen, Tingzhi Shen category:cs.CV published:2015-01-04 summary:We propose a fast, accurate matching method for estimating dense pixelcorrespondences across scenes. It is a challenging problem to estimate densepixel correspondences between images depicting different scenes or instances ofthe same object category. While most such matching methods rely on hand-craftedfeatures such as SIFT, we learn features from a large amount of unlabeled imagepatches using unsupervised learning. Pixel-layer features are obtained byencoding over the dictionary, followed by spatial pooling to obtain patch-layerfeatures. The learned features are then seamlessly embedded into a multi-layermatch- ing framework. We experimentally demonstrate that the learned features,together with our matching model, outperforms state-of-the-art methods such asthe SIFT flow, coherency sensitive hashing and the recent deformable spatialpyramid matching methods both in terms of accuracy and computation efficiency.Furthermore, we evaluate the performance of a few different dictionary learningand feature encoding methods in the proposed pixel correspondences estimationframework, and analyse the impact of dictionary learning and feature encodingwith respect to the final matching performance.
arxiv-9600-94 | Cross-language Wikipedia Editing of Okinawa, Japan | http://arxiv.org/pdf/1501.00657v2.pdf | author:Scott A. Hale category:cs.CY cs.CL cs.SI H.5.4, H.5.3 published:2015-01-04 summary:This article analyzes users who edit Wikipedia articles about Okinawa, Japan,in English and Japanese. It finds these users are among the most active anddedicated users in their primary languages, where they make many large,high-quality edits. However, when these users edit in their non-primarylanguages, they tend to make edits of a different type that are overall smallerin size and more often restricted to the narrow set of articles that exist inboth languages. Design changes to motivate wider contributions from users intheir non-primary languages and to encourage multilingual users to transfermore information across language divides are presented.
arxiv-9600-95 | Non-iterative rigid 2D/3D point-set registration using semidefinite programming | http://arxiv.org/pdf/1501.00630v3.pdf | author:Yuehaw Khoo, Ankur Kapoor category:cs.CV math.OC 90C22, 92C55 G.1.6; I.4.9 published:2015-01-04 summary:We describe a convex programming framework for pose estimation in 2D/3Dpoint-set registration with unknown point correspondences. We give twomixed-integer nonlinear program (MINP) formulations of the 2D/3D registrationproblem when there are multiple 2D images, and propose convex relaxations forboth of the MINPs to semidefinite programs (SDP) that can be solved efficientlyby interior point methods. Our approach to the 2D/3D registration problem isnon-iterative in nature as we jointly solve for pose and correspondence.Furthermore, these convex programs can readily incorporate feature descriptorsof points to enhance registration results. We prove that the convex programsexactly recover the solution to the original nonconvex 2D/3D registrationproblem under noiseless condition. We apply these formulations to theregistration of 3D models of coronary vessels to their 2D projections obtainedfrom multiple intra-operative fluoroscopic images. For this application, weexperimentally corroborate the exact recovery property in the absence of noiseand further demonstrate robustness of the convex programs in the presence ofnoise.
arxiv-9600-96 | A Taxonomy of Big Data for Optimal Predictive Machine Learning and Data Mining | http://arxiv.org/pdf/1501.00604v1.pdf | author:Ernest Fokoue category:stat.ML 60K35 published:2015-01-03 summary:Big data comes in various ways, types, shapes, forms and sizes. Indeed,almost all areas of science, technology, medicine, public health, economics,business, linguistics and social science are bombarded by ever increasing flowsof data begging to analyzed efficiently and effectively. In this paper, wepropose a rough idea of a possible taxonomy of big data, along with some of themost commonly used tools for handling each particular category of bigness. Thedimensionality p of the input space and the sample size n are usually the mainingredients in the characterization of data bigness. The specific statisticalmachine learning technique used to handle a particular big data set will dependon which category it falls in within the bigness taxonomy. Large p small n datasets for instance require a different set of tools from the large n small pvariety. Among other tools, we discuss Preprocessing, Standardization,Imputation, Projection, Regularization, Penalization, Compression, Reduction,Selection, Kernelization, Hybridization, Parallelization, Aggregation,Randomization, Replication, Sequentialization. Indeed, it is important toemphasize right away that the so-called no free lunch theorem applies here, inthe sense that there is no universally superior method that outperforms allother methods on all categories of bigness. It is also important to stress thefact that simplicity in the sense of Ockham's razor non plurality principle ofparsimony tends to reign supreme when it comes to massive data. We concludewith a comparison of the predictive performance of some of the most commonlyused methods on a few data sets.
arxiv-9600-97 | The Learnability of Unknown Quantum Measurements | http://arxiv.org/pdf/1501.00559v1.pdf | author:Hao-Chung Cheng, Min-Hsiu Hsieh, Ping-Cheng Yeh category:quant-ph cs.LG stat.ML published:2015-01-03 summary:Quantum machine learning has received significant attention in recent years,and promising progress has been made in the development of quantum algorithmsto speed up traditional machine learning tasks. In this work, however, we focuson investigating the information-theoretic upper bounds of sample complexity -how many training samples are sufficient to predict the future behaviour of anunknown target function. This kind of problem is, arguably, one of the mostfundamental problems in statistical learning theory and the bounds forpractical settings can be completely characterised by a simple measure ofcomplexity. Our main result in the paper is that, for learning an unknown quantummeasurement, the upper bound, given by the fat-shattering dimension, islinearly proportional to the dimension of the underlying Hilbert space.Learning an unknown quantum state becomes a dual problem to ours, and as abyproduct, we can recover Aaronson's famous result [Proc. R. Soc. A463:3089-3144 (2007)] solely using a classical machine learning technique. Inaddition, other famous complexity measures like covering numbers and Rademachercomplexities are derived explicitly. We are able to connect measures of samplecomplexity with various areas in quantum information science, e.g. quantumstate/measurement tomography, quantum state discrimination and quantum randomaccess codes, which may be of independent interest. Lastly, with the assistanceof general Bloch-sphere representation, we show that learning quantummeasurements/states can be mathematically formulated as a neural network.Consequently, classical ML algorithms can be applied to efficiently accomplishthe two quantum learning tasks.
arxiv-9600-98 | Evaluation of Predictive Data Mining Algorithms in Erythemato-Squamous Disease Diagnosis | http://arxiv.org/pdf/1501.00607v1.pdf | author:Kwetishe Danjuma, Adenike O. Osofisan category:cs.LG cs.CE published:2015-01-03 summary:A lot of time is spent searching for the most performing data miningalgorithms applied in clinical diagnosis. The study set out to identify themost performing predictive data mining algorithms applied in the diagnosis ofErythemato-squamous diseases. The study used Naive Bayes, Multilayer Perceptronand J48 decision tree induction to build predictive data mining models on 366instances of Erythemato-squamous diseases datasets. Also, 10-foldcross-validation and sets of performance metrics were used to evaluate thebaseline predictive performance of the classifiers. The comparative analysisshows that the Naive Bayes performed best with accuracy of 97.4%, MultilayerPerceptron came out second with accuracy of 96.6%, and J48 came out the worstwith accuracy of 93.5%. The evaluation of these classifiers on clinicaldatasets, gave an insight into the predictive ability of different data miningalgorithms applicable in clinical diagnosis especially in the diagnosis ofErythemato-squamous diseases.
arxiv-9600-99 | Efficiently Discovering Frequent Motifs in Large-scale Sensor Data | http://arxiv.org/pdf/1501.00405v1.pdf | author:Puneet Agarwal, Gautam Shroff, Sarmimala Saikia, Zaigham Khan category:cs.DB cs.LG published:2015-01-02 summary:While analyzing vehicular sensor data, we found that frequently occurringwaveforms could serve as features for further analysis, such as rule mining,classification, and anomaly detection. The discovery of waveform patterns, alsoknown as time-series motifs, has been studied extensively; however, availabletechniques for discovering frequently occurring time-series motifs were foundlacking in either efficiency or quality: Standard subsequence clusteringresults in poor quality, to the extent that it has even been termed'meaningless'. Variants of hierarchical clustering using techniques forefficient discovery of 'exact pair motifs' find high-quality frequent motifs,but at the cost of high computational complexity, making such techniquesunusable for our voluminous vehicular sensor data. We show that good qualityfrequent motifs can be discovered using bounded spherical clustering oftime-series subsequences, which we refer to as COIN clustering, with nearlinear complexity in time-series size. COIN clustering addresses many of thechallenges that previously led to subsequence clustering being viewed asmeaningless. We describe an end-to-end motif-discovery procedure using asequence of pre and post-processing techniques that remove trivial-matches andshifted-motifs, which also plagued previous subsequence-clustering approaches.We demonstrate that our technique efficiently discovers frequent motifs involuminous vehicular sensor data as well as in publicly available data sets.
arxiv-9600-100 | An Experimental Analysis of the Echo State Network Initialization Using the Particle Swarm Optimization | http://arxiv.org/pdf/1501.00436v1.pdf | author:Sebastián Basterrech, Enrique Alba, Václav Snášel category:cs.NE published:2015-01-02 summary:This article introduces a robust hybrid method for solving supervisedlearning tasks, which uses the Echo State Network (ESN) model and the ParticleSwarm Optimization (PSO) algorithm. An ESN is a Recurrent Neural Network withthe hidden-hidden weights fixed in the learning process. The recurrent part ofthe network stores the input information in internal states of the network.Another structure forms a free-memory method used as supervised learning tool.The setting procedure for initializing the recurrent structure of the ESN modelcan impact on the model performance. On the other hand, the PSO has been shownto be a successful technique for finding optimal points in complex spaces.Here, we present an approach to use the PSO for finding some initialhidden-hidden weights of the ESN model. We present empirical results thatcompare the canonical ESN model with this hybrid method on a wide range ofbenchmark problems.
arxiv-9600-101 | (Non-) asymptotic properties of Stochastic Gradient Langevin Dynamics | http://arxiv.org/pdf/1501.00438v2.pdf | author:Sebastian J. Vollmer, Konstantinos C. Zygalakis, and Yee Whye Teh category:stat.ME math.ST stat.ML stat.TH 60J05, 65C05 published:2015-01-02 summary:Applying standard Markov chain Monte Carlo (MCMC) algorithms to large datasets is computationally infeasible. The recently proposed stochastic gradientLangevin dynamics (SGLD) method circumvents this problem in three ways: itgenerates proposed moves using only a subset of the data, it skips theMetropolis-Hastings accept-reject step, and it uses sequences of decreasingstep sizes. In \cite{TehThierryVollmerSGLD2014}, we provided the mathematicalfoundations for the decreasing step size SGLD, including consistency and acentral limit theorem. However, in practice the SGLD is run for a relativelysmall number of iterations, and its step size is not decreased to zero. Thepresent article investigates the behaviour of the SGLD with fixed step size. Inparticular we characterise the asymptotic bias explicitly, along with itsdependence on the step size and the variance of the stochastic gradient. Onthat basis a modified SGLD which removes the asymptotic bias due to thevariance of the stochastic gradients up to first order in the step size isderived. Moreover, we are able to obtain bounds on the finite-time bias,variance and mean squared error (MSE). The theory is illustrated with aGaussian toy model for which the bias and the MSE for the estimation of momentscan be obtained explicitly. For this toy model we study the gain of the SGLDover the standard Euler method in the limit of large data sets.
arxiv-9600-102 | An Empirical Study of the L2-Boost technique with Echo State Networks | http://arxiv.org/pdf/1501.00503v1.pdf | author:Sebastián Basterrech category:cs.LG cs.NE published:2015-01-02 summary:A particular case of Recurrent Neural Network (RNN) was introduced at thebeginning of the 2000s under the name of Echo State Networks (ESNs). The ESNmodel overcomes the limitations during the training of the RNNs whileintroducing no significant disadvantages. Although the model presents somewell-identified drawbacks when the parameters are not well initialised. Theperformance of an ESN is highly dependent on its internal parameters andpattern of connectivity of the hidden-hidden weights Often, the tuning of thenetwork parameters can be hard and can impact in the accuracy of the models. In this work, we investigate the performance of a specific boosting technique(called L2-Boost) with ESNs as single predictors. The L2-Boost technique hasbeen shown to be an effective tool to combine "weak" predictors in regressionproblems. In this study, we use an ensemble of random initialized ESNs (withoutcontrol their parameters) as "weak" predictors of the boosting procedure. Weevaluate our approach on five well-know time-series benchmark problems.Additionally, we compare this technique with a baseline approach that consistsof averaging the prediction of an ensemble of ESNs.
arxiv-9600-103 | Computational Feasibility of Clustering under Clusterability Assumptions | http://arxiv.org/pdf/1501.00437v1.pdf | author:Shai Ben-David category:cs.CC cs.LG 68Q25, 68Q32 published:2015-01-02 summary:It is well known that most of the common clustering objectives are NP-hard tooptimize. In practice, however, clustering is being routinely carried out. Oneapproach for providing theoretical understanding of this seeming discrepancy isto come up with notions of clusterability that distinguish realisticallyinteresting input data from worst-case data sets. The hope is that there willbe clustering algorithms that are provably efficient on such 'clusterable'instances. In other words, hope that "Clustering is difficult only when it doesnot matter" (CDNM thesis, for short). We believe that to some extent this may indeed be the case. This paperprovides a survey of recent papers along this line of research and a criticalevaluation their results. Our bottom line conclusion is that that CDNM thesisis still far from being formally substantiated. We start by discussing whichrequirements should be met in order to provide formal support the validity ofthe CDNM thesis. In particular, we list some implied requirements for notionsof clusterability. We then examine existing results in view of thoserequirements and outline some research challenges and open questions.
arxiv-9600-104 | Comprehend DeepWalk as Matrix Factorization | http://arxiv.org/pdf/1501.00358v1.pdf | author:Cheng Yang, Zhiyuan Liu category:cs.LG published:2015-01-02 summary:Word2vec, as an efficient tool for learning vector representation of wordshas shown its effectiveness in many natural language processing tasks. Mikolovet al. issued Skip-Gram and Negative Sampling model for developing thistoolbox. Perozzi et al. introduced the Skip-Gram model into the study of socialnetwork for the first time, and designed an algorithm named DeepWalk forlearning node embedding on a graph. We prove that the DeepWalk algorithm isactually factoring a matrix M where each entry M_{ij} is logarithm of theaverage probability that node i randomly walks to node j in fix steps.
arxiv-9600-105 | Passing Expectation Propagation Messages with Kernel Methods | http://arxiv.org/pdf/1501.00375v1.pdf | author:Wittawat Jitkrittum, Arthur Gretton, Nicolas Heess category:stat.ML cs.LG published:2015-01-02 summary:We propose to learn a kernel-based message operator which takes as input allexpectation propagation (EP) incoming messages to a factor node and produces anoutgoing message. In ordinary EP, computing an outgoing message involvesestimating a multivariate integral which may not have an analytic expression.Learning such an operator allows one to bypass the expensive computation of theintegral during inference by directly mapping all incoming messages into anoutgoing message. The operator can be learned from training data (examples ofinput and output messages) which allows automated inference to be made on anykind of factor that can be sampled.
arxiv-9600-106 | Consistent Classification Algorithms for Multi-class Non-Decomposable Performance Metrics | http://arxiv.org/pdf/1501.00287v1.pdf | author:Harish G. Ramaswamy, Harikrishna Narasimhan, Shivani Agarwal category:cs.LG stat.ML published:2015-01-01 summary:We study consistency of learning algorithms for a multi-class performancemetric that is a non-decomposable function of the confusion matrix of aclassifier and cannot be expressed as a sum of losses on individual datapoints; examples of such performance metrics include the macro F-measurepopular in information retrieval and the G-mean metric used in class-imbalancedproblems. While there has been much work in recent years in understanding theconsistency properties of learning algorithms for `binary' non-decomposablemetrics, little is known either about the form of the optimal classifier for ageneral multi-class non-decomposable metric, or about how these learningalgorithms generalize to the multi-class case. In this paper, we provide aunified framework for analysing a multi-class non-decomposable performancemetric, where the problem of finding the optimal classifier for the performancemetric is viewed as an optimization problem over the space of all confusionmatrices achievable under the given distribution. Using this framework, we showthat (under a continuous distribution) the optimal classifier for a multi-classperformance metric can be obtained as the solution of a cost-sensitiveclassification problem, thus generalizing several previous results on specificbinary non-decomposable metrics. We then design a consistent learning algorithmfor concave multi-class performance metrics that proceeds via a sequence ofcost-sensitive classification problems, and can be seen as applying theconditional gradient (CG) optimization method over the space of feasibleconfusion matrices. To our knowledge, this is the first efficient learningalgorithm (whose running time is polynomial in the number of classes) that isconsistent for a large family of multi-class non-decomposable metrics. Ourconsistency proof uses a novel technique based on the convergence analysis ofthe CG method.
arxiv-9600-107 | QANUS: An Open-source Question-Answering Platform | http://arxiv.org/pdf/1501.00311v1.pdf | author:Jun-Ping Ng, Min-Yen Kan category:cs.IR cs.CL published:2015-01-01 summary:In this paper, we motivate the need for a publicly available, genericsoftware framework for question-answering (QA) systems. We present anopen-source QA framework QANUS which researchers can leverage on to build newQA systems easily and rapidly. The framework implements much of the code thatwill otherwise have been repeated across different QA systems. To demonstratethe utility and practicality of the framework, we further present a fullyfunctioning factoid QA system QA-SYS built on top of QANUS.
arxiv-9600-108 | Statistical consistency and asymptotic normality for high-dimensional robust M-estimators | http://arxiv.org/pdf/1501.00312v1.pdf | author:Po-Ling Loh category:math.ST cs.IT math.IT stat.ML stat.TH 62F12 published:2015-01-01 summary:We study theoretical properties of regularized robust M-estimators,applicable when data are drawn from a sparse high-dimensional linear model andcontaminated by heavy-tailed distributions and/or outliers in the additiveerrors and covariates. We first establish a form of local statisticalconsistency for the penalized regression estimators under fairly mildconditions on the error distribution: When the derivative of the loss functionis bounded and satisfies a local restricted curvature condition, all stationarypoints within a constant radius of the true regression vector converge at theminimax rate enjoyed by the Lasso with sub-Gaussian errors. When an appropriatenonconvex regularizer is used in place of an l_1-penalty, we show that suchstationary points are in fact unique and equal to the local oracle solutionwith the correct support---hence, results on asymptotic normality in thelow-dimensional case carry over immediately to the high-dimensional setting.This has important implications for the efficiency of regularized nonconvexM-estimators when the errors are heavy-tailed. Our analysis of the localcurvature of the loss function also has useful consequences for optimizationwhen the robust regression function and/or regularizer is nonconvex and theobjective function possesses stationary points outside the local region. Weshow that as long as a composite gradient descent algorithm is initializedwithin a constant radius of the true regression vector, successive iterateswill converge at a linear rate to a stationary point within the local region.Furthermore, the global optimum of a convex regularized robust regressionfunction may be used to obtain a suitable initialization. The result is a noveltwo-step procedure that uses a convex M-estimator to achieve consistency and anonconvex M-estimator to increase efficiency.
arxiv-9600-109 | Multi-Access Communications with Energy Harvesting: A Multi-Armed Bandit Model and the Optimality of the Myopic Policy | http://arxiv.org/pdf/1501.00329v1.pdf | author:Pol Blasco, Deniz Gunduz category:cs.IT cs.LG math.IT published:2015-01-01 summary:A multi-access wireless network with N transmitting nodes, each equipped withan energy harvesting (EH) device and a rechargeable battery of finite capacity,is studied. At each time slot (TS) a node is operative with a certainprobability, which may depend on the availability of data, or the state of itschannel. The energy arrival process at each node is modelled as an independenttwo-state Markov process, such that, at each TS, a node either harvests oneunit of energy, or none. At each TS a subset of the nodes is scheduled by theaccess point (AP). The scheduling policy that maximises the total throughput isstudied assuming that the AP does not know the states of either the EHprocesses or the batteries. The problem is identified as a restless multiarmedbandit (RMAB) problem, and an upper bound on the optimal scheduling policy isfound. Under certain assumptions regarding the EH processes and the batterysizes, the optimality of the myopic policy (MP) is proven. For the generalcase, the performance of MP is compared numerically to the upper bound.
arxiv-9600-110 | A robust sub-linear time R-FFAST algorithm for computing a sparse DFT | http://arxiv.org/pdf/1501.00320v1.pdf | author:Sameer Pawar, Kannan Ramchandran category:cs.IT cs.LG math.IT published:2015-01-01 summary:The Fast Fourier Transform (FFT) is the most efficiently known way to computethe Discrete Fourier Transform (DFT) of an arbitrary n-length signal, and has acomputational complexity of O(n log n). If the DFT X of the signal x has only knon-zero coefficients (where k < n), can we do better? In [1], we addressedthis question and presented a novel FFAST (Fast Fourier Aliasing-based SparseTransform) algorithm that cleverly induces sparse graph alias codes in the DFTdomain, via a Chinese-Remainder-Theorem (CRT)-guided sub-sampling operation ofthe time-domain samples. The resulting sparse graph alias codes are thenexploited to devise a fast and iterative onion-peeling style decoder thatcomputes an n length DFT of a signal using only O(k) time-domain samples andO(klog k) computations. The FFAST algorithm is applicable whenever k issub-linear in n (i.e. k = o(n)), but is obviously most attractive when k ismuch smaller than n. In this paper, we adapt the FFAST framework of [1] to the case where thetime-domain samples are corrupted by a white Gaussian noise. In particular, weshow that the extended noise robust algorithm R-FFAST computes an n-lengthk-sparse DFT X using O(klog ^3 n) noise-corrupted time-domain samples, inO(klog^4n) computations, i.e., sub-linear time complexity. While ourtheoretical results are for signals with a uniformly random support of thenon-zero DFT coefficients and additive white Gaussian noise, we providesimulation results which demonstrates that the R-FFAST algorithm performs welleven for signals like MR images, that have an approximately sparse Fourierspectrum with a non-uniform support for the dominant DFT coefficients.
arxiv-9600-111 | Sequence Modeling using Gated Recurrent Neural Networks | http://arxiv.org/pdf/1501.00299v1.pdf | author:Mohammad Pezeshki category:cs.NE cs.LG published:2015-01-01 summary:In this paper, we have used Recurrent Neural Networks to capture and modelhuman motion data and generate motions by prediction of the next immediate datapoint at each time-step. Our RNN is armed with recently proposed GatedRecurrent Units which has shown promising results in some sequence modelingproblems such as Machine Translation and Speech Synthesis. We demonstrate thatthis model is able to capture long-term dependencies in data and generaterealistic motions.
arxiv-9600-112 | Communication-Efficient Distributed Optimization of Self-Concordant Empirical Loss | http://arxiv.org/pdf/1501.00263v1.pdf | author:Yuchen Zhang, Lin Xiao category:math.OC cs.LG stat.ML published:2015-01-01 summary:We consider distributed convex optimization problems originated from sampleaverage approximation of stochastic optimization, or empirical riskminimization in machine learning. We assume that each machine in thedistributed computing system has access to a local empirical loss function,constructed with i.i.d. data sampled from a common distribution. We propose acommunication-efficient distributed algorithm to minimize the overall empiricalloss, which is the average of the local empirical losses. The algorithm isbased on an inexact damped Newton method, where the inexact Newton steps arecomputed by a distributed preconditioned conjugate gradient method. We analyzeits iteration complexity and communication efficiency for minimizingself-concordant empirical loss functions, and discuss the results fordistributed ridge regression, logistic regression and binary classificationwith a smoothed hinge loss. In a standard setting for supervised learning, therequired number of communication rounds of the algorithm does not increase withthe sample size, and only grows slowly with the number of machines.
arxiv-9600-113 | ModDrop: adaptive multi-modal gesture recognition | http://arxiv.org/pdf/1501.00102v2.pdf | author:Natalia Neverova, Christian Wolf, Graham W. Taylor, Florian Nebout category:cs.CV cs.HC cs.LG published:2014-12-31 summary:We present a method for gesture detection and localisation based onmulti-scale and multi-modal deep learning. Each visual modality capturesspatial information at a particular spatial scale (such as motion of the upperbody or a hand), and the whole system operates at three temporal scales. Key toour technique is a training strategy which exploits: i) careful initializationof individual modalities; and ii) gradual fusion involving random dropping ofseparate channels (dubbed ModDrop) for learning cross-modality correlationswhile preserving uniqueness of each modality-specific representation. Wepresent experiments on the ChaLearn 2014 Looking at People Challenge gesturerecognition track, in which we placed first out of 17 teams. Fusing multiplemodalities at several spatial and temporal scales leads to a significantincrease in recognition rates, allowing the model to compensate for errors ofthe individual classifiers as well as noise in the separate channels.Futhermore, the proposed ModDrop training technique ensures robustness of theclassifier to missing signals in one or several channels to produce meaningfulpredictions from any number of available modalities. In addition, wedemonstrate the applicability of the proposed fusion scheme to modalities ofarbitrary nature by experiments on the same dataset augmented with audio.
arxiv-9600-114 | ACCAMS: Additive Co-Clustering to Approximate Matrices Succinctly | http://arxiv.org/pdf/1501.00199v1.pdf | author:Alex Beutel, Amr Ahmed, Alexander J. Smola category:cs.LG stat.ML published:2014-12-31 summary:Matrix completion and approximation are popular tools to capture a user'spreferences for recommendation and to approximate missing data. Instead ofusing low-rank factorization we take a drastically different approach, based onthe simple insight that an additive model of co-clusterings allows one toapproximate matrices efficiently. This allows us to build a concise model that,per bit of model learned, significantly beats all factorization approaches tomatrix approximation. Even more surprisingly, we find that summing over smallco-clusterings is more effective in modeling matrices than classicco-clustering, which uses just one large partitioning of the matrix. Following Occam's razor principle suggests that the simple structure inducedby our model better captures the latent preferences and decision makingprocesses present in the real world than classic co-clustering or matrixfactorization. We provide an iterative minimization algorithm, a collapsedGibbs sampler, theoretical guarantees for matrix approximation, and excellentempirical evidence for the efficacy of our approach. We achievestate-of-the-art results on the Netflix problem with a fraction of the modelcomplexity.
arxiv-9600-115 | Image Super-Resolution Using Deep Convolutional Networks | http://arxiv.org/pdf/1501.00092v3.pdf | author:Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang category:cs.CV cs.NE I.4.5; I.2.6 published:2014-12-31 summary:We propose a deep learning method for single image super-resolution (SR). Ourmethod directly learns an end-to-end mapping between the low/high-resolutionimages. The mapping is represented as a deep convolutional neural network (CNN)that takes the low-resolution image as the input and outputs thehigh-resolution one. We further show that traditional sparse-coding-based SRmethods can also be viewed as a deep convolutional network. But unliketraditional methods that handle each component separately, our method jointlyoptimizes all layers. Our deep CNN has a lightweight structure, yetdemonstrates state-of-the-art restoration quality, and achieves fast speed forpractical on-line usage. We explore different network structures and parametersettings to achieve trade-offs between performance and speed. Moreover, weextend our network to cope with three color channels simultaneously, and showbetter overall reconstruction quality.
arxiv-9600-116 | HSI based colour image equalization using iterative nth root and nth power | http://arxiv.org/pdf/1501.00108v1.pdf | author:Gholamreza Anbarjafari category:cs.CV cs.GR published:2014-12-31 summary:In this paper an equalization technique for colour images is introduced. Themethod is based on nth root and nth power equalization approach but withoptimization of the mean of the image in different colour channels such as RGBand HSI. The performance of the proposed method has been measured by the meansof peak signal to noise ratio. The proposed algorithm has been compared withconventional histogram equalization and the visual and quantitativeexperimental results are showing that the proposed method over perform thehistogram equalization.
arxiv-9600-117 | Maximum Margin Clustering for State Decomposition of Metastable Systems | http://arxiv.org/pdf/1501.00125v1.pdf | author:Hao Wu category:cs.LG cs.NA cs.SY math.NA published:2014-12-31 summary:When studying a metastable dynamical system, a prime concern is how todecompose the phase space into a set of metastable states. Unfortunately, themetastable state decomposition based on simulation or experimental data isstill a challenge. The most popular and simplest approach is geometricclustering which is developed based on the classical clustering technique.However, the prerequisites of this approach are: (1) data are obtained fromsimulations or experiments which are in global equilibrium and (2) thecoordinate system is appropriately selected. Recently, the kinetic clusteringapproach based on phase space discretization and transition probabilityestimation has drawn much attention due to its applicability to more generalcases, but the choice of discretization policy is a difficult task. In thispaper, a new decomposition method designated as maximum margin metastableclustering is proposed, which converts the problem of metastable statedecomposition to a semi-supervised learning problem so that the large margintechnique can be utilized to search for the optimal decomposition without phasespace discretization. Moreover, several simulation examples are given toillustrate the effectiveness of the proposed method.
arxiv-9600-118 | Detailed Derivations of Small-Variance Asymptotics for some Hierarchical Bayesian Nonparametric Models | http://arxiv.org/pdf/1501.00052v1.pdf | author:Jonathan H. Huggins, Ardavan Saeedi, Matthew J. Johnson category:stat.ML cs.LG published:2014-12-31 summary:In this note we provide detailed derivations of two versions ofsmall-variance asymptotics for hierarchical Dirichlet process (HDP) mixturemodels and the HDP hidden Markov model (HDP-HMM, a.k.a. the infinite HMM). Weinclude derivations for the probabilities of certain CRP and CRF partitions,which are of more general interest.
arxiv-9600-119 | The continuum-of-urns scheme, generalized beta and Indian buffet processes, and hierarchies thereof | http://arxiv.org/pdf/1501.00208v1.pdf | author:Daniel M. Roy category:math.PR math.ST stat.ML stat.TH published:2014-12-31 summary:We describe the combinatorial stochastic process underlying a sequence ofconditionally independent Bernoulli processes with a shared beta process hazardmeasure. As shown by Thibaux and Jordan [TJ07], in the special case when theunderlying beta process has a constant concentration function and a finite andnonatomic mean, the combinatorial structure is that of the Indian buffetprocess (IBP) introduced by Griffiths and Ghahramani [GG05]. By reinterpretingthe beta process introduced by Hjort [Hjo90] as a measurable family ofDirichlet processes, we obtain a simple predictive rule for the general case,which can be thought of as a continuum of Blackwell-MacQueen urn schemes (orequivalently, one-parameter Hoppe urn schemes). The corresponding measurablefamily of Perman-Pitman-Yor processes leads to a continuum of two-parameterHoppe urn schemes, whose ordinary component is the three-parameter IBPintroduced by Teh and G\"or\"ur [TG09], which exhibits power-law behavior, asfurther studied by Broderick, Jordan, and Pitman [BJP12]. The idea extends toarbitrary measurable families of exchangeable partition probability functionsand gives rise to generalizations of the beta process with matching buffetprocesses. Finally, in the same way that hierarchies of Dirichlet processeswere given Chinese restaurant franchise representations by Teh, Jordan, Beal,and Blei [Teh+06], one can construct representations of sequences of Bernoulliprocesses directed by hierarchies of beta processes (and their generalizations)using the stochastic process we uncover.
arxiv-9600-120 | Learning Parameters for Weighted Matrix Completion via Empirical Estimation | http://arxiv.org/pdf/1501.00192v4.pdf | author:Jason Jo category:stat.ML published:2014-12-31 summary:Recently theoretical guarantees have been obtained for matrix completion inthe non-uniform sampling regime. In particular, if the sampling distributionaligns with the underlying matrix's leverage scores, then with high probabilitynuclear norm minimization will exactly recover the low rank matrix. In thisarticle, we analyze the scenario in which the non-uniform sampling distributionmay or may not not align with the underlying matrix's leverage scores. Here weexplore learning the parameters for weighted nuclear norm minimization in termsof the empirical sampling distribution. We provide a sufficiency condition forthese learned weights which provide an exact recovery guarantee for weightednuclear norm minimization. It has been established that a specific choice ofweights in terms of the true sampling distribution not only allows for weightednuclear norm minimization to exactly recover the low rank matrix, but alsoallows for a quantifiable relaxation in the exact recovery conditions. In thisarticle we extend this quantifiable relaxation in exact recovery conditions fora specific choice of weights defined analogously in terms of the empiricaldistribution as opposed to the true sampling distribution. To accomplish thiswe employ a concentration of measure bound and a large deviation bound. We alsopresent numerical evidence for the healthy robustness of the weighted nuclearnorm minimization algorithm to the choice of empirically learned weights. Thesenumerical experiments show that for a variety of easily computable empiricalweights, weighted nuclear norm minimization outperforms unweighted nuclear normminimization in the non-uniform sampling regime.
arxiv-9600-121 | Face recognition using color local binary pattern from mutually independent color channels | http://arxiv.org/pdf/1501.00105v1.pdf | author:Gholamreza Anbarjafari category:cs.CV published:2014-12-31 summary:In this paper, a high performance face recognition system based on localbinary pattern (LBP) using the probability distribution functions (PDF) ofpixels in different mutually independent color channels which are robust tofrontal homogenous illumination and planer rotation is proposed. Theillumination of faces is enhanced by using the state-of-the-art technique whichis using discrete wavelet transform (DWT) and singular value decomposition(SVD). After equalization, face images are segmented by use of local SuccessiveMean Quantization Transform (SMQT) followed by skin color based face detectionsystem. Kullback-Leibler Distance (KLD) between the concatenated PDFs of agiven face obtained by LBP and the concatenated PDFs of each face in thedatabase is used as a metric in the recognition process. Various decisionfusion techniques have been used in order to improve the recognition rate. Theproposed system has been tested on the FERET, HP, and Bosphorus face databases.The proposed system is compared with conventional and thestate-of-the-arttechniques. The recognition rates obtained using FVF approach for FERETdatabase is 99.78% compared with 79.60% and 68.80% for conventional gray scaleLBP and Principle Component Analysis (PCA) based face recognition techniquesrespectively.
arxiv-9600-122 | A multistep segmentation algorithm for vessel extraction in medical imaging | http://arxiv.org/pdf/1412.8656v1.pdf | author:Nasser Aghazadeh, Ladan Sharafyan Cigaroudy category:cs.CV math.NA published:2014-12-30 summary:The main contribution of this paper is to propose an iterative procedure fortubular structure segmentation of 2D images, which combines tight frame ofCurvelet transforms with a SURE technique thresholding which is based onprinciple obtained by minimizing Stein Unbiased Risk Estimate for denoising.This proposed algorithm is mainly based on the TFA proposal presented in [1,9], which we use eigenvectors of Hessian matrix of image for improving thisiterative part in segmenting unclear and narrow vessels and filling the gapbetween separate pieces of detected vessels. The experimental results arepresented to demonstrate the effectiveness of the proposed model.
arxiv-9600-123 | From Logical to Distributional Models | http://arxiv.org/pdf/1412.8527v1.pdf | author:Anne Preller category:cs.LO cs.CL quant-ph F.4.0; F.4.1 published:2014-12-30 summary:The paper relates two variants of semantic models for natural language,logical functional models and compositional distributional vector space models,by transferring the logic and reasoning from the logical to the distributionalmodels. The geometrical operations of quantum logic are reformulated as algebraicoperations on vectors. A map from functional models to vector space modelsmakes it possible to compare the meaning of sentences word by word.
arxiv-9600-124 | Disjunctive Normal Networks | http://arxiv.org/pdf/1412.8534v1.pdf | author:Mehdi Sajjadi, Mojtaba Seyedhosseini, Tolga Tasdizen category:cs.LG cs.NE published:2014-12-30 summary:Artificial neural networks are powerful pattern classifiers; however, theyhave been surpassed in accuracy by methods such as support vector machines andrandom forests that are also easier to use and faster to train.Backpropagation, which is used to train artificial neural networks, suffersfrom the herd effect problem which leads to long training times and limitclassification accuracy. We use the disjunctive normal form and approximate theboolean conjunction operations with products to construct a novel networkarchitecture. The proposed model can be trained by minimizing an error functionand it allows an effective and intuitive initialization which solves theherd-effect problem associated with backpropagation. This leads to state-of-theart classification accuracy and fast training times. In addition, our model canbe jointly optimized with convolutional features in an unified structureleading to state-of-the-art results on computer vision problems with fastconvergence rates. A GPU implementation of LDNN with optional convolutionalfeatures is also available
arxiv-9600-125 | Domain-Size Pooling in Local Descriptors: DSP-SIFT | http://arxiv.org/pdf/1412.8556v3.pdf | author:Jingming Dong, Stefano Soatto category:cs.CV published:2014-12-30 summary:We introduce a simple modification of local image descriptors, such as SIFT,based on pooling gradient orientations across different domain sizes, inaddition to spatial locations. The resulting descriptor, which we callDSP-SIFT, outperforms other methods in wide-baseline matching benchmarks,including those based on convolutional neural networks, despite having the samedimension of SIFT and requiring no training.
arxiv-9600-126 | Accurate and Conservative Estimates of MRF Log-likelihood using Reverse Annealing | http://arxiv.org/pdf/1412.8566v1.pdf | author:Yuri Burda, Roger B. Grosse, Ruslan Salakhutdinov category:cs.LG stat.ML published:2014-12-30 summary:Markov random fields (MRFs) are difficult to evaluate as generative modelsbecause computing the test log-probabilities requires the intractable partitionfunction. Annealed importance sampling (AIS) is widely used to estimate MRFpartition functions, and often yields quite accurate results. However, AIS isprone to overestimate the log-likelihood with little indication that anythingis wrong. We present the Reverse AIS Estimator (RAISE), a stochastic lowerbound on the log-likelihood of an approximation to the original MRF model.RAISE requires only the same MCMC transition operators as standard AIS.Experimental results indicate that RAISE agrees closely with AISlog-probability estimates for RBMs, DBMs, and DBNs, but typically errs on theside of underestimating, rather than overestimating, the log-likelihood.
arxiv-9600-127 | Holistic random encoding for imaging through multimode fibers | http://arxiv.org/pdf/1501.03997v1.pdf | author:Hwanchol Jang, Changhyeong Yoon, Euiheon Chung, Wonshik Choi, Heung-No Lee category:physics.optics cs.CV published:2014-12-30 summary:The input numerical aperture (NA) of multimode fiber (MMF) can be effectivelyincreased by placing turbid media at the input end of the MMF. This providesthe potential for high-resolution imaging through the MMF. While the input NAis increased, the number of propagation modes in the MMF and hence the outputNA remains the same. This makes the image reconstruction processunderdetermined and may limit the quality of the image reconstruction. In thispaper, we aim to improve the signal to noise ratio (SNR) of the imagereconstruction in imaging through MMF. We notice that turbid media placed inthe input of the MMF transforms the incoming waves into a better format forinformation transmission and information extraction. We call thistransformation as holistic random (HR) encoding of turbid media. By exploitingthe HR encoding, we make a considerable improvement on the SNR of the imagereconstruction. For efficient utilization of the HR encoding, we employ sparserepresentation (SR), a relatively new signal reconstruction framework when itis provided with a HR encoded signal. This study shows for the first time toour knowledge the benefit of utilizing the HR encoding of turbid media forrecovery in the optically underdetermined systems where the output NA of it issmaller than the input NA for imaging through MMF.
arxiv-9600-128 | Breaking the Curse of Dimensionality with Convex Neural Networks | http://arxiv.org/pdf/1412.8690v1.pdf | author:Francis Bach category:cs.LG math.OC math.ST stat.TH published:2014-12-30 summary:We consider neural networks with a single hidden layer and non-decreasinghomogeneous activa-tion functions like the rectified linear units. By lettingthe number of hidden units grow unbounded and using classical non-Euclideanregularization tools on the output weights, we provide a detailed theoreticalanalysis of their generalization performance, with a study of both theapproximation and the estimation errors. We show in particular that they areadaptive to unknown underlying linear structures, such as the dependence on theprojection of the input variables onto a low-dimensional subspace. Moreover,when using sparsity-inducing norms on the input weights, we show thathigh-dimensional non-linear variable selection may be achieved, without anystrong assumption regarding the data and with a total number of variablespotentially exponential in the number of ob-servations. In addition, we providea simple geometric interpretation to the non-convex problem of addition of anew unit, which is the core potentially hard computational element in theframework of learning from continuously many basis functions. We provide simpleconditions for convex relaxations to achieve the same generalization errorbounds, even when constant-factor approxi-mations cannot be found (e.g.,because it is NP-hard such as for the zero-homogeneous activation function). Wewere not able to find strong enough convex relaxations and leave open theexistence or non-existence of polynomial-time algorithms.
arxiv-9600-129 | A General Theory of Hypothesis Tests and Confidence Regions for Sparse High Dimensional Models | http://arxiv.org/pdf/1412.8765v2.pdf | author:Yang Ning, Han Liu category:stat.ML published:2014-12-30 summary:We consider the problem of uncertainty assessment for low dimensionalcomponents in high dimensional models. Specifically, we propose a decorrelatedscore function to handle the impact of high dimensional nuisance parameters. Weconsider both hypothesis tests and confidence regions for generic penalizedM-estimators. Unlike most existing inferential methods which are tailored forindividual models, our approach provides a general framework for highdimensional inference and is applicable to a wide range of applications. Fromthe testing perspective, we develop general theorems to characterize thelimiting distributions of the decorrelated score test statistic under both nullhypothesis and local alternatives. These results provide asymptotic guaranteeson the type I errors and local powers of the proposed test. Furthermore, weshow that the decorrelated score function can be used to construct point andconfidence region estimators that are semiparametrically efficient. We alsogeneralize this framework to broaden its applications. First, we extend it tohandle high dimensional null hypothesis, where the number of parameters ofinterest can increase exponentially fast with the sample size. Second, weestablish the theory for model misspecification. Third, we go beyond thelikelihood framework, by introducing the generalized score test based ongeneral loss functions. Thorough numerical studies are conducted to back up thedeveloped theoretical results.
arxiv-9600-130 | Deep Roto-Translation Scattering for Object Classification | http://arxiv.org/pdf/1412.8659v2.pdf | author:Edouard Oyallon, Stéphane Mallat category:cs.CV published:2014-12-30 summary:Dictionary learning algorithms or supervised deep convolution networks haveconsiderably improved the efficiency of predefined feature representations suchas SIFT. We introduce a deep scattering convolution network, with predefinedwavelet filters over spatial and angular variables. This representation bringsan important improvement to results previously obtained with predefinedfeatures over object image databases such as Caltech and CIFAR. The resultingaccuracy is comparable to results obtained with unsupervised deep learning anddictionary based representations. This shows that refining imagerepresentations by using geometric priors is a promising direction to improveimage classification and its understanding.
arxiv-9600-131 | On Semiparametric Exponential Family Graphical Models | http://arxiv.org/pdf/1412.8697v2.pdf | author:Zhuoran Yang, Yang Ning, Han Liu category:stat.ML published:2014-12-30 summary:We propose a new class of semiparametric exponential family graphical modelsfor the analysis of high dimensional mixed data. Different from the existingmixed graphical models, we allow the nodewise conditional distributions to besemiparametric generalized linear models with unspecified base measurefunctions. Thus, one advantage of our method is that it is unnecessary tospecify the type of each node and the method is more convenient to apply inpractice. Under the proposed model, we consider both problems of parameterestimation and hypothesis testing in high dimensions. In particular, we proposea symmetric pairwise score test for the presence of a single edge in the graph.Compared to the existing methods for hypothesis tests, our approach takes intoaccount of the symmetry of the parameters, such that the inferential resultsare invariant with respect to the different parametrizations of the same edge.Thorough numerical simulations and a real data example are provided to back upour results.
arxiv-9600-132 | Discriminative Clustering with Relative Constraints | http://arxiv.org/pdf/1501.00037v1.pdf | author:Yuanli Pei, Xiaoli Z. Fern, Rómer Rosales, Teresa Vania Tjahja category:cs.LG published:2014-12-30 summary:We study the problem of clustering with relative constraints, where eachconstraint specifies relative similarities among instances. In particular, eachconstraint $(x_i, x_j, x_k)$ is acquired by posing a query: is instance $x_i$more similar to $x_j$ than to $x_k$? We consider the scenario where answers tosuch queries are based on an underlying (but unknown) class concept, which weaim to discover via clustering. Different from most existing methods that onlyconsider constraints derived from yes and no answers, we also incorporate don'tknow responses. We introduce a Discriminative Clustering method with RelativeConstraints (DCRC) which assumes a natural probabilistic relationship betweeninstances, their underlying cluster memberships, and the observed constraints.The objective is to maximize the model likelihood given the constraints, and inthe meantime enforce cluster separation and cluster balance by also making useof the unlabeled instances. We evaluated the proposed method using constraintsgenerated from ground-truth class labels, and from (noisy) human judgments froma user study. Experimental results demonstrate: 1) the usefulness of relativeconstraints, in particular when don't know answers are considered; 2) theimproved performance of the proposed method over state-of-the-art methods thatutilize either relative or pairwise constraints; and 3) the robustness of ourmethod in the presence of noisy constraints, such as those provided by humanjudgement.
arxiv-9600-133 | High Dimensional Expectation-Maximization Algorithm: Statistical Optimization and Asymptotic Normality | http://arxiv.org/pdf/1412.8729v2.pdf | author:Zhaoran Wang, Quanquan Gu, Yang Ning, Han Liu category:stat.ML published:2014-12-30 summary:We provide a general theory of the expectation-maximization (EM) algorithmfor inferring high dimensional latent variable models. In particular, we maketwo contributions: (i) For parameter estimation, we propose a novel highdimensional EM algorithm which naturally incorporates sparsity structure intoparameter estimation. With an appropriate initialization, this algorithmconverges at a geometric rate and attains an estimator with the (near-)optimalstatistical rate of convergence. (ii) Based on the obtained estimator, wepropose new inferential procedures for testing hypotheses and constructingconfidence intervals for low dimensional components of high dimensionalparameters. For a broad family of statistical models, our framework establishesthe first computationally feasible approach for optimal estimation andasymptotic inference in high dimensions. Our theory is supported by thoroughnumerical results.
arxiv-9600-134 | A General Framework for Robust Testing and Confidence Regions in High-Dimensional Quantile Regression | http://arxiv.org/pdf/1412.8724v2.pdf | author:Tianqi Zhao, Mladen Kolar, Han Liu category:stat.ML published:2014-12-30 summary:We propose a robust inferential procedure for assessing uncertainties ofparameter estimation in high-dimensional linear models, where the dimension $p$can grow exponentially fast with the sample size $n$. Our method combines thede-biasing technique with the composite quantile function to construct anestimator that is asymptotically normal. Hence it can be used to constructvalid confidence intervals and conduct hypothesis tests. Our estimator isrobust and does not require the existence of first or second moment of thenoise distribution. It also preserves efficiency in the sense that the worstcase efficiency loss is less than 30\% compared to the square-loss-basedde-biased Lasso estimator. In many cases our estimator is close to or betterthan the latter, especially when the noise is heavy-tailed. Our de-biasingprocedure does not require solving the $L_1$-penalized composite quantileregression. Instead, it allows for any first-stage estimator with desiredconvergence rate and empirical sparsity. The paper also provides new prooftechniques for developing theoretical guarantees of inferential procedures withnon-smooth loss functions. To establish the main results, we exploit the localcurvature of the conditional expectation of composite quantile loss and applyempirical process theories to control the difference between empiricalquantities and their conditional expectations. Our results are establishedunder weaker assumptions compared to existing work on inference forhigh-dimensional quantile regression. Furthermore, we consider ahigh-dimensional simultaneous test for the regression parameters by applyingthe Gaussian approximation and multiplier bootstrap theories. We also studydistributed learning and exploit the divide-and-conquer estimator to reducecomputation complexity when the sample size is massive. Finally, we provideempirical results to verify the theory.
arxiv-9600-135 | Probing the topological properties of complex networks modeling short written texts | http://arxiv.org/pdf/1412.8504v1.pdf | author:Diego R. Amancio category:cs.CL physics.soc-ph published:2014-12-29 summary:In recent years, graph theory has been widely employed to probe severallanguage properties. More specifically, the so-called word adjacency model hasbeen proven useful for tackling several practical problems, especially thoserelying on textual stylistic analysis. The most common approach to treat textsas networks has simply considered either large pieces of texts or entire books.This approach has certainly worked well -- many informative discoveries havebeen made this way -- but it raises an uncomfortable question: could there beimportant topological patterns in small pieces of texts? To address thisproblem, the topological properties of subtexts sampled from entire books wasprobed. Statistical analyzes performed on a dataset comprising 50 novelsrevealed that most of the traditional topological measurements are stable forshort subtexts. When the performance of the authorship recognition task wasanalyzed, it was found that a proper sampling yields a discriminability similarto the one found with full texts. Surprisingly, the support vector machineclassification based on the characterization of short texts outperformed theone performed with entire books. These findings suggest that a localtopological analysis of large documents might improve its globalcharacterization. Most importantly, it was verified, as a proof of principle,that short texts can be analyzed with the methods and concepts of complexnetworks. As a consequence, the techniques described here can be extended in astraightforward fashion to analyze texts as time-varying complex networks.
arxiv-9600-136 | Rigid and Non-rigid Shape Evolutions for Shape Alignment and Recovery in Images | http://arxiv.org/pdf/1412.8287v1.pdf | author:Junyan Wang, Kap-Luk Chan category:cs.CV published:2014-12-29 summary:The same type of objects in different images may vary in their shapes becauseof rigid and non-rigid shape deformations, occluding foreground as well ascluttered background. The problem concerned in this work is the shapeextraction in such challenging situations. We approach the shape extractionthrough shape alignment and recovery. This paper presents a novel and generalmethod for shape alignment and recovery by using one example shapes based ondeterministic energy minimization. Our idea is to use general model of shapedeformation in minimizing active contour energies. Given \emph{a priori} formof the shape deformation, we show how the curve evolution equationcorresponding to the shape deformation can be derived. The curve evolution iscalled the prior variation shape evolution (PVSE). We also derive theenergy-minimizing PVSE for minimizing active contour energies. For shaperecovery, we propose to use the PVSE that deforms the shape while preservingits shape characteristics. For choosing such shape-preserving PVSE, a theory ofshape preservability of the PVSE is established. Experimental results validatethe theory and the formulations, and they demonstrate the effectiveness of ourmethod.
arxiv-9600-137 | Accurate Localization in Dense Urban Area Using Google Street View Image | http://arxiv.org/pdf/1412.8496v1.pdf | author:Mahdi Salarian category:cs.CV published:2014-12-29 summary:Accurate information about the location and orientation of a camera in mobiledevices is central to the utilization of location-based services (LBS). Most ofsuch mobile devices rely on GPS data but this data is subject to inaccuracy dueto imperfections in the quality of the signal provided by satellites. Thisshortcoming has spurred the research into improving the accuracy oflocalization. Since mobile devices have camera, a major thrust of this researchhas been seeks to acquire the local scene and apply image retrieval techniquesby querying a GPS-tagged image database to find the best match for the acquiredscene.. The techniques are however computationally demanding and unsuitable forreal-time applications such as assistive technology for navigation by the blindand visually impaired which motivated out work. To overcome the high complexityof those techniques, we investigated the use of inertial sensors as an aid inimage-retrieval-based approach. Armed with information of media other thanimages, such as data from the GPS module along with orientation sensors such asaccelerometer and gyro, we sought to limit the size of the image set to csearch for the best match. Specifically, data from the orientation sensorsalong with Dilution of precision (DOP) from GPS are used to find the angle ofview and estimation of position. We present analysis of the reduction in theimage set size for the search as well as simulations to demonstrate theeffectiveness in a fast implementation with 98% Estimated Position Error.
arxiv-9600-138 | An ADMM algorithm for solving a proximal bound-constrained quadratic program | http://arxiv.org/pdf/1412.8493v1.pdf | author:Miguel Á. Carreira-Perpiñán category:math.OC cs.LG stat.ML published:2014-12-29 summary:We consider a proximal operator given by a quadratic function subject tobound constraints and give an optimization algorithm using the alternatingdirection method of multipliers (ADMM). The algorithm is particularly efficientto solve a collection of proximal operators that share the same quadratic form,or if the quadratic program is the relaxation of a binary quadratic problem.
arxiv-9600-139 | Marginal likelihood and model selection for Gaussian latent tree and forest models | http://arxiv.org/pdf/1412.8285v2.pdf | author:Mathias Drton, Shaowei Lin, Luca Weihs, Piotr Zwiernik category:stat.ME math.ST stat.ML stat.TH published:2014-12-29 summary:Gaussian latent tree models, or more generally, Gaussian latent forest modelshave Fisher-information matrices that become singular along interestingsubmodels, namely, models that correspond to subforests. For thesesingularities, we compute the real log-canonical thresholds (also known asstochastic complexities or learning coefficients) that quantify thelarge-sample behavior of the marginal likelihood in Bayesian inference. Thisprovides the information needed for a recently introduced generalization of theBayesian information criterion. Our mathematical developments treat the generalsetting of Laplace integrals whose phase functions are sums of squareddifferences between monomials and constants. We clarify how in this case reallog-canonical thresholds can be computed using polyhedral geometry, and we showhow to apply the general theory to the Laplace integrals associated withGaussian latent tree and forest models. In simulations and a data example, wedemonstrate how the mathematical knowledge can be applied in model selection.
arxiv-9600-140 | Quasi-Monte Carlo Feature Maps for Shift-Invariant Kernels | http://arxiv.org/pdf/1412.8293v2.pdf | author:Haim Avron, Vikas Sindhwani, Jiyan Yang, Michael Mahoney category:stat.ML cs.LG math.NA stat.CO published:2014-12-29 summary:We consider the problem of improving the efficiency of randomized Fourierfeature maps to accelerate training and testing speed of kernel methods onlarge datasets. These approximate feature maps arise as Monte Carloapproximations to integral representations of shift-invariant kernel functions(e.g., Gaussian kernel). In this paper, we propose to use Quasi-Monte Carlo(QMC) approximations instead, where the relevant integrands are evaluated on alow-discrepancy sequence of points as opposed to random point sets as in theMonte Carlo approach. We derive a new discrepancy measure called boxdiscrepancy based on theoretical characterizations of the integration errorwith respect to a given sequence. We then propose to learn QMC sequencesadapted to our setting based on explicit box discrepancy minimization. Ourtheoretical analyses are complemented with empirical results that demonstratethe effectiveness of classical and adaptive QMC techniques for this problem.
arxiv-9600-141 | Simple Image Description Generator via a Linear Phrase-Based Approach | http://arxiv.org/pdf/1412.8419v3.pdf | author:Remi Lebret, Pedro O. Pinheiro, Ronan Collobert category:cs.CL cs.CV cs.NE published:2014-12-29 summary:Generating a novel textual description of an image is an interesting problemthat connects computer vision and natural language processing. In this paper,we present a simple model that is able to generate descriptive sentences givena sample image. This model has a strong focus on the syntax of thedescriptions. We train a purely bilinear model that learns a metric between animage representation (generated from a previously trained Convolutional NeuralNetwork) and phrases that are used to described them. The system is then ableto infer phrases from a given image sample. Based on caption syntax statistics,we propose a simple language model that can produce relevant descriptions for agiven test image using the phrases inferred. Our approach, which isconsiderably simpler than state-of-the-art models, achieves comparable resultson the recently release Microsoft COCO dataset.
arxiv-9600-142 | Spy vs. Spy: Rumor Source Obfuscation | http://arxiv.org/pdf/1412.8439v3.pdf | author:Giulia Fanti, Peter Kairouz, Sewoong Oh, Pramod Viswanath category:cs.SI cs.LG published:2014-12-29 summary:Anonymous messaging platforms, such as Secret and Whisper, have emerged asimportant social media for sharing one's thoughts without the fear of beingjudged by friends, family, or the public. Further, such anonymous platforms arecrucial in nations with authoritarian governments; the right to free expressionand sometimes the personal safety of the author of the message depend onanonymity. Whether for fear of judgment or personal endangerment, it is crucialto keep anonymous the identity of the user who initially posted a sensitivemessage. In this paper, we consider an adversary who observes a snapshot of thespread of a message at a certain time. Recent advances in rumor sourcedetection shows that the existing messaging protocols are vulnerable againstsuch an adversary. We introduce a novel messaging protocol, which we calladaptive diffusion, and show that it spreads the messages fast and achieves aperfect obfuscation of the source when the underlying contact network is aninfinite regular tree: all users with the message are nearly equally likely tohave been the origin of the message. Experiments on a sampled Facebook networkshow that it effectively hides the location of the source even when the graphis finite, irregular and has cycles. We further consider a stronger adversarialmodel where a subset of colluding users track the reception of messages. Weshow that the adaptive diffusion provides a strong protection of the anonymityof the source even under this scenario.
arxiv-9600-143 | Quantifying origin and character of long-range correlations in narrative texts | http://arxiv.org/pdf/1412.8319v2.pdf | author:Stanisław Drożdż, Paweł Oświęcimka, Andrzej Kulig, Jarosław Kwapień, Katarzyna Bazarnik, Iwona Grabska-Gradzińska, Jan Rybicki, Marek Stanuszek category:cs.CL physics.soc-ph published:2014-12-29 summary:In natural language using short sentences is considered efficient forcommunication. However, a text composed exclusively of such sentences lookstechnical and reads boring. A text composed of long ones, on the other hand,demands significantly more effort for comprehension. Studying characteristicsof the sentence length variability (SLV) in a large corpus of world-famousliterary texts shows that an appealing and aesthetic optimum appears somewherein between and involves selfsimilar, cascade-like alternation of variouslengths sentences. A related quantitative observation is that the power spectraS(f) of thus characterized SLV universally develop a convincing `1/f^beta'scaling with the average exponent beta =~ 1/2, close to what has beenidentified before in musical compositions or in the brain waves. Anoverwhelming majority of the studied texts simply obeys such fractal attributesbut especially spectacular in this respect are hypertext-like, "stream ofconsciousness" novels. In addition, they appear to develop structurescharacteristic of irreducibly interwoven sets of fractals called multifractals.Scaling of S(f) in the present context implies existence of the long-rangecorrelations in texts and appearance of multifractality indicates that theycarry even a nonlinear component. A distinct role of the full stops in inducingthe long-range correlations in texts is evidenced by the fact that the abovequantitative characteristics on the long-range correlations manifest themselvesin variation of the full stops recurrence times along texts, thus in SLV, butto a much lesser degree in the recurrence times of the most frequent words. Inthis latter case the nonlinear correlations, thus multifractality, disappeareven completely for all the texts considered. Treated as one extra word, thefull stops at the same time appear to obey the Zipfian rank-frequencydistribution, however.
arxiv-9600-144 | A simple coding for cross-domain matching with dimension reduction via spectral graph embedding | http://arxiv.org/pdf/1412.8380v2.pdf | author:Hidetoshi Shimodaira category:stat.ML cs.CV cs.LG published:2014-12-29 summary:Data vectors are obtained from multiple domains. They are feature vectors ofimages or vector representations of words. Domains may have different numbersof data vectors with different dimensions. These data vectors from multipledomains are projected to a common space by linear transformations in order tosearch closely related vectors across domains. We would like to find projectionmatrices to minimize distances between closely related data vectors. Thisformulation of cross-domain matching is regarded as an extension of thespectral graph embedding to multi-domain setting, and it includes severalmultivariate analysis methods of statistics such as multiset canonicalcorrelation analysis, correspondence analysis, and principal componentanalysis. Similar approaches are very popular recently in pattern recognitionand vision. In this paper, instead of proposing a novel method, we willintroduce an embarrassingly simple idea of coding the data vectors forexplaining all the above mentioned approaches. A data vector is concatenatedwith zero vectors from all other domains to make an augmented vector. Thecross-domain matching is solved by applying the single-domain version ofspectral graph embedding to these augmented vectors of all the domains. Aninteresting connection to the classical associative memory model of neuralnetworks is also discussed by noticing a coding for association. Across-validation method for choosing the dimension of the common space and aregularization parameter will be discussed in an illustrative numericalexample.
arxiv-9600-145 | Spectral classification using convolutional neural networks | http://arxiv.org/pdf/1412.8341v1.pdf | author:Pavel Hála category:cs.CV astro-ph.IM cs.NE published:2014-12-29 summary:There is a great need for accurate and autonomous spectral classificationmethods in astrophysics. This thesis is about training a convolutional neuralnetwork (ConvNet) to recognize an object class (quasar, star or galaxy) fromone-dimension spectra only. Author developed several scripts and C programs fordatasets preparation, preprocessing and postprocessing of the data. EBLearnlibrary (developed by Pierre Sermanet and Yann LeCun) was used to createConvNets. Application on dataset of more than 60000 spectra yielded successrate of nearly 95%. This thesis conclusively proved great potential ofconvolutional neural networks and deep learning methods in astrophysics.
arxiv-9600-146 | Alternating Minimization Algorithm with Automatic Relevance Determination for Transmission Tomography under Poisson Noise | http://arxiv.org/pdf/1412.8464v2.pdf | author:Yan Kaganovsky, Shaobo Han, Soysal Degirmenci, David G. Politte, David J. Brady, Joseph A. O'Sullivan, Lawrence Carin category:math.NA stat.ML published:2014-12-29 summary:We propose a globally convergent alternating minimization (AM) algorithm forimage reconstruction in transmission tomography, which extends automaticrelevance determination (ARD) to Poisson noise models with Beer's law. Thealgorithm promotes solutions that are sparse in the pixel/voxel-differencesdomain by introducing additional latent variables, one for each pixel/voxel,and then learning these variables from the data using a hierarchical Bayesianmodel. Importantly, the proposed AM algorithm is free of any tuning parameterswith image quality comparable to standard penalized likelihood methods. Ouralgorithm exploits optimization transfer principles which reduce the probleminto parallel 1D optimization tasks (one for each pixel/voxel), making thealgorithm feasible for large-scale problems. This approach considerably reducesthe computational bottleneck of ARD associated with the posterior variances.Positivity constraints inherent in transmission tomography problems are alsoenforced. We demonstrate the performance of the proposed algorithm for x-raycomputed tomography using synthetic and real-world datasets. The algorithm isshown to have much better performance than prior ARD algorithms based onapproximate Gaussian noise models, even for high photon flux.
arxiv-9600-147 | Improving approximate RPCA with a k-sparsity prior | http://arxiv.org/pdf/1412.8291v1.pdf | author:Maximilian Karl, Christian Osendorfer category:cs.NE cs.LG published:2014-12-29 summary:A process centric view of robust PCA (RPCA) allows its fast approximateimplementation based on a special form o a deep neural network with weightsshared across all layers. However, empirically this fast approximation to RPCAfails to find representations that are parsemonious. We resolve these bad localminima by relaxing the elementwise L1 and L2 priors and instead utilize astructure inducing k-sparsity prior. In a discriminative classification taskthe newly learned representations outperform these from the originalapproximate RPCA formulation significantly.
arxiv-9600-148 | Fast, simple and accurate handwritten digit classification by training shallow neural network classifiers with the 'extreme learning machine' algorithm | http://arxiv.org/pdf/1412.8307v2.pdf | author:Mark D. McDonnell, Migel D. Tissera, Tony Vladusich, André van Schaik, Jonathan Tapson category:cs.NE cs.CV cs.LG published:2014-12-29 summary:Recent advances in training deep (multi-layer) architectures have inspired arenaissance in neural network use. For example, deep convolutional networks arebecoming the default option for difficult tasks on large datasets, such asimage and speech recognition. However, here we show that error rates below 1%on the MNIST handwritten digit benchmark can be replicated with shallownon-convolutional neural networks. This is achieved by training such networksusing the 'Extreme Learning Machine' (ELM) approach, which also enables a veryrapid training time (~10 minutes). Adding distortions, as is common practisefor MNIST, reduces error rates even further. Our methods are also shown to becapable of achieving less than 5.5% error rates on the NORB image database. Toachieve these results, we introduce several enhancements to the standard ELMalgorithm, which individually and in combination can significantly improveperformance. The main innovation is to ensure each hidden-unit operates only ona randomly sized and positioned patch of each image. This form of random`receptive field' sampling of the input ensures the input weight matrix issparse, with about 90% of weights equal to zero. Furthermore, combining ourmethods with a small number of iterations of a single-batch backpropagationmethod can significantly reduce the number of hidden-units required to achievea particular performance. Our close to state-of-the-art results for MNIST andNORB suggest that the ease of use and accuracy of the ELM algorithm fordesigning a single-hidden-layer neural network classifier should cause it to begiven greater consideration either as a standalone method for simpler problems,or as the final classification stage in deep neural networks applied to moredifficult problems.
arxiv-9600-149 | Improving Persian Document Classification Using Semantic Relations between Words | http://arxiv.org/pdf/1412.8147v1.pdf | author:Saeed Parseh, Ahmad Baraani category:cs.IR cs.LG published:2014-12-28 summary:With the increase of information, document classification as one of themethods of text mining, plays vital role in many management and organizinginformation. Document classification is the process of assigning a document toone or more predefined category labels. Document classification includesdifferent parts such as text processing, term selection, term weighting andfinal classification. The accuracy of document classification is veryimportant. Thus improvement in each part of classification should lead tobetter results and higher precision. Term weighting has a great impact on theaccuracy of the classification. Most of the existing weighting methods exploitthe statistical information of terms in documents and do not consider semanticrelations between words. In this paper, an automated document classificationsystem is presented that uses a novel term weighting method based on semanticrelations between terms. To evaluate the proposed method, three standardPersian corpuses are used. Experiment results show 2 to 4 percent improvementin classification accuracy compared with the best previous designed system forPersian documents.
arxiv-9600-150 | Metacarpal Bones Localization in X-ray Imagery Using Particle Filter Segmentation | http://arxiv.org/pdf/1412.8197v2.pdf | author:Z. Bardosi, D. Granata, G. Lugos, A. P. Tafti, S. Saxena category:cs.CV published:2014-12-28 summary:Statistical methods such as sequential Monte Carlo Methods were proposed fordetection, segmentation and tracking of objects in digital images. A similarapproach, called Shape Particle Filters was introduced for the segmentation ofvertebra, lungs and hearts [1]. In this contribution, a global shape and alocal appearance model are derived from specific object annotated X-ray imagesof the metacarpal bones. In the test data a unique labeling of the boneboundary and the background points and a manual annotation is given. Using aset of local features (Haar-like) in the neighborhood of each pixel aprobabilistic pixel classifier is built using the random forest algorithm. Tofit the shape model to a new image, a label probability map is extracted andthen the optimal shape is obtained by maximizing the probability of eachlandmark with the Differential Evolution algorithm.
arxiv-9600-151 | Proceedings of the 11th workshop on Quantum Physics and Logic | http://arxiv.org/pdf/1412.8102v1.pdf | author:Bob Coecke, Ichiro Hasuo, Prakash Panangaden category:cs.LO cs.CL cs.PL quant-ph published:2014-12-28 summary:This volume contains the proceedings of the 11th International Workshop onQuantum Physics and Logic (QPL 2014), which was held from the 4th to the 6th ofJune, 2014, at Kyoto University, Japan. The goal of the QPL workshop series is to bring together researchers workingon mathematical foundations of quantum physics, quantum computing andspatio-temporal causal structures, and in particular those that use logicaltools, ordered algebraic and category-theoretic structures, formal languages,semantic methods and other computer science methods for the study of physicalbehavior in general. Over the past few years, there has been growing activityin these foundational approaches, together with a renewed interest in thefoundations of quantum theory, which complement the more mainstream research inquantum computation. Earlier workshops in this series, with the same acronymunder the name "Quantum Programming Languages", were held in Ottawa (2003),Turku (2004), Chicago (2005), and Oxford (2006). The first QPL under the newname Quantum Physics and Logic was held in Reykjavik (2008), followed by Oxford(2009 and 2010), Nijmegen (2011), Brussels (2012) and Barcelona (2013).
arxiv-9600-152 | Coordinate Descent with Arbitrary Sampling II: Expected Separable Overapproximation | http://arxiv.org/pdf/1412.8063v2.pdf | author:Zheng Qu, Peter Richtárik category:math.OC cs.LG cs.NA math.NA math.PR published:2014-12-27 summary:The design and complexity analysis of randomized coordinate descent methods,and in particular of variants which update a random subset (sampling) ofcoordinates in each iteration, depends on the notion of expected separableoverapproximation (ESO). This refers to an inequality involving the objectivefunction and the sampling, capturing in a compact way certain smoothnessproperties of the function in a random subspace spanned by the sampledcoordinates. ESO inequalities were previously established for special classesof samplings only, almost invariably for uniform samplings. In this paper wedevelop a systematic technique for deriving these inequalities for a largeclass of functions and for arbitrary samplings. We demonstrate that one canrecover existing ESO results using our general approach, which is based on thestudy of eigenvalues associated with samplings and the data describing thefunction.
arxiv-9600-153 | Coordinate Descent with Arbitrary Sampling I: Algorithms and Complexity | http://arxiv.org/pdf/1412.8060v2.pdf | author:Zheng Qu, Peter Richtárik category:math.OC cs.LG cs.NA math.NA published:2014-12-27 summary:We study the problem of minimizing the sum of a smooth convex function and aconvex block-separable regularizer and propose a new randomized coordinatedescent method, which we call ALPHA. Our method at every iteration updates arandom subset of coordinates, following an arbitrary distribution. Nocoordinate descent methods capable to handle an arbitrary sampling have beenstudied in the literature before for this problem. ALPHA is a remarkablyflexible algorithm: in special cases, it reduces to deterministic andrandomized methods such as gradient descent, coordinate descent, parallelcoordinate descent and distributed coordinate descent -- both in nonacceleratedand accelerated variants. The variants with arbitrary (or importance) samplingare new. We provide a complexity analysis of ALPHA, from which we deduce as adirect corollary complexity bounds for its many variants, all matching orimproving best known bounds.
arxiv-9600-154 | Persian Sentiment Analyzer: A Framework based on a Novel Feature Selection Method | http://arxiv.org/pdf/1412.8079v1.pdf | author:Ayoub Bagheri, Mohamad Saraee category:cs.CL cs.IR published:2014-12-27 summary:In the recent decade, with the enormous growth of digital content in internetand databases, sentiment analysis has received more and more attention betweeninformation retrieval and natural language processing researchers. Sentimentanalysis aims to use automated tools to detect subjective information fromreviews. One of the main challenges in sentiment analysis is feature selection.Feature selection is widely used as the first stage of analysis andclassification tasks to reduce the dimension of problem, and improve speed bythe elimination of irrelevant and redundant features. Up to now as there arefew researches conducted on feature selection in sentiment analysis, there arevery rare works for Persian sentiment analysis. This paper considers theproblem of sentiment classification using different feature selection methodsfor online customer reviews in Persian language. Three of the challenges ofPersian text are using of a wide variety of declensional suffixes, differentword spacing and many informal or colloquial words. In this paper we studythese challenges by proposing a model for sentiment classification of Persianreview documents. The proposed model is based on lemmatization and featureselection and is employed Naive Bayes algorithm for classification. We evaluatethe performance of the model on a manually gathered collection of cellphonereviews, where the results show the effectiveness of the proposed approaches.
arxiv-9600-155 | Construction of Vietnamese SentiWordNet by using Vietnamese Dictionary | http://arxiv.org/pdf/1412.8010v1.pdf | author:Xuan-Son Vu, Seong-Bae Park category:cs.CL published:2014-12-27 summary:SentiWordNet is an important lexical resource supporting sentiment analysisin opinion mining applications. In this paper, we propose a novel approach toconstruct a Vietnamese SentiWordNet (VSWN). SentiWordNet is typically generatedfrom WordNet in which each synset has numerical scores to indicate its opinionpolarities. Many previous studies obtained these scores by applying a machinelearning method to WordNet. However, Vietnamese WordNet is not availableunfortunately by the time of this paper. Therefore, we propose a method toconstruct VSWN from a Vietnamese dictionary, not from WordNet. We show theeffectiveness of the proposed method by generating a VSWN with 39,561 synsetsautomatically. The method is experimentally tested with 266 synsets with aspectof positivity and negativity. It attains a competitive result compared withEnglish SentiWordNet that is 0.066 and 0.052 differences for positivity andnegativity sets respectively.
arxiv-9600-156 | Functional correspondence by matrix completion | http://arxiv.org/pdf/1412.8070v1.pdf | author:Artiom Kovnatsky, Michael M. Bronstein, Xavier Bresson, Pierre Vandergheynst category:cs.CV published:2014-12-27 summary:In this paper, we consider the problem of finding dense intrinsiccorrespondence between manifolds using the recently introduced functionalframework. We pose the functional correspondence problem as matrix completionwith manifold geometric structure and inducing functional localization with the$L_1$ norm. We discuss efficient numerical procedures for the solution of ourproblem. Our method compares favorably to the accuracy of state-of-the-artcorrespondence algorithms on non-rigid shape matching benchmarks, and isespecially advantageous in settings when only scarce data is available.
arxiv-9600-157 | Adjusting Leverage Scores by Row Weighting: A Practical Approach to Coherent Matrix Completion | http://arxiv.org/pdf/1412.7938v2.pdf | author:Shusen Wang, Tong Zhang, Zhihua Zhang category:cs.LG stat.ML published:2014-12-26 summary:Low-rank matrix completion is an important problem with extensive real-worldapplications. When observations are uniformly sampled from the underlyingmatrix entries, existing methods all require the matrix to be incoherent. Thispaper provides the first working method for coherent matrix completion underthe standard uniform sampling model. Our approach is based on the weightednuclear norm minimization idea proposed in several recent work, and our keycontribution is a practical method to compute the weighting matrices so thatthe leverage scores become more uniform after weighting. Under suitableconditions, we are able to derive theoretical results, showing theeffectiveness of our approach. Experiments on synthetic data show that ourapproach recovers highly coherent matrices with high precision, whereas thestandard unweighted method fails even on noise-free data.
arxiv-9600-158 | Exploring Sparsity in Multi-class Linear Discriminant Analysis | http://arxiv.org/pdf/1412.7983v2.pdf | author:Dong Xia category:stat.ML I.5.2 published:2014-12-26 summary:Recent studies in the literature have paid much attention to the sparsity inlinear classification tasks. One motivation of imposing sparsity assumption onthe linear discriminant direction is to rule out the noninformative features,making hardly contribution to the classification problem. Most of those workwere focused on the scenarios of binary classification. In the presence ofmulti-class data, preceding researches recommended individually pairwise sparselinear discriminant analysis(LDA). However, further sparsity should beexplored. In this paper, an estimator of grouped LASSO type is proposed to takeadvantage of sparsity for multi-class data. It enjoys appealing non-asymptoticproperties which allows insignificant correlations among features. Thisestimator exhibits superior capability on both simulated and real data.
arxiv-9600-159 | Predicting User Engagement in Twitter with Collaborative Ranking | http://arxiv.org/pdf/1412.7990v1.pdf | author:Ernesto Diaz-Aviles, Hoang Thanh Lam, Fabio Pinelli, Stefano Braghin, Yiannis Gkoufas, Michele Berlingerio, Francesco Calabrese category:cs.IR cs.CY cs.LG H.3.3; I.2.6 published:2014-12-26 summary:Collaborative Filtering (CF) is a core component of popular web-basedservices such as Amazon, YouTube, Netflix, and Twitter. Most applications useCF to recommend a small set of items to the user. For instance, YouTubepresents to a user a list of top-n videos she would likely watch next based onher rating and viewing history. Current methods of CF evaluation have beenfocused on assessing the quality of a predicted rating or the rankingperformance for top-n recommended items. However, restricting the recommendersystem evaluation to these two aspects is rather limiting and neglects otherdimensions that could better characterize a well-perceived recommendation. Inthis paper, instead of optimizing rating or top-n recommendation, we focus onthe task of predicting which items generate the highest user engagement. Inparticular, we use Twitter as our testbed and cast the problem as aCollaborative Ranking task where the rich features extracted from the metadataof the tweets help to complement the transaction information limited to userids, item ids, ratings and timestamps. We learn a scoring function thatdirectly optimizes the user engagement in terms of nDCG@10 on the predictedranking. Experiments conducted on an extended version of the MovieTweetingsdataset, released as part of the RecSys Challenge 2014, show the effectivenessof our approach.
arxiv-9600-160 | Polyphonic Music Generation by Modeling Temporal Dependencies Using a RNN-DBN | http://arxiv.org/pdf/1412.7927v1.pdf | author:Kratarth Goel, Raunaq Vohra, J. K. Sahoo category:cs.LG cs.AI cs.NE published:2014-12-26 summary:In this paper, we propose a generic technique to model temporal dependenciesand sequences using a combination of a recurrent neural network and a DeepBelief Network. Our technique, RNN-DBN, is an amalgamation of the memory stateof the RNN that allows it to provide temporal information and a multi-layer DBNthat helps in high level representation of the data. This makes RNN-DBNs idealfor sequence generation. Further, the use of a DBN in conjunction with the RNNmakes this model capable of significantly more complex data representation thanan RBM. We apply this technique to the task of polyphonic music generation.
arxiv-9600-161 | A Novel Feature Selection and Extraction Technique for Classification | http://arxiv.org/pdf/1412.7934v1.pdf | author:Kratarth Goel, Raunaq Vohra, Ainesh Bakshi category:cs.LG cs.CV published:2014-12-26 summary:This paper presents a versatile technique for the purpose of featureselection and extraction - Class Dependent Features (CDFs). We use CDFs toimprove the accuracy of classification and at the same time controlcomputational expense by tackling the curse of dimensionality. In order todemonstrate the generality of this technique, it is applied to handwrittendigit recognition and text categorization.
arxiv-9600-162 | Enhancing fractal descriptors on images by combining boundary and interior of Minkowski dilation | http://arxiv.org/pdf/1412.7880v1.pdf | author:Marcos W. S. Oliveira, Dalcimar Casanova, João B. Florindo, Odemir Martinez Bruno category:cs.CV published:2014-12-26 summary:This work proposes to obtain novel fractal descriptors from gray-leveltexture images by combining information from interior and boundary measures ofthe Minkowski dilation applied to the texture surface. At first, the image isconverted into a surface where the height of each point is the gray intensityof the respective pixel in that position in the image. Thus, this surface ismorphologically dilated by spheres. The radius of such spheres is ranged withinan interval and the volume and the external area of the dilated structure arecomputed for each radius. The final descriptors are given by such measuresconcatenated and subject to a canonical transform to reduce the dimensionality.The proposal is an enhancement to the classical Bouligand-Minkowski fractaldescriptors, where only the volume (interior) information is considered. Asdifferent structures may have the same volume, but not the same area, theproposal yields to more rich descriptors as confirmed by results on theclassification of benchmark databases.
arxiv-9600-163 | Unsupervised Learning through Prediction in a Model of Cortex | http://arxiv.org/pdf/1412.7955v1.pdf | author:Christos H. Papadimitriou, Santosh S. Vempala category:cs.NE cs.DS q-bio.NC stat.ML published:2014-12-26 summary:We propose a primitive called PJOIN, for "predictive join," which combinesand extends the operations JOIN and LINK, which Valiant proposed as the basisof a computational theory of cortex. We show that PJOIN can be implemented inValiant's model. We also show that, using PJOIN, certain reasonably complexlearning and pattern matching tasks can be performed, in a way that involvesphenomena which have been observed in cognition and the brain, namelymemory-based prediction and downward traffic in the cortical hierarchy.
arxiv-9600-164 | Improved texture image classification through the use of a corrosion-inspired cellular automaton | http://arxiv.org/pdf/1412.7889v1.pdf | author:Núbia Rosa da Silva, Pieter Van der Weeën, Bernard De Baets, Odemir Martinez Bruno category:cs.CV published:2014-12-26 summary:In this paper, the problem of classifying synthetic and natural textureimages is addressed. To tackle this problem, an innovative method is proposedthat combines concepts from corrosion modeling and cellular automata togenerate a texture descriptor. The core processes of metal (pitting) corrosionare identified and applied to texture images by incorporating the basicmechanisms of corrosion in the transition function of the cellular automaton.The surface morphology of the image is analyzed before and during theapplication of the transition function of the cellular automaton. In eachiteration the cumulative mass of corroded product is obtained to construct eachof the attributes of the texture descriptor. In a final step, this texturedescriptor is used for image classification by applying Linear DiscriminantAnalysis. The method was tested on the well-known Brodatz and Vistex databases.In addition, in order to verify the robustness of the method, its invariance tonoise and rotation were tested. To that end, different variants of the originaltwo databases were obtained through addition of noise to and rotation of theimages. The results showed that the method is effective for textureclassification according to the high success rates obtained in all cases. Thisindicates the potential of employing methods inspired on natural phenomena inother fields.
arxiv-9600-165 | Sparkle Vision: Seeing the World through Random Specular Microfacets | http://arxiv.org/pdf/1412.7884v1.pdf | author:Zhengdong Zhang, Phillip Isola, Edward H. Adelson category:cs.CV published:2014-12-26 summary:In this paper, we study the problem of reproducing the world lighting from asingle image of an object covered with random specular microfacets on thesurface. We show that such reflectors can be interpreted as a randomizedmapping from the lighting to the image. Such specular objects have verydifferent optical properties from both diffuse surfaces and smooth specularobjects like metals, so we design special imaging system to robustly andeffectively photograph them. We present simple yet reliable algorithms tocalibrate the proposed system and do the inference. We conduct experiments toverify the correctness of our model assumptions and prove the effectiveness ofour pipeline.
arxiv-9600-166 | Detect2Rank : Combining Object Detectors Using Learning to Rank | http://arxiv.org/pdf/1412.7957v1.pdf | author:Sezer Karaoglu, Yang Liu, Theo Gevers category:cs.CV published:2014-12-26 summary:Object detection is an important research area in the field of computervision. Many detection algorithms have been proposed. However, each objectdetector relies on specific assumptions of the object appearance and imagingconditions. As a consequence, no algorithm can be considered as universal. Withthe large variety of object detectors, the subsequent question is how to selectand combine them. In this paper, we propose a framework to learn how to combine objectdetectors. The proposed method uses (single) detectors like DPM, CN and EES,and exploits their correlation by high level contextual features to yield acombined detection list. Experiments on the PASCAL VOC07 and VOC10 datasets show that the proposedmethod significantly outperforms single object detectors, DPM (8.4%), CN (6.8%)and EES (17.0%) on VOC07 and DPM (6.5%), CN (5.5%) and EES (16.2%) on VOC10.
arxiv-9600-167 | Texture analysis by multi-resolution fractal descriptors | http://arxiv.org/pdf/1412.7963v1.pdf | author:João B. Florindo, Odemir M. Bruno category:cs.CV published:2014-12-26 summary:This work proposes a texture descriptor based on fractal theory. The methodis based on the Bouligand-Minkowski descriptors. We decompose the originalimage recursively into 4 equal parts. In each recursion step, we estimate theaverage and the deviation of the Bouligand-Minkowski descriptors computed overeach part. Thus, we extract entropy features from both average and deviation.The proposed descriptors are provided by the concatenation of such measures.The method is tested in a classification experiment under well known datasets,that is, Brodatz and Vistex. The results demonstrate that the proposedtechnique achieves better results than classical and state-of-the-art texturedescriptors, such as Gabor-wavelets and co-occurrence matrix.
arxiv-9600-168 | Brachiaria species identification using imaging techniques based on fractal descriptors | http://arxiv.org/pdf/1412.7849v1.pdf | author:João Batista Florindo, Núbia Rosa da Silva, Liliane Maria Romualdo, Fernanda de Fátima da Silva, Pedro Henrique de Cerqueira Luz, Valdo Rodrigues Herling, Odemir Martinez Bruno category:cs.CV published:2014-12-25 summary:The use of a rapid and accurate method in diagnosis and classification ofspecies and/or cultivars of forage has practical relevance, scientific andtrade in various areas of study. Thus, leaf samples of fodder plant species\textit{Brachiaria} were previously identified, collected and scanned to betreated by means of artificial vision to make the database and be used insubsequent classifications. Forage crops used were: \textit{Brachiariadecumbens} cv. IPEAN; \textit{Brachiaria ruziziensis} Germain \& Evrard;\textit{Brachiaria Brizantha} (Hochst. ex. A. Rich.) Stapf; \textit{Brachiariaarrecta} (Hack.) Stent. and \textit{Brachiaria spp}. The images were analyzedby the fractal descriptors method, where a set of measures are obtained fromthe values of the fractal dimension at different scales. Therefore such valuesare used as inputs for a state-of-the-art classifier, the Support VectorMachine, which finally discriminates the images according to the respectivespecies.
arxiv-9600-169 | Texture analysis using volume-radius fractal dimension | http://arxiv.org/pdf/1412.7844v1.pdf | author:André R. Backes, Odemir M. Bruno category:cs.CV published:2014-12-25 summary:Texture plays an important role in computer vision. It is one of the mostimportant visual attributes used in image analysis, once it providesinformation about pixel organization at different regions of the image. Thispaper presents a novel approach for texture characterization, based oncomplexity analysis. The proposed approach expands the idea of the Mass-radiusfractal dimension, a method originally developed for shape analysis, to a setof coordinates in 3D-space that represents the texture under analysis in asignature able to characterize efficiently different texture classes in termsof complexity. An experiment using images from the Brodatz album illustratesthe method performance.
arxiv-9600-170 | Fractal descriptors based on the probability dimension: a texture analysis and classification approach | http://arxiv.org/pdf/1412.7851v1.pdf | author:João Batista Florindo, Odemir Martinez Bruno category:cs.CV published:2014-12-25 summary:In this work, we propose a novel technique for obtaining descriptors ofgray-level texture images. The descriptors are provided by applying amultiscale transform to the fractal dimension of the image estimated throughthe probability (Voss) method. The effectiveness of the descriptors is verifiedin a classification task using benchmark over texture datasets. The resultsobtained demonstrate the efficiency of the proposed method as a tool for thedescription and discrimination of texture images.
arxiv-9600-171 | Joint Deep Learning for Car Detection | http://arxiv.org/pdf/1412.7854v1.pdf | author:Seyedshams Feyzabadi category:cs.CV published:2014-12-25 summary:Traditional object recognition approaches apply feature extraction, partdeformation handling, occlusion handling and classification sequentially whilethey are independent from each other. Ouyang and Wang proposed a model forjointly learning of all of the mentioned processes using one deep neuralnetwork. We utilized, and manipulated their toolbox in order to apply it in cardetection scenarios where it had not been tested. Creating a single deeparchitecture from these components, improves the interaction between them andcan enhance the performance of the whole system. We believe that the approachcan be used as a general purpose object detection toolbox. We tested thealgorithm on UIUC car dataset, and achieved a reasonable result. The accuracyof our method was 86 % while there are better results of accuracy with up to 91% and will be shown later. We strongly believe that having an experiment on alarger dataset can show the advantage of using deep models over shallow ones.
arxiv-9600-172 | Gabor wavelets combined with volumetric fractal dimension applied to texture analysis | http://arxiv.org/pdf/1412.7856v1.pdf | author:Álvaro Gomez Z., João B. Florindo, Odemir M. Bruno category:cs.CV published:2014-12-25 summary:Texture analysis and classification remain as one of the biggest challengesfor the field of computer vision and pattern recognition. On this matter, Gaborwavelets has proven to be a useful technique to characterize distinctivetexture patterns. However, most of the approaches used to extract descriptorsof the Gabor magnitude space usually fail in representing adequately therichness of detail present into a unique feature vector. In this paper, wepropose a new method to enhance the Gabor wavelets process extracting a fractalsignature of the magnitude spaces. Each signature is reduced using a canonicalanalysis function and concatenated to form the final feature vector.Experiments were conducted on several texture image databases to prove thepower and effectiveness of the proposed method. Results obtained shown thatthis method outperforms other early proposed method, creating a more reliabletechnique for texture feature extraction.
arxiv-9600-173 | Gaussian Process Pseudo-Likelihood Models for Sequence Labeling | http://arxiv.org/pdf/1412.7868v1.pdf | author:P. K. Srijith, P. Balamurugan, Shirish Shevade category:cs.LG stat.ML published:2014-12-25 summary:Several machine learning problems arising in natural language processing canbe modeled as a sequence labeling problem. We provide Gaussian process modelsbased on pseudo-likelihood approximation to perform sequence labeling. Gaussianprocesses (GPs) provide a Bayesian approach to learning in a kernel basedframework. The pseudo-likelihood model enables one to capture long rangedependencies among the output components of the sequence without becomingcomputationally intractable. We use an efficient variational Gaussianapproximation method to perform inference in the proposed model. We alsoprovide an iterative algorithm which can effectively make use of theinformation from the neighboring labels to perform prediction. The ability tocapture long range dependencies makes the proposed approach useful for a widerange of sequence labeling problems. Numerical experiments on some sequencelabeling data sets demonstrate the usefulness of the proposed approach.
arxiv-9600-174 | Plagiarism Detection on Electronic Text based Assignments using Vector Space Model (ICIAfS14) | http://arxiv.org/pdf/1412.7782v1.pdf | author:MAC Jiffriya, MAC Akmal Jahan, Roshan G. Ragel category:cs.IR cs.CL published:2014-12-25 summary:Plagiarism is known as illegal use of others' part of work or whole work asone's own in any field such as art, poetry, literature, cinema, research andother creative forms of study. Plagiarism is one of the important issues inacademic and research fields and giving more concern in academic systems. Thesituation is even worse with the availability of ample resources on the web.This paper focuses on an effective plagiarism detection tool on identifyingsuitable intra-corpal plagiarism detection for text based assignments bycomparing unigram, bigram, trigram of vector space model with cosine similaritymeasure. Manually evaluated, labelled dataset was tested using unigram, bigramand trigram vector. Even though trigram vector consumes comparatively moretime, it shows better results with the labelled data. In addition, the selectedtrigram vector space model with cosine similarity measure is compared withtri-gram sequence matching technique with Jaccard measure. In the results,cosine similarity score shows slightly higher values than the other. Because,it focuses on giving more weight for terms that do not frequently exist in thedataset and cosine similarity measure using trigram technique is morepreferable than the other. Therefore, we present our new tool and it could beused as an effective tool to evaluate text based electronic assignments andminimize the plagiarism among students.
arxiv-9600-175 | Cloud K-SVD: A Collaborative Dictionary Learning Algorithm for Big, Distributed Data | http://arxiv.org/pdf/1412.7839v2.pdf | author:Haroon Raja, Waheed U. Bajwa category:cs.LG cs.IT math.IT stat.ML published:2014-12-25 summary:This paper studies the problem of data-adaptive representations for big,distributed data. It is assumed that a number of geographically-distributed,interconnected sites have massive local data and they are interested incollaboratively learning a low-dimensional geometric structure underlying thesedata. In contrast to previous works on subspace-based data representations,this paper focuses on the geometric structure of a union of subspaces (UoS). Inthis regard, it proposes a distributed algorithm---termed cloud K-SVD---forcollaborative learning of a UoS structure underlying distributed data ofinterest. The goal of cloud K-SVD is to learn a common overcomplete dictionaryat each individual site such that every sample in the distributed data can berepresented through a small number of atoms of the learned dictionary. CloudK-SVD accomplishes this goal without requiring exchange of individual samplesbetween sites. This makes it suitable for applications where sharing of rawdata is discouraged due to either privacy concerns or large volumes of data.This paper also provides an analysis of cloud K-SVD that gives insights intoits properties as well as deviations of the dictionaries learned at individualsites from a centralized solution in terms of different measures oflocal/global data and topology of interconnections. Finally, the papernumerically illustrates the efficacy of cloud K-SVD on real and syntheticdistributed data.
arxiv-9600-176 | Improved Parameter Identification Method Based on Moving Rate | http://arxiv.org/pdf/1412.7774v1.pdf | author:Chol Man Ho, Son Il Gwak, Song Ho Pak, Jong Won Ha category:cs.NE published:2014-12-25 summary:To improve the problem that the parameter identification for fuzzy neuralnetwork has many time complexities in calculating, an improved T-S fuzzyinference method and an parameter identification method for fuzzy neuralnetwork are proposed. It mainly includes three parts. First, improved fuzzyinference method based on production term for T-S Fuzzy model is explained.Then, compared with existing Sugeno fuzzy inference based on Compositionalrules and type-distance fuzzy inference method, the proposed fuzzy inferencealgorithm has a less amount of complexity in calculating and the calculatingprocess is simple. Next, a parameter identification method for FNN based onproduction inference is proposed. Finally, the proposed method is applied forthe precipitation forecast and security situation prediction. Test resultsshowed that the proposed method significantly improved the effectiveness ofidentification, reduced the learning order, time complexity and learning error.
arxiv-9600-177 | Protein Secondary Structure Prediction with Long Short Term Memory Networks | http://arxiv.org/pdf/1412.7828v2.pdf | author:Søren Kaae Sønderby, Ole Winther category:q-bio.QM cs.LG cs.NE published:2014-12-25 summary:Prediction of protein secondary structure from the amino acid sequence is aclassical bioinformatics problem. Common methods use feed forward neuralnetworks or SVMs combined with a sliding window, as these models does notnaturally handle sequential data. Recurrent neural networks are angeneralization of the feed forward neural network that naturally handlesequential data. We use a bidirectional recurrent neural network with longshort term memory cells for prediction of secondary structure and evaluateusing the CB513 dataset. On the secondary structure 8-class problem we reportbetter performance (0.674) than state of the art (0.664). Our model includesfeed forward networks between the long short term memory cells, a path that canbe further explored.
arxiv-9600-178 | Fast Convolutional Nets With fbfft: A GPU Performance Evaluation | http://arxiv.org/pdf/1412.7580v3.pdf | author:Nicolas Vasilache, Jeff Johnson, Michael Mathieu, Soumith Chintala, Serkan Piantino, Yann LeCun category:cs.LG cs.DC cs.NE published:2014-12-24 summary:We examine the performance profile of Convolutional Neural Network trainingon the current generation of NVIDIA Graphics Processing Units. We introduce twonew Fast Fourier Transform convolution implementations: one based on NVIDIA'scuFFT library, and another based on a Facebook authored FFT implementation,fbfft, that provides significant speedups over cuFFT (over 1.5x) for wholeCNNs. Both of these convolution implementations are available in open source,and are faster than NVIDIA's cuDNN implementation for many common convolutionallayers (up to 23.5x for some synthetic kernel configurations). We discussdifferent performance regimes of convolutions, comparing areas wherestraightforward time domain convolutions outperform Fourier frequency domainconvolutions. Details on algorithmic applications of NVIDIA GPU hardwarespecifics in the implementation of fbfft are also provided.
arxiv-9600-179 | Differential Privacy and Machine Learning: a Survey and Review | http://arxiv.org/pdf/1412.7584v1.pdf | author:Zhanglong Ji, Zachary C. Lipton, Charles Elkan category:cs.LG cs.CR cs.DB published:2014-12-24 summary:The objective of machine learning is to extract useful information from data,while privacy is preserved by concealing information. Thus it seems hard toreconcile these competing interests. However, they frequently must be balancedwhen mining sensitive data. For example, medical research represents animportant application where it is necessary both to extract useful informationand protect patient privacy. One way to resolve the conflict is to extractgeneral characteristics of whole populations without disclosing the privateinformation of individuals. In this paper, we consider differential privacy, one of the most popular andpowerful definitions of privacy. We explore the interplay between machinelearning and differential privacy, namely privacy-preserving machine learningalgorithms and learning-based data release mechanisms. We also describe sometheoretical results that address what can be learned differentially privatelyand upper bounds of loss functions for differentially private algorithms. Finally, we present some open questions, including how to incorporate publicdata, how to deal with missing data in private datasets, and whether, as thenumber of observed samples grows arbitrarily large, differentially privatemachine learning algorithms can be achieved at no cost to utility as comparedto corresponding non-differentially private algorithms.
arxiv-9600-180 | Learning Longer Memory in Recurrent Neural Networks | http://arxiv.org/pdf/1412.7753v2.pdf | author:Tomas Mikolov, Armand Joulin, Sumit Chopra, Michael Mathieu, Marc'Aurelio Ranzato category:cs.NE cs.LG published:2014-12-24 summary:Recurrent neural network is a powerful model that learns temporal patterns insequential data. For a long time, it was believed that recurrent networks aredifficult to train using simple optimizers, such as stochastic gradientdescent, due to the so-called vanishing gradient problem. In this paper, weshow that learning longer term patterns in real data, such as in naturallanguage, is perfectly possible using gradient descent. This is achieved byusing a slight structural modification of the simple recurrent neural networkarchitecture. We encourage some of the hidden units to change their stateslowly by making part of the recurrent weight matrix close to identity, thusforming kind of a longer term memory. We evaluate our model in languagemodeling experiments, where we obtain similar performance to the much morecomplex Long Short Term Memory (LSTM) networks (Hochreiter & Schmidhuber,1997).
arxiv-9600-181 | Transformation Properties of Learned Visual Representations | http://arxiv.org/pdf/1412.7659v3.pdf | author:Taco S. Cohen, Max Welling category:cs.LG cs.CV cs.NE published:2014-12-24 summary:When a three-dimensional object moves relative to an observer, a changeoccurs on the observer's image plane and in the visual representation computedby a learned model. Starting with the idea that a good visual representation isone that transforms linearly under scene motions, we show, using the theory ofgroup representations, that any such representation is equivalent to acombination of the elementary irreducible representations. We derive a strikingrelationship between irreducibility and the statistical dependency structure ofthe representation, by showing that under restricted conditions, irreduciblerepresentations are decorrelated. Under partial observability, as induced bythe perspective projection of a scene onto the image plane, the motion groupdoes not have a linear action on the space of images, so that it becomesnecessary to perform inference over a latent representation that does transformlinearly. This idea is demonstrated in a model of rotating NORB objects thatemploys a latent representation of the non-commutative 3D rotation group SO(3).
arxiv-9600-182 | Automatic Photo Adjustment Using Deep Neural Networks | http://arxiv.org/pdf/1412.7725v2.pdf | author:Zhicheng Yan, Hao Zhang, Baoyuan Wang, Sylvain Paris, Yizhou Yu category:cs.CV cs.GR cs.LG published:2014-12-24 summary:Photo retouching enables photographers to invoke dramatic visual impressionsby artistically enhancing their photos through stylistic color and toneadjustments. However, it is also a time-consuming and challenging task thatrequires advanced skills beyond the abilities of casual photographers. Using anautomated algorithm is an appealing alternative to manual work but such analgorithm faces many hurdles. Many photographic styles rely on subtleadjustments that depend on the image content and even its semantics. Further,these adjustments are often spatially varying. Because of thesecharacteristics, existing automatic algorithms are still limited and cover onlya subset of these challenges. Recently, deep machine learning has shown uniqueabilities to address hard problems that resisted machine algorithms for long.This motivated us to explore the use of deep learning in the context of photoediting. In this paper, we explain how to formulate the automatic photoadjustment problem in a way suitable for this approach. We also introduce animage descriptor that accounts for the local semantics of an image. Ourexperiments demonstrate that our deep learning formulation applied using thesedescriptors successfully capture sophisticated photographic styles. Inparticular and unlike previous techniques, it can model local adjustments thatdepend on the image semantics. We show on several examples that this yieldsresults that are qualitatively and quantitatively better than previous work.
arxiv-9600-183 | The Computational Theory of Intelligence: Information Entropy | http://arxiv.org/pdf/1412.7978v1.pdf | author:Daniel Kovach category:cs.AI cs.LG 68T27 I.2.1 published:2014-12-24 summary:This paper presents an information theoretic approach to the concept ofintelligence in the computational sense. We introduce a probabilistic frameworkfrom which computational intelligence is shown to be an entropy minimizingprocess at the local level. Using this new scheme, we develop a simple datadriven clustering example and discuss its applications.
arxiv-9600-184 | Multiple Object Recognition with Visual Attention | http://arxiv.org/pdf/1412.7755v2.pdf | author:Jimmy Ba, Volodymyr Mnih, Koray Kavukcuoglu category:cs.LG cs.CV cs.NE published:2014-12-24 summary:We present an attention-based model for recognizing multiple objects inimages. The proposed model is a deep recurrent neural network trained withreinforcement learning to attend to the most relevant regions of the inputimage. We show that the model learns to both localize and recognize multipleobjects despite being given only class labels during training. We evaluate themodel on the challenging task of transcribing house number sequences fromGoogle Street View images and show that it is both more accurate than thestate-of-the-art convolutional networks and uses fewer parameters and lesscomputation.
arxiv-9600-185 | AltecOnDB: A Large-Vocabulary Arabic Online Handwriting Recognition Database | http://arxiv.org/pdf/1412.7626v1.pdf | author:Ibrahim Abdelaziz, Sherif Abdou category:cs.CV published:2014-12-24 summary:Arabic is a semitic language characterized by a complex and rich morphology.The exceptional degree of ambiguity in the writing system, the rich morphology,and the highly complex word formation process of roots and patterns allcontribute to making computational approaches to Arabic very challenging. As aresult, a practical handwriting recognition system should support largevocabulary to provide a high coverage and use the context information fordisambiguation. Several research efforts have been devoted for building onlineArabic handwriting recognition systems. Most of these methods are either usingtheir small private test data sets or a standard database with limited lexiconand coverage. A large scale handwriting database is an essential resource thatcan advance the research of online handwriting recognition. Currently, there isno online Arabic handwriting database with large lexicon, high coverage, largenumber of writers and training/testing data. In this paper, we introduce AltecOnDB, a large scale online Arabichandwriting database. AltecOnDB has 98% coverage of all the possible PAWS ofthe Arabic language. The collected samples are complete sentences that includedigits and punctuation marks. The collected data is available on sentence, wordand character levels, hence, high-level linguistic models can be used forperformance improvements. Data is collected from more than 1000 writers withdifferent backgrounds, genders and ages. Annotation and verification tools aredeveloped to facilitate the annotation and verification phases. We built anelementary recognition system to test our database and show the existingdifficulties when handling a large vocabulary and dealing with large amounts ofstyles variations in the collected data.
arxiv-9600-186 | Concentration for matrix martingales in continuous time and microscopic activity of social networks | http://arxiv.org/pdf/1412.7705v1.pdf | author:Emmanuel Bacry, Stéphane Gaïffas, Jean-François Muzy category:math.PR stat.ML published:2014-12-24 summary:This paper gives new concentration inequalities for the spectral norm ofmatrix martingales in continuous time. Both cases of purely discountinuous andcontinuous martingales are considered. The analysis is based on a newsupermartingale property of the trace exponential, based on tools fromstochastic calculus. Matrix martingales in continuous time are probabilisticobjects that naturally appear for statistical learning of time-dependentsystems. We focus here on the the microscopic study of (social) networks, basedon self-exciting counting processes, such as the Hawkes process, together witha low-rank prior assumption of the self-exciting component. A consequence ofthese new concentration inequalities is a push forward of the theoreticalanalysis of such models.
arxiv-9600-187 | Locating Tables in Scanned Documents for Reconstructing and Republishing (ICIAfS14) | http://arxiv.org/pdf/1412.7689v1.pdf | author:Akmal Jahan Mac, Roshan G Ragel category:cs.CV published:2014-12-24 summary:Pool of knowledge available to the mankind depends on the source of learningresources, which can vary from ancient printed documents to present electronicmaterial. The rapid conversion of material available in traditional librariesto digital form needs a significant amount of work if we are to maintain theformat and the look of the electronic documents as same as their printedcounterparts. Most of the printed documents contain not only characters and itsformatting but also some associated non text objects such as tables, charts andgraphical objects. It is challenging to detect them and to concentrate on theformat preservation of the contents while reproducing them. To address thisissue, we propose an algorithm using local thresholds for word space and lineheight to locate and extract all categories of tables from scanned documentimages. From the experiments performed on 298 documents, we conclude that ouralgorithm has an overall accuracy of about 75% in detecting tables from thescanned document images. Since the algorithm does not completely depend on rulelines, it can detect all categories of tables in a range of scanned documentswith different font types, styles and sizes to extract their formattingfeatures. Moreover, the algorithm can be applied to locate tables in multicolumn layouts with small modification in layout analysis. Treating tables withtheir existing formatting features will tremendously help the reproducing ofprinted documents for reprinting and updating purposes.
arxiv-9600-188 | A Fuzzy Based Model to Identify Printed Sinhala Characters (ICIAfS14) | http://arxiv.org/pdf/1412.7680v1.pdf | author:G. I. Gunarathna, M. A. P. Chamikara, R. G. Ragel category:cs.CV published:2014-12-24 summary:Character recognition techniques for printed documents are widely used forEnglish language. However, the systems that are implemented to recognize Asianlanguages struggle to increase the accuracy of recognition. Among other Asianlanguages (such as Arabic, Tamil, Chinese), Sinhala characters are unique,mainly because they are round in shape. This unique feature makes it achallenge to extend the prevailing techniques to improve recognition of Sinhalacharacters. Therefore, a little attention has been given to improve theaccuracy of Sinhala character recognition. A novel method, which makes use ofthis unique feature, could be advantageous over other methods. This paperdescribes the use of a fuzzy inference system to recognize Sinhala characters.Feature extraction is mainly focused on distance and intersection measurementsin different directions from the center of the letter making use of the roundshape of characters. The results showed an overall accuracy of 90.7% for 140instances of letters tested, much better than similar systems.
arxiv-9600-189 | An Effective Semi-supervised Divisive Clustering Algorithm | http://arxiv.org/pdf/1412.7625v2.pdf | author:Teng Qiu, Yongjie Li category:cs.LG cs.CV stat.ML published:2014-12-24 summary:Nowadays, data are generated massively and rapidly from scientific fields asbioinformatics, neuroscience and astronomy to business and engineering fields.Cluster analysis, as one of the major data analysis tools, is therefore moresignificant than ever. We propose in this work an effective Semi-supervisedDivisive Clustering algorithm (SDC). Data points are first organized by aminimal spanning tree. Next, this tree structure is transitioned to the in-treestructure, and then divided into sub-trees under the supervision of the labeleddata, and in the end, all points in the sub-trees are directly associated withspecific cluster centers. SDC is fully automatic, non-iterative, involving nofree parameter, insensitive to noise, able to detect irregularly shaped clusterstructures, applicable to the data sets of high dimensionality and differentattributes. The power of SDC is demonstrated on several datasets.
arxiv-9600-190 | Inference for Sparse Conditional Precision Matrices | http://arxiv.org/pdf/1412.7638v1.pdf | author:Jialei Wang, Mladen Kolar category:stat.ML published:2014-12-24 summary:Given $n$ i.i.d. observations of a random vector $(X,Z)$, where $X$ is ahigh-dimensional vector and $Z$ is a low-dimensional index variable, we studythe problem of estimating the conditional inverse covariance matrix $\Omega(z)= (E[(X-E[X \mid Z])(X-E[X \mid Z])^T \mid Z=z])^{-1}$ under the assumptionthat the set of non-zero elements is small and does not depend on the indexvariable. We develop a novel procedure that combines the ideas of the localconstant smoothing and the group Lasso for estimating the conditional inversecovariance matrix. A proximal iterative smoothing algorithm is used to solvethe corresponding convex optimization problems. We prove that our procedurerecovers the conditional independence assumptions of the distribution $X \midZ$ with high probability. This result is established by developing a uniformdeviation bound for the high-dimensional conditional covariance matrix from itspopulation counterpart, which may be of independent interest. Furthermore, wedevelop point-wise confidence intervals for individual elements of theconditional inverse covariance matrix. We perform extensive simulation studies,in which we demonstrate that our proposed procedure outperforms sensiblecompetitors. We illustrate our proposal on a S&P 500 stock price data set.
arxiv-9600-191 | Facial Expressions recognition Based on Principal Component Analysis (PCA) | http://arxiv.org/pdf/1506.01939v1.pdf | author:Abdelmajid Hassan Mansour, Gafar Zen Alabdeen Salh, Ali Shaif Alhalemi category:cs.CV published:2014-12-23 summary:The facial expression recognition is an ocular task that can be performedwithout human discomfort, is really a speedily growing on the computer researchfield. There are many applications and programs uses facial expression toevaluate human character, judgment, feelings, and viewpoint. The process ofrecognizing facial expression is a hard task due to the several circumstancessuch as facial occlusions, face shape, illumination, face colors, and etc. Thispaper present a PCA methodology to distinguish expressions of faces underdifferent circumstances and identifying it. Relies on Eigen faces techniqueusing standard Data base images. So as to overcome the problem of difficulty tocomputers to identify the features and expressions of persons.
arxiv-9600-192 | Particle Metropolis adjusted Langevin algorithms | http://arxiv.org/pdf/1412.7299v2.pdf | author:Christopher Nemeth, Chris Sherlock, Paul Fearnhead category:stat.ME stat.CO stat.ML published:2014-12-23 summary:Pseudo-marginal and particle MCMC have recently been introduced as classes ofalgorithms that can be used to analyse models where the likelihood function isintractable. They use Monte Carlo methods, such as particle filters, toestimate the posterior density, and MCMC moves to update the model parameters.Particle filter algorithms can also produce Monte Carlo estimates of thegradient of the log-posterior which can then be used within the MCMC proposaldistribution for the parameters. The resulting particle MCMC algorithm can beviewed as an approximation to the Metropolis adjusted Langevin algorithm, whichwe call particle MALA. We investigate the theoretical properties of particleMALA under standard asymptotics, which correspond to an increasing dimension ofthe parameters, n. Our results show that the behaviour of particle MALA dependscrucially on how accurately one can estimate the gradient of the log-posterior.If the error in the estimate of the gradient is not controlled sufficientlywell as dimension increases, then asymptotically there will be no advantage inusing particle MALA over the simpler random-walk proposal. However, if theerror is well-behaved, then the optimal scaling of particle MALA proposals willbe $O(n^{-1/6})$ compared to $O(n^{-1/2})$ for the random-walk. Our theory alsogives guidelines as to how to tune the number of particles and the step sizeused within particle MALA.
arxiv-9600-193 | Fusing Color and Texture Cues to Categorize the Fruit Diseases from Images | http://arxiv.org/pdf/1412.7277v1.pdf | author:Shiv Ram Dubey, Anand Singh Jalal category:cs.CV published:2014-12-23 summary:The economic and production losses in agricultural industry worldwide are dueto the presence of diseases in the several kinds of fruits. In this paper, amethod for the classification of fruit diseases is proposed and experimentallyvalidated. The image processing based proposed approach is composed of thefollowing main steps; in the first step K-Means clustering technique is usedfor the defect segmentation, in the second step color and textural cues areextracted and fused from the segmented image, and finally images are classifiedinto one of the classes by using a Multi-class Support Vector Machine. We haveconsidered diseases of apple as a test case and evaluated our approach forthree types of apple diseases namely apple scab, apple blotch and apple rot andnormal apples without diseases. Our experimentation points out that theproposed fusion scheme can significantly support accurate detection andautomatic classification of fruit diseases.
arxiv-9600-194 | Grammar as a Foreign Language | http://arxiv.org/pdf/1412.7449v3.pdf | author:Oriol Vinyals, Lukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, Geoffrey Hinton category:cs.CL cs.LG stat.ML published:2014-12-23 summary:Syntactic constituency parsing is a fundamental problem in natural languageprocessing and has been the subject of intensive research and engineering fordecades. As a result, the most accurate parsers are domain specific, complex,and inefficient. In this paper we show that the domain agnosticattention-enhanced sequence-to-sequence model achieves state-of-the-art resultson the most widely used syntactic constituency parsing dataset, when trained ona large synthetic corpus that was annotated using existing parsers. It alsomatches the performance of standard parsers when trained only on a smallhuman-annotated dataset, which shows that this model is highly data-efficient,in contrast to sequence-to-sequence models without the attention mechanism. Ourparser is also fast, processing over a hundred sentences per second with anunoptimized CPU implementation.
arxiv-9600-195 | Theoretical guarantees for approximate sampling from smooth and log-concave densities | http://arxiv.org/pdf/1412.7392v5.pdf | author:Arnak S. Dalalyan category:stat.CO math.ST stat.ML stat.TH published:2014-12-23 summary:Sampling from various kinds of distributions is an issue of paramountimportance in statistics since it is often the key ingredient for constructingestimators, test procedures or confidence intervals. In many situations, theexact sampling from a given distribution is impossible or computationallyexpensive and, therefore, one needs to resort to approximate samplingstrategies. However, there is no well-developed theory providing meaningfulnonasymptotic guarantees for the approximate sampling procedures, especially inthe high-dimensional problems. This paper makes some progress in this directionby considering the problem of sampling from a distribution having a smooth andlog-concave density defined on $\mathbb R^p$, for some integer $p>0$. Weestablish nonasymptotic bounds for the error of approximating the truedistribution by the one obtained by the Langevin Monte Carlo method and itsvariants. We illustrate the effectiveness of the established guarantees withvarious experiments. Underlying our analysis are insights from the theory ofcontinuous-time diffusion processes, which may be of interest beyond theframework of distributions with log-concave densities considered in the presentwork.
arxiv-9600-196 | Unsupervised Feature Learning with C-SVDDNet | http://arxiv.org/pdf/1412.7259v3.pdf | author:Dong Wang, Xiaoyang Tan category:cs.CV cs.LG cs.NE published:2014-12-23 summary:In this paper, we investigate the problem of learning feature representationfrom unlabeled data using a single-layer K-means network. A K-means networkmaps the input data into a feature representation by finding the nearestcentroid for each input point, which has attracted researchers' great attentionrecently due to its simplicity, effectiveness, and scalability. However, onedrawback of this feature mapping is that it tends to be unreliable when thetraining data contains noise. To address this issue, we propose a SVDD basedfeature learning algorithm that describes the density and distribution of eachcluster from K-means with an SVDD ball for more robust feature representation.For this purpose, we present a new SVDD algorithm called C-SVDD that centersthe SVDD ball towards the mode of local density of each cluster, and we showthat the objective of C-SVDD can be solved very efficiently as a linearprogramming problem. Additionally, traditional unsupervised feature learningmethods usually take an average or sum of local representations to obtainglobal representation which ignore spatial relationship among them. To usespatial information we propose a global representation with a variant of SIFTdescriptor. The architecture is also extended with multiple receptive fieldscales and multiple pooling sizes. Extensive experiments on several popularobject recognition benchmarks, such as STL-10, MINST, Holiday and Copydaysshows that the proposed C-SVDDNet method yields comparable or betterperformance than that of the previous state of the art methods.
arxiv-9600-197 | Learning of Proto-object Representations via Fixations on Low Resolution | http://arxiv.org/pdf/1412.7242v2.pdf | author:Chengyao Shen, Xun Huang, Qi Zhao category:cs.CV published:2014-12-23 summary:While previous researches in eye fixation prediction typically rely onintegrating low-level features (e.g. color, edge) to form a saliency map,recently it has been found that the structural organization of these featuresinto a proto-object representation can play a more significant role. In thiswork, we present a computational framework based on deep network to demonstratethat proto-object representations can be learned from low-resolution imagepatches from fixation regions. We advocate the use of low-resolution inputs inthis work due to the following reasons: (1) Proto-objects are computed inparallel over an entire visual field (2) People can perceive or recognizeobjects well even it is in low resolution. (3) Fixations from lower resolutionimages can predict fixations on higher resolution images. In the proposedcomputational model, we extract multi-scale image patches on fixation regionsfrom eye fixation datasets, resize them to low resolution and feed them into ahierarchical. With layer-wise unsupervised feature learning, we find that manyproto-objects like features responsive to different shapes of object blobs arelearned out. Visualizations also show that these features are selective topotential objects in the scene and the responses of these features work well inpredicting eye fixations on the images when combined with learned weights.
arxiv-9600-198 | Model Selection in High-Dimensional Misspecified Models | http://arxiv.org/pdf/1412.7468v1.pdf | author:Pallavi Basu, Yang Feng, Jinchi Lv category:math.ST stat.ME stat.ML stat.TH published:2014-12-23 summary:Model selection is indispensable to high-dimensional sparse modeling inselecting the best set of covariates among a sequence of candidate models. Mostexisting work assumes implicitly that the model is correctly specified or offixed dimensions. Yet model misspecification and high dimensionality are commonin real applications. In this paper, we investigate two classicalKullback-Leibler divergence and Bayesian principles of model selection in thesetting of high-dimensional misspecified models. Asymptotic expansions of theseprinciples reveal that the effect of model misspecification is crucial andshould be taken into account, leading to the generalized AIC and generalizedBIC in high dimensions. With a natural choice of prior probabilities, wesuggest the generalized BIC with prior probability which involves a logarithmicfactor of the dimensionality in penalizing model complexity. We furtherestablish the consistency of the covariance contrast matrix estimator in ageneral setting. Our results and new method are supported by numerical studies.
arxiv-9600-199 | A Unified Perspective on Multi-Domain and Multi-Task Learning | http://arxiv.org/pdf/1412.7489v3.pdf | author:Yongxin Yang, Timothy M. Hospedales category:stat.ML cs.LG cs.NE published:2014-12-23 summary:In this paper, we provide a new neural-network based perspective onmulti-task learning (MTL) and multi-domain learning (MDL). By introducing theconcept of a semantic descriptor, this framework unifies MDL and MTL as well asencompassing various classic and recent MTL/MDL algorithms by interpreting themas different ways of constructing semantic descriptors. Our interpretationprovides an alternative pipeline for zero-shot learning (ZSL), where a modelfor a novel class can be constructed without training data. Moreover, it leadsto a new and practically relevant problem setting of zero-shot domainadaptation (ZSDA), which is the analogous to ZSL but for novel domains: A modelfor an unseen domain can be generated by its semantic descriptor. Experimentsacross this range of problems demonstrate that our framework outperforms avariety of alternatives.
arxiv-9600-200 | Higher-order Spatial Accuracy in Diffeomorphic Image Registration | http://arxiv.org/pdf/1412.7504v2.pdf | author:Henry O. Jacobs, Stefan Sommer category:cs.CV math.DG math.OC published:2014-12-23 summary:We discretize a cost functional for image registration problems by derivingTaylor expansions for the matching term. Minima of the discretized costfunctionals can be computed with no spatial discretization error, and theoptimal solutions are equivalent to minimal energy curves in the space of$k$-jets. We show that the solutions convergence to optimal solutions of theoriginal cost functional as the number of particles increases with aconvergence rate of $O(h^{d+k})$ where $h$ is a resolution parameter. Theeffect of this approach over traditional particle methods is illustrated onsynthetic examples and real images.
arxiv-9600-201 | Symmetry in Image Registration and Deformation Modeling | http://arxiv.org/pdf/1412.7513v2.pdf | author:Stefan Sommer, Henry O. Jacobs category:cs.CV math.DG published:2014-12-23 summary:We survey the role of symmetry in diffeomorphic registration of landmarks,curves, surfaces, images and higher-order data. The infinite dimensionalproblem of finding correspondences between objects can for a range of concretedata types be reduced resulting in compact representations of shape and spatialstructure. This reduction is possible because the available data is incompletein encoding the full deformation model. Using reduction by symmetry, wedescribe the reduced models in a common theoretical framework that draws onlinks between the registration problem and geometric mechanics. Symmetry alsoarises in reduction to the Lie algebra using particle relabeling symmetryallowing the equations of motion to be written purely in terms of Eulerianvelocity field. Reduction by symmetry has recently been applied forjet-matching and higher-order discrete approximations of the image matchingproblem. We outline these constructions and further cases where reduction bysymmetry promises new approaches to registration of complex data types.
arxiv-9600-202 | Bayesian leave-one-out cross-validation approximations for Gaussian latent variable models | http://arxiv.org/pdf/1412.7461v2.pdf | author:Aki Vehtari, Tommi Mononen, Ville Tolvanen, Tuomas Sivula, Ole Winther category:stat.CO stat.ML published:2014-12-23 summary:The future predictive performance of a Bayesian model can be estimated usingBayesian cross-validation. In this article, we consider Gaussian latentvariable models where the integration over the latent values is approximatedusing the Laplace method or expectation propagation (EP). We study theproperties of several Bayesian leave-one-out (LOO) cross-validationapproximations that in most cases can be computed with a small additional costafter forming the posterior approximation given the whole data. Our mainobjective is to assess the accuracy of the approximative LOO cross-validationestimators. That is, for each method (Laplace and EP) we compare theapproximate fast computation with the exact brute force LOO computation.Secondarily, we evaluate the accuracy of the Laplace and EP approximationsthemselves against a ground truth established through extensive Markov chainMonte Carlo simulation. Our empirical results show that the approach based upona Gaussian approximation to the LOO marginal distribution (the so-called cavitydistribution) gives the most accurate and reliable results among the fastmethods.
arxiv-9600-203 | A General Theory of Pathwise Coordinate Optimization | http://arxiv.org/pdf/1412.7477v3.pdf | author:Tuo Zhao, Han Liu, Tong Zhang category:stat.ML published:2014-12-23 summary:The pathwise coordinate optimization is one of the most importantcomputational frameworks for solving high dimensional convex and nonconvexsparse learning problems. It differs from the classical coordinate optimizationalgorithms in three salient features: warm start initialization, active setupdating, and strong rule for coordinate preselection. These three featuresgrant superior empirical performance, but also pose significant challenge totheoretical analysis. To tackle this long lasting problem, we develop a newtheory showing that these three features play pivotal roles in guaranteeing theoutstanding statistical and computational performance of the pathwisecoordinate optimization framework. In particular, we analyze the existingmethods for pathwise coordinate optimization and provide new theoreticalinsights into them. The obtained theory motivates the development of severalmodifications to improve the pathwise coordinate optimization framework, whichguarantees linear convergence to a unique sparse local optimum with optimalstatistical properties (e.g. minimax optimality and oracle properties). This isthe first result establishing the computational and statistical guarantees ofthe pathwise coordinate optimization framework in high dimensions. Thoroughnumerical experiments are provided to back up our theory.
arxiv-9600-204 | ADASECANT: Robust Adaptive Secant Method for Stochastic Gradient | http://arxiv.org/pdf/1412.7419v5.pdf | author:Caglar Gulcehre, Marcin Moczulski, Yoshua Bengio category:cs.LG cs.NE stat.ML published:2014-12-23 summary:Stochastic gradient algorithms have been the main focus of large-scalelearning problems and they led to important successes in machine learning. Theconvergence of SGD depends on the careful choice of learning rate and theamount of the noise in stochastic estimates of the gradients. In this paper, wepropose a new adaptive learning rate algorithm, which utilizes curvatureinformation for automatically tuning the learning rates. The information aboutthe element-wise curvature of the loss function is estimated from the localstatistics of the stochastic first order gradients. We further propose a newvariance reduction technique to speed up the convergence. In our preliminaryexperiments with deep neural networks, we obtained better performance comparedto the popular stochastic gradient algorithms.
arxiv-9600-205 | Learning Non-deterministic Representations with Energy-based Ensembles | http://arxiv.org/pdf/1412.7272v2.pdf | author:Maruan Al-Shedivat, Emre Neftci, Gert Cauwenberghs category:cs.LG cs.NE published:2014-12-23 summary:The goal of a generative model is to capture the distribution underlying thedata, typically through latent variables. After training, these variables areoften used as a new representation, more effective than the original featuresin a variety of learning tasks. However, the representations constructed bycontemporary generative models are usually point-wise deterministic mappingsfrom the original feature space. Thus, even with representations robust toclass-specific transformations, statistically driven models trained on themwould not be able to generalize when the labeled data is scarce. Inspired bythe stochasticity of the synaptic connections in the brain, we introduceEnergy-based Stochastic Ensembles. These ensembles can learn non-deterministicrepresentations, i.e., mappings from the feature space to a family ofdistributions in the latent space. These mappings are encoded in a distributionover a (possibly infinite) collection of models. By conditionally samplingmodels from the ensemble, we obtain multiple representations for every inputexample and effectively augment the data. We propose an algorithm similar tocontrastive divergence for training restricted Boltzmann stochastic ensembles.Finally, we demonstrate the concept of the stochastic representations on asynthetic dataset as well as test them in the one-shot learning scenario onMNIST.
arxiv-9600-206 | A prototype Malayalam to Sign Language Automatic Translator | http://arxiv.org/pdf/1412.7415v2.pdf | author:Jestin Joy, Kannan Balakrishnan category:cs.CL published:2014-12-23 summary:Sign language, which is a medium of communication for deaf people, usesmanual communication and body language to convey meaning, as opposed to usingsound. This paper presents a prototype Malayalam text to sign languagetranslation system. The proposed system takes Malayalam text as input andgenerates corresponding Sign Language. Output animation is rendered using acomputer generated model. This system will help to disseminate information tothe deaf people in public utility places like railways, banks, hospitals etc.This will also act as an educational tool in learning Sign Language.
arxiv-9600-207 | Deep Networks With Large Output Spaces | http://arxiv.org/pdf/1412.7479v4.pdf | author:Sudheendra Vijayanarasimhan, Jonathon Shlens, Rajat Monga, Jay Yagnik category:cs.NE cs.LG published:2014-12-23 summary:Deep neural networks have been extremely successful at various image, speech,video recognition tasks because of their ability to model deep structureswithin the data. However, they are still prohibitively expensive to train andapply for problems containing millions of classes in the output layer. Based onthe observation that the key computation common to most neural network layersis a vector/matrix product, we propose a fast locality-sensitive hashingtechnique to approximate the actual dot product enabling us to scale up thetraining and inference to millions of output classes. We evaluate our techniqueon three diverse large-scale recognition tasks and show that our approach cantrain large-scale models at a faster rate (in terms of steps/total time)compared to baseline methods.
arxiv-9600-208 | Learning Deep Temporal Representations for Brain Decoding | http://arxiv.org/pdf/1412.7522v4.pdf | author:Orhan Firat, Emre Aksan, Ilke Oztekin, Fatos T. Yarman Vural category:cs.LG cs.NE published:2014-12-23 summary:Functional magnetic resonance imaging produces high dimensional data, with aless then ideal number of labelled samples for brain decoding tasks (predictingbrain states). In this study, we propose a new deep temporal convolutionalneural network architecture with spatial pooling for brain decoding which aimsto reduce dimensionality of feature space along with improved classificationperformance. Temporal representations (filters) for each layer of theconvolutional model are learned by leveraging unlabelled fMRI data in anunsupervised fashion with regularized autoencoders. Learned temporalrepresentations in multiple levels capture the regularities in the temporaldomain and are observed to be a rich bank of activation patterns which alsoexhibit similarities to the actual hemodynamic responses. Further, spatialpooling layers in the convolutional architecture reduce the dimensionalitywithout losing excessive information. By employing the proposed temporalconvolutional architecture with spatial pooling, raw input fMRI data is mappedto a non-linear, highly-expressive and low-dimensional feature space where thefinal classification is conducted. In addition, we propose a simple heuristicapproach for hyper-parameter tuning when no validation data is available.Proposed method is tested on a ten class recognition memory experiment withnine subjects. The results support the efficiency and potential of the proposedmodel, compared to the baseline multi-voxel pattern analysis techniques.
arxiv-9600-209 | Difference Target Propagation | http://arxiv.org/pdf/1412.7525v5.pdf | author:Dong-Hyun Lee, Saizheng Zhang, Asja Fischer, Yoshua Bengio category:cs.LG cs.NE published:2014-12-23 summary:Back-propagation has been the workhorse of recent successes of deep learningbut it relies on infinitesimal effects (partial derivatives) in order toperform credit assignment. This could become a serious issue as one considersdeeper and more non-linear functions, e.g., consider the extreme case ofnonlinearity where the relation between parameters and cost is actuallydiscrete. Inspired by the biological implausibility of back-propagation, a fewapproaches have been proposed in the past that could play a similar creditassignment role. In this spirit, we explore a novel approach to creditassignment in deep networks that we call target propagation. The main idea isto compute targets rather than gradients, at each layer. Like gradients, theyare propagated backwards. In a way that is related but different frompreviously proposed proxies for back-propagation which rely on a backwardsnetwork with symmetric weights, target propagation relies on auto-encoders ateach layer. Unlike back-propagation, it can be applied even when units exchangestochastic bits rather than real numbers. We show that a linear correction forthe imperfectness of the auto-encoders, called difference target propagation,is very effective to make target propagation actually work, leading to resultscomparable to back-propagation for deep networks with discrete and continuousunits and denoising auto-encoders and achieving state of the art for stochasticnetworks.
arxiv-9600-210 | Approximate Subspace-Sparse Recovery with Corrupted Data via Constrained $\ell_1$-Minimization | http://arxiv.org/pdf/1412.7260v2.pdf | author:Ehsan Elhamifar, Mahdi Soltanolkotabi, Shankar Sastry category:stat.ML published:2014-12-23 summary:High-dimensional data often lie in low-dimensional subspaces corresponding todifferent classes they belong to. Finding sparse representations of data pointsin a dictionary built using the collection of data helps to uncoverlow-dimensional subspaces and address problems such as clustering,classification, subset selection and more. In this paper, we address theproblem of recovering sparse representations for noisy data points in adictionary whose columns correspond to corrupted data lying close to a union ofsubspaces. We consider a constrained $\ell_1$-minimization and study conditionsunder which the solution of the proposed optimization satisfies the approximatesubspace-sparse recovery condition. More specifically, we show that each noisydata point, perturbed from a subspace by a noise of the magnitude of$\varepsilon$, will be reconstructed using data points from the same subspacewith a small error of the order of $O(\varepsilon)$ and that the coefficientscorresponding to data points in other subspaces will be sufficiently small,\ie, of the order of $O(\varepsilon)$. We do not impose any randomnessassumption on the arrangement of subspaces or distribution of data points ineach subspace. Our framework is based on a novel generalization of thenull-space property to the setting where data lie in multiple subspaces, thenumber of data points in each subspace exceeds the dimension of the subspace,and all data points are corrupted by noise. Moreover, assuming a randomdistribution for data points, we further show that coefficients from thedesired support not only reconstruct a given point with high accuracy, but alsohave sufficiently large values, \ie, of the order of $O(1)$.
arxiv-9600-211 | A Bayesian encourages dropout | http://arxiv.org/pdf/1412.7003v3.pdf | author:Shin-ichi Maeda category:cs.LG cs.NE stat.ML published:2014-12-22 summary:Dropout is one of the key techniques to prevent the learning fromoverfitting. It is explained that dropout works as a kind of modified L2regularization. Here, we shed light on the dropout from Bayesian standpoint.Bayesian interpretation enables us to optimize the dropout rate, which isbeneficial for learning of weight parameters and prediction after learning. Theexperiment result also encourages the optimization of the dropout.
arxiv-9600-212 | Generative Class-conditional Autoencoders | http://arxiv.org/pdf/1412.7009v3.pdf | author:Jan Rudy, Graham Taylor category:cs.NE cs.LG published:2014-12-22 summary:Recent work by Bengio et al. (2013) proposes a sampling procedure fordenoising autoencoders which involves learning the transition operator of aMarkov chain. The transition operator is typically unimodal, which limits itscapacity to model complex data. In order to perform efficient sampling fromconditional distributions, we extend this work, both theoretically andalgorithmically, to gated autoencoders (Memisevic, 2013), The proposed model isable to generate convincing class-conditional samples when trained on both theMNIST and TFD datasets.
arxiv-9600-213 | Parameter Selection In Particle Swarm Optimization For Transportation Network Design Problem | http://arxiv.org/pdf/1412.7185v3.pdf | author:Mehran Fasihozaman Langerudi category:math.OC cs.NE published:2014-12-22 summary:In transportation planning and development, transport network design problemseeks to optimize specific objectives (e.g. total travel time) through choosingamong a given set of projects while keeping consumption of resources (e.g.budget) within their limits. Due to the numerous cases of choosing projects,solving such a problem is very difficult and time-consuming. Based on particleswarm optimization (PSO) technique, a heuristic solution algorithm for thebi-level problem is designed. This paper evaluates the algorithm performance inthe response of changing certain basic PSO parameters.
arxiv-9600-214 | Clustering multi-way data: a novel algebraic approach | http://arxiv.org/pdf/1412.7056v2.pdf | author:Eric Kernfeld, Shuchin Aeron, Misha Kilmer category:cs.LG cs.CV cs.IT math.IT stat.ML published:2014-12-22 summary:In this paper, we develop a method for unsupervised clustering of two-way(matrix) data by combining two recent innovations from different fields: theSparse Subspace Clustering (SSC) algorithm [10], which groups points comingfrom a union of subspaces into their respective subspaces, and the t-product[18], which was introduced to provide a matrix-like multiplication for thirdorder tensors. Our algorithm is analogous to SSC in that an "affinity" betweendifferent data points is built using a sparse self-representation of the data.Unlike SSC, we employ the t-product in the self-representation. This allows usmore flexibility in modeling; infact, SSC is a special case of our method. Whenusing the t-product, three-way arrays are treated as matrices whose elements(scalars) are n-tuples or tubes. Convolutions take the place of scalarmultiplication. This framework allows us to embed the 2-D data into avector-space-like structure called a free module over a commutative ring. Thesefree modules retain many properties of complex inner-product spaces, and weleverage that to provide theoretical guarantees on our algorithm. We show thatcompared to vector-space counterparts, SSmC achieves higher accuracy and betterable to cluster data with less preprocessing in some image clustering problems.In particular we show the performance of the proposed method on Weizmann facedatabase, the Extended Yale B Face database and the MNIST handwritten digitsdatabase.
arxiv-9600-215 | Denoising autoencoder with modulated lateral connections learns invariant representations of natural images | http://arxiv.org/pdf/1412.7210v4.pdf | author:Antti Rasmus, Tapani Raiko, Harri Valpola category:cs.NE cs.CV cs.LG stat.ML published:2014-12-22 summary:Suitable lateral connections between encoder and decoder are shown to allowhigher layers of a denoising autoencoder (dAE) to focus on invariantrepresentations. In regular autoencoders, detailed information needs to becarried through the highest layers but lateral connections from encoder todecoder relieve this pressure. It is shown that abstract invariant features canbe translated to detailed reconstructions when invariant features are allowedto modulate the strength of the lateral connection. Three dAE structures withmodulated and additive lateral connections, and without lateral connectionswere compared in experiments using real-world images. The experiments verifythat adding modulated lateral connections to the model 1) improves the accuracyof the probability model for inputs, as measured by denoising performance; 2)results in representations whose degree of invariance grows faster towards thehigher layers; and 3) supports the formation of diverse invariant poolings.
arxiv-9600-216 | Learning Compact Convolutional Neural Networks with Nested Dropout | http://arxiv.org/pdf/1412.7155v4.pdf | author:Chelsea Finn, Lisa Anne Hendricks, Trevor Darrell category:cs.CV cs.LG cs.NE published:2014-12-22 summary:Recently, nested dropout was proposed as a method for ordering representationunits in autoencoders by their information content, without diminishingreconstruction cost. However, it has only been applied to trainingfully-connected autoencoders in an unsupervised setting. We explore the impactof nested dropout on the convolutional layers in a CNN trained bybackpropagation, investigating whether nested dropout can provide a simple andsystematic way to determine the optimal representation size with respect to thedesired accuracy and desired task and data complexity.
arxiv-9600-217 | Training deep neural networks with low precision multiplications | http://arxiv.org/pdf/1412.7024v5.pdf | author:Matthieu Courbariaux, Yoshua Bengio, Jean-Pierre David category:cs.LG cs.CV cs.NE published:2014-12-22 summary:Multipliers are the most space and power-hungry arithmetic operators of thedigital implementation of deep neural networks. We train a set ofstate-of-the-art neural networks (Maxout networks) on three benchmark datasets:MNIST, CIFAR-10 and SVHN. They are trained with three distinct formats:floating point, fixed point and dynamic fixed point. For each of those datasetsand for each of those formats, we assess the impact of the precision of themultiplications on the final error after training. We find that very lowprecision is sufficient not just for running trained networks but also fortraining them. For example, it is possible to train Maxout networks with 10bits multiplications.
arxiv-9600-218 | Occlusion Edge Detection in RGB-D Frames using Deep Convolutional Networks | http://arxiv.org/pdf/1412.7007v3.pdf | author:Soumik Sarkar, Vivek Venugopalan, Kishore Reddy, Michael Giering, Julian Ryde, Navdeep Jaitly category:cs.CV cs.LG cs.NE published:2014-12-22 summary:Occlusion edges in images which correspond to range discontinuity in thescene from the point of view of the observer are an important prerequisite formany vision and mobile robot tasks. Although they can be extracted from rangedata however extracting them from images and videos would be extremelybeneficial. We trained a deep convolutional neural network (CNN) to identifyocclusion edges in images and videos with both RGB-D and RGB inputs. The use ofCNN avoids hand-crafting of features for automatically isolating occlusionedges and distinguishing them from appearance edges. Other than quantitativeocclusion edge detection results, qualitative results are provided todemonstrate the trade-off between high resolution analysis and frame-levelcomputation time which is critical for real-time robotics applications.
arxiv-9600-219 | Deep Fried Convnets | http://arxiv.org/pdf/1412.7149v4.pdf | author:Zichao Yang, Marcin Moczulski, Misha Denil, Nando de Freitas, Alex Smola, Le Song, Ziyu Wang category:cs.LG cs.NE stat.ML published:2014-12-22 summary:The fully connected layers of a deep convolutional neural network typicallycontain over 90% of the network parameters, and consume the majority of thememory required to store the network parameters. Reducing the number ofparameters while preserving essentially the same predictive performance iscritically important for operating deep neural networks in memory constrainedenvironments such as GPUs or embedded devices. In this paper we show how kernel methods, in particular a single Fastfoodlayer, can be used to replace all fully connected layers in a deepconvolutional neural network. This novel Fastfood layer is also end-to-endtrainable in conjunction with convolutional layers, allowing us to combine theminto a new architecture, named deep fried convolutional networks, whichsubstantially reduces the memory footprint of convolutional networks trained onMNIST and ImageNet with no drop in predictive performance.
arxiv-9600-220 | An $\{l_1,l_2,l_{\infty}\}$-Regularization Approach to High-Dimensional Errors-in-variables Models | http://arxiv.org/pdf/1412.7216v1.pdf | author:Alexandre Belloni, Mathieu Rosenbaum, Alexandre B. Tsybakov category:math.ST stat.ML stat.TH published:2014-12-22 summary:Several new estimation methods have been recently proposed for the linearregression model with observation error in the design. Different assumptions onthe data generating process have motivated different estimators and analysis.In particular, the literature considered (1) observation errors in the designuniformly bounded by some $\bar \delta$, and (2) zero mean independentobservation errors. Under the first assumption, the rates of convergence of theproposed estimators depend explicitly on $\bar \delta$, while the secondassumption has been applied when an estimator for the second moment of theobservational error is available. This work proposes and studies two newestimators which, compared to other procedures for regression models witherrors in the design, exploit an additional $l_{\infty}$-norm regularization.The first estimator is applicable when both (1) and (2) hold but does notrequire an estimator for the second moment of the observational error. Thesecond estimator is applicable under (2) and requires an estimator for thesecond moment of the observation error. Importantly, we impose no assumption onthe accuracy of this pilot estimator, in contrast to the previously knownprocedures. As the recent proposals, we allow the number of covariates to bemuch larger than the sample size. We establish the rates of convergence of theestimators and compare them with the bounds obtained for related estimators inthe literature. These comparisons show interesting insights on the interplay ofthe assumptions and the achievable rates of convergence.
arxiv-9600-221 | Multi-modal Sensor Registration for Vehicle Perception via Deep Neural Networks | http://arxiv.org/pdf/1412.7006v2.pdf | author:Michael Giering, Vivek Venugopalan, Kishore Reddy category:cs.CV cs.LG cs.NE published:2014-12-22 summary:The ability to simultaneously leverage multiple modes of sensor informationis critical for perception of an automated vehicle's physical surroundings.Spatio-temporal alignment of registration of the incoming information is oftena prerequisite to analyzing the fused data. The persistence and reliability ofmulti-modal registration is therefore the key to the stability of decisionsupport systems ingesting the fused information. LiDAR-video systems like onthose many driverless cars are a common example of where keeping the LiDAR andvideo channels registered to common physical features is important. We developa deep learning method that takes multiple channels of heterogeneous data, todetect the misalignment of the LiDAR-video inputs. A number of variations weretested on the Ford LiDAR-video driving test data set and will be discussed. Tothe best of our knowledge the use of multi-modal deep convolutional neuralnetworks for dynamic real-time LiDAR-video registration has not been presented.
arxiv-9600-222 | Online Distributed Optimization on Dynamic Networks | http://arxiv.org/pdf/1412.7215v1.pdf | author:Saghar Hosseini, Airlie Chapman, Mehran Mesbahi category:math.OC cs.DS cs.LG cs.MA cs.SY published:2014-12-22 summary:This paper presents a distributed optimization scheme over a network ofagents in the presence of cost uncertainties and over switching communicationtopologies. Inspired by recent advances in distributed convex optimization, wepropose a distributed algorithm based on a dual sub-gradient averaging. Theobjective of this algorithm is to minimize a cost function cooperatively.Furthermore, the algorithm changes the weights on the communication links inthe network to adapt to varying reliability of neighboring agents. Aconvergence rate analysis as a function of the underlying network topology isthen presented, followed by simulation results for representative classes ofsensor networks.
arxiv-9600-223 | Audio Source Separation Using a Deep Autoencoder | http://arxiv.org/pdf/1412.7193v1.pdf | author:Giljin Jang, Han-Gyu Kim, Yung-Hwan Oh category:cs.SD cs.LG cs.NE published:2014-12-22 summary:This paper proposes a novel framework for unsupervised audio sourceseparation using a deep autoencoder. The characteristics of unknown sourcesignals mixed in the mixed input is automatically by properly configuredautoencoders implemented by a network with many layers, and separated byclustering the coefficient vectors in the code layer. By investigating theweight vectors to the final target, representation layer, the primitivecomponents of the audio signals in the frequency domain are observed. Byclustering the activation coefficients in the code layer, the previouslyunknown source signals are segregated. The original source sounds are thenseparated and reconstructed by using code vectors which belong to differentclusters. The restored sounds are not perfect but yield promising results forthe possibility in the success of many practical applications.
arxiv-9600-224 | Bayesian Optimisation for Machine Translation | http://arxiv.org/pdf/1412.7180v1.pdf | author:Yishu Miao, Ziyu Wang, Phil Blunsom category:cs.CL cs.LG I.2.7 published:2014-12-22 summary:This paper presents novel Bayesian optimisation algorithms for minimum errorrate training of statistical machine translation systems. We explore twoclasses of algorithms for efficiently exploring the translation space, with thefirst based on N-best lists and the second based on a hypergraph representationthat compactly represents an exponential number of translation options. Ouralgorithms exhibit faster convergence and are capable of obtaining lower errorrates than the existing translation model specific approaches, all within ageneric Bayesian optimisation framework. Further more, we also introduce arandom embedding algorithm to scale our approach to sparse high dimensionalfeature sets.
arxiv-9600-225 | Half-CNN: A General Framework for Whole-Image Regression | http://arxiv.org/pdf/1412.6885v1.pdf | author:Jun Yuan, Bingbing Ni, Ashraf A. Kassim category:cs.CV cs.LG cs.NE published:2014-12-22 summary:The Convolutional Neural Network (CNN) has achieved great success in imageclassification. The classification model can also be utilized at image or patchlevel for many other applications, such as object detection and segmentation.In this paper, we propose a whole-image CNN regression model, by removing thefull connection layer and training the network with continuous feature maps.This is a generic regression framework that fits many applications. Wedemonstrate this method through two tasks: simultaneous face detection &segmentation, and scene saliency prediction. The result is comparable withother models in the respective fields, using only a small scale network. Sincethe regression model is trained on corresponding image / feature map pairs,there are no requirements on uniform input size as opposed to theclassification model. Our framework avoids classifier design, a process thatmay introduce too much manual intervention in model development. Yet, it ishighly correlated to the classification network and offers some in-deep reviewof CNN structures.
arxiv-9600-226 | A New Way to Factorize Linear Cameras | http://arxiv.org/pdf/1412.6847v1.pdf | author:Feng Lu, Ziqiang Chen category:cs.CV published:2014-12-22 summary:The implementation details of factorizing the 3x4 projection matrices oflinear cameras into their left matrix factors and the 4x4 homogeneouscentral(also parallel for infinite center cases) projection factors arepresented in this work. Any full row rank 3x4 real matrix can be factorizedinto such basic matrices which will be called LC factors. A further extension to multiple view midpoint triangulation, for both pinholeand affine camera cases, is also presented based on such camera factorizations.
arxiv-9600-227 | Learning Deep Object Detectors from 3D Models | http://arxiv.org/pdf/1412.7122v4.pdf | author:Xingchao Peng, Baochen Sun, Karim Ali, Kate Saenko category:cs.CV cs.LG cs.NE published:2014-12-22 summary:Crowdsourced 3D CAD models are becoming easily accessible online, and canpotentially generate an infinite number of training images for almost anyobject category.We show that augmenting the training data of contemporary DeepConvolutional Neural Net (DCNN) models with such synthetic data can beeffective, especially when real training data is limited or not well matched tothe target domain. Most freely available CAD models capture 3D shape but areoften missing other low level cues, such as realistic object texture, pose, orbackground. In a detailed analysis, we use synthetic CAD-rendered images toprobe the ability of DCNN to learn without these cues, with surprisingfindings. In particular, we show that when the DCNN is fine-tuned on the targetdetection task, it exhibits a large degree of invariance to missing low-levelcues, but, when pretrained on generic ImageNet classification, it learns betterwhen the low-level cues are simulated. We show that our synthetic DCNN trainingapproach significantly outperforms previous methods on the PASCAL VOC2007dataset when learning in the few-shot scenario and improves performance in adomain shift scenario on the Office benchmark.
arxiv-9600-228 | Pragmatic Neural Language Modelling in Machine Translation | http://arxiv.org/pdf/1412.7119v3.pdf | author:Paul Baltescu, Phil Blunsom category:cs.CL published:2014-12-22 summary:This paper presents an in-depth investigation on integrating neural languagemodels in translation systems. Scaling neural language models is a difficulttask, but crucial for real-world applications. This paper evaluates the impacton end-to-end MT quality of both new and existing scaling techniques. We showwhen explicitly normalising neural models is necessary and what optimisationtricks one should use in such scenarios. We also focus on scalable trainingalgorithms and investigate noise contrastive estimation and diagonal contextsas sources for further speed improvements. We explore the trade-offs betweenneural models and back-off n-gram models and find that neural models makestrong candidates for natural language applications in memory constrainedenvironments, yet still lag behind traditional models in raw translationquality. We conclude with a set of recommendations one should follow to build ascalable neural language model for MT.
arxiv-9600-229 | Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs | http://arxiv.org/pdf/1412.7062v3.pdf | author:Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L. Yuille category:cs.CV cs.LG cs.NE published:2014-12-22 summary:Deep Convolutional Neural Networks (DCNNs) have recently shown state of theart performance in high level vision tasks, such as image classification andobject detection. This work brings together methods from DCNNs andprobabilistic graphical models for addressing the task of pixel-levelclassification (also called "semantic image segmentation"). We show thatresponses at the final layer of DCNNs are not sufficiently localized foraccurate object segmentation. This is due to the very invariance propertiesthat make DCNNs good for high level tasks. We overcome this poor localizationproperty of deep networks by combining the responses at the final DCNN layerwith a fully connected Conditional Random Field (CRF). Qualitatively, our"DeepLab" system is able to localize segment boundaries at a level of accuracywhich is beyond previous methods. Quantitatively, our method sets the newstate-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching71.6% IOU accuracy in the test set. We show how these results can be obtainedefficiently: Careful network re-purposing and a novel application of the 'hole'algorithm from the wavelet community allow dense computation of neural netresponses at 8 frames per second on a modern GPU.
arxiv-9600-230 | Adam: A Method for Stochastic Optimization | http://arxiv.org/pdf/1412.6980v8.pdf | author:Diederik Kingma, Jimmy Ba category:cs.LG published:2014-12-22 summary:We introduce Adam, an algorithm for first-order gradient-based optimizationof stochastic objective functions, based on adaptive estimates of lower-ordermoments. The method is straightforward to implement, is computationallyefficient, has little memory requirements, is invariant to diagonal rescalingof the gradients, and is well suited for problems that are large in terms ofdata and/or parameters. The method is also appropriate for non-stationaryobjectives and problems with very noisy and/or sparse gradients. Thehyper-parameters have intuitive interpretations and typically require littletuning. Some connections to related algorithms, on which Adam was inspired, arediscussed. We also analyze the theoretical convergence properties of thealgorithm and provide a regret bound on the convergence rate that is comparableto the best known results under the online convex optimization framework.Empirical results demonstrate that Adam works well in practice and comparesfavorably to other stochastic optimization methods. Finally, we discuss AdaMax,a variant of Adam based on the infinity norm.
arxiv-9600-231 | Contour Detection Using Cost-Sensitive Convolutional Neural Networks | http://arxiv.org/pdf/1412.6857v5.pdf | author:Jyh-Jing Hwang, Tyng-Luh Liu category:cs.CV cs.LG cs.NE published:2014-12-22 summary:We address the problem of contour detection via per-pixel classifications ofedge point. To facilitate the process, the proposed approach leverages withDenseNet, an efficient implementation of multiscale convolutional neuralnetworks (CNNs), to extract an informative feature vector for each pixel anduses an SVM classifier to accomplish contour detection. The main challenge liesin adapting a pre-trained per-image CNN model for yielding per-pixel imagefeatures. We propose to base on the DenseNet architecture to achieve pixelwisefine-tuning and then consider a cost-sensitive strategy to further improve thelearning with a small dataset of edge and non-edge image patches. In theexperiment of contour detection, we look into the effectiveness of combiningper-pixel features from different CNN layers and obtain comparable performancesto the state-of-the-art on BSDS500.
arxiv-9600-232 | Tailoring Word Embeddings for Bilexical Predictions: An Experimental Comparison | http://arxiv.org/pdf/1412.7004v2.pdf | author:Pranava Swaroop Madhyastha, Xavier Carreras, Ariadna Quattoni category:cs.CL cs.LG published:2014-12-22 summary:We investigate the problem of inducing word embeddings that are tailored fora particular bilexical relation. Our learning algorithm takes an existinglexical vector space and compresses it such that the resulting word embeddingsare good predictors for a target bilexical relation. In experiments we showthat task-specific embeddings can benefit both the quality and efficiency inlexical prediction tasks.
arxiv-9600-233 | Representation Learning for cold-start recommendation | http://arxiv.org/pdf/1412.7156v5.pdf | author:Gabriella Contardo, Ludovic Denoyer, Thierry Artieres category:cs.IR cs.LG published:2014-12-22 summary:A standard approach to Collaborative Filtering (CF), i.e. prediction of userratings on items, relies on Matrix Factorization techniques. Representationsfor both users and items are computed from the observed ratings and used forprediction. Unfortunatly, these transductive approaches cannot handle the caseof new users arriving in the system, with no known rating, a problem known asuser cold-start. A common approach in this context is to ask these incomingusers for a few initialization ratings. This paper presents a model to tacklethis twofold problem of (i) finding good questions to ask, (ii) buildingefficient representations from this small amount of information. The model canalso be used in a more standard (warm) context. Our approach is evaluated onthe classical CF problem and on the cold-start problem on four differentdatasets showing its ability to improve baseline performance in both cases.
arxiv-9600-234 | Efficient Exact Gradient Update for training Deep Networks with Very Large Sparse Targets | http://arxiv.org/pdf/1412.7091v3.pdf | author:Pascal Vincent, Alexandre de Brébisson, Xavier Bouthillier category:cs.NE cs.CL cs.LG published:2014-12-22 summary:An important class of problems involves training deep neural networks withsparse prediction targets of very high dimension D. These occur naturally ine.g. neural language models or the learning of word-embeddings, often posed aspredicting the probability of next words among a vocabulary of size D (e.g. 200000). Computing the equally large, but typically non-sparse D-dimensionaloutput vector from a last hidden layer of reasonable dimension d (e.g. 500)incurs a prohibitive O(Dd) computational cost for each example, as doesupdating the D x d output weight matrix and computing the gradient needed forbackpropagation to previous layers. While efficient handling of large sparsenetwork inputs is trivial, the case of large sparse targets is not, and hasthus so far been sidestepped with approximate alternatives such as hierarchicalsoftmax or sampling-based approximations during training. In this work wedevelop an original algorithmic approach which, for a family of loss functionsthat includes squared error and spherical softmax, can compute the exact loss,gradient update for the output weights, and gradient for backpropagation, allin O(d^2) per example instead of O(Dd), remarkably without ever computing theD-dimensional output. The proposed algorithm yields a speedup of D/4d , i.e.two orders of magnitude for typical sizes, for that critical part of thecomputations that often dominates the training time in this kind of networkarchitecture.
arxiv-9600-235 | Reply to the commentary "Be careful when assuming the obvious", by P. Alday | http://arxiv.org/pdf/1412.7186v2.pdf | author:Ramon Ferrer-i-Cancho category:cs.CL physics.soc-ph published:2014-12-22 summary:Here we respond to some comments by Alday concerning headedness in linguistictheory and the validity of the assumptions of a mathematical model for wordorder. For brevity, we focus only on two assumptions: the unit of measurementof dependency length and the monotonicity of the cost of a dependency as afunction of its length. We also revise the implicit psychological bias inAlday's comments. Notwithstanding, Alday is indicating the path for linguisticresearch with his unusual concerns about parsimony from multiple dimensions.
arxiv-9600-236 | Fully Convolutional Multi-Class Multiple Instance Learning | http://arxiv.org/pdf/1412.7144v4.pdf | author:Deepak Pathak, Evan Shelhamer, Jonathan Long, Trevor Darrell category:cs.CV cs.LG cs.NE published:2014-12-22 summary:Multiple instance learning (MIL) can reduce the need for costly annotation intasks such as semantic segmentation by weakening the required degree ofsupervision. We propose a novel MIL formulation of multi-class semanticsegmentation learning by a fully convolutional network. In this setting, weseek to learn a semantic segmentation model from just weak image-level labels.The model is trained end-to-end to jointly optimize the representation whiledisambiguating the pixel-image label assignment. Fully convolutional trainingaccepts inputs of any size, does not need object proposal pre-processing, andoffers a pixelwise loss map for selecting latent instances. Our multi-class MILloss exploits the further supervision given by images with multiple labels. Weevaluate this approach through preliminary experiments on the PASCAL VOCsegmentation challenge.
arxiv-9600-237 | Audio Source Separation with Discriminative Scattering Networks | http://arxiv.org/pdf/1412.7022v3.pdf | author:Pablo Sprechmann, Joan Bruna, Yann LeCun category:cs.SD cs.LG published:2014-12-22 summary:In this report we describe an ongoing line of research for solvingsingle-channel source separation problems. Many monaural signal decompositiontechniques proposed in the literature operate on a feature space consisting ofa time-frequency representation of the input data. A challenge faced by theseapproaches is to effectively exploit the temporal dependencies of the signalsat scales larger than the duration of a time-frame. In this work we propose totackle this problem by modeling the signals using a time-frequencyrepresentation with multiple temporal resolutions. The proposed representationconsists of a pyramid of wavelet scattering operators, which generalizesConstant Q Transforms (CQT) with extra layers of convolution and complexmodulus. We first show that learning standard models with this multi-resolutionsetting improves source separation results over fixed-resolution methods. Asstudy case, we use Non-Negative Matrix Factorizations (NMF) that has beenwidely considered in many audio application. Then, we investigate the inclusionof the proposed multi-resolution setting into a discriminative training regime.We discuss several alternatives using different deep neural networkarchitectures.
arxiv-9600-238 | Object Detectors Emerge in Deep Scene CNNs | http://arxiv.org/pdf/1412.6856v2.pdf | author:Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba category:cs.CV cs.NE published:2014-12-22 summary:With the success of new computational architectures for visual processing,such as convolutional neural networks (CNN) and access to image databases withmillions of labeled examples (e.g., ImageNet, Places), the state of the art incomputer vision is advancing rapidly. One important factor for continuedprogress is to understand the representations that are learned by the innerlayers of these deep architectures. Here we show that object detectors emergefrom training CNNs to perform scene classification. As scenes are composed ofobjects, the CNN for scene classification automatically discovers meaningfulobjects detectors, representative of the learned scene categories. With objectdetectors emerging as a result of learning to recognize scenes, our workdemonstrates that the same network can perform both scene recognition andobject localization in a single forward-pass, without ever having beenexplicitly taught the notion of objects.
arxiv-9600-239 | Diverse Embedding Neural Network Language Models | http://arxiv.org/pdf/1412.7063v5.pdf | author:Kartik Audhkhasi, Abhinav Sethy, Bhuvana Ramabhadran category:cs.CL cs.LG cs.NE published:2014-12-22 summary:We propose Diverse Embedding Neural Network (DENN), a novel architecture forlanguage models (LMs). A DENNLM projects the input word history vector ontomultiple diverse low-dimensional sub-spaces instead of a singlehigher-dimensional sub-space as in conventional feed-forward neural networkLMs. We encourage these sub-spaces to be diverse during network trainingthrough an augmented loss function. Our language modeling experiments on thePenn Treebank data set show the performance benefit of using a DENNLM.
arxiv-9600-240 | Joint RNN-Based Greedy Parsing and Word Composition | http://arxiv.org/pdf/1412.7028v4.pdf | author:Joël Legrand, Ronan Collobert category:cs.LG cs.CL cs.NE published:2014-12-22 summary:This paper introduces a greedy parser based on neural networks, whichleverages a new compositional sub-tree representation. The greedy parser andthe compositional procedure are jointly trained, and tightly depends oneach-other. The composition procedure outputs a vector representation whichsummarizes syntactically (parsing tags) and semantically (words) sub-trees.Composition and tagging is achieved over continuous (word or tag)representations, and recurrent neural networks. We reach F1 performance on parwith well-known existing parsers, while having the advantage of speed, thanksto the greedy nature of the parser. We provide a fully functionalimplementation of the method described in this paper.
arxiv-9600-241 | Language Recognition using Random Indexing | http://arxiv.org/pdf/1412.7026v2.pdf | author:Aditya Joshi, Johan Halseth, Pentti Kanerva category:cs.CL cs.LG published:2014-12-22 summary:Random Indexing is a simple implementation of Random Projections with a widerange of applications. It can solve a variety of problems with good accuracywithout introducing much complexity. Here we use it for identifying thelanguage of text samples. We present a novel method of generating languagerepresentation vectors using letter blocks. Further, we show that the method iseasily implemented and requires little computational power and space.Experiments on a number of model parameters illustrate certain properties abouthigh dimensional sparse vector representations of data. Proof of statisticallyrelevant language vectors are shown through the extremely high success ofvarious language recognition tasks. On a difficult data set of 21,000 shortsentences from 21 different languages, our model performs a languagerecognition task and achieves 97.8% accuracy, comparable to state-of-the-artmethods.
arxiv-9600-242 | On Learning Vector Representations in Hierarchical Label Spaces | http://arxiv.org/pdf/1412.6881v3.pdf | author:Jinseok Nam, Johannes Fürnkranz category:cs.LG cs.CL stat.ML published:2014-12-22 summary:An important problem in multi-label classification is to capture labelpatterns or underlying structures that have an impact on such patterns. Thispaper addresses one such problem, namely how to exploit hierarchical structuresover labels. We present a novel method to learn vector representations of alabel space given a hierarchy of labels and label co-occurrence patterns. Ourexperimental results demonstrate qualitatively that the proposed method is ableto learn regularities among labels by exploiting a label hierarchy as well aslabel co-occurrences. It highlights the importance of the hierarchicalinformation in order to obtain regularities which facilitate analogicalreasoning over a label space. We also experimentally illustrate the dependencyof the learned representations on the label hierarchy.
arxiv-9600-243 | Attention for Fine-Grained Categorization | http://arxiv.org/pdf/1412.7054v3.pdf | author:Pierre Sermanet, Andrea Frome, Esteban Real category:cs.CV cs.LG cs.NE published:2014-12-22 summary:This paper presents experiments extending the work of Ba et al. (2014) onrecurrent neural models for attention into less constrained visualenvironments, specifically fine-grained categorization on the Stanford Dogsdata set. In this work we use an RNN of the same structure but substitute amore powerful visual network and perform large-scale pre-training of the visualnetwork outside of the attention RNN. Most work in attention models to datefocuses on tasks with toy or more constrained visual environments, whereas wepresent results for fine-grained categorization better than thestate-of-the-art GoogLeNet classification model. We show that our model learnsto direct high resolution attention to the most discriminative regions withoutany spatial supervision such as bounding boxes, and it is able to discriminatefine-grained dog breeds moderately well even when given only an initiallow-resolution context image and narrow, inexpensive glimpses at faces and furpatterns. This and similar attention models have the major advantage of beingtrained end-to-end, as opposed to other current detection and recognitionpipelines with hand-engineered components where information is lost. While ourmodel is state-of-the-art, further work is needed to fully leverage thesequential input.
arxiv-9600-244 | Learning linearly separable features for speech recognition using convolutional neural networks | http://arxiv.org/pdf/1412.7110v6.pdf | author:Dimitri Palaz, Mathew Magimai Doss, Ronan Collobert category:cs.LG cs.CL cs.NE published:2014-12-22 summary:Automatic speech recognition systems usually rely on spectral-based features,such as MFCC of PLP. These features are extracted based on prior knowledge suchas, speech perception or/and speech production. Recently, convolutional neuralnetworks have been shown to be able to estimate phoneme conditionalprobabilities in a completely data-driven manner, i.e. using directly temporalraw speech signal as input. This system was shown to yield similar or betterperformance than HMM/ANN based system on phoneme recognition task and on largescale continuous speech recognition task, using less parameters. Motivated bythese studies, we investigate the use of simple linear classifier in theCNN-based framework. Thus, the network learns linearly separable features fromraw speech. We show that such system yields similar or better performance thanMLP based system using cepstral-based features as input.
arxiv-9600-245 | Convolutional Neural Networks for joint object detection and pose estimation: A comparative study | http://arxiv.org/pdf/1412.7190v4.pdf | author:Francisco Massa, Mathieu Aubry, Renaud Marlet category:cs.CV cs.LG cs.NE published:2014-12-22 summary:In this paper we study the application of convolutional neural networks forjointly detecting objects depicted in still images and estimating their 3Dpose. We identify different feature representations of oriented objects, andenergies that lead a network to learn this representations. The choice of therepresentation is crucial since the pose of an object has a natural, continuousstructure while its category is a discrete variable. We evaluate the differentapproaches on the joint object detection and pose estimation task of thePascal3D+ benchmark using Average Viewpoint Precision. We show that aclassification approach on discretized viewpoints achieves state-of-the-artperformance for joint object detection and pose estimation, and significantlyoutperforms existing baselines on this benchmark.
arxiv-9600-246 | SENNS: Sparse Extraction Neural NetworkS for Feature Extraction | http://arxiv.org/pdf/1412.6749v1.pdf | author:Abdulrahman Oladipupo Ibraheem category:cs.CV cs.AI cs.NE math.OC stat.ML 90-08 published:2014-12-21 summary:By drawing on ideas from optimisation theory, artificial neural networks(ANN), graph embeddings and sparse representations, I develop a noveltechnique, termed SENNS (Sparse Extraction Neural NetworkS), aimed ataddressing the feature extraction problem. The proposed method uses (preferablydeep) ANNs for projecting input attribute vectors to an output space whereinpairwise distances are maximized for vectors belonging to different classes,but minimized for those belonging to the same class, while simultaneouslyenforcing sparsity on the ANN outputs. The vectors that result from theprojection can then be used as features in any classifier of choice.Mathematically, I formulate the proposed method as the minimisation of anobjective function which can be interpreted, in the ANN output space, as anegative factor of the sum of the squares of the pair-wise distances betweenoutput vectors belonging to different classes, added to a positive factor ofthe sum of squares of the pair-wise distances between output vectors belongingto the same classes, plus sparsity and weight decay terms. To derive analgorithm for minimizing the objective function via gradient descent, I use themulti-variate version of the chain rule to obtain the partial derivatives ofthe function with respect to ANN weights and biases, and find that each of therequired partial derivatives can be expressed as a sum of six terms. As itturns out, four of those six terms can be computed using the standard backpropagation algorithm; the fifth can be computed via a slight modification ofthe standard backpropagation algorithm; while the sixth one can be computed viasimple arithmetic. Finally, I propose experiments on the ARABASE Arabic corporaof digits and letters, the CMU PIE database of faces, the MNIST digitsdatabase, and other standard machine learning databases.
arxiv-9600-247 | Locally Weighted Learning for Naive Bayes Classifier | http://arxiv.org/pdf/1412.6741v1.pdf | author:Kim-Hung Li, Cheuk Ting Li category:stat.ML cs.LG published:2014-12-21 summary:As a consequence of the strong and usually violated conditional independenceassumption (CIA) of naive Bayes (NB) classifier, the performance of NB becomesless and less favorable compared to sophisticated classifiers when the samplesize increases. We learn from this phenomenon that when the size of thetraining data is large, we should either relax the assumption or apply NB to a"reduced" data set, say for example use NB as a local model. The latterapproach trades the ignored information for the robustness to the modelassumption. In this paper, we consider using NB as a model for locally weighteddata. A special weighting function is designed so that if CIA holds for theunweighted data, it also holds for the weighted data. The new method isintuitive and capable of handling class imbalance. It is theoretically moresound than the locally weighted learners of naive Bayes that baseclassification only on the $k$ nearest neighbors. Empirical study shows thatthe new method with appropriate choice of parameter outperforms seven existingclassifiers of similar nature.
arxiv-9600-248 | Implicit Temporal Differences | http://arxiv.org/pdf/1412.6734v1.pdf | author:Aviv Tamar, Panos Toulis, Shie Mannor, Edoardo M. Airoldi category:stat.ML cs.LG published:2014-12-21 summary:In reinforcement learning, the TD($\lambda$) algorithm is a fundamentalpolicy evaluation method with an efficient online implementation that issuitable for large-scale problems. One practical drawback of TD($\lambda$) isits sensitivity to the choice of the step-size. It is an empirically well-knownfact that a large step-size leads to fast convergence, at the cost of highervariance and risk of instability. In this work, we introduce the implicitTD($\lambda$) algorithm which has the same function and computational cost asTD($\lambda$), but is significantly more stable. We provide a theoreticalexplanation of this stability and an empirical evaluation of implicitTD($\lambda$) on typical benchmark tasks. Our results show that implicitTD($\lambda$) outperforms standard TD($\lambda$) and a state-of-the-art methodthat automatically tunes the step-size, and thus shows promise for wideapplicability.
arxiv-9600-249 | Correlation of Data Reconstruction Error and Shrinkages in Pair-wise Distances under Principal Component Analysis (PCA) | http://arxiv.org/pdf/1412.6752v1.pdf | author:Abdulrahman Oladipupo Ibraheem category:cs.LG stat.ML published:2014-12-21 summary:In this on-going work, I explore certain theoretical and empiricalimplications of data transformations under the PCA. In particular, I state andprove three theorems about PCA, which I paraphrase as follows: 1). PCA withoutdiscarding eigenvector rows is injective, but looses this injectivity wheneigenvector rows are discarded 2). PCA without discarding eigen- vector rowspreserves pair-wise distances, but tends to cause pair-wise distances to shrinkwhen eigenvector rows are discarded. 3). For any pair of points, the shrinkagein pair-wise distance is bounded above by an L1 norm reconstruction errorassociated with the points. Clearly, 3). suggests that there might exist somecorrelation between shrinkages in pair-wise distances and mean squarereconstruction error which is defined as the sum of those eigenvaluesassociated with the discarded eigenvectors. I therefore decided to performnumerical experiments to obtain the corre- lation between the sum of thoseeigenvalues and shrinkages in pair-wise distances. In addition, I have alsoperformed some experiments to check respectively the effect of the sum of thoseeigenvalues and the effect of the shrinkages on classification accuracies underthe PCA map. So far, I have obtained the following results on some publiclyavailable data from the UCI Machine Learning Repository: 1). There seems to bea strong cor- relation between the sum of those eigenvalues associated withdiscarded eigenvectors and shrinkages in pair-wise distances. 2). Neither thesum of those eigenvalues nor pair-wise distances have any strong correlationswith classification accuracies. 1
arxiv-9600-250 | A Stable Multi-Scale Kernel for Topological Machine Learning | http://arxiv.org/pdf/1412.6821v1.pdf | author:Jan Reininghaus, Stefan Huber, Ulrich Bauer, Roland Kwitt category:stat.ML cs.CV cs.LG math.AT published:2014-12-21 summary:Topological data analysis offers a rich source of valuable information tostudy vision problems. Yet, so far we lack a theoretically sound connection topopular kernel-based learning techniques, such as kernel SVMs or kernel PCA. Inthis work, we establish such a connection by designing a multi-scale kernel forpersistence diagrams, a stable summary representation of topological featuresin data. We show that this kernel is positive definite and prove its stabilitywith respect to the 1-Wasserstein distance. Experiments on two benchmarkdatasets for 3D shape classification/retrieval and texture recognition showconsiderable performance gains of the proposed method compared to analternative approach that is based on the recently introduced persistencelandscapes.
arxiv-9600-251 | Mixture of Parts Revisited: Expressive Part Interactions for Pose Estimation | http://arxiv.org/pdf/1412.6791v1.pdf | author:Anoop Katti, Anurag Mittal category:cs.CV published:2014-12-21 summary:Part-based models with restrictive tree-structured interactions for the HumanPose Estimation problem, leaves many part interactions unhandled. Two of themost common and strong manifestations of such unhandled interactions areself-occlusion among the parts and the confusion in the localization of thenon-adjacent symmetric parts. By handling the self-occlusion in a dataefficient manner, we improve the performance of the basic Mixture of Partsmodel by a large margin, especially on uncommon poses. Through addressing theconfusion in the symmetric limb localization using a combination of twocomplementing trees, we improve the performance on all the parts by atmostdoubling the running time. Finally, we show that the combination of the twosolutions improves the results. We report results that are equivalent to thestate-of-the-art on two standard datasets. Because of maintaining thetree-structured interactions and only part-level modeling of the base Mixtureof Parts model, this is achieved in time that is much less than the bestperforming part-based model.
arxiv-9600-252 | Learning the nonlinear geometry of high-dimensional data: Models and algorithms | http://arxiv.org/pdf/1412.6808v2.pdf | author:Tong Wu, Waheed U. Bajwa category:stat.ML cs.CV cs.LG published:2014-12-21 summary:Modern information processing relies on the axiom that high-dimensional datalie near low-dimensional geometric structures. This paper revisits the problemof data-driven learning of these geometric structures and puts forth two newnonlinear geometric models for data describing "related" objects/phenomena. Thefirst one of these models straddles the two extremes of the subspace model andthe union-of-subspaces model, and is termed the metric-constrainedunion-of-subspaces (MC-UoS) model. The second one of these models---suited fordata drawn from a mixture of nonlinear manifolds---generalizes the kernelsubspace model, and is termed the metric-constrained kernel union-of-subspaces(MC-KUoS) model. The main contributions of this paper in this regard includethe following. First, it motivates and formalizes the problems of MC-UoS andMC-KUoS learning. Second, it presents algorithms that efficiently learn anMC-UoS or an MC-KUoS underlying data of interest. Third, it extends thesealgorithms to the case when parts of the data are missing. Last, but not least,it reports the outcomes of a series of numerical experiments involving bothsynthetic and real data that demonstrate the superiority of the proposedgeometric models and learning algorithms over existing approaches in theliterature. These experiments also help clarify the connections between thiswork and the literature on (subspace and kernel k-means) clustering.
arxiv-9600-253 | Extraction of Salient Sentences from Labelled Documents | http://arxiv.org/pdf/1412.6815v2.pdf | author:Misha Denil, Alban Demiraj, Nando de Freitas category:cs.CL cs.IR cs.LG published:2014-12-21 summary:We present a hierarchical convolutional document model with an architecturedesigned to support introspection of the document structure. Using this model,we show how to use visualisation techniques from the computer vision literatureto identify and extract topic-relevant sentences. We also introduce a new scalable evaluation technique for automatic sentenceextraction systems that avoids the need for time consuming human annotation ofvalidation data.
arxiv-9600-254 | Microbial community pattern detection in human body habitats via ensemble clustering framework | http://arxiv.org/pdf/1412.7384v3.pdf | author:Peng Yang, Xiaoquan Su, Le Ou-Yang, Hon-Nian Chua, Xiao-Li Li, Kang Ning category:q-bio.QM cs.CE cs.LG q-bio.GN published:2014-12-21 summary:The human habitat is a host where microbial species evolve, function, andcontinue to evolve. Elucidating how microbial communities respond to humanhabitats is a fundamental and critical task, as establishing baselines of humanmicrobiome is essential in understanding its role in human disease and health.However, current studies usually overlook a complex and interconnectedlandscape of human microbiome and limit the ability in particular body habitatswith learning models of specific criterion. Therefore, these methods could notcapture the real-world underlying microbial patterns effectively. To obtain acomprehensive view, we propose a novel ensemble clustering framework to minethe structure of microbial community pattern on large-scale metagenomic data.Particularly, we first build a microbial similarity network via integrating1920 metagenomic samples from three body habitats of healthy adults. Then anovel symmetric Nonnegative Matrix Factorization (NMF) based ensemble model isproposed and applied onto the network to detect clustering pattern. Extensiveexperiments are conducted to evaluate the effectiveness of our model onderiving microbial community with respect to body habitat and host gender. Fromclustering results, we observed that body habitat exhibits a strong bound butnon-unique microbial structural patterns. Meanwhile, human microbiome revealsdifferent degree of structural variations over body habitat and host gender. Insummary, our ensemble clustering framework could efficiently explore integratedclustering results to accurately identify microbial communities, and provide acomprehensive view for a set of microbial communities. Such trends depict anintegrated biography of microbial communities, which offer a new insighttowards uncovering pathogenic model of human microbiome.
arxiv-9600-255 | Bi-directional Shape Correspondences (BSC): A Novel Technique for 2-d Shape Warping in Quadratic Time? | http://arxiv.org/pdf/1412.6759v1.pdf | author:Abdulrahman Oladipupo Ibraheem category:cs.CV published:2014-12-21 summary:We propose Bidirectional Shape Correspondence (BSC) as a possible improvementon the famous shape contexts (SC) framework. Our proposals derive from theobservation that the SC framework enforces a one-to-one correspondence betweensample points, and that this leads to two possible drawbacks. First, thisdenies the framework the opportunity to effect advantageous many-to-manymatching between points on the two shapes being compared. Second, this callsfor the Hungarian algorithm which unfortunately usurps cubic time. While thedynamic-space-warping dynamic programming algorithm has provided a standardsolution to the first problem above, it demands quintic time for generalmulti-contour shapes, and w times quadratic time for the special case ofsingle-contour shapes, even after an heuristic search window of width w hasbeen chosen. Therefore, in this work, we propose a simple method for computing"many-to-many" correspondences for the class of all 2-d shapes in quadratictime. Our approach is to explicitly let each point on the first shape choose abest match on the second shape, and vice versa. Along the way, we also proposethe use of data-clustering techniques for dealing with the outliers problem,and, from another viewpoint, it turns out that this clustering can be seen asan autonomous, rather than pre-computed, sampling of shape boundary.
arxiv-9600-256 | Principal Sensitivity Analysis | http://arxiv.org/pdf/1412.6785v2.pdf | author:Sotetsu Koyamada, Masanori Koyama, Ken Nakae, Shin Ishii category:stat.ML cs.LG published:2014-12-21 summary:We present a novel algorithm (Principal Sensitivity Analysis; PSA) to analyzethe knowledge of the classifier obtained from supervised machine learningtechniques. In particular, we define principal sensitivity map (PSM) as thedirection on the input space to which the trained classifier is most sensitive,and use analogously defined k-th PSM to define a basis for the input space. Wetrain neural networks with artificial data and real data, and apply thealgorithm to the obtained supervised classifiers. We then visualize the PSMs todemonstrate the PSA's ability to decompose the knowledge acquired by thetrained classifiers.
arxiv-9600-257 | Striving for Simplicity: The All Convolutional Net | http://arxiv.org/pdf/1412.6806v3.pdf | author:Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, Martin Riedmiller category:cs.LG cs.CV cs.NE published:2014-12-21 summary:Most modern convolutional neural networks (CNNs) used for object recognitionare built using the same principles: Alternating convolution and max-poolinglayers followed by a small number of fully connected layers. We re-evaluate thestate of the art for object recognition from small images with convolutionalnetworks, questioning the necessity of different components in the pipeline. Wefind that max-pooling can simply be replaced by a convolutional layer withincreased stride without loss in accuracy on several image recognitionbenchmarks. Following this finding -- and building on other recent work forfinding simple network structures -- we propose a new architecture thatconsists solely of convolutional layers and yields competitive or state of theart performance on several object recognition datasets (CIFAR-10, CIFAR-100,ImageNet). To analyze the network we introduce a new variant of the"deconvolution approach" for visualizing features learned by CNNs, which can beapplied to a broader range of network structures than existing approaches.
arxiv-9600-258 | Learning Activation Functions to Improve Deep Neural Networks | http://arxiv.org/pdf/1412.6830v3.pdf | author:Forest Agostinelli, Matthew Hoffman, Peter Sadowski, Pierre Baldi category:cs.NE cs.CV cs.LG stat.ML published:2014-12-21 summary:Artificial neural networks typically have a fixed, non-linear activationfunction at each neuron. We have designed a novel form of piecewise linearactivation function that is learned independently for each neuron usinggradient descent. With this adaptive activation function, we are able toimprove upon deep neural network architectures composed of static rectifiedlinear units, achieving state-of-the-art performance on CIFAR-10 (7.51%),CIFAR-100 (30.83%), and a benchmark from high-energy physics involving Higgsboson decay modes.
arxiv-9600-259 | Hot Swapping for Online Adaptation of Optimization Hyperparameters | http://arxiv.org/pdf/1412.6599v3.pdf | author:Kevin Bache, Dennis DeCoste, Padhraic Smyth category:cs.LG 62L20 G.1.6; I.2.6 published:2014-12-20 summary:We describe a general framework for online adaptation of optimizationhyperparameters by `hot swapping' their values during learning. We investigatethis approach in the context of adaptive learning rate selection using anexplore-exploit strategy from the multi-armed bandit literature. Experiments ona benchmark neural network show that the hot swapping approach leads toconsistently better solutions compared to well-known alternatives such asAdaDelta and stochastic gradient with exhaustive hyperparameter search.
arxiv-9600-260 | Explorations on high dimensional landscapes | http://arxiv.org/pdf/1412.6615v4.pdf | author:Levent Sagun, V. Ugur Guney, Gerard Ben Arous, Yann LeCun category:stat.ML cs.LG published:2014-12-20 summary:Finding minima of a real valued non-convex function over a high dimensionalspace is a major challenge in science. We provide evidence that some suchfunctions that are defined on high dimensional domains have a narrow band ofvalues whose pre-image contains the bulk of its critical points. This is incontrast with the low dimensional picture in which this band is wide. Oursimulations agree with the previous theoretical work on spin glasses thatproves the existence of such a band when the dimension of the domain tends toinfinity. Furthermore our experiments on teacher-student networks with theMNIST dataset establish a similar phenomenon in deep networks. We finallyobserve that both the gradient descent and the stochastic gradient descentmethods can reach this level within the same number of steps.
arxiv-9600-261 | Modeling Compositionality with Multiplicative Recurrent Neural Networks | http://arxiv.org/pdf/1412.6577v3.pdf | author:Ozan İrsoy, Claire Cardie category:cs.LG cs.CL stat.ML published:2014-12-20 summary:We present the multiplicative recurrent neural network as a general model forcompositional meaning in language, and evaluate it on the task of fine-grainedsentiment analysis. We establish a connection to the previously investigatedmatrix-space models for compositionality, and show they are special cases ofthe multiplicative recurrent net. Our experiments show that these modelsperform comparably or better than Elman-type additive recurrent neural networksand outperform matrix-space models on a standard fine-grained sentimentanalysis corpus. Furthermore, they yield comparable results to structural deepmodels on the recently published Stanford Sentiment Treebank without the needfor generating parse trees.
arxiv-9600-262 | Deep learning with Elastic Averaging SGD | http://arxiv.org/pdf/1412.6651v8.pdf | author:Sixin Zhang, Anna Choromanska, Yann LeCun category:cs.LG stat.ML published:2014-12-20 summary:We study the problem of stochastic optimization for deep learning in theparallel computing environment under communication constraints. A new algorithmis proposed in this setting where the communication and coordination of workamong concurrent processes (local workers), is based on an elastic force whichlinks the parameters they compute with a center variable stored by theparameter server (master). The algorithm enables the local workers to performmore exploration, i.e. the algorithm allows the local variables to fluctuatefurther from the center variable by reducing the amount of communicationbetween local workers and the master. We empirically demonstrate that in thedeep learning setting, due to the existence of many local optima, allowing moreexploration can lead to the improved performance. We propose synchronous andasynchronous variants of the new algorithm. We provide the stability analysisof the asynchronous variant in the round-robin scheme and compare it with themore common parallelized method ADMM. We show that the stability of EASGD isguaranteed when a simple stability condition is satisfied, which is not thecase for ADMM. We additionally propose the momentum-based version of ouralgorithm that can be applied in both synchronous and asynchronous settings.Asynchronous variant of the algorithm is applied to train convolutional neuralnetworks for image classification on the CIFAR and ImageNet datasets.Experiments demonstrate that the new algorithm accelerates the training of deeparchitectures compared to DOWNPOUR and other common baseline approaches andfurthermore is very communication efficient.
arxiv-9600-263 | Generative Modeling of Hidden Functional Brain Networks | http://arxiv.org/pdf/1412.6602v2.pdf | author:Shaurabh Nandy, Richard M. Golden category:stat.ML q-bio.NC published:2014-12-20 summary:Functional connectivity refers to the temporal statistical relationshipbetween spatially distinct brain regions and is usually inferred from the timeseries coherence/correlation in brain activity between regions of interest. Inhuman functional brain networks, the network structure is often inferred fromfunctional magnetic resonance imaging (fMRI) blood oxygen level dependent(BOLD) signal. Since the BOLD signal is a proxy for neuronal activity, it is ofinterest to learn the latent functional network structure. Additionally,despite a core set of observations about functional networks such assmall-worldness, modularity, exponentially truncated degree distributions, andpresence of various types of hubs, very little is known about the computationalprinciples which can give rise to these observations. This paper introduces aHidden Markov Random Field framework for the purpose of representing,estimating, and evaluating latent neuronal functional relationships betweendifferent brain regions using fMRI data.
arxiv-9600-264 | Embedding Entities and Relations for Learning and Inference in Knowledge Bases | http://arxiv.org/pdf/1412.6575v4.pdf | author:Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, Li Deng category:cs.CL published:2014-12-20 summary:We consider learning representations of entities and relations in KBs usingthe neural-embedding approach. We show that most existing models, including NTN(Socher et al., 2013) and TransE (Bordes et al., 2013b), can be generalizedunder a unified learning framework, where entities are low-dimensional vectorslearned from a neural network and relations are bilinear and/or linear mappingfunctions. Under this framework, we compare a variety of embedding models onthe link prediction task. We show that a simple bilinear formulation achievesnew state-of-the-art results for the task (achieving a top-10 accuracy of 73.2%vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approachthat utilizes the learned relation embeddings to mine logical rules such as"BornInCity(a,b) and CityInCountry(b,c) => Nationality(a,c)". We find thatembeddings learned from the bilinear objective are particularly good atcapturing relational semantics and that the composition of relations ischaracterized by matrix multiplication. More interestingly, we demonstrate thatour embedding-based rule extraction approach successfully outperforms astate-of-the-art confidence-based rule mining approach in mining Horn rulesthat involve compositional reasoning.
arxiv-9600-265 | Deep metric learning using Triplet network | http://arxiv.org/pdf/1412.6622v3.pdf | author:Elad Hoffer, Nir Ailon category:cs.LG cs.CV stat.ML published:2014-12-20 summary:Deep learning has proven itself as a successful set of models for learninguseful semantic representations of data. These, however, are mostly implicitlylearned as part of a classification task. In this paper we propose the tripletnetwork model, which aims to learn useful representations by distancecomparisons. A similar model was defined by Wang et al. (2014), tailor made forlearning a ranking for image information retrieval. Here we demonstrate usingvarious datasets that our model learns a better representation than that of itsimmediate competitor, the Siamese network. We also discuss future possibleusage as a framework for unsupervised learning.
arxiv-9600-266 | Training Deep Neural Networks on Noisy Labels with Bootstrapping | http://arxiv.org/pdf/1412.6596v3.pdf | author:Scott Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, Andrew Rabinovich category:cs.CV cs.LG cs.NE published:2014-12-20 summary:Current state-of-the-art deep learning systems for visual object recognitionand detection use purely supervised training with regularization such asdropout to avoid overfitting. The performance depends critically on the amountof labeled examples, and in current practice the labels are assumed to beunambiguous and accurate. However, this assumption often does not hold; e.g. inrecognition, class labels may be missing; in detection, objects in the imagemay not be localized; and in general, the labeling may be subjective. In thiswork we propose a generic way to handle noisy and incomplete labeling byaugmenting the prediction objective with a notion of consistency. We consider aprediction consistent if the same prediction is made given similar percepts,where the notion of similarity is between deep network features computed fromthe input data. In experiments we demonstrate that our approach yieldssubstantial robustness to label noise on several datasets. On MNIST handwrittendigits, we show that our model is robust to label corruption. On the TorontoFace Database, we show that our model handles well the case of subjectivelabels in emotion recognition, achieving state-of-the- art results, and canalso benefit from unlabeled face images with no modification to our method. Onthe ILSVRC2014 detection challenge data, we show that our approach extends tovery deep networks, high resolution images and structured outputs, and resultsin improved scalable detection.
arxiv-9600-267 | Move Evaluation in Go Using Deep Convolutional Neural Networks | http://arxiv.org/pdf/1412.6564v2.pdf | author:Chris J. Maddison, Aja Huang, Ilya Sutskever, David Silver category:cs.LG cs.NE published:2014-12-20 summary:The game of Go is more challenging than other board games, due to thedifficulty of constructing a position or move evaluation function. In thispaper we investigate whether deep convolutional networks can be used todirectly represent and learn this knowledge. We train a large 12-layerconvolutional neural network by supervised learning from a database of humanprofessional games. The network correctly predicts the expert move in 55% ofpositions, equalling the accuracy of a 6 dan human player. When the trainedconvolutional network was used directly to play games of Go, without anysearch, it beat the traditional search program GnuGo in 97% of games, andmatched the performance of a state-of-the-art Monte-Carlo tree search thatsimulates a million positions per move.
arxiv-9600-268 | Competing with the Empirical Risk Minimizer in a Single Pass | http://arxiv.org/pdf/1412.6606v2.pdf | author:Roy Frostig, Rong Ge, Sham M. Kakade, Aaron Sidford category:stat.ML cs.LG published:2014-12-20 summary:In many estimation problems, e.g. linear and logistic regression, we wish tominimize an unknown objective given only unbiased samples of the objectivefunction. Furthermore, we aim to achieve this using as few samples as possible.In the absence of computational constraints, the minimizer of a sample averageof observed data -- commonly referred to as either the empirical risk minimizer(ERM) or the $M$-estimator -- is widely regarded as the estimation strategy ofchoice due to its desirable statistical convergence properties. Our goal inthis work is to perform as well as the ERM, on every problem, while minimizingthe use of computational resources such as running time and space usage. We provide a simple streaming algorithm which, under standard regularityassumptions on the underlying problem, enjoys the following properties: * The algorithm can be implemented in linear time with a single pass of theobserved data, using space linear in the size of a single sample. * The algorithm achieves the same statistical rate of convergence as theempirical risk minimizer on every problem, even considering constant factors. * The algorithm's performance depends on the initial error at a rate thatdecreases super-polynomially. * The algorithm is easily parallelizable. Moreover, we quantify the (finite-sample) rate at which the algorithm becomescompetitive with the ERM.
arxiv-9600-269 | On the Robustness of Learning in Games with Stochastically Perturbed Payoff Observations | http://arxiv.org/pdf/1412.6565v1.pdf | author:Mario Bravo, Panayotis Mertikopoulos category:math.OC cs.GT math.PR stat.ML published:2014-12-20 summary:We study a general class of game-theoretic learning dynamics in the presenceof random payoff disturbances and observation noise, and we provide a unifiedframework that extends several rationality properties of the (stochastic)replicator dynamics and other game dynamics. In the unilateral case, we showthat the stochastic dynamics under study lead to no regret, irrespective of thenoise level. In the multi-player case, we find that dominated strategies becomeextinct (a.s.) and strict Nash equilibria remain stochastically asymptoticallystable - again, independently of the perturbations' magnitude. Finally, weestablish an averaging principle for 2-player games and we show that theempirical distribution of play converges to Nash equilibrium in zero-sum gamesunder any noise level.
arxiv-9600-270 | The local low-dimensionality of natural images | http://arxiv.org/pdf/1412.6626v4.pdf | author:Olivier J. Hénaff, Johannes Ballé, Neil C. Rabinowitz, Eero P. Simoncelli category:cs.CV published:2014-12-20 summary:We develop a new statistical model for photographic images, in which thelocal responses of a bank of linear filters are described as jointly Gaussian,with zero mean and a covariance that varies slowly over spatial position. Weoptimize sets of filters so as to minimize the nuclear norms of matrices oftheir local activations (i.e., the sum of the singular values), thusencouraging a flexible form of sparsity that is not tied to any particulardictionary or coordinate system. Filters optimized according to this objectiveare oriented and bandpass, and their responses exhibit substantial localcorrelation. We show that images can be reconstructed nearly perfectly fromestimates of the local filter response covariances alone, and with minimaldegradation (either visual or MSE) from low-rank approximations of thesecovariances. As such, this representation holds much promise for use inapplications such as denoising, compression, and texture representation, andmay form a useful substrate for hierarchical decompositions.
arxiv-9600-271 | Permutohedral Lattice CNNs | http://arxiv.org/pdf/1412.6618v3.pdf | author:Martin Kiefel, Varun Jampani, Peter V. Gehler category:cs.CV cs.LG cs.NE published:2014-12-20 summary:This paper presents a convolutional layer that is able to process sparseinput features. As an example, for image recognition problems this allows anefficient filtering of signals that do not lie on a dense grid (like pixelposition), but of more general features (such as color values). The presentedalgorithm makes use of the permutohedral lattice data structure. Thepermutohedral lattice was introduced to efficiently implement a bilateralfilter, a commonly used image processing operation. Its use allows for ageneralization of the convolution type found in current (spatial) convolutionalnetwork architectures.
arxiv-9600-272 | Self-informed neural network structure learning | http://arxiv.org/pdf/1412.6563v2.pdf | author:David Warde-Farley, Andrew Rabinovich, Dragomir Anguelov category:stat.ML cs.CV cs.LG cs.NE published:2014-12-20 summary:We study the problem of large scale, multi-label visual recognition with alarge number of possible classes. We propose a method for augmenting a trainedneural network classifier with auxiliary capacity in a manner designed tosignificantly improve upon an already well-performing model, while minimallyimpacting its computational footprint. Using the predictions of the networkitself as a descriptor for assessing visual similarity, we define apartitioning of the label space into groups of visually similar entities. Wethen augment the network with auxilliary hidden layer pathways withconnectivity only to these groups of label units. We report a significantimprovement in mean average precision on a large-scale object recognition taskwith the augmented model, while increasing the number of multiply-adds by lessthan 3%.
arxiv-9600-273 | Variational Recurrent Auto-Encoders | http://arxiv.org/pdf/1412.6581v6.pdf | author:Otto Fabius, Joost R. van Amersfoort category:stat.ML cs.LG cs.NE published:2014-12-20 summary:In this paper we propose a model that combines the strengths of RNNs andSGVB: the Variational Recurrent Auto-Encoder (VRAE). Such a model can be usedfor efficient, large scale unsupervised learning on time series data, mappingthe time series data to a latent vector representation. The model isgenerative, such that data can be generated from samples of the latent space.An important contribution of this work is that the model can make use ofunlabeled data in order to facilitate supervised training of RNNs byinitialising the weights and network state.
arxiv-9600-274 | Video (language) modeling: a baseline for generative models of natural videos | http://arxiv.org/pdf/1412.6604v5.pdf | author:MarcAurelio Ranzato, Arthur Szlam, Joan Bruna, Michael Mathieu, Ronan Collobert, Sumit Chopra category:cs.LG cs.CV published:2014-12-20 summary:We propose a strong baseline model for unsupervised feature learning usingvideo data. By learning to predict missing frames or extrapolate future framesfrom an input video sequence, the model discovers both spatial and temporalcorrelations which are useful to represent complex deformations and motionpatterns. The models we propose are largely borrowed from the language modelingliterature, and adapted to the vision domain by quantizing the space of imagepatches into a large dictionary. We demonstrate the approach on both a fillingand a generation task. For the first time, we show that, after training onnatural videos, such a model can predict non-trivial motions over short videosequences.
arxiv-9600-275 | Neural Network Regularization via Robust Weight Factorization | http://arxiv.org/pdf/1412.6630v2.pdf | author:Jan Rudy, Weiguang Ding, Daniel Jiwoong Im, Graham W. Taylor category:cs.LG cs.NE stat.ML published:2014-12-20 summary:Regularization is essential when training large neural networks. As deepneural networks can be mathematically interpreted as universal functionapproximators, they are effective at memorizing sampling noise in the trainingdata. This results in poor generalization to unseen data. Therefore, it is nosurprise that a new regularization technique, Dropout, was partiallyresponsible for the now-ubiquitous winning entry to ImageNet 2012 by theUniversity of Toronto. Currently, Dropout (and related methods such asDropConnect) are the most effective means of regularizing large neuralnetworks. These amount to efficiently visiting a large number of related modelsat training time, while aggregating them to a single predictor at test time.The proposed FaMe model aims to apply a similar strategy, yet learns afactorization of each weight matrix such that the factors are robust to noise.
arxiv-9600-276 | Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN) | http://arxiv.org/pdf/1412.6632v5.pdf | author:Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, Alan Yuille category:cs.CV cs.CL cs.LG published:2014-12-20 summary:In this paper, we present a multimodal Recurrent Neural Network (m-RNN) modelfor generating novel image captions. It directly models the probabilitydistribution of generating a word given previous words and an image. Imagecaptions are generated by sampling from this distribution. The model consistsof two sub-networks: a deep recurrent neural network for sentences and a deepconvolutional network for images. These two sub-networks interact with eachother in a multimodal layer to form the whole m-RNN model. The effectiveness ofour model is validated on four benchmark datasets (IAPR TC-12, Flickr 8K,Flickr 30K and MS COCO). Our model outperforms the state-of-the-art methods. Inaddition, we apply the m-RNN model to retrieval tasks for retrieving images orsentences, and achieves significant performance improvement over thestate-of-the-art methods which directly optimize the ranking objective functionfor retrieval. The project page of this work is:www.stat.ucla.edu/~junhua.mao/m-RNN.html .
arxiv-9600-277 | Understanding Minimum Probability Flow for RBMs Under Various Kinds of Dynamics | http://arxiv.org/pdf/1412.6617v6.pdf | author:Daniel Jiwoong Im, Ethan Buchman, Graham W. Taylor category:cs.LG published:2014-12-20 summary:Energy-based models are popular in machine learning due to the elegance oftheir formulation and their relationship to statistical physics. Among these,the Restricted Boltzmann Machine (RBM), and its staple training algorithmcontrastive divergence (CD), have been the prototype for some recentadvancements in the unsupervised training of deep neural networks. However, CDhas limited theoretical motivation, and can in some cases produce undesirablebehavior. Here, we investigate the performance of Minimum Probability Flow(MPF) learning for training RBMs. Unlike CD, with its focus on approximating anintractable partition function via Gibbs sampling, MPF proposes a tractable,consistent, objective function defined in terms of a Taylor expansion of the KLdivergence with respect to sampling dynamics. Here we propose a more generalform for the sampling dynamics in MPF, and explore the consequences ofdifferent choices for these dynamics for training RBMs. Experimental resultsshow MPF outperforming CD for various RBM configurations.
arxiv-9600-278 | Scoring and Classifying with Gated Auto-encoders | http://arxiv.org/pdf/1412.6610v5.pdf | author:Daniel Jiwoong Im, Graham W. Taylor category:cs.LG cs.NE published:2014-12-20 summary:Auto-encoders are perhaps the best-known non-probabilistic methods forrepresentation learning. They are conceptually simple and easy to train. Recenttheoretical work has shed light on their ability to capture manifold structure,and drawn connections to density modelling. This has motivated researchers toseek ways of auto-encoder scoring, which has furthered their use inclassification. Gated auto-encoders (GAEs) are an interesting and flexibleextension of auto-encoders which can learn transformations among differentimages or pixel covariances within images. However, they have been much lessstudied, theoretically or empirically. In this work, we apply a dynamicalsystems view to GAEs, deriving a scoring function, and drawing connections toRestricted Boltzmann Machines. On a set of deep learning benchmarks, we alsodemonstrate their effectiveness for single and multi-label classification.
arxiv-9600-279 | Visual Instance Retrieval with Deep Convolutional Networks | http://arxiv.org/pdf/1412.6574v4.pdf | author:Ali Sharif Razavian, Josephine Sullivan, Stefan Carlsson, Atsuto Maki category:cs.CV published:2014-12-20 summary:This paper provides an extensive study on the availability of imagerepresentations based on convolutional networks (ConvNets) for the task ofvisual instance retrieval. Besides the choice of convolutional layers, wepresent an efficient pipeline exploiting multi-scale schemes to extract localfeatures, in particular, by taking geometric invariance into explicit account,i.e. positions, scales and spatial consistency. In our experiments using fivestandard image retrieval datasets, we demonstrate that generic ConvNet imagerepresentations can outperform other state-of-the-art methods if they areextracted appropriately.
arxiv-9600-280 | Incremental Adaptation Strategies for Neural Network Language Models | http://arxiv.org/pdf/1412.6650v4.pdf | author:Aram Ter-Sarkisov, Holger Schwenk, Loic Barrault, Fethi Bougares category:cs.NE cs.CL cs.LG published:2014-12-20 summary:It is today acknowledged that neural network language models outperformbackoff language models in applications like speech recognition or statisticalmachine translation. However, training these models on large amounts of datacan take several days. We present efficient techniques to adapt a neuralnetwork language model to new data. Instead of training a completely new modelor relying on mixture approaches, we propose two new methods: continuedtraining on resampled data or insertion of adaptation layers. We presentexperimental results in an CAT environment where the post-edits of professionaltranslators are used to improve an SMT system. Both methods are very fast andachieve significant improvements without overfitting the small adaptation data.
arxiv-9600-281 | Automatic Discovery and Optimization of Parts for Image Classification | http://arxiv.org/pdf/1412.6598v2.pdf | author:Sobhan Naderi Parizi, Andrea Vedaldi, Andrew Zisserman, Pedro Felzenszwalb category:cs.CV cs.LG published:2014-12-20 summary:Part-based representations have been shown to be very useful for imageclassification. Learning part-based models is often viewed as a two-stageproblem. First, a collection of informative parts is discovered, usingheuristics that promote part distinctiveness and diversity, and thenclassifiers are trained on the vector of part responses. In this paper we unifythe two stages and learn the image classifiers and a set of shared partsjointly. We generate an initial pool of parts by randomly sampling partcandidates and selecting a good subset using L1/L2 regularization. All stepsare driven "directly" by the same objective namely the classification loss on atraining set. This lets us do away with engineered heuristics. We alsointroduce the notion of "negative parts", intended as parts that are negativelycorrelated with one or more classes. Negative parts are complementary to theparts discovered by other methods, which look only for positive correlations.
arxiv-9600-282 | Word Representations via Gaussian Embedding | http://arxiv.org/pdf/1412.6623v4.pdf | author:Luke Vilnis, Andrew McCallum category:cs.CL cs.LG published:2014-12-20 summary:Current work in lexical distributed representations maps each word to a pointvector in low-dimensional space. Mapping instead to a density provides manyinteresting advantages, including better capturing uncertainty about arepresentation and its relationships, expressing asymmetries more naturallythan dot product or cosine similarity, and enabling more expressiveparameterization of decision boundaries. This paper advocates for density-baseddistributed embeddings and presents a method for learning representations inthe space of Gaussian distributions. We compare performance on various wordembedding benchmarks, investigate the ability of these embeddings to modelentailment and other asymmetric relationships, and explore novel properties ofthe representation.
arxiv-9600-283 | Explaining and Harnessing Adversarial Examples | http://arxiv.org/pdf/1412.6572v3.pdf | author:Ian J. Goodfellow, Jonathon Shlens, Christian Szegedy category:stat.ML cs.LG published:2014-12-20 summary:Several machine learning models, including neural networks, consistentlymisclassify adversarial examples---inputs formed by applying small butintentionally worst-case perturbations to examples from the dataset, such thatthe perturbed input results in the model outputting an incorrect answer withhigh confidence. Early attempts at explaining this phenomenon focused onnonlinearity and overfitting. We argue instead that the primary cause of neuralnetworks' vulnerability to adversarial perturbation is their linear nature.This explanation is supported by new quantitative results while giving thefirst explanation of the most intriguing fact about them: their generalizationacross architectures and training sets. Moreover, this view yields a simple andfast method of generating adversarial examples. Using this approach to provideexamples for adversarial training, we reduce the test set error of a maxoutnetwork on the MNIST dataset.
arxiv-9600-284 | An Analysis of Unsupervised Pre-training in Light of Recent Advances | http://arxiv.org/pdf/1412.6597v4.pdf | author:Tom Le Paine, Pooya Khorrami, Wei Han, Thomas S. Huang category:cs.CV cs.LG cs.NE published:2014-12-20 summary:Convolutional neural networks perform well on object recognition because of anumber of recent advances: rectified linear units (ReLUs), data augmentation,dropout, and large labelled datasets. Unsupervised data has been proposed asanother way to improve performance. Unfortunately, unsupervised pre-training isnot used by state-of-the-art methods leading to the following question: Isunsupervised pre-training still useful given recent advances? If so, when? Weanswer this in three parts: we 1) develop an unsupervised method thatincorporates ReLUs and recent unsupervised regularization techniques, 2)analyze the benefits of unsupervised pre-training compared to data augmentationand dropout on CIFAR-10 while varying the ratio of unsupervised to supervisedsamples, 3) verify our findings on STL-10. We discover unsupervisedpre-training, as expected, helps when the ratio of unsupervised to supervisedsamples is high, and surprisingly, hurts when the ratio is low. We also useunsupervised pre-training with additional color augmentation to achieve nearstate-of-the-art performance on STL-10.
arxiv-9600-285 | Outperforming Word2Vec on Analogy Tasks with Random Projections | http://arxiv.org/pdf/1412.6616v2.pdf | author:Abram Demski, Volkan Ustun, Paul Rosenbloom, Cody Kommers category:cs.CL cs.LG published:2014-12-20 summary:We present a distributed vector representation based on a simplification ofthe BEAGLE system, designed in the context of the Sigma cognitive architecture.Our method does not require gradient-based training of neural networks, matrixdecompositions as with LSA, or convolutions as with BEAGLE. All that isinvolved is a sum of random vectors and their pointwise products. Despite thesimplicity of this technique, it gives state-of-the-art results on analogyproblems, in most cases better than Word2Vec. To explain this success, weinterpret it as a dimension reduction via random projection.
arxiv-9600-286 | A deep-structured fully-connected random field model for structured inference | http://arxiv.org/pdf/1412.6586v3.pdf | author:Alexander Wong, Mohammad Javad Shafiee, Parthipan Siva, Xiao Yu Wang category:stat.ML cs.IT cs.LG math.IT stat.ME published:2014-12-20 summary:There has been significant interest in the use of fully-connected graphicalmodels and deep-structured graphical models for the purpose of structuredinference. However, fully-connected and deep-structured graphical models havebeen largely explored independently, leaving the unification of these twoconcepts ripe for exploration. A fundamental challenge with unifying these twotypes of models is in dealing with computational complexity. In this study, weinvestigate the feasibility of unifying fully-connected and deep-structuredmodels in a computationally tractable manner for the purpose of structuredinference. To accomplish this, we introduce a deep-structured fully-connectedrandom field (DFRF) model that integrates a series of intermediate sparseauto-encoding layers placed between state layers to significantly reducecomputational complexity. The problem of image segmentation was used toillustrate the feasibility of using the DFRF for structured inference in acomputationally tractable manner. Results in this study show that it isfeasible to unify fully-connected and deep-structured models in acomputationally tractable manner for solving structured inference problems suchas image segmentation.
arxiv-9600-287 | Using Neural Networks for Click Prediction of Sponsored Search | http://arxiv.org/pdf/1412.6601v3.pdf | author:Afroze Ibrahim Baqapuri, Ilya Trofimov category:cs.LG cs.NE published:2014-12-20 summary:Sponsored search is a multi-billion dollar industry and makes up a majorsource of revenue for search engines (SE). click-through-rate (CTR) estimationplays a crucial role for ads selection, and greatly affects the SE revenue,advertiser traffic and user experience. We propose a novel architecture forsolving CTR prediction problem by combining artificial neural networks (ANN)with decision trees. First we compare ANN with respect to other popular machinelearning models being used for this task. Then we go on to combine ANN withMatrixNet (proprietary implementation of boosted trees) and evaluate theperformance of the system as a whole. The results show that our approachprovides significant improvement over existing models.
arxiv-9600-288 | Weakly Supervised Multi-Embeddings Learning of Acoustic Models | http://arxiv.org/pdf/1412.6645v3.pdf | author:Gabriel Synnaeve, Emmanuel Dupoux category:cs.SD cs.CL cs.LG published:2014-12-20 summary:We trained a Siamese network with multi-task same/different information on aspeech dataset, and found that it was possible to share a network for bothtasks without a loss in performance. The first task was to discriminate betweentwo same or different words, and the second was to discriminate between twosame or different talkers.
arxiv-9600-289 | Discovering Hidden Factors of Variation in Deep Networks | http://arxiv.org/pdf/1412.6583v4.pdf | author:Brian Cheung, Jesse A. Livezey, Arjun K. Bansal, Bruno A. Olshausen category:cs.LG cs.CV cs.NE published:2014-12-20 summary:Deep learning has enjoyed a great deal of success because of its ability tolearn useful features for tasks such as classification. But there has been lessexploration in learning the factors of variation apart from the classificationsignal. By augmenting autoencoders with simple regularization terms duringtraining, we demonstrate that standard deep architectures can discover andexplicitly represent factors of variation beyond those relevant forcategorization. We introduce a cross-covariance penalty (XCov) as a method todisentangle factors like handwriting style for digits and subject identity infaces. We demonstrate this on the MNIST handwritten digit database, the TorontoFaces Database (TFD) and the Multi-PIE dataset by generating manipulatedinstances of the data. Furthermore, we demonstrate these deep networks canextrapolate `hidden' variation in the supervised signal.
arxiv-9600-290 | Classifier with Hierarchical Topographical Maps as Internal Representation | http://arxiv.org/pdf/1412.6567v4.pdf | author:Thomas Trappenberg, Paul Hollensen, Pitoyo Hartono category:cs.NE published:2014-12-20 summary:In this study we want to connect our previously proposed context-relevanttopographical maps with the deep learning community. Our architecture is aclassifier with hidden layers that are hierarchical two-dimensionaltopographical maps. These maps differ from the conventional self-organizingmaps in that their organizations are influenced by the context of the datalabels in a top-down manner. In this way bottom-up and top-down learning arecombined in a biologically relevant representational learning setting. Comparedto our previous work, we are here specifically elaborating the model in a morechallenging setting compared to our previous experiments and to advance morehidden representation layers to bring our discussions into the context of deeprepresentational learning.
arxiv-9600-291 | Visual Scene Representations: Contrast, Scaling and Occlusion | http://arxiv.org/pdf/1412.6607v5.pdf | author:Stefano Soatto, Jingming Dong, Nikolaos Karianakis category:cs.CV published:2014-12-20 summary:We study the structure of representations, defined as approximations ofminimal sufficient statistics that are maximal invariants to nuisance factors,for visual data subject to scaling and occlusion of line-of-sight. We deriveanalytical expressions for such representations and show that, under certainrestrictive assumptions, they are related to features commonly in use in thecomputer vision community. This link highlights the condition tacitly assumedby these descriptors, and also suggests ways to improve and generalize them.This new interpretation draws connections to the classical theories ofsampling, hypothesis testing and group invariance.
arxiv-9600-292 | Why does Deep Learning work? - A perspective from Group Theory | http://arxiv.org/pdf/1412.6621v3.pdf | author:Arnab Paul, Suresh Venkatasubramanian category:cs.LG cs.NE stat.ML published:2014-12-20 summary:Why does Deep Learning work? What representations does it capture? How dohigher-order representations emerge? We study these questions from theperspective of group theory, thereby opening a new approach towards a theory ofDeep learning. One factor behind the recent resurgence of the subject is a key algorithmicstep called pre-training: first search for a good generative model for theinput samples, and repeat the process one layer at a time. We show deeperimplications of this simple principle, by establishing a connection with theinterplay of orbits and stabilizers of group actions. Although the neuralnetworks themselves may not form groups, we show the existence of {\em shadow}groups whose elements serve as close approximations. Over the shadow groups, the pre-training step, originally introduced as amechanism to better initialize a network, becomes equivalent to a search forfeatures with minimal orbits. Intuitively, these features are in a way the {\emsimplest}. Which explains why a deep learning network learns simple featuresfirst. Next, we show how the same principle, when repeated in the deeperlayers, can capture higher order representations, and why representationcomplexity increases as the layers get deeper.
arxiv-9600-293 | Visualizing and Comparing Convolutional Neural Networks | http://arxiv.org/pdf/1412.6631v2.pdf | author:Wei Yu, Kuiyuan Yang, Yalong Bai, Hongxun Yao, Yong Rui category:cs.CV published:2014-12-20 summary:Convolutional Neural Networks (CNNs) have achieved comparable error rates towell-trained human on ILSVRC2014 image classification task. To achieve betterperformance, the complexity of CNNs is continually increasing with deeper andbigger architectures. Though CNNs achieved promising external classificationbehavior, understanding of their internal work mechanism is still limited. Inthis work, we attempt to understand the internal work mechanism of CNNs byprobing the internal representations in two comprehensive aspects, i.e.,visualizing patches in the representation spaces constructed by differentlayers, and visualizing visual information kept in each layer. We furthercompare CNNs with different depths and show the advantages brought by deeperarchitecture.
arxiv-9600-294 | The Vapnik-Chervonenkis Dimension of Norms on $\mathbb{R}^d$ | http://arxiv.org/pdf/1412.6612v2.pdf | author:Christian J. J. Despres category:math.CO math.MG stat.ML published:2014-12-20 summary:The Vapnik-Chervonenkis dimension of a collection of subsets of a set is animportant combinatorial parameter in machine learning. In this paper we showthat the VC dimension of the family of d-dimensional cubes in $\mathbb{R}^d$(that is, the closed balls according to the $\ell^\infty$ norm) is $\lfloor(3d+1)/2 \rfloor$. We also prove that the VC dimension of certain families ofconvex sets in $\mathbb{R}^2$ (including the balls of all norms) is at most 3,and that there is a norm in $\mathbb{R}^3$ the collection of whose balls hasinfinite VC dimension.
arxiv-9600-295 | In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning | http://arxiv.org/pdf/1412.6614v4.pdf | author:Behnam Neyshabur, Ryota Tomioka, Nathan Srebro category:cs.LG cs.AI cs.CV stat.ML published:2014-12-20 summary:We present experiments demonstrating that some other form of capacitycontrol, different from network size, plays a central role in learningmultilayer feed-forward networks. We argue, partially through analogy to matrixfactorization, that this is an inductive bias that can help shed light on deeplearning.
arxiv-9600-296 | Improving zero-shot learning by mitigating the hubness problem | http://arxiv.org/pdf/1412.6568v3.pdf | author:Georgiana Dinu, Angeliki Lazaridou, Marco Baroni category:cs.CL cs.LG published:2014-12-20 summary:The zero-shot paradigm exploits vector-based word representations extractedfrom text corpora with unsupervised methods to learn general mapping functionsfrom other feature spaces onto word space, where the words associated to thenearest neighbours of the mapped vectors are used as their linguistic labels.We show that the neighbourhoods of the mapped elements are strongly polluted byhubs, vectors that tend to be near a high proportion of items, pushing theircorrect labels down the neighbour list. After illustrating the problemempirically, we propose a simple method to correct it by taking the proximitydistribution of potential neighbours across many mapped vectors into account.We show that this correction leads to consistent improvements in realisticzero-shot experiments in the cross-lingual, image labeling and image retrievaldomains.
arxiv-9600-297 | Leveraging Monolingual Data for Crosslingual Compositional Word Representations | http://arxiv.org/pdf/1412.6334v4.pdf | author:Hubert Soyer, Pontus Stenetorp, Akiko Aizawa category:cs.CL published:2014-12-19 summary:In this work, we present a novel neural network based architecture forinducing compositional crosslingual word representations. Unlike previouslyproposed methods, our method fulfills the following three criteria; itconstrains the word-level representations to be compositional, it is capable ofleveraging both bilingual and monolingual data, and it is scalable to largevocabularies and large quantities of data. The key component of our approach iswhat we refer to as a monolingual inclusion criterion, that exploits theobservation that phrases are more closely semantically related to theirsub-phrases than to other randomly sampled phrases. We evaluate our method on awell-established crosslingual document classification task and achieve resultsthat are either comparable, or greatly improve upon previous state-of-the-artmethods. Concretely, our method reaches a level of 92.7% and 84.4% accuracy forthe English to German and German to English sub-tasks respectively. The formeradvances the state of the art by 0.9% points of accuracy, the latter is anabsolute improvement upon the previous state of the art by 7.7% points ofaccuracy and an improvement of 33.0% in error reduction.
arxiv-9600-298 | Fast Label Embeddings via Randomized Linear Algebra | http://arxiv.org/pdf/1412.6547v7.pdf | author:Paul Mineiro, Nikos Karampatziakis category:cs.LG published:2014-12-19 summary:Many modern multiclass and multilabel problems are characterized byincreasingly large output spaces. For these problems, label embeddings havebeen shown to be a useful primitive that can improve computational andstatistical efficiency. In this work we utilize a correspondence between rankconstrained estimation and low dimensional label embeddings that uncovers afast label embedding algorithm which works in both the multiclass andmultilabel settings. The result is a randomized algorithm whose running time isexponentially faster than naive algorithms. We demonstrate our techniques ontwo large-scale public datasets, from the Large Scale Hierarchical TextChallenge and the Open Directory Project, where we obtain state of the artresults.
arxiv-9600-299 | Qualitatively characterizing neural network optimization problems | http://arxiv.org/pdf/1412.6544v6.pdf | author:Ian J. Goodfellow, Oriol Vinyals, Andrew M. Saxe category:cs.NE cs.LG stat.ML published:2014-12-19 summary:Training neural networks involves solving large-scale non-convex optimizationproblems. This task has long been believed to be extremely difficult, with fearof local minima and other obstacles motivating a variety of schemes to improveoptimization, such as unsupervised pretraining. However, modern neural networksare able to achieve negligible training error on complex tasks, using onlydirect training with stochastic gradient descent. We introduce a simpleanalysis technique to look for evidence that such networks are overcoming localoptima. We find that, in fact, on a straight path from initialization tosolution, a variety of state of the art neural networks never encounter anysignificant obstacles.
arxiv-9600-300 | Algorithmic Robustness for Learning via $(ε, γ, τ)$-Good Similarity Functions | http://arxiv.org/pdf/1412.6452v3.pdf | author:Maria-Irina Nicolae, Marc Sebban, Amaury Habrard, Éric Gaussier, Massih-Reza Amini category:cs.LG published:2014-12-19 summary:The notion of metric plays a key role in machine learning problems such asclassification, clustering or ranking. However, it is worth noting that thereis a severe lack of theoretical guarantees that can be expected on thegeneralization capacity of the classifier associated to a given metric. Thetheoretical framework of $(\epsilon, \gamma, \tau)$-good similarity functions(Balcan et al., 2008) has been one of the first attempts to draw a link betweenthe properties of a similarity function and those of a linear classifier makinguse of it. In this paper, we extend and complete this theory by providing a newgeneralization bound for the associated classifier based on the algorithmicrobustness framework.
