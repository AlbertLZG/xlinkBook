arxiv-12600-1 | Learning in Unlabeled Networks - An Active Learning and Inference Approach | http://arxiv.org/pdf/1510.01270v1.pdf | author:Tomasz Kajdanowicz, Radosław Michalski, Katarzyna Musiał, Przemysław Kazienko category:stat.ML cs.LG cs.SI published:2015-10-05 summary:The task of determining labels of all network nodes based on the knowledgeabout network structure and labels of some training subset of nodes is calledthe within-network classification. It may happen that none of the labels of thenodes is known and additionally there is no information about number of classesto which nodes can be assigned. In such a case a subset of nodes has to beselected for initial label acquisition. The question that arises is: "labels ofwhich nodes should be collected and used for learning in order to provide thebest classification accuracy for the whole network?". Active learning andinference is a practical framework to study this problem. A set of methods for active learning and inference for within networkclassification is proposed and validated. The utility score calculation foreach node based on network structure is the first step in the process. Thescores enable to rank the nodes. Based on the ranking, a set of nodes, forwhich the labels are acquired, is selected (e.g. by taking top or bottom N fromthe ranking). The new measure-neighbour methods proposed in the paper suggestnot obtaining labels of nodes from the ranking but rather acquiring labels oftheir neighbours. The paper examines 29 distinct formulations of utility scoreand selection methods reporting their impact on the results of two collectiveclassification algorithms: Iterative Classification Algorithm and Loopy BeliefPropagation. We advocate that the accuracy of presented methods depends on the structuralproperties of the examined network. We claim that measure-neighbour methodswill work better than the regular methods for networks with higher clusteringcoefficient and worse than regular methods for networks with low clusteringcoefficient. According to our hypothesis, based on clustering coefficient weare able to recommend appropriate active learning and inference method.
arxiv-12600-2 | Efficient Object Detection for High Resolution Images | http://arxiv.org/pdf/1510.01257v1.pdf | author:Yongxi Lu, Tara Javidi category:cs.CV published:2015-10-05 summary:Efficient generation of high-quality object proposals is an essential step instate-of-the-art object detection systems based on deep convolutional neuralnetworks (DCNN) features. Current object proposal algorithms arecomputationally inefficient in processing high resolution images containingsmall objects, which makes them the bottleneck in object detection systems. Inthis paper we present effective methods to detect objects for high resolutionimages. We combine two complementary strategies. The first approach is topredict bounding boxes based on adjacent visual features. The second approachuses high level image features to guide a two-step search process thatadaptively focuses on regions that are likely to contain small objects. Weextract features required for the two strategies by utilizing a pre-trainedDCNN model known as AlexNet. We demonstrate the effectiveness of our algorithmby showing its performance on a high-resolution image subset of the SUN 2012object detection dataset.
arxiv-12600-3 | Bayesian Inference via Approximation of Log-likelihood for Priors in Exponential Family | http://arxiv.org/pdf/1510.01225v1.pdf | author:Tohid Ardeshiri, Umut Orguner, Fredrik Gustafsson category:cs.LG stat.ML published:2015-10-05 summary:In this paper, a Bayesian inference technique based on Taylor seriesapproximation of the logarithm of the likelihood function is presented. Theproposed approximation is devised for the case, where the prior distributionbelongs to the exponential family of distributions. The logarithm of thelikelihood function is linearized with respect to the sufficient statistic ofthe prior distribution in exponential family such that the posterior obtainsthe same exponential family form as the prior. Similarities between theproposed method and the extended Kalman filter for nonlinear filtering areillustrated. Furthermore, an extended target measurement update for targetmodels where the target extent is represented by a random matrix having aninverse Wishart distribution is derived. The approximate update covers theimportant case where the spread of measurement is due to the target extent aswell as the measurement noise in the sensor.
arxiv-12600-4 | Cross-Device Tracking: Matching Devices and Cookies | http://arxiv.org/pdf/1510.01175v1.pdf | author:Roberto Díaz-Morales category:cs.LG cs.CY published:2015-10-05 summary:The number of computers, tablets and smartphones is increasing rapidly, whichentails the ownership and use of multiple devices to perform online tasks. Aspeople move across devices to complete these tasks, their identities becomesfragmented. Understanding the usage and transition between those devices isessential to develop efficient applications in a multi-device world. In thispaper we present a solution to deal with the cross-device identification ofusers based on semi-supervised machine learning methods to identify whichcookies belong to an individual using a device. The method proposed in thispaper scored third in the ICDM 2015 Drawbridge Cross-Device Connectionschallenge proving its good performance.
arxiv-12600-5 | Convergence Analysis of a Stochastic Projection-free Algorithm | http://arxiv.org/pdf/1510.01171v1.pdf | author:Jean Lafond, Hoi-To Wai, Eric Moulines category:stat.ML cs.LG published:2015-10-05 summary:This paper presents and analyzes a stochastic version of the Frank-Wolfealgorithm (a.k.a. conditional gradient method or projection-free algorithm) forconstrained convex optimization. We first prove that when the quality ofgradient estimate improves as ${\cal O}( \sqrt{ \eta_t^{\Delta} / t } )$, where$t$ is the iteration index and $\eta_t^{\Delta}$ is an increasing sequence,then the objective value of the stochastic Frank-Wolfe algorithm converges inat least the same order. When the optimal solution lies in the interior of theconstraint set, the convergence rate is accelerated to ${\calO}(\eta_t^{\Delta} /t)$. Secondly, we study how the stochastic Frank-Wolfealgorithm can be applied to a few practical machine learning problems. Tightbounds on the gradient estimate errors for these examples are established.Numerical simulations support our findings.
arxiv-12600-6 | Significance of the levels of spectral valleys with application to front/back distinction of vowel sounds | http://arxiv.org/pdf/1506.04828v2.pdf | author:T. V. Ananthapadmanabha, A. G. Ramakrishnan, Shubham Sharma category:cs.CL cs.SD published:2015-06-16 summary:An objective critical distance (OCD) has been defined as that spacing betweenadjacent formants, when the level of the valley between them reaches the meanspectral level. The measured OCD lies in the same range (viz., 3-3.5 bark) asthe critical distance determined by subjective experiments for similarexperimental conditions. The level of spectral valley serves a purpose similarto that of the spacing between the formants with an added advantage that it canbe measured from the spectral envelope without an explicit knowledge of formantfrequencies. Based on the relative spacing of formant frequencies, the level ofthe spectral valley, VI (between F1 and F2) is much higher than the level ofVII (spectral valley between F2 and F3) for back vowels and vice-versa forfront vowels. Classification of vowels into front/back distinction with thedifference (VI-VII) as an acoustic feature, tested using TIMIT, NTIMIT, Tamiland Kannada language databases gives, on the average, an accuracy of about 95%,which is comparable to the accuracy (90.6%) obtained using a neural networkclassifier trained and tested using MFCC as the feature vector for TIMITdatabase. The acoustic feature (VI-VII) has also been tested for its robustnesson the TIMIT database for additive white and babble noise and an accuracy ofabout 95% has been obtained for SNRs down to 25 dB for both types of noise.
arxiv-12600-7 | Bregman Iteration for Correspondence Problems: A Study of Optical Flow | http://arxiv.org/pdf/1510.01130v1.pdf | author:Laurent Hoeltgen, Michael Breuß category:math.OC cs.CV 65Kxx, 65Nxx published:2015-10-05 summary:Bregman iterations are known to yield excellent results for denoising,deblurring and compressed sensing tasks, but so far this technique has rarelybeen used for other image processing problems. In this paper we give a thoroughdescription of the Bregman iteration, unifying thereby results of differentauthors within a common framework. Then we show how to adapt the split Bregmaniteration, originally developed by Goldstein and Osher for image restorationpurposes, to optical flow which is a fundamental correspondence problem incomputer vision. We consider some classic and modern optical flow models andpresent detailed algorithms that exhibit the benefits of the Bregman iteration.By making use of the results of the Bregman framework, we address the issues ofconvergence and error estimation for the algorithms. Numerical examplescomplement the theoretical part.
arxiv-12600-8 | Nonlinear Spectral Analysis via One-homogeneous Functionals - Overview and Future Prospects | http://arxiv.org/pdf/1510.01077v1.pdf | author:Guy Gilboa, Michael Moeller, Martin Burger category:math.SP cs.CV cs.NA math.NA published:2015-10-05 summary:We present in this paper the motivation and theory of nonlinear spectralrepresentations, based on convex regularizing functionals. Some comparisons andanalogies are drawn to the fields of signal processing, harmonic analysis andsparse representations. The basic approach, main results and initialapplications are shown. A discussion of open problems and future directionsconcludes this work.
arxiv-12600-9 | Boosting in the presence of outliers: adaptive classification with non-convex loss functions | http://arxiv.org/pdf/1510.01064v1.pdf | author:Alexander Hanbo Li, Jelena Bradic category:stat.ML cs.LG math.ST stat.TH published:2015-10-05 summary:This paper examines the role and efficiency of the non-convex loss functionsfor binary classification problems. In particular, we investigate how to designa simple and effective boosting algorithm that is robust to the outliers in thedata. The analysis of the role of a particular non-convex loss for predictionaccuracy varies depending on the diminishing tail properties of the gradient ofthe loss -- the ability of the loss to efficiently adapt to the outlying data,the local convex properties of the loss and the proportion of the contaminateddata. In order to use these properties efficiently, we propose a new family ofnon-convex losses named $\gamma$-robust losses. Moreover, we present a newboosting framework, {\it Arch Boost}, designed for augmenting the existing worksuch that its corresponding classification algorithm is significantly moreadaptable to the unknown data contamination. Along with the Arch Boostingframework, the non-convex losses lead to the new class of boosting algorithms,named adaptive, robust, boosting (ARB). Furthermore, we present theoreticalexamples that demonstrate the robustness properties of the proposed algorithms.In particular, we develop a new breakdown point analysis and a new influencefunction analysis that demonstrate gains in robustness. Moreover, we presentnew theoretical results, based only on local curvatures, which may be used toestablish statistical and optimization properties of the proposed Arch boostingalgorithms with highly non-convex loss functions. Extensive numericalcalculations are used to illustrate these theoretical properties and revealadvantages over the existing boosting methods when data exhibits a number ofoutliers.
arxiv-12600-10 | Stochastic Texture Difference for Scale-Dependent Data Analysis | http://arxiv.org/pdf/1503.03278v3.pdf | author:Nicolas Brodu, Hussein Yahia category:cs.CV published:2015-03-11 summary:This article introduces the Stochastic Texture Difference method foranalyzing data at prescribed spatial and value scales. This method relies onconstrained random walks around each pixel, describing how nearby image valuestypically evolve on each side of this pixel. Textures are represented asprobability distributions of such random walks, so a texture differenceoperator is statistically defined as a distance between these distributions ina suitable reproducing kernel Hilbert space. The method is thus not limited toscalar pixel values: any data type for which a kernel is available may beconsidered, from color triplets and multispectral vector data to strings,graphs, and more. By adjusting the size of the neighborhoods that are compared,the method is implicitly scale-dependent. It is also able to focus on eithersmall changes or large gradients. We demonstrate how it can be used to inferspatial and data value characteristic scales in measured signals and naturalimages.
arxiv-12600-11 | Automatic Taxonomy Extraction from Query Logs with no Additional Sources of Information | http://arxiv.org/pdf/1510.00618v2.pdf | author:Miguel Fernandez-Fernandez, Daniel Gayo-Avello category:cs.CL published:2015-10-02 summary:Search engine logs store detailed information on Web users interactions.Thus, as more and more people use search engines on a daily basis, importanttrails of users common knowledge are being recorded in those files. Previousresearch has shown that it is possible to extract concept taxonomies from fulltext documents, while other scholars have proposed methods to obtain similarqueries from query logs. We propose a mixture of both lines of research, thatis, mining query logs not to find related queries nor query hierarchies, butactual term taxonomies that could be used to improve search engineeffectiveness and efficiency. As a result, in this study we have developed amethod that combines lexical heuristics with a supervised classification modelto successfully extract hyponymy relations from specialization search patternsrevealed from log missions, with no additional sources of information, and in alanguage independent way.
arxiv-12600-12 | GPU-Based Computation of 2D Least Median of Squares with Applications to Fast and Robust Line Detection | http://arxiv.org/pdf/1510.01041v1.pdf | author:Gil Shapira, Tal Hassner category:cs.CV published:2015-10-05 summary:The 2D Least Median of Squares (LMS) is a popular tool in robust regressionbecause of its high breakdown point: up to half of the input data can becontaminated with outliers without affecting the accuracy of the LMS estimator.The complexity of 2D LMS estimation has been shown to be $\Omega(n^2)$ where$n$ is the total number of points. This high theoretical complexity along withthe availability of graphics processing units (GPU) motivates the developmentof a fast, parallel, GPU-based algorithm for LMS computation. We present a CUDAbased algorithm for LMS computation and show it to be much faster than theoptimal state of the art single threaded CPU algorithm. We begin by describingthe proposed method and analyzing its performance. We then demonstrate how itcan be used to modify the well-known Hough Transform (HT) in order toefficiently detect image lines in noisy images. Our method is compared withstandard HT-based line detection methods and shown to overcome theirshortcomings in terms of both efficiency and accuracy.
arxiv-12600-13 | Relaxed Multiple-Instance SVM with Application to Object Discovery | http://arxiv.org/pdf/1510.01027v1.pdf | author:Xinggang Wang, Zhuotun Zhu, Cong Yao, Xiang Bai category:cs.CV cs.LG published:2015-10-05 summary:Multiple-instance learning (MIL) has served as an important tool for a widerange of vision applications, for instance, image classification, objectdetection, and visual tracking. In this paper, we propose a novel method tosolve the classical MIL problem, named relaxed multiple-instance SVM (RMI-SVM).We treat the positiveness of instance as a continuous variable, use Noisy-ORmodel to enforce the MIL constraints, and jointly optimize the bag label andinstance label in a unified framework. The optimization problem can beefficiently solved using stochastic gradient decent. The extensive experimentsdemonstrate that RMI-SVM consistently achieves superior performance on variousbenchmarks for MIL. Moreover, we simply applied RMI-SVM to a challenging visiontask, common object discovery. The state-of-the-art results of object discoveryon Pascal VOC datasets further confirm the advantages of the proposed method.
arxiv-12600-14 | Calculating entropy at different scales among diverse communication systems | http://arxiv.org/pdf/1510.01026v1.pdf | author:Gerardo Febres, Klaus Jaffe category:cs.IT cs.CL math.IT published:2015-10-05 summary:We evaluated the impact of changing the observation scale over the entropymeasures for text descriptions. MIDI coded Music, computer code and two humannatural languages were studied at the scale of characters, words, and at theFundamental Scale resulting from adjusting the symbols length used to interpreteach text-description until it produced minimum entropy. The results show thatthe Fundamental Scale method is comparable with the use of words when measuringentropy levels in written texts. However, this method can also be used incommunication systems lacking words such as music. Measuring symbolic entropyat the fundamental scale allows to calculate quantitatively, relative levels ofcomplexity for different communication systems. The results open novel visionon differences among the structure of the communication systems studied.
arxiv-12600-15 | Quadratic Optimization with Orthogonality Constraints: Explicit Lojasiewicz Exponent and Linear Convergence of Line-Search Methods | http://arxiv.org/pdf/1510.01025v1.pdf | author:Huikang Liu, Weijie Wu, Anthony Man-Cho So category:math.OC cs.LG cs.NA math.NA published:2015-10-05 summary:A fundamental class of matrix optimization problems that arise in many areasof science and engineering is that of quadratic optimization with orthogonalityconstraints. Such problems can be solved using line-search methods on theStiefel manifold, which are known to converge globally under mild conditions.To determine the convergence rate of these methods, we give an explicitestimate of the exponent in a Lojasiewicz inequality for the (non-convex) setof critical points of the aforementioned class of problems. By combining suchan estimate with known arguments, we are able to establish the linearconvergence of a large class of line-search methods. A key step in our proof isto establish a local error bound for the set of critical points, which may beof independent interest.
arxiv-12600-16 | Single Image Dehazing through Improved Atmospheric Light Estimation | http://arxiv.org/pdf/1510.01018v1.pdf | author:Huimin Lu, Yujie Li, Shota Nakashima, Seiichi Serikawa category:cs.CV published:2015-10-05 summary:Image contrast enhancement for outdoor vision is important for smart carauxiliary transport systems. The video frames captured in poor weatherconditions are often characterized by poor visibility. Most image dehazingalgorithms consider to use a hard threshold assumptions or user input toestimate atmospheric light. However, the brightest pixels sometimes are objectssuch as car lights or streetlights, especially for smart car auxiliarytransport systems. Simply using a hard threshold may cause a wrong estimation.In this paper, we propose a single optimized image dehazing method thatestimates atmospheric light efficiently and removes haze through the estimationof a semi-globally adaptive filter. The enhanced images are characterized withlittle noise and good exposure in dark regions. The textures and edges of theprocessed images are also enhanced significantly.
arxiv-12600-17 | Accuracy of Bayesian Latent Variable Estimation with Redundant Dimension | http://arxiv.org/pdf/1510.01003v1.pdf | author:Keisuke Yamazaki category:stat.ML published:2015-10-05 summary:Hierarchical learning models such as mixture models and Bayesian networks arewidely employed for unsupervised learning tasks such as clustering analysis.They consist of two variables: observable and hidden variables, which representthe given data and their hidden generation process, respectively. It has beenpointed out that the conventional statistical analysis is not applicable tothese models because singularities exist in the parameter space. In recentyears, a method based on algebraic geometry allows us to analyze accuracy ofobservable variable prediction on the Bayes estimation. However, analysis forthe latent variable has not been studied well though one of the main issues inunsupervised learning is how precisely the latent variable is estimated. Aprevious study proposed a method for the latent variable when the range of alatent variable has redundancy compared with the model generating data. Thepresent paper extends the method to another redundancy; there are redundantlatent variables instead of the variable range. We formulate two types of theerror function, and derive the asymptotic forms of both types. Moreover,calculation on the error functions is demonstrated in two-layered Bayesiannetworks.
arxiv-12600-18 | Implicit stochastic gradient descent | http://arxiv.org/pdf/1408.2923v5.pdf | author:Panos Toulis, Edoardo M. Airoldi category:stat.ME stat.CO stat.ML published:2014-08-13 summary:Stochastic optimization procedures, such as stochastic gradient descent, havegained popularity for parameter estimation from large data sets. However,standard stochastic optimization procedures cannot effectively combinenumerical stability with statistical and computational efficiency. Here, weintroduce an implicit stochastic gradient descent procedure, the iterates ofwhich are implicitly defined. Intuitively, implicit iterates shrink thestandard iterates. The amount of shrinkage depends on the observed Fisherinformation matrix, which does not need to be explicitly computed in practice,thus increasing stability without increasing the computational burden. Whencombined with averaging, the proposed procedure achieves statistical efficiencyas well. We derive non-asymptotic bounds and characterize the asymptoticdistribution of implicit procedures. Our analysis also reveals the asymptoticvariance of a number of existing procedures. We demonstrate implicit stochasticgradient descent by further developing theory for generalized linear models,Cox proportional hazards, and M-estimation problems, and by carrying outextensive experiments. Our results suggest that the implicit stochasticgradient descent procedure is poised to become the workhorse of estimation withlarge data sets.
arxiv-12600-19 | Automatic 3D Liver Segmentation Using Sparse Representation of Global and Local Image Information via Level Set Formulation | http://arxiv.org/pdf/1508.01521v2.pdf | author:Saif Dawood Salman Al-Shaikhli, Michael Ying Yang, Bodo Rosenhahn category:cs.CV published:2015-08-06 summary:In this paper, a novel framework for automated liver segmentation via a levelset formulation is presented. A sparse representation of both global(region-based) and local (voxel-wise) image information is embedded in a levelset formulation to innovate a new cost function. Two dictionaries are build: Aregion-based feature dictionary and a voxel-wise dictionary. These dictionariesare learned, using the K-SVD method, from a public database of liversegmentation challenge (MICCAI-SLiver07). The learned dictionaries provideprior knowledge to the level set formulation. For the quantitative evaluation,the proposed method is evaluated using the testing data of MICCAI-SLiver07database. The results are evaluated using different metric scores computed bythe challenge organizers. The experimental results demonstrate the superiorityof the proposed framework by achieving the highest segmentation accuracy(79.6\%) in comparison to the state-of-the-art methods.
arxiv-12600-20 | Cross-convolutional-layer Pooling for Generic Visual Recognition | http://arxiv.org/pdf/1510.00921v1.pdf | author:Lingqiao Liu, Chunhua Shen, Anton van den Hengel category:cs.CV published:2015-10-04 summary:Recent studies have shown that a Deep Convolutional Neural Network (DCNN)pretrained on a large image dataset can be used as a universal imagedescriptor, and that doing so leads to impressive performance for a variety ofimage classification tasks. Most of these studies adopt activations from asingle DCNN layer, usually the fully-connected layer, as the imagerepresentation. In this paper, we proposed a novel way to extract imagerepresentations from two consecutive convolutional layers: one layer isutilized for local feature extraction and the other serves as guidance to poolthe extracted features. By taking different viewpoints of convolutional layers,we further develop two schemes to realize this idea. The first one directlyuses convolutional layers from a DCNN. The second one applies the pretrainedCNN on densely sampled image regions and treats the fully-connected activationsof each image region as convolutional feature activations. We then trainanother convolutional layer on top of that as the pooling-guidanceconvolutional layer. By applying our method to three popular visualclassification tasks, we find our first scheme tends to perform better on theapplications which need strong discrimination on subtle object patterns withinsmall regions while the latter excels in the cases that require discriminationon category-level patterns. Overall, the proposed method achieves superiorperformance over existing ways of extracting image representations from a DCNN.
arxiv-12600-21 | Convex Modeling of Interactions with Strong Heredity | http://arxiv.org/pdf/1410.3517v2.pdf | author:Asad Haris, Daniela Witten, Noah Simon category:stat.ML published:2014-10-13 summary:We consider the task of fitting a regression model involving interactionsamong a potentially large set of covariates, in which we wish to enforce strongheredity. We propose FAMILY, a very general framework for this task. Ourproposal is a generalization of several existing methods, such as VANISH[Radchenko and James, 2010], hierNet [Bien et al., 2013], the all-pairs lasso,and the lasso using only main effects. It can be formulated as the solution toa convex optimization problem, which we solve using an efficient alternatingdirections method of multipliers (ADMM) algorithm. This algorithm hasguaranteed convergence to the global optimum, can be easily specialized to anyconvex penalty function of interest, and allows for a straightforward extensionto the setting of generalized linear models. We derive an unbiased estimator ofthe degrees of freedom of FAMILY, and explore its performance in a simulationstudy and on an HIV sequence data set.
arxiv-12600-22 | Holistically-Nested Edge Detection | http://arxiv.org/pdf/1504.06375v2.pdf | author:Saining Xie, Zhuowen Tu category:cs.CV published:2015-04-24 summary:We develop a new edge detection algorithm that tackles two important issuesin this long-standing vision problem: (1) holistic image training andprediction; and (2) multi-scale and multi-level feature learning. Our proposedmethod, holistically-nested edge detection (HED), performs image-to-imageprediction by means of a deep learning model that leverages fully convolutionalneural networks and deeply-supervised nets. HED automatically learns richhierarchical representations (guided by deep supervision on side responses)that are important in order to approach the human ability resolve thechallenging ambiguity in edge and object boundary detection. We significantlyadvance the state-of-the-art on the BSD500 dataset (ODS F-score of .782) andthe NYU Depth dataset (ODS F-score of .746), and do so with an improved speed(0.4 second per image) that is orders of magnitude faster than some recentCNN-based edge detection algorithms.
arxiv-12600-23 | A Lower Bound for the Optimization of Finite Sums | http://arxiv.org/pdf/1410.0723v4.pdf | author:Alekh Agarwal, Leon Bottou category:stat.ML math.OC published:2014-10-02 summary:This paper presents a lower bound for optimizing a finite sum of $n$functions, where each function is $L$-smooth and the sum is $\mu$-stronglyconvex. We show that no algorithm can reach an error $\epsilon$ in minimizingall functions from this class in fewer than $\Omega(n +\sqrt{n(\kappa-1)}\log(1/\epsilon))$ iterations, where $\kappa=L/\mu$ is asurrogate condition number. We then compare this lower bound to upper boundsfor recently developed methods specializing to this setting. When the functionsinvolved in this sum are not arbitrary, but based on i.i.d. random data, thenwe further contrast these complexity results with those for optimal first-ordermethods to directly optimize the sum. The conclusion we draw is that a lot ofcaution is necessary for an accurate comparison, and identify machine learningscenarios where the new methods help computationally.
arxiv-12600-24 | Background Image Generation Using Boolean Operations | http://arxiv.org/pdf/1510.00889v1.pdf | author:Kardi Teknomo, Proceso Fernandez category:cs.CV I.4.6 published:2015-10-04 summary:Tracking moving objects from a video sequence requires segmentation of theseobjects from the background image. However, getting the actual background imageautomatically without object detection and using only the video is difficult.In this paper, we describe a novel algorithm that generates background fromreal world images without foreground detection. The algorithm assumes that thebackground image is shown in the majority of the video. Given this simpleassumption, the method described in this paper is able to accurately generate,with high probability, the background image from a video using only a smallnumber of binary operations.
arxiv-12600-25 | Approximate Fisher Kernels of non-iid Image Models for Image Categorization | http://arxiv.org/pdf/1510.00857v1.pdf | author:Ramazan Gokberk Cinbis, Jakob Verbeek, Cordelia Schmid category:cs.CV cs.LG published:2015-10-03 summary:The bag-of-words (BoW) model treats images as sets of local descriptors andrepresents them by visual word histograms. The Fisher vector (FV)representation extends BoW, by considering the first and second orderstatistics of local descriptors. In both representations local descriptors areassumed to be identically and independently distributed (iid), which is a poorassumption from a modeling perspective. It has been experimentally observedthat the performance of BoW and FV representations can be improved by employingdiscounting transformations such as power normalization. In this paper, weintroduce non-iid models by treating the model parameters as latent variableswhich are integrated out, rendering all local regions dependent. Using theFisher kernel principle we encode an image by the gradient of the datalog-likelihood w.r.t. the model hyper-parameters. Our models naturally generatediscounting effects in the representations; suggesting that suchtransformations have proven successful because they closely correspond to therepresentations obtained for non-iid models. To enable tractable computation,we rely on variational free-energy bounds to learn the hyper-parameters and tocompute approximate Fisher kernels. Our experimental evaluation resultsvalidate that our models lead to performance improvements comparable to usingpower normalization, as employed in state-of-the-art feature aggregationmethods.
arxiv-12600-26 | Projected Iterative Soft-thresholding Algorithm for Tight Frames in Compressed Sensing Magnetic Resonance Imaging | http://arxiv.org/pdf/1504.07786v2.pdf | author:Yunsong Liu, Zhifang Zhan, Jian-Feng Cai, Di Guo, Zhong Chen, Xiaobo Qu category:physics.med-ph cs.CV math.OC published:2015-04-29 summary:Compressed sensing has shown great potentials in accelerating magneticresonance imaging. Fast image reconstruction and high image quality are twomain issues faced by this new technology. It has been shown that, redundantimage representations, e.g. tight frames, can significantly improve the imagequality. But how to efficiently solve the reconstruction problem with theseredundant representation systems is still challenging. This paper attempts toaddress the problem of applying iterative soft-thresholding algorithm (ISTA) totight frames based magnetic resonance image reconstruction. By introducing thecanonical dual frame to construct the orthogonal projection operator on therange of the analysis sparsity operator, we propose a projected iterativesoft-thresholding algorithm (pISTA) and further accelerate it by incorporatingthe strategy proposed by Beck and Teboulle in 2009. We theoretically prove thatpISTA converges to the minimum of a function with a balanced tight framesparsity. Experimental results demonstrate that the proposed algorithm achievesbetter reconstruction than the widely used synthesis sparse model and theaccelerated pISTA converges faster or comparable to the state-of-art smoothingFISTA. One major advantage of pISTA is that only one extra parameter, the stepsize, is introduced and the numerical solution is stable to it in terms ofimage reconstruction errors, thus allowing easily setting in many fast magneticresonance imaging applications.
arxiv-12600-27 | Distributed Parameter Map-Reduce | http://arxiv.org/pdf/1510.00817v1.pdf | author:Qi Li category:cs.DC cs.LG stat.ML published:2015-10-03 summary:This paper describes how to convert a machine learning problem into a seriesof map-reduce tasks. We study logistic regression algorithm. In logisticregression algorithm, it is assumed that samples are independent and eachsample is assigned a probability. Parameters are obtained by maxmizing theproduct of all sample probabilities. Rapid expansion of training samples bringschallenges to machine learning method. Training samples are so many that theycan be only stored in distributed file system and driven by map-reduce styleprograms. The main step of logistic regression is inference. According tomap-reduce spirit, each sample makes inference through a separate mapprocedure. But the premise of inference is that the map procedure holdsparameters for all features in the sample. In this paper, we proposeDistributed Parameter Map-Reduce, in which not only samples, but alsoparameters are distributed in nodes of distributed filesystem. Through a seriesof map-reduce tasks, we assign each sample parameters for its features, makeinference for the sample and update paramters of the model. The above processesare excuted looply until convergence. We test the proposed algorithm in actualhadoop production environment. Experiments show that the acceleration of thealgorithm is in linear relationship with the number of cluster nodes.
arxiv-12600-28 | Online Tensor Methods for Learning Latent Variable Models | http://arxiv.org/pdf/1309.0787v5.pdf | author:Furong Huang, U. N. Niranjan, Mohammad Umar Hakeem, Animashree Anandkumar category:cs.LG cs.DC cs.SI stat.ML published:2013-09-03 summary:We introduce an online tensor decomposition based approach for two latentvariable modeling problems namely, (1) community detection, in which we learnthe latent communities that the social actors in social networks belong to, and(2) topic modeling, in which we infer hidden topics of text articles. Weconsider decomposition of moment tensors using stochastic gradient descent. Weconduct optimization of multilinear operations in SGD and avoid directlyforming the tensors, to save computational and storage costs. We presentoptimized algorithm in two platforms. Our GPU-based implementation exploits theparallelism of SIMD architectures to allow for maximum speed-up by a carefuloptimization of storage and data transfer, whereas our CPU-based implementationuses efficient sparse matrix computations and is suitable for large sparsedatasets. For the community detection problem, we demonstrate accuracy andcomputational efficiency on Facebook, Yelp and DBLP datasets, and for the topicmodeling problem, we also demonstrate good performance on the New York Timesdataset. We compare our results to the state-of-the-art algorithms such as thevariational method, and report a gain of accuracy and a gain of several ordersof magnitude in the execution time.
arxiv-12600-29 | Achieving Optimal Misclassification Proportion in Stochastic Block Model | http://arxiv.org/pdf/1505.03772v5.pdf | author:Chao Gao, Zongming Ma, Anderson Y. Zhang, Harrison H. Zhou category:math.ST cs.SI stat.ME stat.ML stat.TH published:2015-05-14 summary:Community detection is a fundamental statistical problem in network dataanalysis. Many algorithms have been proposed to tackle this problem. Most ofthese algorithms are not guaranteed to achieve the statistical optimality ofthe problem, while procedures that achieve information theoretic limits forgeneral parameter spaces are not computationally tractable. In this paper, wepresent a computationally feasible two-stage method that achieves optimalstatistical performance in misclassification proportion for stochastic blockmodel under weak regularity conditions. Our two-stage procedure consists of ageneric refinement step that can take a wide range of weakly consistentcommunity detection procedures as initializer, to which the refinement stageapplies and outputs a community assignment achieving optimal misclassificationproportion with high probability. The practical effectiveness of the newalgorithm is demonstrated by competitive numerical results.
arxiv-12600-30 | Machine Learning for Machine Data from a CATI Network | http://arxiv.org/pdf/1510.00772v1.pdf | author:Sou-Cheng T. Choi category:cs.LG published:2015-10-03 summary:This is a machine learning application paper involving big data. We presenthigh-accuracy prediction methods of rare events in semi-structured machine logfiles, which are produced at high velocity and high volume by NORC'scomputer-assisted telephone interviewing (CATI) network for conducting surveys.We judiciously apply natural language processing (NLP) techniques anddata-mining strategies to train effective learning and prediction models forclassifying uncommon error messages in the log---without access to source code,updated documentation or dictionaries. In particular, our simple but effectiveapproach of features preallocation for learning from imbalanced data coupledwith naive Bayes classifiers can be conceivably generalized to supervised orsemi-supervised learning and prediction methods for other critical events suchas cyberattack detection.
arxiv-12600-31 | Design and Analysis of a Single-Camera Omnistereo Sensor for Quadrotor Micro Aerial Vehicles (MAVs) | http://arxiv.org/pdf/1510.00771v1.pdf | author:Carlos Jaramillo category:cs.CV cs.RO cs.SY published:2015-10-03 summary:We describe the design and 3D sensing performance of an omnidirectionalstereo-vision system (omnistereo) as applied to Micro Aerial Vehicles (MAVs).The proposed omnistereo model employs a monocular camera that is co-axiallyaligned with a pair of hyperboloidal mirrors (folded catadioptricconfiguration). We show that this arrangement is practical for performingstereo-vision when mounted on top of propeller-based MAVs characterized by lowpayloads. The theoretical single viewpoint (SVP) constraint helps us deriveanalytical solutions for the sensor's projective geometry and generateSVP-compliant panoramic images to compute 3D information from stereocorrespondences (in a truly synchronous fashion). We perform an extensiveanalysis on various system characteristics such as its size, catadioptricspatial resolution, field-of-view. In addition, we pose a probabilistic modelfor uncertainty estimation of the depth from triangulation for skewback-projection rays. We expect to motivate the reproducibility of our solutionsince it can be adapted (optimally) to other catadioptric-based omnistereovision applications.
arxiv-12600-32 | P-trac Procedure: The Dispersion and Neutralization of Contrasts in Lexicon | http://arxiv.org/pdf/1510.00760v1.pdf | author:Afshin Rahimi, Bahram Vazirnezhad, Moharram Eslami category:cs.CL published:2015-10-03 summary:Cognitive acoustic cues have an important role in shaping the phonologicalstructure of language as a means to optimal communication. In this paper weintroduced P-trac procedure in order to track dispersion of contrasts indifferent contexts in lexicon. The results of applying P-trac procedure to thecase of dispersion of contrasts in pre- consonantal contexts and in consonantalpositions of CVCC sequences in Persian provide Evidence in favor of phoneticbasis of dispersion argued by Licensing by Cue hypothesis and the DispersionTheory of Contrast. The P- trac procedure is proved to be very effective inrevealing the dispersion of contrasts in lexicon especially when comparing thedispersion of contrasts in different contexts.
arxiv-12600-33 | It is not all downhill from here: Syllable Contact Law in Persian | http://arxiv.org/pdf/1510.00759v1.pdf | author:Afshin Rahimi, Moharram Eslami, Bahram Vazirnezhad category:cs.CL published:2015-10-03 summary:Syllable contact pairs crosslinguistically tend to have a falling sonorityslope a constraint which is called the Syllable Contact Law SCL In this studythe phonotactics of syllable contacts in 4202 CVCCVC words of Persian lexiconis investigated The consonants of Persian were divided into five sonoritycategories and the frequency of all possible sonority slopes is computed bothin lexicon type frequency and in corpus token frequency Since an unmarkedphonological structure has been shown to diachronically become more frequent weexpect to see the same pattern for syllable contact pairs with falling sonorityslope The correlation of sonority categories of the two consonants in asyllable contact pair is measured using Pointwise Mutual Information
arxiv-12600-34 | Rapidly Mixing Gibbs Sampling for a Class of Factor Graphs Using Hierarchy Width | http://arxiv.org/pdf/1510.00756v1.pdf | author:Christopher De Sa, Ce Zhang, Kunle Olukotun, Christopher Ré category:cs.LG published:2015-10-02 summary:Gibbs sampling on factor graphs is a widely used inference technique, whichoften produces good empirical results. Theoretical guarantees for itsperformance are weak: even for tree structured graphs, the mixing time of Gibbsmay be exponential in the number of variables. To help understand the behaviorof Gibbs sampling, we introduce a new (hyper)graph property, called hierarchywidth. We show that under suitable conditions on the weights, bounded hierarchywidth ensures polynomial mixing time. Our study of hierarchy width is in partmotivated by a class of factor graph templates, hierarchical templates, whichhave bounded hierarchy width---regardless of the data used to instantiate them.We demonstrate a rich application from natural language processing in whichGibbs sampling provably mixes rapidly and achieves accuracy that exceeds humanvolunteers.
arxiv-12600-35 | Taming the Wild: A Unified Analysis of Hogwild!-Style Algorithms | http://arxiv.org/pdf/1506.06438v2.pdf | author:Christopher De Sa, Ce Zhang, Kunle Olukotun, Christopher Ré category:cs.LG math.OC stat.ML published:2015-06-22 summary:Stochastic gradient descent (SGD) is a ubiquitous algorithm for a variety ofmachine learning problems. Researchers and industry have developed severaltechniques to optimize SGD's runtime performance, including asynchronousexecution and reduced precision. Our main result is a martingale-based analysisthat enables us to capture the rich noise models that may arise from suchtechniques. Specifically, we use our new analysis in three ways: (1) we deriveconvergence rates for the convex case (Hogwild!) with relaxed assumptions onthe sparsity of the problem; (2) we analyze asynchronous SGD algorithms fornon-convex matrix problems including matrix completion; and (3) we design andanalyze an asynchronous SGD algorithm, called Buckwild!, that useslower-precision arithmetic. We show experimentally that our algorithms runefficiently for a variety of problems on modern hardware.
arxiv-12600-36 | WHOI-Plankton- A Large Scale Fine Grained Visual Recognition Benchmark Dataset for Plankton Classification | http://arxiv.org/pdf/1510.00745v1.pdf | author:Eric C. Orenstein, Oscar Beijbom, Emily E. Peacock, Heidi M. Sosik category:cs.CV published:2015-10-02 summary:Planktonic organisms are of fundamental importance to marine ecosystems: theyform the basis of the food web, provide the link between the atmosphere and thedeep ocean, and influence global-scale biogeochemical cycles. Scientists areincreasingly using imaging-based technologies to study these creatures in theirnatural habit. Images from such systems provide an unique opportunity to modeland understand plankton ecosystems, but the collected datasets can be enormous.The Imaging FlowCytobot (IFCB) at Woods Hole Oceanographic Institution, forexample, is an \emph{in situ} system that has been continuously imagingplankton since 2006. To date, it has generated more than 700 million samples.Manual classification of such a vast image collection is impractical due to thesize of the data set. In addition, the annotation task is challenging due tothe large space of relevant classes, intra-class variability, and inter-classsimilarity. Methods for automated classification exist, but the accuracy isoften below that of human experts. Here we introduce WHOI-Plankton: a largescale, fine-grained visual recognition dataset for plankton classification,which comprises over 3.4 million expert-labeled images across 70 classes. Thelabeled image set is complied from over 8 years of near continuous datacollection with the IFCB at the Martha's Vineyard Coastal Observatory (MVCO).We discuss relevant metrics for evaluation of classification performance andprovide results for a traditional method based on hand-engineered features andtwo methods based on convolutional neural networks.
arxiv-12600-37 | A Primer on Neural Network Models for Natural Language Processing | http://arxiv.org/pdf/1510.00726v1.pdf | author:Yoav Goldberg category:cs.CL published:2015-10-02 summary:Over the past few years, neural networks have re-emerged as powerfulmachine-learning models, yielding state-of-the-art results in fields such asimage recognition and speech processing. More recently, neural network modelsstarted to be applied also to textual natural language signals, again with verypromising results. This tutorial surveys neural network models from theperspective of natural language processing research, in an attempt to bringnatural-language researchers up to speed with the neural techniques. Thetutorial covers input encoding for natural language tasks, feed-forwardnetworks, convolutional networks, recurrent networks and recursive networks, aswell as the computation graph abstraction for automatic gradient computation.
arxiv-12600-38 | Minimax Lower Bounds for Noisy Matrix Completion Under Sparse Factor Models | http://arxiv.org/pdf/1510.00701v1.pdf | author:Abhinav V. Sambasivan, Jarvis D. Haupt category:cs.IT math.IT stat.ML published:2015-10-02 summary:This paper examines fundamental error characteristics for a general class ofmatrix completion problems, where matrix of interest is a product of two apriori unknown matrices, one of which is sparse, and the observations arenoisy. Our main contributions come in the form of minimax lower bounds for theexpected per-element squared error for these problems under severalnoise/corruption models; specifically, we analyze scenarios where thecorruptions are characterized by additive Gaussian noise or additiveheavier-tailed (Laplace) noise, Poisson-distributed observations, andhighly-quantized (e.g., one-bit) observations. Our results establish that theerror bounds derived in (Soni et al., 2014) for complexity-regularized maximumlikelihood estimators achieve, up to multiplicative constant and logarithmicfactors, the minimax error rates in each of these noise scenarios, provided thesparse factor exhibits linear sparsity.
arxiv-12600-39 | Applying Deep Learning to Answer Selection: A Study and An Open Task | http://arxiv.org/pdf/1508.01585v2.pdf | author:Minwei Feng, Bing Xiang, Michael R. Glass, Lidan Wang, Bowen Zhou category:cs.CL cs.LG published:2015-08-07 summary:We apply a general deep learning framework to address the non-factoidquestion answering task. Our approach does not rely on any linguistic tools andcan be applied to different languages or domains. Various architectures arepresented and compared. We create and release a QA corpus and setup a new QAtask in the insurance domain. Experimental results demonstrate superiorperformance compared to the baseline methods and various technologies givefurther improvements. For this highly challenging task, the top-1 accuracy canreach up to 65.3% on a test set, which indicates a great potential forpractical use.
arxiv-12600-40 | Fast Clustering and Topic Modeling Based on Rank-2 Nonnegative Matrix Factorization | http://arxiv.org/pdf/1509.01208v3.pdf | author:Da Kuang, Barry Drake, Haesun Park category:cs.LG cs.IR cs.NA F.2.1; H.3.3 published:2015-09-03 summary:The importance of unsupervised clustering and topic modeling is wellrecognized with ever-increasing volumes of text data. In this paper, we proposea fast method for hierarchical clustering and topic modeling called HierNMF2.Our method is based on fast Rank-2 nonnegative matrix factorization (NMF) thatperforms binary clustering and an efficient node splitting rule. Furtherutilizing the final leaf nodes generated in HierNMF2 and the idea ofnonnegative least squares fitting, we propose a new clustering/topic modelingmethod called FlatNMF2 that recovers a flat clustering/topic modeling result ina very simple yet significantly more effective way than any other existingmethods. We implement highly optimized open source software in C++ for bothHierNMF2 and FlatNMF2 for hierarchical and partitional clustering/topicmodeling of document data sets. Substantial experimental tests are presented that illustrate significantimprovements both in computational time as well as quality of solutions. Wecompare our methods to other clustering methods including K-means, standardNMF, and CLUTO, and also topic modeling methods including latent Dirichletallocation (LDA) and recently proposed algorithms for NMF with separabilityconstraints. Overall, we present efficient tools for analyzing large-scale datasets, and techniques that can be generalized to many other data analyticsproblem domains.
arxiv-12600-41 | Distributed Multitask Learning | http://arxiv.org/pdf/1510.00633v1.pdf | author:Jialei Wang, Mladen Kolar, Nathan Srebro category:stat.ML cs.LG published:2015-10-02 summary:We consider the problem of distributed multi-task learning, where eachmachine learns a separate, but related, task. Specifically, each machine learnsa linear predictor in high-dimensional space,where all tasks share the samesmall support. We present a communication-efficient estimator based on thedebiased lasso and show that it is comparable with the optimal centralizedmethod.
arxiv-12600-42 | Exact Expression For Information Distance | http://arxiv.org/pdf/1410.7328v9.pdf | author:P. M. B. Vitanyi category:cs.IT cs.CC cs.CV cs.DM math.IT published:2014-10-27 summary:Information distance can be defined not only between two strings but also ina finite multiset of strings of cardinality greater than two. We give anelementary proof for expressing the information distance. It is exact since foreach cardinality of the multiset the lower bound for some multiset equals theupper bound for all multisets up to a constant additive term. We discussoverlap.
arxiv-12600-43 | Multi-armed Bandits with Application to 5G Small Cells | http://arxiv.org/pdf/1510.00627v1.pdf | author:Setareh Maghsudi, Ekram Hossain category:cs.LG cs.DC cs.NI published:2015-10-02 summary:Due to the pervasive demand for mobile services, next generation wirelessnetworks are expected to be able to deliver high date rates while wirelessresources become more and more scarce. This requires the next generationwireless networks to move towards new networking paradigms that are able toefficiently support resource-demanding applications such as personalized mobileservices. Examples of such paradigms foreseen for the emerging fifth generation(5G) cellular networks include very densely deployed small cells anddevice-to-device communications. For 5G networks, it will be imperative tosearch for spectrum and energy-efficient solutions to the resource allocationproblems that i) are amenable to distributed implementation, ii) are capable ofdealing with uncertainty and lack of information, and iii) can cope with users'selfishness. The core objective of this article is to investigate and toestablish the potential of multi-armed bandit (MAB) framework to address thischallenge. In particular, we provide a brief tutorial on bandit problems,including different variations and solution approaches. Furthermore, we discussrecent applications as well as future research directions. In addition, weprovide a detailed example of using an MAB model for energy-efficient smallcell planning in 5G networks.
arxiv-12600-44 | Fast Low-rank Representation based Spatial Pyramid Matching for Image Classification | http://arxiv.org/pdf/1409.5786v2.pdf | author:Xi Peng, Rui Yan, Bo Zhao, Huajin Tang, Zhang Yi category:cs.CV published:2014-09-22 summary:Spatial Pyramid Matching (SPM) and its variants have achieved a lot ofsuccess in image classification. The main difference among them is theirencoding schemes. For example, ScSPM incorporates Sparse Code (SC) instead ofVector Quantization (VQ) into the framework of SPM. Although the methodsachieve a higher recognition rate than the traditional SPM, they consume moretime to encode the local descriptors extracted from the image. In this paper,we propose using Low Rank Representation (LRR) to encode the descriptors underthe framework of SPM. Different from SC, LRR considers the group effect amongdata points instead of sparsity. Benefiting from this property, the proposedmethod (i.e., LrrSPM) can offer a better performance. To further improve thegeneralizability and robustness, we reformulate the rank-minimization problemas a truncated projection problem. Extensive experimental studies show thatLrrSPM is more efficient than its counterparts (e.g., ScSPM) while achievingcompetitive recognition rates on nine image data sets.
arxiv-12600-45 | Distinguishing short and long $Fermi$ gamma-ray bursts | http://arxiv.org/pdf/1507.04886v4.pdf | author:Mariusz Tarnopolski category:astro-ph.HE astro-ph.CO stat.ML published:2015-07-17 summary:Two classes of gamma-ray bursts (GRBs), short and long, have been determinedwithout any doubts, and are usually ascribed to different progenitors, yetthese classes overlap for a variety of descriptive parameters. A subsample of46 long and 22 short $Fermi$ GRBs with estimated Hurst Exponents (HEs),complemented by minimum variability time-scales (MVTS) and durations ($T_{90}$)is used to perform a supervised Machine Learning (ML) and Monte Carlo (MC)simulation using a Support Vector Machine (SVM) algorithm. It is found thatwhile $T_{90}$ itself performs very well in distinguishing short and long GRBs,the overall success ratio is higher when the training set is complemented byMVTS and HE. These results may allow to introduce a new (non-linear) parameterthat might provide less ambiguous classification of GRBs.
arxiv-12600-46 | Human Action Recognition using Factorized Spatio-Temporal Convolutional Networks | http://arxiv.org/pdf/1510.00562v1.pdf | author:Lin Sun, Kui Jia, Dit-Yan Yeung, Bertram E. Shi category:cs.CV published:2015-10-02 summary:Human actions in video sequences are three-dimensional (3D) spatio-temporalsignals characterizing both the visual appearance and motion dynamics of theinvolved humans and objects. Inspired by the success of convolutional neuralnetworks (CNN) for image classification, recent attempts have been made tolearn 3D CNNs for recognizing human actions in videos. However, partly due tothe high complexity of training 3D convolution kernels and the need for largequantities of training videos, only limited success has been reported. This hastriggered us to investigate in this paper a new deep architecture which canhandle 3D signals more effectively. Specifically, we propose factorizedspatio-temporal convolutional networks (FstCN) that factorize the original 3Dconvolution kernel learning as a sequential process of learning 2D spatialkernels in the lower layers (called spatial convolutional layers), followed bylearning 1D temporal kernels in the upper layers (called temporal convolutionallayers). We introduce a novel transformation and permutation operator to makefactorization in FstCN possible. Moreover, to address the issue of sequencealignment, we propose an effective training and inference strategy based onsampling multiple video clips from a given action video sequence. We havetested FstCN on two commonly used benchmark datasets (UCF-101 and HMDB-51).Without using auxiliary training videos to boost the performance, FstCNoutperforms existing CNN based methods and achieves comparable performance witha recent method that benefits from using auxiliary training videos.
arxiv-12600-47 | Marginalizing Gaussian Process Hyperparameters using Sequential Monte Carlo | http://arxiv.org/pdf/1502.01908v2.pdf | author:Andreas Svensson, Johan Dahlin, Thomas B. Schön category:stat.ML stat.CO published:2015-02-06 summary:Gaussian process regression is a popular method for non-parametricprobabilistic modeling of functions. The Gaussian process prior ischaracterized by so-called hyperparameters, which often have a large influenceon the posterior model and can be difficult to tune. This work provides amethod for numerical marginalization of the hyperparameters, relying on therigorous framework of sequential Monte Carlo. Our method is well suited foronline problems, and we demonstrate its ability to handle real-world problemswith several dimensions and compare it to other marginalization methods. Wealso conclude that our proposed method is a competitive alternative to thecommonly used point estimates maximizing the likelihood, both in terms ofcomputational load and its ability to handle multimodal posteriors.
arxiv-12600-48 | See the Difference: Direct Pre-Image Reconstruction and Pose Estimation by Differentiating HOG | http://arxiv.org/pdf/1505.00663v4.pdf | author:Wei-Chen Chiu, Mario Fritz category:cs.CV published:2015-05-04 summary:The Histogram of Oriented Gradient (HOG) descriptor has led to many advancesin computer vision over the last decade and is still part of many state of theart approaches. We realize that the associated feature computation is piecewisedifferentiable and therefore many pipelines which build on HOG can be madedifferentiable. This lends to advanced introspection as well as opportunitiesfor end-to-end optimization. We present our implementation of $\nabla$HOG basedon the auto-differentiation toolbox Chumpy and show applications to pre-imagevisualization and pose estimation which extends the existing differentiablerenderer OpenDR pipeline. Both applications improve on the respectivestate-of-the-art HOG approaches.
arxiv-12600-49 | Local Higher-Order Statistics (LHS) describing images with statistics of local non-binarized pixel patterns | http://arxiv.org/pdf/1510.00542v1.pdf | author:Gaurav Sharma, Frederic Jurie category:cs.CV published:2015-10-02 summary:We propose a new image representation for texture categorization and facialanalysis, relying on the use of higher-order local differential statistics asfeatures. It has been recently shown that small local pixel patterndistributions can be highly discriminative while being extremely efficient tocompute, which is in contrast to the models based on the global structure ofimages. Motivated by such works, we propose to use higher-order statistics oflocal non-binarized pixel patterns for the image description. The proposedmodel does not require either (i) user specified quantization of the space (ofpixel patterns) or (ii) any heuristics for discarding low occupancy volumes ofthe space. We propose to use a data driven soft quantization of the space, withparametric mixture models, combined with higher-order statistics, based onFisher scores. We demonstrate that this leads to a more expressiverepresentation which, when combined with discriminatively learned classifiersand metrics, achieves state-of-the-art performance on challenging texture andfacial analysis datasets, in low complexity setup. Further, it is complementaryto higher complexity features and when combined with them improves performance.
arxiv-12600-50 | On the Consistency of Ordinal Regression Methods | http://arxiv.org/pdf/1408.2327v7.pdf | author:Fabian Pedregosa, Francis Bach, Alexandre Gramfort category:cs.LG published:2014-08-11 summary:Many of the ordinal regression models that have been proposed in theliterature can be seen as methods that minimize a convex surrogate of thezero-one, absolute, or squared loss functions. A key property that allows tostudy the statistical implications of such approximations is that of Fisherconsistency. In this paper we will characterize the Fisher consistency of arich family of surrogate loss functions used in the context of ordinalregression, including support vector ordinal regression, ORBoosting and leastabsolute deviation. We will see that, for a family of surrogate loss functionsthat subsumes support vector ordinal regression and ORBoosting, consistency canbe fully characterized by the derivative of a real-valued function at zero, ashappens for convex margin-based surrogates in binary classification. We alsoderive excess risk bounds for a surrogate of the absolute error that generalizeexisting risk bounds for binary classification. Finally, our analysis suggestsa novel surrogate of the squared error loss. To prove the empirical performanceof such surrogate, we benchmarked it in terms of cross-validation error on 9different datasets, where it outperforms competing approaches on 7 out of 9datasets.
arxiv-12600-51 | Effective Object Tracking in Unstructured Crowd Scenes | http://arxiv.org/pdf/1510.00479v1.pdf | author:Ishan Jindal, Shanmuganathan Raman category:cs.CV published:2015-10-02 summary:In this paper, we are presenting a rotation variant Oriented Texture Curve(OTC) descriptor based mean shift algorithm for tracking an object in anunstructured crowd scene. The proposed algorithm works by first obtaining theOTC features for a manually selected object target, then a visual vocabulary iscreated by using all the OTC features of the target. The target histogram isobtained using codebook encoding method which is then used in mean shiftframework to perform similarity search. Results are obtained on differentvideos of challenging scenes and the comparison of the proposed approach withseveral state-of-the-art approaches are provided. The analysis shows theadvantages and limitations of the proposed approach for tracking an object inunstructured crowd scenes.
arxiv-12600-52 | Learning a Discriminative Model for the Perception of Realism in Composite Images | http://arxiv.org/pdf/1510.00477v1.pdf | author:Jun-Yan Zhu, Philipp Krähenbühl, Eli Shechtman, Alexei A. Efros category:cs.CV published:2015-10-02 summary:What makes an image appear realistic? In this work, we are answering thisquestion from a data-driven perspective by learning the perception of visualrealism directly from large amounts of data. In particular, we train aConvolutional Neural Network (CNN) model that distinguishes natural photographsfrom automatically generated composite images. The model learns to predictvisual realism of a scene in terms of color, lighting and texturecompatibility, without any human annotations pertaining to it. Our modeloutperforms previous works that rely on hand-crafted heuristics, for the taskof classifying realistic vs. unrealistic photos. Furthermore, we apply ourlearned model to compute optimal parameters of a compositing method, tomaximize the visual realism score predicted by our CNN model. We demonstrateits advantage against existing methods via a human perception study.
arxiv-12600-53 | Learning like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images | http://arxiv.org/pdf/1504.06692v2.pdf | author:Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, Alan Yuille category:cs.CV cs.CL cs.LG published:2015-04-25 summary:In this paper, we address the task of learning novel visual concepts, andtheir interactions with other concepts, from a few images with sentencedescriptions. Using linguistic context and visual features, our method is ableto efficiently hypothesize the semantic meaning of new words and add them toits word dictionary so that they can be used to describe images which containthese novel concepts. Our method has an image captioning module based on m-RNNwith several improvements. In particular, we propose a transposed weightsharing scheme, which not only improves performance on image captioning, butalso makes the model more suitable for the novel concept learning task. Wepropose methods to prevent overfitting the new concepts. In addition, threenovel concept datasets are constructed for this new task. In the experiments,we show that our method effectively learns novel visual concepts from a fewexamples without disturbing the previously learned concepts. The project pageis http://www.stat.ucla.edu/~junhua.mao/projects/child_learning.html
arxiv-12600-54 | Towards Machine Wald | http://arxiv.org/pdf/1508.02449v2.pdf | author:Houman Owhadi, Clint Scovel category:math.ST cs.LG stat.TH 62C99, 68Q32 published:2015-08-10 summary:The past century has seen a steady increase in the need of estimating andpredicting complex systems and making (possibly critical) decisions withlimited information. Although computers have made possible the numericalevaluation of sophisticated statistical models, these models are still designed\emph{by humans} because there is currently no known recipe or algorithm fordividing the design of a statistical model into a sequence of arithmeticoperations. Indeed enabling computers to \emph{think} as \emph{humans} have theability to do when faced with uncertainty is challenging in several major ways:(1) Finding optimal statistical models remains to be formulated as a well posedproblem when information on the system of interest is incomplete and comes inthe form of a complex combination of sample data, partial knowledge ofconstitutive relations and a limited description of the distribution of inputrandom variables. (2) The space of admissible scenarios along with the space ofrelevant information, assumptions, and/or beliefs, tend to be infinitedimensional, whereas calculus on a computer is necessarily discrete and finite.With this purpose, this paper explores the foundations of a rigorous frameworkfor the scientific computation of optimal statistical estimators/models andreviews their connections with Decision Theory, Machine Learning, BayesianInference, Stochastic Optimization, Robust Optimization, Optimal UncertaintyQuantification and Information Based Complexity.
arxiv-12600-55 | Response to Liu, Xu, and Liang (2015) and Ferrer-i-Cancho and Gómez-Rodríguez (2015) on Dependency Length Minimization | http://arxiv.org/pdf/1510.00436v1.pdf | author:Richard Futrell, Kyle Mahowald, Edward Gibson category:cs.CL published:2015-10-01 summary:We address recent criticisms (Liu et al., 2015; Ferrer-i-Cancho andG\'omez-Rodr\'iguez, 2015) of our work on empirical evidence of dependencylength minimization across languages (Futrell et al., 2015). First, weacknowledge error in failing to acknowledge Liu (2008)'s previous work oncorpora of 20 languages with similar aims. A correction will appear in PNAS.Nevertheless, we argue that our work provides novel, strong evidence fordependency length minimization as a universal quantitative property oflanguages, beyond this previous work, because it provides baselines which focuson word order preferences. Second, we argue that our choices of baselines wereappropriate because they control for alternative theories.
arxiv-12600-56 | An Asynchronous Implementation of the Limited Memory CMA-ES | http://arxiv.org/pdf/1510.00419v1.pdf | author:Viktor Arkhipov, Maxim Buzdalov, Anatoly Shalyto category:cs.NE 90C56 G.1.6; I.2.8 published:2015-10-01 summary:We present our asynchronous implementation of the LM-CMA-ES algorithm, whichis a modern evolution strategy for solving complex large-scale continuousoptimization problems. Our implementation brings the best results when thenumber of cores is relatively high and the computational complexity of thefitness function is also high. The experiments with benchmark functions showthat it is able to overcome its origin on the Sphere function, reaches certainthresholds faster on the Rosenbrock and Ellipsoid function, and surprisinglyperforms much better than the original version on the Rastrigin function.
arxiv-12600-57 | A Pseudo-Euclidean Iteration for Optimal Recovery in Noisy ICA | http://arxiv.org/pdf/1502.04148v2.pdf | author:James Voss, Mikhail Belkin, Luis Rademacher category:cs.LG stat.ML published:2015-02-13 summary:Independent Component Analysis (ICA) is a popular model for blind signalseparation. The ICA model assumes that a number of independent source signalsare linearly mixed to form the observed signals. We propose a new algorithm,PEGI (for pseudo-Euclidean Gradient Iteration), for provable model recovery forICA with Gaussian noise. The main technical innovation of the algorithm is touse a fixed point iteration in a pseudo-Euclidean (indefinite "inner product")space. The use of this indefinite "inner product" resolves technical issuescommon to several existing algorithms for noisy ICA. This leads to an algorithmwhich is conceptually simple, efficient and accurate in testing. Our second contribution is combining PEGI with the analysis of objectives foroptimal recovery in the noisy ICA model. It has been observed that the directapproach of demixing with the inverse of the mixing matrix is suboptimal forsignal recovery in terms of the natural Signal to Interference plus Noise Ratio(SINR) criterion. There have been several partial solutions proposed in the ICAliterature. It turns out that any solution to the mixing matrix reconstructionproblem can be used to construct an SINR-optimal ICA demixing, despite the factthat SINR itself cannot be computed from data. That allows us to obtain apractical and provably SINR-optimal recovery method for ICA with arbitraryGaussian noise.
arxiv-12600-58 | RDF Knowledge Graph Visualization From a Knowledge Extraction System | http://arxiv.org/pdf/1510.00244v1.pdf | author:Fadhela Kerdjoudj, Olivier Curé category:cs.HC cs.CL published:2015-10-01 summary:In this paper, we present a system to visualize RDF knowledge graphs. Thesegraphs are obtained from a knowledge extraction system designed byGEOLSemantics. This extraction is performed using natural language processingand trigger detection. The user can visualize subgraphs by selecting someontology features like concepts or individuals. The system is alsomultilingual, with the use of the annotated ontology in English, French, Arabicand Chinese.
arxiv-12600-59 | Determination of the Internet Anonymity Influence on the Level of Aggression and Usage of Obscene Lexis | http://arxiv.org/pdf/1510.00240v1.pdf | author:Rodmonga Potapova, Denis Gordeev category:cs.CL published:2015-10-01 summary:This article deals with the analysis of the semantic content of the anonymousRussian-speaking forum 2ch.hk, different verbal means of expressing of theemotional state of aggression are revealed for this site, and aggression isclassified by its directions. The lexis of different Russian-and English-speaking anonymous forums (2ch.hk and iichan.hk, 4chan.org) and publiccommunity "MDK" of the Russian-speaking social network VK is analyzed andcompared with the Open Corpus of the Russian language (Opencorpora.org andBrown corpus). The analysis shows that anonymity has no influence on the amountof invective items usage. The effectiveness of moderation was shown foranonymous forums. It was established that Russian obscene lexis was used toexpress the emotional state of aggression only in 60.4% of cases for 2ch.hk.These preliminary results show that the Russian obscene lexis on the Internetdoes not have direct dependence on the emotional state of aggression.
arxiv-12600-60 | Data Association for an Adaptive Multi-target Particle Filter Tracking System | http://arxiv.org/pdf/1510.00203v1.pdf | author:R. Alampay, K. Teknomo category:cs.CV I.5.4 published:2015-10-01 summary:This paper presents a novel approach to improve the accuracy of trackingmultiple objects in a static scene using a particle filter system byintroducing a data association step, a state queue for the collection oftracked objects and adaptive parameters to the system. The data associationstep makes use of the object detection phase and appearance model to determineif the approximated targets given by the particle filter step match the givenset of detected objects. The remaining detected objects are used as informationto instantiate new objects for tracking. State queues are also used for eachtracked object to deal with occlusion events and occlusion recovery. Finally wepresent how the parameters adjust to occlusion events. The adaptive property ofthe system is also used for possible occlusion recovery. Results of the systemare then compared to a ground truth data set for performance evaluation. Oursystem produced accurate results and was able to handle partially occludedobjects as well as proper occlusion recovery from tracking multiple objects
arxiv-12600-61 | First Steps Towards a Runtime Comparison of Natural and Artificial Evolution | http://arxiv.org/pdf/1504.06260v2.pdf | author:Tiago Paixão, Jorge Pérez Heredia, Dirk Sudholt, Barbora Trubenová category:cs.NE F.2.2 published:2015-04-23 summary:Evolutionary algorithms (EAs) form a popular optimisation paradigm inspiredby natural evolution. In recent years the field of evolutionary computation hasdeveloped a rigorous analytical theory to analyse their runtime on manyillustrative problems. Here we apply this theory to a simple model of naturalevolution. In the Strong Selection Weak Mutation (SSWM) evolutionary regime thetime between occurrence of new mutations is much longer than the time it takesfor a new beneficial mutation to take over the population. In this situation,the population only contains copies of one genotype and evolution can bemodelled as a (1+1)-type process where the probability of accepting a newgenotype (improvements or worsenings) depends on the change in fitness. We present an initial runtime analysis of SSWM, quantifying its performancefor various parameters and investigating differences to the (1+1)EA. We showthat SSWM can have a moderate advantage over the (1+1)EA at crossing fitnessvalleys and study an example where SSWM outperforms the (1+1)EA by takingadvantage of information on the fitness gradient.
arxiv-12600-62 | Ask Your Neurons: A Neural-based Approach to Answering Questions about Images | http://arxiv.org/pdf/1505.01121v3.pdf | author:Mateusz Malinowski, Marcus Rohrbach, Mario Fritz category:cs.CV cs.AI cs.CL published:2015-05-05 summary:We address a question answering task on real-world images that is set up as aVisual Turing Test. By combining latest advances in image representation andnatural language processing, we propose Neural-Image-QA, an end-to-endformulation to this problem for which all parts are trained jointly. Incontrast to previous efforts, we are facing a multi-modal problem where thelanguage output (answer) is conditioned on visual and natural language input(image and question). Our approach Neural-Image-QA doubles the performance ofthe previous best approach on this problem. We provide additional insights intothe problem by analyzing how much information is contained only in the languagepart for which we provide a new human baseline. To study human consensus, whichis related to the ambiguities inherent in this challenging task, we propose twonovel metrics and collect additional answers which extends the original DAQUARdataset to DAQUAR-Consensus.
arxiv-12600-63 | Label-Embedding for Image Classification | http://arxiv.org/pdf/1503.08677v2.pdf | author:Zeynep Akata, Florent Perronnin, Zaid Harchaoui, Cordelia Schmid category:cs.CV published:2015-03-30 summary:Attributes act as intermediate representations that enable parameter sharingbetween classes, a must when training data is scarce. We propose to viewattribute-based image classification as a label-embedding problem: each classis embedded in the space of attribute vectors. We introduce a function thatmeasures the compatibility between an image and a label embedding. Theparameters of this function are learned on a training set of labeled samples toensure that, given an image, the correct classes rank higher than the incorrectones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasetsshow that the proposed framework outperforms the standard Direct AttributePrediction baseline in a zero-shot learning scenario. Label embedding enjoys abuilt-in ability to leverage alternative sources of information instead of orin addition to attributes, such as e.g. class hierarchies or textualdescriptions. Moreover, label embedding encompasses the whole range of learningsettings from zero-shot learning to regular learning with a large number oflabeled examples.
arxiv-12600-64 | Using consumer behavior data to reduce energy consumption in smart homes | http://arxiv.org/pdf/1510.00165v1.pdf | author:Daniel Schweizer, Michael Zehnder, Holger Wache, Hans-Friedrich Witschel, Danilo Zanatta, Miguel Rodriguez category:cs.CY stat.ML published:2015-10-01 summary:This paper discusses how usage patterns and preferences of inhabitants can belearned efficiently to allow smart homes to autonomously achieve energysavings. We propose a frequent sequential pattern mining algorithm suitable forreal-life smart home event data. The performance of the proposed algorithm iscompared to existing algorithms regarding completeness/correctness of theresults, run times as well as memory consumption and elaborates on theshortcomings of the different solutions. We also present a recommender systembased on the developed algorithm that provides recommendations to the users toreduce their energy consumption. The recommender system was deployed to a setof test homes. The test participants rated the impact of the recommendations ontheir comfort. We used this feedback to adjust the system parameters and makeit more accurate during a second test phase.
arxiv-12600-65 | Diffusion Adaptation Over Clustered Multitask Networks Based on the Affine Projection Algorithm | http://arxiv.org/pdf/1507.08566v4.pdf | author:Vinay Chakravarthi Gogineni, Mrityunjoy Chakraborty category:cs.DC cs.SY math.ST stat.ML stat.TH published:2015-07-29 summary:Distributed adaptive networks achieve better estimation performance byexploiting temporal and as well spatial diversity while consuming fewresources. Recent works have studied the single task distributed estimationproblem, in which the nodes estimate a single optimum parameter vectorcollaboratively. However, there are many important applications where themultiple vectors have to estimated simultaneously, in a collaborative manner.This paper presents multi-task diffusion strategies based on the AffineProjection Algorithm (APA), usage of APA makes the algorithm robust against thecorrelated input. The performance analysis of the proposed multi-task diffusionAPA algorithm is studied in mean and mean square sense. And also a modifiedmulti-task diffusion strategy is proposed that improves the performance interms of convergence rate and steady state EMSE as well. Simulations areconducted to verify the analytical results.
arxiv-12600-66 | Disk storage management for LHCb based on Data Popularity estimator | http://arxiv.org/pdf/1510.00132v1.pdf | author:Mikhail Hushchyn, Philippe Charpentier, Andrey Ustyuzhanin category:cs.DC cs.LG published:2015-10-01 summary:This paper presents an algorithm providing recommendations for optimizing theLHCb data storage. The LHCb data storage system is a hybrid system. Alldatasets are kept as archives on magnetic tapes. The most popular datasets arekept on disks. The algorithm takes the dataset usage history and metadata(size, type, configuration etc.) to generate a recommendation report. Thisarticle presents how we use machine learning algorithms to predict future datapopularity. Using these predictions it is possible to estimate which datasetsshould be removed from disk. We use regression algorithms and time seriesanalysis to find the optimal number of replicas for datasets that are kept ondisk. Based on the data popularity and the number of replicas optimization, thealgorithm minimizes a loss function to find the optimal data distribution. Theloss function represents all requirements for data distribution in the datastorage system. We demonstrate how our algorithm helps to save disk space andto reduce waiting times for jobs using this data.
arxiv-12600-67 | Multi-objective Differential Evolution with Helper Functions for Constrained Optimization | http://arxiv.org/pdf/1509.09060v2.pdf | author:Tao Xu, Jun He category:cs.NE published:2015-09-30 summary:Solving constrained optimization problems by multi-objective evolutionaryalgorithms has scored tremendous achievements in the last decade. Standardmulti-objective schemes usually aim at minimizing the objective function andalso the degree of constraint violation simultaneously. This paper proposes anew multi-objective method for solving constrained optimization problems. Thenew method keeps two standard objectives: the original objective function andthe sum of degrees of constraint violation. But besides them, four moreobjectives are added. One is based on the feasible rule. The other three comefrom the penalty functions. This paper conducts an initial experimental studyon thirteen benchmark functions. A simplified version of CMODE is applied tosolving multi-objective optimization problems. Our initial experimental resultsconfirm our expectation that adding more helper functions could be useful. Theperformance of SMODE with more helper functions (four or six) is better thanthat with only two helper functions.
arxiv-12600-68 | Amodal Completion and Size Constancy in Natural Scenes | http://arxiv.org/pdf/1509.08147v2.pdf | author:Abhishek Kar, Shubham Tulsiani, João Carreira, Jitendra Malik category:cs.CV published:2015-09-27 summary:We consider the problem of enriching current object detection systems withveridical object sizes and relative depth estimates from a single image. Thereare several technical challenges to this, such as occlusions, lack ofcalibration data and the scale ambiguity between object size and distance.These have not been addressed in full generality in previous work. Here wepropose to tackle these issues by building upon advances in object recognitionand using recently created large-scale datasets. We first introduce the task ofamodal bounding box completion, which aims to infer the the full extent of theobject instances in the image. We then propose a probabilistic framework forlearning category-specific object size distributions from available annotationsand leverage these in conjunction with amodal completion to infer veridicalsizes in novel images. Finally, we introduce a focal length prediction approachthat exploits scene recognition to overcome inherent scaling ambiguities and wedemonstrate qualitative results on challenging real-world scenes.
arxiv-12600-69 | Joint Optimization of Masks and Deep Recurrent Neural Networks for Monaural Source Separation | http://arxiv.org/pdf/1502.04149v4.pdf | author:Po-Sen Huang, Minje Kim, Mark Hasegawa-Johnson, Paris Smaragdis category:cs.SD cs.AI cs.LG cs.MM published:2015-02-13 summary:Monaural source separation is important for many real world applications. Itis challenging because, with only a single channel of information available,without any constraints, an infinite number of solutions are possible. In thispaper, we explore joint optimization of masking functions and deep recurrentneural networks for monaural source separation tasks, including monaural speechseparation, monaural singing voice separation, and speech denoising. The jointoptimization of the deep recurrent neural networks with an extra masking layerenforces a reconstruction constraint. Moreover, we explore a discriminativecriterion for training neural networks to further enhance the separationperformance. We evaluate the proposed system on the TSP, MIR-1K, and TIMITdatasets for speech separation, singing voice separation, and speech denoisingtasks, respectively. Our approaches achieve 2.30--4.98 dB SDR gain compared toNMF models in the speech separation task, 2.30--2.48 dB GNSDR gain and4.32--5.42 dB GSIR gain compared to existing models in the singing voiceseparation task, and outperform NMF and DNN baselines in the speech denoisingtask.
arxiv-12600-70 | Supporting Regularized Logistic Regression Privately and Efficiently | http://arxiv.org/pdf/1510.00095v1.pdf | author:Wenfa Li, Hongzhe Liu, Peng Yang, Wei Xie category:cs.LG cs.CR q-bio.GN published:2015-10-01 summary:As one of the most popular statistical and machine learning models, logisticregression with regularization has found wide adoption in biomedicine, socialsciences, information technology, and so on. These domains often involve dataof human subjects that are contingent upon strict privacy regulations.Increasing concerns over data privacy make it more and more difficult tocoordinate and conduct large-scale collaborative studies, which typically relyon cross-institution data sharing and joint analysis. Our work here focuses onsafeguarding regularized logistic regression, a widely-used machine learningmodel in various disciplines while at the same time has not been investigatedfrom a data security and privacy perspective. We consider a common use scenarioof multi-institution collaborative studies, such as in the form of researchconsortia or networks as widely seen in genetics, epidemiology, socialsciences, etc. To make our privacy-enhancing solution practical, we demonstratea non-conventional and computationally efficient method leveraging distributingcomputing and strong cryptography to provide comprehensive protection overindividual-level and summary data. Extensive empirical evaluation on severalstudies validated the privacy guarantees, efficiency and scalability of ourproposal. We also discuss the practical implications of our solution forlarge-scale studies and applications from various disciplines, includinggenetic and biomedical studies, smart grid, network analysis, etc.
arxiv-12600-71 | Clamping Improves TRW and Mean Field Approximations | http://arxiv.org/pdf/1510.00087v1.pdf | author:Adrian Weller, Justin Domke category:cs.LG cs.AI stat.ML published:2015-10-01 summary:We examine the effect of clamping variables for approximate inference inundirected graphical models with pairwise relationships and discrete variables.For any number of variable labels, we demonstrate that clamping and summingapproximate sub-partition functions can lead only to a decrease in thepartition function estimate for TRW, and an increase for the naive mean fieldmethod, in each case guaranteeing an improvement in the approximation andbound. We next focus on binary variables, add the Bethe approximation toconsideration and examine ways to choose good variables to clamp, introducingnew methods. We show the importance of identifying highly frustrated cycles,and of checking the singleton entropy of a variable. We explore the value ofour methods by empirical analysis and draw lessons to guide practitioners.
arxiv-12600-72 | Describing Videos by Exploiting Temporal Structure | http://arxiv.org/pdf/1502.08029v5.pdf | author:Li Yao, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher Pal, Hugo Larochelle, Aaron Courville category:stat.ML cs.AI cs.CL cs.CV cs.LG published:2015-02-27 summary:Recent progress in using recurrent neural networks (RNNs) for imagedescription has motivated the exploration of their application for videodescription. However, while images are static, working with videos requiresmodeling their dynamic temporal structure and then properly integrating thatinformation into a natural language description. In this context, we propose anapproach that successfully takes into account both the local and globaltemporal structure of videos to produce descriptions. First, our approachincorporates a spatial temporal 3-D convolutional neural network (3-D CNN)representation of the short temporal dynamics. The 3-D CNN representation istrained on video action recognition tasks, so as to produce a representationthat is tuned to human motion and behavior. Second we propose a temporalattention mechanism that allows to go beyond local temporal modeling and learnsto automatically select the most relevant temporal segments given thetext-generating RNN. Our approach exceeds the current state-of-art for bothBLEU and METEOR metrics on the Youtube2Text dataset. We also present results ona new, larger and more challenging dataset of paired video and natural languagedescriptions.
arxiv-12600-73 | Hierarchy of Scales in Language Dynamics | http://arxiv.org/pdf/1505.00122v2.pdf | author:Richard A. Blythe category:physics.soc-ph cs.CL published:2015-05-01 summary:Methods and insights from statistical physics are finding an increasingvariety of applications where one seeks to understand the emergent propertiesof a complex interacting system. One such area concerns the dynamics oflanguage at a variety of levels of description, from the behaviour ofindividual agents learning simple artificial languages from each other, up tochanges in the structure of languages shared by large groups of speakers overhistorical timescales. In this Colloquium, we survey a hierarchy of scales atwhich language and linguistic behaviour can be described, along with the mainprogress in understanding that has been made at each of them---much of whichhas come from the statistical physics community. We argue that futuredevelopments may arise by linking the different levels of the hierarchytogether in a more coherent fashion, in particular where this allows moreeffective use of rich empirical data sets.
arxiv-12600-74 | General Dynamic Scene Reconstruction from Multiple View Video | http://arxiv.org/pdf/1509.09294v1.pdf | author:Armin Mustafa, Hansung Kim, Jean-Yves Guillemaut, Adrian Hilton category:cs.CV published:2015-09-30 summary:This paper introduces a general approach to dynamic scene reconstruction frommultiple moving cameras without prior knowledge or limiting constraints on thescene structure, appearance, or illumination. Existing techniques for dynamicscene reconstruction from multiple wide-baseline camera views primarily focuson accurate reconstruction in controlled environments, where the cameras arefixed and calibrated and background is known. These approaches are not robustfor general dynamic scenes captured with sparse moving cameras. Previousapproaches for outdoor dynamic scene reconstruction assume prior knowledge ofthe static background appearance and structure. The primary contributions ofthis paper are twofold: an automatic method for initial coarse dynamic scenesegmentation and reconstruction without prior knowledge of backgroundappearance or structure; and a general robust approach for joint segmentationrefinement and dense reconstruction of dynamic scenes from multiplewide-baseline static or moving cameras. Evaluation is performed on a variety ofindoor and outdoor scenes with cluttered backgrounds and multiple dynamicnon-rigid objects such as people. Comparison with state-of-the-art approachesdemonstrates improved accuracy in both multiple view segmentation and densereconstruction. The proposed approach also eliminates the requirement for priorknowledge of scene structure and appearance.
arxiv-12600-75 | Extended Formulations for Online Linear Bandit Optimization | http://arxiv.org/pdf/1311.5022v3.pdf | author:Shaona Ghosh, Adam Prugel-Bennett category:cs.LG cs.DS published:2013-11-20 summary:On-line linear optimization on combinatorial action sets (d-dimensionalactions) with bandit feedback, is known to have complexity in the order of thedimension of the problem. The exponential weighted strategy achieves the bestknown regret bound that is of the order of $d^{2}\sqrt{n}$ (where $d$ is thedimension of the problem, $n$ is the time horizon). However, such strategiesare provably suboptimal or computationally inefficient. The complexity isattributed to the combinatorial structure of the action set and the dearth ofefficient exploration strategies of the set. Mirror descent with entropicregularization function comes close to solving this problem by enforcing ameticulous projection of weights with an inherent boundary condition. Entropicregularization in mirror descent is the only known way of achieving alogarithmic dependence on the dimension. Here, we argue otherwise and recoverthe original intuition of exponential weighting by borrowing a technique fromdiscrete optimization and approximation algorithms called `extendedformulation'. Such formulations appeal to the underlying geometry of the setwith a guaranteed logarithmic dependence on the dimension underpinned by aninformation theoretic entropic analysis.
arxiv-12600-76 | A spatial compositional model (SCM) for linear unmixing and endmember uncertainty estimation | http://arxiv.org/pdf/1509.09243v1.pdf | author:Yuan Zhou, Anand Rangarajan, Paul Gader category:cs.CV published:2015-09-30 summary:The normal compositional model (NCM) has been extensively used inhyperspectral unmixing. However, most of the previous research has focused onestimation of endmembers and/or their variability. Also, little work hasemployed spatial information in NCM. In this paper, we show that NCM can beused for calculating the uncertainty of the estimated endmembers with spatialpriors incorporated for better unmixing. This results in a spatialcompositional model (SCM) which features (i) spatial priors that forceneighboring abundances to be similar based on their pixel similarity and (ii) aposterior that is obtained from a likelihood model which does not assume pixelindependence. The resulting algorithm turns out to be easy to implement andefficient to run. We compared SCM with current state-of-the-art algorithms onsynthetic and real images. The results show that SCM can in the main providemore accurate endmembers and abundances. Moreover, the estimated uncertaintycan serve as a prediction of endmember error under certain conditions.
arxiv-12600-77 | Generative Adversarial Networks in Estimation of Distribution Algorithms for Combinatorial Optimization | http://arxiv.org/pdf/1509.09235v1.pdf | author:Malte Probst category:cs.NE published:2015-09-30 summary:Estimation of Distribution Algorithms (EDAs) require flexible probabilitymodels that can be efficiently learned and sampled. Generative AdversarialNetworks (GAN) are generative neural networks which can be trained toimplicitly model the probability distribution of given data, and it is possibleto sample this distribution. We integrate a GAN into an EDA and evaluate theperformance of this system when solving combinatorial optimization problemswith a single objective. We use several standard benchmark problems and comparethe results to state-of-the-art multivariate EDAs. GAN-EDA doe not yieldcompetitive results - the GAN lacks the ability to quickly learn a goodapproximation of the probability distribution. A key reason seems to be thelarge amount of noise present in the first EDA generations.
arxiv-12600-78 | Fault Tolerance in Distributed Neural Computing | http://arxiv.org/pdf/1509.09199v1.pdf | author:Anton Kulakov, Mark Zwolinski, Jeff Reeve category:cs.NE cs.DC published:2015-09-30 summary:With the increasing complexity of computing systems, complete hardwarereliability can no longer be guaranteed. We need, however, to ensure overallsystem reliability. One of the most important features of artificial neuralnetworks is their intrinsic fault-tolerance. The aim of this work is toinvestigate whether such networks have features that can be applied to widercomputational systems. This paper presents an analysis, in both the learningand operational phases, of a distributed feed-forward neural network withdecentralised event-driven time management, which is insensitive tointermittent faults caused by unreliable communication or faulty hardwarecomponents. The learning rules used in the model are local in space and time,which allows efficient scalable distributed implementation. We investigate theoverhead caused by injected faults and analyse the sensitivity to limitedfailures in the computational hardware in different areas of the network.
arxiv-12600-79 | Deep Haar Scattering Networks | http://arxiv.org/pdf/1509.09187v1.pdf | author:Xiuyuan Cheng, Xu Chen, Stephane Mallat category:cs.LG published:2015-09-30 summary:An orthogonal Haar scattering transform is a deep network, computed with ahierarchy of additions, subtractions and absolute values, over pairs ofcoefficients. It provides a simple mathematical model for unsupervised deepnetwork learning. It implements non-linear contractions, which are optimizedfor classification, with an unsupervised pair matching algorithm, of polynomialcomplexity. A structured Haar scattering over graph data computes permutationinvariant representations of groups of connected points in the graph. If thegraph connectivity is unknown, unsupervised Haar pair learning can provide aconsistent estimation of connected dyadic groups of points. Classificationresults are given on image data bases, defined on regular grids or graphs, witha connectivity which may be known or unknown.
arxiv-12600-80 | Towards Trainable Media: Using Waves for Neural Network-Style Training | http://arxiv.org/pdf/1510.03776v1.pdf | author:Michiel Hermans, Thomas Van Vaerenbergh category:cs.NE physics.optics published:2015-09-30 summary:In this paper we study the concept of using the interaction between waves anda trainable medium in order to construct a matrix-vector multiplier. Inparticular we study such a device in the context of the backpropagationalgorithm, which is commonly used for training neural networks. Here, theweights of the connections between neurons are trained by multiplying a`forward' signal with a backwards propagating `error' signal. We show that thisconcept can be extended to trainable media, where the gradient for the localwave number is given by multiplying signal waves and error waves. We provide anumerical example of such a system with waves traveling freely in a trainablemedium, and we discuss a potential way to build such a device in an integratedphotonics chip.
arxiv-12600-81 | Learning From Missing Data Using Selection Bias in Movie Recommendation | http://arxiv.org/pdf/1509.09130v1.pdf | author:Claire Vernade, Olivier Cappé category:stat.ML cs.IR cs.LG cs.SI published:2015-09-30 summary:Recommending items to users is a challenging task due to the large amount ofmissing information. In many cases, the data solely consist of ratings or tagsvoluntarily contributed by each user on a very limited subset of the availableitems, so that most of the data of potential interest is actually missing.Current approaches to recommendation usually assume that the unobserved data ismissing at random. In this contribution, we provide statistical evidence thatexisting movie recommendation datasets reveal a significant positiveassociation between the rating of items and the propensity to select theseitems. We propose a computationally efficient variational approach that makesit possible to exploit this selection bias so as to improve the estimation ofratings from small populations of users. Results obtained with this approachapplied to neighborhood-based collaborative filtering illustrate its potentialfor improving the reliability of the recommendation.
arxiv-12600-82 | The "handedness" of language: Directional symmetry breaking of sign usage in words | http://arxiv.org/pdf/1509.09121v1.pdf | author:Md Izhar Ashraf, Sitabhra Sinha category:cs.CL published:2015-09-30 summary:Using large written corpora for many different scripts, we show that theoccurrence probability distributions of signs at the left and right ends ofwords have a distinct heterogeneous nature. Characterizing this asymmetry usingquantitative inequality measures, we show that the beginning of a word is lessrestrictive in sign usage than the end. The asymmetry is also seen inundeciphered inscriptions and we use this to infer the direction of writingwhich agrees with archaeological evidence. Unlike traditional investigations ofphonotactic constraints which focus on language-specific patterns, our studyreveals a property valid across languages and writing systems. As both languageand writing are unique aspects of our species, this universal signature mayreflect an innate feature of the human cognitive phenomenon.
arxiv-12600-83 | Online Object Tracking with Proposal Selection | http://arxiv.org/pdf/1509.09114v1.pdf | author:Yang Hua, Karteek Alahari, Cordelia Schmid category:cs.CV published:2015-09-30 summary:Tracking-by-detection approaches are some of the most successful objecttrackers in recent years. Their success is largely determined by the detectormodel they learn initially and then update over time. However, underchallenging conditions where an object can undergo transformations, e.g.,severe rotation, these methods are found to be lacking. In this paper, weaddress this problem by formulating it as a proposal selection task and makingtwo contributions. The first one is introducing novel proposals estimated fromthe geometric transformations undergone by the object, and building a richcandidate set for predicting the object location. The second one is devising anovel selection strategy using multiple cues, i.e., detection score andedgeness score computed from state-of-the-art object edges and motionboundaries. We extensively evaluate our approach on the visual object tracking2014 challenge and online tracking benchmark datasets, and show the bestperformance.
arxiv-12600-84 | Polish to English Statistical Machine Translation | http://arxiv.org/pdf/1510.00001v1.pdf | author:Krzysztof Wołk category:cs.CL stat.ML published:2015-09-30 summary:This research explores the effects of various training settings on a Polishto English Statistical Machine Translation system for spoken language. Variouselements of the TED, Europarl, and OPUS parallel text corpora were used as thebasis for training of language models, for development, tuning and testing ofthe translation system. The BLEU, NIST, METEOR and TER metrics were used toevaluate the effects of the data preparations on the translation results.
arxiv-12600-85 | Polish - English Speech Statistical Machine Translation Systems for the IWSLT 2013 | http://arxiv.org/pdf/1509.09097v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL stat.ML published:2015-09-30 summary:This research explores the effects of various training settings from Polishto English Statistical Machine Translation system for spoken language. Variouselements of the TED parallel text corpora for the IWSLT 2013 evaluationcampaign were used as the basis for training of language models, and fordevelopment, tuning and testing of the translation system. The BLEU, NIST,METEOR and TER metrics were used to evaluate the effects of data preparationson translation results. Our experiments included systems, which use stems andmorphological information on Polish words. We also conducted a deep analysis ofprovided Polish data as preparatory work for the automatic data correction andcleaning phase.
arxiv-12600-86 | A Sentence Meaning Based Alignment Method for Parallel Text Corpora Preparation | http://arxiv.org/pdf/1509.09093v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL cs.IR published:2015-09-30 summary:Text alignment is crucial to the accuracy of Machine Translation (MT)systems, some NLP tools or any other text processing tasks requiring bilingualdata. This research proposes a language independent sentence alignment approachbased on Polish (not position-sensitive language) to English experiments. Thisalignment approach was developed on the TED Talks corpus, but can be used forany text domain or language pair. The proposed approach implements variousheuristics for sentence recognition. Some of them value synonyms and semantictext structure analysis as a part of additional information. Minimization ofdata loss was ensured. The solution is compared to other sentence alignmentimplementations. Also an improvement in MT system score with text processedwith described tool is shown.
arxiv-12600-87 | Real-Time Statistical Speech Translation | http://arxiv.org/pdf/1509.09090v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL stat.ML published:2015-09-30 summary:This research investigates the Statistical Machine Translation approaches totranslate speech in real time automatically. Such systems can be used in apipeline with speech recognition and synthesis software in order to produce areal-time voice communication system between foreigners. We obtained three maindata sets from spoken proceedings that represent three different types of humanspeech. TED, Europarl, and OPUS parallel text corpora were used as the basisfor training of language models, for developmental tuning and testing of thetranslation system. We also conducted experiments involving part of speechtagging, compound splitting, linear language model interpolation, TrueCasingand morphosyntactic analysis. We evaluated the effects of variety of datapreparations on the translation results using the BLEU, NIST, METEOR and TERmetrics and tried to give answer which metric is most suitable for PL-ENlanguage pair.
arxiv-12600-88 | Moving Object Detection in Video Using Saliency Map and Subspace Learning | http://arxiv.org/pdf/1509.09089v1.pdf | author:Yanwei Pang, Li Ye, Xuelong Li, Jing Pan category:cs.CV published:2015-09-30 summary:Moving object detection is a key to intelligent video analysis. On the onehand, what moves is not only interesting objects but also noise and clutteredbackground. On the other hand, moving objects without rich texture are pronenot to be detected. So there are undesirable false alarms and missed alarms inmany algorithms of moving object detection. To reduce the false alarms andmissed alarms, in this paper, we propose to incorporate a saliency map into anincremental subspace analysis framework where the saliency map makes estimatedbackground has less chance than foreground (i.e., moving objects) to containsalient objects. The proposed objective function systematically takes accountinto the properties of sparsity, low-rank, connectivity, and saliency. Analternative minimization algorithm is proposed to seek the optimal solutions.Experimental results on the Perception Test Images Sequences demonstrate thatthe proposed method is effective in reducing false alarms and missed alarms.
arxiv-12600-89 | Enhanced Bilingual Evaluation Understudy | http://arxiv.org/pdf/1509.09088v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL stat.ML published:2015-09-30 summary:Our research extends the Bilingual Evaluation Understudy (BLEU) evaluationtechnique for statistical machine translation to make it more adjustable androbust. We intend to adapt it to resemble human evaluation more. We performexperiments to evaluate the performance of our technique against the primaryexisting evaluation methods. We describe and show the improvements it makesover existing methods as well as correlation to them. When human translatorstranslate a text, they often use synonyms, different word orders or style, andother similar variations. We propose an SMT evaluation technique that enhancesthe BLEU metric to consider variations such as those.
arxiv-12600-90 | Distributed Weighted Parameter Averaging for SVM Training on Big Data | http://arxiv.org/pdf/1509.09030v1.pdf | author:Ayan Das, Sourangshu Bhattacharya category:cs.LG published:2015-09-30 summary:Two popular approaches for distributed training of SVMs on big data areparameter averaging and ADMM. Parameter averaging is efficient but suffers fromloss of accuracy with increase in number of partitions, while ADMM in thefeature space is accurate but suffers from slow convergence. In this paper, wereport a hybrid approach called weighted parameter averaging (WPA), whichoptimizes the regularized hinge loss with respect to weights on parameters. Theproblem is shown to be same as solving SVM in a projected space. We alsodemonstrate an $O(\frac{1}{N})$ stability bound on final hypothesis given byWPA, using novel proof techniques. Experimental results on a variety of toy andreal world datasets show that our approach is significantly more accurate thanparameter averaging for high number of partitions. It is also seen the proposedmethod enjoys much faster convergence compared to ADMM in features space.
arxiv-12600-91 | Regret Lower Bound and Optimal Algorithm in Finite Stochastic Partial Monitoring | http://arxiv.org/pdf/1509.09011v1.pdf | author:Junpei Komiyama, Junya Honda, Hiroshi Nakagawa category:stat.ML cs.LG published:2015-09-30 summary:Partial monitoring is a general model for sequential learning with limitedfeedback formalized as a game between two players. In this game, the learnerchooses an action and at the same time the opponent chooses an outcome, thenthe learner suffers a loss and receives a feedback signal. The goal of thelearner is to minimize the total loss. In this paper, we study partialmonitoring with finite actions and stochastic outcomes. We derive a logarithmicdistribution-dependent regret lower bound that defines the hardness of theproblem. Inspired by the DMED algorithm (Honda and Takemura, 2010) for themulti-armed bandit problem, we propose PM-DMED, an algorithm that minimizes thedistribution-dependent regret. PM-DMED significantly outperformsstate-of-the-art algorithms in numerical experiments. To show the optimality ofPM-DMED with respect to the regret bound, we slightly modify the algorithm byintroducing a hinge function (PM-DMED-Hinge). Then, we derive an asymptoticallyoptimal regret upper bound of PM-DMED-Hinge that matches the lower bound.
arxiv-12600-92 | Learning without Recall: A Case for Log-Linear Learning | http://arxiv.org/pdf/1509.08990v1.pdf | author:Mohammad Amin Rahimian, Ali Jadbabaie category:cs.SI cs.LG cs.SY math.OC stat.ML published:2015-09-30 summary:We analyze a model of learning and belief formation in networks in whichagents follow Bayes rule yet they do not recall their history of pastobservations and cannot reason about how other agents' beliefs are formed. Theydo so by making rational inferences about their observations which include asequence of independent and identically distributed private signals as well asthe beliefs of their neighboring agents at each time. Fully rational agentswould successively apply Bayes rule to the entire history of observations. Thisleads to forebodingly complex inferences due to lack of knowledge about theglobal network structure that causes those observations. To address thesecomplexities, we consider a Learning without Recall model, which in addition toproviding a tractable framework for analyzing the behavior of rational agentsin social networks, can also provide a behavioral foundation for the variety ofnon-Bayesian update rules in the literature. We present the implications ofvarious choices for time-varying priors of such agents and how this choiceaffects learning and its rate.
arxiv-12600-93 | Symbol Emergence in Robotics: A Survey | http://arxiv.org/pdf/1509.08973v1.pdf | author:Tadahiro Taniguchi, Takayuki Nagai, Tomoaki Nakamura, Naoto Iwahashi, Tetsuya Ogata, Hideki Asoh category:cs.AI cs.CL cs.CV cs.RO published:2015-09-29 summary:Humans can learn the use of language through physical interaction with theirenvironment and semiotic communication with other people. It is very importantto obtain a computational understanding of how humans can form a symbol systemand obtain semiotic skills through their autonomous mental development.Recently, many studies have been conducted on the construction of roboticsystems and machine-learning methods that can learn the use of language throughembodied multimodal interaction with their environment and other systems.Understanding human social interactions and developing a robot that cansmoothly communicate with human users in the long term, requires anunderstanding of the dynamics of symbol systems and is crucially important. Theembodied cognition and social interaction of participants gradually change asymbol system in a constructive manner. In this paper, we introduce a field ofresearch called symbol emergence in robotics (SER). SER is a constructiveapproach towards an emergent symbol system. The emergent symbol system issocially self-organized through both semiotic communications and physicalinteractions with autonomous cognitive developmental agents, i.e., humans anddevelopmental robots. Specifically, we describe some state-of-art researchtopics concerning SER, e.g., multimodal categorization, word discovery, and adouble articulation analysis, that enable a robot to obtain words and theirembodied meanings from raw sensory--motor information, including visualinformation, haptic information, auditory information, and acoustic speechsignals, in a totally unsupervised manner. Finally, we suggest futuredirections of research in SER.
arxiv-12600-94 | VLSI Implementation of Deep Neural Network Using Integral Stochastic Computing | http://arxiv.org/pdf/1509.08972v1.pdf | author:Arash Ardakani, François Leduc-Primeau, Naoya Onizawa, Takahiro Hanyu, Warren J. Gross category:cs.NE cs.AR published:2015-09-29 summary:The hardware implementation of deep neural networks (DNNs) has recentlyreceived tremendous attention: many applications in fact require high-speedoperations that suit a hardware implementation. However, numerous elements andcomplex interconnections are usually required, leading to a large areaoccupation and copious power consumption. Stochastic computing has shownpromising results for low-power area-efficient hardware implementations, eventhough existing stochastic algorithms require long streams that cause longlatencies. In this paper, we propose an integer form of stochastic computationand introduce some elementary circuits. We then propose an efficientimplementation of a DNN based on integral stochastic computing. The proposedarchitecture uses integer stochastic streams and a modified Finite StateMachine-based tanh function to perform computations and even reduce the latencycompared to conventional stochastic computation. The proposed architecture hasbeen implemented on a Virtex7 FPGA, resulting in 44.96% and 62.36% averagereductions in area and latency compared to the best reported architecture inliterature. We also synthesize the circuits in a 65 nm CMOS technology and showthat they can tolerate a fault rate of up to 20% on some computations whentiming violations are allowed to occur, resulting in power savings. Thefault-tolerance property of the proposed architectures make them suitable forinherently unreliable advanced process technologies such as memristortechnology.
arxiv-12600-95 | Light Field Reconstruction Using Shearlet Transform | http://arxiv.org/pdf/1509.08969v1.pdf | author:Suren Vagharshakyan, Robert Bregovic, Atanas Gotchev category:cs.CV published:2015-09-29 summary:In this article we develop an image based rendering technique based on lightfield reconstruction from a limited set of perspective views acquired bycameras. Our approach utilizes sparse representation of epipolar-plane imagesin a directionally sensitive transform domain, obtained by an adapted discreteshearlet transform. The used iterative thresholding algorithm provideshigh-quality reconstruction results for relatively big disparities betweenneighboring views. The generated densely sampled light field of a given 3Dscene is thus suitable for all applications which requires light fieldreconstruction. The proposed algorithm is compared favorably against state ofthe art depth image based rendering techniques.
arxiv-12600-96 | Polish -English Statistical Machine Translation of Medical Texts | http://arxiv.org/pdf/1509.08909v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL cs.IR stat.ML published:2015-09-29 summary:This new research explores the effects of various training methods on aPolish to English Statistical Machine Translation system for medical texts.Various elements of the EMEA parallel text corpora from the OPUS project wereused as the basis for training of phrase tables and language models and fordevelopment, tuning and testing of the translation system. The BLEU, NIST,METEOR, RIBES and TER metrics have been used to evaluate the effects of varioussystem and data preparations on translation results. Our experiments includedsystems that used POS tagging, factored phrase models, hierarchical models,syntactic taggers, and many different alignment methods. We also conducted adeep analysis of Polish data as preparatory work for automatic data correctionsuch as true casing and punctuation normalization phase.
arxiv-12600-97 | Scalable Nonlinear Embeddings for Semantic Category-based Image Retrieval | http://arxiv.org/pdf/1509.08902v1.pdf | author:Gaurav Sharma, Bernt Schiele category:cs.CV published:2015-09-29 summary:We propose a novel algorithm for the task of supervised discriminativedistance learning by nonlinearly embedding vectors into a low dimensionalEuclidean space. We work in the challenging setting where supervision is withconstraints on similar and dissimilar pairs while training. The proposed methodis derived by an approximate kernelization of a linear Mahalanobis-likedistance metric learning algorithm and can also be seen as a kernel neuralnetwork. The number of model parameters and test time evaluation complexity ofthe proposed method are O(dD) where D is the dimensionality of the inputfeatures and d is the dimension of the projection space - this is in contrastto the usual kernelization methods as, unlike them, the complexity does notscale linearly with the number of training examples. We propose a stochasticgradient based learning algorithm which makes the method scalable (w.r.t. thenumber of training examples), while being nonlinear. We train the method withup to half a million training pairs of 4096 dimensional CNN features. We giveempirical comparisons with relevant baselines on seven challenging datasets forthe task of low dimensional semantic category based image retrieval.
arxiv-12600-98 | Bilinear CNN Models for Fine-grained Visual Recognition | http://arxiv.org/pdf/1504.07889v3.pdf | author:Tsung-Yu Lin, Aruni RoyChowdhury, Subhransu Maji category:cs.CV published:2015-04-29 summary:We propose bilinear models, a recognition architecture that consists of twofeature extractors whose outputs are multiplied using outer product at eachlocation of the image and pooled to obtain an image descriptor. Thisarchitecture can model local pairwise feature interactions in a translationallyinvariant manner which is particularly useful for fine-grained categorization.It also generalizes various orderless texture descriptors such as the Fishervector, VLAD and O2P. We present experiments with bilinear models where thefeature extractors are based on convolutional neural networks. The bilinearform simplifies gradient computation and allows end-to-end training of bothnetworks using image labels only. Using networks initialized from the ImageNetdataset followed by domain specific fine-tuning we obtain 84.1% accuracy of theCUB-200-2011 dataset requiring only category labels at training time. Wepresent experiments and visualizations that analyze the effects of fine-tuningand the choice two networks on the speed and accuracy of the models. Resultsshow that the architecture compares favorably to the existing state of the arton a number of fine-grained datasets while being substantially simpler andeasier to train. Moreover, our most accurate model is fairly efficient runningat 8 frames/sec on a NVIDIA Tesla K40 GPU. The source code for the completesystem will be made available at http://vis-www.cs.umass.edu/bcnn.
arxiv-12600-99 | A Semi-Supervised Method for Predicting Cancer Survival Using Incomplete Clinical Data | http://arxiv.org/pdf/1509.08888v1.pdf | author:Hamid Reza Hassanzadeh, John H. Phan, May D. Wang category:cs.LG published:2015-09-29 summary:Prediction of survival for cancer patients is an open area of research.However, many of these studies focus on datasets with a large number ofpatients. We present a novel method that is specifically designed to addressthe challenge of data scarcity, which is often the case for cancer datasets.Our method is able to use unlabeled data to improve classification by adoptinga semi-supervised training approach to learn an ensemble classifier. Theresults of applying our method to three cancer datasets show the promise ofsemi-supervised learning for prediction of cancer survival.
arxiv-12600-100 | Building Subject-aligned Comparable Corpora and Mining it for Truly Parallel Sentence Pairs | http://arxiv.org/pdf/1509.08881v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL cs.IR stat.ML published:2015-09-29 summary:Parallel sentences are a relatively scarce but extremely useful resource formany applications including cross-lingual retrieval and statistical machinetranslation. This research explores our methodology for mining such data frompreviously obtained comparable corpora. The task is highly practical sincenon-parallel multilingual data exist in far greater quantities than parallelcorpora, but parallel sentences are a much more useful resource. Here wepropose a web crawling method for building subject-aligned comparable corporafrom Wikipedia articles. We also introduce a method for extracting trulyparallel sentences that are filtered out from noisy or just comparable sentencepairs. We describe our implementation of a specialized tool for this task aswell as training and adaption of a machine translation system that supplies ourfilter with additional information about the similarity of comparable sentencepairs.
arxiv-12600-101 | Polish - English Speech Statistical Machine Translation Systems for the IWSLT 2014 | http://arxiv.org/pdf/1509.08874v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL published:2015-09-29 summary:This research explores effects of various training settings between Polishand English Statistical Machine Translation systems for spoken language.Various elements of the TED parallel text corpora for the IWSLT 2014 evaluationcampaign were used as the basis for training of language models, and fordevelopment, tuning and testing of the translation system as well as Wikipediabased comparable corpora prepared by us. The BLEU, NIST, METEOR and TER metricswere used to evaluate the effects of data preparations on translation results.Our experiments included systems, which use lemma and morphological informationon Polish words. We also conducted a deep analysis of provided Polish data aspreparatory work for the automatic data correction and cleaning phase.
arxiv-12600-102 | On-the-Fly Learning in a Perpetual Learning Machine | http://arxiv.org/pdf/1509.00913v3.pdf | author:Andrew J. R. Simpson category:cs.LG 68Txx published:2015-09-03 summary:Despite the promise of brain-inspired machine learning, deep neural networks(DNN) have frustratingly failed to bridge the deceptively large gap betweenlearning and memory. Here, we introduce a Perpetual Learning Machine; a newtype of DNN that is capable of brain-like dynamic 'on the fly' learning becauseit exists in a self-supervised state of Perpetual Stochastic Gradient Descent.Thus, we provide the means to unify learning and memory within a machinelearning framework. We also explore the elegant duality of abstraction andsynthesis: the Yin and Yang of deep learning.
arxiv-12600-103 | Automatically Segmenting Oral History Transcripts | http://arxiv.org/pdf/1509.08842v1.pdf | author:Ryan Shaw category:cs.CL published:2015-09-29 summary:Dividing oral histories into topically coherent segments can make them moreaccessible online. People regularly make judgments about where coherentsegments can be extracted from oral histories. But making these judgments canbe taxing, so automated assistance is potentially attractive to speed the taskof extracting segments from open-ended interviews. When different people areasked to extract coherent segments from the same oral histories, they often donot agree about precisely where such segments begin and end. This low agreementmakes the evaluation of algorithmic segmenters challenging, but there is reasonto believe that for segmenting oral history transcripts, some approaches aremore promising than others. The BayesSeg algorithm performs slightly betterthan TextTiling, while TextTiling does not perform significantly better than auniform segmentation. BayesSeg might be used to suggest boundaries to someonesegmenting oral histories, but this segmentation task needs to be betterdefined.
arxiv-12600-104 | Non-parametric PSF estimation from celestial transit solar images using blind deconvolution | http://arxiv.org/pdf/1412.6279v3.pdf | author:Adriana Gonzalez, Véronique Delouille, Laurent Jacques category:cs.CV astro-ph.SR published:2014-12-19 summary:Context: Characterization of instrumental effects in astronomical imaging isimportant in order to extract accurate physical information from theobservations. The measured image in a real optical instrument is usuallyrepresented by the convolution of an ideal image with a Point Spread Function(PSF). Additionally, the image acquisition process is also contaminated byother sources of noise (read-out, photon-counting). The problem of estimatingboth the PSF and a denoised image is called blind deconvolution and isill-posed. Aims: We propose a blind deconvolution scheme that relies on imageregularization. Contrarily to most methods presented in the literature, ourmethod does not assume a parametric model of the PSF and can thus be applied toany telescope. Methods: Our scheme uses a wavelet analysis prior model on the image and weakassumptions on the PSF. We use observations from a celestial transit, where theocculting body can be assumed to be a black disk. These constraints allow us toretain meaningful solutions for the filter and the image, eliminating trivial,translated and interchanged solutions. Under an additive Gaussian noiseassumption, they also enforce noise canceling and avoid reconstructionartifacts by promoting the whiteness of the residual between the blurredobservations and the cleaned data. Results: Our method is applied to synthetic and experimental data. The PSF isestimated for the SECCHI/EUVI instrument using the 2007 Lunar transit, and forSDO/AIA using the 2012 Venus transit. Results show that the proposednon-parametric blind deconvolution method is able to estimate the core of thePSF with a similar quality to parametric methods proposed in the literature. Wealso show that, if these parametric estimations are incorporated in theacquisition model, the resulting PSF outperforms both the parametric andnon-parametric methods.
arxiv-12600-105 | How to Formulate and Solve Statistical Recognition and Learning Problems | http://arxiv.org/pdf/1509.08830v1.pdf | author:Michail Schlesinger, Evgeniy Vodolazskiy category:cs.LG published:2015-09-29 summary:We formulate problems of statistical recognition and learning in a commonframework of complex hypothesis testing. Based on arguments from multi-criteriaoptimization, we identify strategies that are improper for solving theseproblems and derive a common form of the remaining strategies. We show thatsome widely used approaches to recognition and learning are improper in thissense. We then propose a generalized formulation of the recognition andlearning problem which embraces the whole range of sizes of the learningsample, including the zero size. Learning becomes a special case of recognitionwithout learning. We define the concept of closest to optimal strategy, being asolution to the formulated problem, and describe a technique for finding such astrategy. On several illustrative cases, the strategy is shown to be superiorto the widely used learning methods based on maximal likelihood estimation.
arxiv-12600-106 | Representation Benefits of Deep Feedforward Networks | http://arxiv.org/pdf/1509.08101v2.pdf | author:Matus Telgarsky category:cs.LG cs.NE published:2015-09-27 summary:This note provides a family of classification problems, indexed by a positiveinteger $k$, where all shallow networks with fewer than exponentially (in $k$)many nodes exhibit error at least $1/6$, whereas a deep network with 2 nodes ineach of $2k$ layers achieves zero error, as does a recurrent network with 3distinct nodes iterated $k$ times. The proof is elementary, and the networksare standard feedforward networks with ReLU (Rectified Linear Unit)nonlinearities.
arxiv-12600-107 | Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning | http://arxiv.org/pdf/1509.08731v1.pdf | author:Shakir Mohamed, Danilo Jimenez Rezende category:stat.ML cs.AI cs.LG published:2015-09-29 summary:The mutual information is a core statistical quantity that has applicationsin all areas of machine learning, whether this is in training of density modelsover multiple data modalities, in maximising the efficiency of noisytransmission channels, or when learning behaviour policies for exploration byartificial agents. Most learning algorithms that involve optimisation of themutual information rely on the Blahut-Arimoto algorithm --- an enumerativealgorithm with exponential complexity that is not suitable for modern machinelearning applications. This paper provides a new approach for scalableoptimisation of the mutual information by merging techniques from variationalinference and deep learning. We develop our approach by focusing on the problemof intrinsically-motivated learning, where the mutual information forms thedefinition of a well-known internal drive known as empowerment. Using avariational lower bound on the mutual information, combined with convolutionalnetworks for handling visual input streams, we develop a stochasticoptimisation algorithm that allows for scalable information maximisation andempowerment-based reasoning directly from pixels to actions.
arxiv-12600-108 | Retinex filtering of foggy images: generation of a bulk set with selection and ranking | http://arxiv.org/pdf/1509.08715v1.pdf | author:Roberto Marazzato, Amelia Carolina Sparavigna category:cs.CV published:2015-09-29 summary:In this paper we are proposing the use of GIMP Retinex, a filter of the GNUImage Manipulation Program, for enhancing foggy images. This filter involvesadjusting four different parameters to find the output image which has to bepreferred according to some specific purposes. Aiming to obtain a processing,which is able of choosing automatically the best image from a given set, we areproposing a method for the generation a bulk set of GIMP Retinex filteredimages and a preliminary approach for selecting and ranking them.
arxiv-12600-109 | DCTNet : A Simple Learning-free Approach for Face Recognition | http://arxiv.org/pdf/1507.02049v3.pdf | author:Cong Jie Ng, Andrew Beng Jin Teoh category:cs.CV published:2015-07-08 summary:PCANet was proposed as a lightweight deep learning network that mainlyleverages Principal Component Analysis (PCA) to learn multistage filter banksfollowed by binarization and block-wise histograming. PCANet was shown workedsurprisingly well in various image classification tasks. However, PCANet isdata-dependence hence inflexible. In this paper, we proposed adata-independence network, dubbed DCTNet for face recognition in which we adoptDiscrete Cosine Transform (DCT) as filter banks in place of PCA. This ismotivated by the fact that 2D DCT basis is indeed a good approximation for highranked eigenvectors of PCA. Both 2D DCT and PCA resemble a kind of modulatedsine-wave patterns, which can be perceived as a bandpass filter bank. DCTNet isfree from learning as 2D DCT bases can be computed in advance. Besides that, wealso proposed an effective method to regulate the block-wise histogram featurevector of DCTNet for robustness. It is shown to provide surprising performanceboost when the probe image is considerably different in appearance from thegallery image. We evaluate the performance of DCTNet extensively on a number ofbenchmark face databases and being able to achieve on par with or often betteraccuracy performance than PCANet.
arxiv-12600-110 | Adaptive-treed bandits | http://arxiv.org/pdf/1302.2489v4.pdf | author:Adam D. Bull category:math.ST stat.ML stat.TH published:2013-02-11 summary:We describe a novel algorithm for noisy global optimisation andcontinuum-armed bandits, with good convergence properties over any continuousreward function having finitely many polynomial maxima. Over such functions,our algorithm achieves square-root regret in bandits, and inverse-square-rooterror in optimisation, without prior information. Our algorithm works byreducing these problems to tree-armed bandits, and we also provide new resultsin this setting. We show it is possible to adaptively combine multiple trees soas to minimise the regret, and also give near-matching lower bounds on theregret in terms of the zooming dimension.
arxiv-12600-111 | Censoring Diffusion for Harvesting WSNs | http://arxiv.org/pdf/1509.08660v1.pdf | author:Jesus Fernandez-Bes, Rocío Arroyo-Valles, Jerónimo Arenas-García, Jesús Cid-Sueiro category:cs.SY cs.MA math.OC stat.ML published:2015-09-29 summary:In this paper, we analyze energy-harvesting adaptive diffusion networks for adistributed estimation problem. In order to wisely manage the available energyresources, we propose a scheme where a censoring algorithm is jointly appliedover the diffusion strategy. An energy-aware variation of a diffusion algorithmis used, and a new way of measuring the relevance of the estimates in diffusionnetworks is proposed in order to apply a subsequent censoring mechanism.Simulation results show the potential benefit of integrating censoring schemesin energy-constrained diffusion networks.
arxiv-12600-112 | Long-Range Trajectories from Global and Local Motion Representations | http://arxiv.org/pdf/1509.08647v1.pdf | author:Eduardo M. Pereira, Jaime S. Cardoso, Ricardo Morla category:cs.CV published:2015-09-29 summary:Motion is a fundamental cue for scene analysis and human activity understan-ding in videos. It can be encoded in trajectories for tracking objects and foraction recognition, or in form of flow to address behaviour analysis in crowdedscenes. Each approach can only be applied on limited scenarios. We propose amotion-based system that represents the spatial and temporal features of theflow in terms of long-range trajectories. The novelty resides on the systemformulation, its generic approach to handle scene variability and motionvariations, motion integration from local and global representations, and theresulting long-range trajectories that overcome trajectory-based approachproblems. We report the results and conclusions that state its pertinence ondifferent scenarios, comparing and correlating the extracted trajectories ofindividual pedestrians, manually annotated. We also propose an evaluationframework and stress the diverse system characteristics that can be used forhuman activity tasks, namely on motion segmentation.
arxiv-12600-113 | Neural-based machine translation for medical text domain. Based on European Medicines Agency leaflet texts | http://arxiv.org/pdf/1509.08644v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL cs.CY cs.NE stat.ML published:2015-09-29 summary:The quality of machine translation is rapidly evolving. Today one can findseveral machine translation systems on the web that provide reasonabletranslations, although the systems are not perfect. In some specific domains,the quality may decrease. A recently proposed approach to this domain is neuralmachine translation. It aims at building a jointly-tuned single neural networkthat maximizes translation performance, a very different approach fromtraditional statistical machine translation. Recently proposed neural machinetranslation models often belong to the encoder-decoder family in which a sourcesentence is encoded into a fixed length vector that is, in turn, decoded togenerate a translation. The present research examines the effects of differenttraining methods on a Polish-English Machine Translation system used formedical data. The European Medicines Agency parallel text corpus was used asthe basis for training of neural and statistical network-based translationsystems. The main machine translation evaluation metrics have also been used inanalysis of the systems. A comparison and implementation of a real-time medicaltranslator is the main focus of our experiments.
arxiv-12600-114 | Tuned and GPU-accelerated parallel data mining from comparable corpora | http://arxiv.org/pdf/1509.08639v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL cs.AI cs.DS published:2015-09-29 summary:The multilingual nature of the world makes translation a crucial requirementtoday. Parallel dictionaries constructed by humans are a widely-availableresource, but they are limited and do not provide enough coverage for goodquality translation purposes, due to out-of-vocabulary words and neologisms.This motivates the use of statistical translation systems, which areunfortunately dependent on the quantity and quality of training data. Such hasa very limited availability especially for some languages and very narrow textdomains. Is this research we present our improvements to Yalign miningmethodology by reimplementing the comparison algorithm, introducing a tuningscripts and by improving performance using GPU computing acceleration. Theexperiments are conducted on various text domains and bi-data is extracted fromthe Wikipedia dumps.
arxiv-12600-115 | Learning dynamic Boltzmann machines with spike-timing dependent plasticity | http://arxiv.org/pdf/1509.08634v1.pdf | author:Takayuki Osogami, Makoto Otsuka category:cs.NE cs.AI cs.LG stat.ML published:2015-09-29 summary:We propose a particularly structured Boltzmann machine, which we refer to asa dynamic Boltzmann machine (DyBM), as a stochastic model of amulti-dimensional time-series. The DyBM can have infinitely many layers ofunits but allows exact and efficient inference and learning when its parametershave a proposed structure. This proposed structure is motivated by postulatesand observations, from biological neural networks, that the synaptic weight isstrengthened or weakened, depending on the timing of spikes (i.e., spike-timingdependent plasticity or STDP). We show that the learning rule of updating theparameters of the DyBM in the direction of maximizing the likelihood of giventime-series can be interpreted as STDP with long term potentiation and longterm depression. The learning rule has a guarantee of convergence and can beperformed in a distributed matter (i.e., local in space) with limited memory(i.e., local in time).
arxiv-12600-116 | Semantics, Representations and Grammars for Deep Learning | http://arxiv.org/pdf/1509.08627v1.pdf | author:David Balduzzi category:cs.LG cs.NE stat.ML published:2015-09-29 summary:Deep learning is currently the subject of intensive study. However,fundamental concepts such as representations are not formally defined --researchers "know them when they see them" -- and there is no common languagefor describing and analyzing algorithms. This essay proposes an abstractframework that identifies the essential features of current practice and mayprovide a foundation for future developments. The backbone of almost all deep learning algorithms is backpropagation, whichis simply a gradient computation distributed over a neural network. The mainingredients of the framework are thus, unsurprisingly: (i) game theory, toformalize distributed optimization; and (ii) communication protocols, to trackthe flow of zeroth and first-order information. The framework allows naturaldefinitions of semantics (as the meaning encoded in functions), representations(as functions whose semantics is chosen to optimized a criterion) and grammars(as communication protocols equipped with first-order convergence guarantees). Much of the essay is spent discussing examples taken from the literature. Theultimate aim is to develop a graphical language for describing the structure ofdeep learning algorithms that backgrounds the details of the optimizationprocedure and foregrounds how the components interact. Inspiration is takenfrom probabilistic graphical models and factor graphs, which capture theessential structural features of multivariate distributions.
arxiv-12600-117 | Tractable Fully Bayesian Inference via Convex Optimization and Optimal Transport Theory | http://arxiv.org/pdf/1509.08582v1.pdf | author:Sanggyun Kim, Diego Mesa, Rui Ma, Todd P. Coleman category:stat.ML published:2015-09-29 summary:We consider the problem of transforming samples from one continuous sourcedistribution into samples from another target distribution. We demonstrate withoptimal transport theory that when the source distribution can be easilysampled from and the target distribution is log-concave, this can be tractablysolved with convex optimization. We show that a special case of this, when thesource is the prior and the target is the posterior, is Bayesian inference.Here, we can tractably calculate the normalization constant and draw posteriori.i.d. samples. Remarkably, our Bayesian tractability criterion is simply logconcavity of the prior and likelihood: the same criterion for tractablecalculation of the maximum a posteriori point estimate. With simulated data, wedemonstrate how we can attain the Bayes risk in simulations. With physiologicdata, we demonstrate improvements over point estimation in intensive care unitoutcome prediction and electroencephalography-based sleep staging.
arxiv-12600-118 | Recurrent Network Models for Human Dynamics | http://arxiv.org/pdf/1508.00271v2.pdf | author:Katerina Fragkiadaki, Sergey Levine, Panna Felsen, Jitendra Malik category:cs.CV published:2015-08-02 summary:We propose the Encoder-Recurrent-Decoder (ERD) model for recognition andprediction of human body pose in videos and motion capture. The ERD model is arecurrent neural network that incorporates nonlinear encoder and decodernetworks before and after recurrent layers. We test instantiations of ERDarchitectures in the tasks of motion capture (mocap) generation, body poselabeling and body pose forecasting in videos. Our model handles mocap trainingdata across multiple subjects and activity domains, and synthesizes novelmotions while avoid drifting for long periods of time. For human pose labeling,ERD outperforms a per frame body part detector by resolving left-right bodypart confusions. For video pose forecasting, ERD predicts body jointdisplacements across a temporal horizon of 400ms and outperforms a first ordermotion model based on optical flow. ERDs extend previous Long Short Term Memory(LSTM) models in the literature to jointly learn representations and theirdynamics. Our experiments show such representation learning is crucial for bothlabeling and prediction in space-time. We find this is a distinguishing featurebetween the spatio-temporal visual domain in comparison to 1D text, speech orhandwriting, where straightforward hard coded representations have shownexcellent results when directly combined with recurrent units.
arxiv-12600-119 | Parallel Stochastic Gradient Markov Chain Monte Carlo for Matrix Factorisation Models | http://arxiv.org/pdf/1506.01418v2.pdf | author:Umut Şimşekli, Hazal Koptagel, Hakan Güldaş, A. Taylan Cemgil, Figen Öztoprak, Ş. İlker Birbil category:stat.ML published:2015-06-03 summary:For large matrix factorisation problems, we develop a distributed MarkovChain Monte Carlo (MCMC) method based on stochastic gradient Langevin dynamics(SGLD) that we call Parallel SGLD (PSGLD). PSGLD has very favourable scalingproperties with increasing data size and is comparable in terms ofcomputational requirements to optimisation methods based on stochastic gradientdescent. PSGLD achieves high performance by exploiting the conditionalindependence structure of the MF models to sub-sample data in a systematicmanner as to allow parallelisation and distributed computation. We provide aconvergence proof of the algorithm and verify its superior performance onvarious architectures such as Graphics Processing Units, shared memorymulti-core systems and multi-computer clusters.
arxiv-12600-120 | Efficient Empowerment | http://arxiv.org/pdf/1509.08455v1.pdf | author:Maximilian Karl, Justin Bayer, Patrick van der Smagt category:stat.ML cs.LG published:2015-09-28 summary:Empowerment quantifies the influence an agent has on its environment. This isformally achieved by the maximum of the expected KL-divergence between thedistribution of the successor state conditioned on a specific action and adistribution where the actions are marginalised out. This is a naturalcandidate for an intrinsic reward signal in the context of reinforcementlearning: the agent will place itself in a situation where its action havemaximum stability and maximum influence on the future. The limiting factor sofar has been the computational complexity of the method: the only way ofcalculation has so far been a brute force algorithm, reducing the applicabilityof the method to environments with a small set discrete states. In this work,we propose to use an efficient approximation for marginalising out the actionsin the case of continuous environments. This allows fast evaluation ofempowerment, paving the way towards challenging environments such as real worldrobotics. The method is presented on a pendulum swing up problem.
arxiv-12600-121 | Hyper-Fisher Vectors for Action Recognition | http://arxiv.org/pdf/1509.08439v1.pdf | author:Sanath Narayan, Kalpathi R. Ramakrishnan category:cs.CV published:2015-09-28 summary:In this paper, a novel encoding scheme combining Fisher vector andbag-of-words encodings has been proposed for recognizing action in videos. Theproposed Hyper-Fisher vector encoding is sum of local Fisher vectors which arecomputed based on the traditional Bag-of-Words (BoW) encoding. Thus, theproposed encoding is simple and yet an effective representation over thetraditional Fisher Vector encoding. By extensive evaluation on challengingaction recognition datasets, viz., Youtube, Olympic Sports, UCF50 and HMDB51,we show that the proposed Hyper-Fisher Vector encoding improves the recognitionperformance by around 2-3% compared to the improved Fisher Vector encoding. Wealso perform experiments to show that the performance of the Hyper-FisherVector is robust to the dictionary size of the BoW encoding.
arxiv-12600-122 | Pose Induction for Novel Object Categories | http://arxiv.org/pdf/1505.00066v2.pdf | author:Shubham Tulsiani, João Carreira, Jitendra Malik category:cs.CV published:2015-05-01 summary:We address the task of predicting pose for objects of unannotated objectcategories from a small seed set of annotated object classes. We present ageneralized classifier that can reliably induce pose given a single instance ofa novel category. In case of availability of a large collection of novelinstances, our approach then jointly reasons over all instances to improve theinitial estimates. We empirically validate the various components of ouralgorithm and quantitatively show that our method produces reliable poseestimates. We also show qualitative results on a diverse set of classes andfurther demonstrate the applicability of our system for learning shape modelsof novel object classes.
arxiv-12600-123 | A Review of Relational Machine Learning for Knowledge Graphs | http://arxiv.org/pdf/1503.00759v3.pdf | author:Maximilian Nickel, Kevin Murphy, Volker Tresp, Evgeniy Gabrilovich category:stat.ML cs.LG published:2015-03-02 summary:Relational machine learning studies methods for the statistical analysis ofrelational, or graph-structured, data. In this paper, we provide a review ofhow such statistical models can be "trained" on large knowledge graphs, andthen used to predict new facts about the world (which is equivalent topredicting new edges in the graph). In particular, we discuss two fundamentallydifferent kinds of statistical relational models, both of which can scale tomassive datasets. The first is based on latent feature models such as tensorfactorization and multiway neural networks. The second is based on miningobservable patterns in the graph. We also show how to combine these latent andobservable models to get improved modeling power at decreased computationalcost. Finally, we discuss how such statistical models of graphs can be combinedwith text-based information extraction methods for automatically constructingknowledge graphs from the Web. To this end, we also discuss Google's KnowledgeVault project as an example of such combination.
arxiv-12600-124 | Learning Concept Embeddings with Combined Human-Machine Expertise | http://arxiv.org/pdf/1509.07479v2.pdf | author:Michael J. Wilber, Iljung S. Kwak, David Kriegman, Serge Belongie category:cs.CV published:2015-09-24 summary:This paper presents our work on "SNaCK," a low-dimensional concept embeddingalgorithm that combines human expertise with automatic machine similaritykernels. Both parts are complimentary: human insight can capture relationshipsthat are not apparent from the object's visual similarity and the machine canhelp relieve the human from having to exhaustively specify many constraints. Weshow that our SNaCK embeddings are useful in several tasks: distinguishingprime and nonprime numbers on MNIST, discovering labeling mistakes in theCaltech UCSD Birds (CUB) dataset with the help of deep-learned features,creating training datasets for bird classifiers, capturing subjective humantaste on a new dataset of 10,000 foods, and qualitatively exploring anunstructured set of pictographic characters. Comparisons with thestate-of-the-art in these tasks show that SNaCK produces better conceptembeddings that require less human supervision than the leading methods.
arxiv-12600-125 | Quantile Search: A Distance-Penalized Active Learning Algorithm for Spatial Sampling | http://arxiv.org/pdf/1509.08387v1.pdf | author:John Lipor, Laura Balzano, Branko Kerkez, Don Scavia category:stat.ML cs.LG 62L05 G.3; H.3.3 published:2015-09-28 summary:Adaptive sampling theory has shown that, with proper assumptions on thesignal class, algorithms exist to reconstruct a signal in $\mathbb{R}^{d}$ withan optimal number of samples. We generalize this problem to when the cost ofsampling is not only the number of samples but also the distance traveledbetween samples. This is motivated by our work studying regions of low oxygenconcentration in the Great Lakes. We show that for one-dimensional thresholdclassifiers, a tradeoff between number of samples and distance traveled can beachieved using a generalization of binary search, which we refer to as quantilesearch. We derive the expected total sampling time for noiseless measurementsand the expected number of samples for an extension to the noisy case. Weillustrate our results in simulations relevant to our sampling application.
arxiv-12600-126 | Efficient Discriminative Nonorthogonal Binary Subspace with its Application to Visual Tracking | http://arxiv.org/pdf/1509.08383v1.pdf | author:Ang Li, Feng Tang, Yanwen Guo, Hai Tao category:cs.CV published:2015-09-28 summary:One of the crucial problems in visual tracking is how the object isrepresented. Conventional appearance-based trackers are using increasingly morecomplex features in order to be robust. However, complex representationstypically not only require more computation for feature extraction, but alsomake the state inference complicated. We show that with a careful featureselection scheme, extremely simple yet discriminative features can be used forrobust object tracking. The central component of the proposed method is asuccinct and discriminative representation of the object using discriminativenon-orthogonal binary subspace (DNBS) which is spanned by Haar-like features.The DNBS representation inherits the merits of the original NBS in that itefficiently describes the object. It also incorporates the discriminativeinformation to distinguish foreground from background. However, the problem offinding the DNBS bases from an over-complete dictionary is NP-hard. We proposea greedy algorithm called discriminative optimized orthogonal matching pursuit(D-OOMP) to solve this problem. An iterative formulation named iterative D-OOMPis further developed to drastically reduce the redundant computation betweeniterations and a hierarchical selection strategy is integrated for reducing thesearch space of features. The proposed DNBS representation is applied to objecttracking through SSD-based template matching. We validate the effectiveness ofour method through extensive experiments on challenging videos with comparisonsagainst several state-of-the-art trackers and demonstrate its capability totrack objects in clutter and moving background.
arxiv-12600-127 | Compressive spectral embedding: sidestepping the SVD | http://arxiv.org/pdf/1509.08360v1.pdf | author:Dinesh Ramasamy, Upamanyu Madhow category:stat.ML cs.LG published:2015-09-28 summary:Spectral embedding based on the Singular Value Decomposition (SVD) is awidely used "preprocessing" step in many learning tasks, typically leading todimensionality reduction by projecting onto a number of dominant singularvectors and rescaling the coordinate axes (by a predefined function of thesingular value). However, the number of such vectors required to captureproblem structure grows with problem size, and even partial SVD computationbecomes a bottleneck. In this paper, we propose a low-complexity it compressivespectral embedding algorithm, which employs random projections and finite orderpolynomial expansions to compute approximations to SVD-based embedding. For anm times n matrix with T non-zeros, its time complexity is O((T+m+n)log(m+n)),and the embedding dimension is O(log(m+n)), both of which are independent ofthe number of singular vectors whose effect we wish to capture. To the best ofour knowledge, this is the first work to circumvent this dependence on thenumber of singular vectors for general SVD-based embeddings. The key tosidestepping the SVD is the observation that, for downstream inference taskssuch as clustering and classification, we are only interested in using theresulting embedding to evaluate pairwise similarity metrics derived from theeuclidean norm, rather than capturing the effect of the underlying matrix onarbitrary vectors as a partial SVD tries to do. Our numerical results onnetwork datasets demonstrate the efficacy of the proposed method, and motivatefurther exploration of its application to large-scale inference tasks.
arxiv-12600-128 | A Preliminary Study on the Learning Informativeness of Data Subsets | http://arxiv.org/pdf/1510.04104v1.pdf | author:Simon Kaltenbacher, Nicholas H. Kirk, Dongheui Lee category:cs.CL cs.RO published:2015-09-28 summary:Estimating the internal state of a robotic system is complex: this isperformed from multiple heterogeneous sensor inputs and knowledge sources.Discretization of such inputs is done to capture saliences, represented assymbolic information, which often presents structure and recurrence. As thesesequences are used to reason over complex scenarios, a more compactrepresentation would aid exactness of technical cognitive reasoningcapabilities, which are today constrained by computational complexity issuesand fallback to representational heuristics or human intervention. Suchproblems need to be addressed to ensure timely and meaningful human-robotinteraction. Our work is towards understanding the variability of learninginformativeness when training on subsets of a given input dataset. This is inview of reducing the training size while retaining the majority of the symboliclearning potential. We prove the concept on human-written texts, and conjecturethis work will reduce training data size of sequential instructions, whilepreserving semantic relations, when gathering information from large remotesources.
arxiv-12600-129 | Vision System and Depth Processing for DRC-HUBO+ | http://arxiv.org/pdf/1509.06114v2.pdf | author:Inwook Shim, Seunghak Shin, Yunsu Bok, Kyungdon Joo, Dong-Geol Choi, Joon-Young Lee, Jaesik Park, Jun-Ho Oh, In So Kweon category:cs.CV cs.RO published:2015-09-21 summary:This paper presents a vision system and a depth processing algorithm forDRC-HUBO+, the winner of the DRC finals 2015. Our system is designed toreliably capture 3D information of a scene and objects robust to challengingenvironment conditions. We also propose a depth-map upsampling method thatproduces an outliers-free depth map by explicitly handling depth outliers. Oursystem is suitable for an interactive robot with real-world that requiresaccurate object detection and pose estimation. We evaluate our depth processingalgorithm over state-of-the-art algorithms on several synthetic and real-worlddatasets.
arxiv-12600-130 | Theoretical Analysis of the Optimal Free Responses of Graph-Based SFA for the Design of Training Graphs | http://arxiv.org/pdf/1509.08329v1.pdf | author:Alberto N. Escalante-B., Laurenz Wiskott category:cs.AI cs.CV stat.ML published:2015-09-28 summary:Slow feature analysis (SFA) is an unsupervised learning algorithm thatextracts slowly varying features from a time series. Graph-based SFA (GSFA) isa supervised extension that can solve regression problems if followed by apost-processing regression algorithm. A training graph specifies arbitraryconnections between the training samples. The connections in current graphs,however, only depend on the rank of the involved labels. Exploiting the exactlabel values makes further improvements in estimation accuracy possible. In this article, we propose the exact label learning (ELL) method to create agraph that codes the desired label explicitly, so that GSFA is able to extracta normalized version of it directly. The ELL method is used for three tasks:(1) We estimate gender from artificial images of human faces (regression) andshow the advantage of coding additional labels, particularly skin color. (2) Weanalyze two existing graphs for regression. (3) We extract compactdiscriminative features to classify traffic sign images. When the number ofoutput features is limited, a higher classification rate is obtained comparedto a graph equivalent to nonlinear Fisher discriminant analysis. The method isversatile, directly supports multiple labels, and provides higher accuracycompared to current graphs for the problems considered.
arxiv-12600-131 | What Properties are Desirable from an Electron Microscopy Segmentation Algorithm | http://arxiv.org/pdf/1503.05430v3.pdf | author:Toufiq Parag category:cs.CV published:2015-03-18 summary:The prospect of neural reconstruction from Electron Microscopy (EM) imageshas been elucidated by the automatic segmentation algorithms. Althoughsegmentation algorithms eliminate the necessity of tracing the neurons by hand,significant manual effort is still essential for correcting the mistakes theymake. A considerable amount of human labor is also required for annotatinggroundtruth volumes for training the classifiers of a segmentation framework.It is critically important to diminish the dependence on human interaction inthe overall reconstruction system. This study proposes a novel classifiertraining algorithm for EM segmentation aimed to reduce the amount of manualeffort demanded by the groundtruth annotation and error refinement tasks.Instead of using an exhaustive pixel level groundtruth, an active learningalgorithm is proposed for sparse labeling of pixel and boundaries ofsuperpixels. Because over-segmentation errors are in general more tolerable andeasier to correct than the under-segmentation errors, our algorithm is designedto prioritize minimization of false-merges over false-split mistakes. Ourexperiments on both 2D and 3D data suggest that the proposed method yieldssegmentation outputs that are more amenable to neural reconstruction than thoseof existing methods.
arxiv-12600-132 | Neural NILM: Deep Neural Networks Applied to Energy Disaggregation | http://arxiv.org/pdf/1507.06594v3.pdf | author:Jack Kelly, William Knottenbelt category:cs.NE I.2.6; I.5.2 published:2015-07-23 summary:Energy disaggregation estimates appliance-by-appliance electricityconsumption from a single meter that measures the whole home's electricitydemand. Recently, deep neural networks have driven remarkable improvements inclassification performance in neighbouring machine learning fields such asimage classification and automatic speech recognition. In this paper, we adaptthree deep neural network architectures to energy disaggregation: 1) a form ofrecurrent neural network called `long short-term memory' (LSTM); 2) denoisingautoencoders; and 3) a network which regresses the start time, end time andaverage power demand of each appliance activation. We use seven metrics to testthe performance of these algorithms on real aggregate power data from fiveappliances. Tests are performed against a house not seen during training andagainst houses seen during training. We find that all three neural nets achievebetter F1 scores (averaged over all five appliances) than either combinatorialoptimisation or factorial hidden Markov models and that our neural netalgorithms generalise well to an unseen house.
arxiv-12600-133 | Analysis of Intelligent Classifiers and Enhancing the Detection Accuracy for Intrusion Detection System | http://arxiv.org/pdf/1509.08239v1.pdf | author:Mohanad Albayati, Biju Issac category:cs.CR cs.LG published:2015-09-28 summary:In this paper we discuss and analyze some of the intelligent classifierswhich allows for automatic detection and classification of networks attacks forany intrusion detection system. We will proceed initially with their analysisusing the WEKA software to work with the classifiers on a well-known IDS(Intrusion Detection Systems) dataset like NSL-KDD dataset. The NSL-KDD datasetof network attacks was created in a military network by MIT Lincoln Labs. Thenwe will discuss and experiment some of the hybrid AI (Artificial Intelligence)classifiers that can be used for IDS, and finally we developed a Java softwarewith three most efficient classifiers and compared it with other options. Theoutputs would show the detection accuracy and efficiency of the single andcombined classifiers used.
arxiv-12600-134 | A Comprehensive Study On The Applications Of Machine Learning For Diagnosis Of Cancer | http://arxiv.org/pdf/1505.01345v4.pdf | author:Mohnish Chakravarti, Tanay Kothari category:cs.LG published:2015-05-06 summary:Collectively, lung cancer, breast cancer and melanoma was diagnosed in over535,340 people out of which, 209,400 deaths were reported [13]. It is estimatedthat over 600,000 people will be diagnosed with these forms of cancer in 2015.Most of the deaths from lung cancer, breast cancer and melanoma result due tolate detection. All of these cancers, if detected early, are 100% curable. Inthis study, we develop and evaluate algorithms to diagnose Breast cancer,Melanoma, and Lung cancer. In the first part of the study, we employed anormalised Gradient Descent and an Artificial Neural Network to diagnose breastcancer with an overall accuracy of 91% and 95% respectively. In the second partof the study, an artificial neural network coupled with image processing andanalysis algorithms was employed to achieve an overall accuracy of 93% A naivemobile based application that allowed people to take diagnostic tests on theirphones was developed. Finally, a Support Vector Machine algorithm incorporatingimage processing and image analysis algorithms was developed to diagnose lungcancer with an accuracy of 94%. All of the aforementioned systems had very lowfalse positive and false negative rates. We are developing an online networkthat incorporates all of these systems and allows people to collaborateglobally.
arxiv-12600-135 | Fast Non-local Stereo Matching based on Hierarchical Disparity Prediction | http://arxiv.org/pdf/1509.08197v1.pdf | author:Xuan Luo, Xuejiao Bai, Shuo Li, Hongtao Lu, Sei-ichiro Kamata category:cs.CV published:2015-09-28 summary:Stereo matching is the key step in estimating depth from two or more images.Recently, some tree-based non-local stereo matching methods have been proposed,which achieved state-of-the-art performance. The algorithms employed some treestructures to aggregate cost and thus improved the performance and reduced thecoputation load of the stereo matching. However, the computational complexityof these tree-based algorithms is still high because they search over theentire disparity range. In addition, the extreme greediness of the minimumspanning tree (MST) causes the poor performance in large areas with similarcolors but varying disparities. In this paper, we propose an efficient stereomatching method using a hierarchical disparity prediction (HDP) framework todramatically reduce the disparity search range so as to speed up the tree-basednon-local stereo methods. Our disparity prediction scheme works on a graphpyramid derived from an image whose disparity to be estimated. We utilize thedisparity of a upper graph to predict a small disparity range for the lowergraph. Some independent disparity trees (DT) are generated to form a disparityprediction forest (HDPF) over which the cost aggregation is made. When combinedwith the state-of-the-art tree-based methods, our scheme not only dramaticallyspeeds up the original methods but also improves their performance byalleviating the second drawback of the tree-based methods. This is partiallybecause our DTs overcome the extreme greediness of the MST. Extensiveexperimental results on some benchmark datasets demonstrate the effectivenessand efficiency of our framework. For example, the segment-tree based stereomatching becomes about 25.57 times faster and 2.2% more accurate over theMiddlebury 2006 full-size dataset.
arxiv-12600-136 | Robust video object tracking using particle filter with likelihood based feature fusion and adaptive template updating | http://arxiv.org/pdf/1509.08182v1.pdf | author:Yi Dai, Bin Liu category:cs.CV 68T45 I.4.8; I.5.4 published:2015-09-28 summary:A robust algorithm solution is proposed for tracking an object in complexvideo scenes. In this solution, the bootstrap particle filter (PF) isinitialized by an object detector, which models the time-evolving background ofthe video signal by an adaptive Gaussian mixture. The motion of the object isexpressed by a Markov model, which defines the state transition prior. Thecolor and texture features are used to represent the object, and a marginallikelihood based feature fusion approach is proposed. A corresponding objecttemplate model updating procedure is developed to account for possible scalechanges of the object in the tracking process. Experimental results show thatour algorithm beats several existing alternatives in tackling challengingscenarios in video tracking tasks.
arxiv-12600-137 | TransA: An Adaptive Approach for Knowledge Graph Embedding | http://arxiv.org/pdf/1509.05490v2.pdf | author:Han Xiao, Minlie Huang, Yu Hao, Xiaoyan Zhu category:cs.CL published:2015-09-18 summary:Knowledge representation is a major topic in AI, and many studies attempt torepresent entities and relations of knowledge base in a continuous vectorspace. Among these attempts, translation-based methods build entity andrelation vectors by minimizing the translation loss from a head entity to atail one. In spite of the success of these methods, translation-based methodsalso suffer from the oversimplified loss metric, and are not competitive enoughto model various and complex entities/relations in knowledge bases. To addressthis issue, we propose \textbf{TransA}, an adaptive metric approach forembedding, utilizing the metric learning ideas to provide a more flexibleembedding method. Experiments are conducted on the benchmark datasets and ourproposed method makes significant and consistent improvements over thestate-of-the-art baselines.
arxiv-12600-138 | Multi-view Convolutional Neural Networks for 3D Shape Recognition | http://arxiv.org/pdf/1505.00880v3.pdf | author:Hang Su, Subhransu Maji, Evangelos Kalogerakis, Erik Learned-Miller category:cs.CV cs.GR published:2015-05-05 summary:A longstanding question in computer vision concerns the representation of 3Dshapes for recognition: should 3D shapes be represented with descriptorsoperating on their native 3D formats, such as voxel grid or polygon mesh, orcan they be effectively represented with view-based descriptors? We addressthis question in the context of learning to recognize 3D shapes from acollection of their rendered views on 2D images. We first present a standardCNN architecture trained to recognize the shapes' rendered views independentlyof each other, and show that a 3D shape can be recognized even from a singleview at an accuracy far higher than using state-of-the-art 3D shapedescriptors. Recognition rates further increase when multiple views of theshapes are provided. In addition, we present a novel CNN architecture thatcombines information from multiple views of a 3D shape into a single andcompact shape descriptor offering even better recognition performance. The samearchitecture can be applied to accurately recognize human hand-drawn sketchesof shapes. We conclude that a collection of 2D views can be highly informativefor 3D shape recognition and is amenable to emerging CNN architectures andtheir derivatives.
arxiv-12600-139 | Feature Selection for classification of hyperspectral data by minimizing a tight bound on the VC dimension | http://arxiv.org/pdf/1509.08112v1.pdf | author:Phool Preet, Sanjit Singh Batra, Jayadeva category:cs.LG published:2015-09-27 summary:Hyperspectral data consists of large number of features which requiresophisticated analysis to be extracted. A popular approach to reducecomputational cost, facilitate information representation and accelerateknowledge discovery is to eliminate bands that do not improve theclassification and analysis methods being applied. In particular, algorithmsthat perform band elimination should be designed to take advantage of thespecifics of the classification method being used. This paper employs arecently proposed filter-feature-selection algorithm based on minimizing atight bound on the VC dimension. We have successfully applied this algorithm todetermine a reasonable subset of bands without any user-defined stoppingcriteria on widely used hyperspectral images and demonstrate that this methodoutperforms state-of-the-art methods in terms of both sparsity of feature setas well as accuracy of classification.\end{abstract}
arxiv-12600-140 | Fast R-CNN | http://arxiv.org/pdf/1504.08083v2.pdf | author:Ross Girshick category:cs.CV published:2015-04-30 summary:This paper proposes a Fast Region-based Convolutional Network method (FastR-CNN) for object detection. Fast R-CNN builds on previous work to efficientlyclassify object proposals using deep convolutional networks. Compared toprevious work, Fast R-CNN employs several innovations to improve training andtesting speed while also increasing detection accuracy. Fast R-CNN trains thevery deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, andachieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trainsVGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN isimplemented in Python and C++ (using Caffe) and is available under theopen-source MIT License at https://github.com/rbgirshick/fast-rcnn.
arxiv-12600-141 | HAMSI: Distributed Incremental Optimization Algorithm Using Quadratic Approximations for Partially Separable Problems | http://arxiv.org/pdf/1509.01698v2.pdf | author:Umut Şimşekli, Hazal Koptagel, Figen Öztoprak, Ş. İlker Birbil, Ali Taylan Cemgil category:stat.ML cs.LG published:2015-09-05 summary:We propose HAMSI, a provably convergent incremental algorithm for solvinglarge-scale partially separable optimization problems that frequently emerge inmachine learning and inferential statistics. The algorithm is based on a localquadratic approximation and hence allows incorporating a second order curvatureinformation to speed-up the convergence. Furthermore, HAMSI needs almost notuning, and it is scalable as well as easily parallelizable. In large-scalesimulation studies with the MovieLens datasets, we illustrate that the methodis superior to a state-of-the-art distributed stochastic gradient descentmethod in terms of convergence behavior. This performance gain comes at theexpense of using memory that scales only linearly with the total size of theoptimization variables. We conclude that HAMSI may be considered as a viablealternative in many scenarios, where first order methods based on variants ofstochastic gradient descent are applicable.
arxiv-12600-142 | Learning to track for spatio-temporal action localization | http://arxiv.org/pdf/1506.01929v2.pdf | author:Philippe Weinzaepfel, Zaid Harchaoui, Cordelia Schmid category:cs.CV published:2015-06-05 summary:We propose an effective approach for spatio-temporal action localization inrealistic videos. The approach first detects proposals at the frame-level andscores them with a combination of static and motion CNN features. It thentracks high-scoring proposals throughout the video using atracking-by-detection approach. Our tracker relies simultaneously oninstance-level and class-level detectors. The tracks are scored using aspatio-temporal motion histogram, a descriptor at the track level, incombination with the CNN features. Finally, we perform temporal localization ofthe action using a sliding-window approach at the track level. We presentexperimental results for spatio-temporal localization on the UCF-Sports, J-HMDBand UCF-101 action localization datasets, where our approach outperforms thestate of the art with a margin of 15%, 7% and 12% respectively in mAP.
arxiv-12600-143 | Non-asymptotic Analysis of $\ell_1$-norm Support Vector Machines | http://arxiv.org/pdf/1509.08083v1.pdf | author:Anton Kolleck, Jan Vybíral category:cs.IT cs.LG math.FA math.IT math.ST stat.TH published:2015-09-27 summary:Support Vector Machines (SVM) with $\ell_1$ penalty became a standard tool inanalysis of highdimensional classification problems with sparsity constraintsin many applications including bioinformatics and signal processing. AlthoughSVM have been studied intensively in the literature, this paper has to ourknowledge first non-asymptotic results on the performance of $\ell_1$-SVM inidentification of sparse classifiers. We show that a $d$-dimensional $s$-sparseclassification vector can be (with high probability) well approximated fromonly $O(s\log(d))$ Gaussian trials. The methods used in the proof includeconcentration of measure and probability in Banach spaces.
arxiv-12600-144 | Segment-Phrase Table for Semantic Segmentation, Visual Entailment and Paraphrasing | http://arxiv.org/pdf/1509.08075v1.pdf | author:Hamid Izadinia, Fereshteh Sadeghi, Santosh Kumar Divvala, Yejin Choi, Ali Farhadi category:cs.CV published:2015-09-27 summary:We introduce Segment-Phrase Table (SPT), a large collection of bijectiveassociations between textual phrases and their corresponding segmentations.Leveraging recent progress in object recognition and natural languagesemantics, we show how we can successfully build a high-quality segment-phrasetable using minimal human supervision. More importantly, we demonstrate theunique value unleashed by this rich bimodal resource, for both vision as wellas natural language understanding. First, we show that fine-grained textuallabels facilitate contextual reasoning that helps in satisfying semanticconstraints across image segments. This feature enables us to achievestate-of-the-art segmentation results on benchmark datasets. Next, we show thatthe association of high-quality segmentations to textual phrases aids in richersemantic understanding and reasoning of these textual phrases. Leveraging thisfeature, we motivate the problem of visual entailment and visual paraphrasing,and demonstrate its utility on a large dataset.
arxiv-12600-145 | Learning And-Or Models to Represent Context and Occlusion for Car Detection and Viewpoint Estimation | http://arxiv.org/pdf/1501.07359v2.pdf | author:Tianfu Wu, Bo Li, Song-Chun Zhu category:cs.CV published:2015-01-29 summary:This paper presents a method for learning And-Or models to represent contextand occlusion for car detection and viewpoint estimation. The learned And-Ormodel represents car-to-car context and occlusion configurations at threelevels: (i) spatially-aligned cars, (ii) single car under different occlusionconfigurations, and (iii) a small number of parts. The And-Or model embeds agrammar for representing large structural and appearance variations in areconfigurable hierarchy. The learning process consists of two stages in aweakly supervised way (i.e., only bounding boxes of single cars are annotated).Firstly, the structure of the And-Or model is learned with three components:(a) mining multi-car contextual patterns based on layouts of annotated singlecar bounding boxes, (b) mining occlusion configurations between single cars,and (c) learning different combinations of part visibility based on car 3D CADsimulation. The And-Or model is organized in a directed and acyclic graph whichcan be inferred by Dynamic Programming. Secondly, the model parameters (forappearance, deformation and bias) are jointly trained using Weak-LabelStructural SVM. In experiments, we test our model on four car detectiondatasets --- the KITTI dataset \cite{Geiger12}, the PASCAL VOC2007 cardataset~\cite{pascal}, and two self-collected car datasets, namely theStreet-Parking car dataset and the Parking-Lot car dataset, and three datasetsfor car viewpoint estimation --- the PASCAL VOC2006 car dataset~\cite{pascal},the 3D car dataset~\cite{savarese}, and the PASCAL3D+ cardataset~\cite{xiang_wacv14}. Compared with state-of-the-art variants ofdeformable part-based models and other methods, our model achieves significantimprovement consistently on the four detection datasets, and comparableperformance on car viewpoint estimation.
arxiv-12600-146 | End-to-End Text-Dependent Speaker Verification | http://arxiv.org/pdf/1509.08062v1.pdf | author:Georg Heigold, Ignacio Moreno, Samy Bengio, Noam Shazeer category:cs.LG cs.SD published:2015-09-27 summary:In this paper we present a data-driven, integrated approach to speakerverification, which maps a test utterance and a few reference utterancesdirectly to a single score for verification and jointly optimizes the system'scomponents using the same evaluation protocol and metric as at test time. Suchan approach will result in simple and efficient systems, requiring littledomain-specific knowledge and making few model assumptions. We implement theidea by formulating the problem as a single neural network architecture,including the estimation of a speaker model on only a few utterances, andevaluate it on our internal "Ok Google" benchmark for text-dependent speakerverification. The proposed approach appears to be very effective for big dataapplications like ours that require highly accurate, easy-to-maintain systemswith a small footprint.
arxiv-12600-147 | A 128 channel Extreme Learning Machine based Neural Decoder for Brain Machine Interfaces | http://arxiv.org/pdf/1509.07450v2.pdf | author:Yi Chen, Enyi Yao, Arindam Basu category:cs.LG cs.HC published:2015-09-22 summary:Currently, state-of-the-art motor intention decoding algorithms inbrain-machine interfaces are mostly implemented on a PC and consume significantamount of power. A machine learning co-processor in 0.35um CMOS for motorintention decoding in brain-machine interfaces is presented in this paper.Using Extreme Learning Machine algorithm and low-power analog processing, itachieves an energy efficiency of 290 GMACs/W at a classification rate of 50 Hz.The learning in second stage and corresponding digitally stored coefficientsare used to increase robustness of the core analog processor. The chip isverified with neural data recorded in monkey finger movements experiment,achieving a decoding accuracy of 99.3% for movement type. The same co-processoris also used to decode time of movement from asynchronous neural spikes. Withtime-delayed feature dimension enhancement, the classification accuracy can beincreased by 5% with limited number of input channels. Further, a sparsitypromoting training scheme enables reduction of number of programmable weightsby ~2X.
arxiv-12600-148 | Deep Trans-layer Unsupervised Networks for Representation Learning | http://arxiv.org/pdf/1509.08038v1.pdf | author:Wentao Zhu, Jun Miao, Laiyun Qing, Xilin Chen category:cs.NE cs.CV cs.LG published:2015-09-27 summary:Learning features from massive unlabelled data is a vast prevalent topic forhigh-level tasks in many machine learning applications. The recent greatimprovements on benchmark data sets achieved by increasingly complexunsupervised learning methods and deep learning models with lots of parametersusually requires many tedious tricks and much expertise to tune. However,filters learned by these complex architectures are quite similar to standardhand-crafted features visually. In this paper, unsupervised learning methods,such as PCA or auto-encoder, are employed as the building block to learn filterbanks at each layer. The lower layer responses are transferred to the lastlayer (trans-layer) to form a more complete representation retaining moreinformation. In addition, some beneficial methods such as local contrastnormalization and whitening are added to the proposed deep trans-layer networksto further boost performance. The trans-layer representations are followed byblock histograms with binary encoder schema to learn translation and rotationinvariant representations, which are utilized to do high-level tasks such asrecognition and classification. Compared to traditional deep learning methods,the implemented feature learning method has much less parameters and isvalidated in several typical experiments, such as digit recognition on MNISTand MNIST variations, object recognition on Caltech 101 dataset and faceverification on LFW dataset. The deep trans-layer unsupervised learningachieves 99.45% accuracy on MNIST dataset, 67.11% accuracy on 15 samples perclass and 75.98% accuracy on 30 samples per class on Caltech 101 dataset,87.10% on LFW dataset.
arxiv-12600-149 | DeepBox: Learning Objectness with Convolutional Networks | http://arxiv.org/pdf/1505.02146v2.pdf | author:Weicheng Kuo, Bharath Hariharan, Jitendra Malik category:cs.CV published:2015-05-08 summary:Existing object proposal approaches use primarily bottom-up cues to rankproposals, while we believe that objectness is in fact a high level construct.We argue for a data-driven, semantic approach for ranking object proposals. Ourframework, which we call DeepBox, uses convolutional neural networks (CNNs) torerank proposals from a bottom-up method. We use a novel four-layer CNNarchitecture that is as good as much larger networks on the task of evaluatingobjectness while being much faster. We show that DeepBox significantly improvesover the bottom-up ranking, achieving the same recall with 500 proposals asachieved by bottom-up methods with 2000. This improvement generalizes tocategories the CNN has never seen before and leads to a 4.5-point gain indetection mAP. Our implementation achieves this performance while running at260 ms per image.
arxiv-12600-150 | Warping Peirce Quincuncial Panoramas | http://arxiv.org/pdf/1011.3189v5.pdf | author:Chamberlain Fong, Brian K. Vogel category:cs.CV cs.GR published:2010-11-14 summary:The Peirce quincuncial projection is a mapping of the surface of a sphere tothe interior of a square. It is a conformal map except for four points on theequator. These points of non-conformality cause significant artifacts inphotographic applications. In this paper, we propose an algorithm anduser-interface to mitigate these artifacts. Moreover, in order to facilitate aninteractive user-interface, we present a fast algorithm for calculating thePeirce quincuncial projection of spherical imagery. We then promote the Peircequincuncial projection as a viable alternative to the more popularstereographic projection in some scenarios.
arxiv-12600-151 | Targeted Fused Ridge Estimation of Inverse Covariance Matrices from Multiple High-Dimensional Data Classes | http://arxiv.org/pdf/1509.07982v1.pdf | author:Anders Ellern Bilgrau, Carel F. W. Peeters, Poul Svante Eriksen, Martin Bøgsted, Wessel N. van Wieringen category:stat.ME q-bio.MN stat.ML published:2015-09-26 summary:We consider the problem of jointly estimating multiple precision matricesfrom (aggregated) high-dimensional data consisting of distinct classes. An$\ell_2$-penalized maximum-likelihood approach is employed. The suggestedapproach is flexible and generic, incorporating several other$\ell_2$-penalized estimators as special cases. In addition, the approachallows for the specification of target matrices through which prior knowledgemay be incorporated and which can stabilize the estimation procedure inhigh-dimensional settings. The result is a targeted fused ridge estimator thatis of use when the precision matrices of the constituent classes are believedto chiefly share the same structure while potentially differing in a number oflocations of interest. It has many applications in (multi)factorial studydesigns. We focus on the graphical interpretation of precision matrices withthe proposed estimator then serving as a basis for integrative or meta-analyticGaussian graphical modeling. Situations are considered in which the classes aredefined by data sets and/or (subtypes of) diseases. The performance of theproposed estimator in the graphical modeling setting is assessed throughextensive simulation experiments. Its practical usability is illustrated by thedifferential network modeling of 11 large-scale diffuse large B-cell lymphomagene expression data sets. The estimator and its related procedures areincorporated into the R-package rags2ridges.
arxiv-12600-152 | Modeling Curiosity in a Mobile Robot for Long-Term Autonomous Exploration and Monitoring | http://arxiv.org/pdf/1509.07975v1.pdf | author:Yogesh Girdhar, Gregory Dudek category:cs.RO cs.CV cs.LG published:2015-09-26 summary:This paper presents a novel approach to modeling curiosity in a mobile robot,which is useful for monitoring and adaptive data collection tasks, especiallyin the context of long term autonomous missions where pre-programmed missionsare likely to have limited utility. We use a realtime topic modeling techniqueto build a semantic perception model of the environment, using which, we plan apath through the locations in the world with high semantic information content.The life-long learning behavior of the proposed perception model makes itsuitable for long-term exploration missions. We validate the approach usingsimulated exploration experiments using aerial and underwater data, anddemonstrate an implementation on the Aqua underwater robot in a variety ofscenarios. We find that the proposed exploration paths that are biased towardslocations with high topic perplexity, produce better terrain models with highdiscriminative power. Moreover, we show that the proposed algorithm implementedon Aqua robot is able to do tasks such as coral reef inspection, diverfollowing, and sea floor exploration, without any prior training orpreparation.
arxiv-12600-153 | A Bayesian Approach to Sparse plus Low rank Network Identification | http://arxiv.org/pdf/1503.07340v2.pdf | author:Mattia Zorzi, Alessandro Chiuso category:math.OC stat.ML published:2015-03-25 summary:We consider the problem of modeling multivariate time series withparsimonious dynamical models which can be represented as sparse dynamicBayesian networks with few latent nodes. This structure translates into asparse plus low rank model. In this paper, we propose a Gaussian regressionapproach to identify such a model.
arxiv-12600-154 | AttentionNet: Aggregating Weak Directions for Accurate Object Detection | http://arxiv.org/pdf/1506.07704v2.pdf | author:Donggeun Yoo, Sunggyun Park, Joon-Young Lee, Anthony S. Paek, In So Kweon category:cs.CV cs.LG published:2015-06-25 summary:We present a novel detection method using a deep convolutional neural network(CNN), named AttentionNet. We cast an object detection problem as an iterativeclassification problem, which is the most suitable form of a CNN. AttentionNetprovides quantized weak directions pointing a target object and the ensemble ofiterative predictions from AttentionNet converges to an accurate objectboundary box. Since AttentionNet is a unified network for object detection, itdetects objects without any separated models from the object proposal to thepost bounding-box regression. We evaluate AttentionNet by a human detectiontask and achieve the state-of-the-art performance of 65% (AP) on PASCAL VOC2007/2012 with an 8-layered architecture only.
arxiv-12600-155 | A Revisit of Infinite Population Models for Evolutionary Algorithms on Continuous Optimization Problems | http://arxiv.org/pdf/1509.07946v1.pdf | author:Bo Song, Victor O. K. Li category:cs.NE math.OC published:2015-09-26 summary:Infinite population models are important tools for studying populationdynamics of evolutionary algorithms. They describe how the distributions ofpopulations change between consecutive generations. In general, infinitepopulation models are derived from Markov chains by exploiting symmetriesbetween individuals in the population and analyzing the limit as the populationsize goes to infinity. In this paper, we study the theoretical foundations ofinfinite population models of evolutionary algorithms on continuousoptimization problems. First, we show that the convergence proofs in a widelycited study were in fact problematic and incomplete. We further show that themodeling assumption of exchangeability of individuals cannot yield thetransition equation. Then, in order to analyze infinite population models, webuild an analytical framework based on convergence in distribution of randomelements which take values in the metric space of infinite sequences. Theframework is concise and mathematically rigorous. It also provides aninfrastructure for studying the convergence of the stacking of operators and ofiterating the algorithm which previous studies failed to address. Finally, weuse the framework to prove the convergence of infinite population models forthe mutation operator and the $k$-ary recombination operator. We show thatthese operators can provide accurate predictions for real population dynamicsas the population size goes to infinity, provided that the initial populationis identically and independently distributed.
arxiv-12600-156 | DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving | http://arxiv.org/pdf/1505.00256v3.pdf | author:Chenyi Chen, Ari Seff, Alain Kornhauser, Jianxiong Xiao category:cs.CV published:2015-05-01 summary:Today, there are two major paradigms for vision-based autonomous drivingsystems: mediated perception approaches that parse an entire scene to make adriving decision, and behavior reflex approaches that directly map an inputimage to a driving action by a regressor. In this paper, we propose a thirdparadigm: a direct perception approach to estimate the affordance for driving.We propose to map an input image to a small number of key perception indicatorsthat directly relate to the affordance of a road/traffic state for driving. Ourrepresentation provides a set of compact yet complete descriptions of the sceneto enable a simple controller to drive autonomously. Falling in between the twoextremes of mediated perception and behavior reflex, we argue that our directperception representation provides the right level of abstraction. Todemonstrate this, we train a deep Convolutional Neural Network using recordingfrom 12 hours of human driving in a video game and show that our model can workwell to drive a car in a very diverse set of virtual environments. We alsotrain a model for car distance estimation on the KITTI dataset. Results showthat our direct perception approach can generalize well to real driving images.Source code and data are available on our project website.
arxiv-12600-157 | A prototype Malayalam to Sign Language Automatic Translator | http://arxiv.org/pdf/1412.7415v2.pdf | author:Jestin Joy, Kannan Balakrishnan category:cs.CL published:2014-12-23 summary:Sign language, which is a medium of communication for deaf people, usesmanual communication and body language to convey meaning, as opposed to usingsound. This paper presents a prototype Malayalam text to sign languagetranslation system. The proposed system takes Malayalam text as input andgenerates corresponding Sign Language. Output animation is rendered using acomputer generated model. This system will help to disseminate information tothe deaf people in public utility places like railways, banks, hospitals etc.This will also act as an educational tool in learning Sign Language.
arxiv-12600-158 | Super-Resolution Off the Grid | http://arxiv.org/pdf/1509.07943v1.pdf | author:Qingqing Huang, Sham M. Kakade category:cs.LG published:2015-09-26 summary:Super-resolution is the problem of recovering a superposition of pointsources using bandlimited measurements, which may be corrupted with noise. Thissignal processing problem arises in numerous imaging problems, ranging fromastronomy to biology to spectroscopy, where it is common to take (coarse)Fourier measurements of an object. Of particular interest is in obtainingestimation procedures which are robust to noise, with the following desirablestatistical and computational properties: we seek to use coarse Fouriermeasurements (bounded by some cutoff frequency); we hope to take a(quantifiably) small number of measurements; we desire our algorithm to runquickly. Suppose we have k point sources in d dimensions, where the points areseparated by at least \Delta from each other (in Euclidean distance). This workprovides an algorithm with the following favorable guarantees: - The algorithmuses Fourier measurements, whose frequencies are bounded by O(1/\Delta) (up tolog factors). Previous algorithms require a cutoff frequency which may be aslarge as {\Omega}( d/\Delta). - The number of measurements taken by and thecomputational complexity of our algorithm are bounded by a polynomial in boththe number of points k and the dimension d, with no dependence on theseparation \Delta. In contrast, previous algorithms depended inversepolynomially on the minimal separation and exponentially on the dimension forboth of these quantities. Our estimation procedure itself is simple: we take random bandlimitedmeasurements (as opposed to taking an exponential number of measurements on thehyper-grid). Furthermore, our analysis and algorithm are elementary (based onconcentration bounds for sampling and the singular value decomposition).
arxiv-12600-159 | Algorithms for Linear Bandits on Polyhedral Sets | http://arxiv.org/pdf/1509.07927v1.pdf | author:Manjesh K. Hanawal, Amir Leshem, Venkatesh Saligrama category:cs.LG published:2015-09-26 summary:We study stochastic linear optimization problem with bandit feedback. The setof arms take values in an $N$-dimensional space and belong to a boundedpolyhedron described by finitely many linear inequalities. We provide a lowerbound for the expected regret that scales as $\Omega(N\log T)$. We then providea nearly optimal algorithm and show that its expected regret scales as$O(N\log^{1+\epsilon}(T))$ for an arbitrary small $\epsilon >0$. The algorithmalternates between exploration and exploitation intervals sequentially wheredeterministic set of arms are played in the exploration intervals and greedilyselected arm is played in the exploitation intervals. We also develop analgorithm that achieves the optimal regret when sub-Gaussianity parameter ofthe noise term is known. Our key insight is that for a polyhedron the optimalarm is robust to small perturbations in the reward function. Consequently, agreedily selected arm is guaranteed to be optimal when the estimation errorfalls below some suitable threshold. Our solution resolves a question posed byRusmevichientong and Tsitsiklis (2011) that left open the possibility ofefficient algorithms with asymptotic logarithmic regret bounds. We also showthat the regret upper bounds hold with probability $1$. Our numericalinvestigations show that while theoretical results are asymptotic theperformance of our algorithms compares favorably to state-of-the-art algorithmsin finite time as well.
arxiv-12600-160 | Evasion and Hardening of Tree Ensemble Classifiers | http://arxiv.org/pdf/1509.07892v1.pdf | author:Alex Kantchelian, J. D. Tygar, Anthony D. Joseph category:cs.LG cs.CR stat.ML published:2015-09-25 summary:Recent work has successfully constructed adversarial "evading" instances fordifferentiable prediction models. However generating adversarial instances fortree ensembles, a piecewise constant class of models, has remained an openproblem. In this paper, we construct both exact and approximate evasionalgorithms for tree ensembles: for a given instance x we find the "nearest"instance x' such that the classifier predictions of x and x' are different.First, we show that finding such instances is practically possible despite treeensemble models being non-differentiable and the optimal evasion problem beingNP-hard. In addition, we quantify the susceptibility of such models applied to thetask of recognizing handwritten digits by measuring the distance between theoriginal instance and the modified instance under the L0, L1, L2 and L-infinitynorms. We also analyze a wide variety of classifiers including linear andRBF-kernel models, max-ensemble of linear models, and neural networks forcomparison purposes. Our analysis shows that tree ensembles produced by astate-of-the-art gradient boosting method are consistently the least robustmodels notwithstanding their competitive accuracy. Finally, we show that asufficient number of retraining rounds with L0-adversarial instances makes thehardened model three times harder to evade. This retraining set also marginallyimproves classification accuracy, but simultaneously makes the model moresusceptible to L1, L2 and L-infinity evasions.
arxiv-12600-161 | Zero-Shot Learning via Semantic Similarity Embedding | http://arxiv.org/pdf/1509.04767v2.pdf | author:Ziming Zhang, Venkatesh Saligrama category:cs.CV stat.ML published:2015-09-15 summary:In this paper we consider a version of the zero-shot learning problem whereseen class source and target domain data are provided. The goal duringtest-time is to accurately predict the class label of an unseen target domaininstance based on revealed source domain side information (\eg attributes) forunseen classes. Our method is based on viewing each source or target data as amixture of seen class proportions and we postulate that the mixture patternshave to be similar if the two instances belong to the same unseen class. Thisperspective leads us to learning source/target embedding functions that map anarbitrary source/target domain data into a same semantic space where similaritycan be readily measured. We develop a max-margin framework to learn thesesimilarity functions and jointly optimize parameters by means of crossvalidation. Our test results are compelling, leading to significant improvementin terms of accuracy on most benchmark datasets for zero-shot recognition.
arxiv-12600-162 | Person Recognition in Personal Photo Collections | http://arxiv.org/pdf/1509.03502v2.pdf | author:Seong Joon Oh, Rodrigo Benenson, Mario Fritz, Bernt Schiele category:cs.CV published:2015-09-11 summary:Recognising persons in everyday photos presents major challenges (occludedfaces, different clothing, locations, etc.) for machine vision. We propose aconvnet based person recognition system on which we provide an in-depthanalysis of informativeness of different body cues, impact of training data,and the common failure modes of the system. In addition, we discuss thelimitations of existing benchmarks and propose more challenging ones. Ourmethod is simple and is built on open source and open data, yet it improves thestate of the art results on a large dataset of social media photos (PIPA).
arxiv-12600-163 | Selecting Relevant Web Trained Concepts for Automated Event Retrieval | http://arxiv.org/pdf/1509.07845v1.pdf | author:Bharat Singh, Xintong Han, Zhe Wu, Vlad I. Morariu, Larry S. Davis category:cs.CV cs.CL cs.IR published:2015-09-25 summary:Complex event retrieval is a challenging research problem, especially when notraining videos are available. An alternative to collecting training videos isto train a large semantic concept bank a priori. Given a text description of anevent, event retrieval is performed by selecting concepts linguisticallyrelated to the event description and fusing the concept responses on unseenvideos. However, defining an exhaustive concept lexicon and pre-training itrequires vast computational resources. Therefore, recent approaches automateconcept discovery and training by leveraging large amounts of weakly annotatedweb data. Compact visually salient concepts are automatically obtained by theuse of concept pairs or, more generally, n-grams. However, not all visuallysalient n-grams are necessarily useful for an event query--some combinations ofconcepts may be visually compact but irrelevant--and this drastically affectsperformance. We propose an event retrieval algorithm that constructs pairs ofautomatically discovered concepts and then prunes those concepts that areunlikely to be helpful for retrieval. Pruning depends both on the query and onthe specific video instance being evaluated. Our approach also addressescalibration and domain adaptation issues that arise when applying conceptdetectors to unseen videos. We demonstrate large improvements over other visionbased systems on the TRECVID MED 13 dataset.
arxiv-12600-164 | Generalization in Adaptive Data Analysis and Holdout Reuse | http://arxiv.org/pdf/1506.02629v2.pdf | author:Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, Aaron Roth category:cs.LG cs.DS published:2015-06-08 summary:Overfitting is the bane of data analysts, even when data are plentiful.Formal approaches to understanding this problem focus on statistical inferenceand generalization of individual analysis procedures. Yet the practice of dataanalysis is an inherently interactive and adaptive process: new analyses andhypotheses are proposed after seeing the results of previous ones, parametersare tuned on the basis of obtained results, and datasets are shared and reused.An investigation of this gap has recently been initiated by the authors in(Dwork et al., 2014), where we focused on the problem of estimatingexpectations of adaptively chosen functions. In this paper, we give a simple and practical method for reusing a holdout(or testing) set to validate the accuracy of hypotheses produced by a learningalgorithm operating on a training set. Reusing a holdout set adaptivelymultiple times can easily lead to overfitting to the holdout set itself. Wegive an algorithm that enables the validation of a large number of adaptivelychosen hypotheses, while provably avoiding overfitting. We illustrate theadvantages of our algorithm over the standard use of the holdout set via asimple synthetic experiment. We also formalize and address the general problem of data reuse in adaptivedata analysis. We show how the differential-privacy based approach given in(Dwork et al., 2014) is applicable much more broadly to adaptive data analysis.We then show that a simple approach based on description length can also beused to give guarantees of statistical validity in adaptive settings. Finally,we demonstrate that these incomparable approaches can be unified via the notionof approximate max-information that we introduce.
arxiv-12600-165 | Deep Multimodal Embedding: Manipulating Novel Objects with Point-clouds, Language and Trajectories | http://arxiv.org/pdf/1509.07831v1.pdf | author:Jaeyong Sung, Ian Lenz, Ashutosh Saxena category:cs.RO cs.AI cs.CV cs.LG published:2015-09-25 summary:A robot operating in a real-world environment needs to perform reasoning witha variety of sensing modalities. However, manually designing features thatallow a learning algorithm to relate these different modalities can beextremely challenging. In this work, we consider the task of manipulating novelobjects and appliances. To this end, we learn to embed point-cloud, naturallanguage, and manipulation trajectory data into a shared embedding space usinga deep neural network. In order to learn semantically meaningful spacesthroughout our network, we introduce a method for pre-training its lower layersfor multimodal feature embedding and a method for fine-tuning this embeddingspace using a loss-based margin. We test our model on the Robobarista dataset[22], where we achieve significant improvements in both accuracy and inferencetime over the previous state of the art.
arxiv-12600-166 | Computational Intelligence Challenges and Applications on Large-Scale Astronomical Time Series Databases | http://arxiv.org/pdf/1509.07823v1.pdf | author:Pablo Huijse, Pablo A. Estevez, Pavlos Protopapas, Jose C. Principe, Pablo Zegers category:astro-ph.IM cs.LG published:2015-09-25 summary:Time-domain astronomy (TDA) is facing a paradigm shift caused by theexponential growth of the sample size, data complexity and data generationrates of new astronomical sky surveys. For example, the Large Synoptic SurveyTelescope (LSST), which will begin operations in northern Chile in 2022, willgenerate a nearly 150 Petabyte imaging dataset of the southern hemisphere sky.The LSST will stream data at rates of 2 Terabytes per hour, effectivelycapturing an unprecedented movie of the sky. The LSST is expected not only toimprove our understanding of time-varying astrophysical objects, but also toreveal a plethora of yet unknown faint and fast-varying phenomena. To cope witha change of paradigm to data-driven astronomy, the fields of astroinformaticsand astrostatistics have been created recently. The new data-oriented paradigmsfor astronomy combine statistics, data mining, knowledge discovery, machinelearning and computational intelligence, in order to provide the automated androbust methods needed for the rapid detection and classification of knownastrophysical objects as well as the unsupervised characterization of novelphenomena. In this article we present an overview of machine learning andcomputational intelligence applications to TDA. Future big data challenges andnew lines of research in TDA, focusing on the LSST, are identified anddiscussed from the viewpoint of computational intelligence/machine learning.Interdisciplinary collaboration will be required to cope with the challengesposed by the deluge of astronomical data coming from the LSST.
arxiv-12600-167 | Predicting Deep Zero-Shot Convolutional Neural Networks using Textual Descriptions | http://arxiv.org/pdf/1506.00511v2.pdf | author:Jimmy Ba, Kevin Swersky, Sanja Fidler, Ruslan Salakhutdinov category:cs.LG cs.CV cs.NE published:2015-06-01 summary:One of the main challenges in Zero-Shot Learning of visual categories isgathering semantic attributes to accompany images. Recent work has shown thatlearning from textual descriptions, such as Wikipedia articles, avoids theproblem of having to explicitly define these attributes. We present a new modelthat can classify unseen categories from their textual description.Specifically, we use text features to predict the output weights of both theconvolutional and the fully connected layers in a deep convolutional neuralnetwork (CNN). We take advantage of the architecture of CNNs and learn featuresat different layers, rather than just learning an embedding space for bothmodalities, as is common with existing approaches. The proposed model alsoallows us to automatically generate a list of pseudo- attributes for eachvisual category consisting of words from Wikipedia articles. We train ourmodels end-to-end us- ing the Caltech-UCSD bird and flower datasets andevaluate both ROC and Precision-Recall curves. Our empirical results show thatthe proposed model significantly outperforms previous methods.
arxiv-12600-168 | On Data Preconditioning for Regularized Loss Minimization | http://arxiv.org/pdf/1408.3115v4.pdf | author:Tianbao Yang, Rong Jin, Shenghuo Zhu, Qihang Lin category:cs.NA cs.LG stat.ML published:2014-08-13 summary:In this work, we study data preconditioning, a well-known and long-existingtechnique, for boosting the convergence of first-order methods for regularizedloss minimization. It is well understood that the condition number of theproblem, i.e., the ratio of the Lipschitz constant to the strong convexitymodulus, has a harsh effect on the convergence of the first-order optimizationmethods. Therefore, minimizing a small regularized loss for achieving goodgeneralization performance, yielding an ill conditioned problem, becomes thebottleneck for big data problems. We provide a theory on data preconditioningfor regularized loss minimization. In particular, our analysis exhibits anappropriate data preconditioner and characterizes the conditions on the lossfunction and on the data under which data preconditioning can reduce thecondition number and therefore boost the convergence for minimizing theregularized loss. To make the data preconditioning practically useful, weendeavor to employ and analyze a random sampling approach to efficientlycompute the preconditioned data. The preliminary experiments validate ourtheory.
arxiv-12600-169 | A Mathematical Theory for Clustering in Metric Spaces | http://arxiv.org/pdf/1509.07755v1.pdf | author:Cheng-Shang Chang, Wanjiun Liao, Yu-Sheng Chen, Li-Heng Liou category:cs.LG published:2015-09-25 summary:Clustering is one of the most fundamental problems in data analysis and ithas been studied extensively in the literature. Though many clusteringalgorithms have been proposed, clustering theories that justify the use ofthese clustering algorithms are still unsatisfactory. In particular, one of thefundamental challenges is to address the following question: What is a cluster in a set of data points? In this paper, we make an attempt to address such a question by considering aset of data points associated with a distance measure (metric). We firstpropose a new cohesion measure in terms of the distance measure. Using thecohesion measure, we define a cluster as a set of points that are cohesive tothemselves. For such a definition, we show there are various equivalentstatements that have intuitive explanations. We then consider the secondquestion: How do we find clusters and good partitions of clusters under such adefinition? For such a question, we propose a hierarchical agglomerative algorithm and apartitional algorithm. Unlike standard hierarchical agglomerative algorithms,our hierarchical agglomerative algorithm has a specific stopping criterion andit stops with a partition of clusters. Our partitional algorithm, called theK-sets algorithm in the paper, appears to be a new iterative algorithm. Unlikethe Lloyd iteration that needs two-step minimization, our K-sets algorithm onlytakes one-step minimization. One of the most interesting findings of our paper is the duality resultbetween a distance measure and a cohesion measure. Such a duality result leadsto a dual K-sets algorithm for clustering a set of data points with a cohesionmeasure. The dual K-sets algorithm converges in the same way as a sequentialversion of the classical kernel K-means algorithm. The key difference is that acohesion measure does not need to be positive semi-definite.
arxiv-12600-170 | Efficient Computation of the Quasi Likelihood function for Discretely Observed Diffusion Processes | http://arxiv.org/pdf/1509.07751v1.pdf | author:Lars Josef Höök, Erik Lindström category:stat.CO q-fin.ST stat.ML published:2015-09-25 summary:We introduce a simple method for nearly simultaneous computation of allmoments needed for quasi maximum likelihood estimation of parameters indiscretely observed stochastic differential equations commonly seen in finance.The method proposed in this papers is not restricted to any particular dynamicsof the differential equation and is virtually insensitive to the samplinginterval. The key contribution of the paper is that computational complexity issublinear in the number of observations as we compute all moments through asingle operation. Furthermore, that operation can be done offline. Thesimulations show that the method is unbiased for all practical purposes for anysampling design, including random sampling, and that the computational cost iscomparable (actually faster for moderate and large data sets) to the simple,often severely biased, Euler-Maruyama approximation.
arxiv-12600-171 | Online Stochastic Linear Optimization under One-bit Feedback | http://arxiv.org/pdf/1509.07728v1.pdf | author:Lijun Zhang, Tianbao Yang, Rong Jin, Zhi-Hua Zhou category:cs.LG published:2015-09-25 summary:In this paper, we study a special bandit setting of online stochastic linearoptimization, where only one-bit of information is revealed to the learner ateach round. This problem has found many applications including onlineadvertisement and online recommendation. We assume the binary feedback is arandom variable generated from the logit model, and aim to minimize the regretdefined by the unknown linear function. Although the existing method forgeneralized linear bandit can be applied to our problem, the high computationalcost makes it impractical for real-world problems. To address this challenge,we develop an efficient online learning algorithm by exploiting particularstructures of the observation model. Specifically, we adopt online Newton stepto estimate the unknown parameter and derive a tight confidence region based onthe exponential concavity of the logistic loss. Our analysis shows that theproposed algorithm achieves a regret bound of $O(d\sqrt{T})$, which matches theoptimal result of stochastic linear bandits.
arxiv-12600-172 | Utility-based Dueling Bandits as a Partial Monitoring Game | http://arxiv.org/pdf/1507.02750v2.pdf | author:Pratik Gajane, Tanguy Urvoy category:cs.LG published:2015-07-10 summary:Partial monitoring is a generic framework for sequential decision-making withincomplete feedback. It encompasses a wide class of problems such as duelingbandits, learning with expect advice, dynamic pricing, dark pools, and labelefficient prediction. We study the utility-based dueling bandit problem as aninstance of partial monitoring problem and prove that it fits the time-regretpartial monitoring hierarchy as an easy - i.e. Theta (sqrt{T})- instance. Wesurvey some partial monitoring algorithms and see how they could be used tosolve dueling bandits efficiently. Keywords: Online learning, Dueling Bandits,Partial Monitoring, Partial Feedback, Multiarmed Bandits
arxiv-12600-173 | A hybrid COA$ε$-constraint method for solving multi-objective problems | http://arxiv.org/pdf/1509.08302v1.pdf | author:Mahdi parvizi, Elham Shadkam, Niloofar Jahani category:cs.NE published:2015-09-25 summary:In this paper, a hybrid method for solving multi-objective problem has beenprovided. The proposed method is combining the {\epsilon}-Constraint and theCuckoo algorithm. First the multi objective problem transfers into asingle-objective problem using $\epsilon$-Constraint, then the Cuckoooptimization algorithm will optimize the problem in each task. At last theoptimized Pareto frontier will be drawn. The advantage of this method is thehigh accuracy and the dispersion of its Pareto frontier. In order to testingthe efficiency of the suggested method, a lot of test problems have been solvedusing this method. Comparing the results of this method with the results ofother similar methods shows that the Cuckoo algorithm is more suitable forsolving the multi-objective problems.
arxiv-12600-174 | Dense image registration and deformable surface reconstruction in presence of occlusions and minimal texture | http://arxiv.org/pdf/1503.03429v3.pdf | author:Dat Tien Ngo, Sanghuyk Park, Anne Jorstad, Alberto Crivellaro, Chang Yoo, Pascal Fua category:cs.CV published:2015-03-11 summary:Deformable surface tracking from monocular images is well-known to beunder-constrained. Occlusions often make the task even more challenging, andcan result in failure if the surface is not sufficiently textured. In thiswork, we explicitly address the problem of 3D reconstruction of poorlytextured, occluded surfaces, proposing a framework based on a template-matchingapproach that scales dense robust features by a relevancy score. Our approachis extensively compared to current methods employing both local featurematching and dense template alignment. We test on standard datasets as well ason a new dataset (that will be made publicly available) of a sparsely textured,occluded surface. Our framework achieves state-of-the-art results for both welland poorly textured, occluded surfaces.
arxiv-12600-175 | Feature Evaluation of Deep Convolutional Neural Networks for Object Recognition and Detection | http://arxiv.org/pdf/1509.07627v1.pdf | author:Hirokatsu Kataoka, Kenji Iwata, Yutaka Satoh category:cs.CV cs.AI cs.MM published:2015-09-25 summary:In this paper, we evaluate convolutional neural network (CNN) features usingthe AlexNet architecture and very deep convolutional network (VGGNet)architecture. To date, most CNN researchers have employed the last layersbefore output, which were extracted from the fully connected feature layers.However, since it is unlikely that feature representation effectiveness isdependent on the problem, this study evaluates additional convolutional layersthat are adjacent to fully connected layers, in addition to executing simpletuning for feature concatenation (e.g., layer 3 + layer 5 + layer 7) andtransformation, using tools such as principal component analysis. In ourexperiments, we carried out detection and classification tasks using theCaltech 101 and Daimler Pedestrian Benchmark Datasets.
arxiv-12600-176 | Self-localization Using Visual Experience Across Domains | http://arxiv.org/pdf/1509.07618v1.pdf | author:Taisho Tsukamoto, Kanji Tanaka category:cs.CV published:2015-09-25 summary:In this study, we aim to solve the single-view robot self-localizationproblem by using visual experience across domains. Although the bag-of-wordsmethod constitutes a popular approach to single-view localization, it failsbadly when it's visual vocabulary is learned and tested in different domains.Further, we are interested in using a cross-domain setting, in which the visualvocabulary is learned in different seasons and routes from the inputquery/database scenes. Our strategy is to mine a cross-domain visualexperience, a library of raw visual images collected in different domains, todiscover the relevant visual patterns that effectively explain the input scene,and use them for scene retrieval. In particular, we show that the appearanceand the pose of the mined visual patterns of a query scene can be efficientlyand discriminatively matched against those of the database scenes by employingimage-to-class distance and spatial pyramid matching. Experimental resultsobtained using a novel cross-domain dataset show that our system achievespromising results despite our visual vocabulary being learned and tested indifferent domains.
arxiv-12600-177 | Discriminative Map Retrieval Using View-Dependent Map Descriptor | http://arxiv.org/pdf/1509.07615v1.pdf | author:Enfu Liu, Kanji Tanaka category:cs.CV published:2015-09-25 summary:Map retrieval, the problem of similarity search over a large collection of 2Dpointset maps previously built by mobile robots, is crucial for autonomousnavigation in indoor and outdoor environments. Bag-of-words (BoW) methodsconstitute a popular approach to map retrieval; however, these methods haveextremely limited descriptive ability because they ignore the spatial layoutinformation of the local features. The main contribution of this paper is anextension of the bag-of-words map retrieval method to enable the use of spatialinformation from local features. Our strategy is to explicitly model a uniqueviewpoint of an input local map; the pose of the local feature is defined withrespect to this unique viewpoint, and can be viewed as an additional invariantfeature for discriminative map retrieval. Specifically, we wish to determine aunique viewpoint that is invariant to moving objects, clutter, occlusions, andactual viewpoints. Hence, we perform scene parsing to analyze the scenestructure, and consider the "center" of the scene structure to be the uniqueviewpoint. Our scene parsing is based on a Manhattan world grammar that imposesa quasi-Manhattan world constraint to enable the robust detection of a scenestructure that is invariant to clutter and moving objects. Experimental resultsusing the publicly available radish dataset validate the efficacy of theproposed approach.
arxiv-12600-178 | Sentiment Uncertainty and Spam in Twitter Streams and Its Implications for General Purpose Realtime Sentiment Analysis | http://arxiv.org/pdf/1509.07612v1.pdf | author:Nils Haldenwang, Oliver Vornberger category:cs.CL published:2015-09-25 summary:State of the art benchmarks for Twitter Sentiment Analysis do not considerthe fact that for more than half of the tweets from the public stream adistinct sentiment cannot be chosen. This paper provides a new perspective onTwitter Sentiment Analysis by highlighting the necessity of explicitlyincorporating uncertainty. Moreover, a dataset of high quality to evaluatesolutions for this new problem is introduced and made publicly available.
arxiv-12600-179 | Incremental Loop Closure Verification by Guided Sampling | http://arxiv.org/pdf/1509.07611v1.pdf | author:Kanji Tanaka category:cs.CV published:2015-09-25 summary:Loop closure detection, the task of identifying locations revisited by arobot in a sequence of odometry and perceptual observations, is typicallyformulated as a combination of two subtasks: (1) bag-of-words image retrievaland (2) post-verification using RANSAC geometric verification. The maincontribution of this study is the proposal of a novel post-verificationframework that achieves good precision recall trade-off in loop closuredetection. This study is motivated by the fact that not all loop closurehypotheses are equally plausible (e.g., owing to mutual consistency betweenloop closure constraints) and that if we have evidence that one hypothesis ismore plausible than the others, then it should be verified more frequently. Wedemonstrate that the problem of loop closure detection can be viewed as aninstance of a multi-model hypothesize-and-verify framework and build guidedsampling strategies on the framework where loop closures proposed using imageretrieval are verified in a planned order (rather than in a conventionaluniform order) to operate in a constant time. Experimental results using astereo SLAM system confirm that the proposed strategy, the use of loop closureconstraints and robot trajectory hypotheses as a guide, achieves promisingresults despite the fact that there exists a significant number of falsepositive constraints and hypotheses.
arxiv-12600-180 | A Hierarchical Distance-dependent Bayesian Model for Event Coreference Resolution | http://arxiv.org/pdf/1504.05929v2.pdf | author:Bishan Yang, Claire Cardie, Peter Frazier category:cs.CL stat.ML published:2015-04-22 summary:We present a novel hierarchical distance-dependent Bayesian model for eventcoreference resolution. While existing generative models for event coreferenceresolution are completely unsupervised, our model allows for the incorporationof pairwise distances between event mentions -- information that is widely usedin supervised coreference models to guide the generative clustering processingfor better event clustering both within and across documents. We model thedistances between event mentions using a feature-rich learnable distancefunction and encode them as Bayesian priors for nonparametric clustering.Experiments on the ECB+ corpus show that our model outperforms state-of-the-artmethods for both within- and cross-document event coreference resolution.
arxiv-12600-181 | Linear-time Learning on Distributions with Approximate Kernel Embeddings | http://arxiv.org/pdf/1509.07553v1.pdf | author:Dougal J. Sutherland, Junier B. Oliva, Barnabás Póczos, Jeff Schneider category:stat.ML cs.LG published:2015-09-24 summary:Many interesting machine learning problems are best posed by consideringinstances that are distributions, or sample sets drawn from distributions.Previous work devoted to machine learning tasks with distributional inputs hasdone so through pairwise kernel evaluations between pdfs (or sample sets).While such an approach is fine for smaller datasets, the computation of an $N\times N$ Gram matrix is prohibitive in large datasets. Recent scalableestimators that work over pdfs have done so only with kernels that useEuclidean metrics, like the $L_2$ distance. However, there are a myriad ofother useful metrics available, such as total variation, Hellinger distance,and the Jensen-Shannon divergence. This work develops the first random featuresfor pdfs whose dot product approximates kernels using these non-Euclideanmetrics, allowing estimators using such kernels to scale to large datasets byworking in a primal space, without computing large Gram matrices. We provide ananalysis of the approximation error in using our proposed random features andshow empirically the quality of our approximation both in estimating a Grammatrix and in solving learning tasks in real-world and synthetic data.
arxiv-12600-182 | On Optimizing Human-Machine Task Assignments | http://arxiv.org/pdf/1509.07543v1.pdf | author:Andreas Veit, Michael Wilber, Rajan Vaish, Serge Belongie, James Davis, Vishal Anand, Anshu Aviral, Prithvijit Chakrabarty, Yash Chandak, Sidharth Chaturvedi, Chinmaya Devaraj, Ankit Dhall, Utkarsh Dwivedi, Sanket Gupte, Sharath N. Sridhar, Karthik Paga, Anuj Pahuja, Aditya Raisinghani, Ayush Sharma, Shweta Sharma, Darpana Sinha, Nisarg Thakkar, K. Bala Vignesh, Utkarsh Verma, Kanniganti Abhishek, Amod Agrawal, Arya Aishwarya, Aurgho Bhattacharjee, Sarveshwaran Dhanasekar, Venkata Karthik Gullapalli, Shuchita Gupta, Chandana G, Kinjal Jain, Simran Kapur, Meghana Kasula, Shashi Kumar, Parth Kundaliya, Utkarsh Mathur, Alankrit Mishra, Aayush Mudgal, Aditya Nadimpalli, Munakala Sree Nihit, Akanksha Periwal, Ayush Sagar, Ayush Shah, Vikas Sharma, Yashovardhan Sharma, Faizal Siddiqui, Virender Singh, Abhinav S., Anurag. D. Yadav category:cs.HC cs.CV published:2015-09-24 summary:When crowdsourcing systems are used in combination with machine inferencesystems in the real world, they benefit the most when the machine system isdeeply integrated with the crowd workers. However, if researchers wish tointegrate the crowd with "off-the-shelf" machine classifiers, this deepintegration is not always possible. This work explores two strategies toincrease accuracy and decrease cost under this setting. First, we show thatreordering tasks presented to the human can create a significant accuracyimprovement. Further, we show that greedily choosing parameters to maximizemachine accuracy is sub-optimal, and joint optimization of the combined systemimproves performance.
arxiv-12600-183 | Description of the Odin Event Extraction Framework and Rule Language | http://arxiv.org/pdf/1509.07513v1.pdf | author:Marco A. Valenzuela-Escárcega, Gus Hahn-Powell, Mihai Surdeanu category:cs.CL published:2015-09-24 summary:This document describes the Odin framework, which is a domain-independentplatform for developing rule-based event extraction models. Odin aims to bepowerful (the rule language allows the modeling of complex syntacticstructures) and robust (to recover from syntactic parsing errors, syntacticpatterns can be freely mixed with surface, token-based patterns), whileremaining simple (some domain grammars can be up and running in minutes), andfast (Odin processes over 100 sentences/second in a real-world domain with over200 rules). Here we include a thorough definition of the Odin rule language,together with a description of the Odin API in the Scala language, which allowsone to apply these rules to arbitrary texts.
arxiv-12600-184 | Spatially Encoding Temporal Correlations to Classify Temporal Data Using Convolutional Neural Networks | http://arxiv.org/pdf/1509.07481v1.pdf | author:Zhiguang Wang, Tim Oates category:cs.LG published:2015-09-24 summary:We propose an off-line approach to explicitly encode temporal patternsspatially as different types of images, namely, Gramian Angular Fields andMarkov Transition Fields. This enables the use of techniques from computervision for feature learning and classification. We used Tiled ConvolutionalNeural Networks to learn high-level features from individual GAF, MTF, andGAF-MTF images on 12 benchmark time series datasets and two realspatial-temporal trajectory datasets. The classification results of ourapproach are competitive with state-of-the-art approaches on both types ofdata. An analysis of the features and weights learned by the CNNs explains whythe approach works.
arxiv-12600-185 | Learning Visual Clothing Style with Heterogeneous Dyadic Co-occurrences | http://arxiv.org/pdf/1509.07473v1.pdf | author:Andreas Veit, Balazs Kovacs, Sean Bell, Julian McAuley, Kavita Bala, Serge Belongie category:cs.CV published:2015-09-24 summary:With the rapid proliferation of smart mobile devices, users now take millionsof photos every day. These include large numbers of clothing and accessoryimages. We would like to answer questions like `What outfit goes well with thispair of shoes?' To answer these types of questions, one has to go beyondlearning visual similarity and learn a visual notion of compatibility acrosscategories. In this paper, we propose a novel learning framework to help answerthese types of questions. The main idea of this framework is to learn a featuretransformation from images of items into a latent space that expressescompatibility. For the feature transformation, we use a Siamese ConvolutionalNeural Network (CNN) architecture, where training examples are pairs of itemsthat are either compatible or incompatible. We model compatibility based onco-occurrence in large-scale user behavior data; in particular co-purchase datafrom Amazon.com. To learn cross-category fit, we introduce a strategic methodto sample training data, where pairs of items are heterogeneous dyads, i.e.,the two elements of a pair belong to different high-level categories. Whilethis approach is applicable to a wide variety of settings, we focus on therepresentative problem of learning compatible clothing style. Our resultsindicate that the proposed framework is capable of learning semanticinformation about visual style and is able to generate outfits of clothes, withitems from different categories, that go well together.
arxiv-12600-186 | Channel Vector Subspace Estimation from Low-Dimensional Projections | http://arxiv.org/pdf/1509.07469v1.pdf | author:Saeid Haghighatshoar, Giuseppe Caire category:cs.IT math.IT stat.ML published:2015-09-24 summary:In this paper, we propose efficient algorithms for estimating the signalsubspace of mobile users in a wireless communication environment with amulti-antenna base-station with $M$ antennas. We assume that, for reducing theRF front-end complexity and overall A/D conversion rate, the JSDMtransmitter/receiver is split into the product of a baseband linear projection(digital) and an RF reconfigurable beamforming network (analog) with only $m\ll M$ RF chains. This implies that only $m$ analog observations can beobtained for subspace estimation, and the standard sample covariance estimatoris not available. We develop efficient algorithms that estimate the dominant signal subspacefrom sampling only $m=O(2 \sqrt{M})$ specific array elements according to acoprime scheme, and for a given $p \leq M$, return a $p$-dimensional beamformerthat has a performance comparable with the best $p$-dim beamformer designed byknowing the exact covariance matrix of the received signal. We asses theperformance of our proposed estimators both analytically and empirically vianumerical simulations, and compare it with that of the other state-of-the-artmethods proposed in the literature, which are also reviewed and put in thecontext of estimating the subspace of the signal.
arxiv-12600-187 | Convolutional Channel Features | http://arxiv.org/pdf/1504.07339v3.pdf | author:Bin Yang, Junjie Yan, Zhen Lei, Stan Z. Li category:cs.CV published:2015-04-28 summary:Deep learning methods are powerful tools but often suffer from expensivecomputation and limited flexibility. An alternative is to combine light-weightmodels with deep representations. As successful cases exist in several visualproblems, a unified framework is absent. In this paper, we revisit two widelyused approaches in computer vision, namely filtered channel features andConvolutional Neural Networks (CNN), and absorb merits from both by proposingan integrated method called Convolutional Channel Features (CCF). CCF transferslow-level features from pre-trained CNN models to feed the boosting forestmodel. With the combination of CNN features and boosting forest, CCF benefitsfrom the richer capacity in feature representation compared with channelfeatures, as well as lower cost in computation and storage compared withend-to-end CNN methods. We show that CCF serves as a good way of tailoringpre-trained CNN models to diverse tasks without fine-tuning the whole networkto each task by achieving state-of-the-art performances in pedestriandetection, face detection, edge detection and object proposal generation.
arxiv-12600-188 | A Review of Feature Selection Methods Based on Mutual Information | http://arxiv.org/pdf/1509.07577v1.pdf | author:Jorge R. Vergara, Pablo A. Estévez category:cs.LG stat.ML published:2015-09-24 summary:In this work we present a review of the state of the art of informationtheoretic feature selection methods. The concepts of feature relevance,redundance and complementarity (synergy) are clearly defined, as well as Markovblanket. The problem of optimal feature selection is defined. A unifyingtheoretical framework is described, which can retrofit successful heuristiccriteria, indicating the approximations made by each method. A number of openproblems in the field are presented.
arxiv-12600-189 | Adaptive Sequential Optimization with Applications to Machine Learning | http://arxiv.org/pdf/1509.07422v1.pdf | author:Craig Wilson, Venugopal V. Veeravalli category:cs.LG cs.DS published:2015-09-24 summary:A framework is introduced for solving a sequence of slowly changingoptimization problems, including those arising in regression and classificationapplications, using optimization algorithms such as stochastic gradient descent(SGD). The optimization problems change slowly in the sense that the minimizerschange at either a fixed or bounded rate. A method based on estimates of thechange in the minimizers and properties of the optimization algorithm isintroduced for adaptively selecting the number of samples needed from thedistributions underlying each problem in order to ensure that the excess risk,i.e., the expected gap between the loss achieved by the approximate minimizerproduced by the optimization algorithm and the exact minimizer, does not exceeda target level. Experiments with synthetic and real data are used to confirmthat this approach performs well.
arxiv-12600-190 | Towards Real-time Customer Experience Prediction for Telecommunication Operators | http://arxiv.org/pdf/1508.02884v2.pdf | author:Ernesto Diaz-Aviles, Fabio Pinelli, Karol Lynch, Zubair Nabi, Yiannis Gkoufas, Eric Bouillet, Francesco Calabrese, Eoin Coughlan, Peter Holland, Jason Salzwedel category:cs.CY cs.IR stat.ML published:2015-08-12 summary:Telecommunications operators (telcos) traditional sources of income, voiceand SMS, are shrinking due to customers using over-the-top (OTT) applicationssuch as WhatsApp or Viber. In this challenging environment it is critical fortelcos to maintain or grow their market share, by providing users with as goodan experience as possible on their network. But the task of extracting customer insights from the vast amounts of datacollected by telcos is growing in complexity and scale everey day. How can wemeasure and predict the quality of a user's experience on a telco network inreal-time? That is the problem that we address in this paper. We present an approach to capture, in (near) real-time, the mobile customerexperience in order to assess which conditions lead the user to place a call toa telco's customer care center. To this end, we follow a supervised learningapproach for prediction and train our 'Restricted Random Forest' model using,as a proxy for bad experience, the observed customer transactions in the telcodata feed before the user places a call to a customer care center. We evaluate our approach using a rich dataset provided by a major Africantelecommunication's company and a novel big data architecture for both thetraining and scoring of predictive models. Our empirical study shows oursolution to be effective at predicting user experience by inferring if acustomer will place a call based on his current context. These promising results open new possibilities for improved customer service,which will help telcos to reduce churn rates and improve customer experience,both factors that directly impact their revenue growth.
arxiv-12600-191 | A marginal sampler for $σ$-Stable Poisson-Kingman mixture models | http://arxiv.org/pdf/1407.4211v3.pdf | author:María Lomelí, Stefano Favaro, Yee Whye Teh category:stat.CO stat.ML published:2014-07-16 summary:We investigate the class of $\sigma$-stable Poisson-Kingman randomprobability measures (RPMs) in the context of Bayesian nonparametric mixturemodeling. This is a large class of discrete RPMs which encompasses most of thethe popular discrete RPMs used in Bayesian nonparametrics, such as theDirichlet process, Pitman-Yor process, the normalized inverse Gaussian processand the normalized generalized Gamma process. We show how certain samplingproperties and marginal characterizations of $\sigma$-stable Poisson-KingmanRPMs can be usefully exploited for devising a Markov chain Monte Carlo (MCMC)algorithm for making inference in Bayesian nonparametric mixture modeling.Specifically, we introduce a novel and efficient MCMC sampling scheme in anaugmented space that has a fixed number of auxiliary variables per iteration.We apply our sampling scheme for a density estimation and clustering tasks withunidimensional and multidimensional datasets, and we compare it againstcompeting sampling schemes.
arxiv-12600-192 | Designing Behaviour in Bio-inspired Robots Using Associative Topologies of Spiking-Neural-Networks | http://arxiv.org/pdf/1509.07035v2.pdf | author:Cristian Jimenez-Romero, David Sousa-Rodrigues, Jeffrey H. Johnson category:cs.RO cs.AI cs.NE published:2015-09-23 summary:This study explores the design and control of the behaviour of agents androbots using simple circuits of spiking neurons and Spike Timing DependentPlasticity (STDP) as a mechanism of associative and unsupervised learning.Based on a "reward and punishment" classical conditioning, it is demonstratedthat these robots learnt to identify and avoid obstacles as well as to identifyand look for rewarding stimuli. Using the simulation and programmingenvironment NetLogo, a software engine for the Integrate and Fire model wasdeveloped, which allowed us to monitor in discrete time steps the dynamics ofeach single neuron, synapse and spike in the proposed neural networks. Thesespiking neural networks (SNN) served as simple brains for the experimentalrobots. The Lego Mindstorms robot kit was used for the embodiment of thesimulated agents. In this paper the topological building blocks are presentedas well as the neural parameters required to reproduce the experiments. Thispaper summarizes the resulting behaviour as well as the observed dynamics ofthe neural circuits. The Internet-link to the NetLogo code is included in theannex.
arxiv-12600-193 | Semantic Image Segmentation via Deep Parsing Network | http://arxiv.org/pdf/1509.02634v2.pdf | author:Ziwei Liu, Xiaoxiao Li, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV published:2015-09-09 summary:This paper addresses semantic image segmentation by incorporating richinformation into Markov Random Field (MRF), including high-order relations andmixture of label contexts. Unlike previous works that optimized MRFs usingiterative algorithm, we solve MRF by proposing a Convolutional Neural Network(CNN), namely Deep Parsing Network (DPN), which enables deterministicend-to-end computation in a single forward pass. Specifically, DPN extends acontemporary CNN architecture to model unary terms and additional layers arecarefully devised to approximate the mean field algorithm (MF) for pairwiseterms. It has several appealing properties. First, different from the recentworks that combined CNN and MRF, where many iterations of MF were required foreach training image during back-propagation, DPN is able to achieve highperformance by approximating one iteration of MF. Second, DPN representsvarious types of pairwise terms, making many existing works as its specialcases. Third, DPN makes MF easier to be parallelized and speeded up inGraphical Processing Unit (GPU). DPN is thoroughly evaluated on the PASCAL VOC2012 dataset, where a single DPN model yields a new state-of-the-artsegmentation accuracy.
arxiv-12600-194 | Deep Learning Face Attributes in the Wild | http://arxiv.org/pdf/1411.7766v3.pdf | author:Ziwei Liu, Ping Luo, Xiaogang Wang, Xiaoou Tang category:cs.CV published:2014-11-28 summary:Predicting face attributes in the wild is challenging due to complex facevariations. We propose a novel deep learning framework for attribute predictionin the wild. It cascades two CNNs, LNet and ANet, which are fine-tuned jointlywith attribute tags, but pre-trained differently. LNet is pre-trained bymassive general object categories for face localization, while ANet ispre-trained by massive face identities for attribute prediction. This frameworknot only outperforms the state-of-the-art with a large margin, but also revealsvaluable facts on learning face representation. (1) It shows how the performances of face localization (LNet) and attributeprediction (ANet) can be improved by different pre-training strategies. (2) It reveals that although the filters of LNet are fine-tuned only withimage-level attribute tags, their response maps over entire images have strongindication of face locations. This fact enables training LNet for facelocalization with only image-level annotations, but without face bounding boxesor landmarks, which are required by all attribute recognition works. (3) It also demonstrates that the high-level hidden neurons of ANetautomatically discover semantic concepts after pre-training with massive faceidentities, and such concepts are significantly enriched after fine-tuning withattribute tags. Each attribute can be well explained with a sparse linearcombination of these concepts.
arxiv-12600-195 | Opinion mining from twitter data using evolutionary multinomial mixture models | http://arxiv.org/pdf/1509.07344v1.pdf | author:Md. Abul Hasnat, Julien Velcin, Stéphane Bonnevay, Julien Jacques category:cs.IR stat.ML published:2015-09-24 summary:Image of an entity can be defined as a structured and dynamic representationwhich can be extracted from the opinions of a group of users or population.Automatic extraction of such an image has certain importance in politicalscience and sociology related studies, e.g., when an extended inquiry fromlarge-scale data is required. We study the images of two politicallysignificant entities of France. These images are constructed by analyzing theopinions collected from a well known social media called Twitter. Our goal isto build a system which can be used to automatically extract the image ofentities over time. In this paper, we propose a novel evolutionary clustering method based on theparametric link among Multinomial mixture models. First we propose theformulation of a generalized model that establishes parametric links among theMultinomial distributions. Afterward, we follow a model-based clusteringapproach to explore different parametric sub-models and select the best model.For the experiments, first we use synthetic temporal data. Next, we apply themethod to analyze the annotated social media data. Results show that theproposed method is better than the state-of-the-art based on the commonevaluation metrics. Additionally, our method can provide interpretation aboutthe temporal evolution of the clusters.
arxiv-12600-196 | Facial landmark detection using structured output deep neural networks | http://arxiv.org/pdf/1504.07550v3.pdf | author:Soufiane Belharbi, Clement Chatelain, Romain Herault, Sebastien Adam category:cs.LG stat.ML published:2015-04-28 summary:Facial landmark detection is an important step for many perception tasks suchas face recognition and facial analysis. Regression-based methods have shown alarge success. In particular, deep neural networks (DNN) has demonstrated astrong capability to model the high non-linearity between the face image andthe face shape. In this paper, we tackle this task as a structured outputproblem, where we exploit the strong dependencies that lie between the outputs.Beside learning a regression mapping function from the input to the output, welearn, in an unsupervised way, the inter-dependencies between the outputs. Forthis, we propose a generic regression framework for structured output problems.Our framework allows a successful incorporation of learning the outputstructure into DNN using the pre-training trick. We apply our method on afacial landmark detection task, where the output is strongly structured. Weevaluate our DNN, named Input/Output Deep Architecture (IODA), on two publicchallenging datasets: LFPW and HELEN. We show that IODA outperforms traditionaldeep architectures.
arxiv-12600-197 | An Asymptotically Optimal Policy for Uniform Bandits of Unknown Support | http://arxiv.org/pdf/1505.01918v3.pdf | author:Wesley Cowan, Michael N. Katehakis category:stat.ML cs.LG published:2015-05-08 summary:Consider the problem of a controller sampling sequentially from a finitenumber of $N \geq 2$ populations, specified by random variables $X^i_k$, $ i =1,\ldots , N,$ and $k = 1, 2, \ldots$; where $X^i_k$ denotes the outcome frompopulation $i$ the $k^{th}$ time it is sampled. It is assumed that for eachfixed $i$, $\{ X^i_k \}_{k \geq 1}$ is a sequence of i.i.d. uniform randomvariables over some interval $[a_i, b_i]$, with the support (i.e., $a_i, b_i$)unknown to the controller. The objective is to have a policy $\pi$ fordeciding, based on available data, from which of the $N$ populations to samplefrom at any time $n=1,2,\ldots$ so as to maximize the expected sum of outcomesof $n$ samples or equivalently to minimize the regret due to lack oninformation of the parameters $\{ a_i \}$ and $\{ b_i \}$. In this paper, wepresent a simple inflated sample mean (ISM) type policy that is asymptoticallyoptimal in the sense of its regret achieving the asymptotic lower bound ofBurnetas and Katehakis (1996). Additionally, finite horizon regret bounds aregiven.
arxiv-12600-198 | A Large-Scale Car Dataset for Fine-Grained Categorization and Verification | http://arxiv.org/pdf/1506.08959v2.pdf | author:Linjie Yang, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV cs.AI published:2015-06-30 summary:Updated on 24/09/2015: This update provides preliminary experiment resultsfor fine-grained classification on the surveillance data of CompCars. Thetrain/test splits are provided in the updated dataset. See details in Section6.
arxiv-12600-199 | Sparsity-based Correction of Exponential Artifacts | http://arxiv.org/pdf/1509.07234v1.pdf | author:Yin Ding, Ivan W. Selesnick category:cs.LG published:2015-09-24 summary:This paper describes an exponential transient excision algorithm (ETEA). Inbiomedical time series analysis, e.g., in vivo neural recording andelectrocorticography (ECoG), some measurement artifacts take the form ofpiecewise exponential transients. The proposed method is formulated as anunconstrained convex optimization problem, regularized by smoothed l1-normpenalty function, which can be solved by majorization-minimization (MM) method.With a slight modification of the regularizer, ETEA can also suppress moreirregular piecewise smooth artifacts, especially, ocular artifacts (OA) inelectroencephalog- raphy (EEG) data. Examples of synthetic signal, EEG data,and ECoG data are presented to illustrate the proposed algorithms.
arxiv-12600-200 | Automatic Concept Discovery from Parallel Text and Visual Corpora | http://arxiv.org/pdf/1509.07225v1.pdf | author:Chen Sun, Chuang Gan, Ram Nevatia category:cs.CV published:2015-09-24 summary:Humans connect language and vision to perceive the world. How to build asimilar connection for computers? One possible way is via visual concepts,which are text terms that relate to visually discriminative entities. Wepropose an automatic visual concept discovery algorithm using parallel text andvisual corpora; it filters text terms based on the visual discriminative powerof the associated images, and groups them into concepts using visual andsemantic similarities. We illustrate the applications of the discoveredconcepts using bidirectional image and sentence retrieval task and imagetagging task, and show that the discovered concepts not only outperform severallarge sets of manually selected concepts significantly, but also achieves thestate-of-the-art performance in the retrieval task.
arxiv-12600-201 | Noise-Robust ASR for the third 'CHiME' Challenge Exploiting Time-Frequency Masking based Multi-Channel Speech Enhancement and Recurrent Neural Network | http://arxiv.org/pdf/1509.07211v1.pdf | author:Zaihu Pang, Fengyun Zhu category:cs.SD cs.CL published:2015-09-24 summary:In this paper, the Lingban entry to the third 'CHiME' speech separation andrecognition challenge is presented. A time-frequency masking based speechenhancement front-end is proposed to suppress the environmental noise utilizingmulti-channel coherence and spatial cues. The state-of-the-art speechrecognition techniques, namely recurrent neural network based acoustic andlanguage modeling, state space minimum Bayes risk based discriminative acousticmodeling, and i-vector based acoustic condition modeling, are carefullyintegrated into the speech recognition back-end. To further improve the systemperformance by fully exploiting the advantages of different technologies, thefinal recognition results are obtained by lattice combination and rescoring.Evaluations carried out on the official dataset prove the effectiveness of theproposed systems. Comparing with the best baseline result, the proposed systemobtains consistent improvements with over 57% relative word error ratereduction on the real-data test set.
arxiv-12600-202 | IllinoisSL: A JAVA Library for Structured Prediction | http://arxiv.org/pdf/1509.07179v1.pdf | author:Kai-Wei Chang, Shyam Upadhyay, Ming-Wei Chang, Vivek Srikumar, Dan Roth category:cs.LG cs.CL stat.ML published:2015-09-23 summary:IllinoisSL is a Java library for learning structured prediction models. Itsupports structured Support Vector Machines and structured Perceptron. Thelibrary consists of a core learning module and several applications, which canbe executed from command-lines. Documentation is provided to guide users. InComparison to other structured learning libraries, IllinoisSL is efficient,general, and easy to use.
arxiv-12600-203 | Object detection via a multi-region & semantic segmentation-aware CNN model | http://arxiv.org/pdf/1505.01749v3.pdf | author:Spyros Gidaris, Nikos Komodakis category:cs.CV cs.LG cs.NE published:2015-05-07 summary:We propose an object detection system that relies on a multi-region deepconvolutional neural network (CNN) that also encodes semanticsegmentation-aware features. The resulting CNN-based representation aims atcapturing a diverse set of discriminative appearance factors and exhibitslocalization sensitivity that is essential for accurate object localization. Weexploit the above properties of our recognition module by integrating it on aniterative localization mechanism that alternates between scoring a box proposaland refining its location with a deep CNN regression model. Thanks to theefficient use of our modules, we detect objects with very high localizationaccuracy. On the detection challenges of PASCAL VOC2007 and PASCAL VOC2012 weachieve mAP of 78.2% and 73.9% correspondingly, surpassing any other publishedwork by a significant margin.
arxiv-12600-204 | A Nonparametric Bayesian Approach Toward Stacked Convolutional Independent Component Analysis | http://arxiv.org/pdf/1411.4423v5.pdf | author:Sotirios P. Chatzis category:cs.CV published:2014-11-17 summary:Unsupervised feature learning algorithms based on convolutional formulationsof independent components analysis (ICA) have been demonstrated to yieldstate-of-the-art results in several action recognition benchmarks. However,existing approaches do not allow for the number of latent components (features)to be automatically inferred from the data in an unsupervised manner. This is asignificant disadvantage of the state-of-the-art, as it results in considerableburden imposed on researchers and practitioners, who must resort to tediouscross-validation procedures to obtain the optimal number of latent features. Toresolve these issues, in this paper we introduce a convolutional nonparametricBayesian sparse ICA architecture for overcomplete feature learning fromhigh-dimensional data. Our method utilizes an Indian buffet process prior tofacilitate inference of the appropriate number of latent features under ahybrid variational inference algorithm, scalable to massive datasets. As weshow, our model can be naturally used to obtain deep unsupervised hierarchicalfeature extractors, by greedily stacking successive model layers, similar toexisting approaches. In addition, inference for this model is completelyheuristics-free; thus, it obviates the need of tedious parameter tuning, whichis a major challenge most deep learning approaches are faced with. We evaluateour method on several action recognition benchmarks, and exhibit its advantagesover the state-of-the-art.
arxiv-12600-205 | A review of learning vector quantization classifiers | http://arxiv.org/pdf/1509.07093v1.pdf | author:David Nova, Pablo A. Estevez category:cs.LG astro-ph.IM cs.NE stat.ML published:2015-09-23 summary:In this work we present a review of the state of the art of Learning VectorQuantization (LVQ) classifiers. A taxonomy is proposed which integrates themost relevant LVQ approaches to date. The main concepts associated with modernLVQ approaches are defined. A comparison is made among eleven LVQ classifiersusing one real-world and two artificial datasets.
arxiv-12600-206 | Deep Temporal Sigmoid Belief Networks for Sequence Modeling | http://arxiv.org/pdf/1509.07087v1.pdf | author:Zhe Gan, Chunyuan Li, Ricardo Henao, David Carlson, Lawrence Carin category:stat.ML cs.LG published:2015-09-23 summary:Deep dynamic generative models are developed to learn sequential dependenciesin time-series data. The multi-layered model is designed by constructing ahierarchy of temporal sigmoid belief networks (TSBNs), defined as a sequentialstack of sigmoid belief networks (SBNs). Each SBN has a contextual hiddenstate, inherited from the previous SBNs in the sequence, and is used toregulate its hidden bias. Scalable learning and inference algorithms arederived by introducing a recognition model that yields fast sampling from thevariational posterior. This recognition model is trained jointly with thegenerative model, by maximizing its variational lower bound on thelog-likelihood. Experimental results on bouncing balls, polyphonic music,motion capture, and text streams show that the proposed approach achievesstate-of-the-art predictive performance, and has the capacity to synthesizevarious sequences.
arxiv-12600-207 | Fractionally-Supervised Classification | http://arxiv.org/pdf/1307.3598v5.pdf | author:Irene Vrbik, Paul D. McNicholas category:stat.ME stat.AP stat.CO stat.ML published:2013-07-13 summary:Traditionally, there are three species of classification: unsupervised,supervised, and semi-supervised. Supervised and semi-supervised classificationdiffer by whether or not weight is given to unlabelled observations in theclassification procedure. In unsupervised classification, or clustering, allobservations are unlabeled and hence full weight is given to unlabelledobservations. When some observations are unlabelled, it can be very difficultto \textit{a~priori} choose the optimal level of supervision, and theconsequences of a sub-optimal choice can be non-trivial. A flexiblefractionally-supervised approach to classification is introduced, where anylevel of supervision --- ranging from unsupervised to supervised --- can beattained. Our approach uses a weighted likelihood, wherein weights control therelative role that labelled and unlabelled data have in building a classifier.A comparison between our approach and the traditional species is presentedusing simulated and real data. Gaussian mixture models are used as a vehicle toillustrate our fractionally-supervised classification approach; however, it isbroadly applicable and variations on the postulated model can be easily made.
arxiv-12600-208 | Well Tops Guided Prediction of Reservoir Properties using Modular Neural Network Concept A Case Study from Western Onshore, India | http://arxiv.org/pdf/1509.07079v1.pdf | author:Soumi Chaki, Akhilesh K Verma, Aurobinda Routray, William K Mohanty, Mamata Jenamani category:cs.NE cs.CE published:2015-09-23 summary:This paper proposes a complete framework consisting pre-processing, modeling,and post-processing stages to carry out well tops guided prediction of areservoir property (sand fraction) from three seismic attributes (seismicimpedance, instantaneous amplitude, and instantaneous frequency) using theconcept of modular artificial neural network (MANN). The data set used in thisstudy comprising three seismic attributes and well log data from eight wells,is acquired from a western onshore hydrocarbon field of India. Firstly, theacquired data set is integrated and normalized. Then, well log analysis andsegmentation of the total depth range into three different units (zones)separated by well tops are carried out. Secondly, three different networks aretrained corresponding to three different zones using combined data set of sevenwells and then trained networks are validated using the remaining test well.The target property of the test well is predicted using three different tunednetworks corresponding to three zones; and then the estimated values obtainedfrom three different networks are concatenated to represent the predicted logalong the complete depth range of the testing well. The application of multiplesimpler networks instead of a single one improves the prediction accuracy interms of performance metrics such as correlation coefficient, root mean squareerror, absolute error mean and program execution time.
arxiv-12600-209 | 3D Scan Registration using Curvelet Features in Planetary Environments | http://arxiv.org/pdf/1509.07075v1.pdf | author:Siddhant Ahuja, Peter Iles, Steven L. Waslander category:cs.CV cs.RO published:2015-09-23 summary:Topographic mapping in planetary environments relies on accurate 3D scanregistration methods. However, most global registration algorithms relying onfeatures such as FPFH and Harris-3D show poor alignment accuracy in thesesettings due to the poor structure of the Mars-like terrain and variableresolution, occluded, sparse range data that is hard to register without somea-priori knowledge of the environment. In this paper, we propose an alternativeapproach to 3D scan registration using the curvelet transform that performsmulti-resolution geometric analysis to obtain a set of coefficients indexed byscale (coarsest to finest), angle and spatial position. Features are detectedin the curvelet domain to take advantage of the directional selectivity of thetransform. A descriptor is computed for each feature by calculating the 3Dspatial histogram of the image gradients, and nearest neighbor based matchingis used to calculate the feature correspondences. Correspondence rejectionusing Random Sample Consensus identifies inliers, and a locally optimalSingular Value Decomposition-based estimation of the rigid-body transformationaligns the laser scans given the re-projected correspondences in the metricspace. Experimental results on a publicly available data-set of planetaryanalogue indoor facility, as well as simulated and real-world scans from NeptecDesign Group's IVIGMS 3D laser rangefinder at the outdoor CSA Mars yarddemonstrates improved performance over existing methods in the challengingsparse Mars-like terrain.
arxiv-12600-210 | A Novel Pre-processing Scheme to Improve the Prediction of Sand Fraction from Seismic Attributes using Neural Networks | http://arxiv.org/pdf/1509.07065v1.pdf | author:Soumi Chaki, Aurobinda Routray, William K. Mohanty category:cs.CE cs.LG published:2015-09-23 summary:This paper presents a novel pre-processing scheme to improve the predictionof sand fraction from multiple seismic attributes such as seismic impedance,amplitude and frequency using machine learning and information filtering. Theavailable well logs along with the 3-D seismic data have been used to benchmarkthe proposed pre-processing stage using a methodology which primarily consistsof three steps: pre-processing, training and post-processing. An ArtificialNeural Network (ANN) with conjugate-gradient learning algorithm has been usedto model the sand fraction. The available sand fraction data from the highresolution well logs has far more information content than the low resolutionseismic attributes. Therefore, regularization schemes based on FourierTransform (FT), Wavelet Decomposition (WD) and Empirical Mode Decomposition(EMD) have been proposed to shape the high resolution sand fraction data foreffective machine learning. The input data sets have been segregated intotraining, testing and validation sets. The test results are primarily used tocheck different network structures and activation function performances. Oncethe network passes the testing phase with an acceptable performance in terms ofthe selected evaluators, the validation phase follows. In the validation stage,the prediction model is tested against unseen data. The network yieldingsatisfactory performance in the validation stage is used to predictlithological properties from seismic attributes throughout a given volume.Finally, a post-processing scheme using 3-D spatial filtering is implementedfor smoothing the sand fraction in the volume. Prediction of lithologicalproperties using this framework is helpful for Reservoir Characterization.
arxiv-12600-211 | Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks | http://arxiv.org/pdf/1506.03099v3.pdf | author:Samy Bengio, Oriol Vinyals, Navdeep Jaitly, Noam Shazeer category:cs.LG cs.CL cs.CV published:2015-06-09 summary:Recurrent Neural Networks can be trained to produce sequences of tokens givensome input, as exemplified by recent results in machine translation and imagecaptioning. The current approach to training them consists of maximizing thelikelihood of each token in the sequence given the current (recurrent) stateand the previous token. At inference, the unknown previous token is thenreplaced by a token generated by the model itself. This discrepancy betweentraining and inference can yield errors that can accumulate quickly along thegenerated sequence. We propose a curriculum learning strategy to gently changethe training process from a fully guided scheme using the true previous token,towards a less guided scheme which mostly uses the generated token instead.Experiments on several sequence prediction tasks show that this approach yieldssignificant improvements. Moreover, it was used successfully in our winningentry to the MSCOCO image captioning challenge, 2015.
arxiv-12600-212 | Fast k-NN search | http://arxiv.org/pdf/1509.06957v1.pdf | author:Ville Hyvönen, Teemu Pitkänen, Sotiris Tasoulis, Liang Wang, Teemu Roos, Jukka Corander category:stat.ML cs.DS cs.LG published:2015-09-23 summary:Random projection trees have proven to be effective for approximate nearestneighbor searches in high dimensional spaces where conventional methods are notapplicable due to excessive usage of memory and computational time. We showthat building multiple trees on the same data can improve the performance evenfurther, without significantly increasing the total computational cost ofqueries when executed in a modern parallel computing environment. Ourexperiments identify suitable parameter values to achieve accurate searcheswith extremely fast query times, while also retaining a feasible complexity forindex construction.
arxiv-12600-213 | Enabling Depth-driven Visual Attention on the iCub Humanoid Robot: Instructions for Use and New Perspectives | http://arxiv.org/pdf/1509.06939v1.pdf | author:Giulia Pasquale, Tanis Mar, Carlo Ciliberto, Lorenzo Rosasco, Lorenzo Natale category:cs.RO cs.CV published:2015-09-23 summary:The importance of depth perception in the interactions that humans havewithin their nearby space is a well established fact. Consequently, it is alsowell known that the possibility of exploiting good stereo information wouldease and, in many cases, enable, a large variety of attentional and interactivebehaviors on humanoid robotic platforms. However, the difficulty of computingreal-time and robust binocular disparity maps from moving stereo cameras oftenprevents from relying on this kind of cue to visually guide robots' attentionand actions in real-world scenarios. The contribution of this paper istwo-fold: first, we show that the Efficient Large-scale Stereo Matchingalgorithm (ELAS) by A. Geiger et al. 2010 for computation of the disparity mapis well suited to be used on a humanoid robotic platform as the iCub robot;second, we show how, provided with a fast and reliable stereo system,implementing relatively challenging visual behaviors in natural settings canrequire much less effort. As a case of study we consider the common situationwhere the robot is asked to focus the attention on one object close in thescene, showing how a simple but effective disparity-based segmentation solvesthe problem in this case. Indeed this example paves the way to a variety ofother similar applications.
arxiv-12600-214 | Fully automatic multi-language translation with a catalogue of phrases - successful employment for the Swiss avalanche bulletin | http://arxiv.org/pdf/1509.06937v1.pdf | author:Kurt Winkler, Tobias Kuhn category:cs.CL published:2015-09-23 summary:The Swiss avalanche bulletin is produced twice a day in four languages. Dueto the lack of time available for manual translation, a fully automatedtranslation system is employed, based on a catalogue of predefined phrases andpredetermined rules of how these phrases can be combined to produce sentences.Because this catalogue of phrases is limited to a small sublanguage, the systemis able to automatically translate such sentences from German into the targetlanguages French, Italian and English without subsequent proofreading orcorrection. Having been operational for two winter seasons, we assess here thequality of the produced texts based on two different surveys where participantsrated texts from real avalanche bulletins from both origins, the catalogue ofphrases versus manually written and translated texts. With a mean recognitionrate of 55%, users can hardly distinguish between thetwo types of texts, andgive very similar ratings with respect to their language quality. Overall, theoutput from the catalogue system can be considered virtually equivalent to atext written by avalanche forecasters and then manually translated byprofessional translators. Furthermore, forecasters declared that all relevantsituations were captured by the system with sufficient accuracy. Forecaster'sworking load did not change with the introduction of the catalogue: the extratime to find matching sentences is compensated by the fact that they no longerneed to double-check manually translated texts. The reduction of dailytranslation costs is expected to offset the initial development costs within afew years.
arxiv-12600-215 | Automatic Dialect Detection in Arabic Broadcast Speech | http://arxiv.org/pdf/1509.06928v1.pdf | author:Ahmed Ali, Peter Bell, Steve Renals category:cs.CL published:2015-09-23 summary:We investigate different approaches for dialect identification in Arabicbroadcast speech, using phonetic, lexical features obtained from a speechrecognition system, and acoustic features using the i-vector framework. Westudied both generative and discriminate classifiers, and we combined thesefeatures using a multi-class Support Vector Machine (SVM). We validated ourresults on an Arabic/English language identification task, with an accuracy of100%. We used these features in a binary classifier to discriminate betweenModern Standard Arabic (MSA) and Dialectal Arabic, with an accuracy of 100%. Wefurther report results using the proposed method to discriminate between thefive most widely used dialects of Arabic: namely Egyptian, Gulf, Levantine,North African, and MSA, with an accuracy of 52%. We discuss dialectidentification errors in the context of dialect code-switching betweenDialectal Arabic and MSA, and compare the error pattern between manuallylabeled data, and the output from our classifier. We also release the train andtest data as standard corpus for dialect identification.
arxiv-12600-216 | Robust Object Tracking with a Hierarchical Ensemble Framework | http://arxiv.org/pdf/1509.06925v1.pdf | author:Mengmeng Wang, Yong Liu category:cs.CV published:2015-09-23 summary:Autonomous robots enjoy a wide popularity nowadays and have been applied inmany applications, such as home security, entertainment, delivery, navigationand guidance. It is vital to robots to track objects accurately in theseapplications, so it is necessary to focus on tracking algorithms to improve therobustness and accuracy. In this paper, we propose a robust object trackingalgorithm based on a hierarchical ensemble framework which can incorporateinformation including individual pixel features, local patches and holistictarget models. The framework combines multiple ensemble models simultaneouslyinstead of using a single ensemble model individually. A discriminative modelwhich accounts for the matching degree of local patches is adopted via a bottomensemble layer, and a generative model which exploits holistic templates isused to search for the object through the middle ensemble layer as well as anadaptive Kalman filter. We test the proposed tracker on challenging benchmarkimage sequences. Both qualitative and quantitative evaluations demonstrate thatthe proposed tracker performs superiorly against several state-of-the-artalgorithms, especially when the appearance changes dramatically and theocclusions occur.
arxiv-12600-217 | Predicting Climate Variability over the Indian Region Using Data Mining Strategies | http://arxiv.org/pdf/1509.06920v1.pdf | author:Naresh Kumar Mallenahalli category:stat.ML physics.ao-ph published:2015-09-23 summary:In this paper an approach based on expectation maximization (EM) clusteringto find the climate regions and a support vector machine to build a predictivemodel for each of these regions is proposed. To minimize the biases in theestimations a ten cross fold validation is adopted both for obtaining clustersand building the predictive models. The EM clustering could identify all thezones as per the Koppen classification over Indian region. The proposedstrategy when employed for predicting temperature has resulted in an RMSE of$1.19$ in the Montane climate region and $0.89$ in the Humid Sub Tropicalregion as compared to $2.9$ and $0.95$ respectively predicted using k-means andlinear regression method.
arxiv-12600-218 | P-CNN: Pose-based CNN Features for Action Recognition | http://arxiv.org/pdf/1506.03607v2.pdf | author:Guilhem Chéron, Ivan Laptev, Cordelia Schmid category:cs.CV published:2015-06-11 summary:This work targets human action recognition in video. While recent methodstypically represent actions by statistics of local video features, here weargue for the importance of a representation derived from human pose. To thisend we propose a new Pose-based Convolutional Neural Network descriptor (P-CNN)for action recognition. The descriptor aggregates motion and appearanceinformation along tracks of human body parts. We investigate different schemesof temporal aggregation and experiment with P-CNN features obtained both forautomatically estimated and manually annotated human poses. We evaluate ourmethod on the recent and challenging JHMDB and MPII Cooking datasets. For bothdatasets our method shows consistent improvement over the state of the art.
arxiv-12600-219 | Efficient reconstruction of transmission probabilities in a spreading process from partial observations | http://arxiv.org/pdf/1509.06893v1.pdf | author:Andrey Y. Lokhov, Theodor Misiakiewicz category:physics.soc-ph cs.LG cs.SI stat.ML published:2015-09-23 summary:An important problem of reconstruction of diffusion network and transmissionprobabilities from the data has attracted a considerable attention in the pastseveral years. A number of recent papers introduced efficient algorithms forthe estimation of spreading parameters, based on the maximization of thelikelihood of observed cascades, assuming that the full information for all thenodes in the network is available. In this work, we focus on a more realisticand restricted scenario, in which only a partial information on the cascades isavailable: either the set of activation times for a limited number of nodes, orthe states of nodes for a subset of observation times. To tackle this problem,we first introduce a framework based on the maximization of the likelihood ofthe incomplete diffusion trace. However, we argue that the computation of thisincomplete likelihood is a computationally hard problem, and show that a fastand robust reconstruction of transmission probabilities in sparse networks canbe achieved with a new algorithm based on recently introduced dynamicmessage-passing equations for the spreading processes. The suggested approachcan be easily generalized to a large class of discrete and continuous dynamicmodels, as well as to the cases of dynamically-changing networks and noisyinformation.
arxiv-12600-220 | New Fuzzy LBP Features for Face Recognition | http://arxiv.org/pdf/1509.06853v1.pdf | author:Abdullah Gubbi, Mohammed Fazle Azeem, Zahid Ansari category:cs.CV published:2015-09-23 summary:There are many Local texture features each very in way they implement andeach of the Algorithm trying improve the performance. An attempt is made inthis paper to represent a theoretically very simple and computationallyeffective approach for face recognition. In our implementation the face imageis divided into 3x3 sub-regions from which the features are extracted using theLocal Binary Pattern (LBP) over a window, fuzzy membership function and at thecentral pixel. The LBP features possess the texture discriminative property andtheir computational cost is very low. By utilising the information from LBP,membership function, and central pixel, the limitations of traditional LBP iseliminated. The bench mark database like ORL and Sheffield Databases are usedfor the evaluation of proposed features with SVM classifier. For the proposedapproach K-fold and ROC curves are obtained and results are compared.
arxiv-12600-221 | Minimum Weight Perfect Matching via Blossom Belief Propagation | http://arxiv.org/pdf/1509.06849v1.pdf | author:Sungsoo Ahn, Sejun Park, Michael Chertkov, Jinwoo Shin category:cs.DS cs.AI stat.ML published:2015-09-23 summary:Max-product Belief Propagation (BP) is a popular message-passing algorithmfor computing a Maximum-A-Posteriori (MAP) assignment over a distributionrepresented by a Graphical Model (GM). It has been shown that BP can solve anumber of combinatorial optimization problems including minimum weightmatching, shortest path, network flow and vertex cover under the followingcommon assumption: the respective Linear Programming (LP) relaxation is tight,i.e., no integrality gap is present. However, when LP shows an integrality gap,no model has been known which can be solved systematically via sequentialapplications of BP. In this paper, we develop the first such algorithm, coinedBlossom-BP, for solving the minimum weight matching problem over arbitrarygraphs. Each step of the sequential algorithm requires applying BP over amodified graph constructed by contractions and expansions of blossoms, i.e.,odd sets of vertices. Our scheme guarantees termination in O(n^2) of BP runs,where n is the number of vertices in the original graph. In essence, theBlossom-BP offers a distributed version of the celebrated Edmonds' Blossomalgorithm by jumping at once over many sub-steps with a single BP. Moreover,our result provides an interpretation of the Edmonds' algorithm as a sequenceof LPs.
arxiv-12600-222 | Learning Deep Neural Network Policies with Continuous Memory States | http://arxiv.org/pdf/1507.01273v2.pdf | author:Marvin Zhang, Zoe McCarthy, Chelsea Finn, Sergey Levine, Pieter Abbeel category:cs.LG cs.RO published:2015-07-05 summary:Policy learning for partially observed control tasks requires policies thatcan remember salient information from past observations. In this paper, wepresent a method for learning policies with internal memory forhigh-dimensional, continuous systems, such as robotic manipulators. Ourapproach consists of augmenting the state and action space of the system withcontinuous-valued memory states that the policy can read from and write to.Learning general-purpose policies with this type of memory representationdirectly is difficult, because the policy must automatically figure out themost salient information to memorize at each time step. We show that, bydecomposing this policy search problem into a trajectory optimization phase anda supervised learning phase through a method called guided policy search, wecan acquire policies with effective memorization and recall strategies.Intuitively, the trajectory optimization phase chooses the values of the memorystates that will make it easier for the policy to produce the right action infuture states, while the supervised learning phase encourages the policy to usememorization actions to produce those memory states. We evaluate our method ontasks involving continuous control in manipulation and navigation settings, andshow that our method can learn complex policies that successfully complete arange of tasks that require memory.
arxiv-12600-223 | A Feature-Based Comparison of Evolutionary Computing Techniques for Constrained Continuous Optimisation | http://arxiv.org/pdf/1509.06842v1.pdf | author:Shayan Poursoltan, Frank Neumann category:cs.AI cs.NE published:2015-09-23 summary:Evolutionary algorithms have been frequently applied to constrainedcontinuous optimisation problems. We carry out feature based comparisons ofdifferent types of evolutionary algorithms such as evolution strategies,differential evolution and particle swarm optimisation for constrainedcontinuous optimisation. In our study, we examine how sets of constraintsinfluence the difficulty of obtaining close to optimal solutions. Using amulti-objective approach, we evolve constrained continuous problems having aset of linear and/or quadratic constraints where the different evolutionaryapproaches show a significant difference in performance. Afterwards, we discussthe features of the constraints that exhibit a difference in performance of thedifferent evolutionary approaches under consideration.
arxiv-12600-224 | Probabilistic Group Testing under Sum Observations: A Parallelizable 2-Approximation for Entropy Loss | http://arxiv.org/pdf/1407.4446v3.pdf | author:Weidong Han, Purnima Rajan, Peter I. Frazier, Bruno M. Jedynak category:cs.IT cs.LG math.IT math.OC math.ST stat.ML stat.TH published:2014-07-16 summary:We consider the problem of group testing with sum observations and noiselessanswers, in which we aim to locate multiple objects by querying the number ofobjects in each of a sequence of chosen sets. We study a probabilistic settingwith entropy loss, in which we assume a joint Bayesian prior density on thelocations of the objects and seek to choose the sets queried to minimize theexpected entropy of the Bayesian posterior distribution after a fixed number ofquestions. We present a new non-adaptive policy, called the dyadic policy, showit is optimal among non-adaptive policies, and is within a factor of two ofoptimal among adaptive policies. This policy is quick to compute, itsnonadaptive nature makes it easy to parallelize, and our bounds show itperforms well even when compared with adaptive policies. We also study anadaptive greedy policy, which maximizes the one-step expected reduction inentropy, and show that it performs at least as well as the dyadic policy,offering greater query efficiency but reduced parallelism. Numericalexperiments demonstrate that both procedures outperform a divide-and-conquerbenchmark policy from the literature, called sequential bifurcation, and showhow these procedures may be applied in a stylized computer vision problem.
arxiv-12600-225 | Density Estimation via Discrepancy | http://arxiv.org/pdf/1509.06831v1.pdf | author:Kun Yang, Hao Su, Wing Hung Wang category:stat.ML published:2015-09-23 summary:Given i.i.d samples from some unknown continuous density on hyper-rectangle$[0, 1]^d$, we attempt to learn a piecewise constant function that approximatesthis underlying density non-parametrically. Our density estimate is defined ona binary split of $[0, 1]^d$ and built up sequentially according to discrepancycriteria; the key ingredient is to control the discrepancy adaptively in eachsub-rectangle to achieve overall bound. We prove that the estimate, even thoughsimple as it appears, preserves most of the estimation power. By exploiting itsstructure, it can be directly applied to some important pattern recognitiontasks such as mode seeking and density landscape exploration. We demonstrateits applicability through simulations and examples.
arxiv-12600-226 | Supersizing Self-supervision: Learning to Grasp from 50K Tries and 700 Robot Hours | http://arxiv.org/pdf/1509.06825v1.pdf | author:Lerrel Pinto, Abhinav Gupta category:cs.LG cs.CV cs.RO published:2015-09-23 summary:Current learning-based robot grasping approaches exploit human-labeleddatasets for training the models. However, there are two problems with such amethodology: (a) since each object can be grasped in multiple ways, manuallylabeling grasp locations is not a trivial task; (b) human labeling is biased bysemantics. While there have been attempts to train robots using trial-and-errorexperiments, the amount of data used in such experiments remains substantiallylow and hence makes the learner prone to over-fitting. In this paper, we takethe leap of increasing the available training data to 40 times more than priorwork, leading to a dataset size of 50K data points collected over 700 hours ofrobot grasping attempts. This allows us to train a Convolutional Neural Network(CNN) for the task of predicting grasp locations without severe overfitting. Inour formulation, we recast the regression problem to an 18-way binaryclassification over image patches. We also present a multi-stage learningapproach where a CNN trained in one stage is used to collect hard negatives insubsequent stages. Our experiments clearly show the benefit of usinglarge-scale datasets (and multi-stage training) for the task of grasping. Wealso compare to several baselines and show state-of-the-art performance ongeneralization to unseen objects for grasping.
arxiv-12600-227 | Splash: User-friendly Programming Interface for Parallelizing Stochastic Algorithms | http://arxiv.org/pdf/1506.07552v2.pdf | author:Yuchen Zhang, Michael I. Jordan category:cs.LG published:2015-06-24 summary:Stochastic algorithms are efficient approaches to solving machine learningand optimization problems. In this paper, we propose a general framework calledSplash for parallelizing stochastic algorithms on multi-node distributedsystems. Splash consists of a programming interface and an execution engine.Using the programming interface, the user develops sequential stochasticalgorithms without concerning any detail about distributed computing. Thealgorithm is then automatically parallelized by a communication-efficientexecution engine. We provide theoretical justifications on the optimal rate ofconvergence for parallelizing stochastic gradient descent. Splash is built ontop of Apache Spark. The real-data experiments on logistic regression,collaborative filtering and topic modeling verify that Splash yieldsorder-of-magnitude speedup over single-thread stochastic algorithms and overstate-of-the-art implementations on Spark.
arxiv-12600-228 | Training deep neural networks with low precision multiplications | http://arxiv.org/pdf/1412.7024v5.pdf | author:Matthieu Courbariaux, Yoshua Bengio, Jean-Pierre David category:cs.LG cs.CV cs.NE published:2014-12-22 summary:Multipliers are the most space and power-hungry arithmetic operators of thedigital implementation of deep neural networks. We train a set ofstate-of-the-art neural networks (Maxout networks) on three benchmark datasets:MNIST, CIFAR-10 and SVHN. They are trained with three distinct formats:floating point, fixed point and dynamic fixed point. For each of those datasetsand for each of those formats, we assess the impact of the precision of themultiplications on the final error after training. We find that very lowprecision is sufficient not just for running trained networks but also fortraining them. For example, it is possible to train Maxout networks with 10bits multiplications.
arxiv-12600-229 | Learning Wake-Sleep Recurrent Attention Models | http://arxiv.org/pdf/1509.06812v1.pdf | author:Jimmy Ba, Roger Grosse, Ruslan Salakhutdinov, Brendan Frey category:cs.LG published:2015-09-22 summary:Despite their success, convolutional neural networks are computationallyexpensive because they must examine all image locations. Stochasticattention-based models have been shown to improve computational efficiency attest time, but they remain difficult to train because of intractable posteriorinference and high variance in the stochastic gradient estimates. Borrowingtechniques from the literature on training deep generative models, we presentthe Wake-Sleep Recurrent Attention Model, a method for training stochasticattention networks which improves posterior inference and which reduces thevariability in the stochastic gradients. We show that our method can greatlyspeed up the training time for stochastic attention networks in the domains ofimage classification and caption generation.
arxiv-12600-230 | Bandit Label Inference for Weakly Supervised Learning | http://arxiv.org/pdf/1509.06807v1.pdf | author:Ke Li, Jitendra Malik category:cs.LG stat.ML published:2015-09-22 summary:The scarcity of data annotated at the desired level of granularity is arecurring issue in many applications. Significant amounts of effort have beendevoted to developing weakly supervised methods tailored to each individualsetting, which are often carefully designed to take advantage of the particularproperties of weak supervision regimes, form of available data and priorknowledge of the task at hand. Unfortunately, it is difficult to adapt thesemethods to new tasks and/or forms of data, which often require different weaksupervision regimes or models. We present a general-purpose method that cansolve any weakly supervised learning problem irrespective of the weaksupervision regime or the model. The proposed method turns any off-the-shelfstrongly supervised classifier into a weakly supervised classifier and allowsthe user to specify any arbitrary weakly supervision regime via a lossfunction. We apply the method to several different weak supervision regimes anddemonstrate competitive results compared to methods specifically engineered forthose settings.
arxiv-12600-231 | Denoising without access to clean data using a partitioned autoencoder | http://arxiv.org/pdf/1509.05982v2.pdf | author:Dan Stowell, Richard E. Turner category:cs.NE cs.LG published:2015-09-20 summary:Training a denoising autoencoder neural network requires access to trulyclean data, a requirement which is often impractical. To remedy this, weintroduce a method to train an autoencoder using only noisy data, havingexamples with and without the signal class of interest. The autoencoder learnsa partitioned representation of signal and noise, learning to reconstruct eachseparately. We illustrate the method by denoising birdsong audio (availableabundantly in uncontrolled noisy datasets) using a convolutional autoencoder.
arxiv-12600-232 | Hardness of Online Sleeping Combinatorial Optimization Problems | http://arxiv.org/pdf/1509.03600v2.pdf | author:Satyen Kale, Chansoo Lee, Dávid Pál category:cs.LG cs.DS published:2015-09-11 summary:We show that several online combinatorial optimization problems that admitefficient no-regret algorithms become computationally hard in the sleepingsetting where a subset of actions becomes unavailable in each round.Specifically, we show that the sleeping versions of these problems, usingper-action regret as the performance measure, are at least as hard as PAClearning DNF expressions, a long standing open problem. We show hardness forthe sleeping versions of Online Shortest Paths, Online Minimum Spanning Tree,Online $k$-Subsets, Online $k$-Truncated Permutations, Online Minimum Cut, andOnline Bipartite Matching. The hardness result for the sleeping version of theOnline Shortest Paths problem resolves an open problem presented at COLT 2015(Koolen et al., 2015). We also give an efficient reduction of the task ofminimizing per-action regret to the task of minimizing ranking regret, adifferent performance measure. Thus, existing efficient algorithms forminimizing ranking regret under various restrictions of the adversary can beused to efficiently minimize per-action regret as well.
arxiv-12600-233 | Detecting Table Region in PDF Documents Using Distant Supervision | http://arxiv.org/pdf/1506.08891v6.pdf | author:Miao Fan, Doo Soon Kim category:cs.CV cs.IR published:2015-06-29 summary:Superior to state-of-the-art approaches which compete in table recognitionwith 67 annotated government reports in PDF format released by {\it ICDAR 2013Table Competition}, this paper contributes a novel paradigm leveraginglarge-scale unlabeled PDF documents to open-domain table detection. Weintegrate the paradigm into our latest developed system ({\it PdfExtra}) todetect the region of tables by means of 9,466 academic articles from the entirerepository of {\it ACL Anthology}, where almost all papers are archived by PDFformat without annotation for tables. The paradigm first designs heuristics toautomatically construct weakly labeled data. It then feeds diverse evidences,such as layouts of documents and linguistic features, which are extracted by{\it Apache PDFBox} and processed by {\it Stanford NLP} toolkit, into differentcanonical classifiers. We finally use these classifiers, i.e. {\it NaiveBayes}, {\it Logistic Regression} and {\it Support Vector Machine}, tocollaboratively vote on the region of tables. Experimental results show that{\it PdfExtra} achieves a great leap forward, compared with thestate-of-the-art approach. Moreover, we discuss the factors of differentfeatures, learning models and even domains of documents that may impact theperformance. Extensive evaluations demonstrate that our paradigm is compatibleenough to leverage various features and learning models for open-domain tableregion detection within PDF files.
arxiv-12600-234 | Invariants of objects and their images under surjective maps | http://arxiv.org/pdf/1509.06690v1.pdf | author:Irina A. Kogan, Peter J. Olver category:math.DG cs.CV I.2.10 published:2015-09-22 summary:We examine the relationships between the differential invariants of objectsand of their images under a surjective map. We analyze both the case when theunderlying transformation group is projectable and hence induces an action onthe image, and the case when only a proper subgroup of the entire group actsprojectably. In the former case, we establish a constructible isomorphismbetween the algebra of differential invariants of the images and the algebra offiber-wise constant (gauge) differential invariants of the objects. In thelatter case, we describe residual effects of the full transformation group onthe image invariants. Our motivation comes from the problem of reconstructionof an object from multiple-view images, with central and parallel projectionsof curves from three-dimensional space to the two-dimensional plane serving asour main examples.
arxiv-12600-235 | Classification error in multiclass discrimination from Markov data | http://arxiv.org/pdf/1509.06673v1.pdf | author:Sören Christensen, Albrecht Irle, Lars Willert category:stat.ML math.ST stat.TH published:2015-09-22 summary:As a model for an on-line classification setting we consider a stochasticprocess $(X_{-n},Y_{-n})_{n}$, the present time-point being denoted by 0, withobservables $ \ldots,X_{-n},X_{-n+1},\ldots, X_{-1}, X_0$ from which thepattern $Y_0$ is to be inferred. So in this classification setting, in additionto the present observation $X_0$ a number $l$ of preceding observations may beused for classification, thus taking a possible dependence structure intoaccount as it occurs e.g. in an ongoing classification of handwrittencharacters. We treat the question how the performance of classifiers isimproved by using such additional information. For our analysis, a hiddenMarkov model is used. Letting $R_l$ denote the minimal risk ofmisclassification using $l$ preceding observations we show that the difference$\sup_k R_l - R_{l+k}$ decreases exponentially fast as $l$ increases. Thissuggests that a small $l$ might already lead to a noticeable improvement. Tofollow this point we look at the use of past observations for kernelclassification rules. Our practical findings in simulated hidden Markov modelsand in the classification of handwritten characters indicate that using $l=1$,i.e. just the last preceding observation in addition to $X_0$, can lead to asubstantial reduction of the risk of misclassification. So, in the presence ofstochastic dependencies, we advocate to use $ X_{-1},X_0$ for finding thepattern $Y_0$ instead of only $X_0$ as one would in the independent situation.
arxiv-12600-236 | Learning quantitative sequence-function relationships from massively parallel experiments | http://arxiv.org/pdf/1506.00054v2.pdf | author:Gurinder S. Atwal, Justin B. Kinney category:q-bio.QM math.ST physics.bio-ph stat.ML stat.TH published:2015-05-30 summary:A fundamental aspect of biological information processing is the ubiquity ofsequence-function relationships -- functions that map the sequence of DNA, RNA,or protein to a biochemically relevant activity. Most sequence-functionrelationships in biology are quantitative, but only recently have experimentaltechniques for effectively measuring these relationships been developed. Theadvent of such "massively parallel" experiments presents an excitingopportunity for the concepts and methods of statistical physics to inform thestudy of biological systems. After reviewing these recent experimentaladvances, we focus on the problem of how to infer parametric models ofsequence-function relationships from the data produced by these experiments.Specifically, we retrace and extend recent theoretical work showing thatinference based on mutual information, not the standard likelihood-basedapproach, is often necessary for accurately learning the parameters of thesemodels. Closely connected with this result is the emergence of "diffeomorphicmodes" -- directions in parameter space that are far less constrained by datathan likelihood-based inference would suggest. Analogous to Goldstone modes inphysics, diffeomorphic modes arise from an arbitrarily broken symmetry of theinference problem. An analytically tractable model of a massively parallelexperiment is then described, providing an explicit demonstration of thesefundamental aspects of statistical inference. This paper concludes with anoutlook on the theoretical and computational challenges currently facingstudies of quantitative sequence-function relationships.
arxiv-12600-237 | Robust Optimization for Deep Regression | http://arxiv.org/pdf/1505.06606v2.pdf | author:Vasileios Belagiannis, Christian Rupprecht, Gustavo Carneiro, Nassir Navab category:cs.CV published:2015-05-25 summary:Convolutional Neural Networks (ConvNets) have successfully contributed toimprove the accuracy of regression-based methods for computer vision tasks suchas human pose estimation, landmark localization, and object detection. Thenetwork optimization has been usually performed with L2 loss and withoutconsidering the impact of outliers on the training process, where an outlier inthis context is defined by a sample estimation that lies at an abnormaldistance from the other training sample estimations in the objective space. Inthis work, we propose a regression model with ConvNets that achieves robustnessto such outliers by minimizing Tukey's biweight function, an M-estimator robustto outliers, as the loss function for the ConvNet. In addition to the robustloss, we introduce a coarse-to-fine model, which processes input images ofprogressively higher resolutions for improving the accuracy of the regressedvalues. In our experiments, we demonstrate faster convergence and bettergeneralization of our robust loss function for the tasks of human poseestimation and age estimation from face images. We also show that thecombination of the robust loss function with the coarse-to-fine model producescomparable or better results than current state-of-the-art approaches in fourpublicly available human pose estimation datasets.
arxiv-12600-238 | A Compositional Explanation of the Pet Fish Phenomenon | http://arxiv.org/pdf/1509.06594v1.pdf | author:Bob Coecke, Martha Lewis category:cs.AI cs.CL math.CT published:2015-09-22 summary:The `pet fish' phenomenon is often cited as a paradigm example of the`non-compositionality' of human concept use. We show here how this phenomenonis naturally accommodated within a compositional distributional model ofmeaning. This model describes the meaning of a composite concept by accountingfor interaction between its constituents via their grammatical roles. We givetwo illustrative examples to show how the qualitative phenomena are exhibited.We go on to apply the model to experimental data, and finally discussextensions of the formalism.
arxiv-12600-239 | Graph Kernels exploiting Weisfeiler-Lehman Graph Isomorphism Test Extensions | http://arxiv.org/pdf/1509.06589v1.pdf | author:Giovanni Da San Martino, Nicolò Navarin, Alessandro Sperduti category:cs.LG cs.AI published:2015-09-22 summary:In this paper we present a novel graph kernel framework inspired the by theWeisfeiler-Lehman (WL) isomorphism tests. Any WL test comprises a relabellingphase of the nodes based on test-specific information extracted from the graph,for example the set of neighbours of a node. We defined a novel relabelling andderived two kernels of the framework from it. The novel kernels are very fastto compute and achieve state-of-the-art results on five real-world datasets.
arxiv-12600-240 | A Review of Features for the Discrimination of Twitter Users: Application to the Prediction of Offline Influence | http://arxiv.org/pdf/1509.06585v1.pdf | author:Jean-Valère Cossu, Vincent Labatut, Nicolas Dugué category:cs.CL cs.SI published:2015-09-22 summary:Many works related to Twitter aim at characterizing its users in some way:role on the service (spammers, bots, organizations, etc.), nature of the user(socio-professional category, age, etc.), topics of interest, and others.However, for a given user classification problem, it is very difficult toselect a set of appropriate features, because the many features described inthe literature are very heterogeneous, with name overlaps and collisions, andnumerous very close variants. In this article, we review a wide range of suchfeatures. In order to present a clear state-of-the-art description, we unifytheir names, definitions and relationships, and we propose a new, neutral,typology. We then illustrate the interest of our review by applying a selectionof these features to the offline influence detection problem. This taskconsists in identifying users which are influential in real-life, based ontheir Twitter account and related data. We show that most features deemedefficient to predict online influence, such as the numbers of retweets andfollowers, are not relevant to this problem. However, We propose severalcontent-based approaches to label Twitter users as Influencers or not. We alsorank them according to a predicted influence level. Our proposals are evaluatedover the CLEF RepLab 2014 dataset, and outmatch state-of-the-art methods.
arxiv-12600-241 | Homotopy relations for digital images | http://arxiv.org/pdf/1509.06576v1.pdf | author:Laurence Boxer, P. Christopher Staecker category:math.GN cs.CV 55P10, 55Q05 I.4.m published:2015-09-22 summary:We introduce three generalizations of homotopy equivalence in digital images,to allow us to express whether a finite and an infinite digital image aresimilar with respect to homotopy. We show that these three generalizations are not equivalent to ordinaryhomotopy equivalence, and give several examples. We show that, like homotopyequivalence, our three generalizations imply isomorphism of fundamental groups,and are
arxiv-12600-242 | Local Multi-Grouped Binary Descriptor with Ring-based Pooling Configuration and Optimization | http://arxiv.org/pdf/1509.06557v1.pdf | author:Yongqiang Gao, Weilin Huang, Yu Qiao category:cs.CV published:2015-09-22 summary:Local binary descriptors are attracting increasingly attention due to theirgreat advantages in computational speed, which are able to achieve real-timeperformance in numerous image/vision applications. Various methods have beenproposed to learn data-dependent binary descriptors. However, most existingbinary descriptors aim overly at computational simplicity at the expense ofsignificant information loss which causes ambiguity in similarity measure usingHamming distance. In this paper, by considering multiple features might sharecomplementary information, we present a novel local binary descriptor, referredas Ring-based Multi-Grouped Descriptor (RMGD), to successfully bridge theperformance gap between current binary and floated-point descriptors. Ourcontributions are two-fold. Firstly, we introduce a new pooling configurationbased on spatial ring-region sampling, allowing for involving binary tests onthe full set of pairwise regions with different shapes, scales and distances.This leads to a more meaningful description than existing methods whichnormally apply a limited set of pooling configurations. Then, an extendedAdaboost is proposed for efficient bit selection by emphasizing high varianceand low correlation, achieving a highly compact representation. Secondly, theRMGD is computed from multiple image properties where binary strings areextracted. We cast multi-grouped features integration as rankSVM or sparse SVMlearning problem, so that different features can compensate strongly for eachother, which is the key to discriminativeness and robustness. The performanceof RMGD was evaluated on a number of publicly available benchmarks, where theRMGD outperforms the state-of-the-art binary descriptors significantly.
arxiv-12600-243 | Deep Boltzmann Machines in Estimation of Distribution Algorithms for Combinatorial Optimization | http://arxiv.org/pdf/1509.06535v1.pdf | author:Malte Probst, Franz Rothlauf category:cs.NE published:2015-09-22 summary:Estimation of Distribution Algorithms (EDAs) require flexible probabilitymodels that can be efficiently learned and sampled. Deep Boltzmann Machines(DBMs) are generative neural networks with these desired properties. Weintegrate a DBM into an EDA and evaluate the performance of this system insolving combinatorial optimization problems with a single objective. We comparethe results to the Bayesian Optimization Algorithm. The performance of DBM-EDAwas superior to BOA for difficult additively decomposable functions, i.e.,concatenated deceptive traps of higher order. For most other benchmarkproblems, DBM-EDA cannot clearly outperform BOA, or other neural network-basedEDAs. In particular, it often yields optimal solutions for a subset of the runs(with fewer evaluations than BOA), but is unable to provide reliableconvergence to the global optimum competitively. At the same time, the modelbuilding process is computationally more expensive than that of other EDAsusing probabilistic models from the neural network family, such as DAE-EDA.
arxiv-12600-244 | A survey on feature weighting based K-Means algorithms | http://arxiv.org/pdf/1601.03483v1.pdf | author:Renato Cordeiro de Amorim category:cs.LG published:2015-09-22 summary:In a real-world data set there is always the possibility, rather high in ouropinion, that different features may have different degrees of relevance. Mostmachine learning algorithms deal with this fact by either selecting ordeselecting features in the data preprocessing phase. However, we maintain thateven among relevant features there may be different degrees of relevance, andthis should be taken into account during the clustering process. With over 50years of history, K-Means is arguably the most popular partitional clusteringalgorithm there is. The first K-Means based clustering algorithm to computefeature weights was designed just over 30 years ago. Various such algorithmshave been designed since but there has not been, to our knowledge, a surveyintegrating empirical evidence of cluster recovery ability, common flaws, andpossible directions for future research. This paper elaborates on the conceptof feature weighting and addresses these issues by critically analysing some ofthe most popular, or innovative, feature weighting mechanisms based in K-Means.
arxiv-12600-245 | Modifying iterated Laplace approximations | http://arxiv.org/pdf/1509.06492v1.pdf | author:Tiep Mai, Simon Wilson category:stat.ME stat.ML published:2015-09-22 summary:In this paper, several modifications are introduced to the functionalapproximation method iterLap to reduce the approximation error, includingstopping rule adjustment, proposal of new residual function, starting pointselection for numerical optimisation, scaling of Hessian matrix. Illustrativeexamples are also provided to show the trade-off between running time andaccuracy of the original and modified methods.
arxiv-12600-246 | Bayesian Conditional Density Filtering | http://arxiv.org/pdf/1401.3632v3.pdf | author:Shaan Qamar, Rajarshi Guhaniyogi, David B. Dunson category:stat.ML cs.LG stat.CO published:2014-01-15 summary:We propose a Conditional Density Filtering (C-DF) algorithm for efficientonline Bayesian inference. C-DF adapts MCMC sampling to the online setting,sampling from approximations to conditional posterior distributions obtained bypropagating surrogate conditional sufficient statistics (a function of data andparameter estimates) as new data arrive. These quantities eliminate the need tostore or process the entire dataset simultaneously and offer a number ofdesirable features. Often, these include a reduction in memory requirements andruntime and improved mixing, along with state-of-the-art parameter inferenceand prediction. These improvements are demonstrated through severalillustrative examples including an application to high dimensional compressedregression. Finally, we show that C-DF samples converge to the target posteriordistribution asymptotically as sampling proceeds and more data arrives.
arxiv-12600-247 | Understand Scene Categories by Objects: A Semantic Regularized Scene Classifier Using Convolutional Neural Networks | http://arxiv.org/pdf/1509.06470v1.pdf | author:Yiyi Liao, Sarath Kodagoda, Yue Wang, Lei Shi, Yong Liu category:cs.CV published:2015-09-22 summary:Scene classification is a fundamental perception task for environmentalunderstanding in today's robotics. In this paper, we have attempted to exploitthe use of popular machine learning technique of deep learning to enhance sceneunderstanding, particularly in robotics applications. As scene images havelarger diversity than the iconic object images, it is more challenging for deeplearning methods to automatically learn features from scene images with lesssamples. Inspired by human scene understanding based on object knowledge, weaddress the problem of scene classification by encouraging deep neural networksto incorporate object-level information. This is implemented with aregularization of semantic segmentation. With only 5 thousand training images,as opposed to 2.5 million images, we show the proposed deep architectureachieves superior scene classification results to the state-of-the-art on apublicly available SUN RGB-D dataset. In addition, performance of semanticsegmentation, the regularizer, also reaches a new record with refinementderived from predicted scene labels. Finally, we apply our SUN RGB-D datasettrained model to a mobile robot captured images to classify scenes in ouruniversity demonstrating the generalization ability of the proposed algorithm.
arxiv-12600-248 | Stochastic gradient descent methods for estimation with large data sets | http://arxiv.org/pdf/1509.06459v1.pdf | author:Dustin Tran, Panos Toulis, Edoardo M. Airoldi category:stat.CO stat.ME stat.ML published:2015-09-22 summary:We develop methods for parameter estimation in settings with large-scale datasets, where traditional methods are no longer tenable. Our methods rely onstochastic approximations, which are computationally efficient as they maintainone iterate as a parameter estimate, and successively update that iterate basedon a single data point. When the update is based on a noisy gradient, thestochastic approximation is known as standard stochastic gradient descent,which has been fundamental in modern applications with large data sets.Additionally, our methods are numerically stable because they employ implicitupdates of the iterates. Intuitively, an implicit update is a shrinked versionof a standard one, where the shrinkage factor depends on the observed Fisherinformation at the corresponding data point. This shrinkage prevents numericaldivergence of the iterates, which can be caused either by excess noise oroutliers. Our sgd package in R offers the most extensive and robustimplementation of stochastic gradient descent methods. We demonstrate that sgddominates alternative software in runtime for several estimation problems withmassive data sets. Our applications include the wide class of generalizedlinear models as well as M-estimation for robust regression.
arxiv-12600-249 | Harmonic Extension | http://arxiv.org/pdf/1509.06458v1.pdf | author:Zuoqiang Shi, Jian Sun, Minghao Tian category:cs.LG math.NA published:2015-09-22 summary:In this paper, we consider the harmonic extension problem, which is widelyused in many applications of machine learning. We find that the transitionalmethod of graph Laplacian fails to produce a good approximation of theclassical harmonic function. To tackle this problem, we propose a new methodcalled the point integral method (PIM). We consider the harmonic extensionproblem from the point of view of solving PDEs on manifolds. The basic idea ofthe PIM method is to approximate the harmonicity using an integral equation,which is easy to be discretized from points. Based on the integral equation, weexplain the reason why the transitional graph Laplacian may fail to approximatethe harmonicity in the classical sense and propose a different approach whichwe call the volume constraint method (VCM). Theoretically, both the PIM and theVCM computes a harmonic function with convergence guarantees, and practically,they are both simple, which amount to solve a linear system. One importantapplication of the harmonic extension in machine learning is semi-supervisedlearning. We run a popular semi-supervised learning algorithm by Zhu et al.over a couple of well-known datasets and compare the performance of theaforementioned approaches. Our experiments show the PIM performs the best.
arxiv-12600-250 | Identifying collusion groups using spectral clustering | http://arxiv.org/pdf/1509.06457v1.pdf | author:Suneel Sarswat, Kandathil Mathew Abraham, Subir Kumar Ghosh category:q-fin.TR cs.CE stat.ML published:2015-09-22 summary:In an illiquid stock, traders can collude and place orders on a predeterminedprice and quantity at a fixed schedule. This is usually done to manipulate theprice of the stock or to create artificial liquidity in the stock, which maymislead genuine investors. Here, the problem is to identify such group ofcolluding traders. We modeled the problem instance as a graph, where eachtrader corresponds to a vertex of the graph and trade corresponds to edges ofthe graph. Further, we assign weights on edges depending on total volume, totalnumber of trades, maximum change in the price and commonality between twovertices. Spectral clustering algorithms are used on the constructed graph toidentify colluding group(s). We have compared our results with simulated datato show the effectiveness of spectral clustering to detecting colluding groups.Moreover, we also have used parameters of real data to test the effectivenessof our algorithm.
arxiv-12600-251 | From Facial Parts Responses to Face Detection: A Deep Learning Approach | http://arxiv.org/pdf/1509.06451v1.pdf | author:Shuo Yang, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV published:2015-09-22 summary:In this paper, we propose a novel deep convolutional network (DCN) thatachieves outstanding performance on FDDB, PASCAL Face, and AFW. Specifically,our method achieves a high recall rate of 90.99% on the challenging FDDBbenchmark, outperforming the state-of-the-art method by a large margin of2.91%. Importantly, we consider finding faces from a new perspective throughscoring facial parts responses by their spatial structure and arrangement. Thescoring mechanism is carefully formulated considering challenging cases wherefaces are only partially visible. This consideration allows our network todetect faces under severe occlusion and unconstrained pose variation, which arethe main difficulty and bottleneck of most existing face detection approaches.We show that despite the use of DCN, our network can achieve practical runtimespeed.
arxiv-12600-252 | Efficient Neighborhood Selection for Gaussian Graphical Models | http://arxiv.org/pdf/1509.06449v1.pdf | author:Yingxiang Yang, Jalal Etesami, Negar Kiyavash category:stat.ML cs.IT cs.LG math.IT published:2015-09-22 summary:This paper addresses the problem of neighborhood selection for Gaussiangraphical models. We present two heuristic algorithms: a forward-backwardgreedy algorithm for general Gaussian graphical models based on mutualinformation test, and a threshold-based algorithm for walk summable Gaussiangraphical models. Both algorithms are shown to be structurally consistent, andefficient. Numerical results show that both algorithms work very well.
arxiv-12600-253 | Twitter User Geolocation Using a Unified Text and Network Prediction Model | http://arxiv.org/pdf/1506.08259v3.pdf | author:Afshin Rahimi, Trevor Cohn, Timothy Baldwin category:cs.CL cs.SI published:2015-06-27 summary:We propose a label propagation approach to geolocation prediction based onModified Adsorption, with two enhancements:(1) the removal of "celebrity" nodesto increase location homophily and boost tractability, and (2) he incorporationof text-based geolocation priors for test users. Experiments over three Twitterbenchmark datasets achieve state-of-the-art results, and demonstrate theeffectiveness of the enhancements.
arxiv-12600-254 | Love Thy Neighbors: Image Annotation by Exploiting Image Metadata | http://arxiv.org/pdf/1508.07647v2.pdf | author:Justin Johnson, Lamberto Ballan, Fei-Fei Li category:cs.CV published:2015-08-30 summary:Some images that are difficult to recognize on their own may become moreclear in the context of a neighborhood of related images with similarsocial-network metadata. We build on this intuition to improve multilabel imageannotation. Our model uses image metadata nonparametrically to generateneighborhoods of related images using Jaccard similarities, then uses a deepneural network to blend visual information from the image and its neighbors.Prior work typically models image metadata parametrically, in contrast, ournonparametric treatment allows our model to perform well even when thevocabulary of metadata changes between training and testing. We performcomprehensive experiments on the NUS-WIDE dataset, where we show that our modeloutperforms state-of-the-art methods for multilabel image annotation even whenour model is forced to generalize to new types of metadata.
arxiv-12600-255 | Detecting falls with X-Factor HMMs when the training data for falls is not available | http://arxiv.org/pdf/1504.02141v3.pdf | author:Shehroz S. Khan, Michelle E. Karg, Dana Kulic, Jesse Hoey category:cs.LG cs.AI published:2015-04-08 summary:Identification of falls while performing normal activities of daily living(ADL) is important to ensure personal safety and well-being. However, fallingis a short term activity that occurs infrequently. This poses a challenge totraditional classification algorithms, because there may be very littletraining data for falls (or none at all). This paper proposes an approach forthe identification of falls using a wearable device in the absence of trainingdata for falls but with plentiful data for normal ADL. We propose three`X-Factor' Hidden Markov Model (XHMMs) approaches. The XHMMs model unseen fallsusing "inflated" output covariances (observation models). To estimate theinflated covariances, we propose a novel cross validation method to remove"outliers" from the normal ADL that serve as proxies for the unseen falls andallow learning the XHMMs using only normal activities. We tested the proposedXHMM approaches on two activity recognition datasets and show high detectionrates for falls in the absence of fall-specific training data. We show that thetraditional method of choosing a threshold based on maximum of negative oflog-likelihood to identify unseen falls is ill-posed for this problem. We alsoshow that supervised classification methods perform poorly when very limitedfall data are available during the training phase.
arxiv-12600-256 | The Online Coupon-Collector Problem and Its Application to Lifelong Reinforcement Learning | http://arxiv.org/pdf/1506.03379v2.pdf | author:Emma Brunskill, Lihong Li category:cs.LG cs.AI published:2015-06-10 summary:Transferring knowledge across a sequence of related tasks is an importantchallenge in reinforcement learning (RL). Despite much encouraging empiricalevidence, there has been little theoretical analysis. In this paper, we study aclass of lifelong RL problems: the agent solves a sequence of tasks modeled asfinite Markov decision processes (MDPs), each of which is from a finite set ofMDPs with the same state/action sets and different transition/reward functions.Motivated by the need for cross-task exploration in lifelong learning, weformulate a novel online coupon-collector problem and give an optimalalgorithm. This allows us to develop a new lifelong RL algorithm, whose overallsample complexity in a sequence of tasks is much smaller than single-tasklearning, even if the sequence of tasks is generated by an adversary. Benefitsof the algorithm are demonstrated in simulated problems, including a recentlyintroduced human-robot interaction problem.
arxiv-12600-257 | A Multi-Agent System Approach to Load-Balancing and Resource Allocation for Distributed Computing | http://arxiv.org/pdf/1509.06420v1.pdf | author:Soumya Banerjee, Joshua Hecker category:cs.NE cs.DC published:2015-09-21 summary:In this research we use a decentralized computing approach to allocate andschedule tasks on a massively distributed grid. Using emergent properties ofmulti-agent systems, the algorithm dynamically creates and dissociates clustersto serve the changing resource demands of a global task queue. The algorithm iscompared to a standard First-in First-out (FIFO) scheduling algorithm.Experiments done on a simulator show that the distributed resource allocationprotocol (dRAP) algorithm outperforms the FIFO scheduling algorithm on time toempty queue, average waiting time and CPU utilization. Such a decentralizedcomputing approach holds promise for massively distributed processing scenarioslike SETI@home and Google MapReduce.
arxiv-12600-258 | Conservativeness of untied auto-encoders | http://arxiv.org/pdf/1506.07643v3.pdf | author:Daniel Jiwoong Im, Mohamed Ishmael Diwan Belghazi, Roland Memisevic category:cs.LG published:2015-06-25 summary:We discuss necessary and sufficient conditions for an auto-encoder to definea conservative vector field, in which case it is associated with an energyfunction akin to the unnormalized log-probability of the data. We show that theconditions for conservativeness are more general than for encoder and decoderweights to be the same ("tied weights"), and that they also depend on the formof the hidden unit activation function, but that contractive training criteria,such as denoising, will enforce these conditions locally. Based on theseobservations, we show how we can use auto-encoders to extract the conservativecomponent of a vector field.
arxiv-12600-259 | Estimating Random Delays in Modbus Network Using Experiments and General Linear Regression Neural Networks with Genetic Algorithm Smoothing | http://arxiv.org/pdf/1509.06839v1.pdf | author:B. Sreram, F. Bounapane, B. Subathra, Seshadhri Srinivasan category:cs.SY cs.NE published:2015-09-21 summary:Time-varying delays adversely affect the performance of networked controlsys-tems (NCS) and in the worst-case can destabilize the entire system.Therefore, modelling network delays is important for designing NCS. However,modelling time-varying delays is challenging because of their dependence onmultiple pa-rameters such as length, contention, connected devices, protocolemployed, and channel loading. Further, these multiple parameters areinherently random and de-lays vary in a non-linear fashion with respect totime. This makes estimating ran-dom delays challenging. This investigationpresents a methodology to model de-lays in NCS using experiments and generalregression neural network (GRNN) due to their ability to capture non-linearrelationship. To compute the optimal smoothing parameter that computes the bestestimates, genetic algorithm is used. The objective of the genetic algorithm isto compute the optimal smoothing pa-rameter that minimizes the mean absolutepercentage error (MAPE). Our results illustrate that the resulting GRNN is ableto predict the delays with less than 3% error. The proposed delay model gives aframework to design compensation schemes for NCS subjected to time-varyingdelays.
arxiv-12600-260 | Learning from Synthetic Data Using a Stacked Multichannel Autoencoder | http://arxiv.org/pdf/1509.05463v2.pdf | author:Xi Zhang, Yanwei Fu, Shanshan Jiang, Leonid Sigal, Gady Agam category:cs.CV cs.AI published:2015-09-17 summary:Learning from synthetic data has many important and practical applications.An example of application is photo-sketch recognition. Using synthetic data ischallenging due to the differences in feature distributions between syntheticand real data, a phenomenon we term synthetic gap. In this paper, weinvestigate and formalize a general framework-Stacked Multichannel Autoencoder(SMCAE) that enables bridging the synthetic gap and learning from syntheticdata more efficiently. In particular, we show that our SMCAE can not onlytransform and use synthetic data on the challenging face-sketch recognitiontask, but that it can also help simulate real images, which can be used fortraining classifiers for recognition. Preliminary experiments validate theeffectiveness of the framework.
arxiv-12600-261 | High-for-Low and Low-for-High: Efficient Boundary Detection from Deep Object Features and its Applications to High-Level Vision | http://arxiv.org/pdf/1504.06201v3.pdf | author:Gedas Bertasius, Jianbo Shi, Lorenzo Torresani category:cs.CV published:2015-04-23 summary:Most of the current boundary detection systems rely exclusively on low-levelfeatures, such as color and texture. However, perception studies suggest thathumans employ object-level reasoning when judging if a particular pixel is aboundary. Inspired by this observation, in this work we show how to predictboundaries by exploiting object-level features from a pretrainedobject-classification network. Our method can be viewed as a "High-for-Low"approach where high-level object features inform the low-level boundarydetection process. Our model achieves state-of-the-art performance on anestablished boundary detection benchmark and it is efficient to run. Additionally, we show that due to the semantic nature of our boundaries wecan use them to aid a number of high-level vision tasks. We demonstrate thatusing our boundaries we improve the performance of state-of-the-art methods onthe problems of semantic boundary labeling, semantic segmentation and objectproposal generation. We can view this process as a "Low-for-High" scheme, wherelow-level boundaries aid high-level vision tasks. Thus, our contributions include a boundary detection system that is accurate,efficient, generalizes well to multiple datasets, and is also shown to improveexisting state-of-the-art high-level vision methods on three distinct tasks.
arxiv-12600-262 | Evaluating the visualization of what a Deep Neural Network has learned | http://arxiv.org/pdf/1509.06321v1.pdf | author:Wojciech Samek, Alexander Binder, Grégoire Montavon, Sebastian Bach, Klaus-Robert Müller category:cs.CV published:2015-09-21 summary:Deep Neural Networks (DNNs) have demonstrated impressive performance incomplex machine learning tasks such as image classification or speechrecognition. However, due to their multi-layer nonlinear structure, they arenot transparent, i.e., it is hard to grasp what makes them arrive at aparticular classification or recognition decision given a new unseen datasample. Recently, several approaches have been proposed enabling one tounderstand and interpret the reasoning embodied in a DNN for a single testimage. These methods quantify the ''importance'' of individual pixels wrt theclassification decision and allow a visualization in terms of a heatmap inpixel/input space. While the usefulness of heatmaps can be judged subjectivelyby a human, an objective quality measure is missing. In this paper we present ageneral methodology based on region perturbation for evaluating orderedcollections of pixels such as heatmaps. We compare heatmaps computed by threedifferent methods on the SUN397, ILSVRC2012 and MIT Places data sets. Our mainresult is that the recently proposed Layer-wise Relevance Propagation (LRP)algorithm qualitatively and quantitatively provides a better explanation ofwhat made a DNN arrive at a particular classification decision than thesensitivity-based approach or the deconvolution method. We provide theoreticalarguments to explain this result and discuss its practical implications.Finally, we investigate the use of heatmaps for unsupervised assessment ofneural network performance.
arxiv-12600-263 | A Bayesian Compressed Sensing Kalman Filter for Direction of Arrival Estimation | http://arxiv.org/pdf/1509.06290v1.pdf | author:Matthew Hawes, Lyudmila Mihaylova, Francois Septier, Simon Godsill category:stat.ML cs.IT math.IT published:2015-09-21 summary:In this paper, we look to address the problem of estimating the dynamicdirection of arrival (DOA) of a narrowband signal impinging on a sensor arrayfrom the far field. The initial estimate is made using a Bayesian compressivesensing (BCS) framework and then tracked using a Bayesian compressed sensingKalman filter (BCSKF). The BCS framework splits the angular region into Npotential DOAs and enforces a belief that only a few of the DOAs will have anon-zero valued signal present. A BCSKF can then be used to track the change inthe DOA using the same framework. There can be an issue when the DOA approachesthe endfire of the array. In this angular region current methods can struggleto accurately estimate and track changes in the DOAs. To tackle this problem,we propose changing the traditional sparse belief associated with BCS to abelief that the estimated signals will match the predicted signals given aknown DOA change. This is done by modelling the difference between the expectedsparse received signals and the estimated sparse received signals as a Gaussiandistribution. Example test scenarios are provided and comparisons made with thetraditional BCS based estimation method. They show that an improvement inestimation accuracy is possible without a significant increase in computationalcomplexity.
arxiv-12600-264 | Multiple Object Tracking: A Literature Review | http://arxiv.org/pdf/1409.7618v3.pdf | author:Wenhan Luo, Junliang Xing, Xiaoqin Zhang, Xiaowei Zhao, Tae-Kyun Kim category:cs.CV I.4.8 published:2014-09-26 summary:Multiple Object Tracking is an important computer vision task which hasgained increasing attention due to its academic and commercial potential.Although different approaches have been proposed to tackle it, there stillexist many issues unsolved. In order to help readers understand this topic, wecontribute a systematic and comprehensive review. In the review, we inspectrecent advances in various aspects and propose some interesting directions forfuture research. To our best knowledge, there has not been any review about this topic in thecommunity. We endeavor to provide a thorough review on the development of thisproblem in the last decades. The main contributions are fourfold: 1) Keyaspects in a multiple object tracking system, including how to formulate MOTgenerally, how to categorize MOT algorithms, what needs to be considered whendeveloping a MOT system and how to evaluate a MOT system, are discussed fromthe perspective of understanding a topic. We believe this could not onlyprovide researchers, especially new comers to the topic of MOT, a generalunderstanding of the state of the arts, but also help them to comprehend theessential components of a MOT system and the inter-component connection. 2)Instead of enumerating individual works, we discuss existing work according tothe various aspects involved in a MOT system. In each aspect, methods aredivided into different groups and each group is discussed in details for theprinciples, advances and drawbacks. 3) We examine experiments of existingpublications and give tables which list results on the popular data sets toprovide convenient comparison. We also provide some interesting discoveries byanalyzing these tables. 4) We offer some potential directions and respectivediscussions about MOT, which are still open issues and need more researchefforts. This would be helpful to identify interesting problems.
arxiv-12600-265 | Artificial Neural Networks Applied to Taxi Destination Prediction | http://arxiv.org/pdf/1508.00021v2.pdf | author:Alexandre de Brébisson, Étienne Simon, Alex Auvolat, Pascal Vincent, Yoshua Bengio category:cs.LG cs.NE published:2015-07-31 summary:We describe our first-place solution to the ECML/PKDD discovery challenge ontaxi destination prediction. The task consisted in predicting the destinationof a taxi based on the beginning of its trajectory, represented as avariable-length sequence of GPS points, and diverse associatedmeta-information, such as the departure time, the driver id and clientinformation. Contrary to most published competitor approaches, we used analmost fully automated approach based on neural networks and we ranked firstout of 381 teams. The architectures we tried use multi-layer perceptrons,bidirectional recurrent neural networks and models inspired from recentlyintroduced memory networks. Our approach could easily be adapted to otherapplications in which the goal is to predict a fixed-length output from avariable-length sequence.
arxiv-12600-266 | LEWIS: Latent Embeddings for Word Images and their Semantics | http://arxiv.org/pdf/1509.06243v1.pdf | author:Albert Gordo, Jon Almazan, Naila Murray, Florent Perronnin category:cs.CV published:2015-09-21 summary:The goal of this work is to bring semantics into the tasks of textrecognition and retrieval in natural images. Although text recognition andretrieval have received a lot of attention in recent years, previous works havefocused on recognizing or retrieving exactly the same word used as a query,without taking the semantics into consideration. In this paper, we ask the following question: \emph{can we predict semanticconcepts directly from a word image, without explicitly trying to transcribethe word image or its characters at any point?} For this goal we propose aconvolutional neural network (CNN) with a weighted ranking loss objective thatensures that the concepts relevant to the query image are ranked ahead of thosethat are not relevant. This can also be interpreted as learning a Euclideanspace where word images and concepts are jointly embedded. This model islearned in an end-to-end manner, from image pixels to semantic concepts, usinga dataset of synthetically generated word images and concepts mined from alexical database (WordNet). Our results show that, despite the complexity ofthe task, word images and concepts can indeed be associated with a high degreeof accuracy
arxiv-12600-267 | Denoising Autoencoders for fast Combinatorial Black Box Optimization | http://arxiv.org/pdf/1503.01954v2.pdf | author:Malte Probst category:cs.NE I.2.6; I.2.8 published:2015-03-06 summary:Estimation of Distribution Algorithms (EDAs) require flexible probabilitymodels that can be efficiently learned and sampled. Autoencoders (AE) aregenerative stochastic networks with these desired properties. We integrate aspecial type of AE, the Denoising Autoencoder (DAE), into an EDA and evaluatethe performance of DAE-EDA on several combinatorial optimization problems witha single objective. We asses the number of fitness evaluations as well as therequired CPU times. We compare the results to the performance to the BayesianOptimization Algorithm (BOA) and RBM-EDA, another EDA which is based on agenerative neural network which has proven competitive with BOA. For theconsidered problem instances, DAE-EDA is considerably faster than BOA andRBM-EDA, sometimes by orders of magnitude. The number of fitness evaluations ishigher than for BOA, but competitive with RBM-EDA. These results show that DAEscan be useful tools for problems with low but non-negligible fitness evaluationcosts.
arxiv-12600-268 | (Non-) asymptotic properties of Stochastic Gradient Langevin Dynamics | http://arxiv.org/pdf/1501.00438v2.pdf | author:Sebastian J. Vollmer, Konstantinos C. Zygalakis, and Yee Whye Teh category:stat.ME math.ST stat.ML stat.TH 60J05, 65C05 published:2015-01-02 summary:Applying standard Markov chain Monte Carlo (MCMC) algorithms to large datasets is computationally infeasible. The recently proposed stochastic gradientLangevin dynamics (SGLD) method circumvents this problem in three ways: itgenerates proposed moves using only a subset of the data, it skips theMetropolis-Hastings accept-reject step, and it uses sequences of decreasingstep sizes. In \cite{TehThierryVollmerSGLD2014}, we provided the mathematicalfoundations for the decreasing step size SGLD, including consistency and acentral limit theorem. However, in practice the SGLD is run for a relativelysmall number of iterations, and its step size is not decreased to zero. Thepresent article investigates the behaviour of the SGLD with fixed step size. Inparticular we characterise the asymptotic bias explicitly, along with itsdependence on the step size and the variance of the stochastic gradient. Onthat basis a modified SGLD which removes the asymptotic bias due to thevariance of the stochastic gradients up to first order in the step size isderived. Moreover, we are able to obtain bounds on the finite-time bias,variance and mean squared error (MSE). The theory is illustrated with aGaussian toy model for which the bias and the MSE for the estimation of momentscan be obtained explicitly. For this toy model we study the gain of the SGLDover the standard Euler method in the limit of large data sets.
arxiv-12600-269 | Multi-label Classification using Labels as Hidden Nodes | http://arxiv.org/pdf/1503.09022v2.pdf | author:Jesse Read, Jaakko Hollmén category:stat.ML cs.LG published:2015-03-31 summary:Competitive methods for multi-label classification typically invest inlearning labels together. To do so in a beneficial way, analysis of labeldependence is often seen as a fundamental step, separate and prior toconstructing a classifier. Some methods invest up to hundreds of times morecomputational effort in building dependency models, than training the finalclassifier itself. We extend some recent discussion in the literature andprovide a deeper analysis, namely, developing the view that label dependence isoften introduced by an inadequate base classifier, rather than being inherentto the data or underlying concept; showing how even an exhaustive analysis oflabel dependence may not lead to an optimal classification structure. Viewinglabels as additional features (a transformation of the input), we createneural-network inspired novel methods that remove the emphasis of a priordependency structure. Our methods have an important advantage particular tomulti-label data: they leverage labels to create effective units in middlelayers, rather than learning these units from scratch in an unsupervisedfashion with gradient-based methods. Results are promising. The methods wepropose perform competitively, and also have very important qualities ofscalability.
arxiv-12600-270 | The Utility of Clustering in Prediction Tasks | http://arxiv.org/pdf/1509.06163v1.pdf | author:Shubhendu Trivedi, Zachary A. Pardos, Neil T. Heffernan category:cs.LG published:2015-09-21 summary:We explore the utility of clustering in reducing error in various predictiontasks. Previous work has hinted at the improvement in prediction accuracyattributed to clustering algorithms if used to pre-process the data. In thiswork we more deeply investigate the direct utility of using clustering toimprove prediction accuracy and provide explanations for why this may be so. Welook at a number of datasets, run k-means at different scales and for eachscale we train predictors. This produces k sets of predictions. Thesepredictions are then combined by a na\"ive ensemble. We observed that this useof a predictor in conjunction with clustering improved the prediction accuracyin most datasets. We believe this indicates the predictive utility ofexploiting structure in the data and the data compression handed over byclustering. We also found that using this method improves upon the predictionof even a Random Forests predictor which suggests this method is providing anovel, and useful source of variance in the prediction process.
arxiv-12600-271 | Cascaded Regressor based 3D Face Reconstruction from a Single Arbitrary View Image | http://arxiv.org/pdf/1509.06161v1.pdf | author:Feng Liu, Dan Zeng, Jing Li, Qijun Zhao category:cs.CV published:2015-09-21 summary:State-of-the-art methods reconstruct three-dimensional (3D) face shapes froma single image by fitting 3D face models to input images or by directlylearning mapping functions between two-dimensional (2D) images and 3D faces.However, they are often difficult to use in real-world applications due toexpensive online optimization or to the requirement of frontal face images.This paper approaches the 3D face reconstruction problem as a regressionproblem rather than a model fitting problem. Given an input face image alongwith some pre-defined facial landmarks on it, a series of shape adjustments tothe initial 3D face shape are computed through cascaded regressors based on thedeviations between the input landmarks and the landmarks obtained from thereconstructed 3D faces. The cascaded regressors are offline learned from a setof 3D faces and their corresponding 2D face images in various views. Bytreating the landmarks that are invisible in large view angles as missing data,the proposed method can handle arbitrary view face images in a unified way withthe same regressors. Experiments on the BFM and Bosphorus databases demonstratethat the proposed method can reconstruct 3D faces from arbitrary view imagesmore efficiently and more accurately than existing methods.
arxiv-12600-272 | Noise Robust IOA/CAS Speech Separation and Recognition System For The Third 'CHIME' Challenge | http://arxiv.org/pdf/1509.06103v1.pdf | author:Xiaofei Wang, Chao Wu, Pengyuan Zhang, Ziteng Wang, Yong Liu, Xu Li, Qiang Fu, Yonghong Yan category:cs.SD cs.CL published:2015-09-21 summary:This paper presents the contribution to the third 'CHiME' speech separationand recognition challenge including both front-end signal processing andback-end speech recognition. In the front-end, Multi-channel Wiener filter(MWF) is designed to achieve background noise reduction. Different fromtraditional MWF, optimized parameter for the tradeoff between noise reductionand target signal distortion is built according to the desired noise reductionlevel. In the back-end, several techniques are taken advantage to improve thenoisy Automatic Speech Recognition (ASR) performance including Deep NeuralNetwork (DNN), Convolutional Neural Network (CNN) and Long short-term memory(LSTM) using medium vocabulary, Lattice rescoring with a big vocabularylanguage model finite state transducer, and ROVER scheme. Experimental resultsshow the proposed system combining front-end and back-end is effective toimprove the ASR performance.
arxiv-12600-273 | Multilayer bootstrap network for unsupervised speaker recognition | http://arxiv.org/pdf/1509.06095v1.pdf | author:Xiao-Lei Zhang category:cs.LG cs.SD published:2015-09-21 summary:We apply multilayer bootstrap network (MBN), a recent proposed unsupervisedlearning method, to unsupervised speaker recognition. The proposed method firstextracts supervectors from an unsupervised universal background model, thenreduces the dimension of the high-dimensional supervectors by multilayerbootstrap network, and finally conducts unsupervised speaker recognition byclustering the low-dimensional data. The comparison results with 2 unsupervisedand 1 supervised speaker recognition techniques demonstrate the effectivenessand robustness of the proposed method.
arxiv-12600-274 | Significance Analysis of High-Dimensional, Low-Sample Size Partially Labeled Data | http://arxiv.org/pdf/1509.06088v1.pdf | author:Qiyi Lu, Xingye Qiao category:stat.ML cs.LG stat.ME published:2015-09-21 summary:Classification and clustering are both important topics in statisticallearning. A natural question herein is whether predefined classes are reallydifferent from one another, or whether clusters are really there. Specifically,we may be interested in knowing whether the two classes defined by some classlabels (when they are provided), or the two clusters tagged by a clusteringalgorithm (where class labels are not provided), are from the same underlyingdistribution. Although both are challenging questions for the high-dimensional,low-sample size data, there has been some recent development for both. However,when it is costly to manually place labels on observations, it is often thatonly a small portion of the class labels is available. In this article, wepropose a significance analysis approach for such type of data, namelypartially labeled data. Our method makes use of the whole data and tries totest the class difference as if all the labels were observed. Compared to atesting method that ignores the label information, our method provides agreater power, meanwhile, maintaining the size, illustrated by a comprehensivesimulation study. Theoretical properties of the proposed method are studiedwith emphasis on the high-dimensional, low-sample size setting. Our simulatedexamples help to understand when and how the information extracted from thelabeled data can be effective. A real data example further illustrates theusefulness of the proposed method.
arxiv-12600-275 | On Large-Scale Retrieval: Binary or n-ary Coding? | http://arxiv.org/pdf/1509.06066v1.pdf | author:Mahyar Najibi, Mohammad Rastegari, Larry S. Davis category:cs.CV published:2015-09-20 summary:The growing amount of data available in modern-day datasets makes the need toefficiently search and retrieve information. To make large-scale searchfeasible, Distance Estimation and Subset Indexing are the main approaches.Although binary coding has been popular for implementing both techniques, n-arycoding (known as Product Quantization) is also very effective for DistanceEstimation. However, their relative performance has not been studied for SubsetIndexing. We investigate whether binary or n-ary coding works better underdifferent retrieval strategies. This leads to the design of a new n-ary codingmethod, "Linear Subspace Quantization (LSQ)" which, unlike other n-aryencoders, can be used as a similarity-preserving embedding. Experiments onimage retrieval show that when Distance Estimation is used, n-ary LSQoutperforms other methods. However, when Subset Indexing is applied,interestingly, binary codings are more effective and binary LSQ achieves thebest accuracy.
arxiv-12600-276 | A Statistical Theory of Deep Learning via Proximal Splitting | http://arxiv.org/pdf/1509.06061v1.pdf | author:Nicholas G. Polson, Brandon T. Willard, Massoud Heidari category:stat.ML published:2015-09-20 summary:In this paper we develop a statistical theory and an implementation of deeplearning models. We show that an elegant variable splitting scheme for thealternating direction method of multipliers optimises a deep learningobjective. We allow for non-smooth non-convex regularisation penalties toinduce sparsity in parameter weights. We provide a link between traditionalshallow layer statistical models such as principal component and sliced inverseregression and deep layer models. We also define the degrees of freedom of adeep learning predictor and a predictive MSE criteria to perform modelselection for comparing architecture designs. We focus on deep multiclasslogistic learning although our methods apply more generally. Our resultssuggest an interesting and previously under-exploited relationship between deeplearning and proximal splitting techniques. To illustrate our methodology, weprovide a multi-class logit classification analysis of Fisher's Iris data wherewe illustrate the convergence of our algorithm. Finally, we conclude withdirections for future research.
arxiv-12600-277 | Impact of noise on a dynamical system: prediction and uncertainties from a swarm-optimized neural network | http://arxiv.org/pdf/1509.06057v1.pdf | author:C. H. López-Caraballo, J. A. Lazzús, I. Salfate, P. Rojas, M. Rivera, L. Palma-Chilla category:cs.NE published:2015-09-20 summary:In this study, an artificial neural network (ANN) based on particle swarmoptimization (PSO) was developed for the time series prediction. The hybridANN+PSO algorithm was applied on Mackey--Glass chaotic time series in theshort-term $x(t+6)$. The performance prediction was evaluated and compared withanother studies available in the literature. Also, we presented properties ofthe dynamical system via the study of chaotic behaviour obtained from thepredicted time series. Next, the hybrid ANN+PSO algorithm was complemented witha Gaussian stochastic procedure (called {\it stochastic} hybrid ANN+PSO) inorder to obtain a new estimator of the predictions, which also allowed us tocompute uncertainties of predictions for noisy Mackey--Glass chaotic timeseries. Thus, we studied the impact of noise for several cases with a whitenoise level ($\sigma_{N}$) from 0.01 to 0.1.
arxiv-12600-278 | Early text classification: a Naive solution | http://arxiv.org/pdf/1509.06053v1.pdf | author:Hugo Jair Escalante, Manuel Montes-y-Gómez, Luis Villaseñor-Pineda, Marcelo Luis Errecalde category:cs.CL published:2015-09-20 summary:Text classification is a widely studied problem, and it can be consideredsolved for some domains and under certain circumstances. There are scenarios,however, that have received little or no attention at all, despite itsrelevance and applicability. One of such scenarios is early textclassification, where one needs to know the category of a document by usingpartial information only. A document is processed as a sequence of terms, andthe goal is to devise a method that can make predictions as fast as possible.The importance of this variant of the text classification problem is evident indomains like sexual predator detection, where one wants to identify an offenderas early as possible. This paper analyzes the suitability of the standard naiveBayes classifier for approaching this problem. Specifically, we assess itsperformance when classifying documents after seeing an increasingly number ofterms. A simple modification to the standard naive Bayes implementation allowsus to make predictions with partial information. To the best of our knowledgenaive Bayes has not been used for this purpose before. Throughout an extensiveexperimental evaluation we show the effectiveness of the classifier for earlytext classification. What is more, we show that this simple solution is verycompetitive when compared with state of the art methodologies that are moreelaborated. We foresee our work will pave the way for the development of moreeffective early text classification techniques based in the naive Bayesformulation.
arxiv-12600-279 | Robust Image Sentiment Analysis Using Progressively Trained and Domain Transferred Deep Networks | http://arxiv.org/pdf/1509.06041v1.pdf | author:Quanzeng You, Jiebo Luo, Hailin Jin, Jianchao Yang category:cs.CV cs.IR cs.LG published:2015-09-20 summary:Sentiment analysis of online user generated content is important for manysocial media analytics tasks. Researchers have largely relied on textualsentiment analysis to develop systems to predict political elections, measureeconomic indicators, and so on. Recently, social media users are increasinglyusing images and videos to express their opinions and share their experiences.Sentiment analysis of such large scale visual content can help better extractuser sentiments toward events or topics, such as those in image tweets, so thatprediction of sentiment from visual content is complementary to textualsentiment analysis. Motivated by the needs in leveraging large scale yet noisytraining data to solve the extremely challenging problem of image sentimentanalysis, we employ Convolutional Neural Networks (CNN). We first design asuitable CNN architecture for image sentiment analysis. We obtain half amillion training samples by using a baseline sentiment algorithm to labelFlickr images. To make use of such noisy machine labeled data, we employ aprogressive strategy to fine-tune the deep network. Furthermore, we improve theperformance on Twitter images by inducing domain transfer with a small numberof manually labeled Twitter images. We have conducted extensive experiments onmanually labeled Twitter images. The results show that the proposed CNN canachieve better performance in image sentiment analysis than competingalgorithms.
arxiv-12600-280 | Image Retrieval Based on LBP Pyramidal Multiresolution using Reversible Watermarking | http://arxiv.org/pdf/1509.06035v1.pdf | author:H. Ouahi, K. Afdel, M. Machkour category:cs.CV published:2015-09-20 summary:In the medical field, images are increasingly used to facilitate diagnosis ofdiseases. These images are stored in multimedia databases accompanied by doctors prescriptions and other information related to patients.Search for medicalimages has become for clinical applications an essential tool to bringeffective aid in diagnosis. Content Based Image Retrieval (CBIR) is one of thepossible solutions to effectively manage these databases. Our contribution isto define a relevant descriptor to retrieve images based on multiresolutionanalysis of texture using Local Binary Pattern LBP. This descriptor oncecalculated and information s relating to the patient; will be placed in theimage using the technique of reversible watermarking. Thereby, the image,descriptor of its contents, the BFILE locator and patientrelated informationbecome a single entity, so even the administrator cannot have access to thepatient private data.
arxiv-12600-281 | Deep Convolutional Features for Image Based Retrieval and Scene Categorization | http://arxiv.org/pdf/1509.06033v1.pdf | author:Arsalan Mousavian, Jana Kosecka category:cs.CV published:2015-09-20 summary:Several recent approaches showed how the representations learned byConvolutional Neural Networks can be repurposed for novel tasks. Most commonlyit has been shown that the activation features of the last fully connectedlayers (fc7 or fc6) of the network, followed by a linear classifier outperformthe state-of-the-art on several recognition challenge datasets. Instead ofrecognition, this paper focuses on the image retrieval problem and proposes aexamines alternative pooling strategies derived for CNN features. The presentedscheme uses the features maps from an earlier layer 5 of the CNN architecture,which has been shown to preserve coarse spatial information and is semanticallymeaningful. We examine several pooling strategies and demonstrate superiorperformance on the image retrieval task (INRIA Holidays) at the fraction of thecomputational cost, while using a relatively small memory requirements. Inaddition to retrieval, we see similar efficiency gains on the SUN397 scenecategorization dataset, demonstrating wide applicability of this simplestrategy. We also introduce and evaluate a novel GeoPlaces5K dataset fromdifferent geographical locations in the world for image retrieval that stressesmore dramatic changes in appearance and viewpoint.
arxiv-12600-282 | Image Set Querying Based Localization | http://arxiv.org/pdf/1509.06016v1.pdf | author:Lei Deng, Siyuan Huang, Yueqi Duan, Baohua Chen, Jie Zhou category:cs.CV published:2015-09-20 summary:Conventional single image based localization methods usually fail to localizea querying image when there exist large variations between the querying imageand the pre-built scene. To address this, we propose an image-set queryingbased localization approach. When the localization by a single image fails towork, the system will ask the user to capture more auxiliary images. First, alocal 3D model is established for the querying image set. Then, the pose of thequerying image set is estimated by solving a nonlinear optimization problem,which aims to match the local 3D model against the pre-built scene. Experimentshave shown the effectiveness and feasibility of the proposed approach.
arxiv-12600-283 | Effective Approaches to Attention-based Neural Machine Translation | http://arxiv.org/pdf/1508.04025v5.pdf | author:Minh-Thang Luong, Hieu Pham, Christopher D. Manning category:cs.CL published:2015-08-17 summary:An attentional mechanism has lately been used to improve neural machinetranslation (NMT) by selectively focusing on parts of the source sentenceduring translation. However, there has been little work exploring usefularchitectures for attention-based NMT. This paper examines two simple andeffective classes of attentional mechanism: a global approach which alwaysattends to all source words and a local one that only looks at a subset ofsource words at a time. We demonstrate the effectiveness of both approachesover the WMT translation tasks between English and German in both directions.With local attention, we achieve a significant gain of 5.0 BLEU points overnon-attentional systems which already incorporate known techniques such asdropout. Our ensemble model using different attention architectures hasestablished a new state-of-the-art result in the WMT'15 English to Germantranslation task with 25.9 BLEU points, an improvement of 1.0 BLEU points overthe existing best system backed by NMT and an n-gram reranker.
arxiv-12600-284 | Telugu OCR Framework using Deep Learning | http://arxiv.org/pdf/1509.05962v1.pdf | author:Rakesh Achanta, Trevor Hastie category:stat.ML cs.AI cs.CV cs.LG cs.NE published:2015-09-20 summary:In this paper, we address the task of Optical Character Recognition(OCR) forthe Telugu script. We present an end-to-end framework that segments the textimage, classifies the characters and extracts lines using a language model. Thesegmentation is based on mathematical morphology. The classification module,which is the most challenging task of the three, is a deep convolutional neuralnetwork. The language is modelled as a third degree markov chain at the glyphlevel. Telugu script is a complex abugida and the language is agglutinative,making the problem hard. In this paper we apply the latest advances in neuralnetworks to achieve acceptable error rates.
arxiv-12600-285 | Lexical Normalisation of Twitter Data | http://arxiv.org/pdf/1409.4614v4.pdf | author:Bilal Ahmed category:cs.CL published:2014-09-16 summary:Twitter with over 500 million users globally, generates over 100,000 tweetsper minute . The 140 character limit per tweet, perhaps unintentionally,encourages users to use shorthand notations and to strip spellings to theirbare minimum "syllables" or elisions e.g. "srsly". The analysis of twittermessages which typically contain misspellings, elisions, and grammaticalerrors, poses a challenge to established Natural Language Processing (NLP)tools which are generally designed with the assumption that the data conformsto the basic grammatical structure commonly used in English language. In orderto make sense of Twitter messages it is necessary to first transform them intoa canonical form, consistent with the dictionary or grammar. This process,performed at the level of individual tokens ("words"), is called lexicalnormalisation. This paper investigates various techniques for lexicalnormalisation of Twitter data and presents the findings as the techniques areapplied to process raw data from Twitter.
arxiv-12600-286 | Using Neural Networks for Click Prediction of Sponsored Search | http://arxiv.org/pdf/1412.6601v3.pdf | author:Afroze Ibrahim Baqapuri, Ilya Trofimov category:cs.LG cs.NE published:2014-12-20 summary:Sponsored search is a multi-billion dollar industry and makes up a majorsource of revenue for search engines (SE). click-through-rate (CTR) estimationplays a crucial role for ads selection, and greatly affects the SE revenue,advertiser traffic and user experience. We propose a novel architecture forsolving CTR prediction problem by combining artificial neural networks (ANN)with decision trees. First we compare ANN with respect to other popular machinelearning models being used for this task. Then we go on to combine ANN withMatrixNet (proprietary implementation of boosted trees) and evaluate theperformance of the system as a whole. The results show that our approachprovides significant improvement over existing models.
arxiv-12600-287 | Face Photo Sketch Synthesis via Larger Patch and Multiresolution Spline | http://arxiv.org/pdf/1509.05897v1.pdf | author:Xu Yang category:cs.CV published:2015-09-19 summary:Face photo sketch synthesis has got some researchers' attention in recentyears because of its potential applications in digital entertainment and lawenforcement. Some patches based methods have been proposed to solve thisproblem. These methods usually focus more on how to get a sketch patch for agiven photo patch than how to blend these generated patches. However, withoutappropriately blending method, some jagged parts and mottled points will appearin the entire face sketch. In order to get a smoother sketch, we propose a newmethod to reduce such jagged parts and mottled points. In our system, we resortto an existed method, which is Markov Random Fields (MRF), to train a crudeface sketch firstly. Then this crude sketch face sketch will be divided intosome larger patches again and retrained by Non-Negative Matrix Factorization(NMF). At last, we use Multiresolution Spline and a blend trick namedfull-coverage trick to blend these retrained patches. The experiment resultsshow that compared with some previous method, we can get a smoother facesketch.
arxiv-12600-288 | A Fuzzy MLP Approach for Non-linear Pattern Classification | http://arxiv.org/pdf/1601.03481v1.pdf | author:Tirtharaj Dash, H. S. Behera category:cs.NE published:2015-09-19 summary:In case of decision making problems, classification of pattern is a complexand crucial task. Pattern classification using multilayer perceptron (MLP)trained with back propagation learning becomes much complex with increase innumber of layers, number of nodes and number of epochs and ultimate increasescomputational time [31]. In this paper, an attempt has been made to use fuzzyMLP and its learning algorithm for pattern classification. The time and spacecomplexities of the algorithm have been analyzed. A training performancecomparison has been carried out between MLP and the proposed fuzzy-MLP model byconsidering six cases. Results are noted against different learning ratesranging from 0 to 1. A new performance evaluation factor 'convergence gain' hasbeen introduced. It is observed that the number of epochs drastically reducedand performance increased compared to MLP. The average and minimum gain hasbeen found to be 93% and 75% respectively. The best gain is found to be 95% andis obtained by setting the learning rate to 0.55.
arxiv-12600-289 | Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting | http://arxiv.org/pdf/1506.04214v2.pdf | author:Xingjian Shi, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-kin Wong, Wang-chun Woo category:cs.CV published:2015-06-13 summary:The goal of precipitation nowcasting is to predict the future rainfallintensity in a local region over a relatively short period of time. Very fewprevious studies have examined this crucial and challenging weather forecastingproblem from the machine learning perspective. In this paper, we formulateprecipitation nowcasting as a spatiotemporal sequence forecasting problem inwhich both the input and the prediction target are spatiotemporal sequences. Byextending the fully connected LSTM (FC-LSTM) to have convolutional structuresin both the input-to-state and state-to-state transitions, we propose theconvolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable modelfor the precipitation nowcasting problem. Experiments show that our ConvLSTMnetwork captures spatiotemporal correlations better and consistentlyoutperforms FC-LSTM and the state-of-the-art operational ROVER algorithm forprecipitation nowcasting.
arxiv-12600-290 | Car that Knows Before You Do: Anticipating Maneuvers via Learning Temporal Driving Models | http://arxiv.org/pdf/1504.02789v2.pdf | author:Ashesh Jain, Hema S. Koppula, Bharad Raghavan, Shane Soh, Ashutosh Saxena category:cs.CV published:2015-04-10 summary:Advanced Driver Assistance Systems (ADAS) have made driving safer over thelast decade. They prepare vehicles for unsafe road conditions and alert driversif they perform a dangerous maneuver. However, many accidents are unavoidablebecause by the time drivers are alerted, it is already too late. Anticipatingmaneuvers beforehand can alert drivers before they perform the maneuver andalso give ADAS more time to avoid or prepare for the danger. In this work we anticipate driving maneuvers a few seconds before they occur.For this purpose we equip a car with cameras and a computing device to capturethe driving context from both inside and outside of the car. We propose anAutoregressive Input-Output HMM to model the contextual information alongwiththe maneuvers. We evaluate our approach on a diverse data set with 1180 milesof natural freeway and city driving and show that we can anticipate maneuvers3.5 seconds before they occur with over 80\% F1-score in real-time.
arxiv-12600-291 | Similar Handwritten Chinese Character Discrimination by Weakly Supervised Learning | http://arxiv.org/pdf/1509.05844v1.pdf | author:Zhibo Yang, Huanle Xu, Keda Fu, Yong Xia category:cs.CV published:2015-09-19 summary:Traditional approaches for handwritten Chinese character recognition sufferin classifying similar characters. In this paper, we propose to discriminatesimilar handwritten Chinese characters by using weakly supervised learning. Ourapproach learns a discriminative SVM for each similar pair which simultaneouslylocalizes the discriminative region of similar character and makes theclassification. For the first time, similar handwritten Chinese characterrecognition (SHCCR) is formulated as an optimization problem extended from SVM.We also propose a novel feature descriptor, Gradient Context, and applybag-of-words model to represent regions with different scales. In our method,we do not need to select a sized-fixed sub-window to differentiate similarcharacters. The unconstrained property makes our method well adapted to highvariance in the size and position of discriminative regions in similarhandwritten Chinese characters. We evaluate our proposed approach over theCASIA Chinese character data set and the results show that our methodoutperforms the state of the art.
arxiv-12600-292 | DenseBox: Unifying Landmark Localization with End to End Object Detection | http://arxiv.org/pdf/1509.04874v3.pdf | author:Lichao Huang, Yi Yang, Yafeng Deng, Yinan Yu category:cs.CV published:2015-09-16 summary:How can a single fully convolutional neural network (FCN) perform on objectdetection? We introduce DenseBox, a unified end-to-end FCN framework thatdirectly predicts bounding boxes and object class confidences through alllocations and scales of an image. Our contribution is two-fold. First, we showthat a single FCN, if designed and optimized carefully, can detect multipledifferent objects extremely accurately and efficiently. Second, we show thatwhen incorporating with landmark localization during multi-task learning,DenseBox further improves object detection accuray. We present experimentalresults on public benchmark datasets including MALF face detection and KITTIcar detection, that indicate our DenseBox is the state-of-the-art system fordetecting challenging objects such as faces and cars.
arxiv-12600-293 | Robobarista: Object Part based Transfer of Manipulation Trajectories from Crowd-sourcing in 3D Pointclouds | http://arxiv.org/pdf/1504.03071v2.pdf | author:Jaeyong Sung, Seok Hyun Jin, Ashutosh Saxena category:cs.RO cs.AI cs.LG published:2015-04-13 summary:There is a large variety of objects and appliances in human environments,such as stoves, coffee dispensers, juice extractors, and so on. It ischallenging for a roboticist to program a robot for each of these object typesand for each of their instantiations. In this work, we present a novel approachto manipulation planning based on the idea that many household objects sharesimilarly-operated object parts. We formulate the manipulation planning as astructured prediction problem and design a deep learning model that can handlelarge noise in the manipulation demonstrations and learns features from threedifferent modalities: point-clouds, language and trajectory. In order tocollect a large number of manipulation demonstrations for different objects, wedeveloped a new crowd-sourcing platform called Robobarista. We test our modelon our dataset consisting of 116 objects with 249 parts along with 250 languageinstructions, for which there are 1225 crowd-sourced manipulationdemonstrations. We further show that our robot can even manipulate objects ithas never seen before.
arxiv-12600-294 | Word, graph and manifold embedding from Markov processes | http://arxiv.org/pdf/1509.05808v1.pdf | author:Tatsunori B. Hashimoto, David Alvarez-Melis, Tommi S. Jaakkola category:cs.CL cs.LG stat.ML published:2015-09-18 summary:Continuous vector representations of words and objects appear to carrysurprisingly rich semantic content. In this paper, we advance both theconceptual and theoretical understanding of word embeddings in three ways.First, we ground embeddings in semantic spaces studied incognitive-psychometric literature and introduce new evaluation tasks. Second,in contrast to prior work, we take metric recovery as the key object of study,unify existing algorithms as consistent metric recovery methods based onco-occurrence counts from simple Markov random walks, and propose a newrecovery algorithm. Third, we generalize metric recovery to graphs andmanifolds, relating co-occurence counts on random walks in graphs and randomprocesses on manifolds to the underlying metric to be recovered, therebyreconciling manifold estimation and embedding algorithms. We compare embeddingalgorithms across a range of tasks, from nonlinear dimensionality reduction tothree semantic language tasks, including analogies, sequence completion, andclassification.
arxiv-12600-295 | "Oddball SGD": Novelty Driven Stochastic Gradient Descent for Training Deep Neural Networks | http://arxiv.org/pdf/1509.05765v1.pdf | author:Andrew J. R. Simpson category:cs.LG 68Txx published:2015-09-18 summary:Stochastic Gradient Descent (SGD) is arguably the most popular of the machinelearning methods applied to training deep neural networks (DNN) today. It hasrecently been demonstrated that SGD can be statistically biased so that certainelements of the training set are learned more rapidly than others. In thisarticle, we place SGD into a feedback loop whereby the probability of selectionis proportional to error magnitude. This provides a novelty-driven oddball SGDprocess that learns more rapidly than traditional SGD by prioritising thoseelements of the training set with the largest novelty (error). In our DNNexample, oddball SGD trains some 50x faster than regular SGD.
arxiv-12600-296 | Subdominant Dense Clusters Allow for Simple Learning and High Computational Performance in Neural Networks with Discrete Synapses | http://arxiv.org/pdf/1509.05753v1.pdf | author:Carlo Baldassi, Alessandro Ingrosso, Carlo Lucibello, Luca Saglietti, Riccardo Zecchina category:q-bio.NC stat.ML published:2015-09-18 summary:We show that discrete synaptic weights can be efficiently used for learningin large scale neural systems, and lead to unanticipated computationalperformance. We focus on the representative case of learning random patternswith binary synapses in single layer networks. The standard statisticalanalysis shows that this problem is exponentially dominated by isolatedsolutions that are extremely hard to find algorithmically. Here, we introduce anovel method that allows us to find analytical evidence for the existence ofsubdominant and extremely dense regions of solutions. Numerical experimentsconfirm these findings. We also show that the dense regions are surprisinglyaccessible by simple learning protocols, and that these synaptic configurationsare robust to perturbations and generalize better than typical solutions. Theseoutcomes extend to synapses with multiple states and to deeper neuralarchitectures. The large deviation measure also suggests how to design novelalgorithmic schemes for optimization based on local entropy maximization.
arxiv-12600-297 | Evaluation of Protein-protein Interaction Predictors with Noisy Partially Labeled Data Sets | http://arxiv.org/pdf/1509.05742v1.pdf | author:Haohan Wang, Madhavi K. Ganapathiraju category:cs.AI stat.ML published:2015-09-18 summary:Protein-protein interaction (PPI) prediction is an important problem inmachine learning and computational biology. However, there is no data set fortraining or evaluation purposes, where all the instances are accuratelylabeled. Instead, what is available are instances of positive class (withpossibly noisy labels) and no instances of negative class. The non-availabilityof negative class data is typically handled with the observation that randomlychosen protein-pairs have a nearly 100% chance of being negative class, as only1 in 1,500 protein pairs expected is expected to be an interacting pair. Inthis paper, we focused on the problem that non-availability of accuratelylabeled testing data sets in the domain of protein-protein interaction (PPI)prediction may lead to biased evaluation results. We first showed that notacknowledging the inherent skew in the interactome (i.e. rare occurrence ofpositive instances) leads to an over-estimated accuracy of the predictor. Thenwe show that, with the belief that positive interactions are a rare category,sampling random pairs of proteins excluding known interacting proteins set asthe negative testing data set could lead to an under-estimated evaluationresult. We formalized those two problems to validate the above claim, and basedon the formalization, we proposed a balancing method to cancel out theover-estimation with under-estimation. Finally, our experiments validated thetheoretical aspects and showed that this balancing evaluation could evaluatethe exact performance without availability of golden standard data sets.
arxiv-12600-298 | Building a Pilot Software Quality-in-Use Benchmark Dataset | http://arxiv.org/pdf/1509.05736v1.pdf | author:Issa Atoum, Chih How Bong, Narayanan Kulathuramaiyer category:cs.SE cs.CL published:2015-09-18 summary:Prepared domain specific datasets plays an important role to supervisedlearning approaches. In this article a new sentence dataset for softwarequality-in-use is proposed. Three experts were chosen to annotate the datausing a proposed annotation scheme. Then the data were reconciled in a (nomatch eliminate) process to reduce bias. The Kappa, k statistics revealed anacceptable level of agreement; moderate to substantial agreement between theexperts. The built data can be used to evaluate software quality-in-use modelsin sentiment analysis models. Moreover, the annotation scheme can be used toextend the current dataset.
arxiv-12600-299 | Bayesian inference for spatio-temporal spike and slab priors | http://arxiv.org/pdf/1509.04752v2.pdf | author:Michael Riis Andersen, Aki Vehtari, Ole Winther, Lars Kai Hansen category:stat.ML stat.CO stat.ME published:2015-09-15 summary:In this work we address the problem of solving a series of underdeterminedlinear inverse problems subject to a sparsity constraint. We generalize thespike and slab prior distribution to encode a priori correlation of the supportof the solution in both space and time by imposing a transformed Gaussianprocess on the spike and slab probabilities. An expectation propagation (EP)algorithm for posterior inference under the proposed model is derived. Forlarge scale problems, the standard EP algorithm can be prohibitively slow. Wetherefore introduce three different approximation schemes to reduce thecomputational complexity. Finally, we demonstrate the proposed model usingnumerical experiments based on both synthetic and real data sets.
arxiv-12600-300 | Convolutional Color Constancy | http://arxiv.org/pdf/1507.00410v2.pdf | author:Jonathan T. Barron category:cs.CV published:2015-07-02 summary:Color constancy is the problem of inferring the color of the light thatilluminated a scene, usually so that the illumination color can be removed.Because this problem is underconstrained, it is often solved by modeling thestatistical regularities of the colors of natural objects and illumination. Incontrast, in this paper we reformulate the problem of color constancy as a 2Dspatial localization task in a log-chrominance space, thereby allowing us toapply techniques from object detection and structured prediction to the colorconstancy problem. By directly learning how to discriminate between correctlywhite-balanced images and poorly white-balanced images, our model is able toimprove performance on standard benchmarks by nearly 40%.
