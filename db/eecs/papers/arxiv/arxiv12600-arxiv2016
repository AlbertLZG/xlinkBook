arxiv-1507-07458 | Discovery of Shared Semantic Spaces for Multi-Scene Video Query and Summarization |  http://arxiv.org/abs/1507.07458  | author:Xun Xu, Timothy Hospedales, Shaogang Gong category:cs.CV published:2015-07-27 summary:The growing rate of public space CCTV installations has generated a need forautomated methods for exploiting video surveillance data including sceneunderstanding, query, behaviour annotation and summarization. For this reason,extensive research has been performed on surveillance scene understanding andanalysis. However, most studies have considered single scenes, or groups ofadjacent scenes. The semantic similarity between different but related scenes(e.g., many different traffic scenes of similar layout) is not generallyexploited to improve any automated surveillance tasks and reduce manual effort.Exploiting commonality, and sharing any supervised annotations, betweendifferent scenes is however challenging due to: Some scenes are totallyun-related -- and thus any information sharing between them would bedetrimental; while others may only share a subset of common activities -- andthus information sharing is only useful if it is selective. Moreover,semantically similar activities which should be modelled together and sharedacross scenes may have quite different pixel-level appearance in each scene. Toaddress these issues we develop a new framework for distributed multiple-sceneglobal understanding that clusters surveillance scenes by their ability toexplain each other's behaviours; and further discovers which subset ofactivities are shared versus scene-specific within each cluster. We show how touse this structured representation of multiple scenes to improve commonsurveillance tasks including scene activity understanding, cross-scenequery-by-example, behaviour classification with reduced supervised labellingrequirements, and video summarization. In each case we demonstrate how ourmulti-scene model improves on a collection of standard single scene models anda flat model of all scenes.
arxiv-1507-07301 | A Social Spider Algorithm for Solving the Non-convex Economic Load Dispatch Problem |  http://arxiv.org/abs/1507.07301  | author:James J. Q. Yu, Victor O. K. Li category:cs.NE published:2015-07-27 summary:Economic Load Dispatch (ELD) is one of the essential components in powersystem control and operation. Although conventional ELD formulation can besolved using mathematical programming techniques, modern power systemintroduces new models of the power units which are non-convex,non-differentiable, and sometimes non-continuous. In order to solve suchnon-convex ELD problems, in this paper we propose a new approach based on theSocial Spider Algorithm (SSA). The classical SSA is modified and enhanced toadapt to the unique characteristics of ELD problems, e.g., valve-point effects,multi-fuel operations, prohibited operating zones, and line losses. Todemonstrate the superiority of our proposed approach, five widely-adopted testsystems are employed and the simulation results are compared with thestate-of-the-art algorithms. In addition, the parameter sensitivity isillustrated by a series of simulations. The simulation results show that SSAcan solve ELD problems effectively and efficiently.
arxiv-1507-07882 | Occlusion-Aware Object Localization, Segmentation and Pose Estimation |  http://arxiv.org/abs/1507.07882  | author:Samarth Brahmbhatt, Heni Ben Amor, Henrik Christensen category:cs.CV published:2015-07-27 summary:We present a learning approach for localization and segmentation of objectsin an image in a manner that is robust to partial occlusion. Our algorithmproduces a bounding box around the full extent of the object and labels pixelsin the interior that belong to the object. Like existing segmentation awaredetection approaches, we learn an appearance model of the object and considerregions that do not fit this model as potential occlusions. However, inaddition to the established use of pairwise potentials for encouraging localconsistency, we use higher order potentials which capture information at thelevel of im- age segments. We also propose an efficient loss function thattargets both localization and segmentation performance. Our algorithm achieves13.52% segmentation error and 0.81 area under the false-positive per image vs.recall curve on average over the challenging CMU Kitchen Occlusion Dataset.This is a 42.44% decrease in segmentation error and a 16.13% increase inlocalization performance compared to the state-of-the-art. Finally, we showthat the visibility labelling produced by our algorithm can make full 3D poseestimation from a single image robust to occlusion.
arxiv-1507-07374 | A genetic algorithm for autonomous navigation in partially observable domain |  http://arxiv.org/abs/1507.07374  | author:Maxim Borisyak, Andrey Ustyuzhanin category:cs.LG cs.AI cs.NE 68T05 published:2015-07-27 summary:The problem of autonomous navigation is one of the basic problems forrobotics. Although, in general, it may be challenging when an autonomousvehicle is placed into partially observable domain. In this paper we considersimplistic environment model and introduce a navigation algorithm based onLearning Classifier System.
arxiv-1507-07200 | A Neural Prototype for a Virtual Chemical Spectrophotometer |  http://arxiv.org/abs/1507.07200  | author:Jaderick P. Pabico, Jose Rene L. Micor, Elmer Rico E. Mojica category:cs.NE published:2015-07-26 summary:A virtual chemical spectrophotometer for the simultaneous analysis of nickel(Ni) and cobalt (Co) was developed based on an artificial neural network (ANN).The developed ANN correlates the respective concentrations of Co and Ni giventhe absorbance profile of a Co-Ni mixture based on the Beer's Law. The virtualchemical spectrometer was trained using a 3-layer jump connection neuralnetwork model (NNM) with 126 input nodes corresponding to the 126 absorbancereadings from 350 nm to 600 nm, 70 nodes in the hidden layer using a logisticactivation function, and 2 nodes in the output layer with a logistic function.Test result shows that the NNM has correlation coefficients of 0.9953 and0.9922 when predicting [Co] and [Ni], respectively. We observed, however, thatthe NNM has a duality property and that there exists a real-world practicalapplication in solving the dual problem: Predict the Co-Ni mixture's absorbanceprofile given [Co] and [Ni]. It turns out that the dual problem is much harderto solve because the intended output has a much bigger cardinality than that ofthe input. Thus, we trained the dual ANN, a 3-layer jump connection nets with 2input nodes corresponding to [Co] and [Ni], 70-logistic-activated nodes in thehidden layer, and 126 output nodes corresponding to the 126 absorbance readingsfrom 250 nm to 600 nm. Test result shows that the dual NNM has correlationcoefficients that range from 0.9050 through 0.9980 at 356 nm through 578 nmwith the maximum coefficient observed at 480 nm. This means that the dual ANNcan be used to predict the absorbance profile given the respective Co-Niconcentrations which can be of importance in creating academic models for avirtual chemical spectrophotometer.
arxiv-1507-07203 | Capturing the Dynamics of Pedestrian Traffic Using a Machine Vision System |  http://arxiv.org/abs/1507.07203  | author:Louie Vincent A. Ngoho, Jaderick P. Pabico category:cs.CV published:2015-07-26 summary:We developed a machine vision system to automatically capture the dynamics ofpedestrians under four different traffic scenarios. By considering the overheadview of each pedestrian as a digital object, the system processes the imagesequences to track the pedestrians. Considering the perspective effect of thecamera lens and the projected area of the hallway at the top-view scene, thedistance of each tracked object from its original position to its currentposition is approximated every video frame. Using the approximated distance andthe video frame rate (30 frames per second), the respective velocity andacceleration of each tracked object are later derived. The quantified motioncharacteristics of the pedestrians are displayed by the system through2-dimensional graphs of the kinematics of motion. The system also outputs videoimages of the pedestrians with superimposed markers for tracking. These visualmarkers were used to visually describe and quantify the behavior of thepedestrians under different traffic scenarios.
arxiv-1507-07199 | Task Selection for Bandit-Based Task Assignment in Heterogeneous Crowdsourcing |  http://arxiv.org/abs/1507.07199  | author:Hao Zhang, Masashi Sugiyama category:cs.LG published:2015-07-26 summary:Task selection (picking an appropriate labeling task) and worker selection(assigning the labeling task to a suitable worker) are two major challenges intask assignment for crowdsourcing. Recently, worker selection has beensuccessfully addressed by the bandit-based task assignment (BBTA) method, whiletask selection has not been thoroughly investigated yet. In this paper, weexperimentally compare several task selection strategies borrowed from activelearning literature, and show that the least confidence strategy significantlyimproves the performance of task assignment in crowdsourcing.
arxiv-1507-07204 | Modeling Website Workload Using Neural Networks |  http://arxiv.org/abs/1507.07204  | author:Yasir Shoaib, Olivia Das category:cs.DC cs.NE published:2015-07-26 summary:In this article, artificial neural networks (ANN) are used for modeling thenumber of requests received by 1998 FIFA World Cup website. Modeling is done bymeans of time-series forecasting. The log traces of the website, availablethrough the Internet Traffic Archive (ITA), are processed to obtain twotime-series data sets that are used for finding the following measurements:requests/day and requests/second. These are modeled by training and simulatingANN. The method followed to collect and process the data, and perform theexperiments have been detailed in this article. In total, 13 cases have beentried and their results have been presented, discussed, compared andsummarized. Lastly, future works have also been mentioned.
arxiv-1507-07238 | Estimator Selection: End-Performance Metric Aspects |  http://arxiv.org/abs/1507.07238  | author:Dimitrios Katselis, Cristian R. Rojas, Carolyn L. Beck category:cs.IT math.IT stat.ML published:2015-07-26 summary:Recently, a framework for application-oriented optimal experiment design hasbeen introduced. In this context, the distance of the estimated system from thetrue one is measured in terms of a particular end-performance metric. Thistreatment leads to superior unknown system estimates to classical experimentdesigns based on usual pointwise functional distances of the estimated systemfrom the true one. The separation of the system estimator from the experimentdesign is done within this new framework by choosing and fixing the estimationmethod to either a maximum likelihood (ML) approach or a Bayesian estimatorsuch as the minimum mean square error (MMSE). Since the MMSE estimator deliversa system estimate with lower mean square error (MSE) than the ML estimator forfinite-length experiments, it is usually considered the best choice in practicein signal processing and control applications. Within the application-orientedframework a related meaningful question is: Are there end-performance metricsfor which the ML estimator outperforms the MMSE when the experiment isfinite-length? In this paper, we affirmatively answer this question based on asimple linear Gaussian regression example.
arxiv-1507-07260 | Reduced-Set Kernel Principal Components Analysis for Improving the Training and Execution Speed of Kernel Machines |  http://arxiv.org/abs/1507.07260  | author:Hassan A. Kingravi, Patricio A. Vela, Alexandar Gray category:stat.ML cs.LG published:2015-07-26 summary:This paper presents a practical, and theoretically well-founded, approach toimprove the speed of kernel manifold learning algorithms relying on spectraldecomposition. Utilizing recent insights in kernel smoothing and learning withintegral operators, we propose Reduced Set KPCA (RSKPCA), which also suggestsan easy-to-implement method to remove or replace samples with minimal effect onthe empirical operator. A simple data point selection procedure is given togenerate a substitute density for the data, with accuracy that is governed by auser-tunable parameter . The effect of the approximation on the quality of theKPCA solution, in terms of spectral and operator errors, can be shown directlyin terms of the density estimate error and as a function of the parameter . Weshow in experiments that RSKPCA can improve both training and evaluation timeof KPCA by up to an order of magnitude, and compares favorably to thewidely-used Nystrom and density-weighted Nystrom methods.
arxiv-1507-07242 | Face Search at Scale: 80 Million Gallery |  http://arxiv.org/abs/1507.07242  | author:Dayong Wang, Charles Otto, Anil K. Jain category:cs.CV published:2015-07-26 summary:Due to the prevalence of social media websites, one challenge facing computervision researchers is to devise methods to process and search for persons ofinterest among the billions of shared photos on these websites. Facebookrevealed in a 2013 white paper that its users have uploaded more than 250billion photos, and are uploading 350 million new photos each day. Due to thishumongous amount of data, large-scale face search for mining web images is bothimportant and challenging. Despite significant progress in face recognition,searching a large collection of unconstrained face images has not beenadequately addressed. To address this challenge, we propose a face searchsystem which combines a fast search procedure, coupled with a state-of-the-artcommercial off the shelf (COTS) matcher, in a cascaded framework. Given a probeface, we first filter the large gallery of photos to find the top-k mostsimilar faces using deep features generated from a convolutional neuralnetwork. The k candidates are re-ranked by combining similarities from deepfeatures and the COTS matcher. We evaluate the proposed face search system on agallery containing 80 million web-downloaded face images. Experimental resultsdemonstrate that the deep features are competitive with state-of-the-artmethods on unconstrained face recognition benchmarks (LFW and IJB-A). Further,the proposed face search system offers an excellent trade-off between accuracyand scalability on datasets consisting of millions of images. Additionally, inan experiment involving searching for face images of the Tsarnaev brothers,convicted of the Boston Marathon bombing, the proposed face search system couldfind the younger brother's (Dzhokhar Tsarnaev) photo at rank 1 in 1 second on a5M gallery and at rank 8 in 7 seconds on an 80M gallery.
arxiv-1507-07105 | Dimensionality-reduced subspace clustering |  http://arxiv.org/abs/1507.07105  | author:Reinhard Heckel, Michael Tschannen, Helmut Bölcskei category:stat.ML cs.IT cs.LG math.IT published:2015-07-25 summary:Subspace clustering refers to the problem of clustering unlabeledhigh-dimensional data points into a union of low-dimensional linear subspaces,whose number, orientations, and dimensions are all unknown. In practice one mayhave access to dimensionality-reduced observations of the data only, resulting,e.g., from undersampling due to complexity and speed constraints on theacquisition device or mechanism. More pertinently, even if the high-dimensionaldata set is available it is often desirable to first project the data pointsinto a lower-dimensional space and to perform clustering there; this reducesstorage requirements and computational cost. The purpose of this paper is toquantify the impact of dimensionality reduction through random projection onthe performance of three subspace clustering algorithms, all of which are basedon principles from sparse signal recovery. Specifically, we analyze thethresholding based subspace clustering (TSC) algorithm, the sparse subspaceclustering (SSC) algorithm, and an orthogonal matching pursuit variant thereof(SSC-OMP). We find, for all three algorithms, that dimensionality reductiondown to the order of the subspace dimensions is possible without incurringsignificant performance degradation. Moreover, these results are order-wiseoptimal in the sense that reducing the dimensionality further leads to afundamentally ill-posed clustering problem. Our findings carry over to thenoisy case as illustrated through analytical results for TSC and simulationsfor SSC and SSC-OMP. Extensive experiments on synthetic and real datacomplement our theoretical findings.
arxiv-1507-07073 | Efficient Face Alignment via Locality-constrained Representation for Robust Recognition |  http://arxiv.org/abs/1507.07073  | author:Yandong Wen, Weiyang Liu, Meng Yang, Zhifeng Li category:cs.CV published:2015-07-25 summary:Practical face recognition has been studied in the past decades, but stillremains an open challenge. Current prevailing approaches have already achievedsubstantial breakthroughs in recognition accuracy. However, their performanceusually drops dramatically if face samples are severely misaligned. To addressthis problem, we propose a highly efficient misalignment-robustlocality-constrained representation (MRLR) algorithm for practical real-timeface recognition. Specifically, the locality constraint that activates the mostcorrelated atoms and suppresses the uncorrelated ones, is applied to constructthe dictionary for face alignment. Then we simultaneously align the warped faceand update the locality-constrained dictionary, eventually obtaining the finalalignment. Moreover, we make use of the block structure to accelerate thederived analytical solution. Experimental results on public data sets show thatMRLR significantly outperforms several state-of-the-art approaches in terms ofefficiency and scalability with even better performance.
arxiv-1507-07094 | Compressed Sensing without Sparsity Assumptions |  http://arxiv.org/abs/1507.07094  | author:Miles E. Lopes category:cs.IT math.IT math.ST stat.ME stat.ML stat.TH published:2015-07-25 summary:The theory of Compressed Sensing asserts that an unknown signal$x\in\mathbb{R}^p$ can be accurately recovered from an underdetermined set of$n$ linear measurements with $n\ll p$, provided that $x$ is sufficientlysparse. However, in applications, the degree of sparsity $\x\_0$ is typicallyunknown, and the problem of directly estimating $\x\_0$ has been alongstanding gap between theory and practice. A closely related issue is that$\x\_0$ is a highly idealized measure of sparsity, and for real signals withentries not exactly equal to 0, the value $\x\_0=p$ is not a usefuldescription of compressibility. In our previous conference paper that examinedthese problems, Lopes 2013, we considered an alternative measure of "soft"sparsity, $\x\_1^2/\x\_2^2$, and designed a procedure to estimate$\x\_1^2/\x\_2^2$ that does not rely on sparsity assumptions. The present work offers a new deconvolution-based method for estimatingunknown sparsity, which has wider applicability and sharper theoreticalguarantees. Whereas our earlier work was limited to estimating the quantity$\x\_1^2/\x\_2^2$, the current paper introduces a family of entropy-basedsparsity measures $s_q(x):=\big(\frac{\x\_q}{\x\_1}\big)^{\frac{q}{1-q}}$parameterized by $q\in[0,\infty]$. Two other main advantages of the newapproach are that it handles measurement noise with infinite variance, and thatit yields confidence intervals for $s_q(x)$ with asymptotically exact coverageprobability (whereas our previous intervals were conservative). In addition toconfidence intervals, we also analyze several other aspects of our proposedestimator $\hat{s}_q(x)$ and show that randomized measurements are an essentialaspect of our procedure.
arxiv-1507-07075 | A Study of Morphological Filtering Using Graph and Hypergraphs |  http://arxiv.org/abs/1507.07075  | author:Keerthana S. Prakash, R. P. Prakash, V. P. Binu category:cs.CV published:2015-07-25 summary:Mathematical morphology (MM) helps to describe and analyze shapes using settheory. MM can be effectively applied to binary images which are treated assets. Basic morphological operators defined can be used as an effective tool inimage processing. Morphological operators are also developed based on graph andhypergraph. These operators have found better performance and applications inimage processing. Bino et al. [8], [9] developed the theory of morphologicaloperators on hypergraph. A hypergraph structure is considered and basicmorphological operation erosion/dilation is defined. Several new operatorsopening/closing and filtering are also defined on the hypergraphs. Hypergraphbased filtering have found comparatively better performance with morphologicalfilters based on graph. In this paper we evaluate the effectiveness ofhypergraph based ASF on binary images. Experimental results shows thathypergraph based ASF filters have outperformed graph based ASF.
arxiv-1507-07147 | True Online Emphatic TD($λ$): Quick Reference and Implementation Guide |  http://arxiv.org/abs/1507.07147  | author:Richard S. Sutton category:cs.LG published:2015-07-25 summary:This document is a guide to the implementation of true online emphaticTD($\lambda$), a model-free temporal-difference algorithm for learning to makelong-term predictions which combines the emphasis idea (Sutton, Mahmood & White2015) and the true-online idea (van Seijen & Sutton 2014). The setting usedhere includes linear function approximation, the possibility of off-policytraining, and all the generality of general value functions, as well as theemphasis algorithm's notion of "interest".
arxiv-1507-07146 | A Framework of Sparse Online Learning and Its Applications |  http://arxiv.org/abs/1507.07146  | author:Dayong Wang, Pengcheng Wu, Peilin Zhao, Steven C. H. Hoi category:cs.LG published:2015-07-25 summary:The amount of data in our society has been exploding in the era of big datatoday. In this paper, we address several open challenges of big data streamclassification, including high volume, high velocity, high dimensionality, highsparsity, and high class-imbalance. Many existing studies in data miningliterature solve data stream classification tasks in a batch learning setting,which suffers from poor efficiency and scalability when dealing with big data.To overcome the limitations, this paper investigates an online learningframework for big data stream classification tasks. Unlike some existing onlinedata stream classification techniques that are often based on first-orderonline learning, we propose a framework of Sparse Online Classification (SOC)for data stream classification, which includes some state-of-the-artfirst-order sparse online learning algorithms as special cases and allows us toderive a new effective second-order online learning algorithm for data streamclassification. In addition, we also propose a new cost-sensitive sparse onlinelearning algorithm by extending the framework with application to tackle onlineanomaly detection tasks where class distribution of data could be veryimbalanced. We also analyze the theoretical bounds of the proposed method, andfinally conduct an extensive set of experiments, in which encouraging resultsvalidate the efficacy of the proposed algorithms in comparison to a family ofstate-of-the-art techniques on a variety of data stream classification tasks.
arxiv-1507-07870 | Detect & Describe: Deep learning of bank stress in the news |  http://arxiv.org/abs/1507.07870  | author:Samuel Rönnqvist, Peter Sarlin category:q-fin.CP cs.AI cs.LG cs.NE q-fin.RM published:2015-07-25 summary:News is a pertinent source of information on financial risks and stressfactors, which nevertheless is challenging to harness due to the sparse andunstructured nature of natural text. We propose an approach based ondistributional semantics and deep learning with neural networks to model andlink text to a scarce set of bank distress events. Through unsupervisedtraining, we learn semantic vector representations of news articles aspredictors of distress events. The predictive model that we learn can signalcoinciding stress with an aggregated index at bank or European level, whilecrucially allowing for automatic extraction of text descriptions of the events,based on passages with high stress levels. The method offers insight thatmodels based on other types of data cannot provide, while offering a generalmeans for interpreting this type of semantic-predictive model. We model bankdistress with data on 243 events and 6.6M news articles for 101 large Europeanbanks.
arxiv-1507-07077 | Making sense of randomness: an approach for fast recovery of compressively sensed signals |  http://arxiv.org/abs/1507.07077  | author:V. Abrol, P. Sharma, A. K Sao category:cs.IT cs.CV math.IT published:2015-07-25 summary:In compressed sensing (CS) framework, a signal is sampled below Nyquist rate,and the acquired compressed samples are generally random in nature. However,for efficient estimation of the actual signal, the sensing matrix must preservethe relative distances among the acquired compressed samples. Provided thiscondition is fulfilled, we show that CS samples will preserve the envelope ofthe actual signal even at different compression ratios. Exploiting thisenvelope preserving property of CS samples, we propose a new fast dictionarylearning (DL) algorithm which is able to extract prototype signals fromcompressive samples for efficient sparse representation and recovery ofsignals. These prototype signals are orthogonal intrinsic mode functions (IMFs)extracted using empirical mode decomposition (EMD), which is one of the popularmethods to capture the envelope of a signal. The extracted IMFs are used tobuild the dictionary without even comprehending the original signal or thesensing matrix. Moreover, one can build the dictionary on-line as new CSsamples are available. In particularly, to recover first $L$ signals($\in\mathbb{R}^n$) at the decoder, one can build the dictionary in just$\mathcal{O}(nL\log n)$ operations, that is far less as compared to existingapproaches. The efficiency of the proposed approach is demonstratedexperimentally for recovery of speech signals.
arxiv-1602-07335 | Robust Detection of Intensity Variant Clones in Forged and JPEG Compressed Images |  http://arxiv.org/abs/1602.07335  | author:Minati Mishra, M. C. Adhikary category:cs.CV published:2015-07-25 summary:Digitization of images has made image editing easier. Ease of image editingtempted users and professionals to manipulate digital images leading to digitalimage forgeries. Today digital image forgery has posed a great threat to theauthenticity of the popular digital media, the digital images. A lot ofresearch is going on worldwide to detect image forgery and to separate theforged images from their authentic counterparts. This paper provides a novelintensity invariant detection model (IIDM) for detection of intensity variantclones that is robust against JPEG compression, noise attacks and blurring.
arxiv-1507-07096 | Thinning Algorithm Using Hypergraph Based Morphological Operators |  http://arxiv.org/abs/1507.07096  | author:R. P. Prakash, Keerthana S. Prakash, V. P. Binu category:cs.CV published:2015-07-25 summary:The object recognition is a complex problem in the image processing.Mathematical morphology is Shape oriented operations, that simplify image data,preserving their essential shape characteristics and eliminating irrelevancies.This paper briefly describes morphological operators using hypergraph and itsapplications for thinning algorithms. The morphological operators usinghypergraph method is used to preventing errors and irregularities in skeleton,and is an important step recognizing line objects. The morphological operatorsusing hypergraph such as dilation, erosion, opening, closing is a novelapproach in image processing and it act as a filter remove the noise and errorsin the images.
arxiv-1507-06977 | String and Membrane Gaussian Processes |  http://arxiv.org/abs/1507.06977  | author:Yves-Laurent Kom Samo, Stephen Roberts category:stat.ML 60G15 published:2015-07-24 summary:In this paper we introduce a novel framework for making exact nonparametricBayesian inference on latent functions, that is particularly suitable for BigData tasks. Firstly, we introduce a class of stochastic processes we refer toas string Gaussian processes (string GPs), which are not to be mistaken forGaussian processes operating on text. We construct string GPs so that theirfinite-dimensional marginals exhibit suitable local conditional independencestructures, which allow for scalable, distributed, and flexible nonparametricBayesian inference, without resorting to approximations, and while ensuringsome mild global regularity constraints. Furthermore, string GP priorsnaturally cope with heterogeneous input data, and the gradient of the learnedlatent function is readily available for explanatory analysis. Secondly, weprovide some theoretical results relating our approach to the standard GPparadigm. In particular, we prove that some string GPs are Gaussian processes,which provides a complementary global perspective on our framework. Finally, wederive a scalable and distributed MCMC scheme for supervised learning tasksunder string GP priors. The proposed MCMC scheme has computational timecomplexity $\mathcal{O}(N)$ and memory requirement $\mathcal{O}(dN)$, where $N$is the data size and $d$ the dimension of the input space. We illustrate theefficacy of the proposed approach on several synthetic and real-world datasets,including a dataset with $6$ millions input points and $8$ attributes.
arxiv-1507-06970 | Perturbed Iterate Analysis for Asynchronous Stochastic Optimization |  http://arxiv.org/abs/1507.06970  | author:Horia Mania, Xinghao Pan, Dimitris Papailiopoulos, Benjamin Recht, Kannan Ramchandran, Michael I. Jordan category:stat.ML cs.DC cs.DS cs.LG math.OC published:2015-07-24 summary:We introduce and analyze stochastic optimization methods where the input toeach gradient update is perturbed by bounded noise. We show that this frameworkforms the basis of a unified approach to analyze asynchronous implementationsof stochastic optimization algorithms.In this framework, asynchronousstochastic optimization algorithms can be thought of as serial methodsoperating on noisy inputs. Using our perturbed iterate framework, we providenew analyses of the Hogwild! algorithm and asynchronous stochastic coordinatedescent, that are simpler than earlier analyses, remove many assumptions ofprevious models, and in some cases yield improved upper bounds on theconvergence rates. We proceed to apply our framework to develop and analyzeKroMagnon: a novel, parallel, sparse stochastic variance-reduced gradient(SVRG) algorithm. We demonstrate experimentally on a 16-core machine that thesparse and parallel version of SVRG is in some cases more than four orders ofmagnitude faster than the standard SVRG algorithm.
arxiv-1507-06821 | Multimodal Deep Learning for Robust RGB-D Object Recognition |  http://arxiv.org/abs/1507.06821  | author:Andreas Eitel, Jost Tobias Springenberg, Luciano Spinello, Martin Riedmiller, Wolfram Burgard category:cs.CV cs.LG cs.NE cs.RO published:2015-07-24 summary:Robust object recognition is a crucial ingredient of many, if not all,real-world robotics applications. This paper leverages recent progress onConvolutional Neural Networks (CNNs) and proposes a novel RGB-D architecturefor object recognition. Our architecture is composed of two separate CNNprocessing streams - one for each modality - which are consecutively combinedwith a late fusion network. We focus on learning with imperfect sensor data, atypical problem in real-world robotics tasks. For accurate learning, weintroduce a multi-stage training methodology and two crucial ingredients forhandling depth data with CNNs. The first, an effective encoding of depthinformation for CNNs that enables learning without the need for large depthdatasets. The second, a data augmentation scheme for robust learning with depthimages by corrupting them with realistic noise patterns. We presentstate-of-the-art results on the RGB-D object dataset and show recognition inchallenging RGB-D real-world noisy settings.
arxiv-1507-06763 | Differentially Private Analysis of Outliers |  http://arxiv.org/abs/1507.06763  | author:Rina Okada, Kazuto Fukuchi, Kazuya Kakizaki, Jun Sakuma category:stat.ML cs.CR cs.LG published:2015-07-24 summary:This paper investigates differentially private analysis of distance-basedoutliers. The problem of outlier detection is to find a small number ofinstances that are apparently distant from the remaining instances. On theother hand, the objective of differential privacy is to conceal presence (orabsence) of any particular instance. Outlier detection and privacy protectionare thus intrinsically conflicting tasks. In this paper, instead of reportingoutliers detected, we present two types of differentially private queries thathelp to understand behavior of outliers. One is the query to count outliers,which reports the number of outliers that appear in a given subspace. Ourformal analysis on the exact global sensitivity of outlier counts reveals thatregular global sensitivity based method can make the outputs too noisy,particularly when the dimensionality of the given subspace is high. Noting thatthe counts of outliers are typically expected to be relatively small comparedto the number of data, we introduce a mechanism based on the smooth upper boundof the local sensitivity. The other is the query to discovery top-$h$ subspacescontaining a large number of outliers. This task can be naively achieved byissuing count queries to each subspace in turn. However, the variation ofsubspaces can grow exponentially in the data dimensionality. This can causeserious consumption of the privacy budget. For this task, we propose anexponential mechanism with a customized score function for subspace discovery.To the best of our knowledge, this study is the first trial to ensuredifferential privacy for distance-based outlier analysis. We demonstrated ourmethods with synthesized datasets and real datasets. The experimental resultsshow that out method achieve better utility compared to the global sensitivitybased methods.
arxiv-1507-06711 | The SYSU System for the Interspeech 2015 Automatic Speaker Verification Spoofing and Countermeasures Challenge |  http://arxiv.org/abs/1507.06711  | author:Shitao Weng, Shushan Chen, Lei Yu, Xuewei Wu, Weicheng Cai, Zhi Liu, Ming Li category:cs.SD cs.CL published:2015-07-24 summary:Many existing speaker verification systems are reported to be vulnerableagainst different spoofing attacks, for example speaker-adapted speechsynthesis, voice conversion, play back, etc. In order to detect these spoofedspeech signals as a countermeasure, we propose a score level fusion approachwith several different i-vector subsystems. We show that the acoustic levelMel-frequency cepstral coefficients (MFCC) features, the phase level modifiedgroup delay cepstral coefficients (MGDCC) and the phonetic level phonemeposterior probability (PPP) tandem features are effective for thecountermeasure. Furthermore, feature level fusion of these features beforei-vector modeling also enhance the performance. A polynomial kernel supportvector machine is adopted as the supervised classifier. In order to enhance thegeneralizability of the countermeasure, we also adopted the cosine similarityand PLDA scoring as one-class classifications methods. By combining theproposed i-vector subsystems with the OpenSMILE baseline which covers theacoustic and prosodic information further improves the final performance. Theproposed fusion system achieves 0.29% and 3.26% EER on the development and testset of the database provided by the INTERSPEECH 2015 automatic speakerverification spoofing and countermeasures challenge.
arxiv-1507-06838 | Descriptors and regions of interest fusion for gender classification in the wild. Comparison and combination with Convolutional Neural Networks |  http://arxiv.org/abs/1507.06838  | author:M. Castrillón-Santana, J. Lorenzo-Navarro, E. Ramón-Balmaseda category:cs.CV published:2015-07-24 summary:Gender classification (GC) has achieved high accuracy in differentexperimental evaluations based mostly on inner facial details. However, theseresults do not generalize well in unrestricted datasets and particularly incross-database experiments, where the performance drops drastically. In thispaper, we analyze the state-of-the-art GC accuracy on three large datasets:MORPH, LFW and GROUPS. We discuss their respective difficulties and bias,concluding that the most challenging and wildest complexity is present inGROUPS. This dataset covers hard conditions such as low resolution imagery andcluttered background. Firstly, we analyze in depth the performance of differentdescriptors extracted from the face and its local context on this dataset.Selecting the bests and studying their most suitable combination allows us todesign a solution that beats any previously published results for GROUPS withthe Dago's protocol, reaching an accuracy over 94.2%, reducing the gap withother simpler datasets. The chosen solution based on local descriptors is laterevaluated in a cross-database scenario with the three mentioned datasets, andfull dataset 5-fold cross validation. The achieved results are compared with aConvolutional Neural Network approach, achieving rather similar marks. Finally,a solution is proposed combining both focuses, exhibiting greatcomplementarity, boosting GC performance to beat previously published resultsin GC both cross-database, and full in-database evaluations.
arxiv-1507-06738 | Linear Contextual Bandits with Global Constraints and Objective |  http://arxiv.org/abs/1507.06738  | author:Shipra Agrawal, Nikhil R. Devanur category:cs.LG math.OC stat.ML published:2015-07-24 summary:We consider the linear contextual bandit problem with global convexconstraints and a concave objective function. In each round, the outcome ofpulling an arm is a vector, that depends linearly on the context of that arm.The global constraints require the average of these vectors to lie in a certainconvex set. The objective is a concave function of this average vector. Thisproblem turns out to be a common generalization of classic linear contextualbandits (linContextual) [Auer 2003], bandits with concave rewards and convexknapsacks (BwCR) [Agrawal, Devanur 2014], and the online stochastic convexprogramming (OSCP) problem [Agrawal, Devanur 2015]. We present algorithms withnear-optimal regret bounds for this problem. Our bounds compare favorably toresults on the unstructured version of the problem [Agrawal et al. 2015,Badanidiyuru et al. 2014] where the relation between the contexts and theoutcomes could be arbitrary, but the algorithm only competes against a fixedset of policies.
arxiv-1507-06759 | Variational Bayesian strategies for high-dimensional, stochastic design problems |  http://arxiv.org/abs/1507.06759  | author:Phaedon-Stelios Koutsourelakis category:stat.CO math.NA stat.ML published:2015-07-24 summary:This paper is concerned with a lesser-studied problem in the context ofmodel-based, uncertainty quantification (UQ), that ofoptimization/design/control under uncertainty. The solution of such problems ishindered not only by the usual difficulties encountered in UQ tasks (e.g. thehigh computational cost of each forward simulation, the large number of randomvariables) but also by the need to solve a nonlinear optimization probleminvolving large numbers of design variables and potentially constraints. Wepropose a framework that is suitable for a large class of such problems and isbased on the idea of recasting them as probabilistic inference tasks. To thatend, we propose a Variational Bayesian (VB) formulation and an iterativeVB-Expectation-Maximization scheme that is also capable of identifying alow-dimensional set of directions in the design space, along which, theobjective exhibits the largest sensitivity. We demonstrate the validity of the proposed approach in the context of twonumerical examples involving $\mathcal{O}(10^3)$ random and design variables.In all cases considered the cost of the computations in terms of calls to theforward model was of the order $\mathcal{O}(10^2)$. The accuracy of theapproximations provided is assessed by appropriate information-theoreticmetrics.
arxiv-1507-06802 | Implicitly Constrained Semi-Supervised Least Squares Classification |  http://arxiv.org/abs/1507.06802  | author:Jesse H. Krijthe, Marco Loog category:stat.ML cs.LG published:2015-07-24 summary:We introduce a novel semi-supervised version of the least squares classifier.This implicitly constrained least squares (ICLS) classifier minimizes thesquared loss on the labeled data among the set of parameters implied by allpossible labelings of the unlabeled data. Unlike other discriminativesemi-supervised methods, our approach does not introduce explicit additionalassumptions into the objective function, but leverages implicit assumptionsalready present in the choice of the supervised least squares classifier. Weshow this approach can be formulated as a quadratic programming problem and itssolution can be found using a simple gradient descent procedure. We prove that,in a certain way, our method never leads to performance worse than thesupervised classifier. Experimental results corroborate this theoretical resultin the multidimensional case on benchmark datasets, also in terms of the errorrate.
arxiv-1507-06803 | A Neighbourhood-Based Stopping Criterion for Contrastive Divergence Learning |  http://arxiv.org/abs/1507.06803  | author:E. Romero, F. Mazzanti, J. Delgado category:cs.NE cs.LG published:2015-07-24 summary:Restricted Boltzmann Machines (RBMs) are general unsupervised learningdevices to ascertain generative models of data distributions. RBMs are oftentrained using the Contrastive Divergence learning algorithm (CD), anapproximation to the gradient of the data log-likelihood. A simplereconstruction error is often used as a stopping criterion for CD, althoughseveral authors\cite{schulz-et-al-Convergence-Contrastive-Divergence-2010-NIPSw,fischer-igel-Divergence-Contrastive-Divergence-2010-ICANN} have raised doubtsconcerning the feasibility of this procedure. In many cases the evolution curveof the reconstruction error is monotonic while the log-likelihood is not, thusindicating that the former is not a good estimator of the optimal stoppingpoint for learning. However, not many alternatives to the reconstruction errorhave been discussed in the literature. In this manuscript we investigate simplealternatives to the reconstruction error, based on the inclusion of informationcontained in neighboring states to the training set, as a stopping criterionfor CD learning.
arxiv-1507-06829 | The Polylingual Labeled Topic Model |  http://arxiv.org/abs/1507.06829  | author:Lisa Posch, Arnim Bleier, Philipp Schaer, Markus Strohmaier category:cs.CL cs.IR cs.LG G.3; I.2.7 published:2015-07-24 summary:In this paper, we present the Polylingual Labeled Topic Model, a model whichcombines the characteristics of the existing Polylingual Topic Model andLabeled LDA. The model accounts for multiple languages with separate topicdistributions for each language while restricting the permitted topics of adocument to a set of predefined labels. We explore the properties of the modelin a two-language setting on a dataset from the social science domain. Ourexperiments show that our model outperforms LDA and Labeled LDA in terms oftheir held-out perplexity and that it produces semantically coherent topicswhich are well interpretable by human subjects.
arxiv-1507-06837 | YARBUS : Yet Another Rule Based belief Update System |  http://arxiv.org/abs/1507.06837  | author:Jeremy Fix, Herve Frezza-buet category:cs.CL cs.AI published:2015-07-24 summary:We introduce a new rule based system for belief tracking in dialog systems.Despite the simplicity of the rules being considered, the proposed belieftracker ranks favourably compared to the previous submissions on the second andthird Dialog State Tracking challenges. The results of this simple trackerallows to reconsider the performances of previous submissions using moreelaborate techniques.
arxiv-1507-06877 | Multi-objective analysis of computational models |  http://arxiv.org/abs/1507.06877  | author:Stéphane Doncieux, Jean Liénard, Benoît Girard, Mohamed Hamdaoui, Joël Chaskalovic category:cs.NE published:2015-07-24 summary:Computational models are of increasing complexity and their behavior may inparticular emerge from the interaction of different parts. Studying such modelsbecomes then more and more difficult and there is a need for methods and toolssupporting this process. Multi-objective evolutionary algorithms generate a setof trade-off solutions instead of a single optimal solution. The availabilityof a set of solutions that have the specificity to be optimal relative tocarefully chosen objectives allows to perform data mining in order to betterunderstand model features and regularities. We review the corresponding work,propose a unifying framework, and highlight its potential use. Typicalquestions that such a methodology allows to address are the following: what arethe most critical parameters of the model? What are the relations between theparameters and the objectives? What are the typical behaviors of the model? Twoexamples are provided to illustrate the capabilities of the methodology. Thefeatures of a flapping-wing robot are thus evaluated to find out itsspeed-energy relation, together with the criticality of its parameters. Aneurocomputational model of the Basal Ganglia brain nuclei is then consideredand its most salient features according to this methodology are presented anddiscussed.
arxiv-1507-06923 | A Reinforcement Learning Approach to Online Learning of Decision Trees |  http://arxiv.org/abs/1507.06923  | author:Abhinav Garlapati, Aditi Raghunathan, Vaishnavh Nagarajan, Balaraman Ravindran category:cs.LG published:2015-07-24 summary:Online decision tree learning algorithms typically examine all features of anew data point to update model parameters. We propose a novel alternative,Reinforcement Learning- based Decision Trees (RLDT), that uses ReinforcementLearning (RL) to actively examine a minimal number of features of a data pointto classify it with high accuracy. Furthermore, RLDT optimizes a long termreturn, providing a better alternative to the traditional myopic greedyapproach to growing decision trees. We demonstrate that this approach performsas well as batch learning algorithms and other online decision tree learningalgorithms, while making significantly fewer queries about the features of thedata points. We also show that RLDT can effectively handle concept drift.
arxiv-1507-06947 | Fast and Accurate Recurrent Neural Network Acoustic Models for Speech Recognition |  http://arxiv.org/abs/1507.06947  | author:Haşim Sak, Andrew Senior, Kanishka Rao, Françoise Beaufays category:cs.CL cs.LG cs.NE stat.ML published:2015-07-24 summary:We have recently shown that deep Long Short-Term Memory (LSTM) recurrentneural networks (RNNs) outperform feed forward deep neural networks (DNNs) asacoustic models for speech recognition. More recently, we have shown that theperformance of sequence trained context dependent (CD) hidden Markov model(HMM) acoustic models using such LSTM RNNs can be equaled by sequence trainedphone models initialized with connectionist temporal classification (CTC). Inthis paper, we present techniques that further improve performance of LSTM RNNacoustic models for large vocabulary speech recognition. We show that framestacking and reduced frame rate lead to more accurate models and fasterdecoding. CD phone modeling leads to further improvements. We also presentinitial results for LSTM RNN models outputting words directly.
arxiv-1507-06527 | Deep Recurrent Q-Learning for Partially Observable MDPs |  http://arxiv.org/abs/1507.06527  | author:Matthew Hausknecht, Peter Stone category:cs.LG published:2015-07-23 summary:Deep Reinforcement Learning has yielded proficient controllers for complextasks. However, these controllers have limited memory and rely on being able toperceive the complete game screen at each decision point. To address theseshortcomings, this article investigates the effects of adding recurrency to aDeep Q-Network (DQN) by replacing the first post-convolutional fully-connectedlayer with a recurrent LSTM. The resulting \textit{Deep Recurrent Q-Network}(DRQN), although capable of seeing only a single frame at each timestep,successfully integrates information through time and replicates DQN'sperformance on standard Atari games and partially observed equivalentsfeaturing flickering game screens. Additionally, when trained with partialobservations and evaluated with incrementally more complete observations,DRQN's performance scales as a function of observability. Conversely, whentrained with full observations and evaluated with partial observations, DRQN'sperformance degrades less than DQN's. Thus, given the same length of history,recurrency is a viable alternative to stacking a history of frames in the DQN'sinput layer and while recurrency confers no systematic advantage when learningto play the game, the recurrent net can better adapt at evaluation time if thequality of observations changes.
arxiv-1507-06504 | Active skeleton for bacteria modeling |  http://arxiv.org/abs/1507.06504  | author:Jean-Pascal Jacob, Mariella Dimiccoli, Lionel Moisan category:cs.CV published:2015-07-23 summary:The investigation of spatio-temporal dynamics of bacterial cells and theirmolecular components requires automated image analysis tools to track cellshape properties and molecular component locations inside the cells. In thestudy of bacteria aging, the molecular components of interest are proteinaggregates accumulated near bacteria boundaries. This particular location makesvery ambiguous the correspondence between aggregates and cells, since computingaccurately bacteria boundaries in phase-contrast time-lapse imaging is achallenging task. This paper proposes an active skeleton formulation forbacteria modeling which provides several advantages: an easy computation ofshape properties (perimeter, length, thickness, orientation), an improvedboundary accuracy in noisy images, and a natural bacteria-centered coordinatesystem that permits the intrinsic location of molecular components inside thecell. Starting from an initial skeleton estimate, the medial axis of thebacterium is obtained by minimizing an energy function which incorporatesbacteria shape constraints. Experimental results on biological images andcomparative evaluation of the performances validate the proposed approach formodeling cigar-shaped bacteria like Escherichia coli. The Image-J plugin of theproposed method can be found online at http://fluobactracker.inrialpes.fr.
arxiv-1507-06617 | Fourier descriptors based on the structure of the human primary visual cortex with applications to object recognition |  http://arxiv.org/abs/1507.06617  | author:Amine Bohi, Dario Prandi, Vincente Guis, Frédéric Bouchara, Jean-Paul Gauthier category:cs.CV published:2015-07-23 summary:In this paper we propose a supervised object recognition method using newglobal features and inspired by the model of the human primary visual cortex V1as the semidiscrete roto-translation group $SE(2,N) = \mathbb R^2\times \mathbbZ_N$. The proposed technique is based on generalized Fourier descriptors on thelatter group, which are invariant to natural geometric transformations(rotations, translations). These descriptors are then used to feed an SVMclassifier. We have tested our method against the COIL-100 image database andthe ORL face database, and compared it with other techniques based ontraditional descriptors, global and local. The obtained results have shown thatour approach looks extremely efficient and stable to noise, in presence ofwhich it outperforms the other techniques analyzed in the paper.
arxiv-1507-06370 | Sum-of-Squares Lower Bounds for Sparse PCA |  http://arxiv.org/abs/1507.06370  | author:Tengyu Ma, Avi Wigderson category:cs.LG cs.CC math.ST stat.CO stat.ML stat.TH published:2015-07-23 summary:This paper establishes a statistical versus computational trade-off forsolving a basic high-dimensional machine learning problem via a basic convexrelaxation method. Specifically, we consider the {\em Sparse PrincipalComponent Analysis} (Sparse PCA) problem, and the family of {\emSum-of-Squares} (SoS, aka Lasserre/Parillo) convex relaxations. It was wellknown that in large dimension $p$, a planted $k$-sparse unit vector can be {\emin principle} detected using only $n \approx k\log p$ (Gaussian or Bernoulli)samples, but all {\em efficient} (polynomial time) algorithms known require $n\approx k^2$ samples. It was also known that this quadratic gap cannot beimproved by the the most basic {\em semi-definite} (SDP, aka spectral)relaxation, equivalent to a degree-2 SoS algorithms. Here we prove that alsodegree-4 SoS algorithms cannot improve this quadratic gap. This average-caselower bound adds to the small collection of hardness results in machinelearning for this powerful family of convex relaxation algorithms. Moreover,our design of moments (or "pseudo-expectations") for this lower bound is quitedifferent than previous lower bounds. Establishing lower bounds for higherdegree SoS algorithms for remains a challenging problem.
arxiv-1507-06682 | Supervised Collective Classification for Crowdsourcing |  http://arxiv.org/abs/1507.06682  | author:Pin-Yu Chen, Chia-Wei Lien, Fu-Jen Chu, Pai-Shun Ting, Shin-Ming Cheng category:cs.SI cs.LG stat.ML published:2015-07-23 summary:Crowdsourcing utilizes the wisdom of crowds for collective classification viainformation (e.g., labels of an item) provided by labelers. Currentcrowdsourcing algorithms are mainly unsupervised methods that are unaware ofthe quality of crowdsourced data. In this paper, we propose a supervisedcollective classification algorithm that aims to identify reliable labelersfrom the training data (e.g., items with known labels). The reliability (i.e.,weighting factor) of each labeler is determined via a saddle point algorithm.The results on several crowdsourced data show that supervised methods canachieve better classification accuracy than unsupervised methods, and ourproposed method outperforms other algorithms.
arxiv-1507-06550 | Human Pose Estimation with Iterative Error Feedback |  http://arxiv.org/abs/1507.06550  | author:Joao Carreira, Pulkit Agrawal, Katerina Fragkiadaki, Jitendra Malik category:cs.CV cs.LG cs.NE published:2015-07-23 summary:Hierarchical feature extractors such as Convolutional Networks (ConvNets)have achieved impressive performance on a variety of classification tasks usingpurely feedforward processing. Feedforward architectures can learn richrepresentations of the input space but do not explicitly model dependencies inthe output spaces, that are quite structured for tasks such as articulatedhuman pose estimation or object segmentation. Here we propose a framework thatexpands the expressive power of hierarchical feature extractors to encompassboth input and output spaces, by introducing top-down feedback. Instead ofdirectly predicting the outputs in one go, we use a self-correcting model thatprogressively changes an initial solution by feeding back error predictions, ina process we call Iterative Error Feedback (IEF). IEF shows excellentperformance on the task of articulated pose estimation in the challenging MPIIand LSP benchmarks, matching the state-of-the-art without requiring groundtruth scale annotation.
arxiv-1507-06594 | Neural NILM: Deep Neural Networks Applied to Energy Disaggregation |  http://arxiv.org/abs/1507.06594  | author:Jack Kelly, William Knottenbelt category:cs.NE I.2.6; I.5.2 published:2015-07-23 summary:Energy disaggregation estimates appliance-by-appliance electricityconsumption from a single meter that measures the whole home's electricitydemand. Recently, deep neural networks have driven remarkable improvements inclassification performance in neighbouring machine learning fields such asimage classification and automatic speech recognition. In this paper, we adaptthree deep neural network architectures to energy disaggregation: 1) a form ofrecurrent neural network called `long short-term memory' (LSTM); 2) denoisingautoencoders; and 3) a network which regresses the start time, end time andaverage power demand of each appliance activation. We use seven metrics to testthe performance of these algorithms on real aggregate power data from fiveappliances. Tests are performed against a house not seen during training andagainst houses seen during training. We find that all three neural nets achievebetter F1 scores (averaged over all five appliances) than either combinatorialoptimisation or factorial hidden Markov models and that our neural netalgorithms generalise well to an unseen house.
arxiv-1507-06683 | Clustering of Modal Valued Symbolic Data |  http://arxiv.org/abs/1507.06683  | author:Vladimir Batagelj, Nataša Kejžar, Simona Korenjak-Černe category:stat.ML published:2015-07-23 summary:Symbolic Data Analysis is based on special descriptions of data - symbolicobjects (SO). Such descriptions preserve more detailed information about unitsand their clusters than the usual representations with mean values. A specialkind of symbolic object is a representation with frequency or probabilitydistributions (modal values). This representation enables us to consider in theclustering process the variables of all measurement types at the same time. Inthe paper a clustering criterion function for SOs is proposed such that therepresentative of each cluster is again composed of distributions of variables'values over the cluster. The corresponding leaders clustering method is basedon this result. It is also shown that for the corresponding agglomerativehierarchical method a generalized Ward's formula holds. Both methods arecompatible - they are solving the same clustering optimization problem. Theleaders method efficiently solves clustering problems with large number ofunits; while the agglomerative method can be applied alone on the smaller dataset, or it could be applied on leaders, obtained with compatiblenonhierarchical clustering method. Such a combination of two compatible methodsenables us to decide upon the right number of clusters on the basis of thecorresponding dendrogram. The proposed methods were applied on different datasets. In the paper, some results of clustering of ESS data are presented.
arxiv-1507-06397 | Multi-Target Tracking with Time-Varying Clutter Rate and Detection Profile: Application to Time-lapse Cell Microscopy Sequences |  http://arxiv.org/abs/1507.06397  | author:Seyed Hamid Rezatofighi, Stephen Gould, Ba Tuong Vo, Ba-Ngu Vo, Katarina Mele, Richard Hartley category:cs.CV published:2015-07-23 summary:Quantitative analysis of the dynamics of tiny cellular and sub-cellularstructures, known as particles, in time-lapse cell microscopy sequencesrequires the development of a reliable multi-target tracking method capable oftracking numerous similar targets in the presence of high levels of noise, hightarget density, complex motion patterns and intricate interactions. In thispaper, we propose a framework for tracking these structures based on the randomfinite set Bayesian filtering framework. We focus on challenging biologicalapplications where image characteristics such as noise and background intensitychange during the acquisition process. Under these conditions, detectionmethods usually fail to detect all particles and are often followed by misseddetections and many spurious measurements with unknown and time-varying rates.To deal with this, we propose a bootstrap filter composed of an estimator and atracker. The estimator adaptively estimates the required meta parameters forthe tracker such as clutter rate and the detection probability of the targets,while the tracker estimates the state of the targets. Our results show that theproposed approach can outperform state-of-the-art particle trackers on bothsynthetic and real data in this regime.
arxiv-1507-06615 | Optimal Learning Rates for Localized SVMs |  http://arxiv.org/abs/1507.06615  | author:Mona Eberts, Ingo Steinwart category:stat.ML published:2015-07-23 summary:One of the limiting factors of using support vector machines (SVMs) in largescale applications are their super-linear computational requirements in termsof the number of training samples. To address this issue, several approachesthat train SVMs on many small chunks of large data sets separately have beenproposed in the literature. So far, however, almost all these approaches haveonly been empirically investigated. In addition, their motivation was alwaysbased on computational requirements. In this work, we consider a localized SVMapproach based upon a partition of the input space. For this local SVM, wederive a general oracle inequality. Then we apply this oracle inequality toleast squares regression using Gaussian kernels and deduce local learning ratesthat are essentially minimax optimal under some standard smoothness assumptionson the regression function. This gives the first motivation for using localSVMs that is not based on computational requirements but on theoreticalpredictions on the generalization performance. We further introduce adata-dependent parameter selection method for our local SVM approach and showthat this method achieves the same learning rates as before. Finally, wepresent some larger scale experiments for our localized SVM showing that itachieves essentially the same test performance as a global SVM for a fractionof the computational requirements. In addition, it turns out that thecomputational requirements for the local SVMs are similar to those of a vanillarandom chunk approach, while the achieved test errors are significantly better.
arxiv-1507-06580 | Multi-scale exploration of convex functions and bandit convex optimization |  http://arxiv.org/abs/1507.06580  | author:Sébastien Bubeck, Ronen Eldan category:math.MG cs.LG math.OC math.PR stat.ML published:2015-07-23 summary:We construct a new map from a convex function to a distribution on itsdomain, with the property that this distribution is a multi-scale explorationof the function. We use this map to solve a decade-old open problem inadversarial bandit convex optimization by showing that the minimax regret forthis problem is $\tilde{O}(\mathrm{poly}(n) \sqrt{T})$, where $n$ is thedimension and $T$ the number of rounds. This bound is obtained by studying thedual Bayesian maximin regret via the information ratio analysis of Russo andVan Roy, and then using the multi-scale exploration to solve the Bayesianproblem.
arxiv-1507-06535 | Manitest: Are classifiers really invariant? |  http://arxiv.org/abs/1507.06535  | author:Alhussein Fawzi, Pascal Frossard category:cs.CV cs.LG stat.ML published:2015-07-23 summary:Invariance to geometric transformations is a highly desirable property ofautomatic classifiers in many image recognition tasks. Nevertheless, it isunclear to which extent state-of-the-art classifiers are invariant to basictransformations such as rotations and translations. This is mainly due to thelack of general methods that properly measure such an invariance. In thispaper, we propose a rigorous and systematic approach for quantifying theinvariance to geometric transformations of any classifier. Our key idea is tocast the problem of assessing a classifier's invariance as the computation ofgeodesics along the manifold of transformed images. We propose the Manitestmethod, built on the efficient Fast Marching algorithm to compute theinvariance of classifiers. Our new method quantifies in particular theimportance of data augmentation for learning invariance from data, and theincreased invariance of convolutional neural networks with depth. We foreseethat the proposed generic tool for measuring invariance to a large class ofgeometric transformations and arbitrary classifiers will have many applicationsfor evaluating and comparing classifiers based on their invariance, and helpimproving the invariance of existing classifiers.
arxiv-1507-06452 | Dynamic Matrix Factorization with Priors on Unknown Values |  http://arxiv.org/abs/1507.06452  | author:Robin Devooght, Nicolas Kourtellis, Amin Mantrach category:stat.ML cs.IR cs.LG published:2015-07-23 summary:Advanced and effective collaborative filtering methods based on explicitfeedback assume that unknown ratings do not follow the same model as theobserved ones (\emph{not missing at random}). In this work, we build on thisassumption, and introduce a novel dynamic matrix factorization framework thatallows to set an explicit prior on unknown values. When new ratings, users, oritems enter the system, we can update the factorization in time independent ofthe size of data (number of users, items and ratings). Hence, we can quicklyrecommend items even to very recent users. We test our methods on three largedatasets, including two very sparse ones, in static and dynamic conditions. Ineach case, we outrank state-of-the-art matrix factorization methods that do notuse a prior on unknown ratings.
arxiv-1507-06411 | Arbitrariness of peer review: A Bayesian analysis of the NIPS experiment |  http://arxiv.org/abs/1507.06411  | author:Olivier Francois category:stat.OT cs.DL stat.ML published:2015-07-23 summary:The principle of peer review is central to the evaluation of research, byensuring that only high-quality items are funded or published. But peer reviewhas also received criticism, as the selection of reviewers may introduce biasesin the system. In 2014, the organizers of the ``Neural Information ProcessingSystems\rq\rq{} conference conducted an experiment in which $10\%$ of submittedmanuscripts (166 items) went through the review process twice. Arbitrarinesswas measured as the conditional probability for an accepted submission to getrejected if examined by the second committee. This number was equal to $60\%$,for a total acceptance rate equal to $22.5\%$. Here we present a Bayesiananalysis of those two numbers, by introducing a hidden parameter which measuresthe probability that a submission meets basic quality criteria. The standardquality criteria usually include novelty, clarity, reproducibility, correctnessand no form of misconduct, and are met by a large proportions of submitteditems. The Bayesian estimate for the hidden parameter was equal to $56\%$($95\%$CI: $ I = (0.34, 0.83)$), and had a clear interpretation. The resultsuggested the total acceptance rate should be increased in order to decreasearbitrariness estimates in future review processes.
arxiv-1507-06429 | Deep Fishing: Gradient Features from Deep Nets |  http://arxiv.org/abs/1507.06429  | author:Albert Gordo, Adrien Gaidon, Florent Perronnin category:cs.CV published:2015-07-23 summary:Convolutional Networks (ConvNets) have recently improved image recognitionperformance thanks to end-to-end learning of deep feed-forward models from rawpixels. Deep learning is a marked departure from the previous state of the art,the Fisher Vector (FV), which relied on gradient-based encoding of localhand-crafted features. In this paper, we discuss a novel connection betweenthese two approaches. First, we show that one can derive gradientrepresentations from ConvNets in a similar fashion to the FV. Second, we showthat this gradient representation actually corresponds to a structured matrixthat allows for efficient similarity computation. We experimentally study thebenefits of transferring this representation over the outputs of ConvNetlayers, and find consistent improvements on the Pascal VOC 2007 and 2012datasets.
arxiv-1507-06350 | Admissibility of a posterior predictive decision rule |  http://arxiv.org/abs/1507.06350  | author:Giri Gopalan category:stat.ML published:2015-07-22 summary:Recent decades have seen an interest in prediction problems for whichBayesian methodology has been extremely useful. Sampling from or approximatingthe posterior predictive distribution in a Bayesian model allows one to makeinference about potentially observable random quantities given observed data.The purpose of this note is to use statistical decision theory as a basis tojustify the use of a posterior predictive distribution for making a pointprediction.
arxiv-1507-06228 | Training Very Deep Networks |  http://arxiv.org/abs/1507.06228  | author:Rupesh Kumar Srivastava, Klaus Greff, Jürgen Schmidhuber category:cs.LG cs.NE 68T01 I.2.6; G.1.6 published:2015-07-22 summary:Theoretical and empirical evidence indicates that the depth of neuralnetworks is crucial for their success. However, training becomes more difficultas depth increases, and training of very deep networks remains an open problem.Here we introduce a new architecture designed to overcome this. Our so-calledhighway networks allow unimpeded information flow across many layers oninformation highways. They are inspired by Long Short-Term Memory recurrentnetworks and use adaptive gating units to regulate the information flow. Evenwith hundreds of layers, highway networks can be trained directly throughsimple gradient descent. This enables the study of extremely deep and efficientarchitectures.
arxiv-1507-06145 | Dynamic Filtering of Time-Varying Sparse Signals via l1 Minimization |  http://arxiv.org/abs/1507.06145  | author:Adam Charles, Aurele Balavoine, Christopher Rozell category:math.ST stat.ML stat.TH published:2015-07-22 summary:Despite the importance of sparsity signal models and the increasingprevalence of high-dimensional streaming data, there are relatively fewalgorithms for dynamic filtering of time-varying sparse signals. Of theexisting algorithms, fewer still provide strong performance guarantees. Thispaper examines two algorithms for dynamic filtering of sparse signals that arebased on efficient l1 optimization methods. We first present an analysis forone simple algorithm (BPDN-DF) that works well when the system dynamics areknown exactly. We then introduce a novel second algorithm (RWL1-DF) that ismore computationally complex than BPDN-DF but performs better in practice,especially in the case where the system dynamics model is inaccurate.Robustness to model inaccuracy is achieved by using a hierarchicalprobabilistic data model and propagating higher-order statistics from theprevious estimate (akin to Kalman filtering) in the sparse inference process.We demonstrate the properties of these algorithms on both simulated data aswell as natural video sequences. Taken together, the algorithms presented inthis paper represent the first strong performance analysis of dynamic filteringalgorithms for time-varying sparse signals as well as state-of-the-artperformance in this emerging application.
arxiv-1507-06120 | Towards Storytelling from Visual Lifelogging: An Overview |  http://arxiv.org/abs/1507.06120  | author:Marc Bolaños, Mariella Dimiccoli, Petia Radeva category:cs.CV published:2015-07-22 summary:Visual lifelogging consists of acquiring images that capture the dailyexperiences of the user by wearing a camera over a long period of time. Thepictures taken offer considerable potential for knowledge mining concerning howpeople live their lives, hence, they open up new opportunities for manypotential applications in fields including healthcare, security, leisure andthe quantified self. However, automatically building a story from a hugecollection of unstructured egocentric data presents major challenges. Thispaper provides a thorough review of advances made so far in egocentric dataanalysis, and in view of the current state of the art, indicates new lines ofresearch to move us towards storytelling from visual lifelogging.
arxiv-1507-06217 | Persistent Images: A Stable Vector Representation of Persistent Homology |  http://arxiv.org/abs/1507.06217  | author:Henry Adams, Sofya Chepushtanova, Tegan Emerson, Eric Hanson, Michael Kirby, Francis Motta, Rachel Neville, Chris Peterson, Patrick Shipman, Lori Ziegelmeier category:cs.CG math.AT stat.ML F.2.2; I.5.2 published:2015-07-22 summary:Many data sets can be viewed as a noisy sampling of an underlying topologicalspace. A suite of tools in topological data analysis allows one to exploit thisstructure for the purpose of knowledge discovery. One such tool is persistenthomology which provides a multiscale description of the homological featureswithin a data set. A useful representation of this homological information is apersistence diagram (PD). The space of PDs can be given a metric structureallowing a given diagram to be used as a statistic for the purpose ofcomparison against other diagrams. We convert a PD to a persistence image (PI)and prove stability with respect to small perturbations in the inputs. The PIis a vector representation allowing the application of vector-based machinelearning tools, such as linear and sparse support vector machines. These toolshelp to identify discriminatory features which can have a topologicalinterpretation. The PIs and PDs derived from randomly sampled topologicalspaces are compared by applying the K-medoids clustering algorithm. To furtherillustrate the PI technique, linear and sparse support vector machines areimplemented on this data set and classification is performed on additional dataarising from a discrete dynamical system called the linked twist map.
arxiv-1507-06020 | Practical Selection of SVM Supervised Parameters with Different Feature Representations for Vowel Recognition |  http://arxiv.org/abs/1507.06020  | author:Rimah Amami, Dorra Ben Ayed, Noureddine Ellouze category:cs.CL cs.LG published:2015-07-22 summary:It is known that the classification performance of Support Vector Machine(SVM) can be conveniently affected by the different parameters of the kerneltricks and the regularization parameter, C. Thus, in this article, we propose astudy in order to find the suitable kernel with which SVM may achieve goodgeneralization performance as well as the parameters to use. We need to analyzethe behavior of the SVM classifier when these parameters take very small orvery large values. The study is conducted for a multi-class vowel recognitionusing the TIMIT corpus. Furthermore, for the experiments, we used differentfeature representations such as MFCC and PLP. Finally, a comparative study wasdone to point out the impact of the choice of the parameters, kernel trick andfeature representations on the performance of the SVM classifier
arxiv-1507-06266 | Particle detection and tracking by a-contrario approach: application to fluorescence time-lapse imaging |  http://arxiv.org/abs/1507.06266  | author:Mariella Dimiccoli, Jean-Pascal Jacob, Lionel Moisan category:cs.CV published:2015-07-22 summary:In this work, we propose a probabilistic approach for the detection and thetracking of particles on biological images. In presence of very noised and poorquality data, particles and trajectories can be characterized by an a-contrariomodel, that estimates the probability of observing the structures of interestin random data. This approach, first introduced in the modeling of human visualperception and then successfully applied in many image processing tasks, leadsto algorithms that do not require a previous learning stage, nor a tediousparameter tuning and are very robust to noise. Comparative evaluations againsta well established baseline show that the proposed approach outperforms thestate of the art.
arxiv-1507-06346 | Evaluation of Spectral Learning for the Identification of Hidden Markov Models |  http://arxiv.org/abs/1507.06346  | author:Robert Mattila, Cristian R. Rojas, Bo Wahlberg category:stat.ML cs.LG math.OC published:2015-07-22 summary:Hidden Markov models have successfully been applied as models of discretetime series in many fields. Often, when applied in practice, the parameters ofthese models have to be estimated. The currently predominating identificationmethods, such as maximum-likelihood estimation and especiallyexpectation-maximization, are iterative and prone to have problems with localminima. A non-iterative method employing a spectral subspace-like approach hasrecently been proposed in the machine learning literature. This paper evaluatesthe performance of this algorithm, and compares it to the performance of theexpectation-maximization algorithm, on a number of numerical examples. We findthat the performance is mixed; it successfully identifies some systems withrelatively few available observations, but fails completely for some systemseven when a large amount of observations is available. An open question is howthis discrepancy can be explained. We provide some indications that it could berelated to how well-conditioned some system parameters are.
arxiv-1507-06332 | Part Localization using Multi-Proposal Consensus for Fine-Grained Categorization |  http://arxiv.org/abs/1507.06332  | author:Kevin J. Shih, Arun Mallya, Saurabh Singh, Derek Hoiem category:cs.CV published:2015-07-22 summary:We present a simple deep learning framework to simultaneously predictkeypoint locations and their respective visibilities and use those to achievestate-of-the-art performance for fine-grained classification. We show that byconditioning the predictions on object proposals with sufficient image support,our method can do well without complicated spatial reasoning. Instead,inference methods with robustness to outliers, yield state-of-the-art forkeypoint localization. We demonstrate the effectiveness of our accuratekeypoint localization and visibility prediction on the fine-grained birdrecognition task with and without ground truth bird bounding boxes, andoutperform existing state-of-the-art methods by over 2%.
arxiv-1507-06021 | An Empirical Comparison of SVM and Some Supervised Learning Algorithms for Vowel recognition |  http://arxiv.org/abs/1507.06021  | author:Rimah Amami, Dorra Ben Ayed, Noureddine Ellouze category:cs.CL cs.LG published:2015-07-22 summary:In this article, we conduct a study on the performance of some supervisedlearning algorithms for vowel recognition. This study aims to compare theaccuracy of each algorithm. Thus, we present an empirical comparison betweenfive supervised learning classifiers and two combined classifiers: SVM, KNN,Naive Bayes, Quadratic Bayes Normal (QDC) and Nearst Mean. Those algorithmswere tested for vowel recognition using TIMIT Corpus and Mel-frequency cepstralcoefficients (MFCCs).
arxiv-1507-06023 | Robust speech recognition using consensus function based on multi-layer networks |  http://arxiv.org/abs/1507.06023  | author:Rimah Amami, Ghaith Manita, Abir Smiti category:cs.CL cs.LG published:2015-07-22 summary:The clustering ensembles mingle numerous partitions of a specified data intoa single clustering solution. Clustering ensemble has emerged as a potentapproach for ameliorating both the forcefulness and the stability ofunsupervised classification results. One of the major problems in clusteringensembles is to find the best consensus function. Finding final partition fromdifferent clustering results requires skillfulness and robustness of theclassification algorithm. In addition, the major problem with the consensusfunction is its sensitivity to the used data sets quality. This limitation isdue to the existence of noisy, silence or redundant data. This paper proposes anovel consensus function of cluster ensembles based on Multilayer networkstechnique and a maintenance database method. This maintenance database approachis used in order to handle any given noisy speech and, thus, to guarantee thequality of databases. This can generates good results and efficient datapartitions. To show its effectiveness, we support our strategy with empiricalevaluation using distorted speech from Aurora speech databases.
arxiv-1507-06222 | STICK: Spike Time Interval Computational Kernel, A Framework for General Purpose Computation using Neurons, Precise Timing, Delays, and Synchrony |  http://arxiv.org/abs/1507.06222  | author:Xavier Lagorce, Ryad Benosman category:cs.NE published:2015-07-22 summary:There has been significant research over the past two decades in developingnew platforms for spiking neural computation. Current neural computers areprimarily developed to mimick biology. They use neural networks which can betrained to perform specific tasks to mainly solve pattern recognition problems.These machines can do more than simulate biology, they allow us to re-think ourcurrent paradigm of computation. The ultimate goal is to develop brain inspiredgeneral purpose computation architectures that can breach the currentbottleneck introduced by the Von Neumann architecture. This work proposes a newframework for such a machine. We show that the use of neuron like units withprecise timing representation, synaptic diversity, and temporal delays allowsus to set a complete, scalable compact computation framework. The presentedframework provides both linear and non linear operations, allowing us torepresent and solve any function. We show usability in solving real use casesfrom simple differential equations to sets of non-linear differential equationsleading to chaotic attractors.
arxiv-1507-06173 | Bayesian Time-of-Flight for Realtime Shape, Illumination and Albedo |  http://arxiv.org/abs/1507.06173  | author:Amit Adam, Christoph Dann, Omer Yair, Shai Mazor, Sebastian Nowozin category:cs.CV published:2015-07-22 summary:We propose a computational model for shape, illumination and albedo inferencein a pulsed time-of-flight (TOF) camera. In contrast to TOF cameras based onphase modulation, our camera enables general exposure profiles. This results inadded flexibility and requires novel computational approaches. To address this challenge we propose a generative probabilistic model thataccurately relates latent imaging conditions to observed camera responses.While principled, realtime inference in the model turns out to be infeasible,and we propose to employ efficient non-parametric regression trees toapproximate the model outputs. As a result we are able to provide, for eachpixel, at video frame rate, estimates and uncertainty for depth, effectivealbedo, and ambient light intensity. These results we present arestate-of-the-art in depth imaging. The flexibility of our approach allows us to easily enrich our generativemodel. We demonstrate that by extending the original single-path model to atwo-path model, capable of describing some multipath effects. The new model isseamlessly integrated in the system at no additional computational cost. Our work also addresses the important question of optimal exposure design inpulsed TOF systems. Finally, for benchmark purposes and to obtain realisticempirical priors of multipath and insights into this phenomena, we propose aphysically accurate simulation of multipath phenomena.
arxiv-1507-06149 | Data-free parameter pruning for Deep Neural Networks |  http://arxiv.org/abs/1507.06149  | author:Suraj Srinivas, R. Venkatesh Babu category:cs.CV published:2015-07-22 summary:Deep Neural nets (NNs) with millions of parameters are at the heart of manystate-of-the-art computer vision systems today. However, recent works haveshown that much smaller models can achieve similar levels of performance. Inthis work, we address the problem of pruning parameters in a trained NN model.Instead of removing individual weights one at a time as done in previous works,we remove one neuron at a time. We show how similar neurons are redundant, andpropose a systematic way to remove them. Our experiments in pruning the denselyconnected layers show that we can remove upto 85\% of the total parameters inan MNIST-trained network, and about 35\% for AlexNet without significantlyaffecting performance. Our method can be applied on top of most networks with afully connected layer to give a smaller network.
arxiv-1507-06025 | Incorporating Belief Function in SVM for Phoneme Recognition |  http://arxiv.org/abs/1507.06025  | author:Rimah Amami, Dorra Ben Ayed, Nouerddine Ellouze category:cs.CL cs.LG published:2015-07-22 summary:The Support Vector Machine (SVM) method has been widely used in numerousclassification tasks. The main idea of this algorithm is based on the principleof the margin maximization to find an hyperplane which separates the data intotwo different classes.In this paper, SVM is applied to phoneme recognitiontask. However, in many real-world problems, each phoneme in the data set forrecognition problems may differ in the degree of significance due to noise,inaccuracies, or abnormal characteristics; All those problems can lead to theinaccuracies in the prediction phase. Unfortunately, the standard formulationof SVM does not take into account all those problems and, in particular, thevariation in the speech input. This paper presents a new formulation of SVM(B-SVM) that attributes to each phoneme a confidence degree computed based onits geometric position in the space. Then, this degree is used in order tostrengthen the class membership of the tested phoneme. Hence, we introduce areformulation of the standard SVM that incorporates the degree of belief.Experimental performance on TIMIT database shows the effectiveness of theproposed method B-SVM on a phoneme recognition problem.
arxiv-1507-06105 | Banzhaf Random Forests |  http://arxiv.org/abs/1507.06105  | author:Jianyuan Sun, Guoqiang Zhong, Junyu Dong, Yajuan Cai category:cs.LG cs.CV stat.ML published:2015-07-22 summary:Random forests are a type of ensemble method which makes predictions bycombining the results of several independent trees. However, the theory ofrandom forests has long been outpaced by their application. In this paper, wepropose a novel random forests algorithm based on cooperative game theory.Banzhaf power index is employed to evaluate the power of each feature bytraversing possible feature coalitions. Unlike the previously used informationgain rate of information theory, which simply chooses the most informativefeature, the Banzhaf power index can be considered as a metric of theimportance of each feature on the dependency among a group of features. Moreimportantly, we have proved the consistency of the proposed algorithm, namedBanzhaf random forests (BRF). This theoretical analysis takes a step towardsnarrowing the gap between the theory and practice of random forests forclassification problems. Experiments on several UCI benchmark data sets showthat BRF is competitive with state-of-the-art classifiers and dramaticallyoutperforms previous consistent random forests. Particularly, it is much moreefficient than previous consistent random forests.
arxiv-1507-06073 | Discriminative Segmental Cascades for Feature-Rich Phone Recognition |  http://arxiv.org/abs/1507.06073  | author:Hao Tang, Weiran Wang, Kevin Gimpel, Karen Livescu category:cs.CL published:2015-07-22 summary:Discriminative segmental models, such as segmental conditional random fields(SCRFs) and segmental structured support vector machines (SSVMs), have hadsuccess in speech recognition via both lattice rescoring and first-passdecoding. However, such models suffer from slow decoding, hampering the use ofcomputationally expensive features, such as segment neural networks or otherhigh-order features. A typical solution is to use approximate decoding, eitherby beam pruning in a single pass or by beam pruning to generate a latticefollowed by a second pass. In this work, we study discriminative segmentalmodels trained with a hinge loss (i.e., segmental structured SVMs). We showthat beam search is not suitable for learning rescoring models in thisapproach, though it gives good approximate decoding performance when the modelis already well-trained. Instead, we consider an approach inspired bystructured prediction cascades, which use max-marginal pruning to generatelattices. We obtain a high-accuracy phonetic recognition system with severalexpensive feature types: a segment neural network, a second-order languagemodel, and second-order phone boundary features.
arxiv-1507-06065 | MixEst: An Estimation Toolbox for Mixture Models |  http://arxiv.org/abs/1507.06065  | author:Reshad Hosseini, Mohamadreza Mash'al category:stat.ML cs.LG published:2015-07-22 summary:Mixture models are powerful statistical models used in many applicationsranging from density estimation to clustering and classification. When dealingwith mixture models, there are many issues that the experimenter should beaware of and needs to solve. The MixEst toolbox is a powerful and user-friendlypackage for MATLAB that implements several state-of-the-art approaches toaddress these problems. Additionally, MixEst gives the possibility of usingmanifold optimization for fitting the density model, a feature specific to thistoolbox. MixEst simplifies using and integration of mixture models instatistical models and applications. For developing mixture models of newdensities, the user just needs to provide a few functions for that statisticaldistribution and the toolbox takes care of all the issues regarding mixturemodels. MixEst is available at visionlab.ut.ac.ir/mixest and is fullydocumented and is licensed under GPL.
arxiv-1507-06028 | The challenges of SVM optimization using Adaboost on a phoneme recognition problem |  http://arxiv.org/abs/1507.06028  | author:Rimah Amami, Dorra Ben Ayed, Noureddine Ellouze category:cs.CL cs.LG published:2015-07-22 summary:The use of digital technology is growing at a very fast pace which led to theemergence of systems based on the cognitive infocommunications. The expansionof this sector impose the use of combining methods in order to ensure therobustness in cognitive systems.
arxiv-1507-06032 | Elastic Net Procedure for Partially Linear Models |  http://arxiv.org/abs/1507.06032  | author:Chunhong Li, Dengxiang Huang, Hongshuai Dai, Xinxing Wei category:stat.ME math.PR stat.ML published:2015-07-22 summary:Variable selection plays an important role in the high-dimensional dataanalysis. However the high-dimensional data often induces the stronglycorrelated variables problem. In this paper, we propose Elastic Net procedurefor partially linear models and prove the group effect of its estimate. By asimulation study, we show that the strongly correlated variables problem can bebetter handled by the Elastic Net procedure than Lasso, ALasso and Ridge. Basedon an empirical analysis, we can get that the Elastic Net procedure isparticularly useful when the number of predictors $p$ is much bigger than thesample size $n$.
arxiv-1507-05952 | Optimal Testing for Properties of Distributions |  http://arxiv.org/abs/1507.05952  | author:Jayadev Acharya, Constantinos Daskalakis, Gautam Kamath category:cs.DS cs.IT cs.LG math.IT math.ST stat.TH published:2015-07-21 summary:Given samples from an unknown distribution $p$, is it possible to distinguishwhether $p$ belongs to some class of distributions $\mathcal{C}$ versus $p$being far from every distribution in $\mathcal{C}$? This fundamental questionhas received tremendous attention in statistics, focusing primarily onasymptotic analysis, and more recently in information theory and theoreticalcomputer science, where the emphasis has been on small sample size andcomputational complexity. Nevertheless, even for basic properties ofdistributions such as monotonicity, log-concavity, unimodality, independence,and monotone-hazard rate, the optimal sample complexity is unknown. We provide a general approach via which we obtain sample-optimal andcomputationally efficient testers for all these distribution families. At thecore of our approach is an algorithm which solves the following problem: Givensamples from an unknown distribution $p$, and a known distribution $q$, are $p$and $q$ close in $\chi^2$-distance, or far in total variation distance? The optimality of our testers is established by providing matching lowerbounds with respect to both $n$ and $\varepsilon$. Finally, a necessarybuilding block for our testers and an important byproduct of our work are thefirst known computationally efficient proper learners for discrete log-concaveand monotone hazard rate distributions.
arxiv-1507-05775 | Compression of Fully-Connected Layer in Neural Network by Kronecker Product |  http://arxiv.org/abs/1507.05775  | author:Shuchang Zhou, Jia-Nan Wu category:cs.NE cs.CV cs.LG published:2015-07-21 summary:In this paper we propose and study a technique to reduce the number ofparameters and computation time in fully-connected layers of neural networksusing Kronecker product, at a mild cost of the prediction quality. Thetechnique proceeds by replacing Fully-Connected layers with so-called KroneckerFully-Connected layers, where the weight matrices of the FC layers areapproximated by linear combinations of multiple Kronecker products of smallermatrices. In particular, given a model trained on SVHN dataset, we are able toconstruct a new KFC model with 73\% reduction in total number of parameters,while the error only rises mildly. In contrast, using low-rank method can onlyachieve 35\% reduction in total number of parameters given similar qualitydegradation allowance. If we only compare the KFC layer with its counterpartfully-connected layer, the reduction in the number of parameters exceeds 99\%.The amount of computation is also reduced as we replace matrix product of thelarge matrices in FC layers with matrix products of a few smaller matrices inKFC layers. Further experiments on MNIST, SVHN and some Chinese Characterrecognition models also demonstrate effectiveness of our technique.
arxiv-1507-05699 | Bottom-Up and Top-Down Reasoning with Hierarchical Rectified Gaussians |  http://arxiv.org/abs/1507.05699  | author:Peiyun Hu, Deva Ramanan category:cs.CV published:2015-07-21 summary:Convolutional neural nets (CNNs) have demonstrated remarkable performance inrecent history. Such approaches tend to work in a unidirectional bottom-upfeed-forward fashion. However, practical experience and biological evidencetells us that feedback plays a crucial role, particularly for detailed spatialunderstanding tasks. This work explores bidirectional architectures that alsoreason with top-down feedback: neural units are influenced by both lower andhigher-level units. We do so by treating units as rectified latent variables in a quadraticenergy function, which can be seen as a hierarchical Rectified Gaussian model(RGs). We show that RGs can be optimized with a quadratic program (QP), thatcan in turn be optimized with a recurrent neural network (with rectified linearunits). This allows RGs to be trained with GPU-optimized gradient descent. Froma theoretical perspective, RGs help establish a connection between CNNs andhierarchical probabilistic models. From a practical perspective, RGs are wellsuited for detailed spatial tasks that can benefit from top-down reasoning. Weillustrate them on the challenging task of keypoint localization underocclusions, where local bottom-up evidence may be misleading. We demonstratestate-of-the-art results on challenging benchmarks.
arxiv-1507-05899 | Sparsity in Multivariate Extremes with Applications to Anomaly Detection |  http://arxiv.org/abs/1507.05899  | author:Nicolas Goix, Anne Sabourin, Stéphan Clémençon category:stat.ML published:2015-07-21 summary:Capturing the dependence structure of multivariate extreme events is a majorconcern in many fields involving the management of risks stemming from multiplesources, e.g. portfolio monitoring, insurance, environmental risk managementand anomaly detection. One convenient (non-parametric) characterization ofextremal dependence in the framework of multivariate Extreme Value Theory (EVT)is the angular measure, which provides direct information about the probable'directions' of extremes, that is, the relative contribution of eachfeature/coordinate of the 'largest' observations. Modeling the angular measurein high dimensional problems is a major challenge for the multivariate analysisof rare events. The present paper proposes a novel methodology aiming atexhibiting a sparsity pattern within the dependence structure of extremes. Thisis done by estimating the amount of mass spread by the angular measure onrepresentative sets of directions, corresponding to specific sub-cones of$R^d\_+$. This dimension reduction technique paves the way towards scaling upexisting multivariate EVT methods. Beyond a non-asymptotic study providing atheoretical validity framework for our method, we propose as a directapplication a --first-- anomaly detection algorithm based on multivariate EVT.This algorithm builds a sparse 'normal profile' of extreme behaviours, to beconfronted with new (possibly abnormal) extreme observations. Illustrativeexperimental results provide strong empirical evidence of the relevance of ourapproach.
arxiv-1507-05870 | A statistical perspective of sampling scores for linear regression |  http://arxiv.org/abs/1507.05870  | author:Siheng Chen, Rohan Varma, Aarti Singh, Jelena Kovačević category:stat.ML published:2015-07-21 summary:In this paper, we consider a statistical problem of learning a linear modelfrom noisy samples. Existing work has focused on approximating the leastsquares solution by using leverage-based scores as an importance samplingdistribution. However, no finite sample statistical guarantees and nocomputationally efficient optimal sampling strategies have been proposed. Toevaluate the statistical properties of different sampling strategies, wepropose a simple yet effective estimator, which is easy for theoreticalanalysis and is useful in multitask linear regression. We derive the exact meansquare error of the proposed estimator for any given sampling scores. Based onminimizing the mean square error, we propose the optimal sampling scores forboth estimator and predictor, and show that they are influenced by thenoise-to-signal ratio. Numerical simulations match the theoretical analysiswell.
arxiv-1507-05910 | Clustering is Efficient for Approximate Maximum Inner Product Search |  http://arxiv.org/abs/1507.05910  | author:Alex Auvolat, Sarath Chandar, Pascal Vincent, Hugo Larochelle, Yoshua Bengio category:cs.LG cs.CL stat.ML published:2015-07-21 summary:Efficient Maximum Inner Product Search (MIPS) is an important task that has awide applicability in recommendation systems and classification with a largenumber of classes. Solutions based on locality-sensitive hashing (LSH) as wellas tree-based solutions have been investigated in the recent literature, toperform approximate MIPS in sublinear time. In this paper, we compare these toanother extremely simple approach for solving approximate MIPS, based onvariants of the k-means clustering algorithm. Specifically, we propose to traina spherical k-means, after having reduced the MIPS problem to a Maximum CosineSimilarity Search (MCSS). Experiments on two standard recommendation systembenchmarks as well as on large vocabulary word embeddings, show that thissimple approach yields much higher speedups, for the same retrieval precision,than current state-of-the-art hashing-based and tree-based methods. This simplemethod also yields more robust retrievals when the query is corrupted by noise.
arxiv-1507-05950 | On the Worst-Case Approximability of Sparse PCA |  http://arxiv.org/abs/1507.05950  | author:Siu On Chan, Dimitris Papailiopoulos, Aviad Rubinstein category:stat.ML cs.CC cs.DS cs.LG published:2015-07-21 summary:It is well known that Sparse PCA (Sparse Principal Component Analysis) isNP-hard to solve exactly on worst-case instances. What is the complexity ofsolving Sparse PCA approximately? Our contributions include: 1) a simple andefficient algorithm that achieves an $n^{-1/3}$-approximation; 2) NP-hardnessof approximation to within $(1-\varepsilon)$, for some small constant$\varepsilon > 0$; 3) SSE-hardness of approximation to within any constantfactor; and 4) an $\exp\exp\left(\Omega\left(\sqrt{\log \log n}\right)\right)$("quasi-quasi-polynomial") gap for the standard semidefinite program.
arxiv-1507-05936 | The Cumulative Distribution Transform and Linear Pattern Classification |  http://arxiv.org/abs/1507.05936  | author:Se Rim Park, Soheil Kolouri, Shinjini Kundu, Gustavo Rohde category:cs.CV published:2015-07-21 summary:Classifying (determining the label) of data emanating from sensors is animportant problem with many applications in science and technology. We describea new transform for patterns that can be interpreted as a probability densityfunction, that has special properties with regards to classification. Thetransform, which we denote as the Cumulative Distribution Transform (CDT) isinvertible, with well defined forward and inverse operations. We show that itcan be useful in 'parsing out' variations (confounds) that are 'Lagrangian'(displacement or transport) by converting these to 'Eulerian' variations intransform domain. This conversion is the basis for our main result thatdescribes when the CDT can allow for linear classification to be possible insignal domain. We also describe several properties of the transform and show,with computational experiments that used both real and simulated data, that theCDT can help render a variety of real world problems simpler to solve.
arxiv-1507-05880 | A study of the classification of low-dimensional data with supervised manifold learning |  http://arxiv.org/abs/1507.05880  | author:Elif Vural, Christine Guillemot category:cs.LG published:2015-07-21 summary:Supervised manifold learning methods learn data representations by preservingthe geometric structure of data while enhancing the separation between datasamples from different classes. In this paper, we propose a theoretical studyof supervised manifold learning for classification. We first focus on thesupervised Laplacian eigenmaps algorithm and study the conditions under whichthis method computes low-dimensional embeddings where different classes becomelinearly separable. We then consider arbitrary supervised manifold learningalgorithms that compute a linearly separable embedding and study the accuracyof the classifiers given by the out-of-sample extensions of these embeddings.We characterize the classification accuracy in terms of several parameters ofthe classifier such as the separation between different classes in theembedding, the regularity of the interpolation function and the number oftraining samples. The proposed analysis is supported by experiments onsynthetic and real data and has potential for guiding the design of classifiersfor intrinsically low-dimensional data.
arxiv-1507-05869 | Kernel convolution model for decoding sounds from time-varying neural responses |  http://arxiv.org/abs/1507.05869  | author:Ali Faisal, Anni Nora, Jaeho Seol, Hanna Renvall, Riitta Salmelin category:stat.ML q-bio.NC published:2015-07-21 summary:In this study we present a kernel based convolution model to characterizeneural responses to natural sounds by decoding their time-varying acousticfeatures. The model allows to decode natural sounds from high-dimensionalneural recordings, such as magnetoencephalography (MEG), that track timing andlocation of human cortical signalling noninvasively across multiple channels.We used the MEG responses recorded from subjects listening to acousticallydifferent environmental sounds. By decoding the stimulus frequencies from theresponses, our model was able to accurately distinguish between two differentsounds that it had never encountered before with 70% accuracy. Convolutionmodels typically decode frequencies that appear at a certain time point in thesound signal by using neural responses from that time point until a certainfixed duration of the response. Using our model, we evaluated several fixeddurations (time-lags) of the neural responses and observed auditory MEGresponses to be most sensitive to spectral content of the sounds at time-lagsof 250 ms to 500 ms. The proposed model should be useful for determining whataspects of natural sounds are represented by high-dimensional neural responsesand may reveal novel properties of neural signals.
arxiv-1507-05819 | Detecting Internet Filtering from Geographic Time Series |  http://arxiv.org/abs/1507.05819  | author:Joss Wright, Alexander Darer, Oliver Farnan category:cs.CY cs.LG cs.NI published:2015-07-21 summary:We propose an approach based on principle component analysis to identifyper-country anomalous periods in traffic usage as a means to detect internetfiltering, and demonstrate the applicability of this approach with global usagestatistics from the Tor Project. In contrast to previous country-specificinvestigations, our techniques use deviation from global patterns of usage toidentify countries straying from predicted behaviour, allowing theidentification of periods of filtering and related events in any country forwhich usage statistics exist. To our knowledge the work presented here is thefirst automated approach to detecting internet filtering at a global scale. We demonstrate the applicability of our approach by identifying knownhistorical filtering events as well as events injected synthetically into adataset, and evaluate the sensitivity of this technique against differentclasses of censorship events. Importantly, our results show that usage ofcircumvention tools, such as those provided by the Tor Project, act not only asdirect indicators of network censorship but also as a meaningful proxy variablefor related events such as protests in which internet use is restricted.
arxiv-1507-05800 | Bandit-Based Task Assignment for Heterogeneous Crowdsourcing |  http://arxiv.org/abs/1507.05800  | author:Hao Zhang, Yao Ma, Masashi Sugiyama category:cs.LG published:2015-07-21 summary:We consider a task assignment problem in crowdsourcing, which is aimed atcollecting as many reliable labels as possible within a limited budget. Achallenge in this scenario is how to cope with the diversity of tasks and thetask-dependent reliability of workers, e.g., a worker may be good atrecognizing the name of sports teams, but not be familiar with cosmeticsbrands. We refer to this practical setting as heterogeneous crowdsourcing. Inthis paper, we propose a contextual bandit formulation for task assignment inheterogeneous crowdsourcing, which is able to deal with theexploration-exploitation trade-off in worker selection. We also theoreticallyinvestigate the regret bounds for the proposed method, and demonstrate itspractical usefulness experimentally.
arxiv-1507-05781 | Gradient Importance Sampling |  http://arxiv.org/abs/1507.05781  | author:Ingmar Schuster category:stat.ML published:2015-07-21 summary:Adaptive Monte Carlo schemes developed over the last years usually seek toensure ergodicity of the sampling process in line with MCMC tradition. Thisposes constraints on what is possible in terms of adaptation. In the generalcase ergodicity can only be guaranteed if adaptation is diminished at a certainrate. Importance Sampling approaches offer a way to circumvent this limitationand design sampling algorithms that keep adapting. Here I present a gradientinformed variant of SMC (and its special case Population Monte Carlo) forstatic problems.
arxiv-1507-05738 | Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos |  http://arxiv.org/abs/1507.05738  | author:Serena Yeung, Olga Russakovsky, Ning Jin, Mykhaylo Andriluka, Greg Mori, Li Fei-Fei category:cs.CV published:2015-07-21 summary:Every moment counts in action recognition. A comprehensive understanding ofhuman activity in video requires labeling every frame according to the actionsoccurring, placing multiple labels densely over a video sequence. To study thisproblem we extend the existing THUMOS dataset and introduce MultiTHUMOS, a newdataset of dense labels over unconstrained internet videos. Modeling multiple,dense labels benefits from temporal relations within and across classes. Wedefine a novel variant of long short-term memory (LSTM) deep networks formodeling these temporal relations via multiple input and output connections. Weshow that this model improves action labeling accuracy and further enablesdeeper understanding tasks ranging from structured retrieval to actionprediction.
arxiv-1507-05737 | Online Metric-Weighted Linear Representations for Robust Visual Tracking |  http://arxiv.org/abs/1507.05737  | author:Xi Li, Chunhua Shen, Anthony Dick, Zhongfei Zhang, Yueting Zhuang category:cs.CV published:2015-07-21 summary:In this paper, we propose a visual tracker based on a metric-weighted linearrepresentation of appearance. In order to capture the interdependence ofdifferent feature dimensions, we develop two online distance metric learningmethods using proximity comparison information and structured output learning.The learned metric is then incorporated into a linear representation ofappearance. We show that online distance metric learning significantly improves therobustness of the tracker, especially on those sequences exhibiting drasticappearance changes. In order to bound growth in the number of training samples,we design a time-weighted reservoir sampling method. Moreover, we enable our tracker to automatically perform objectidentification during the process of object tracking, by introducing acollection of static template samples belonging to several object classes ofinterest. Object identification results for an entire video sequence areachieved by systematically combining the tracking information and visualrecognition at each frame. Experimental results on challenging video sequencesdemonstrate the effectiveness of the method for both inter-frame tracking andobject identification.
arxiv-1507-05726 | Rule Of Thumb: Deep derotation for improved fingertip detection |  http://arxiv.org/abs/1507.05726  | author:Aaron Wetzler, Ron Slossberg, Ron Kimmel category:cs.CV published:2015-07-21 summary:We investigate a novel global orientation regression approach for articulatedobjects using a deep convolutional neural network. This is integrated with anin-plane image derotation scheme, DeROT, to tackle the problem of per-framefingertip detection in depth images. The method reduces the complexity oflearning in the space of articulated poses which is demonstrated by using twodistinct state-of-the-art learning based hand pose estimation methods appliedto fingertip detection. Significant classification improvements are shown overthe baseline implementation. Our framework involves no tracking, kinematicconstraints or explicit prior model of the articulated object in hand. Tosupport our approach we also describe a new pipeline for high accuracy magneticannotation and labeling of objects imaged by a depth camera.
arxiv-1507-05720 | Gene expression modelling across multiple cell-lines with MapReduce |  http://arxiv.org/abs/1507.05720  | author:David M. Budden, Edmund J. Crampin category:q-bio.QM cs.DC q-bio.GN stat.ML published:2015-07-21 summary:With the wealth of high-throughput sequencing data generated by recentlarge-scale consortia, predictive gene expression modelling has become animportant tool for integrative analysis of transcriptomic and epigenetic data.However, sequencing data-sets are characteristically large, and previouslymodelling frameworks are typically inefficient and unable to leveragemulti-core or distributed processing architectures. In this study, we detail anefficient and parallelised MapReduce implementation of gene expressionmodelling. We leverage the computational efficiency of this framework toprovide an integrative analysis of over fifty histone modification data-setsacross a variety of cancerous and non-cancerous cell-lines. Our resultsdemonstrate that the genome-wide relationships between histone modificationsand mRNA transcription are lineage, tissue and karyotype-invariant, and thatmodels trained on matched epigenetic/transcriptomic data from non-cancerouscell-lines are able to predict cancerous expression with equivalent genome-widefidelity.
arxiv-1507-05717 | An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition |  http://arxiv.org/abs/1507.05717  | author:Baoguang Shi, Xiang Bai, Cong Yao category:cs.CV published:2015-07-21 summary:Image-based sequence recognition has been a long-standing research topic incomputer vision. In this paper, we investigate the problem of scene textrecognition, which is among the most important and challenging tasks inimage-based sequence recognition. A novel neural network architecture, whichintegrates feature extraction, sequence modeling and transcription into aunified framework, is proposed. Compared with previous systems for scene textrecognition, the proposed architecture possesses four distinctive properties:(1) It is end-to-end trainable, in contrast to most of the existing algorithmswhose components are separately trained and tuned. (2) It naturally handlessequences in arbitrary lengths, involving no character segmentation orhorizontal scale normalization. (3) It is not confined to any predefinedlexicon and achieves remarkable performances in both lexicon-free andlexicon-based scene text recognition tasks. (4) It generates an effective yetmuch smaller model, which is more practical for real-world applicationscenarios. The experiments on standard benchmarks, including the IIIT-5K,Street View Text and ICDAR datasets, demonstrate the superiority of theproposed algorithm over the prior arts. Moreover, the proposed algorithmperforms well in the task of image-based music score recognition, whichevidently verifies the generality of it.
arxiv-1507-05695 | A neuromorphic hardware architecture using the Neural Engineering Framework for pattern recognition |  http://arxiv.org/abs/1507.05695  | author:Runchun Wang, Chetan Singh Thakur, Tara Julia Hamilton, Jonathan Tapson, Andre van Schaik category:cs.NE published:2015-07-21 summary:We present a hardware architecture that uses the Neural Engineering Framework(NEF) to implement large-scale neural networks on Field Programmable GateArrays (FPGAs) for performing pattern recognition in real time. NEF is aframework that is capable of synthesising large-scale cognitive systems fromsubnetworks. We will first present the architecture of the proposed neuralnetwork implemented using fixed-point numbers and demonstrate a routine thatcomputes the decoding weights by using the online pseudoinverse update method(OPIUM) in a parallel and distributed manner. The proposed system isefficiently implemented on a compact digital neural core. This neural coreconsists of 64 neurons that are instantiated by a single physical neuron usinga time-multiplexing approach. As a proof of concept, we combined 128 identicalneural cores together to build a handwritten digit recognition system using theMNIST database and achieved a recognition rate of 96.55%. The system isimplemented on a state-of-the-art FPGA and can process 5.12 million digits persecond. The architecture is not limited to handwriting recognition, but isgenerally applicable as an extremely fast pattern recognition processor forvarious kinds of patterns such as speech and images.
arxiv-1507-05630 | Notes About a More Aware Dependency Parser |  http://arxiv.org/abs/1507.05630  | author:Matteo Grella category:cs.CL published:2015-07-20 summary:In this paper I explain the reasons that led me to research and conceive anovel technology for dependency parsing, mixing together the strengths ofdata-driven transition-based and constraint-based approaches. In particular Ihighlight the problem to infer the reliability of the results of a data-driventransition-based parser, which is extremely important for high-level processesthat expect to use correct parsing results. I then briefly introduce a numberof notes about a new parser model I'm working on, capable to proceed with theanalysis in a "more aware" way, with a more "robust" concept of robustness.
arxiv-1507-05605 | A semidefinite program for unbalanced multisection in the stochastic block model |  http://arxiv.org/abs/1507.05605  | author:William Perry, Alexander S. Wein category:cs.DS math.PR stat.ML 68 published:2015-07-20 summary:We analyze semidefinite programming (SDP) algorithms that exactly recovercommunity structure in graphs generated from the stochastic block model. Inthis model, a graph is randomly generated on a vertex set that is partitionedinto multiple communities of potentially different sizes, where edges are moreprobable within communities than between communities. We achieve exact recoveryof the community structure, up to the information-theoretic limits determinedby Abbe and Sandon. By virtue of a semidefinite approach, our algorithmssucceed against a semirandom form of the stochastic block model, guaranteeinggeneralization to scenarios with radically different noise structure.
arxiv-1507-05532 | Clustering Tree-structured Data on Manifold |  http://arxiv.org/abs/1507.05532  | author:Na Lu, Hongyu Miao category:cs.CV cs.LG 68T10, 62H30 published:2015-07-20 summary:Tree-structured data usually contain both topological and geometricalinformation, and are necessarily considered on manifold instead of Euclideanspace for appropriate data parameterization and analysis. In this study, wepropose a novel tree-structured data parameterization, calledTopology-Attribute matrix (T-A matrix), so the data clustering task can beconducted on matrix manifold. We incorporate the structure constraints embeddedin data into the negative matrix factorization method to determine meta-treesfrom the T-A matrix, and the signature vector of each single tree can then beextracted by meta-tree decomposition. The meta-tree space turns out to be acone space, in which we explore the distance metric and implement theclustering algorithm based on the concepts like Fr\'echet mean. Finally, theT-A matrix based clustering (TAMBAC) framework is evaluated and compared usingboth simulated data and real retinal images to illustrate its efficiency andaccuracy.
arxiv-1507-05578 | Subspace Alignment Based Domain Adaptation for RCNN Detector |  http://arxiv.org/abs/1507.05578  | author:Anant Raj, Vinay P. Namboodiri, Tinne Tuytelaars category:cs.CV published:2015-07-20 summary:In this paper, we propose subspace alignment based domain adaptation of thestate of the art RCNN based object detector. The aim is to be able to achievehigh quality object detection in novel, real world target scenarios withoutrequiring labels from the target domain. While, unsupervised domain adaptationhas been studied in the case of object classification, for object detection ithas been relatively unexplored. In subspace based domain adaptation forobjects, we need access to source and target subspaces for the bounding boxfeatures. The absence of supervision (labels and bounding boxes are absent)makes the task challenging. In this paper, we show that we can still adapt sub-spaces that are localized to the object by obtaining detections from the RCNNdetector trained on source and applied on target. Then we form localizedsubspaces from the detections and show that subspace alignment based adaptationbetween these subspaces yields improved object detection. This evaluation isdone by considering challenging real world datasets of PASCAL VOC as source andvalidation set of Microsoft COCO dataset as target for various categories.
arxiv-1507-05523 | How to Generate a Good Word Embedding? |  http://arxiv.org/abs/1507.05523  | author:Siwei Lai, Kang Liu, Liheng Xu, Jun Zhao category:cs.CL published:2015-07-20 summary:We analyze three critical components of word embedding training: the model,the corpus, and the training parameters. We systematize existingneural-network-based word embedding algorithms and compare them using the samecorpus. We evaluate each word embedding in three ways: analyzing its semanticproperties, using it as a feature for supervised tasks and using it toinitialize neural networks. We also provide several simple guidelines fortraining word embeddings. First, we discover that corpus domain is moreimportant than corpus size. We recommend choosing a corpus in a suitable domainfor the desired task, after that, using a larger corpus yields better results.Second, we find that faster models provide sufficient performance in mostcases, and more complex models can be used if the training corpus issufficiently large. Third, the early stopping metric for iterating should relyon the development set of the desired task rather than the validation loss oftraining embedding.
arxiv-1507-05455 | AMP: a new time-frequency feature extraction method for intermittent time-series data |  http://arxiv.org/abs/1507.05455  | author:Duncan Barrack, James Goulding, Keith Hopcraft, Simon Preston, Gavin Smith category:cs.LG G.3 published:2015-07-20 summary:The characterisation of time-series data via their most salient features isextremely important in a range of machine learning task, not least of all withregards to classification and clustering. While there exist many featureextraction techniques suitable for non-intermittent time-series data, theseapproaches are not always appropriate for intermittent time-series data, whereintermittency is characterized by constant values for large periods of timepunctuated by sharp and transient increases or decreases in value. Motivated by this, we present aggregation, mode decomposition and projection(AMP) a feature extraction technique particularly suited to intermittenttime-series data which contain time-frequency patterns. For our method allindividual time-series within a set are combined to form a non-intermittentaggregate. This is decomposed into a set of components which represent theintrinsic time-frequency signals within the data set. Individual time-seriescan then be fit to these components to obtain a set of numerical features thatrepresent their intrinsic time-frequency patterns. To demonstrate theeffectiveness of AMP, we evaluate against the real word task of clusteringintermittent time-series data. Using synthetically generated data we show thata clustering approach which uses the features derived from AMP significantlyoutperforms traditional clustering methods. Our technique is furtherexemplified on a real world data set where AMP can be used to discovergroupings of individuals which correspond to real world sub-populations.
arxiv-1507-05498 | On the Minimax Risk of Dictionary Learning |  http://arxiv.org/abs/1507.05498  | author:Alexander Jung, Yonina C. Eldar, Norbert Görtz category:stat.ML cs.IT cs.LG math.IT published:2015-07-20 summary:We consider the problem of learning a dictionary matrix from a number ofobserved signals, which are assumed to be generated via a linear model with acommon underlying dictionary. In particular, we derive lower bounds on theminimum achievable worst case mean squared error (MSE), regardless ofcomputational complexity of the dictionary learning (DL) schemes. By casting DLas a classical (or frequentist) estimation problem, the lower bounds on theworst case MSE are derived by following an established information-theoreticapproach to minimax estimation. The main conceptual contribution of this paperis the adaption of the information-theoretic approach to minimax estimation forthe DL problem in order to derive lower bounds on the worst case MSE of any DLscheme. We derive three different lower bounds applying to different generativemodels for the observed signals. The first bound applies to a wide range ofmodels, it only requires the existence of a covariance matrix of the (unknown)underlying coefficient vector. By specializing this bound to the case of sparsecoefficient distributions, and assuming the true dictionary satisfies therestricted isometry property, we obtain a lower bound on the worst case MSE ofDL schemes in terms of a signal to noise ratio (SNR). The third bound appliesto a more restrictive subclass of coefficient distributions by requiring thenon-zero coefficients to be Gaussian. While, compared with the previous twobounds, the applicability of this final bound is the most limited it is thetightest of the three bounds in the low SNR regime.
arxiv-1507-05489 | Efficient moving point handling for incremental 3D manifold reconstruction |  http://arxiv.org/abs/1507.05489  | author:Andrea Romanoni, Matteo Matteucci category:cs.CV published:2015-07-20 summary:As incremental Structure from Motion algorithms become effective, a goodsparse point cloud representing the map of the scene becomes availableframe-by-frame. From the 3D Delaunay triangulation of these points,state-of-the-art algorithms build a manifold rough model of the scene. Thesealgorithms integrate incrementally new points to the 3D reconstruction only iftheir position estimate does not change. Indeed, whenever a point moves in a 3DDelaunay triangulation, for instance because its estimation gets refined, a setof tetrahedra have to be removed and replaced with new ones to maintain theDelaunay property; the management of the manifold reconstruction becomes thuscomplex and it entails a potentially big overhead. In this paper we investigatedifferent approaches and we propose an efficient policy to deal with movingpoints in the manifold estimation process. We tested our approach with foursequences of the KITTI dataset and we show the effectiveness of our proposal incomparison with state-of-the-art approaches.
arxiv-1507-05371 | Regret Guarantees for Item-Item Collaborative Filtering |  http://arxiv.org/abs/1507.05371  | author:Guy Bresler, Devavrat Shah, Luis F. Voloch category:cs.LG cs.IR cs.IT math.IT stat.ML published:2015-07-20 summary:There is much empirical evidence that item-item collaborative filtering workswell in practice. Motivated to understand this, we provide a framework todesign and analyze various recommendation algorithms. The setup amounts toonline binary matrix completion, where at each time a random user requests arecommendation and the algorithm chooses an entry to reveal in the user's row.The goal is to minimize regret, or equivalently to maximize the number of +1entries revealed at any time. We analyze an item-item collaborative filteringalgorithm that can achieve fundamentally better performance compared touser-user collaborative filtering. The algorithm achieves good "cold-start"performance (appropriately defined) by quickly making good recommendations tonew users about whom there is little information.
arxiv-1507-05670 | Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries |  http://arxiv.org/abs/1507.05670  | author:Yuke Zhu, Ce Zhang, Christopher Ré, Li Fei-Fei category:cs.CV cs.LG published:2015-07-20 summary:The complexity of the visual world creates significant challenges forcomprehensive visual understanding. In spite of recent successes in visualrecognition, today's vision systems would still struggle to deal with visualqueries that require a deeper reasoning. We propose a knowledge base (KB)framework to handle an assortment of visual queries, without the need to trainnew classifiers for new tasks. Building such a large-scale multimodal KBpresents a major challenge of scalability. We cast a large-scale MRF into a KBrepresentation, incorporating visual, textual and structured data, as well astheir diverse relations. We introduce a scalable knowledge base constructionsystem that is capable of building a KB with half billion variables andmillions of parameters in a few hours. Our system achieves competitive resultscompared to purpose-built models on standard recognition and retrieval tasks,while exhibiting greater flexibility in answering richer visual queries.
arxiv-1507-05444 | Canonical Correlation Forests |  http://arxiv.org/abs/1507.05444  | author:Tom Rainforth, Frank Wood category:stat.ML cs.LG published:2015-07-20 summary:We introduce canonical correlation forests (CCFs), a new decision treeensemble method for classification. Individual canonical correlation trees arebinary decision trees with hyperplane splits based on canonical correlationcomponents. Unlike axis-aligned alternatives, the decision surfaces of CCFs arenot restricted to the coordinate system of the input features and thereforemore naturally represent data with correlation between the features.Additionally we introduce a novel alternative to bagging, the projectionbootstrap, which maintains use of the full dataset in selecting split points.CCFs do not require parameter tuning and our experiments show that theyout-perform axis-aligned random forests, other state-of-the-art tree ensemblemethods and all of the 179 popular classifiers considered in a recent extensivesurvey.
arxiv-1507-05370 | Linear Inverse Problems with Norm and Sparsity Constraints |  http://arxiv.org/abs/1507.05370  | author:Volkan Cevher, Sina Jafarpour, Anastasios Kyrillidis category:cs.IT math.IT math.OC stat.ML published:2015-07-20 summary:We describe two nonconventional algorithms for linear regression, called GAMEand CLASH. The salient characteristics of these approaches is that they exploitthe convex $\ell_1$-ball and non-convex $\ell_0$-sparsity constraints jointlyin sparse recovery. To establish the theoretical approximation guarantees ofGAME and CLASH, we cover an interesting range of topics from game theory,convex and combinatorial optimization. We illustrate that these approaches leadto improved theoretical guarantees and empirical performance beyond convex andnon-convex solvers alone.
arxiv-1507-05409 | A Parameter-free Affinity Based Clustering |  http://arxiv.org/abs/1507.05409  | author:Bhaskar Mukhoty, Ruchir Gupta, Y. N. Singh category:cs.CV published:2015-07-20 summary:Several methods have been proposed to estimate the number of clusters in adataset; the basic ideal behind all of them has been to study an index thatmeasures inter-cluster separation and intra-cluster cohesion over a range ofcluster numbers and report the number which gives an optimum value of theindex. In this paper we propose a simple, parameter free approach that is likehuman cognition to form clusters, where closely lying points are easilyidentified to form a cluster and total number of clusters are revealed. Toidentify closely lying points, affinity of two points is defined as a functionof distance and a threshold affinity is identified, above which two points in adataset are likely to be in the same cluster. Well separated clusters areidentified even in the presence of outliers, whereas for not so well separateddataset, final number of clusters are estimated and the detected clusters aremerged to produce the final clusters. Experiments performed with several largedimensional synthetic and real datasets show good results with robustness tonoise and density variation within dataset.
arxiv-1507-05367 | Structured Sparsity: Discrete and Convex approaches |  http://arxiv.org/abs/1507.05367  | author:Anastasios Kyrillidis, Luca Baldassarre, Marwa El-Halabi, Quoc Tran-Dinh, Volkan Cevher category:cs.IT math.IT math.OC stat.ML published:2015-07-20 summary:Compressive sensing (CS) exploits sparsity to recover sparse or compressiblesignals from dimensionality reducing, non-adaptive sensing mechanisms. Sparsityis also used to enhance interpretability in machine learning and statisticsapplications: While the ambient dimension is vast in modern data analysisproblems, the relevant information therein typically resides in a much lowerdimensional space. However, many solutions proposed nowadays do not leveragethe true underlying structure. Recent results in CS extend the simple sparsityidea to more sophisticated {\em structured} sparsity models, which describe theinterdependency between the nonzero components of a signal, allowing toincrease the interpretability of the results and lead to better recoveryperformance. In order to better understand the impact of structured sparsity,in this chapter we analyze the connections between the discrete models andtheir convex relaxations, highlighting their relative advantages. We start withthe general group sparse model and then elaborate on two important specialcases: the dispersive and the hierarchical models. For each, we present themodels in their discrete nature, discuss how to solve the ensuing discreteproblems and then describe convex relaxations. We also consider more generalstructures as defined by set functions and present their convex proxies.Further, we discuss efficient optimization solutions for structured sparsityproblems and illustrate structured sparsity in action via three applications.
arxiv-1507-05348 | Learning Complexity-Aware Cascades for Deep Pedestrian Detection |  http://arxiv.org/abs/1507.05348  | author:Zhaowei Cai, Mohammad Saberian, Nuno Vasconcelos category:cs.CV published:2015-07-19 summary:The design of complexity-aware cascaded detectors, combining features of verydifferent complexities, is considered. A new cascade design procedure isintroduced, by formulating cascade learning as the Lagrangian optimization of arisk that accounts for both accuracy and complexity. A boosting algorithm,denoted as complexity aware cascade training (CompACT), is then derived tosolve this optimization. CompACT cascades are shown to seek an optimaltrade-off between accuracy and complexity by pushing features of highercomplexity to the later cascade stages, where only a few difficult candidatepatches remain to be classified. This enables the use of features of vastlydifferent complexities in a single detector. In result, the feature pool can beexpanded to features previously impractical for cascade design, such as theresponses of a deep convolutional neural network (CNN). This is demonstratedthrough the design of a pedestrian detector with a pool of features whosecomplexities span orders of magnitude. The resulting cascade generalizes thecombination of a CNN with an object proposal mechanism: rather than apre-processing stage, CompACT cascades seamlessly integrate CNNs in theirstages. This enables state of the art performance on the Caltech and KITTIdatasets, at fairly fast speeds.
arxiv-1507-05331 | Fast Adaptive Weight Noise |  http://arxiv.org/abs/1507.05331  | author:Justin Bayer, Maximilian Karl, Daniela Korhammer, Patrick van der Smagt category:stat.ML cs.LG published:2015-07-19 summary:Marginalising out uncertain quantities within the internal representations orparameters of neural networks is of central importance for a wide range oflearning techniques, such as empirical, variational or full Bayesian methods.We set out to generalise fast dropout (Wang & Manning, 2013) to cover a widervariety of noise processes in neural networks. This leads to an efficientcalculation of the marginal likelihood and predictive distribution which evadessampling and the consequential increase in training time due to highly variantgradient estimates. This allows us to approximate variational Bayes for theparameters of feed-forward neural networks. Inspired by the minimum descriptionlength principle, we also propose and experimentally verify the directoptimisation of the regularised predictive distribution. The methods yieldresults competitive with previous neural network based approaches and Gaussianprocesses on a wide range of regression tasks.
arxiv-1507-05307 | 2 Notes on Classes with Vapnik-Chervonenkis Dimension 1 |  http://arxiv.org/abs/1507.05307  | author:Shai Ben-David category:cs.LG G.2; G.3 published:2015-07-19 summary:The Vapnik-Chervonenkis dimension is a combinatorial parameter that reflectsthe "complexity" of a set of sets (a.k.a. concept classes). It has beenintroduced by Vapnik and Chervonenkis in their seminal 1971 paper and has sincefound many applications, most notably in machine learning theory and incomputational geometry. Arguably the most influential consequence of the VCanalysis is the fundamental theorem of statistical machine learning, statingthat a concept class is learnable (in some precise sense) if and only if itsVC-dimension is finite. Furthermore, for such classes a most simple learningrule - empirical risk minimization (ERM) - is guaranteed to succeed. The simplest non-trivial structures, in terms of the VC-dimension, are theclasses (i.e., sets of subsets) for which that dimension is 1. In this note we show a couple of curious results concerning such classes. Thefirst result shows that such classes share a very simple structure, and, as acorollary, the labeling information contained in any sample labeled by such aclass can be compressed into a single instance. The second result shows that due to some subtle measurability issues, inspite of the above mentioned fundamental theorem, there are classes ofdimension 1 for which an ERM learning rule fails miserably.
arxiv-1507-05244 | Handwriting Recognition |  http://arxiv.org/abs/1507.05244  | author:Jayati Ghosh Dastidar, Surabhi Sarkar, Rick Punyadyuti Sinha, Kasturi Basu category:cs.CV published:2015-07-19 summary:This paper describes the method to recognize offline handwritten characters.A robust algorithm for handwriting segmentation is described here with the helpof which individual characters can be segmented from a selected word from aparagraph of handwritten text image which is given as input.
arxiv-1507-05243 | Hand Gesture Recognition Library |  http://arxiv.org/abs/1507.05243  | author:Jonathan Fidelis Paul, Dibyabiva Seth, Cijo Paul, Jayati Ghosh Dastidar category:cs.CV published:2015-07-19 summary:In this paper we have presented a hand gesture recognition library. Variousfunctions include detecting cluster count, cluster orientation, finger pointingdirection, etc. To use these functions first the input image needs to beprocessed into a logical array for which a function has been developed. Thelibrary has been developed keeping flexibility in mind and thus providesapplication developers a wide range of options to develop custom gestures.
arxiv-1507-05253 | The Population Posterior and Bayesian Inference on Streams |  http://arxiv.org/abs/1507.05253  | author:James McInerney, Rajesh Ranganath, David M. Blei category:stat.ML published:2015-07-19 summary:Many modern data analysis problems involve inferences from streaming data.However, streaming data is not easily amenable to the standard probabilisticmodeling approaches, which assume that we condition on finite data. We developpopulation variational Bayes, a new approach for using Bayesian modeling toanalyze streams of data. It approximates a new type of distribution, thepopulation posterior, which combines the notion of a population distribution ofthe data with Bayesian inference in a probabilistic model. We study our methodwith latent Dirichlet allocation and Dirichlet process mixtures on severallarge-scale data sets.
arxiv-1507-05259 | Learning Fair Classifiers |  http://arxiv.org/abs/1507.05259  | author:Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, Krishna P. Gummadi category:stat.ML cs.LG published:2015-07-19 summary:Automated data-driven decision systems are ubiquitous across a wide varietyof online services, from online social networking and e-commerce toe-government. These systems rely on complex learning methods and vast amountsof data to optimize the service functionality, satisfaction of the end user andprofitability. However, there is a growing concern that these automateddecisions can lead to user discrimination, even in the absence of intent,leading to a lack of fairness, i.e., their outcomes have a disproportionallylarge adverse impact on particular groups of people sharing one or moresensitive attributes (e.g., race, sex). In this paper, we introduce a flexiblemechanism to design fair classifiers in a principled manner, by leveraging anovel intuitive measure of decision boundary (un)fairness. Then, we instantiatethis mechanism on two well-known classifiers: logistic regression and supportvector machines. Experiments on both synthetic and real-world data show thatour mechanism allows for a fine-grained control of the level of fairness, oftenat a minimal cost in terms of accuracy, and it provides more flexibility thanalternatives.
arxiv-1507-05333 | Causal Transfer in Machine Learning |  http://arxiv.org/abs/1507.05333  | author:Mateo Rojas-Carulla, Bernhard Schölkopf, Richard Turner, Jonas Peters category:stat.ML published:2015-07-19 summary:Methods of domain adaptation try to combine knowledge from several relateddomains (or tasks) to improve performance on a test domain. Inspired by causalmethodology, we assume that the covariate shift assumption holds true for asubset of predictor variables: the conditional of the target variable giventhis subset of predictors is invariant over all tasks. We prove that in anadversarial setting using this subset for prediction is optimal if no examplesfrom the test task are observed. For a specific scenario, in which tasks aredrawn from a meta distribution, further optimality results are available. Weintroduce a practical method which allows for automatic inference of the abovesubset and provide corresponding code. We present results on synthetic datasets and a gene deletion data set.
arxiv-1507-05134 | Persistent Topology of Syntax |  http://arxiv.org/abs/1507.05134  | author:Alexander Port, Iulia Gheorghita, Daniel Guth, John M. Clark, Crystal Liang, Shival Dasu, Matilde Marcolli category:cs.CL math.AT 91F20 published:2015-07-18 summary:We study the persistent homology of the data set of syntactic parameters ofthe world languages. We show that, while homology generators behave erraticallyover the whole data set, non-trivial persistent homology appears when onerestricts to specific language families. Different families exhibit differentpersistent homology. We focus on the cases of the Indo-European and theNiger-Congo families, for which we compare persistent homology over differentcluster filtering values. We investigate the possible significance, inhistorical linguistic terms, of the presence of persistent generators of thefirst homology. In particular, we show that the persistent first homologygenerator we find in the Indo-European family is not due (as one might guess)to the Anglo-Norman bridge in the Indo-European phylogenetic network, but isrelated to the position of Ancient Greek and the Hellenic branch within thenetwork.
arxiv-1507-05181 | The Mondrian Process for Machine Learning |  http://arxiv.org/abs/1507.05181  | author:Matej Balog, Yee Whye Teh category:stat.ML cs.LG published:2015-07-18 summary:This report is concerned with the Mondrian process and its applications inmachine learning. The Mondrian process is a guillotine-partition-valuedstochastic process that possesses an elegant self-consistency property. Thefirst part of the report uses simple concepts from applied probability todefine the Mondrian process and explore its properties. The Mondrian process has been used as the main building block of a cleveronline random forest classification algorithm that turns out to be equivalentto its batch counterpart. We outline a slight adaptation of this algorithm toregression, as the remainder of the report uses regression as a case study ofhow Mondrian processes can be utilized in machine learning. In particular, theMondrian process will be used to construct a fast approximation to thecomputationally expensive kernel ridge regression problem with a Laplacekernel. The complexity of random guillotine partitions generated by a Mondrianprocess and hence the complexity of the resulting regression models iscontrolled by a lifetime hyperparameter. It turns out that these models can beefficiently trained and evaluated for all lifetimes in a given range at once,without needing to retrain them from scratch for each lifetime value. Thisleads to an efficient procedure for determining the right model complexity fora dataset at hand. The limitation of having a single lifetime hyperparameter will motivate thefinal Mondrian grid model, in which each input dimension is endowed with itsown lifetime parameter. In this model we preserve the property that itshyperparameters can be tweaked without needing to retrain the modified modelfrom scratch.
arxiv-1507-05185 | Fast Sparse Least-Squares Regression with Non-Asymptotic Guarantees |  http://arxiv.org/abs/1507.05185  | author:Tianbao Yang, Lijun Zhang, Qihang Lin, Rong Jin category:math.ST cs.CC stat.ML stat.TH published:2015-07-18 summary:In this paper, we study a fast approximation method for {\it large-scalehigh-dimensional} sparse least-squares regression problem by exploiting theJohnson-Lindenstrauss (JL) transforms, which embed a set of high-dimensionalvectors into a low-dimensional space. In particular, we propose to apply the JLtransforms to the data matrix and the target vector and then to solve a sparseleast-squares problem on the compressed data with a {\it slightly largerregularization parameter}. Theoretically, we establish the optimization errorbound of the learned model for two different sparsity-inducing regularizers,i.e., the elastic net and the $\ell_1$ norm. Compared with previous relevantwork, our analysis is {\it non-asymptotic and exhibits more insights} on thebound, the sample complexity and the regularization. As an illustration, wealso provide an error bound of the {\it Dantzig selector} under JL transforms.
arxiv-1507-05016 | Incremental Variational Inference for Latent Dirichlet Allocation |  http://arxiv.org/abs/1507.05016  | author:Cedric Archambeau, Beyza Ermis category:stat.ML published:2015-07-17 summary:We introduce incremental variational inference and apply it to latentDirichlet allocation (LDA). Incremental variational inference is inspired byincremental EM and provides an alternative to stochastic variational inference.Incremental LDA can process massive document collections, does not require toset a learning rate, converges faster to a local optimum of the variationalbound and enjoys the attractive property of monotonically increasing it. Westudy the performance of incremental LDA on large benchmark data sets. Wefurther introduce a stochastic approximation of incremental variationalinference which extends to the asynchronous distributed setting. The resultingdistributed algorithm achieves comparable performance as single hostincremental variational inference, but with a significant speed-up.
arxiv-1507-04844 | Learning Robust Deep Face Representation |  http://arxiv.org/abs/1507.04844  | author:Xiang Wu category:cs.CV published:2015-07-17 summary:With the development of convolution neural network, more and more researchersfocus their attention on the advantage of CNN for face recognition task. Inthis paper, we propose a deep convolution network for learning a robust facerepresentation. The deep convolution net is constructed by 4 convolutionlayers, 4 max pooling layers and 2 fully connected layers, which totallycontains about 4M parameters. The Max-Feature-Map activation function is usedinstead of ReLU because the ReLU might lead to the loss of information due tothe sparsity while the Max-Feature-Map can get the compact and discriminativefeature vectors. The model is trained on CASIA-WebFace dataset and evaluated onLFW dataset. The result on LFW achieves 97.77% on unsupervised setting forsingle net.
arxiv-1507-04908 | Analysis of the South Slavic Scripts by Run-Length Features of the Image Texture |  http://arxiv.org/abs/1507.04908  | author:Darko Brodic, Zoran N. Milivojevic, Alessia Amelio category:cs.CV cs.CL published:2015-07-17 summary:The paper proposes an algorithm for the script recognition based on thetexture characteristics. The image texture is achieved by coding each letterwith the equivalent script type (number code) according to its position in thetext line. Each code is transformed into equivalent gray level pixel creatingan 1-D image. Then, the image texture is subjected to the run-length analysis.This analysis extracts the run-length features, which are classified to make adistinction between the scripts under consideration. In the experiment, acustom oriented database is subject to the proposed algorithm. The databaseconsists of some text documents written in Cyrillic, Latin and Glagoliticscripts. Furthermore, it is divided into training and test parts. The resultsof the experiment show that 3 out of 5 run-length features can be used foreffective differentiation between the analyzed South Slavic scripts.
arxiv-1507-05131 | Optimal Estimation of Low Rank Density Matrices |  http://arxiv.org/abs/1507.05131  | author:Vladimir Koltchinskii, Dong Xia category:stat.ML published:2015-07-17 summary:The density matrices are positively semi-definite Hermitian matrices of unittrace that describe the state of a quantum system. The goal of the paper is todevelop minimax lower bounds on error rates of estimation of low rank densitymatrices in trace regression models used in quantum state tomography (inparticular, in the case of Pauli measurements) with explicit dependence of thebounds on the rank and other complexity parameters. Such bounds are establishedfor several statistically relevant distances, including quantum versions ofKullback-Leibler divergence (relative entropy distance) and of Hellingerdistance (so called Bures distance), and Schatten $p$-norm distances. Sharpupper bounds and oracle inequalities for least squares estimator with vonNeumann entropy penalization are obtained showing that minimax lower bounds areattained (up to logarithmic factors) for these distances.
arxiv-1507-04808 | Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models |  http://arxiv.org/abs/1507.04808  | author:Iulian V. Serban, Alessandro Sordoni, Yoshua Bengio, Aaron Courville, Joelle Pineau category:cs.CL cs.AI cs.LG cs.NE I.5.1; I.2.7 published:2015-07-17 summary:We investigate the task of building open domain, conversational dialoguesystems based on large dialogue corpora using generative models. Generativemodels produce system responses that are autonomously generated word-by-word,opening up the possibility for realistic, flexible interactions. In support ofthis goal, we extend the recently proposed hierarchical recurrentencoder-decoder neural network to the dialogue domain, and demonstrate thatthis model is competitive with state-of-the-art neural language models andback-off n-gram models. We investigate the limitations of this and similarapproaches, and show how its performance can be improved by bootstrapping thelearning from a larger question-answer pair corpus and from pretrained wordembeddings.
arxiv-1507-05087 | Type I and Type II Bayesian Methods for Sparse Signal Recovery using Scale Mixtures |  http://arxiv.org/abs/1507.05087  | author:Ritwik Giri, Bhaskar D. Rao category:cs.LG stat.ML published:2015-07-17 summary:In this paper, we propose a generalized scale mixture family ofdistributions, namely the Power Exponential Scale Mixture (PESM) family, tomodel the sparsity inducing priors currently in use for sparse signal recovery(SSR). We show that the successful and popular methods such as LASSO,Reweighted $\ell_1$ and Reweighted $\ell_2$ methods can be formulated in anunified manner in a maximum a posteriori (MAP) or Type I Bayesian frameworkusing an appropriate member of the PESM family as the sparsity inducing prior.In addition, exploiting the natural hierarchical framework induced by the PESMfamily, we utilize these priors in a Type II framework and develop thecorresponding EM based estimation algorithms. Some insight into the differencesbetween Type I and Type II methods is provided and of particular interest inthe algorithmic development is the Type II variant of the popular andsuccessful reweighted $\ell_1$ method. Extensive empirical results are providedand they show that the Type II methods exhibit better support recovery than thecorresponding Type I methods.
arxiv-1507-04910 | Lower Bounds for Multi-armed Bandit with Non-equivalent Multiple Plays |  http://arxiv.org/abs/1507.04910  | author:Aleksandr Vorobev, Gleb Gusev category:cs.LG published:2015-07-17 summary:We study the stochastic multi-armed bandit problem with non-equivalentmultiple plays where, at each step, an agent chooses not only a set of arms,but also their order, which influences reward distribution. In several problemformulations with different assumptions, we provide lower bounds for regretwith standard asymptotics $O(\log{t})$ but novel coefficients and provideoptimal algorithms, thus proving that these bounds cannot be improved.
arxiv-1507-04913 | Tree-based Visualization and Optimization for Image Collection |  http://arxiv.org/abs/1507.04913  | author:Xintong Han, Chongyang Zhang, Weiyao Lin, Mingliang Xu, Bin Sheng, Tao Mei category:cs.MM cs.AI cs.CV published:2015-07-17 summary:The visualization of an image collection is the process of displaying acollection of images on a screen under some specific layout requirements. Thispaper focuses on an important problem that is not well addressed by theprevious methods: visualizing image collections into arbitrary layout shapeswhile arranging images according to user-defined semantic or visualcorrelations (e.g., color or object category). To this end, we first propose aproperty-based tree construction scheme to organize images of a collection intoa tree structure according to user-defined properties. In this way, images canbe adaptively placed with the desired semantic or visual correlations in thefinal visualization layout. Then, we design a two-step visualizationoptimization scheme to further optimize image layouts. As a result, multiplelayout effects including layout shape and image overlap ratio can beeffectively controlled to guarantee a satisfactory visualization. Finally, wealso propose a tree-transfer scheme such that visualization layouts can beadaptively changed when users select different "images of interest". Wedemonstrate the effectiveness of our proposed approach through the comparisonswith state-of-the-art visualization techniques.
arxiv-1507-04997 | FRULER: Fuzzy Rule Learning through Evolution for Regression |  http://arxiv.org/abs/1507.04997  | author:I. Rodríguez-Fdez, M. Mucientes, A. Bugarín category:cs.LG cs.AI stat.ML published:2015-07-17 summary:In regression problems, the use of TSK fuzzy systems is widely extended dueto the precision of the obtained models. Moreover, the use of simple linear TSKmodels is a good choice in many real problems due to the easy understanding ofthe relationship between the output and input variables. In this paper wepresent FRULER, a new genetic fuzzy system for automatically learning accurateand simple linguistic TSK fuzzy rule bases for regression problems. In order toreduce the complexity of the learned models while keeping a high accuracy, thealgorithm consists of three stages: instance selection, multi-granularity fuzzydiscretization of the input variables, and the evolutionary learning of therule base that uses the Elastic Net regularization to obtain the consequents ofthe rules. Each stage was validated using 28 real-world datasets and FRULER wascompared with three state of the art enetic fuzzy systems. Experimental resultsshow that FRULER achieves the most accurate and simple models compared evenwith approximative approaches.
arxiv-1507-05033 | Classification of Complex Wishart Matrices with a Diffusion-Reaction System guided by Stochastic Distances |  http://arxiv.org/abs/1507.05033  | author:Luis Gomez, Luis Alvarez, Luis Mazorra, Alejandro C. Frery category:cs.CV published:2015-07-17 summary:We propose a new method for PolSAR (Polarimetric Synthetic Aperture Radar)imagery classification based on stochastic distances in the space of randommatrices obeying complex Wishart distributions. Given a collection ofprototypes $\{Z_m\}_{m=1}^M$ and a stochastic distance $d(.,.)$, we classifyany random matrix $X$ using two criteria in an iterative setup. Firstly, weassociate $X$ to the class which minimizes the weighted stochastic distance$w_md(X,Z_m)$, where the positive weights $w_m$ are computed to maximize theclass discrimination power. Secondly, we improve the result by embedding theclassification problem into a diffusion-reaction partial differential systemwhere the diffusion term smooths the patches within the image, and the reactionterm tends to move the pixel values towards the closest class prototype. Inparticular, the method inherits the benefits of speckle reduction bydiffusion-like methods. Results on synthetic and real PolSAR data show theperformance of the method.
arxiv-1507-04886 | Distinguishing short and long $Fermi$ gamma-ray bursts |  http://arxiv.org/abs/1507.04886  | author:Mariusz Tarnopolski category:astro-ph.HE astro-ph.CO stat.ML published:2015-07-17 summary:Two classes of gamma-ray bursts (GRBs), short and long, have been determinedwithout any doubts, and are usually ascribed to different progenitors, yetthese classes overlap for a variety of descriptive parameters. A subsample of46 long and 22 short $Fermi$ GRBs with estimated Hurst Exponents (HEs),complemented by minimum variability time-scales (MVTS) and durations ($T_{90}$)is used to perform a supervised Machine Learning (ML) and Monte Carlo (MC)simulation using a Support Vector Machine (SVM) algorithm. It is found thatwhile $T_{90}$ itself performs very well in distinguishing short and long GRBs,the overall success ratio is higher when the training set is complemented byMVTS and HE. These results may allow to introduce a new (non-linear) parameterthat might provide less ambiguous classification of GRBs.
arxiv-1507-04888 | Maximum Entropy Deep Inverse Reinforcement Learning |  http://arxiv.org/abs/1507.04888  | author:Markus Wulfmeier, Peter Ondruska, Ingmar Posner category:cs.LG published:2015-07-17 summary:This paper presents a general framework for exploiting the representationalcapacity of neural networks to approximate complex, nonlinear reward functionsin the context of solving the inverse reinforcement learning (IRL) problem. Weshow in this context that the Maximum Entropy paradigm for IRL lends itselfnaturally to the efficient training of deep architectures. At test time, theapproach leads to a computational complexity independent of the number ofdemonstrations, which makes it especially well-suited for applications inlife-long learning scenarios. Our approach achieves performance commensurate tothe state-of-the-art on existing benchmarks while exceeding on an alternativebenchmark based on highly varying reward structures. Finally, we extend thebasic architecture - which is equivalent to a simplified subclass of FullyConvolutional Neural Networks (FCNNs) with width one - to include largerconvolutions in order to eliminate dependency on precomputed spatial featuresand work on raw input representations.
arxiv-1507-05053 | Massively Deep Artificial Neural Networks for Handwritten Digit Recognition |  http://arxiv.org/abs/1507.05053  | author:Keiron O'Shea category:cs.CV cs.LG cs.NE published:2015-07-17 summary:Greedy Restrictive Boltzmann Machines yield an fairly low 0.72% error rate onthe famous MNIST database of handwritten digits. All that was required toachieve this result was a high number of hidden layers consisting of manyneurons, and a graphics card to greatly speed up the rate of learning.
arxiv-1507-05073 | Sequential Quantiles via Hermite Series Density Estimation |  http://arxiv.org/abs/1507.05073  | author:Michael Stephanou, Melvin Varughese, Iain Macdonald category:stat.CO stat.ML published:2015-07-17 summary:Sequential quantile estimation refers to incorporating observations intoquantile estimates in an incremental fashion thus furnishing an online estimateof one or more quantiles at any given point in time. Sequential quantileestimation is also known as online quantile estimation. This area is relevantto the analysis of data streams and to the one-pass analysis of massive datasets. Applications include network traffic and latency analysis, real timefraud detection and high frequency trading. We introduce new techniques forsequential quantile estimation based on Hermite series estimators in thesettings of static quantile estimation and dynamic quantile estimation. In thestatic quantile estimation setting we apply the existing Gauss-Hermiteexpansion in a novel manner. In particular, we exploit the fact thatGauss-Hermite coefficients can be updated in a sequential manner. To treatdynamic quantile estimation we introduce a novel expansion with anexponentially weighted estimator for the Gauss-Hermite coefficients which weterm the Exponentially Weighted Gauss-Hermite (EWGH) expansion. Thesealgorithms go beyond existing sequential quantile estimation algorithms in thatthey allow arbitrary quantiles (as opposed to pre-specified quantiles) to beestimated at any point in time. In doing so we solve the more general problemof estimating probability densities and cumulative distribution functions ondata streams. In particular we derive an analytical expression for the CDF andprove consistency results for the PDF and CDF under certain conditions.Simulation studies and tests on real data reveal the Gauss-Hermite basedalgorithms to be competitive with a leading existing algorithm.
arxiv-1507-04835 | Multiscale Adaptive Representation of Signals: I. The Basic Framework |  http://arxiv.org/abs/1507.04835  | author:Cheng Tai, Weinan E category:cs.CV published:2015-07-17 summary:We introduce a framework for designing multi-scale, adaptive, shift-invariantframes and bi-frames for representing signals. The new framework, calledAdaFrame, improves over dictionary learning-based techniques in terms ofcomputational efficiency at inference time. It improves classical multi-scalebasis such as wavelet frames in terms of coding efficiency. It provides anattractive alternative to dictionary learning-based techniques for low levelsignal processing tasks, such as compression and denoising, as well as highlevel tasks, such as feature extraction for object recognition. Connectionswith deep convolutional networks are also discussed. In particular, theproposed framework reveals a drawback in the commonly used approach forvisualizing the activations of the intermediate layers in convolutionalnetworks, and suggests a natural alternative.
arxiv-1507-04831 | Deep Multimodal Speaker Naming |  http://arxiv.org/abs/1507.04831  | author:Yongtao Hu, Jimmy Ren, Jingwen Dai, Chang Yuan, Li Xu, Wenping Wang category:cs.CV cs.LG cs.MM cs.SD H.3 published:2015-07-17 summary:Automatic speaker naming is the problem of localizing as well as identifyingeach speaking character in a TV/movie/live show video. This is a challengingproblem mainly attributes to its multimodal nature, namely face cue alone isinsufficient to achieve good performance. Previous multimodal approaches tothis problem usually process the data of different modalities individually andmerge them using handcrafted heuristics. Such approaches work well for simplescenes, but fail to achieve high performance for speakers with large appearancevariations. In this paper, we propose a novel convolutional neural networks(CNN) based learning framework to automatically learn the fusion function ofboth face and audio cues. We show that without using face tracking, faciallandmark localization or subtitle/transcript, our system with robust multimodalfeature extraction is able to achieve state-of-the-art speaker namingperformance evaluated on two diverse TV series. The dataset and implementationof our algorithm are publicly available online.
arxiv-1507-04816 | RBIR Based on Signature Graph |  http://arxiv.org/abs/1507.04816  | author:Thanh The Van, Thanh Manh Le category:cs.CV published:2015-07-17 summary:This paper approaches the image retrieval system on the base of visualfeatures local region RBIR (region-based image retrieval). First of all, thepaper presents a method for extracting the interest points based onHarris-Laplace to create the feature region of the image. Next, in order toreduce the storage space and speed up query image, the paper builds the binarysignature structure to describe the visual content of image. Based on theimage's binary signature, the paper builds the SG (signature graph) to classifyand store image's binary signatures. Since then, the paper builds the imageretrieval algorithm on SG through the similar measure EMD (earth mover'sdistance) between the image's binary signatures. Last but not least, the papergives an image retrieval model RBIR, experiments and assesses the imageretrieval method on Corel image database over 10,000 images.
arxiv-1507-05117 | Fast Approximate Bayesian Computation for Estimating Parameters in Differential Equations |  http://arxiv.org/abs/1507.05117  | author:Sanmitra Ghosh, Srinandan Dasmahapatra, Koushik Maharatna category:stat.ML published:2015-07-17 summary:Approximate Bayesian computation (ABC) using a sequential Monte Carlo methodprovides a comprehensive platform for parameter estimation, model selection andsensitivity analysis in differential equations. However, this method, likeother Monte Carlo methods, incurs a significant computational cost as itrequires explicit numerical integration of differential equations to carry outinference. In this paper we propose a novel method for circumventing therequirement of explicit integration by using derivatives of Gaussian processesto smooth the observations from which parameters are estimated. We evaluate ourmethods using synthetic data generated from model biological systems describedby ordinary and delay differential equations. Upon comparing the performance ofour method to existing ABC techniques, we demonstrate that it producescomparably reliable parameter estimates at a significantly reduced executiontime.
arxiv-1507-05086 | Parallel Correlation Clustering on Big Graphs |  http://arxiv.org/abs/1507.05086  | author:Xinghao Pan, Dimitris Papailiopoulos, Samet Oymak, Benjamin Recht, Kannan Ramchandran, Michael I. Jordan category:cs.DC cs.DS stat.ML published:2015-07-17 summary:Given a similarity graph between items, correlation clustering (CC) groupssimilar items together and dissimilar ones apart. One of the most popular CCalgorithms is KwikCluster: an algorithm that serially clusters neighborhoods ofvertices, and obtains a 3-approximation ratio. Unfortunately, KwikCluster inpractice requires a large number of clustering rounds, a potential bottleneckfor large graphs. We present C4 and ClusterWild!, two algorithms for parallel correlationclustering that run in a polylogarithmic number of rounds and achieve nearlylinear speedups, provably. C4 uses concurrency control to enforceserializability of a parallel clustering process, and guarantees a3-approximation ratio. ClusterWild! is a coordination free algorithm thatabandons consistency for the benefit of better scaling; this leads to aprovably small loss in the 3-approximation ratio. We provide extensive experimental results for both algorithms, where weoutperform the state of the art, both in terms of clustering accuracy andrunning time. We show that our algorithms can cluster billion-edge graphs inunder 5 seconds on 32 cores, while achieving a 15x speedup.
arxiv-1509-03557 | Estimating Absolute-Phase Maps Using ESPIRiT and Virtual Conjugate Coils |  http://arxiv.org/abs/1509.03557  | author:Martin Uecker, Michael Lustig category:cs.CV cs.CE physics.med-ph published:2015-07-17 summary:Purpose: To develop an ESPIRiT-based method to estimate coil sensitivitieswith image phase as a building block for efficient and robust imagereconstruction with phase constraints. Theory and Methods: ESPIRiT is a newframework for calibration of the coil sensitivities and reconstruction inparallel Magnetic Resonance Imaging (MRI). Applying ESPIRiT to a combined setof physical and virtual conjugate coils (VCC-ESPIRiT) implicitly exploitsconjugate symmetry in k-space similar to VCC-GRAPPA. Based on this method, anew post-processing step is proposed for the explicit computation of coilsensitivities that include the absolute phase of the image. The accuracy of thecomputed maps is directly validated using a test based on projection onto fullysampled coil images and also indirectly in phase-constrained parallel-imagingreconstructions. Results: The proposed method can estimate accuratesensitivities which include low-resolution image phase. In case ofhigh-frequency phase variations VCC-ESPIRiT yields an additional set of mapsthat indicates the existence of a high-frequency phase component. Taking thisadditional set of maps into account can improve the robustness ofphase-constrained parallel imaging. Conclusion: The extended VCC-ESPIRiT is auseful tool for phase-constrained imaging.
arxiv-1507-04734 | Variational Gram Functions: Convex Analysis and Optimization |  http://arxiv.org/abs/1507.04734  | author:Amin Jalali, Lin Xiao, Maryam Fazel category:math.OC cs.LG stat.ML published:2015-07-16 summary:We propose a new class of convex penalty functions, called variational Gramfunctions (VGFs), that can promote pairwise relations, such as orthogonality,among a set of vectors in a vector space. When used as regularizers in convexoptimization problems, these functions find application in hierarchicalclassification, multitask learning, and estimation of vectors with disjointsupports, among other applications. We describe a general condition forconvexity, which is then used to prove the convexity of a few known functionsas well as some new ones. We give a characterization of the associatedsubdifferential and the proximal operator, and discuss efficient optimizationalgorithms for some structured regularized loss-minimization problems usingVGFs. Numerical experiments on a hierarchical classification problem are alsopresented that demonstrate the effectiveness of VGFs and the associatedoptimization algorithms in practice.
arxiv-1507-04777 | Sparse Estimation in a Correlated Probit Model |  http://arxiv.org/abs/1507.04777  | author:Stephan Mandt, Florian Wenzel, Shinichi Nakajima, John P. Cunningham, Christoph Lippert, Marius Kloft category:stat.ML cs.LG published:2015-07-16 summary:Among the goals of statistical genetics is to find associations betweengenetic data and binary phenotypes, such as heritable diseases. Often, the dataare obfuscated by confounders such as age, ethnicity, or population structure.Linear mixed models are linear regression models that correct for confoundingby means of correlated label noise; they are widely appreciated in the field ofstatistical genetics. We generalize this modeling paradigm to binaryclassification, where we face the problem that marginalizing over the noiseleads to an intractable, high-dimensional integral. We present a scalable,approximate inference algorithm that lets us fit the model to high-dimensionaldata sets. The algorithm selects features based on an $\ell_1$ norm regularizerwhich are up to 40% less confounded compared to the outcomes of uncorrectedfeature selection, as we show. The proposed method also outperforms Gaussianprocess classification and uncorrelated probit regression in terms ofprediction performance.
arxiv-1507-04727 | Recursive Sparse Point Process Regression with Application to Spectrotemporal Receptive Field Plasticity Analysis |  http://arxiv.org/abs/1507.04727  | author:Alireza Sheikhattar, Jonathan B. Fritz, Shihab A. Shamma, Behtash Babadi category:cs.NE cs.SY math.OC stat.AP stat.CO published:2015-07-16 summary:We consider the problem of estimating the sparse time-varying parametervectors of a point process model in an online fashion, where the observationsand inputs respectively consist of binary and continuous time series. Weconstruct a novel objective function by incorporating a forgetting factormechanism into the point process log-likelihood to enforce adaptivity andemploy $\ell_1$-regularization to capture the sparsity. We provide a rigorousanalysis of the maximizers of the objective function, which extends theguarantees of compressed sensing to our setting. We construct two recursivefilters for online estimation of the parameter vectors based on proximaloptimization techniques, as well as a novel filter for recursive computation ofstatistical confidence regions. Simulation studies reveal that our algorithmsoutperform several existing point process filters in terms of trackability,goodness-of-fit and mean square error. We finally apply our filteringalgorithms to experimentally recorded spiking data from the ferret primaryauditory cortex during attentive behavior in a click rate discrimination task.Our analysis provides new insights into the time-course of the spectrotemporalreceptive field plasticity of the auditory neurons.
arxiv-1507-04646 | A Dependency-Based Neural Network for Relation Classification |  http://arxiv.org/abs/1507.04646  | author:Yang Liu, Furu Wei, Sujian Li, Heng Ji, Ming Zhou, Houfeng Wang category:cs.CL cs.LG cs.NE published:2015-07-16 summary:Previous research on relation classification has verified the effectivenessof using dependency shortest paths or subtrees. In this paper, we furtherexplore how to make full use of the combination of these dependencyinformation. We first propose a new structure, termed augmented dependency path(ADP), which is composed of the shortest dependency path between two entitiesand the subtrees attached to the shortest path. To exploit the semanticrepresentation behind the ADP structure, we develop dependency-based neuralnetworks (DepNN): a recursive neural network designed to model the subtrees,and a convolutional neural network to capture the most important features onthe shortest path. Experiments on the SemEval-2010 dataset show that ourproposed method achieves state-of-art results.
arxiv-1507-04564 | Ordinal optimization - empirical large deviations rate estimators, and stochastic multi-armed bandits |  http://arxiv.org/abs/1507.04564  | author:Peter Glynn, Sandeep Juneja category:math.PR stat.ML 65C05, 60-08 published:2015-07-16 summary:Consider the ordinal optimization problem of finding a population amongstmany with the smallest mean when these means are unknown but population samplescan be generated via simulation. Typically, by selecting a population with thesmallest sample mean, it can be shown that the false selection probabilitydecays at an exponential rate. Lately researchers have sought algorithms thatguarantee that this probability is restricted to a small $\delta$ in order$\log(1/\delta)$ computational time by estimating the associated largedeviations rate function via simulation. We show that such guarantees aremisleading. Enroute, we identify the large deviations principle followed by theempirically estimated large deviations rate function that may also be ofindependent interest. Further, we show a negative result that when populationshave unbounded support, any policy that asymptotically identifies the correctpopulation with probability at least $1-\delta$ for each problem instancerequires more than $O(\log(1/\delta))$ samples in making such a determinationin any problem instance. This suggests that some restrictions are essential onpopulations to devise $O(\log(1/\delta))$ algorithms with $1 - \delta$correctness guarantees. We note that under restriction on population moments,such methods are easily designed. We also observe that sequential methods fromstochastic multi-armed bandit literature can be adapted to devise suchalgorithms.
arxiv-1507-04523 | Upper-Confidence-Bound Algorithms for Active Learning in Multi-Armed Bandits |  http://arxiv.org/abs/1507.04523  | author:Alexandra Carpentier, Alessandro Lazaric, Mohammad Ghavamzadeh, Rémi Munos, Peter Auer, András Antos category:cs.LG G.3 published:2015-07-16 summary:In this paper, we study the problem of estimating uniformly well the meanvalues of several distributions given a finite budget of samples. If thevariance of the distributions were known, one could design an optimal samplingstrategy by collecting a number of independent samples per distribution that isproportional to their variance. However, in the more realistic case where thedistributions are not known in advance, one needs to design adaptive samplingstrategies in order to select which distribution to sample from according tothe previously observed samples. We describe two strategies based on pullingthe distributions a number of times that is proportional to a high-probabilityupper-confidence-bound on their variance (built from previous observed samples)and report a finite-sample performance analysis on the excess estimation errorcompared to the optimal allocation. We show that the performance of theseallocation strategies depends not only on the variances but also on the fullshape of the distributions.
arxiv-1507-04717 | Less is More: Nyström Computational Regularization |  http://arxiv.org/abs/1507.04717  | author:Alessandro Rudi, Raffaello Camoriano, Lorenzo Rosasco category:stat.ML cs.LG published:2015-07-16 summary:We study Nystr\"om type subsampling approaches to large scale kernel methods,and prove learning bounds in the statistical learning setting, where randomsampling and high probability estimates are considered. In particular, we provethat these approaches can achieve optimal learning bounds, provided thesubsampling level is suitably chosen. These results suggest a simpleincremental variant of Nystr\"om Kernel Regularized Least Squares, where thesubsampling level implements a form of computational regularization, in thesense that it controls at the same time regularization and computations.Extensive experimental analysis shows that the considered approach achievesstate of the art performances on benchmark large scale datasets.
arxiv-1507-04513 | Scalable Gaussian Process Classification via Expectation Propagation |  http://arxiv.org/abs/1507.04513  | author:Daniel Hernández-Lobato, José Miguel Hernández-Lobato category:stat.ML published:2015-07-16 summary:Variational methods have been recently considered for scaling the trainingprocess of Gaussian process classifiers to large datasets. As an alternative,we describe here how to train these classifiers efficiently using expectationpropagation. The proposed method allows for handling datasets with millions ofdata instances. More precisely, it can be used for (i) training in adistributed fashion where the data instances are sent to different nodes inwhich the required computations are carried out, and for (ii) maximizing anestimate of the marginal likelihood using a stochastic approximation of thegradient. Several experiments indicate that the method described is competitivewith the variational approach.
arxiv-1507-04512 | Diagnosing State-Of-The-Art Object Proposal Methods |  http://arxiv.org/abs/1507.04512  | author:Hongyuan Zhu, Shijian Lu, Jianfei Cai, Quangqing Lee category:cs.CV published:2015-07-16 summary:Object proposal has become a popular paradigm to replace exhaustive slidingwindow search in current top-performing methods in PASCAL VOC and ImageNet.Recently, Hosang et al. conduct the first unified study of existing methods' interms of various image-level degradations. On the other hand, the vitalquestion "what object-level characteristics really affect existing methods'performance?" is not yet answered. Inspired by Hoiem et al.'s work incategorical object detection, this paper conducts the first meta-analysis ofvarious object-level characteristics' impact on state-of-the-art objectproposal methods. Specifically, we examine the effects of object size, aspectratio, iconic view, color contrast, shape regularity and texture. We alsoanalyse existing methods' localization accuracy and latency for various PASCALVOC object classes. Our study reveals the limitations of existing methods interms of non-iconic view, small object size, low color contrast, shaperegularity etc. Based on our observations, lessons are also learned and sharedwith respect to the selection of existing object proposal technologies as wellas the design of the future ones.
arxiv-1507-04505 | On the Convergence of Stochastic Variational Inference in Bayesian Networks |  http://arxiv.org/abs/1507.04505  | author:Ulrich Paquet category:stat.ML published:2015-07-16 summary:We highlight a pitfall when applying stochastic variational inference togeneral Bayesian networks. For global random variables approximated by anexponential family distribution, natural gradient steps, commonly starting froma unit length step size, are averaged to convergence. This useful insight intothe scaling of initial step sizes is lost when the approximation factorizesacross a general Bayesian network, and care must be taken to ensure practicalconvergence. We experimentally investigate how much of the baby (well-scaledsteps) is thrown out with the bath water (exact gradients).
arxiv-1507-04502 | Towards Predicting First Daily Departure Times: a Gaussian Modeling Approach for Load Shift Forecasting |  http://arxiv.org/abs/1507.04502  | author:Nicholas H. Kirk, Ilya Dianov category:cs.LG published:2015-07-16 summary:This work provides two statistical Gaussian forecasting methods forpredicting First Daily Departure Times (FDDTs) of everyday use electricvehicles. This is important in smart grid applications to understanddisconnection times of such mobile storage units, for instance to forecaststorage of non dispatchable loads (e.g. wind and solar power). We provide areview of the relevant state-of-the-art driving behavior features towards FDDTprediction, to then propose an approximated Gaussian method which qualitativelyforecasts how many vehicles will depart within a given time frame, by assumingthat departure times follow a normal distribution. This method considerssampling sessions as Poisson distributions which are superimposed to obtain asingle approximated Gaussian model. Given the Gaussian distribution assumptionof the departure times, we also model the problem with Gaussian Mixture Models(GMM), in which the priorly set number of clusters represents the desired timegranularity. Evaluation has proven that for the dataset tested, low error andhigh confidence ($\approx 95\%$) is possible for 15 and 10 minute intervals,and that GMM outperforms traditional modeling but is less generalizable acrossdatasets, as it is a closer fit to the sampling data. Conclusively we discussfuture possibilities and practical applications of the discussed model.
arxiv-1507-04540 | Learning to classify with possible sensor failures |  http://arxiv.org/abs/1507.04540  | author:Tianpei Xie, Nasser M. Nasrabadi, Alfred O. Hero category:cs.LG cs.IT math.IT stat.ML published:2015-07-16 summary:In this paper, we propose a general framework to learn a robust large-marginbinary classifier when corrupt measurements, called anomalies, caused by sensorfailure might be present in the training set. The goal is to minimize thegeneralization error of the classifier on non-corrupted measurements whilecontrolling the false alarm rate associated with anomalous samples. Byincorporating a non-parametric regularizer based on an empirical entropyestimator, we propose a Geometric-Entropy-Minimization regularized MaximumEntropy Discrimination (GEM-MED) method to learn to classify and detectanomalies in a joint manner. We demonstrate using simulated data and a realmultimodal data set. Our GEM-MED method can yield improved performance overprevious robust classification methods in terms of both classification accuracyand anomaly detection rate.
arxiv-1507-04798 | Exploratory topic modeling with distributional semantics |  http://arxiv.org/abs/1507.04798  | author:Samuel Rönnqvist category:cs.IR cs.CL cs.LG published:2015-07-16 summary:As we continue to collect and store textual data in a multitude of domains,we are regularly confronted with material whose largely unknown thematicstructure we want to uncover. With unsupervised, exploratory analysis, no priorknowledge about the content is required and highly open-ended tasks can besupported. In the past few years, probabilistic topic modeling has emerged as apopular approach to this problem. Nevertheless, the representation of thelatent topics as aggregations of semi-coherent terms limits theirinterpretability and level of detail. This paper presents an alternative approach to topic modeling that mapstopics as a network for exploration, based on distributional semantics usinglearned word vectors. From the granular level of terms and their semanticsimilarity relations global topic structures emerge as clustered regions andgradients of concepts. Moreover, the paper discusses the visual interactiverepresentation of the topic map, which plays an important role in supportingits exploration.
arxiv-1507-04793 | Sharp Time--Data Tradeoffs for Linear Inverse Problems |  http://arxiv.org/abs/1507.04793  | author:Samet Oymak, Benjamin Recht, Mahdi Soltanolkotabi category:cs.IT cs.LG math.IT math.OC math.ST stat.TH published:2015-07-16 summary:In this paper we characterize sharp time-data tradeoffs for optimizationproblems used for solving linear inverse problems. We focus on the minimizationof a least-squares objective subject to a constraint defined as the sub-levelset of a penalty function. We present a unified convergence analysis of thegradient projection algorithm applied to such problems. We sharply characterizethe convergence rate associated with a wide variety of random measurementensembles in terms of the number of measurements and structural complexity ofthe signal with respect to the chosen penalty function. The results apply toboth convex and nonconvex constraints, demonstrating that a linear convergencerate is attainable even though the least squares objective is not stronglyconvex in these settings. When specialized to Gaussian measurements our resultsshow that such linear convergence occurs when the number of measurements ismerely 4 times the minimal number required to recover the desired signal at all(a.k.a. the phase transition). We also achieve a slower but geometric rate ofconvergence precisely above the phase transition point. Extensive numericalresults suggest that the derived rates exactly match the empirical performance.
arxiv-1507-04457 | Preference Completion: Large-scale Collaborative Ranking from Pairwise Comparisons |  http://arxiv.org/abs/1507.04457  | author:Dohyung Park, Joe Neeman, Jin Zhang, Sujay Sanghavi, Inderjit S. Dhillon category:stat.ML cs.LG published:2015-07-16 summary:In this paper we consider the collaborative ranking setting: a pool of userseach provides a small number of pairwise preferences between $d$ possibleitems; from these we need to predict preferences of the users for items theyhave not yet seen. We do so by fitting a rank $r$ score matrix to the pairwisedata, and provide two main contributions: (a) we show that an algorithm basedon convex optimization provides good generalization guarantees once each userprovides as few as $O(r\log^2 d)$ pairwise comparisons -- essentially matchingthe sample complexity required in the related matrix completion setting (whichuses actual numerical as opposed to pairwise information), and (b) we develop alarge-scale non-convex implementation, which we call AltSVM, that trains afactored form of the matrix via alternating minimization (which we show reducesto alternating SVM problems), and scales and parallelizes very well to largeproblem settings. It also outperforms common baselines on many moderately largepopular collaborative filtering datasets in both NDCG and in other measures ofranking performance.
arxiv-1507-04437 | A Deep Hashing Learning Network |  http://arxiv.org/abs/1507.04437  | author:Guoqiang Zhong, Pan Yang, Sijiang Wang, Junyu Dong category:cs.CV published:2015-07-16 summary:Hashing-based methods seek compact and efficient binary codes that preservethe neighborhood structure in the original data space. For most existinghashing methods, an image is first encoded as a vector of hand-crafted visualfeature, followed by a hash projection and quantization step to get the compactbinary vector. Most of the hand-crafted features just encode the low-levelinformation of the input, the feature may not preserve the semanticsimilarities of images pairs. Meanwhile, the hashing function learning processis independent with the feature representation, so the feature may not beoptimal for the hashing projection. In this paper, we propose a supervisedhashing method based on a well designed deep convolutional neural network,which tries to learn hashing code and compact representations of datasimultaneously. The proposed model learn the binary codes by adding a compactsigmoid layer before the loss layer. Experiments on several image data setsshow that the proposed model outperforms other state-of-the-art methods.
arxiv-1507-04436 | Joint Tensor Factorization and Outlying Slab Suppression with Applications |  http://arxiv.org/abs/1507.04436  | author:Xiao Fu, Kejun Huang, Wing-Kin Ma, Nicholas D. Sidiropoulos, Rasmus Bro category:stat.ML published:2015-07-16 summary:We consider factoring low-rank tensors in the presence of outlying slabs.This problem is important in practice, because data collected in manyreal-world applications, such as speech, fluorescence, and some social networkdata, fit this paradigm. Prior work tackles this problem by iterativelyselecting a fixed number of slabs and fitting, a procedure which may notconverge. We formulate this problem from a group-sparsity promoting point ofview, and propose an alternating optimization framework to handle thecorresponding $\ell_p$ ($0<p\leq 1$) minimization-based low-rank tensorfactorization problem. The proposed algorithm features a similar per-iterationcomplexity as the plain trilinear alternating least squares (TALS) algorithm.Convergence of the proposed algorithm is also easy to analyze under theframework of alternating optimization and its variants. In addition,regularization and constraints can be easily incorporated to make use of\emph{a priori} information on the latent loading factors. Simulations and realdata experiments on blind speech separation, fluorescence data analysis, andsocial network mining are used to showcase the effectiveness of the proposedalgorithm.
arxiv-1507-04635 | Black-Box Policy Search with Probabilistic Programs |  http://arxiv.org/abs/1507.04635  | author:Jan-Willem van de Meent, David Tolpin, Brooks Paige, Frank Wood category:stat.ML cs.AI published:2015-07-16 summary:In this work, we explore how probabilistic programs can be used to representpolicies in sequential decision problems. In this formulation, a probabilisticprogram is a black-box stochastic simulator for both the problem domain and theagent. We relate classic policy gradient techniques to recently introducedblack-box variational methods which generalize to probabilistic programinference. We present case studies in the Canadian traveler problem, RockSample, and a benchmark for optimal diagnosis inspired by Guess Who. Each studyillustrates how programs can efficiently represent policies using moderatenumbers of parameters.
arxiv-1507-04760 | Driver Gaze Region Estimation Without Using Eye Movement |  http://arxiv.org/abs/1507.04760  | author:Lex Fridman, Philipp Langhans, Joonbum Lee, Bryan Reimer category:cs.CV published:2015-07-16 summary:Automated estimation of the allocation of a driver's visual attention may bea critical component of future Advanced Driver Assistance Systems. In theory,vision-based tracking of the eye can provide a good estimate of gaze location.In practice, eye tracking from video is challenging because of sunglasses,eyeglass reflections, lighting conditions, occlusions, motion blur, and otherfactors. Estimation of head pose, on the other hand, is robust to many of theseeffects, but cannot provide as fine-grained of a resolution in localizing thegaze. However, for the purpose of keeping the driver safe, it is sufficient topartition gaze into regions. In this effort, we propose a system that extractsfacial features and classifies their spatial configuration into six regions inreal-time. Our proposed method achieves an average accuracy of 91.4% at anaverage decision rate of 11 Hz on a dataset of 50 drivers from an on-roadstudy.
arxiv-1507-04576 | Multi-Face Tracking by Extended Bag-of-Tracklets in Egocentric Videos |  http://arxiv.org/abs/1507.04576  | author:Maedeh Aghaei, Mariella Dimiccoli, Petia Radeva category:cs.CV published:2015-07-16 summary:Wearable cameras offer a hands-free way to record egocentric images of dailyexperiences, where social events are of special interest. The first steptowards detection of social events is to track the appearance of multiplepersons involved in it. In this paper, we propose a novel method to findcorrespondences of multiple faces in low temporal resolution egocentric videosacquired through a wearable camera. This kind of photo-stream imposesadditional challenges to the multi-tracking problem with respect toconventional videos. Due to the free motion of the camera and to its lowtemporal resolution, abrupt changes in the field of view, in illuminationcondition and in the target location are highly frequent. To overcome suchdifficulties, we propose a multi-face tracking method that generates a set oftracklets through finding correspondences along the whole sequence for eachdetected face and takes advantage of the tracklets redundancy to deal withunreliable ones. Similar tracklets are grouped into the so called extendedbag-of-tracklets (eBoT), which is aimed to correspond to a specific person.Finally, a prototype tracklet is extracted for each eBoT, where the occurredocclusions are estimated by relying on a new measure of confidence. Wevalidated our approach over an extensive dataset of egocentric photo-streamsand compared it to state of the art methods, demonstrating its effectivenessand robustness.
arxiv-1507-04420 | Bias and population structure in the actuation of sound change |  http://arxiv.org/abs/1507.04420  | author:James Kirby, Morgan Sonderegger category:cs.CL physics.soc-ph published:2015-07-16 summary:Why do human languages change at some times, and not others? We address thislongstanding question from a computational perspective, focusing on the case ofsound change. Sound change arises from the pronunciation variability ubiquitousin every speech community, but most such variability does not lead to change.Hence, an adequate model must allow for stability as well as change. Existingtheories of sound change tend to emphasize factors at the level of individuallearners promoting one outcome or the other, such as channel bias (which favorschange) or inductive bias (which favors stability). Here, we consider how theinteraction of these biases can lead to both stability and change in apopulation setting. We find that population structure itself can act as asource of stability, but that both stability and change are possible only whenboth types of bias are active, suggesting that it is possible to understand whysound change occurs at some times and not others as the population-level resultof the interplay between forces promoting each outcome in individual speakers.In addition, if it is assumed that learners learn from two or more teachers,the transition from stability to change is marked by a phase transition,consistent with the abrupt transitions seen in many empirical cases of soundchange. The predictions of multiple-teacher models thus match empirical casesof sound change better than the predictions of single-teacher models,underscoring the importance of modeling language change in a populationsetting.
arxiv-1507-04761 | Deep Learning and Music Adversaries |  http://arxiv.org/abs/1507.04761  | author:Corey Kereliuk, Bob L. Sturm, Jan Larsen category:cs.LG cs.NE cs.SD published:2015-07-16 summary:An adversary is essentially an algorithm intent on making a classificationsystem perform in some particular way given an input, e.g., increase theprobability of a false negative. Recent work builds adversaries for deeplearning systems applied to image object recognition, which exploits theparameters of the system to find the minimal perturbation of the input imagesuch that the network misclassifies it with high confidence. We adapt thisapproach to construct and deploy an adversary of deep learning systems appliedto music content analysis. In our case, however, the input to the systems ismagnitude spectral frames, which requires special care in order to producevalid input audio signals from network-derived perturbations. For two differenttrain-test partitionings of two benchmark datasets, and two different deeparchitectures, we find that this adversary is very effective in defeating theresulting systems. We find the convolutional networks are more robust, however,compared with systems based on a majority vote over individually classifiedaudio frames. Furthermore, we integrate the adversary into the training of newdeep systems, but do not find that this improves their resilience against thesame adversary.
arxiv-1507-04201 | Minimum Density Hyperplanes |  http://arxiv.org/abs/1507.04201  | author:Nicos Pavlidis, David Hofmeyr, Sotiris Tasoulis category:stat.ML cs.LG 62H30, 68T10 published:2015-07-15 summary:Associating distinct groups of objects (clusters) with contiguous regions ofhigh probability density (high-density clusters), is central to manystatistical and machine learning approaches to the classification of unlabelleddata. We propose a novel hyperplane classifier for clustering andsemi-supervised classification which is motivated by this objective. Theproposed minimum density hyperplane minimises the integral of the empiricalprobability density function along it, thereby avoiding intersection with highdensity clusters. We show that the minimum density and the maximum marginhyperplanes are asymptotically equivalent, thus linking this approach tomaximum margin clustering and semi-supervised support vector classifiers. Wepropose a projection pursuit formulation of the associated optimisation problemwhich allows us to find minimum density hyperplanes efficiently in practice,and evaluate its performance on a range of benchmark datasets. The proposedapproach is found to be very competitive with state of the art methods forclustering and semi-supervised classification.
arxiv-1507-04155 | ALEVS: Active Learning by Statistical Leverage Sampling |  http://arxiv.org/abs/1507.04155  | author:Cem Orhan, Öznur Taştan category:cs.LG stat.ML published:2015-07-15 summary:Active learning aims to obtain a classifier of high accuracy by using fewerlabel requests in comparison to passive learning by selecting effectivequeries. Many active learning methods have been developed in the past twodecades, which sample queries based on informativeness or representativeness ofunlabeled data points. In this work, we explore a novel querying criterionbased on statistical leverage scores. The statistical leverage scores of a rowin a matrix are the squared row-norms of the matrix containing its (top) leftsingular vectors and is a measure of influence of the row on the matrix.Leverage scores have been used for detecting high influential points inregression diagnostics and have been recently shown to be useful for dataanalysis and randomized low-rank matrix approximation algorithms. We explorehow sampling data instances with high statistical leverage scores perform inactive learning. Our empirical comparison on several binary classificationdatasets indicate that querying high leverage points is an effective strategy.
arxiv-1507-04126 | Revisiting AdaBoost for Cost-Sensitive Classification. Part II: Empirical Analysis |  http://arxiv.org/abs/1507.04126  | author:Iago Landesa-Vázquez, José Luis Alba-Castro category:cs.CV cs.AI cs.LG published:2015-07-15 summary:A lot of approaches, each following a different strategy, have been proposedin the literature to provide AdaBoost with cost-sensitive properties. In thefirst part of this series of two papers, we have presented these algorithms ina homogeneous notational framework, proposed a clustering scheme for them andperformed a thorough theoretical analysis of those approaches with a fullytheoretical foundation. The present paper, in order to complete our analysis,is focused on the empirical study of all the algorithms previously presentedover a wide range of heterogeneous classification problems. The results of ourexperiments, confirming the theoretical conclusions, seem to reveal that thesimplest approach, just based on cost-sensitive weight initialization, is theone showing the best and soundest results, despite having been recurrentlyoverlooked in the literature.
arxiv-1507-04214 | Associative Measures and Multi-word Unit Extraction in Turkish |  http://arxiv.org/abs/1507.04214  | author:Umit Mersinli category:cs.CL published:2015-07-15 summary:Associative measures are "mathematical formulas determining the strength ofassociation between two or more words based on their occurrences andcooccurrences in a text corpus" (Pecina, 2010, p. 138). The purpose of thispaper is to test the 12 associative measures that Text-NSP (Banerjee &Pedersen, 2003) contains on a 10-million-word subcorpus of Turkish NationalCorpus (TNC) (Aksan et.al., 2012). A statistical comparison of those measuresis out of the scope of the study, and the measures will be evaluated accordingto the linguistic relevance of the rankings they provide. The focus of thestudy is basically on optimizing the corpus data, before applying the measuresand then, evaluating the rankings produced by these measures as a whole, not onthe linguistic relevance of individual n-grams. The findings includeintra-linguistically relevant associative measures for a comma delimited,sentence splitted, lower-cased, well-balanced, representative, 10-million-wordcorpus of Turkish.
arxiv-1507-04230 | The Role of Principal Angles in Subspace Classification |  http://arxiv.org/abs/1507.04230  | author:Jiaji Huang, Qiang Qiu, Robert Calderbank category:stat.ML cs.LG published:2015-07-15 summary:Subspace models play an important role in a wide range of signal processingtasks, and this paper explores how the pairwise geometry of subspacesinfluences the probability of misclassification. When the mismatch between thesignal and the model is vanishingly small, the probability of misclassificationis determined by the product of the sines of the principal angles betweensubspaces. When the mismatch is more significant, the probability ofmisclassification is determined by the sum of the squares of the sines of theprincipal angles. Reliability of classification is derived in terms of thedistribution of signal energy across principal vectors. Larger principal angleslead to smaller classification error, motivating a linear transform thatoptimizes principal angles. The transform presented here (TRAIT) preserves somespecific characteristic of each individual class, and this approach is shown tobe complementary to a previously developed transform (LRT) that enlargesinter-class distance while suppressing intra-class dispersion. Theoreticalresults are supported by demonstration of superior classification accuracy onsynthetic and measured data even in the presence of significant model mismatch.
arxiv-1507-04125 | Revisiting AdaBoost for Cost-Sensitive Classification. Part I: Theoretical Perspective |  http://arxiv.org/abs/1507.04125  | author:Iago Landesa-Vázquez, José Luis Alba-Castro category:cs.CV cs.AI cs.LG published:2015-07-15 summary:Boosting algorithms have been widely used to tackle a plethora of problems.In the last few years, a lot of approaches have been proposed to providestandard AdaBoost with cost-sensitive capabilities, each with a differentfocus. However, for the researcher, these algorithms shape a tangled set withdiffuse differences and properties, lacking a unifying analysis to jointlycompare, classify, evaluate and discuss those approaches on a common basis. Inthis series of two papers we aim to revisit the various proposals, both fromtheoretical (Part I) and practical (Part II) perspectives, in order to analyzetheir specific properties and behavior, with the final goal of identifying thealgorithm providing the best and soundest results.
arxiv-1507-04208 | Combinatorial Cascading Bandits |  http://arxiv.org/abs/1507.04208  | author:Branislav Kveton, Zheng Wen, Azin Ashkan, Csaba Szepesvari category:cs.LG stat.ML published:2015-07-15 summary:We propose combinatorial cascading bandits, a class of partial monitoringproblems where at each step a learning agent chooses a tuple of ground itemssubject to constraints and receives a reward if and only if the weights of allchosen items are one. The weights of the items are binary, stochastic, anddrawn independently of each other. The agent observes the index of the firstchosen item whose weight is zero. This observation model arises in networkrouting, for instance, where the learning agent may only observe the first linkin the routing path which is down, and blocks the path. We propose a UCB-likealgorithm for solving our problems, CombCascade; and prove gap-dependent andgap-free upper bounds on its $n$-step regret. Our proofs build on recent workin stochastic combinatorial semi-bandits but also address two novel challengesof our setting, a non-linear reward function and partial observability. Weevaluate CombCascade on two real-world problems and show that it performs welleven when our modeling assumptions are violated. We also demonstrate that oursetting requires a new learning algorithm.
arxiv-1507-04116 | Language discrimination and clustering via a neural network approach |  http://arxiv.org/abs/1507.04116  | author:Angelo Mariano, Giorgio Parisi, Saverio Pascazio category:cs.CL cs.NE physics.soc-ph published:2015-07-15 summary:We classify twenty-one Indo-European languages starting from written text. Weuse neural networks in order to define a distance among different languages,construct a dendrogram and analyze the ultrametric structure that emerges. Fouror five subgroups of languages are identified, according to the "cut" of thedendrogram, drawn with an entropic criterion. The results and the method arediscussed.
arxiv-1507-04285 | Learning Action Models: Qualitative Approach |  http://arxiv.org/abs/1507.04285  | author:Thomas Bolander, Nina Gierasimczuk category:cs.LG cs.AI cs.LO published:2015-07-15 summary:In dynamic epistemic logic, actions are described using action models. Inthis paper we introduce a framework for studying learnability of action modelsfrom observations. We present first results concerning propositional actionmodels. First we check two basic learnability criteria: finite identifiability(conclusively inferring the appropriate action model in finite time) andidentifiability in the limit (inconclusive convergence to the right actionmodel). We show that deterministic actions are finitely identifiable, whilenon-deterministic actions require more learning power-they are identifiable inthe limit. We then move on to a particular learning method, which proceeds viarestriction of a space of events within a learning-specific action model. Thisway of learning closely resembles the well-known update method from dynamicepistemic logic. We introduce several different learning methods suited forfinite identifiability of particular types of deterministic actions.
arxiv-1507-04319 | Learning Boolean functions with concentrated spectra |  http://arxiv.org/abs/1507.04319  | author:Dustin G. Mixon, Jesse Peterson category:cs.LG cs.IT math.FA math.IT published:2015-07-15 summary:This paper discusses the theory and application of learning Boolean functionsthat are concentrated in the Fourier domain. We first estimate the VC dimensionof this function class in order to establish a small sample complexity oflearning in this case. Next, we propose a computationally efficient method ofempirical risk minimization, and we apply this method to the MNIST database ofhandwritten digits. These results demonstrate the effectiveness of our modelfor modern classification tasks. We conclude with a list of open problems forfuture investigation.
arxiv-1507-04396 | Parallel MMF: a Multiresolution Approach to Matrix Computation |  http://arxiv.org/abs/1507.04396  | author:Risi Kondor, Nedelina Teneva, Pramod K. Mudrakarta category:cs.NA cs.LG stat.ML published:2015-07-15 summary:Multiresolution Matrix Factorization (MMF) was recently introduced as amethod for finding multiscale structure and defining wavelets ongraphs/matrices. In this paper we derive pMMF, a parallel algorithm forcomputing the MMF factorization. Empirically, the running time of pMMF scaleslinearly in the dimension for sparse matrices. We argue that this makes pMMF avaluable new computational primitive in its own right, and present experimentson using pMMF for two distinct purposes: compressing matrices andpreconditioning large sparse linear systems.
arxiv-1507-04124 | On the Computability of Solomonoff Induction and Knowledge-Seeking |  http://arxiv.org/abs/1507.04124  | author:Jan Leike, Marcus Hutter category:cs.AI cs.LG published:2015-07-15 summary:Solomonoff induction is held as a gold standard for learning, but it is knownto be incomputable. We quantify its incomputability by placing various flavorsof Solomonoff's prior M in the arithmetical hierarchy. We also derivecomputability bounds for knowledge-seeking agents, and give a limit-computableweakly asymptotically optimal reinforcement learning agent.
arxiv-1507-04060 | Unsupervised Decision Forest for Data Clustering and Density Estimation |  http://arxiv.org/abs/1507.04060  | author:Hayder Albehadili, Naz Islam category:cs.CV published:2015-07-15 summary:An algorithm to improve performance parameter for unsupervised decisionforest clustering and density estimation is presented. Specifically, a dualassignment parameter is introduced as a density estimator by combining RandomForest and Gaussian Mixture Model. The Random Forest method has beenspecifically applied to construct a robust affinity graph that providesinformation on the underlying structure of data objects used in clustering. Theproposed algorithm differs from the commonly used spectral clustering methodswhere the computed distance metric is used to find similarities between datapoints. Experiments were conducted using five datasets. A comparison with sixother state-of-the-art methods shows that our model is superior to existingapproaches. Efficiency of the proposed model is in capturing the underlyingstructure for a given set of data points. The proposed method is also robust,and can discriminate between the complex features of data points amongdifferent clusters.
arxiv-1507-04296 | Massively Parallel Methods for Deep Reinforcement Learning |  http://arxiv.org/abs/1507.04296  | author:Arun Nair, Praveen Srinivasan, Sam Blackwell, Cagdas Alcicek, Rory Fearon, Alessandro De Maria, Vedavyas Panneershelvam, Mustafa Suleyman, Charles Beattie, Stig Petersen, Shane Legg, Volodymyr Mnih, Koray Kavukcuoglu, David Silver category:cs.LG cs.AI cs.DC cs.NE published:2015-07-15 summary:We present the first massively distributed architecture for deepreinforcement learning. This architecture uses four main components: parallelactors that generate new behaviour; parallel learners that are trained fromstored experience; a distributed neural network to represent the value functionor behaviour policy; and a distributed store of experience. We used ourarchitecture to implement the Deep Q-Network algorithm (DQN). Our distributedalgorithm was applied to 49 games from Atari 2600 games from the ArcadeLearning Environment, using identical hyperparameters. Our performancesurpassed non-distributed DQN in 41 of the 49 games and also reduced thewall-time required to achieve these results by an order of magnitude on mostgames.
arxiv-1507-04121 | Solomonoff Induction Violates Nicod's Criterion |  http://arxiv.org/abs/1507.04121  | author:Jan Leike, Marcus Hutter category:cs.LG cs.AI math.ST stat.TH published:2015-07-15 summary:Nicod's criterion states that observing a black raven is evidence for thehypothesis H that all ravens are black. We show that Solomonoff induction doesnot satisfy Nicod's criterion: there are time steps in which observing blackravens decreases the belief in H. Moreover, while observing any computableinfinite string compatible with H, the belief in H decreases infinitely oftenwhen using the unnormalized Solomonoff prior, but only finitely often whenusing the normalized Solomonoff prior. We argue that the fault is not withSolomonoff induction; instead we should reject Nicod's criterion.
arxiv-1507-03698 | Lifting GIS Maps into Strong Geometric Context for Scene Understanding |  http://arxiv.org/abs/1507.03698  | author:Raúl Díaz, Minhaeng Lee, Jochen Schubert, Charless C. Fowlkes category:cs.CV published:2015-07-14 summary:Contextual information can have a substantial impact on the performance ofvisual tasks such as semantic segmentation, object detection, and geometricestimation. Data stored in Geographic Information Systems (GIS) offers a richsource of contextual information that has been largely untapped by computervision. We propose to leverage such information for scene understanding bycombining GIS resources with large sets of unorganized photographs usingStructure from Motion (SfM) techniques. We present a pipeline to quicklygenerate strong 3D geometric priors from 2D GIS data using SfM models alignedwith minimal user input. Given an image resectioned against this model, wegenerate robust predictions of depth, surface normals, and semantic labels. Weshow that the precision of the predicted geometry is substantially moreaccurate other single-image depth estimation methods. We then demonstrate theutility of these contextual constraints for re-scoring pedestrian detections,and use these GIS contextual features alongside object detection score maps toimprove a CRF-based semantic segmentation framework, boosting accuracy overbaseline models.
arxiv-1507-03857 | MMSE of probabilistic low-rank matrix estimation: Universality with respect to the output channel |  http://arxiv.org/abs/1507.03857  | author:Thibault Lesieur, Florent Krzakala, Lenka Zdeborová category:cs.IT math.IT stat.ML published:2015-07-14 summary:This paper considers probabilistic estimation of a low-rank matrix fromnon-linear element-wise measurements of its elements. We derive thecorresponding approximate message passing (AMP) algorithm and its stateevolution. Relying on non-rigorous but standard assumptions motivated bystatistical physics, we characterize the minimum mean squared error (MMSE)achievable information theoretically and with the AMP algorithm. Unlike inrelated problems of linear estimation, in the present setting the MMSE dependson the output channel only trough a single parameter - its Fisher information.We illustrate this striking finding by analysis of submatrix localization, andof detection of communities hidden in a dense stochastic block model. For thisexample we locate the computational and statistical boundaries that are notequal for rank larger than four.
arxiv-1507-03934 | Recurrent Polynomial Network for Dialogue State Tracking |  http://arxiv.org/abs/1507.03934  | author:Kai Sun, Qizhe Xie, Kai Yu category:cs.CL published:2015-07-14 summary:Dialogue state tracking (DST) is a process to estimate the distribution ofthe dialogue states as a dialogue progresses. Recent studies on constrainedMarkov Bayesian polynomial (CMBP) framework take the first step towardsbridging the gap between rule-based and statistical approaches for DST. In thispaper, the gap is further bridged by a novel framework -- recurrent polynomialnetwork (RPN). RPN's unique structure enables the framework to have all theadvantages of CMBP including efficiency, portability and interpretability.Additionally, RPN achieves more properties of statistical approaches than CMBP.RPN was evaluated on the data corpora of the second and the third Dialog StateTracking Challenge (DSTC-2/3). Experiments showed that RPN can significantlyoutperform both traditional rule-based approaches and statistical approacheswith similar feature set. Compared with the state-of-the-art statistical DSTapproaches with a lot richer features, RPN is also competitive.
arxiv-1507-03955 | Robust Estimation of Self-Exciting Point Process Models with Application to Neuronal Modeling |  http://arxiv.org/abs/1507.03955  | author:Abbas Kazemipour, Min Wu, Behtash Babadi category:cs.NE cs.IT cs.SY math.IT math.OC stat.AP published:2015-07-14 summary:We consider the problem of estimating discrete self-exciting point processmodels from limited binary observations, where the history of the processserves as the covariate. We analyze the performance of two classes ofestimators, namely the $\ell_1$-regularized maximum likelihood and greedyestimators, for a canonical self-exciting point process and characterize thesampling tradeoffs required for stable recovery in the non-asymptotic regime.Our results extend those of compressed sensing for linear and generalizedlinear models with i.i.d. covariates to point processes with highlyinter-dependent covariates. We further provide simulation studies as well asapplication to real spiking data from mouse's lateral geniculate nucleus andferret's retinal ganglion cells which agree with our theoretical predictions.
arxiv-1507-04029 | Training artificial neural networks to learn a nondeterministic game |  http://arxiv.org/abs/1507.04029  | author:Thomas E. Portegys category:cs.LG published:2015-07-14 summary:It is well known that artificial neural networks (ANNs) can learndeterministic automata. Learning nondeterministic automata is another matter.This is important because much of the world is nondeterministic, taking theform of unpredictable or probabilistic events that must be acted upon. If ANNsare to engage such phenomena, then they must be able to learn how to deal withnondeterminism. In this project the game of Pong poses a nondeterministicenvironment. The learner is given an incomplete view of the game state andunderlying deterministic physics, resulting in a nondeterministic game. Threemodels were trained and tested on the game: Mona, Elman, and Numenta's NuPIC.
arxiv-1507-04019 | Feature Normalisation for Robust Speech Recognition |  http://arxiv.org/abs/1507.04019  | author:D. S. Pavan Kumar category:cs.CL cs.SD published:2015-07-14 summary:Speech recognition system performance degrades in noisy environments. If theacoustic models are built using features of clean utterances, the features of anoisy test utterance would be acoustically mismatched with the trained model.This gives poor likelihoods and poor recognition accuracy. Model adaptation andfeature normalisation are two broad areas that address this problem. While theformer often gives better performance, the latter involves estimation of lessernumber of parameters, making the system feasible for practical implementations. This research focuses on the efficacies of various subspace, statistical andstereo based feature normalisation techniques. A subspace projection basedmethod has been investigated as a standalone and adjunct technique involvingreconstruction of noisy speech features from a precomputed set of clean speechbuilding-blocks. The building blocks are learned using non-negative matrixfactorisation (NMF) on log-Mel filter bank coefficients, which form a basis forthe clean speech subspace. The work provides a detailed study on how the methodcan be incorporated into the extraction process of Mel-frequency cepstralcoefficients. Experimental results show that the new features are robust tonoise, and achieve better results when combined with the existing techniques. The work also proposes a modification to the training process of SPLICEalgorithm for noise robust speech recognition. It is based on featurecorrelations, and enables this stereo-based algorithm to improve theperformance in all noise conditions, especially in unseen cases. Further, themodified framework is extended to work for non-stereo datasets where clean andnoisy training utterances, but not stereo counterparts, are required. AnMLLR-based computationally efficient run-time noise adaptation method in SPLICEframework has been proposed.
arxiv-1507-04001 | Structure and inference in annotated networks |  http://arxiv.org/abs/1507.04001  | author:M. E. J. Newman, Aaron Clauset category:cs.SI physics.soc-ph stat.ML published:2015-07-14 summary:For many networks of scientific interest we know both the connections of thenetwork and information about the network nodes, such as the age or gender ofindividuals in a social network, geographic location of nodes in the Internet,or cellular function of nodes in a gene regulatory network. Here we demonstratehow this "metadata" can be used to improve our analysis and understanding ofnetwork structure. We focus in particular on the problem of community detectionin networks and develop a mathematically principled approach that combines anetwork and its metadata to detect communities more accurately than can be donewith either alone. Crucially, the method does not assume that the metadata arecorrelated with the communities we are trying to find. Instead the methodlearns whether a correlation exists and correctly uses or ignores the metadatadepending on whether they contain useful information. The learned correlationsare also of interest in their own right, allowing us to make predictions aboutthe community membership of nodes whose network connections are unknown. Wedemonstrate our method on synthetic networks with known structure and onreal-world networks, large and small, drawn from social, biological, andtechnological domains.
arxiv-1507-03887 | An SVM-like Approach for Expectile Regression |  http://arxiv.org/abs/1507.03887  | author:Muhammad Farooq, Ingo Steinwart category:stat.CO stat.ML published:2015-07-14 summary:Expectile regression is a nice tool for investigating conditionaldistributions beyond the conditional mean. It is well-known that expectiles canbe described with the help of the asymmetric least square loss function, andthis link makes it possible to estimate expectiles in a non-parametricframework by a support vector machine like approach. In this work we develop anefficient sequential-minimal-optimization-based solver for the underlyingoptimization problem. The behavior of the solver is investigated by conductingvarious experiments and the results are compared with the recent R-packageER-Boost.
arxiv-1507-03867 | Rich Component Analysis |  http://arxiv.org/abs/1507.03867  | author:Rong Ge, James Zou category:cs.LG stat.ML published:2015-07-14 summary:In many settings, we have multiple data sets (also called views) that capturedifferent and overlapping aspects of the same phenomenon. We are ofteninterested in finding patterns that are unique to one or to a subset of theviews. For example, we might have one set of molecular observations and one setof physiological observations on the same group of individuals, and we want toquantify molecular patterns that are uncorrelated with physiology. Despitebeing a common problem, this is highly challenging when the correlations comefrom complex distributions. In this paper, we develop the general framework ofRich Component Analysis (RCA) to model settings where the observations fromdifferent views are driven by different sets of latent components, and eachcomponent can be a complex, high-dimensional distribution. We introducealgorithms based on cumulant extraction that provably learn each of thecomponents without having to model the other components. We show how tointegrate RCA with stochastic gradient descent into a meta-algorithm forlearning general models, and demonstrate substantial improvement in accuracy onseveral synthetic and real datasets in both supervised and unsupervised tasks.Our method makes it possible to learn latent variable models when we don't havesamples from the true model but only samples after complex perturbations.
arxiv-1507-03811 | Ensemble of Hankel Matrices for Face Emotion Recognition |  http://arxiv.org/abs/1507.03811  | author:Liliana Lo Presti, Marco La Cascia category:cs.CV cs.HC cs.RO published:2015-07-14 summary:In this paper, a face emotion is considered as the result of the compositionof multiple concurrent signals, each corresponding to the movements of aspecific facial muscle. These concurrent signals are represented by means of aset of multi-scale appearance features that might be correlated with one ormore concurrent signals. The extraction of these appearance features from asequence of face images yields to a set of time series. This paper proposes touse the dynamics regulating each appearance feature time series to recognizeamong different face emotions. To this purpose, an ensemble of Hankel matricescorresponding to the extracted time series is used for emotion classificationwithin a framework that combines nearest neighbor and a majority vote schema.Experimental results on a public available dataset shows that the adoptedrepresentation is promising and yields state-of-the-art accuracy in emotionclassification.
arxiv-1509-03208 | Towards Understanding Egyptian Arabic Dialogues |  http://arxiv.org/abs/1509.03208  | author:Abdelrahim A Elmadany, Sherif M Abdou, Mervat Gheith category:cs.CL published:2015-07-14 summary:Labelling of user's utterances to understanding his attends which calledDialogue Act (DA) classification, it is considered the key player for dialoguelanguage understanding layer in automatic dialogue systems. In this paper, weproposed a novel approach to user's utterances labeling for Egyptianspontaneous dialogues and Instant Messages using Machine Learning (ML) approachwithout relying on any special lexicons, cues, or rules. Due to the lack ofEgyptian dialect dialogue corpus, the system evaluated by multi-genre corpusincludes 4725 utterances for three domains, which are collected and annotatedmanually from Egyptian call-centers. The system achieves F1 scores of 70. 36%overall domains.
arxiv-1507-03751 | Closed Curves and Elementary Visual Object Identification |  http://arxiv.org/abs/1507.03751  | author:Manfred Harringer category:cs.CV cs.LG q-bio.NC published:2015-07-14 summary:For two closed curves on a plane (discrete version) and local criteria forsimilarity of points on the curves one gets a potential, which describes thesimilarity between curve points. This is the base for a global similaritymeasure of closed curves (Fr\'echet distance). I use borderlines of handwrittendigits to demonstrate an area of application. I imagine, measuring thesimilarity of closed curves is an essential and elementary task performed by avisual system. This approach to similarity measures may be used by visualsystems.
arxiv-1507-03734 | Splitting the Smoothed Primal-Dual Gap: Optimal Alternating Direction Methods |  http://arxiv.org/abs/1507.03734  | author:Quoc Tran-Dinh, Volkan Cevher category:math.OC stat.ML published:2015-07-14 summary:We develop rigorous alternating direction optimization methods for aprototype constrained convex optimization template, which has broadapplications in computational sciences. We build upon our earlier work on themodel-based gap reduction (MGR) technique, which revolves around a smoothedestimate of the primal-dual gap. MGR allows us to simultaneously update asequence of primal and dual variables as well as primal and dual smoothnessparameters so that the smoothed gap function converges to the true gap, whichin turn converges to zero -- both at optimal rates. In contrast, this paperintroduces a new split-gap reduction (SGR) technique as a natural counterpartof MGR in order to take advantage of additional splitting structures present inthe prototype template. We illustrate SGR technique using the forward-backwardand Douglas-Rachford splittings on the smoothed gap function and derive newalternating direction methods. The new methods obtain optimal convergence rateswithout heuristics and eliminate the infamous penalty parameter tuning issue inthe existing alternating direction methods. Finally, we verify the performanceof our methods in comparison to the existing state-of-the-art and the newtheoretical performance bounds via numerical examples.
arxiv-1507-03719 | A New Framework for Distributed Submodular Maximization |  http://arxiv.org/abs/1507.03719  | author:Rafael da Ponte Barbosa, Alina Ene, Huy L. Nguyen, Justin Ward category:cs.DS cs.AI cs.DC cs.LG published:2015-07-14 summary:A wide variety of problems in machine learning, including exemplarclustering, document summarization, and sensor placement, can be cast asconstrained submodular maximization problems. A lot of recent effort has beendevoted to developing distributed algorithms for these problems. However, theseresults suffer from high number of rounds, suboptimal approximation ratios, orboth. We develop a framework for bringing existing algorithms in the sequentialsetting to the distributed setting, achieving near optimal approximation ratiosfor many settings in only a constant number of MapReduce rounds. Our techniquesalso give a fast sequential algorithm for non-monotone maximization subject toa matroid constraint.
arxiv-1507-03707 | Projected Wirtinger Gradient Descent for Low-Rank Hankel Matrix Completion in Spectral Compressed Sensing |  http://arxiv.org/abs/1507.03707  | author:Jian-Feng Cai, Suhui Liu, Weiyu Xu category:cs.IT cs.LG math.IT math.OC published:2015-07-14 summary:This paper considers reconstructing a spectrally sparse signal from a smallnumber of randomly observed time-domain samples. The signal of interest is alinear combination of complex sinusoids at $R$ distinct frequencies. Thefrequencies can assume any continuous values in the normalized frequency domain$[0,1)$. After converting the spectrally sparse signal recovery into a low rankstructured matrix completion problem, we propose an efficient feasible pointapproach, named projected Wirtinger gradient descent (PWGD) algorithm, toefficiently solve this structured matrix completion problem. We furtheraccelerate our proposed algorithm by a scheme inspired by FISTA. We give theconvergence analysis of our proposed algorithms. Extensive numericalexperiments are provided to illustrate the efficiency of our proposedalgorithm. Different from earlier approaches, our algorithm can solve problemsof very large dimensions very efficiently.
arxiv-1507-03372 | Ordered Decompositional DAG Kernels Enhancements |  http://arxiv.org/abs/1507.03372  | author:Giovanni Da San Martino, Nicolò Navarin, Alessandro Sperduti category:cs.LG published:2015-07-13 summary:In this paper, we show how the Ordered Decomposition DAGs (ODD) kernelframework, a framework that allows the definition of graph kernels from treekernels, allows to easily define new state-of-the-art graph kernels. Here weconsider a fast graph kernel based on the Subtree kernel (ST), and we proposevarious enhancements to increase its expressiveness. The proposed DAG kernelhas the same worst-case complexity as the one based on ST, but an improvedexpressivity due to an augmented set of features. Moreover, we propose a novelweighting scheme for the features, which can be applied to other kernels of theODD framework. These improvements allow the proposed kernels to improve on theclassification performances of the ST-based kernel for several real-worlddatasets, reaching state-of-the-art performances.
arxiv-1507-03641 | Neural CRF Parsing |  http://arxiv.org/abs/1507.03641  | author:Greg Durrett, Dan Klein category:cs.CL cs.NE published:2015-07-13 summary:This paper describes a parsing model that combines the exact dynamicprogramming of CRF parsing with the rich nonlinear featurization of neural netapproaches. Our model is structurally a CRF that factors over anchored ruleproductions, but instead of linear potential functions based on sparsefeatures, we use nonlinear potentials computed via a feedforward neuralnetwork. Because potentials are still local to anchored rules, structuredinference (CKY) is unchanged from the sparse case. Computing gradients duringlearning involves backpropagating an error signal formed from standard CRFsufficient statistics (expected rule counts). Using only dense features, ourneural CRF already exceeds a strong baseline CRF model (Hall et al., 2014). Incombination with sparse features, our system achieves 91.1 F1 on section 23 ofthe Penn Treebank, and more generally outperforms the best prior single parserresults on a range of languages.
arxiv-1507-03538 | Classifying X-ray Binaries: A Probabilistic Approach |  http://arxiv.org/abs/1507.03538  | author:Giri Gopalan, Saeqa Dil Vrtilek, Luke Bornn category:astro-ph.HE stat.AP stat.ML published:2015-07-13 summary:In X-ray binary star systems consisting of a compact object that accretesmaterial from an orbiting secondary star, there is no straightforward means todecide if the compact object is a black hole or a neutron star. To assist thisprocess we develop a Bayesian statistical model which makes use of the factthat X-ray binary systems appear to cluster based on their compact object typewhen viewed from a 3-dimensional coordinate system derived from X-ray spectraldata, where the first coordinate is the ratio of counts in mid to low energyband (color 1), the second coordinate is the ratio of counts in high to lowenergy band (color 2), and the third coordinate is the sum of counts in allthree bands. Precisely, we use this model to estimate the probabilities that anX-ray binary system contains a black hole, non-pulsing neutron star or pulsingneutron star. In particular we utilize a latent variable model in which thelatent variables follow a Gaussian process prior distribution, and hence we areable to induce the spatial correlation we believe exists between systems of thesame type. The utility of this approach is evidenced by the accurate predictionof system types using Rossi X-ray Timing Explorer All Sky Monitor data, but itis not flawless. In particular, non-pulsing neutron systems containing"bursters" which are close to the boundary demarcating systems containing blackholes tend to be classified as black hole systems. As a byproduct of ouranalyses, we provide the astronomer with public R code that can be used topredict the compact object type of X-ray binaries given training data.
arxiv-1507-03496 | The mRMR variable selection method: a comparative study for functional data |  http://arxiv.org/abs/1507.03496  | author:José R. Berrendero, Antonio Cuevas, José L. Torrecilla category:stat.ME stat.ML published:2015-07-13 summary:The use of variable selection methods is particularly appealing instatistical problems with functional data. The obvious general criterion forvariable selection is to choose the `most representative' or `most relevant'variables. However, it is also clear that a purely relevance-oriented criterioncould lead to select many redundant variables. The mRMR (minimum RedundanceMaximum Relevance) procedure, proposed by Ding and Peng (2005) and Peng et al.(2005) is an algorithm to systematically perform variable selection, achievinga reasonable trade-off between relevance and redundancy. In its original form,this procedure is based on the use of the so-called mutual informationcriterion to assess relevance and redundancy. Keeping the focus on functionaldata problems, we propose here a modified version of the mRMR method, obtainedby replacing the mutual information by the new association measure (calleddistance correlation) suggested by Sz\'ekely et al. (2007). We have alsoperformed an extensive simulation study, including 1600 functional experiments(100 functional models $\times$ 4 sample sizes $\times$ 4 classifiers) andthree real-data examples aimed at comparing the different versions of the mRMRmethodology. The results are quite conclusive in favor of the new proposedalternative.
arxiv-1507-03409 | Unconstrained Facial Landmark Localization with Backbone-Branches Fully-Convolutional Networks |  http://arxiv.org/abs/1507.03409  | author:Zhujin Liang, Shengyong Ding, Liang Lin category:cs.CV published:2015-07-13 summary:This paper investigates how to rapidly and accurately localize faciallandmarks in unconstrained, cluttered environments rather than in the wellsegmented face images. We present a novel Backbone-Branches Fully-ConvolutionalNeural Network (BB-FCN), which produces facial landmark response maps directlyfrom raw images without relying on pre-process or sliding window approaches.BB-FCN contains one backbone and a number of network branches with eachcorresponding to one landmark type, and it operates in a progressive manner.Specifically, the backbone roughly detects the locations of facial landmarks bytaking the whole image as input, and the branches further refine thelocalizations based on a local observation from the backbone's intermediatefeature map. Moreover, our backbone-branches architecture does not containfull-connection layers for location regression, leading to efficient learningand inference. Our extensive experiments show that our model achieves superiorperformances over other state-of-the-arts under both the constrained (i.e. withface regions) and the "in the wild" scenarios.
arxiv-1507-03482 | Individual performance calibration using physiological stress signals |  http://arxiv.org/abs/1507.03482  | author:Francisco Hernando-Gallego, Antonio Artés-Rodríguez category:cs.HC cs.CY stat.ML published:2015-07-13 summary:The relation between performance and stress is described by the Yerkes-DodsonLaw but varies significantly between individuals. This paper describes a methodfor determining the individual optimal performance as a function ofphysiological signals. The method is based on attention and reasoning tests ofincreasing complexity under monitoring of three physiological signals: GalvanicSkin Response (GSR), Heart Rate (HR), and Electromyogram (EMG). Based on thetest results with 15 different individuals, we first show that two of thesignals, GSR and HR, have enough discriminative power to distinguish betweenrelax and stress periods. We then show a positive correlation between thecomplexity level of the tests and the GSR and HR signals, and we finallydetermine the optimal performance point as the signal level just before aperformance decrease. We also discuss the differences among signals dependingon the type of test.
arxiv-1507-03471 | Incremental LSTM-based Dialog State Tracker |  http://arxiv.org/abs/1507.03471  | author:Lukas Zilka, Filip Jurcicek category:cs.CL published:2015-07-13 summary:A dialog state tracker is an important component in modern spoken dialogsystems. We present an incremental dialog state tracker, based on LSTMnetworks. It directly uses automatic speech recognition hypotheses to track thestate. We also present the key non-standard aspects of the model that bring itsperformance close to the state-of-the-art and experimentally analyze theircontribution: including the ASR confidence scores, abstracting scarcelyrepresented values, including transcriptions in the training data, and modelaveraging.
arxiv-1507-03462 | Supervised Hierarchical Classification for Student Answer Scoring |  http://arxiv.org/abs/1507.03462  | author:Itziar Aldabe, Oier Lopez de Lacalle, Iñigo Lopez-Gazpio, Montse Maritxalar category:cs.CL published:2015-07-13 summary:This paper describes a hierarchical system that predicts one label at a timefor automated student response analysis. For the task, we build aclassification binary tree that delays more easily confused labels to laterstages using hierarchical processes. In particular, the paper describes how thehierarchical classifier has been built and how the classification task has beenbroken down into binary subtasks. It finally discusses the motivations andfundamentals of such an approach.
arxiv-1507-03360 | Sparsity assisted solution to the twin image problem in phase retrieval |  http://arxiv.org/abs/1507.03360  | author:Charu Gaur, Baranidharan Mohan, Kedar Khare category:cs.CV physics.optics published:2015-07-13 summary:The iterative phase retrieval problem for complex-valued objects from Fouriertransform magnitude data is known to suffer from the twin image problem. Inparticular, when the object support is centro-symmetric, the iterative solutionoften stagnates such that the resultant complex image contains the features ofboth the desired solution and its inverted and complex-conjugated replica. Theconventional approach to address the twin image problem is to modify the objectsupport during initial iterations which can possibly lead to elimination of oneof the twin images. However, at present there seems to be no deterministicprocedure to make sure that the twin image will always be very weak or absent.In this work we make an important observation that the ideal solution withoutthe twin image is typically more sparse (in some suitable transform domain) ascompared to the stagnated solution containing the twin image. We further showthat introducing a sparsity enhancing step in the iterative algorithm canaddress the twin image problem without the need to change the object supportthroughout the iterative process even when the object support iscentro-symmetric. In a simulation study, we use binary and gray-scale purephase objects and illustrate the effectiveness of the sparsity assisted phaserecovery in the context of the twin image problem. The results have importantimplications for a wide range of topics in Physics where the phase retrievalproblem plays a central role.
arxiv-1507-03340 | Quantitative Evaluation of Performance and Validity Indices for Clustering the Web Navigational Sessions |  http://arxiv.org/abs/1507.03340  | author:Zahid Ansari, M. F. Azeem, Waseem Ahmed, A. Vinaya Babu category:cs.LG cs.SI published:2015-07-13 summary:Clustering techniques are widely used in Web Usage Mining to capture similarinterests and trends among users accessing a Web site. For this purpose, webaccess logs generated at a particular web site are preprocessed to discover theuser navigational sessions. Clustering techniques are then applied to group theuser session data into user session clusters, where intercluster similaritiesare minimized while the intra cluster similarities are maximized. Since theapplication of different clustering algorithms generally results in differentsets of cluster formation, it is important to evaluate the performance of thesemethods in terms of accuracy and validity of the clusters, and also the timerequired to generate them, using appropriate performance measures. This paperdescribes various validity and accuracy measures including Dunn's Index, DaviesBouldin Index, C Index, Rand Index, Jaccard Index, Silhouette Index, FowlkesMallows and Sum of the Squared Error (SSE). We conducted the performanceevaluation of the following clustering techniques: k-Means, k-Medoids, Leader,Single Link Agglomerative Hierarchical and DBSCAN. These techniques areimplemented and tested against the Web user navigational data. Finally theirperformance results are presented and compared.
arxiv-1507-03285 | Scatter Matrix Concordance: A Diagnostic for Regressions on Subsets of Data |  http://arxiv.org/abs/1507.03285  | author:Michael J. Kane, Bryan Lewis, Sekhar Tatikonda, Simon Urbanek category:stat.ML published:2015-07-12 summary:Linear regression models depend directly on the design matrix and itsproperties. Techniques that efficiently estimate model coefficients bypartitioning rows of the design matrix are increasingly popular for large-scaleproblems because they fit well with modern parallel computing architectures. Wepropose a simple measure of {\em concordance} between a design matrix and asubset of its rows that estimates how well a subset captures thevariance-covariance structure of a larger data set. We illustrate the use ofthis measure in a heuristic method for selecting row partition sizes thatbalance statistical and computational efficiency goals in real-world problems.
arxiv-1507-03269 | Tensor principal component analysis via sum-of-squares proofs |  http://arxiv.org/abs/1507.03269  | author:Samuel B. Hopkins, Jonathan Shi, David Steurer category:cs.LG cs.CC cs.DS stat.ML published:2015-07-12 summary:We study a statistical model for the tensor principal component analysisproblem introduced by Montanari and Richard: Given a order-$3$ tensor $T$ ofthe form $T = \tau \cdot v_0^{\otimes 3} + A$, where $\tau \geq 0$ is asignal-to-noise ratio, $v_0$ is a unit vector, and $A$ is a random noisetensor, the goal is to recover the planted vector $v_0$. For the case that $A$has iid standard Gaussian entries, we give an efficient algorithm to recover$v_0$ whenever $\tau \geq \omega(n^{3/4} \log(n)^{1/4})$, and certify that therecovered vector is close to a maximum likelihood estimator, all with highprobability over the random choice of $A$. The previous best algorithms withprovable guarantees required $\tau \geq \Omega(n)$. In the regime $\tau \leq o(n)$, natural tensor-unfolding-based spectralrelaxations for the underlying optimization problem break down (in the sensethat their integrality gap is large). To go beyond this barrier, we use convexrelaxations based on the sum-of-squares method. Our recovery algorithm proceedsby rounding a degree-$4$ sum-of-squares relaxations of themaximum-likelihood-estimation problem for the statistical model. To complementour algorithmic results, we show that degree-$4$ sum-of-squares relaxationsbreak down for $\tau \leq O(n^{3/4}/\log(n)^{1/4})$, which demonstrates thatimproving our current guarantees (by more than logarithmic factors) wouldrequire new techniques or might even be intractable. Finally, we show how to exploit additional problem structure in order tosolve our sum-of-squares relaxations, up to some approximation, veryefficiently. Our fastest algorithm runs in nearly-linear time using shifted(matrix) power iteration and has similar guarantees as above. The analysis ofthis algorithm also confirms a variant of a conjecture of Montanari and Richardabout singular vectors of tensor unfoldings.
arxiv-1507-03229 | Homotopy Continuation Approaches for Robust SV Classification and Regression |  http://arxiv.org/abs/1507.03229  | author:Shinya Suzumura, Kohei Ogawa, Masashi Sugiyama, Masayuki Karasuyama, Ichiro Takeuchi category:stat.ML cs.LG published:2015-07-12 summary:In support vector machine (SVM) applications with unreliable data thatcontains a portion of outliers, non-robustness of SVMs often causesconsiderable performance deterioration. Although many approaches for improvingthe robustness of SVMs have been studied, two major challenges remain in robustSVM learning. First, robust learning algorithms are essentially formulated asnon-convex optimization problems. It is thus important to develop a non-convexoptimization method for robust SVM that can find a good local optimal solution.The second practical issue is how one can tune the hyperparameter that controlsthe balance between robustness and efficiency. Unfortunately, due to thenon-convexity, robust SVM solutions with slightly different hyper-parametervalues can be significantly different, which makes model selection highlyunstable. In this paper, we address these two issues simultaneously byintroducing a novel homotopy approach to non-convex robust SVM learning. Ourbasic idea is to introduce parametrized formulations of robust SVM which bridgethe standard SVM and fully robust SVM via the parameter that represents theinfluence of outliers. We characterize the necessary and sufficient conditionsof the local optimal solutions of robust SVM, and develop an algorithm that cantrace a path of local optimal solutions when the influence of outliers isgradually decreased. An advantage of our homotopy approach is that it can beinterpreted as simulated annealing, a common approach for finding a good localoptimal solution in non-convex optimization problems. In addition, our homotopymethod allows stable and efficient model selection based on the path of localoptimal solutions. Empirical performances of the proposed approach aredemonstrated through intensive numerical experiments both on robustclassification and regression problems.
arxiv-1507-03228 | Scalable Bayesian Inference for Excitatory Point Process Networks |  http://arxiv.org/abs/1507.03228  | author:Scott W. Linderman, Ryan P. Adams category:stat.ML published:2015-07-12 summary:Networks capture our intuition about relationships in the world. Theydescribe the friendships between Facebook users, interactions in financialmarkets, and synapses connecting neurons in the brain. These networks arerichly structured with cliques of friends, sectors of stocks, and a smorgasbordof cell types that govern how neurons connect. Some networks, like socialnetwork friendships, can be directly observed, but in many cases we only havean indirect view of the network through the actions of its constituents and anunderstanding of how the network mediates that activity. In this work, we focuson the problem of latent network discovery in the case where the observableactivity takes the form of a mutually-excitatory point process known as aHawkes process. We build on previous work that has taken a Bayesian approach tothis problem, specifying prior distributions over the latent network structureand a likelihood of observed activity given this network. We extend this workby proposing a discrete-time formulation and developing a computationallyefficient stochastic variational inference (SVI) algorithm that allows us toscale the approach to long sequences of observations. We demonstrate ouralgorithm on the calcium imaging data used in the Chalearn neural connectomicschallenge.
arxiv-1507-03223 | Classifier-Based Text Simplification for Improved Machine Translation |  http://arxiv.org/abs/1507.03223  | author:Shruti Tyagi, Deepti Chopra, Iti Mathur, Nisheeth Joshi category:cs.CL published:2015-07-12 summary:Machine Translation is one of the research fields of ComputationalLinguistics. The objective of many MT Researchers is to develop an MT Systemthat produce good quality and high accuracy output translations and which alsocovers maximum language pairs. As internet and Globalization is increasing dayby day, we need a way that improves the quality of translation. For thisreason, we have developed a Classifier based Text Simplification Model forEnglish-Hindi Machine Translation Systems. We have used support vector machinesand Na\"ive Bayes Classifier to develop this model. We have also evaluated theperformance of these classifiers.
arxiv-1507-03196 | DeepFont: Identify Your Font from An Image |  http://arxiv.org/abs/1507.03196  | author:Zhangyang Wang, Jianchao Yang, Hailin Jin, Eli Shechtman, Aseem Agarwala, Jonathan Brandt, Thomas S. Huang category:cs.CV published:2015-07-12 summary:As font is one of the core design concepts, automatic font identification andsimilar font suggestion from an image or photo has been on the wish list ofmany designers. We study the Visual Font Recognition (VFR) problem, and advancethe state-of-the-art remarkably by developing the DeepFont system. First ofall, we build up the first available large-scale VFR dataset, named AdobeVFR,consisting of both labeled synthetic data and partially labeled real-worlddata. Next, to combat the domain mismatch between available training andtesting data, we introduce a Convolutional Neural Network (CNN) decompositionapproach, using a domain adaptation technique based on a Stacked ConvolutionalAuto-Encoder (SCAE) that exploits a large corpus of unlabeled real-world textimages combined with synthetic data preprocessed in a specific way. Moreover,we study a novel learning-based model compression approach, in order to reducethe DeepFont model size without sacrificing its performance. The DeepFontsystem achieves an accuracy of higher than 80% (top-5) on our collecteddataset, and also produces a good font similarity measure for font selectionand suggestion. We also achieve around 6 times compression of the model withoutany visible loss of recognition accuracy.
arxiv-1507-03176 | Dependent Indian Buffet Process-based Sparse Nonparametric Nonnegative Matrix Factorization |  http://arxiv.org/abs/1507.03176  | author:Junyu Xuan, Jie Lu, Guangquan Zhang, Richard Yi Da Xu, Xiangfeng Luo category:stat.ML published:2015-07-12 summary:Nonnegative Matrix Factorization (NMF) aims to factorize a matrix into twooptimized nonnegative matrices appropriate for the intended applications. Themethod has been widely used for unsupervised learning tasks, includingrecommender systems (rating matrix of users by items) and document clustering(weighting matrix of papers by keywords). However, traditional NMF methodstypically assume the number of latent factors (i.e., dimensionality of theloading matrices) to be fixed. This assumption makes them inflexible for manyapplications. In this paper, we propose a nonparametric NMF framework tomitigate this issue by using dependent Indian Buffet Processes (dIBP). In anutshell, we apply a correlation function for the generation of two stickweights associated with each pair of columns of loading matrices, while stillmaintaining their respective marginal distribution specified by IBP. As aconsequence, the generation of two loading matrices will be column-wise(indirectly) correlated. Under this same framework, two classes of correlationfunction are proposed (1) using Bivariate beta distribution and (2) usingCopula function. Both methods allow us to adopt our work for variousapplications by flexibly choosing an appropriate parameter settings. Comparedwith the other state-of-the art approaches in this area, such as using GaussianProcess (GP)-based dIBP, our work is seen to be much more flexible in terms ofallowing the two corresponding binary matrix columns to have greater variationsin their non-zero entries. Our experiments on the real-world and syntheticdatasets show that three proposed models perform well on the documentclustering task comparing standard NMF without predefining the dimension forthe factor matrices, and the Bivariate beta distribution-based and Copula-basedmodels have better flexibility than the GP-based model.
arxiv-1507-03194 | A Review of Nonnegative Matrix Factorization Methods for Clustering |  http://arxiv.org/abs/1507.03194  | author:Ali Caner Türkmen category:stat.ML cs.LG cs.NA published:2015-07-12 summary:Nonnegative Matrix Factorization (NMF) was first introduced as a low-rankmatrix approximation technique, and has enjoyed a wide area of applications.Although NMF does not seem related to the clustering problem at first, it wasshown that they are closely linked. In this report, we provide a gentleintroduction to clustering and NMF before reviewing the theoreticalrelationship between them. We then explore several NMF variants, namely SparseNMF, Projective NMF, Nonnegative Spectral Clustering and Cluster-NMF, alongwith their clustering interpretations.
arxiv-1507-03292 | Cluster-Aided Mobility Predictions |  http://arxiv.org/abs/1507.03292  | author:Jaeseong Jeong, Mathieu Leconte, Alexandre Proutiere category:cs.LG published:2015-07-12 summary:Predicting the future location of users in wireless net- works has numerousapplications, and can help service providers to improve the quality of serviceperceived by their clients. The location predictors proposed so far estimatethe next location of a specific user by inspecting the past individualtrajectories of this user. As a consequence, when the training data collectedfor a given user is limited, the resulting prediction is inaccurate. In thispaper, we develop cluster-aided predictors that exploit past trajectoriescollected from all users to predict the next location of a given user. Thesepredictors rely on clustering techniques and extract from the training datasimilarities among the mobility patterns of the various users to improve theprediction accuracy. Specifically, we present CAMP (Cluster-Aided MobilityPredictor), a cluster-aided predictor whose design is based on recentnon-parametric bayesian statistical tools. CAMP is robust and adaptive in thesense that it exploits similarities in users' mobility only if suchsimilarities are really present in the training data. We analytically prove theconsistency of the predictions provided by CAMP, and investigate itsperformance using two large-scale datasets. CAMP significantly outperformsexisting predictors, and in particular those that only exploit individual pasttrajectories.
arxiv-1507-03130 | Joint estimation of quantile planes over arbitrary predictor spaces |  http://arxiv.org/abs/1507.03130  | author:Yun Yang, Surya Tokdar category:stat.ME stat.CO stat.ML published:2015-07-11 summary:In spite of the recent surge of interest in quantile regression, jointestimation of linear quantile planes remains a great challenge in statisticsand econometrics. We propose a novel parametrization that characterizes anycollection of non-crossing quantile planes over arbitrarily shaped convexpredictor domains in any dimension by means of unconstrained scalar, vector andfunction valued parameters. Statistical models based on this parametrizationinherit a fast computation of the likelihood function, enabling penalizedlikelihood or Bayesian approaches to model fitting. We introduce a completeBayesian methodology by using Gaussian process prior distributions on thefunction valued parameters and develop a robust and efficient Markov chainMonte Carlo parameter estimation. The resulting method is shown to offerposterior consistency under mild tail and regularity conditions. We presentseveral illustrative examples where the new method is compared against existingapproaches and is found to offer better accuracy, coverage and model fit.
arxiv-1507-03125 | A new boosting algorithm based on dual averaging scheme |  http://arxiv.org/abs/1507.03125  | author:Nan Wang category:cs.LG published:2015-07-11 summary:The fields of machine learning and mathematical optimization increasinglyintertwined. The special topic on supervised learning and convex optimizationexamines this interplay. The training part of most supervised learningalgorithms can usually be reduced to an optimization problem that minimizes aloss between model predictions and training data. While most optimizationtechniques focus on accuracy and speed of convergence, the qualities of goodoptimization algorithm from the machine learning perspective can be quitedifferent since machine learning is more than fitting the data. Betteroptimization algorithms that minimize the training loss can possibly give verypoor generalization performance. In this paper, we examine a particular kind ofmachine learning algorithm, boosting, whose training process can be viewed asfunctional coordinate descent on the exponential loss. We study the relationbetween optimization techniques and machine learning by implementing a newboosting algorithm. DABoost, based on dual-averaging scheme and study itsgeneralization performance. We show that DABoost, although slower in reducingthe training error, in general enjoys a better generalization error thanAdaBoost.
arxiv-1507-03092 | On the Use of Harrell's C for Node Splitting in Random Survival Forests |  http://arxiv.org/abs/1507.03092  | author:Matthias Schmid, Marvin Wright, Andreas Ziegler category:stat.ML published:2015-07-11 summary:Random forests are one of the most successful methods for statisticallearning and prediction. Here we consider random survival forests (RSF), whichare an extension of the original random forest method to right-censored outcomevariables. RSF use the log-rank split criterion to form an ensemble of survivaltrees, the prediction accuracy of the ensemble estimate is subsequentlyevaluated by the concordance index for survival data ("Harrell's C").Conceptually, this strategy means that the split criterion in RSF is differentfrom the evaluation criterion of interest. In view of this discrepancy, weanalyze the theoretical relationship between the two criteria and investigatewhether a unified strategy that uses Harrell's C for both node splitting andevaluation is able to improve the performance of RSF. Based on simulationstudies and the analysis of real-world data, we show that substantialperformance gains are possible if the log-rank statistic is replaced byHarrell's C for node splitting in RSF. Our results also show that C-basedsplitting is not superior to log-rank splitting if the percentage of noisevariables is high, a result which can be attributed to the more unbalancedsplits that are generated by the log-rank statistic.
arxiv-1507-03111 | Kernel Methods for Linear Discrete-Time Equations |  http://arxiv.org/abs/1507.03111  | author:Fritz Colonius, Boumediene Hamzi category:math.DS math.OC math.ST stat.ML stat.TH published:2015-07-11 summary:Methods from learning theory are used in the state space of linear dynamicaland control systems in order to estimate the system matrices. An application tostabilization via algebraic Riccati equations is included. The approach isillustrated via a series of numerical examples.
arxiv-1507-03133 | Best Subset Selection via a Modern Optimization Lens |  http://arxiv.org/abs/1507.03133  | author:Dimitris Bertsimas, Angela King, Rahul Mazumder category:stat.ME math.OC stat.CO stat.ML published:2015-07-11 summary:In the last twenty-five years (1990-2014), algorithmic advances in integeroptimization combined with hardware improvements have resulted in anastonishing 200 billion factor speedup in solving Mixed Integer Optimization(MIO) problems. We present a MIO approach for solving the classical best subsetselection problem of choosing $k$ out of $p$ features in linear regressiongiven $n$ observations. We develop a discrete extension of modern first ordercontinuous optimization methods to find high quality feasible solutions that weuse as warm starts to a MIO solver that finds provably optimal solutions. Theresulting algorithm (a) provides a solution with a guarantee on itssuboptimality even if we terminate the algorithm early, (b) can accommodateside constraints on the coefficients of the linear regression and (c) extendsto finding best subset solutions for the least absolute deviation lossfunction. Using a wide variety of synthetic and real datasets, we demonstratethat our approach solves problems with $n$ in the 1000s and $p$ in the 100s inminutes to provable optimality, and finds near optimal solutions for $n$ in the100s and $p$ in the 1000s in minutes. We also establish via numericalexperiments that the MIO approach performs better than {\texttt {Lasso}} andother popularly used sparse learning procedures, in terms of achieving sparsesolutions with good predictive power.
arxiv-1507-03148 | Face Alignment Assisted by Head Pose Estimation |  http://arxiv.org/abs/1507.03148  | author:Heng Yang, Wenxuan Mou, Yichi Zhang, Ioannis Patras, Hatice Gunes, Peter Robinson category:cs.CV published:2015-07-11 summary:In this paper we propose a supervised initialization scheme for cascaded facealignment based on explicit head pose estimation. We first investigate thefailure cases of most state of the art face alignment approaches and observethat these failures often share one common global property, i.e. the head posevariation is usually large. Inspired by this, we propose a deep convolutionalnetwork model for reliable and accurate head pose estimation. Instead of usinga mean face shape, or randomly selected shapes for cascaded face alignmentinitialisation, we propose two schemes for generating initialisation: the firstone relies on projecting a mean 3D face shape (represented by 3D faciallandmarks) onto 2D image under the estimated head pose; the second one searchesnearest neighbour shapes from the training set according to head pose distance.By doing so, the initialisation gets closer to the actual shape, which enhancesthe possibility of convergence and in turn improves the face alignmentperformance. We demonstrate the proposed method on the benchmark 300W datasetand show very competitive performance in both head pose estimation and facealignment.
arxiv-1507-03077 | A new hybrid stemming algorithm for Persian |  http://arxiv.org/abs/1507.03077  | author:Adel Rahimi category:cs.CL cs.IR published:2015-07-11 summary:Stemming has been an influential part in Information retrieval and searchengines. There have been tremendous endeavours in making stemmer that are bothefficient and accurate. Stemmers can have three method in stemming, Dictionarybased stemmer, statistical-based stemmers, and rule-based stemmers. This paperaims at building a hybrid stemmer that uses both Dictionary based method andrule-based method for stemming. This ultimately helps the efficacy andaccurateness of the stemmer.
arxiv-1507-03060 | LooseCut: Interactive Image Segmentation with Loosely Bounded Boxes |  http://arxiv.org/abs/1507.03060  | author:Hongkai Yu, Youjie Zhou, Hui Qian, Min Xian, Yuewei Lin, Dazhou Guo, Kang Zheng, Kareem Abdelfatah, Song Wang category:cs.CV published:2015-07-11 summary:One popular approach to interactively segment the foreground object ofinterest from an image is to annotate a bounding box that covers the foregroundobject. Then, a binary labeling is performed to achieve a refined segmentation.One major issue of the existing algorithms for such interactive imagesegmentation is their preference of an input bounding box that tightly enclosesthe foreground object. This increases the annotation burden, and prevents thesealgorithms from utilizing automatically detected bounding boxes. In this paper,we develop a new LooseCut algorithm that can handle cases where the inputbounding box only loosely covers the foreground object. We propose a new MarkovRandom Fields (MRF) model for segmentation with loosely bounded boxes,including a global similarity constraint to better distinguish the foregroundand background, and an additional energy term to encourage consistent labelingof similar-appearance pixels. This MRF model is then solved by an iteratedmax-flow algorithm. In the experiments, we evaluate LooseCut in threepublicly-available image datasets, and compare its performance against severalstate-of-the-art interactive image segmentation algorithms. We also show thatLooseCut can be used for enhancing the performance of unsupervised videosegmentation and image saliency detection.
arxiv-1507-02779 | Robust Performance-driven 3D Face Tracking in Long Range Depth Scenes |  http://arxiv.org/abs/1507.02779  | author:Hai X. Pham, Chongyu Chen, Luc N. Dao, Vladimir Pavlovic, Jianfei Cai, Tat-jen Cham category:cs.CV published:2015-07-10 summary:We introduce a novel robust hybrid 3D face tracking framework from RGBD videostreams, which is capable of tracking head pose and facial actions withoutpre-calibration or intervention from a user. In particular, we emphasize onimproving the tracking performance in instances where the tracked subject is ata large distance from the cameras, and the quality of point cloud deterioratesseverely. This is accomplished by the combination of a flexible 3D shaperegressor and the joint 2D+3D optimization on shape parameters. Our approachfits facial blendshapes to the point cloud of the human head, while beingdriven by an efficient and rapid 3D shape regressor trained on generic RGBdatasets. As an on-line tracking system, the identity of the unknown user isadapted on-the-fly resulting in improved 3D model reconstruction andconsequently better tracking performance. The result is a robust RGBD facetracker, capable of handling a wide range of target scene depths, beyond thosethat can be afforded by traditional depth or RGB face trackers. Lastly, sincethe blendshape is not able to accurately recover the real facial shape, we usethe tracked 3D face model as a prior in a novel filtering process to furtherrefine the depth map for use in other tasks, such as 3D reconstruction.
arxiv-1507-02835 | A Trainable Neuromorphic Integrated Circuit that Exploits Device Mismatch |  http://arxiv.org/abs/1507.02835  | author:Chetan Singh Thakur, Runchun Wang, Tara Julia Hamilton, Jonathan Tapson, Andre van Schaik category:cs.NE published:2015-07-10 summary:Random device mismatch that arises as a result of scaling of the CMOS(complementary metal-oxide semi-conductor) technology into the deep submicronregime degrades the accuracy of analogue circuits. Methods to combat thisincrease the complexity of design. We have developed a novel neuromorphicsystem called a Trainable Analogue Block (TAB), which exploits device mismatchas a means for random projections of the input to a higher dimensional space.The TAB framework is inspired by the principles of neural population codingoperating in the biological nervous system. Three neuronal layers, namelyinput, hidden, and output, constitute the TAB framework, with the number ofhidden layer neurons far exceeding the input layer neurons. Here, we presentmeasurement results of the first prototype TAB chip built using a 65nm processtechnology and show its learning capability for various regression tasks. OurTAB chip exploits inherent randomness and variability arising due to thefabrication process to perform various learning tasks. Additionally, wecharacterise each neuron and discuss the statistical variability of its tuningcurve that arises due to random device mismatch, a desirable property for thelearning capability of the TAB. We also discuss the effect of the number ofhidden neurons and the resolution of output weights on the accuracy of thelearning capability of the TAB.
arxiv-1507-02907 | Extending a Single-Document Summarizer to Multi-Document: a Hierarchical Approach |  http://arxiv.org/abs/1507.02907  | author:Luís Marujo, Ricardo Ribeiro, David Martins de Matos, João P. Neto, Anatole Gershman, Jaime Carbonell category:cs.IR cs.CL published:2015-07-10 summary:The increasing amount of online content motivated the development ofmulti-document summarization methods. In this work, we explore straightforwardapproaches to extend single-document summarization methods to multi-documentsummarization. The proposed methods are based on the hierarchical combinationof single-document summaries, and achieves state of the art results.
arxiv-1507-03045 | Markov Logic Networks for Natural Language Question Answering |  http://arxiv.org/abs/1507.03045  | author:Tushar Khot, Niranjan Balasubramanian, Eric Gribkoff, Ashish Sabharwal, Peter Clark, Oren Etzioni category:cs.AI cs.CL published:2015-07-10 summary:Our goal is to answer elementary-level science questions using knowledgeextracted automatically from science textbooks, expressed in a subset offirst-order logic. Given the incomplete and noisy nature of these automaticallyextracted rules, Markov Logic Networks (MLNs) seem a natural model to use, butthe exact way of leveraging MLNs is by no means obvious. We investigate threeways of applying MLNs to our task. In the first, we simply use the extractedscience rules directly as MLN clauses. Unlike typical MLN applications, ourdomain has long and complex rules, leading to an unmanageable number ofgroundings. We exploit the structure present in hard constraints to improvetractability, but the formulation remains ineffective. In the second approach,we instead interpret science rules as describing prototypical entities, thusmapping rules directly to grounded MLN assertions, whose constants are thenclustered using existing entity resolution methods. This drastically simplifiesthe network, but still suffers from brittleness. Finally, our third approach,called Praline, uses MLNs to align the lexical elements as well as define andcontrol how inference should be performed in this task. Our experiments,demonstrating a 15\% accuracy boost and a 10x reduction in runtime, suggestthat the flexibility and different inference semantics of Praline are a betterfit for the natural language question answering task.
arxiv-1507-02971 | Scalable MCMC for Large Data Problems using Data Subsampling and the Difference Estimator |  http://arxiv.org/abs/1507.02971  | author:Matias Quiroz, Mattias Villani, Robert Kohn category:stat.ME stat.CO stat.ML published:2015-07-10 summary:We propose a generic Markov Chain Monte Carlo (MCMC) algorithm to speed upcomputations for datasets with many observations. A key feature of our approachis the use of the highly efficient difference estimator from the surveysampling literature to estimate the log-likelihood accurately using only asmall fraction of the data. Our algorithm improves on the $O(n)$ complexity ofregular MCMC by operating over local data clusters instead of the full samplewhen computing the likelihood. The likelihood estimate is used in aPseudo-marginal framework to sample from a perturbed posterior which is within$O(m^{-1/2})$ of the true posterior, where $m$ is the subsample size. Themethod is applied to a logistic regression model to predict firm bankruptcy fora large data set. We document a significant speed up in comparison to thestandard MCMC on the full dataset.
arxiv-1507-02750 | Utility-based Dueling Bandits as a Partial Monitoring Game |  http://arxiv.org/abs/1507.02750  | author:Pratik Gajane, Tanguy Urvoy category:cs.LG published:2015-07-10 summary:Partial monitoring is a generic framework for sequential decision-making withincomplete feedback. It encompasses a wide class of problems such as duelingbandits, learning with expect advice, dynamic pricing, dark pools, and labelefficient prediction. We study the utility-based dueling bandit problem as aninstance of partial monitoring problem and prove that it fits the time-regretpartial monitoring hierarchy as an easy - i.e. Theta (sqrt{T})- instance. Wesurvey some partial monitoring algorithms and see how they could be used tosolve dueling bandits efficiently. Keywords: Online learning, Dueling Bandits,Partial Monitoring, Partial Feedback, Multiarmed Bandits
arxiv-1507-02879 | Deep Perceptual Mapping for Thermal to Visible Face Recognition |  http://arxiv.org/abs/1507.02879  | author:M. Saquib Sarfraz, Rainer Stiefelhagen category:cs.CV published:2015-07-10 summary:Cross modal face matching between the thermal and visible spectrum is a muchde- sired capability for night-time surveillance and security applications. Dueto a very large modality gap, thermal-to-visible face recognition is one of themost challenging face matching problem. In this paper, we present an approachto bridge this modality gap by a significant margin. Our approach captures thehighly non-linear relationship be- tween the two modalities by using a deepneural network. Our model attempts to learn a non-linear mapping from visibleto thermal spectrum while preserving the identity in- formation. We showsubstantive performance improvement on a difficult thermal-visible facedataset. The presented approach improves the state-of-the-art by more than 10%in terms of Rank-1 identification and bridge the drop in performance due to themodality gap by more than 40%.
arxiv-1507-03040 | Tight Risk Bounds for Multi-Class Margin Classifiers |  http://arxiv.org/abs/1507.03040  | author:Yury Maximov, Daria Reshetova category:stat.ML cs.LG published:2015-07-10 summary:We consider a problem of risk estimation for large-margin multi-classclassifiers. We propose a novel risk bound for the multi-class classificationproblem. The bound involves the marginal distribution of the classifier and theRademacher complexity of the hypothesis class. We prove that our bound is tightin the number of classes. Finally, we compare our bound with the related onesand provide a simplified version of the bound for the multi-classclassification with kernel based hypotheses.
arxiv-1507-02925 | Completely random measures for modelling block-structured networks |  http://arxiv.org/abs/1507.02925  | author:Tue Herlau, Mikkel N. Schmidt, Morten Mørup category:stat.ML published:2015-07-10 summary:Many statistical methods for network data parameterize the edge-probabilityby attributing latent traits to the vertices such as block structure and assumeexchangeability in the sense of the Aldous-Hoover representation theorem.Empirical studies of networks indicate that many real-world networks have apower-law distribution of the vertices which in turn implies the number ofedges scale slower than quadratically in the number of vertices. Theseassumptions are fundamentally irreconcilable as the Aldous-Hoover theoremimplies quadratic scaling of the number of edges. Recently Caron and Fox (2014)proposed the use of a different notion of exchangeability due to Kallenberg(2009) and obtained a network model which admits power-law behaviour whileretaining desirable statistical properties, however this model does not capturelatent vertex traits such as block-structure. In this work we re-introduce theuse of block-structure for network models obeying Kallenberg's notion ofexchangeability and thereby obtain a model which admits the inference ofblock-structure and edge inhomogeneity. We derive a simple expression for thelikelihood and an efficient sampling method. The obtained model is notsignificantly more difficult to implement than existing approaches toblock-modelling and performs well on real network datasets.
arxiv-1507-03032 | Spectral Smoothing via Random Matrix Perturbations |  http://arxiv.org/abs/1507.03032  | author:Jacob Abernethy, Chansoo Lee, Ambuj Tewari category:cs.LG published:2015-07-10 summary:We consider stochastic smoothing of spectral functions of matrices usingperturbations commonly studied in random matrix theory. We show that a spectralfunction remains spectral when smoothed using a unitarily invariantperturbation distribution. We then derive state-of-the-art smoothing bounds forthe maximum eigenvalue function using the Gaussian Orthogonal Ensemble (GOE).Smoothing the maximum eigenvalue function is important for applications insemidefinite optimization and online learning. As a direct consequence of ourGOE smoothing results, we obtain an $O((N \log N)^{1/4} \sqrt{T})$ expectedregret bound for the online variance minimization problem using an algorithmthat performs only a single maximum eigenvector computation per time step. Here$T$ is the number of rounds and $N$ is the matrix dimension. Our algorithm andits analysis also extend to the more general online PCA problem where thelearner has to output a rank $k$ subspace. The algorithm just requirescomputing $k$ maximum eigenvectors per step and enjoys an $O(k (N \log N)^{1/4}\sqrt{T})$ expected regret bound.
arxiv-1507-02772 | Riemannian Dictionary Learning and Sparse Coding for Positive Definite Matrices |  http://arxiv.org/abs/1507.02772  | author:Anoop Cherian, Suvrit Sra category:cs.CV published:2015-07-10 summary:Data encoded as symmetric positive definite (SPD) matrices frequently arisein many areas of computer vision and machine learning. While these matricesform an open subset of the Euclidean space of symmetric matrices, viewing themthrough the lens of non-Euclidean Riemannian geometry often turns out to bebetter suited in capturing several desirable data properties. However,formulating classical machine learning algorithms within such a geometry isoften non-trivial and computationally expensive. Inspired by the great successof dictionary learning and sparse coding for vector-valued data, our goal inthis paper is to represent data in the form of SPD matrices as sparse coniccombinations of SPD atoms from a learned dictionary via a Riemannian geometricapproach. To that end, we formulate a novel Riemannian optimization objectivefor dictionary learning and sparse coding in which the representation loss ischaracterized via the affine invariant Riemannian metric. We also present acomputationally simple algorithm for optimizing our model. Experiments onseveral computer vision datasets demonstrate superior classification andretrieval performance using our approach when compared to sparse coding viaalternative non-Riemannian formulations.
arxiv-1507-03003 | High-Dimensional Asymptotics of Prediction: Ridge Regression and Classification |  http://arxiv.org/abs/1507.03003  | author:Edgar Dobriban, Stefan Wager category:math.ST stat.ML stat.TH published:2015-07-10 summary:We provide a unified analysis of the predictive risk of ridge regression andregularized discriminant analysis in a dense random effects model. We work in ahigh-dimensional asymptotic regime where $p, n \to \infty$ and $p/n \to \gamma\in (0, \, \infty)$, and allow for arbitrary covariance among the features. Forboth methods, we provide an explicit and efficiently computable expression forthe limiting predictive risk, which depends only on the spectrum of thefeature-covariance matrix, the signal strength, and the aspect ratio $\gamma$.Especially in the case of regularized discriminant analysis, we find thatpredictive accuracy has a nuanced dependence on the eigenvalue distribution ofthe covariance matrix, suggesting that analyses based on the operator norm ofthe covariance matrix may not be sharp. Our results also uncover severalqualitative insights about both methods: for example, with ridge regression,there is an exact inverse relation between the limiting predictive risk and thelimiting estimation risk given a fixed signal strength. Our analysis builds onrecent advances in random matrix theory.
arxiv-1507-02801 | Adaptive Mixtures of Factor Analyzers |  http://arxiv.org/abs/1507.02801  | author:Heysem Kaya, Albert Ali Salah category:stat.ML cs.IT cs.LG math.IT G.3; I.5.4 published:2015-07-10 summary:A mixture of factor analyzers is a semi-parametric density estimator thatgeneralizes the well-known mixtures of Gaussians model by allowing eachGaussian in the mixture to be represented in a different lower-dimensionalmanifold. This paper presents a robust and parsimonious model selectionalgorithm for training a mixture of factor analyzers, carrying out simultaneousclustering and locally linear, globally nonlinear dimensionality reduction.Permitting different number of factors per mixture component, the algorithmadapts the model complexity to the data complexity. We compare the proposedalgorithm with related automatic model selection algorithms on a number ofbenchmarks. The results indicate the effectiveness of this fast and robustapproach in clustering, manifold learning and class-conditional modeling.
arxiv-1507-02379 | Understanding Intra-Class Knowledge Inside CNN |  http://arxiv.org/abs/1507.02379  | author:Donglai Wei, Bolei Zhou, Antonio Torrabla, William Freeman category:cs.CV published:2015-07-09 summary:Convolutional Neural Network (CNN) has been successful in image recognitiontasks, and recent works shed lights on how CNN separates different classes withthe learned inter-class knowledge through visualization. In this work, weinstead visualize the intra-class knowledge inside CNN to better understand howan object class is represented in the fully-connected layers. To invert the intra-class knowledge into more interpretable images, wepropose a non-parametric patch prior upon previous CNN visualization models.With it, we show how different "styles" of templates for an object class areorganized by CNN in terms of location and content, and represented in ahierarchical and ensemble way. Moreover, such intra-class knowledge can be usedin many interesting applications, e.g. style-based image retrieval andstyle-based object completion.
arxiv-1507-02356 | Intrinsic Non-stationary Covariance Function for Climate Modeling |  http://arxiv.org/abs/1507.02356  | author:Chintan A. Dalal, Vladimir Pavlovic, Robert E. Kopp category:stat.ML cs.LG published:2015-07-09 summary:Designing a covariance function that represents the underlying correlation isa crucial step in modeling complex natural systems, such as climate models.Geospatial datasets at a global scale usually suffer from non-stationarity andnon-uniformly smooth spatial boundaries. A Gaussian process regression using anon-stationary covariance function has shown promise for this task, as thiscovariance function adapts to the variable correlation structure of theunderlying distribution. In this paper, we generalize the non-stationarycovariance function to address the aforementioned global scale geospatialissues. We define this generalized covariance function as an intrinsicnon-stationary covariance function, because it uses intrinsic statistics of thesymmetric positive definite matrices to represent the characteristic lengthscale and, thereby, models the local stochastic process. Experiments on asynthetic and real dataset of relative sea level changes across the worlddemonstrate improvements in the error metrics for the regression estimatesusing our newly proposed approach.
arxiv-1507-02355 | The Shadows of a Cycle Cannot All Be Paths |  http://arxiv.org/abs/1507.02355  | author:Prosenjit Bose, Jean-Lou De Carufel, Michael G. Dobbins, Heuna Kim, Giovanni Viglietta category:cs.CG cs.CV math.MG published:2015-07-09 summary:A "shadow" of a subset $S$ of Euclidean space is an orthogonal projection of$S$ into one of the coordinate hyperplanes. In this paper we show that it isnot possible for all three shadows of a cycle (i.e., a simple closed curve) in$\mathbb R^3$ to be paths (i.e., simple open curves). We also show two contrasting results: the three shadows of a path in $\mathbbR^3$ can all be cycles (although not all convex) and, for every $d\geq 1$,there exists a $d$-sphere embedded in $\mathbb R^{d+2}$ whose $d+2$ shadowshave no holes (i.e., they deformation-retract onto a point).
arxiv-1507-02347 | Achieving Synergy in Cognitive Behavior of Humanoids via Deep Learning of Dynamic Visuo-Motor-Attentional Coordination |  http://arxiv.org/abs/1507.02347  | author:Jungsik Hwang, Minju Jung, Naveen Madapana, Jinhyung Kim, Minkyu Choi, Jun Tani category:cs.AI cs.LG cs.RO published:2015-07-09 summary:The current study examines how adequate coordination among differentcognitive processes including visual recognition, attention switching, actionpreparation and generation can be developed via learning of robots byintroducing a novel model, the Visuo-Motor Deep Dynamic Neural Network (VMDNN).The proposed model is built on coupling of a dynamic vision network, a motorgeneration network, and a higher level network allocated on top of these two.The simulation experiments using the iCub simulator were conducted forcognitive tasks including visual object manipulation responding to humangestures. The results showed that synergetic coordination can be developed viaiterative learning through the whole network when spatio-temporal hierarchy andtemporal one can be self-organized in the visual pathway and in the motorpathway, respectively, such that the higher level can manipulate them withabstraction.
arxiv-1507-02346 | Neural Network Classifiers for Natural Food Products |  http://arxiv.org/abs/1507.02346  | author:Jaderick P. Pabico, Alona V. De Grano, Alan L. Zarsuela category:cs.CV published:2015-07-09 summary:Two cheap, off-the-shelf machine vision systems (MVS), each using anartificial neural network (ANN) as classifier, were developed, improved andevaluated to automate the classification of tomato ripeness and acceptabilityof eggs, respectively. Six thousand color images of human-graded tomatoes and750 images of human-graded eggs were used to train, test, and validate severalmulti-layered ANNs. The ANNs output the corresponding grade of the produce byaccepting as inputs the spectral patterns of the background-less image. In bothMVS, the ANN with the highest validation rate was automatically chosen by aheuristic and its performance compared to that of the human graders'. Using thevalidation set, the MVS correctly graded 97.00\% and 86.00\% of the tomato andegg data, respectively. The human grader's, however, were measured to performat a daily average of 92.65\% and 72.67\% for tomato and egg grading,respectively. This results show that an ANN-based MVS is a potentialalternative to manual grading.
arxiv-1507-02385 | Towards Effective Codebookless Model for Image Classification |  http://arxiv.org/abs/1507.02385  | author:Qilong Wang, Peihua Li, Lei Zhang, Wangmeng Zuo category:cs.CV published:2015-07-09 summary:The bag-of-features (BoF) model for image classification has been thoroughlystudied over the last decade. Different from the widely used BoF methods whichmodeled images with a pre-trained codebook, the alternative codebook free imagemodeling method, which we call Codebookless Model (CLM), attracted littleattention. In this paper, we present an effective CLM that represents an imagewith a single Gaussian for classification. By embedding Gaussian manifold intoa vector space, we show that the simple incorporation of our CLM into a linearclassifier achieves very competitive accuracy compared with state-of-the-artBoF methods (e.g., Fisher Vector). Since our CLM lies in a high dimensionalRiemannian manifold, we further propose a joint learning method of low-ranktransformation with support vector machine (SVM) classifier on the Gaussianmanifold, in order to reduce computational and storage cost. To study andalleviate the side effect of background clutter on our CLM, we also present asimple yet effective partial background removal method based on saliencydetection. Experiments are extensively conducted on eight widely used databasesto demonstrate the effectiveness and efficiency of our CLM method.
arxiv-1507-02564 | Sampling from a log-concave distribution with Projected Langevin Monte Carlo |  http://arxiv.org/abs/1507.02564  | author:Sébastien Bubeck, Ronen Eldan, Joseph Lehec category:math.PR cs.DS cs.LG published:2015-07-09 summary:We extend the Langevin Monte Carlo (LMC) algorithm to compactly supportedmeasures via a projection step, akin to projected Stochastic Gradient Descent(SGD). We show that (projected) LMC allows to sample in polynomial time from alog-concave distribution with smooth potential. This gives a new Markov chainto sample from a log-concave distribution. Our main result shows in particularthat when the target distribution is uniform, LMC mixes in $\tilde{O}(n^7)$steps (where $n$ is the dimension). We also provide preliminary experimentalevidence that LMC performs at least as well as hit-and-run, for which a bettermixing time of $\tilde{O}(n^4)$ was proved by Lov{\'a}sz and Vempala.
arxiv-1507-02528 | Faster Convex Optimization: Simulated Annealing with an Efficient Universal Barrier |  http://arxiv.org/abs/1507.02528  | author:Jacob Abernethy, Elad Hazan category:math.OC cs.LG published:2015-07-09 summary:This paper explores a surprising equivalence between two seemingly-distinctconvex optimization methods. We show that simulated annealing, a well-studiedrandom walk algorithms, is directly equivalent, in a certain sense, to thecentral path interior point algorithm for the the entropic universal barrierfunction. This connection exhibits several benefits. First, we are able improvethe state of the art time complexity for convex optimization under themembership oracle model. We improve the analysis of the randomized algorithm ofKalai and Vempala by utilizing tools developed by Nesterov and Nemirovskii thatunderly the central path following interior point algorithm. We are able totighten the temperature schedule for simulated annealing which gives animproved running time, reducing by square root of the dimension in certaininstances. Second, we get an efficient randomized interior point method with anefficiently computable universal barrier for any convex set described by amembership oracle. Previously, efficiently computable barriers were known onlyfor particular convex sets.
arxiv-1507-02380 | Learning Structured Ordinal Measures for Video based Face Recognition |  http://arxiv.org/abs/1507.02380  | author:Ran He, Tieniu Tan, Larry Davis, Zhenan Sun category:cs.CV published:2015-07-09 summary:This paper presents a structured ordinal measure method for video-based facerecognition that simultaneously learns ordinal filters and structured ordinalfeatures. The problem is posed as a non-convex integer program problem thatincludes two parts. The first part learns stable ordinal filters to projectvideo data into a large-margin ordinal space. The second seeks self-correctingand discrete codes by balancing the projected data and a rank-one ordinalmatrix in a structured low-rank way. Unsupervised and supervised structures areconsidered for the ordinal matrix. In addition, as a complement to hierarchicalstructures, deep feature representations are integrated into our method toenhance coding stability. An alternating minimization method is employed tohandle the discrete and low-rank constraints, yielding high-quality codes thatcapture prior structures well. Experimental results on three commonly used facevideo databases show that our method with a simple voting classifier canachieve state-of-the-art recognition rates using fewer features and samples.
arxiv-1507-02703 | Robot In a Room: Toward Perfect Object Recognition in Closed Environments |  http://arxiv.org/abs/1507.02703  | author:Shuran Song, Linguang Zhang, Jianxiong Xiao category:cs.CV published:2015-07-09 summary:While general object recognition is still far from being solved, this paperproposes a way for a robot to recognize every object at an almost human-levelaccuracy. Our key observation is that many robots will stay in a relativelyclosed environment (e.g. a house or an office). By constraining a robot to stayin a limited territory, we can ensure that the robot has seen most objectsbefore and the speed of introducing a new object is slow. Furthermore, we canbuild a 3D map of the environment to reliably subtract the background to makerecognition easier. We propose extremely robust algorithms to obtain a 3D mapand enable humans to collectively annotate objects. During testing time, ouralgorithm can recognize all objects very reliably, and query humans from crowdsourcing platform if confidence is low or new objects are identified. Thispaper explains design decisions in building such a system, and constructs abenchmark for extensive evaluation. Experiments suggest that making robotvision appear to be working from an end user's perspective is a reachable goaltoday, as long as the robot stays in a closed environment. By formulating thistask, we hope to lay the foundation of a new direction in vision for robotics.Code and data will be available upon acceptance.
arxiv-1507-02672 | Semi-Supervised Learning with Ladder Networks |  http://arxiv.org/abs/1507.02672  | author:Antti Rasmus, Harri Valpola, Mikko Honkala, Mathias Berglund, Tapani Raiko category:cs.NE cs.LG stat.ML published:2015-07-09 summary:We combine supervised learning with unsupervised learning in deep neuralnetworks. The proposed model is trained to simultaneously minimize the sum ofsupervised and unsupervised cost functions by backpropagation, avoiding theneed for layer-wise pre-training. Our work builds on the Ladder networkproposed by Valpola (2015), which we extend by combining the model withsupervision. We show that the resulting model reaches state-of-the-artperformance in semi-supervised MNIST and CIFAR-10 classification, in additionto permutation-invariant MNIST classification with all labels.
arxiv-1507-02743 | Locally Non-linear Embeddings for Extreme Multi-label Learning |  http://arxiv.org/abs/1507.02743  | author:Kush Bhatia, Himanshu Jain, Purushottam Kar, Prateek Jain, Manik Varma category:cs.LG cs.IR math.OC stat.ML published:2015-07-09 summary:The objective in extreme multi-label learning is to train a classifier thatcan automatically tag a novel data point with the most relevant subset oflabels from an extremely large label set. Embedding based approaches maketraining and prediction tractable by assuming that the training label matrix islow-rank and hence the effective number of labels can be reduced by projectingthe high dimensional label vectors onto a low dimensional linear subspace.Still, leading embedding approaches have been unable to deliver high predictionaccuracies or scale to large problems as the low rank assumption is violated inmost real world applications. This paper develops the X-One classifier to address both limitations. Themain technical contribution in X-One is a formulation for learning a smallensemble of local distance preserving embeddings which can accurately predictinfrequently occurring (tail) labels. This allows X-One to break free of thetraditional low-rank assumption and boost classification accuracy by learningembeddings which preserve pairwise distances between only the nearest labelvectors. We conducted extensive experiments on several real-world as well as benchmarkdata sets and compared our method against state-of-the-art methods for extrememulti-label classification. Experiments reveal that X-One can makesignificantly more accurate predictions then the state-of-the-art methodsincluding both embeddings (by as much as 35%) as well as trees (by as much as6%). X-One can also scale efficiently to data sets with a million labels whichare beyond the pale of leading embedding methods.
arxiv-1507-02387 | Decentralized Joint-Sparse Signal Recovery: A Sparse Bayesian Learning Approach |  http://arxiv.org/abs/1507.02387  | author:Saurabh Khanna, Chandra R. Murthy category:cs.LG cs.IT math.IT published:2015-07-09 summary:This work proposes a decentralized, iterative, Bayesian algorithm calledCB-DSBL for in-network estimation of multiple jointly sparse vectors by anetwork of nodes, using noisy and underdetermined linear measurements. Theproposed algorithm exploits the network wide joint sparsity of the un- knownsparse vectors to recover them from significantly fewer number of localmeasurements compared to standalone sparse signal recovery schemes. To reducethe amount of inter-node communication and the associated overheads, the nodesexchange messages with only a small subset of their single hop neighbors. Underthis communication scheme, we separately analyze the convergence of theunderlying Alternating Directions Method of Multipliers (ADMM) iterations usedin our proposed algorithm and establish its linear convergence rate. Thefindings from the convergence analysis of decentralized ADMM are used toaccelerate the convergence of the proposed CB-DSBL algorithm. Using Monte Carlosimulations, we demonstrate the superior signal reconstruction as well assupport recovery performance of our proposed algorithm compared to existingdecentralized algorithms: DRL-1, DCOMP and DCSP.
arxiv-1507-02438 | Generalized Video Deblurring for Dynamic Scenes |  http://arxiv.org/abs/1507.02438  | author:Tae Hyun Kim, Kyoung Mu Lee category:cs.CV published:2015-07-09 summary:Several state-of-the-art video deblurring methods are based on a strongassumption that the captured scenes are static. These methods fail to deblurblurry videos in dynamic scenes. We propose a video deblurring method to dealwith general blurs inherent in dynamic scenes, contrary to other methods. Tohandle locally varying and general blurs caused by various sources, such ascamera shake, moving objects, and depth variation in a scene, we approximatepixel-wise kernel with bidirectional optical flows. Therefore, we propose asingle energy model that simultaneously estimates optical flows and latentframes to solve our deblurring problem. We also provide a framework andefficient solvers to optimize the energy model. By minimizing the proposedenergy function, we achieve significant improvements in removing blurs andestimating accurate optical flows in blurry frames. Extensive experimentalresults demonstrate the superiority of the proposed method in real andchallenging videos that state-of-the-art methods fail in either deblurring oroptical flow estimation.
arxiv-1507-02558 | Multi-Type Activity Recognition in Robot-Centric Scenarios |  http://arxiv.org/abs/1507.02558  | author:Ilaria Gori, J. K. Aggarwal, Larry Matthies, Michael S. Ryoo category:cs.CV published:2015-07-09 summary:Activity recognition is very useful in scenarios where robots interact with,monitor or assist humans. In the past years many types of activities -- singleactions, two persons interactions or ego-centric activities, to name a few --have been analyzed. Whereas traditional methods treat such types of activitiesseparately, an autonomous robot should be able to detect and recognize multipletypes of activities to effectively fulfill its tasks. We propose a method thatis intrinsically able to detect and recognize activities of different typesthat happen in sequence or concurrently. We present a new unified descriptor,called Relation History Image (RHI), which can be extracted from all theactivity types we are interested in. We then formulate an optimizationprocedure to detect and recognize activities of different types. We apply ourapproach to a new dataset recorded from a robot-centric perspective andsystematically evaluate its quality compared to multiple baselines. Finally, weshow the efficacy of the RHI descriptor on publicly available datasetsperforming extensive comparisons.
arxiv-1507-02620 | Deep filter banks for texture recognition, description, and segmentation |  http://arxiv.org/abs/1507.02620  | author:Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Andrea Vedaldi category:cs.CV published:2015-07-09 summary:Visual textures have played a key role in image understanding because theyconvey important semantics of images, and because texture representations thatpool local image descriptors in an orderless manner have had a tremendousimpact in diverse applications. In this paper we make several contributions totexture understanding. First, instead of focusing on texture instance andmaterial category recognition, we propose a human-interpretable vocabulary oftexture attributes to describe common texture patterns, complemented by a newdescribable texture dataset for benchmarking. Second, we look at the problem ofrecognizing materials and texture attributes in realistic imaging conditions,including when textures appear in clutter, developing corresponding benchmarkson top of the recently proposed OpenSurfaces dataset. Third, we revisit classictexture representations, including bag-of-visual-words and the Fisher vectors,in the context of deep learning and show that these have excellent efficiencyand generalization properties if the convolutional layers of a deep model areused as filter banks. We obtain in this manner state-of-the-art performance innumerous datasets well beyond textures, an efficient method to apply deepfeatures to image regions, as well as benefit in transferring features from onedomain to another.
arxiv-1507-02628 | FAQ-based Question Answering via Word Alignment |  http://arxiv.org/abs/1507.02628  | author:Zhiguo Wang, Abraham Ittycheriah category:cs.CL published:2015-07-09 summary:In this paper, we propose a novel word-alignment-based method to solve theFAQ-based question answering task. First, we employ a neural network model tocalculate question similarity, where the word alignment between two questionsis used for extracting features. Second, we design a bootstrap-based featureextraction method to extract a small set of effective lexical features. Third,we propose a learning-to-rank algorithm to train parameters more suitable forthe ranking tasks. Experimental results, conducted on three languages (English,Spanish and Japanese), demonstrate that the question similarity model is moreeffective than baseline systems, the sparse features bring 5% improvements ontop-1 accuracy, and the learning-to-rank algorithm works significantly betterthan the traditional method. We further evaluate our method on the answersentence selection task. Our method outperforms all the previous systems on thestandard TREC data set.
arxiv-1507-02482 | Differentially Private Ordinary Least Squares: $t$-Values, Confidence Intervals and Rejecting Null-Hypotheses |  http://arxiv.org/abs/1507.02482  | author:Or Sheffet category:cs.DS cs.CR cs.LG published:2015-07-09 summary:Linear regression is one of the most prevalent techniques in data analysis.Given a large collection of samples composed of features $\vec x$ and a label$y$, linear regression is used to find the best prediction of the label as alinear combination of the features. However, it is also common to use linearregression for its \emph{explanatory} capabilities rather than labelprediction. Ordinary Least Squares (OLS) is often used in statistics toestablish a correlation between an attribute (e.g. gender) and a label (e.g.income) in the presence of other features. Under the assumption of a certainrandom generative model for the data, OLS derives \emph{$t$-values} ---representing the likelihood of each real value to be the true correlation inthe underlying distribution. Using $t$-values, OLS can release a\emph{confidence interval} that is likely to contain the true correlation. Whenthis interval does not intersect the origin, we can \emph{reject the nullhypothesis} as it is likely that $x_j$ indeed has a non-zero correlation with$y$. Our work aims at achieving similar guarantees on data under differentiallyprivate estimators. We use the Gaussian Johnson-Lindenstrauss transform, whichhas been shown to satisfy differential privacy if the given data has largesingular values. We analyze the result of projecting the data using JLT underthe OLS model and derive approximated $t$-values, confidence intervals andbound the number of samples needed to reject the null hypothesis when the datais drawn i.i.d from a multivariate Gaussian. When not all singular values ofthe data are sufficiently large, we increase the singular values, thus ourprojected data yields an approximation for the Ridge Regression problem. Wederive, under certain conditions, confidence intervals in this case as well. Wealso derive confidence intervals for the "Analyze Gauss" algorithm of Dwork etal.
arxiv-1507-02642 | Quantum Inspired Training for Boltzmann Machines |  http://arxiv.org/abs/1507.02642  | author:Nathan Wiebe, Ashish Kapoor, Christopher Granade, Krysta M Svore category:cs.LG quant-ph published:2015-07-09 summary:We present an efficient classical algorithm for training deep Boltzmannmachines (DBMs) that uses rejection sampling in concert with variationalapproximations to estimate the gradients of the training objective function.Our algorithm is inspired by a recent quantum algorithm for training DBMs. Weobtain rigorous bounds on the errors in the approximate gradients; in turn, wefind that choosing the instrumental distribution to minimize the alpha=2divergence with the Gibbs state minimizes the asymptotic algorithmiccomplexity. Our rejection sampling approach can yield more accurate gradientsthan low-order contrastive divergence training and the costs incurred infinding increasingly accurate gradients can be easily parallelized. Finally ouralgorithm can train full Boltzmann machines and scales more favorably with thenumber of layers in a DBM than greedy contrastive divergence training.
arxiv-1507-02447 | Data Mining of Causal Relations from Text: Analysing Maritime Accident Investigation Reports |  http://arxiv.org/abs/1507.02447  | author:Santosh Tirunagari category:cs.IR cs.CL published:2015-07-09 summary:Text mining is a process of extracting information of interest from text.Such a method includes techniques from various areas such as InformationRetrieval (IR), Natural Language Processing (NLP), and Information Extraction(IE). In this study, text mining methods are applied to extract causalrelations from maritime accident investigation reports collected from theMarine Accident Investigation Branch (MAIB). These causal relations provideinformation on various mechanisms behind accidents, including human andorganizational factors relating to the accident. The objective of this study isto facilitate the analysis of the maritime accident investigation reports, bymeans of extracting contributory causes with more feasibility. A carefulinvestigation of contributory causes from the reports provide opportunity toimprove safety in future. Two methods have been employed in this study to extract the causal relations.They are 1) Pattern classification method and 2) Connectives method. Theearlier one uses naive Bayes and Support Vector Machines (SVM) as classifiers.The latter simply searches for the words connecting cause and effect insentences. The causal patterns extracted using these two methods are compared to themanual (human expert) extraction. The pattern classification method showed afair and sensible performance with F-measure(average) = 65% when compared toconnectives method with F-measure(average) = 58%. This study is an evidence,that text mining methods could be employed in extracting causal relations frommarine accident investigation reports.
arxiv-1507-02407 | Planar Ultrametric Rounding for Image Segmentation |  http://arxiv.org/abs/1507.02407  | author:Julian Yarkony, Charless C. Fowlkes category:cs.DS cs.CG cs.CV 68T45 published:2015-07-09 summary:We study the problem of hierarchical clustering on planar graphs. Weformulate this in terms of an LP relaxation of ultrametric rounding. To solvethis LP efficiently we introduce a dual cutting plane scheme that uses minimumcost perfect matching as a subroutine in order to efficiently explore the spaceof planar partitions. We apply our algorithm to the problem of hierarchicalimage segmentation.
arxiv-1507-02592 | Fast rates in statistical and online learning |  http://arxiv.org/abs/1507.02592  | author:Tim van Erven, Peter D. Grünwald, Nishant A. Mehta, Mark D. Reid, Robert C. Williamson category:cs.LG stat.ML published:2015-07-09 summary:The speed with which a learning algorithm converges as it is presented withmore data is a central problem in machine learning --- a fast rate ofconvergence means less data is needed for the same level of performance. Thepursuit of fast rates in online and statistical learning has led to thediscovery of many conditions in learning theory under which fast learning ispossible. We show that most of these conditions are special cases of a single,unifying condition, that comes in two forms: the central condition for 'proper'learning algorithms that always output a hypothesis in the given model, andstochastic mixability for online algorithms that may make predictions outsideof the model. We show that under surprisingly weak assumptions both conditionsare, in a certain sense, equivalent. The central condition has are-interpretation in terms of convexity of a set of pseudoprobabilities,linking it to density estimation under misspecification. For bounded losses, weshow how the central condition enables a direct proof of fast rates and weprove its equivalence to the Bernstein condition, itself a generalization ofthe Tsybakov margin condition, both of which have played a central role inobtaining fast rates in statistical learning. Yet, while the Bernsteincondition is two-sided, the central condition is one-sided, making it moresuitable to deal with unbounded losses. In its stochastic mixability form, ourcondition generalizes both a stochastic exp-concavity condition identified byJuditsky, Rigollet and Tsybakov and Vovk's notion of mixability. Our unifyingconditions thus provide a substantial step towards a characterization of fastrates in statistical learning, similar to how classical mixabilitycharacterizes constant regret in the sequential prediction with expert advicesetting.
arxiv-1507-02491 | Parameter Sensitivity Analysis of Social Spider Algorithm |  http://arxiv.org/abs/1507.02491  | author:James J. Q. Yu, Victor O. K. Li category:cs.NE published:2015-07-09 summary:Social Spider Algorithm (SSA) is a recently proposed general-purposereal-parameter metaheuristic designed to solve global numerical optimizationproblems. This work systematically benchmarks SSA on a suite of 11 functionswith different control parameters. We conduct parameter sensitivity analysis ofSSA using advanced non-parametric statistical tests to generate statisticallysignificant conclusion on the best performing parameter settings. Theconclusion can be adopted in future work to reduce the effort in parametertuning. In addition, we perform a success rate test to reveal the impact of thecontrol parameters on the convergence speed of the algorithm.
arxiv-1507-02492 | Adaptive Chemical Reaction Optimization for Global Numerical Optimization |  http://arxiv.org/abs/1507.02492  | author:James J. Q. Yu, Albert Y. S. Lam, Victor O. K. Li category:cs.NE published:2015-07-09 summary:A newly proposed chemical-reaction-inspired metaheurisic, Chemical ReactionOptimization (CRO), has been applied to many optimization problems in bothdiscrete and continuous domains. To alleviate the effort in tuning parameters,this paper reduces the number of optimization parameters in canonical CRO anddevelops an adaptive scheme to evolve them. Our proposed Adaptive CRO (ACRO)adapts better to different optimization problems. We perform simulations withACRO on a widely-used benchmark of continuous problems. The simulation resultsshow that ACRO has superior performance over canonical CRO.
arxiv-1507-02140 | Mining and Analyzing the Future Works in Scientific Articles |  http://arxiv.org/abs/1507.02140  | author:Yue Hu, Xiaojun Wan category:cs.DL cs.CL cs.IR published:2015-07-08 summary:Future works in scientific articles are valuable for researchers and they canguide researchers to new research directions or ideas. In this paper, we minethe future works in scientific articles in order to 1) provide an insight forfuture work analysis and 2) facilitate researchers to search and browse futureworks in a research area. First, we study the problem of future work extractionand propose a regular expression based method to address the problem. Second,we define four different categories for the future works by observing the dataand investigate the multi-class future work classification problem. Third, weapply the extraction method and the classification model to a paper dataset inthe computer science field and conduct a further analysis of the future works.Finally, we design a prototype system to search and demonstrate the futureworks mined from the scientific papers. Our evaluation results show that ourextraction method can get high precision and recall values and ourclassification model can also get good results and it outperforms severalbaseline models. Further analysis of the future work sentences also indicatesinteresting results.
arxiv-1507-02049 | DCTNet : A Simple Learning-free Approach for Face Recognition |  http://arxiv.org/abs/1507.02049  | author:Cong Jie Ng, Andrew Beng Jin Teoh category:cs.CV published:2015-07-08 summary:PCANet was proposed as a lightweight deep learning network that mainlyleverages Principal Component Analysis (PCA) to learn multistage filter banksfollowed by binarization and block-wise histograming. PCANet was shown workedsurprisingly well in various image classification tasks. However, PCANet isdata-dependence hence inflexible. In this paper, we proposed adata-independence network, dubbed DCTNet for face recognition in which we adoptDiscrete Cosine Transform (DCT) as filter banks in place of PCA. This ismotivated by the fact that 2D DCT basis is indeed a good approximation for highranked eigenvectors of PCA. Both 2D DCT and PCA resemble a kind of modulatedsine-wave patterns, which can be perceived as a bandpass filter bank. DCTNet isfree from learning as 2D DCT bases can be computed in advance. Besides that, wealso proposed an effective method to regulate the block-wise histogram featurevector of DCTNet for robustness. It is shown to provide surprising performanceboost when the probe image is considerably different in appearance from thegallery image. We evaluate the performance of DCTNet extensively on a number ofbenchmark face databases and being able to achieve on par with or often betteraccuracy performance than PCANet.
arxiv-1507-02186 | Extending local features with contextual information in graph kernels |  http://arxiv.org/abs/1507.02186  | author:Nicolò Navarin, Alessandro Sperduti, Riccardo Tesselli category:cs.LG published:2015-07-08 summary:Graph kernels are usually defined in terms of simpler kernels over localsubstructures of the original graphs. Different kernels consider differenttypes of substructures. However, in some cases they have similar predictiveperformances, probably because the substructures can be interpreted asapproximations of the subgraphs they induce. In this paper, we propose toassociate to each feature a piece of information about the context in which thefeature appears in the graph. A substructure appearing in two different graphswill match only if it appears with the same context in both graphs. We proposea kernel based on this idea that considers trees as substructures, and wherethe contexts are features too. The kernel is inspired from the framework in[6], even if it is not part of it. We give an efficient algorithm for computingthe kernel and show promising results on real-world graph classificationdatasets.
arxiv-1507-02150 | SAR Imaging of Moving Target based on Knowledge-aided Two-dimensional Autofocus |  http://arxiv.org/abs/1507.02150  | author:Xinhua Mao category:cs.IT cs.CV math.IT published:2015-07-08 summary:Due to uncertainty on target's motion, the range cell migration (RCM) andazimuth phase error (APE) of moving targets can't be completely compensated insynthetic aperture radar (SAR) processing. Therefore, moving targets oftenappear two-dimensional (2-D) defocused in SAR images. In this paper, a 2-Dautofocus method for refocusing defocused moving targets in SAR images ispresented. The new method only requires a direct estimate of APE, while theresidual 2-D phase error ( or RCM) is computed from the estimated APE byexploiting the analytical relationship between the 2-D phase error ( or RCM)and APE. Because the parameter estimation is performed in the reduced-dimensionspace by exploiting prior knowledge on phase error structure, the proposedapproach offers clear advantages in both computational efficiency andestimation accuracy.
arxiv-1507-02145 | Learning to Mine Chinese Coordinate Terms Using the Web |  http://arxiv.org/abs/1507.02145  | author:Xiaojiang Huang, Xiaojun Wan, Jianguo Xiao category:cs.CL published:2015-07-08 summary:Coordinate relation refers to the relation between instances of a concept andthe relation between the directly hyponyms of a concept. In this paper, wefocus on the task of extracting terms which are coordinate with a user givenseed term in Chinese, and grouping the terms which belong to different conceptsif the seed term has several meanings. We propose a semi-supervised method thatintegrates manually defined linguistic patterns and automatically learnedsemi-structural patterns to extract coordinate terms in Chinese from web searchresults. In addition, terms are grouped into different concepts based on theirco-occurring terms and contexts. We further calculate the saliency scores ofextracted terms and rank them accordingly. Experimental results demonstratethat our proposed method generates results with high quality and wide coverage.
arxiv-1507-02216 | Robust Sparse Blind Source Separation |  http://arxiv.org/abs/1507.02216  | author:Cecile Chenot, Jerome Bobin, Jeremy Rapin category:stat.AP cs.LG stat.ML published:2015-07-08 summary:Blind Source Separation is a widely used technique to analyze multichanneldata. In many real-world applications, its results can be significantlyhampered by the presence of unknown outliers. In this paper, a novel algorithmcoined rGMCA (robust Generalized Morphological Component Analysis) isintroduced to retrieve sparse sources in the presence of outliers. Itexplicitly estimates the sources, the mixing matrix, and the outliers. It alsotakes advantage of the estimation of the outliers to further implement aweighting scheme, which provides a highly robust separation procedure.Numerical experiments demonstrate the efficiency of rGMCA to estimate themixing matrix in comparison with standard BSS techniques.
arxiv-1507-02293 | COEVOLVE: A Joint Point Process Model for Information Diffusion and Network Co-evolution |  http://arxiv.org/abs/1507.02293  | author:Mehrdad Farajtabar, Yichen Wang, Manuel Gomez Rodriguez, Shuang Li, Hongyuan Zha, Le Song category:cs.SI cs.LG physics.soc-ph stat.ML published:2015-07-08 summary:Information diffusion in online social networks is affected by the underlyingnetwork topology, but it also has the power to change it. Online users areconstantly creating new links when exposed to new information sources, and inturn these links are alternating the way information spreads. However, thesetwo highly intertwined stochastic processes, information diffusion and networkevolution, have been predominantly studied separately, ignoring theirco-evolutionary dynamics. We propose a temporal point process model, COEVOLVE, for such joint dynamics,allowing the intensity of one process to be modulated by that of the other.This model allows us to efficiently simulate interleaved diffusion and networkevents, and generate traces obeying common diffusion and network patternsobserved in real-world networks. Furthermore, we also develop a convexoptimization framework to learn the parameters of the model from historicaldiffusion and network evolution traces. We experimented with both syntheticdata and data gathered from Twitter, and show that our model provides a goodfit to the data as well as more accurate predictions than alternatives.
arxiv-1507-02188 | AutoCompete: A Framework for Machine Learning Competition |  http://arxiv.org/abs/1507.02188  | author:Abhishek Thakur, Artus Krohn-Grimberghe category:stat.ML cs.LG published:2015-07-08 summary:In this paper, we propose AutoCompete, a highly automated machine learningframework for tackling machine learning competitions. This framework has beenlearned by us, validated and improved over a period of more than two years byparticipating in online machine learning competitions. It aims at minimizinghuman interference required to build a first useful predictive model and toassess the practical difficulty of a given machine learning challenge. Theproposed system helps in identifying data types, choosing a machine learn- ingmodel, tuning hyper-parameters, avoiding over-fitting and optimization for aprovided evaluation metric. We also observe that the proposed system producesbetter (or comparable) results with less runtime as compared to otherapproaches.
arxiv-1507-02086 | The Role of Pragmatics in Legal Norm Representation |  http://arxiv.org/abs/1507.02086  | author:Shashishekar Ramakrishna, Lukasz Gorski, Adrian Paschke category:cs.CL cs.AI 68T30 J.1; I.2.1 published:2015-07-08 summary:Despite the 'apparent clarity' of a given legal provision, its applicationmay result in an outcome that does not exactly conform to the semantic level ofa statute. The vagueness within a legal text is induced intentionally toaccommodate all possible scenarios under which such norms should be applied,thus making the role of pragmatics an important aspect also in therepresentation of a legal norm and reasoning on top of it. The notion ofpragmatics considered in this paper does not focus on the aspects associatedwith judicial decision making. The paper aims to shed light on the aspects ofpragmatics in legal linguistics, mainly focusing on the domain of patent law,only from a knowledge representation perspective. The philosophical discussionspresented in this paper are grounded based on the legal theories from Grice andMarmor.
arxiv-1507-02084 | Shedding Light on the Asymmetric Learning Capability of AdaBoost |  http://arxiv.org/abs/1507.02084  | author:Iago Landesa-Vázquez, José Luis Alba-Castro category:cs.LG cs.AI cs.CV published:2015-07-08 summary:In this paper, we propose a different insight to analyze AdaBoost. Thisanalysis reveals that, beyond some preconceptions, AdaBoost can be directlyused as an asymmetric learning algorithm, preserving all its theoreticalproperties. A novel class-conditional description of AdaBoost, which models theactual asymmetric behavior of the algorithm, is presented.
arxiv-1507-02189 | Intersecting Faces: Non-negative Matrix Factorization With New Guarantees |  http://arxiv.org/abs/1507.02189  | author:Rong Ge, James Zou category:cs.LG stat.ML published:2015-07-08 summary:Non-negative matrix factorization (NMF) is a natural model of admixture andis widely used in science and engineering. A plethora of algorithms have beendeveloped to tackle NMF, but due to the non-convex nature of the problem, thereis little guarantee on how well these methods work. Recently a surge ofresearch have focused on a very restricted class of NMFs, called separable NMF,where provably correct algorithms have been developed. In this paper, wepropose the notion of subset-separable NMF, which substantially generalizes theproperty of separability. We show that subset-separability is a naturalnecessary condition for the factorization to be unique or to have minimumvolume. We developed the Face-Intersect algorithm which provably andefficiently solves subset-separable NMF under natural conditions, and we provethat our algorithm is robust to small noise. We explored the performance ofFace-Intersect on simulations and discuss settings where it empiricallyoutperformed the state-of-art methods. Our work is a step towards findingprovably correct algorithms that solve large classes of NMF problems.
arxiv-1507-02177 | Iris Recognition Using Scattering Transform and Textural Features |  http://arxiv.org/abs/1507.02177  | author:Shervin Minaee, AmirAli Abdolrashidi, Yao Wang category:cs.CV published:2015-07-08 summary:Iris recognition has drawn a lot of attention since the mid-twentiethcentury. Among all biometric features, iris is known to possess a rich set offeatures. Different features have been used to perform iris recognition in thepast. In this paper, two powerful sets of features are introduced to be usedfor iris recognition: scattering transform-based features and texturalfeatures. PCA is also applied on the extracted features to reduce thedimensionality of the feature vector while preserving most of the informationof its initial value. Minimum distance classifier is used to perform templatematching for each new test sample. The proposed scheme is tested on awell-known iris database, and showed promising results with the best accuracyrate of 99.2%.
arxiv-1507-02144 | Spotlight the Negatives: A Generalized Discriminative Latent Model |  http://arxiv.org/abs/1507.02144  | author:Hossein Azizpour, Mostafa Arefiyan, Sobhan Naderi Parizi, Stefan Carlsson category:cs.CV published:2015-07-08 summary:Discriminative latent variable models (LVM) are frequently applied to variousvisual recognition tasks. In these systems the latent (hidden) variablesprovide a formalism for modeling structured variation of visual features.Conventionally, latent variables are de- fined on the variation of theforeground (positive) class. In this work we augment LVMs to include negativelatent variables corresponding to the background class. We formalize thescoring function of such a generalized LVM (GLVM). Then we discuss a frameworkfor learning a model based on the GLVM scoring function. We theoreticallyshowcase how some of the current visual recognition methods can benefit fromthis generalization. Finally, we experiment on a generalized form of DeformablePart Models with negative latent variables and show significant improvements ontwo different detection tasks.
arxiv-1507-02020 | Generating Navigable Semantic Maps from Social Sciences Corpora |  http://arxiv.org/abs/1507.02020  | author:Thierry Poibeau, Pablo Ruiz category:cs.CL cs.AI cs.IR published:2015-07-08 summary:It is now commonplace to observe that we are facing a deluge of onlineinformation. Researchers have of course long acknowledged the potential valueof this information since digital traces make it possible to directly observe,describe and analyze social facts, and above all the co-evolution of ideas andcommunities over time. However, most online information is expressed throughtext, which means it is not directly usable by machines, since computersrequire structured, organized and typed information in order to be able tomanipulate it. Our goal is thus twofold: 1. Provide new natural languageprocessing techniques aiming at automatically extracting relevant informationfrom texts, especially in the context of social sciences, and connect thesepieces of information so as to obtain relevant socio-semantic networks; 2.Provide new ways of exploring these socio-semantic networks, thanks to toolsallowing one to dynamically navigate these networks, de-construct andre-construct them interactively, from different points of view following theneeds expressed by domain experts.
arxiv-1507-02012 | Hindi to English Transfer Based Machine Translation System |  http://arxiv.org/abs/1507.02012  | author:Akanksha Gehlot, Vaishali Sharma, Shashi Pal Singh, Ajai Kumar category:cs.CL published:2015-07-08 summary:In large societies like India there is a huge demand to convert one humanlanguage into another. Lots of work has been done in this area. Many transferbased MTS have developed for English to other languages, as MANTRA CDAC Pune,MATRA CDAC Pune, SHAKTI IISc Bangalore and IIIT Hyderabad. Still there is alittle work done for Hindi to other languages. Currently we are working on it.In this paper we focus on designing a system, that translate the document fromHindi to English by using transfer based approach. This system takes an inputtext check its structure through parsing. Reordering rules are used to generatethe text in target language. It is better than Corpus Based MTS because CorpusBased MTS require large amount of word aligned data for translation that is notavailable for many languages while Transfer Based MTS requires only knowledgeof both the languages(source language and target language) to make transferrules. We get correct translation for simple assertive sentences and almostcorrect for complex and compound sentences.
arxiv-1507-02011 | A Bayesian Approach for Online Classifier Ensemble |  http://arxiv.org/abs/1507.02011  | author:Qinxun Bai, Henry Lam, Stan Sclaroff category:cs.LG published:2015-07-08 summary:We propose a Bayesian approach for recursively estimating the classifierweights in online learning of a classifier ensemble. In contrast with pastmethods, such as stochastic gradient descent or online boosting, our approachestimates the weights by recursively updating its posterior distribution. For aspecified class of loss functions, we show that it is possible to formulate asuitably defined likelihood function and hence use the posterior distributionas an approximation to the global empirical loss minimizer. If the stream oftraining data is sampled from a stationary process, we can also show that ourapproach admits a superior rate of convergence to the expected loss minimizerthan is possible with standard stochastic gradient descent. In experiments withreal-world datasets, our formulation often performs better thanstate-of-the-art stochastic gradient descent and online boosting algorithms.
arxiv-1507-02221 | A Hierarchical Recurrent Encoder-Decoder For Generative Context-Aware Query Suggestion |  http://arxiv.org/abs/1507.02221  | author:Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob G. Simonsen, Jian-Yun Nie category:cs.NE cs.IR published:2015-07-08 summary:Users may strive to formulate an adequate textual query for their informationneed. Search engines assist the users by presenting query suggestions. Topreserve the original search intent, suggestions should be context-aware andaccount for the previous queries issued by the user. Achieving contextawareness is challenging due to data sparsity. We present a probabilisticsuggestion model that is able to account for sequences of previous queries ofarbitrary lengths. Our novel hierarchical recurrent encoder-decoderarchitecture allows the model to be sensitive to the order of queries in thecontext while avoiding data sparsity. Additionally, our model can suggest forrare, or long-tail, queries. The produced suggestions are synthetic and aresampled one word at a time, using computationally cheap decoding techniques.This is in contrast to current synthetic suggestion models relying upon machinelearning pipelines and hand-engineered feature sets. Results show that itoutperforms existing context-aware approaches in a next query predictionsetting. In addition to query suggestion, our model is general enough to beused in a variety of other applications.
arxiv-1507-02045 | What Your Username Says About You |  http://arxiv.org/abs/1507.02045  | author:Aaron Jaech, Mari Ostendorf category:cs.CL published:2015-07-08 summary:Usernames are ubiquitous on the Internet, and they are often suggestive ofuser demographics. This work looks at the degree to which gender and languagecan be inferred from a username alone by making use of unsupervised morphologyinduction to decompose usernames into sub-units. Experimental results on thetwo tasks demonstrate the effectiveness of the proposed morphological featurescompared to a character n-gram baseline.
arxiv-1507-02205 | Talking to the crowd: What do people react to in online discussions? |  http://arxiv.org/abs/1507.02205  | author:Aaron Jaech, Victoria Zayats, Hao Fang, Mari Ostendorf, Hannaneh Hajishirzi category:cs.CL cs.SI published:2015-07-08 summary:This paper addresses the question of how language use affects communityreaction to comments in online discussion forums, and the relative importanceof the message vs. the messenger. A new comment ranking task is proposed basedon community annotated karma in Reddit discussions, which controls for topicand timing of comments. Experimental work with discussion threads from sixsubreddits shows that the importance of different types of language featuresvaries with the community of interest.
arxiv-1507-02159 | Towards Good Practices for Very Deep Two-Stream ConvNets |  http://arxiv.org/abs/1507.02159  | author:Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao category:cs.CV published:2015-07-08 summary:Deep convolutional networks have achieved great success for objectrecognition in still images. However, for action recognition in videos, theimprovement of deep convolutional networks is not so evident. We argue thatthere are two reasons that could probably explain this result. First thecurrent network architectures (e.g. Two-stream ConvNets) are relatively shallowcompared with those very deep models in image domain (e.g. VGGNet, GoogLeNet),and therefore their modeling capacity is constrained by their depth. Second,probably more importantly, the training dataset of action recognition isextremely small compared with the ImageNet dataset, and thus it will be easy toover-fit on the training dataset. To address these issues, this report presents very deep two-stream ConvNetsfor action recognition, by adapting recent very deep architectures into videodomain. However, this extension is not easy as the size of action recognitionis quite small. We design several good practices for the training of very deeptwo-stream ConvNets, namely (i) pre-training for both spatial and temporalnets, (ii) smaller learning rates, (iii) more data augmentation techniques,(iv) high drop out ratio. Meanwhile, we extend the Caffe toolbox into Multi-GPUimplementation with high computational efficiency and low memory consumption.We verify the performance of very deep two-stream ConvNets on the dataset ofUCF101 and it achieves the recognition accuracy of $91.4\%$.
arxiv-1507-02000 | An optimal randomized incremental gradient method |  http://arxiv.org/abs/1507.02000  | author:Guanghui Lan, Yi Zhou category:math.OC cs.CC stat.ML published:2015-07-08 summary:In this paper, we consider a class of finite-sum convex optimization problemswhose objective function is given by the summation of $m$ ($\ge 1$) smoothcomponents together with some other relatively simple terms. We first introducea deterministic primal-dual gradient (PDG) method that can achieve the optimalblack-box iteration complexity for solving these composite optimizationproblems using a primal-dual termination criterion. Our major contribution isto develop a randomized primal-dual gradient (RPDG) method, which needs tocompute the gradient of only one randomly selected smooth component at eachiteration, but can possibly achieve better complexity than PDG in terms of thetotal number of gradient evaluations. More specifically, we show that the totalnumber of gradient evaluations performed by RPDG can be ${\cal O} (\sqrt{m})$times smaller, both in expectation and with high probability, than thoseperformed by deterministic optimal first-order methods under favorablesituations. We also show that the complexity of the RPDG method is notimprovable by developing a new lower complexity bound for a general class ofrandomized methods for solving large-scale finite-sum convex optimizationproblems. Moreover, through the development of PDG and RPDG, we introduce anovel game-theoretic interpretation for these optimal methods for convexoptimization.
arxiv-1507-02313 | Feature Representation in Convolutional Neural Networks |  http://arxiv.org/abs/1507.02313  | author:Ben Athiwaratkun, Keegan Kang category:cs.CV published:2015-07-08 summary:Convolutional Neural Networks (CNNs) are powerful models that achieveimpressive results for image classification. In addition, pre-trained CNNs arealso useful for other computer vision tasks as generic feature extractors. Thispaper aims to gain insight into the feature aspect of CNN and demonstrate otheruses of CNN features. Our results show that CNN feature maps can be used withRandom Forests and SVM to yield classification results that outperforms theoriginal CNN. A CNN that is less than optimal (e.g. not fully trained oroverfitting) can also extract features for Random Forest/SVM that yieldcompetitive classification accuracy. In contrast to the literature which usesthe top-layer activations as feature representation of images for other tasks,using lower-layer features can yield better results for classification.
arxiv-1507-02154 | Double-Base Asymmetric AdaBoost |  http://arxiv.org/abs/1507.02154  | author:Iago Landesa-Vázquez, José Luis Alba-Castro category:cs.CV cs.AI cs.LG published:2015-07-08 summary:Based on the use of different exponential bases to define class-dependenterror bounds, a new and highly efficient asymmetric boosting scheme, coined asAdaBoostDB (Double-Base), is proposed. Supported by a fully theoreticalderivation procedure, unlike most of the other approaches in the literature,our algorithm preserves all the formal guarantees and properties of original(cost-insensitive) AdaBoost, similarly to the state-of-the-art Cost-SensitiveAdaBoost algorithm. However, the key advantage of AdaBoostDB is that our novelderivation scheme enables an extremely efficient conditional search procedure,dramatically improving and simplifying the training phase of the algorithm.Experiments, both over synthetic and real datasets, reveal that AdaBoostDB isable to save over 99% training time with regard to Cost-Sensitive AdaBoost,providing the same cost-sensitive results. This computational advantage ofAdaBoostDB can make a difference in problems managing huge pools of weakclassifiers in which boosting techniques are commonly used.
arxiv-1507-02030 | Beyond Convexity: Stochastic Quasi-Convex Optimization |  http://arxiv.org/abs/1507.02030  | author:Elad Hazan, Kfir Y. Levy, Shai Shalev-Shwartz category:cs.LG math.OC published:2015-07-08 summary:Stochastic convex optimization is a basic and well studied primitive inmachine learning. It is well known that convex and Lipschitz functions can beminimized efficiently using Stochastic Gradient Descent (SGD). The NormalizedGradient Descent (NGD) algorithm, is an adaptation of Gradient Descent, whichupdates according to the direction of the gradients, rather than the gradientsthemselves. In this paper we analyze a stochastic version of NGD and prove itsconvergence to a global minimum for a wider class of functions: we require thefunctions to be quasi-convex and locally-Lipschitz. Quasi-convexity broadensthe con- cept of unimodality to multidimensions and allows for certain types ofsaddle points, which are a known hurdle for first-order optimization methodssuch as gradient descent. Locally-Lipschitz functions are only required to beLipschitz in a small region around the optimum. This assumption circumventsgradient explosion, which is another known hurdle for gradient descentvariants. Interestingly, unlike the vanilla SGD algorithm, the stochasticnormalized gradient descent algorithm provably requires a minimal minibatchsize.
arxiv-1507-02268 | Optimal approximate matrix product in terms of stable rank |  http://arxiv.org/abs/1507.02268  | author:Michael B. Cohen, Jelani Nelson, David P. Woodruff category:cs.DS cs.LG stat.ML published:2015-07-08 summary:We prove, using the subspace embedding guarantee in a black box way, that onecan achieve the spectral norm guarantee for approximate matrix multiplicationwith a dimensionality-reducing map having $m = O(\tilde{r}/\varepsilon^2)$rows. Here $\tilde{r}$ is the maximum stable rank, i.e. squared ratio ofFrobenius and operator norms, of the two matrices being multiplied. This is aquantitative improvement over previous work of [MZ11, KVZ14], and is alsooptimal for any oblivious dimensionality-reducing map. Furthermore, due to theblack box reliance on the subspace embedding property in our proofs, ourtheorem can be applied to a much more general class of sketching matrices thanwhat was known before, in addition to achieving better bounds. For example, onecan apply our theorem to efficient subspace embeddings such as the SubsampledRandomized Hadamard Transform or sparse subspace embeddings, or even withsubspace embedding constructions that may be developed in the future. Our main theorem, via connections with spectral error matrix multiplicationshown in prior work, implies quantitative improvements for approximate leastsquares regression and low rank approximation. Our main result has also alreadybeen applied to improve dimensionality reduction guarantees for $k$-meansclustering [CEMMP14], and implies new results for nonparametric regression[YPW15]. We also separately point out that the proof of the "BSS" deterministicrow-sampling result of [BSS12] can be modified to show that for any matrices$A, B$ of stable rank at most $\tilde{r}$, one can achieve the spectral normguarantee for approximate matrix multiplication of $A^T B$ by deterministicallysampling $O(\tilde{r}/\varepsilon^2)$ rows that can be found in polynomialtime. The original result of [BSS12] was for rank instead of stable rank. Ourobservation leads to a stronger version of a main theorem of [KMST10].
arxiv-1507-02323 | Multisection in the Stochastic Block Model using Semidefinite Programming |  http://arxiv.org/abs/1507.02323  | author:Naman Agarwal, Afonso S. Bandeira, Konstantinos Koiliaris, Alexandra Kolla category:cs.DS math.PR stat.ML published:2015-07-08 summary:We consider the problem of identifying underlying community-like structuresin graphs. Towards this end we study the Stochastic Block Model (SBM) on$k$-clusters: a random model on $n=km$ vertices, partitioned in $k$ equal sizedclusters, with edges sampled independently across clusters with probability $q$and within clusters with probability $p$, $p>q$. The goal is to recover theinitial "hidden" partition of $[n]$. We study semidefinite programming (SDP)based algorithms in this context. In the regime $p = \frac{\alpha \log(m)}{m}$and $q = \frac{\beta \log(m)}{m}$ we show that a certain natural SDP basedalgorithm solves the problem of {\em exact recovery} in the $k$-community SBM,with high probability, whenever $\sqrt{\alpha} - \sqrt{\beta} > \sqrt{1}$, aslong as $k=o(\log n)$. This threshold is known to be the informationtheoretically optimal. We also study the case when $k=\theta(\log(n))$. In thiscase however we achieve recovery guarantees that no longer match the optimalcondition $\sqrt{\alpha} - \sqrt{\beta} > \sqrt{1}$, thus leaving achievingoptimality for this range an open question.
arxiv-1507-02158 | An Empirical Study on Budget-Aware Online Kernel Algorithms for Streams of Graphs |  http://arxiv.org/abs/1507.02158  | author:Giovanni Da San Martino, Nicolò Navarin, Alessandro Sperduti category:cs.LG published:2015-07-08 summary:Kernel methods are considered an effective technique for on-line learning.Many approaches have been developed for compactly representing the dualsolution of a kernel method when the problem imposes memory constraints.However, in literature no work is specifically tailored to streams of graphs.Motivated by the fact that the size of the feature space representation of manystate-of-the-art graph kernels is relatively small and thus it is explicitlycomputable, we study whether executing kernel algorithms in the feature spacecan be more effective than the classical dual approach. We propose threedifferent algorithms and various strategies for managing the budget. Efficiencyand efficacy of the proposed approaches are experimentally assessed onrelatively large graph streams exhibiting concept drift. It turns out that,when strict memory budget constraints have to be enforced, working in featurespace, given the current state of the art on graph kernels, is more than aviable alternative to dual approaches, both in terms of speed andclassification performance.
arxiv-1507-02284 | The Information Sieve |  http://arxiv.org/abs/1507.02284  | author:Greg Ver Steeg, Aram Galstyan category:stat.ML cs.IT cs.LG math.IT published:2015-07-08 summary:We introduce a new framework for unsupervised learning of representationsbased on a novel hierarchical decomposition of information. Intuitively, datais passed through a series of progressively fine-grained sieves. Each layer ofthe sieve recovers a single latent factor that is maximally informative aboutmultivariate dependence in the data. The data is transformed after each pass sothat the remaining unexplained information trickles down to the next layer.Ultimately, we are left with a set of latent factors explaining all thedependence in the original data and remainder information consisting ofindependent noise. We present a practical implementation of this framework fordiscrete variables and apply it to a variety of fundamental tasks inunsupervised learning including independent component analysis, lossy andlossless compression, and predicting missing values in data.
arxiv-1507-02062 | Multi-Document Summarization via Discriminative Summary Reranking |  http://arxiv.org/abs/1507.02062  | author:Xiaojun Wan, Ziqiang Cao, Furu Wei, Sujian Li, Ming Zhou category:cs.CL published:2015-07-08 summary:Existing multi-document summarization systems usually rely on a specificsummarization model (i.e., a summarization method with a specific parametersetting) to extract summaries for different document sets with differenttopics. However, according to our quantitative analysis, none of the existingsummarization models can always produce high-quality summaries for differentdocument sets, and even a summarization model with good overall performance mayproduce low-quality summaries for some document sets. On the contrary, abaseline summarization model may produce high-quality summaries for somedocument sets. Based on the above observations, we treat the summaries producedby different summarization models as candidate summaries, and then explorediscriminative reranking techniques to identify high-quality summaries from thecandidates for difference document sets. We propose to extract a set ofcandidate summaries for each document set based on an ILP framework, and thenleverage Ranking SVM for summary reranking. Various useful features have beendeveloped for the reranking process, including word-level features,sentence-level features and summary-level features. Evaluation results on thebenchmark DUC datasets validate the efficacy and robustness of our proposedapproach.
arxiv-1507-01978 | Learning vector autoregressive models with focalised Granger-causality graphs |  http://arxiv.org/abs/1507.01978  | author:Magda Gregorova, Alexandros Kalousis, Stéphane Marchand-Maillet category:cs.LG stat.ML published:2015-07-07 summary:We consider the problem of learning models for forecasting multipletime-series systems together with discovering the leading indicators that serveas good predictors for the system. We model the systems by linear vectorautoregressive models (VAR) and link the discovery of leading indicators toinferring sparse graphs of Granger-causality. We propose new problemformulations and develop two new methods to learn such models, graduallyincreasing the complexity of assumptions and approaches. While the first methodassumes common structures across the whole system, our second method uncoversmodel clusters based on the Granger-causality and leading indicators togetherwith learning the model parameters. We study the performance of our methods ona comprehensive set of experiments and confirm their efficacy and theiradvantages over state-of-the-art sparse VAR and graphical Granger learningmethods.
arxiv-1507-01826 | Clustering Network Layers With the Strata Multilayer Stochastic Block Model |  http://arxiv.org/abs/1507.01826  | author:Natalie Stanley, Saray Shai, Dane Taylor, Peter J. Mucha category:cs.SI physics.soc-ph stat.ML published:2015-07-07 summary:Multilayer networks are a useful data structure for simultaneously capturingmultiple types of relationships between a set of nodes. In such networks, eachrelational definition gives rise to a layer. While each layer provides its ownset of information, community structure across layers can be collectivelyutilized to discover and quantify underlying relational patterns between nodes.To concisely extract information from a multilayer network, we propose toidentify and combine sets of layers with meaningful similarities in communitystructure. In this paper, we describe the "strata multilayer stochastic blockmodel'' (sMLSBM), a probabilistic model for multilayer community structure. Thecentral extension of the model is that there exist groups of layers, called"strata'', which are defined such that all layers in a given stratum havecommunity structure described by a common stochastic block model (SBM). Thatis, layers in a stratum exhibit similar node-to-community assignments and SBMprobability parameters. Fitting the sMLSBM to a multilayer network provides ajoint clustering that yields node-to-community and layer-to-stratumassignments, which cooperatively aid one another during inference. We describean algorithm for separating layers into their appropriate strata and aninference technique for estimating the SBM parameters for each stratum. Wedemonstrate our method using synthetic networks and a multilayer networkinferred from data collected in the Human Microbiome Project.
arxiv-1507-01784 | Rethinking LDA: moment matching for discrete ICA |  http://arxiv.org/abs/1507.01784  | author:Anastasia Podosinnikova, Francis Bach, Simon Lacoste-Julien category:stat.ML cs.LG published:2015-07-07 summary:We consider moment matching techniques for estimation in Latent DirichletAllocation (LDA). By drawing explicit links between LDA and discrete versionsof independent component analysis (ICA), we first derive a new set ofcumulant-based tensors, with an improved sample complexity. Moreover, we reusestandard ICA techniques such as joint diagonalization of tensors to improveover existing methods based on the tensor power method. In an extensive set ofexperiments on both synthetic and real datasets, we show that our newcombination of tensors and orthogonal joint diagonalization techniquesoutperforms existing moment matching methods.
arxiv-1507-01972 | Wasserstein Training of Boltzmann Machines |  http://arxiv.org/abs/1507.01972  | author:Grégoire Montavon, Klaus-Robert Müller, Marco Cuturi category:stat.ML cs.LG published:2015-07-07 summary:The Boltzmann machine provides a useful framework to learn highly complex,multimodal and multiscale data distributions that occur in the real world. Thedefault method to learn its parameters consists of minimizing theKullback-Leibler (KL) divergence from training samples to the Boltzmann model.We propose in this work a novel approach for Boltzmann training which assumesthat a meaningful metric between observations is given. This metric can berepresented by the Wasserstein distance between distributions, for which wederive a gradient with respect to the model parameters. Minimization of thisnew Wasserstein objective leads to generative models that are better whenconsidering the metric and that have a cluster-like structure. We demonstratethe practical potential of these models for data completion and denoising, forwhich the metric between observations plays a crucial role.
arxiv-1507-01701 | A Survey and Classification of Controlled Natural Languages |  http://arxiv.org/abs/1507.01701  | author:Tobias Kuhn category:cs.CL published:2015-07-07 summary:What is here called controlled natural language (CNL) has traditionally beengiven many different names. Especially during the last four decades, a widevariety of such languages have been designed. They are applied to improvecommunication among humans, to improve translation, or to provide natural andintuitive representations for formal notations. Despite the apparentdifferences, it seems sensible to put all these languages under the sameumbrella. To bring order to the variety of languages, a general classificationscheme is presented here. A comprehensive survey of existing English-based CNLsis given, listing and describing 100 languages from 1930 until today.Classification of these languages reveals that they form a single scatteredcloud filling the conceptual space between natural languages such as English onthe one end and formal languages such as propositional logic on the other. Thegoal of this article is to provide a common terminology and a common model forCNL, to contribute to the understanding of their general nature, to provide astarting point for researchers interested in the area, and to help developersto make design decisions.
arxiv-1507-01839 | Dependency-based Convolutional Neural Networks for Sentence Embedding |  http://arxiv.org/abs/1507.01839  | author:Mingbo Ma, Liang Huang, Bing Xiang, Bowen Zhou category:cs.CL cs.AI cs.LG published:2015-07-07 summary:In sentence modeling and classification, convolutional neural networkapproaches have recently achieved state-of-the-art results, but all suchefforts process word vectors sequentially and neglect long-distancedependencies. To exploit both deep learning and linguistic structures, wepropose a tree-based convolutional neural network model which exploit variouslong-distance relationships between words. Our model improves the sequentialbaselines on all three sentiment and question classification tasks, andachieves the highest published accuracy on TREC.
arxiv-1507-01698 | Learning Tractable Probabilistic Models for Fault Localization |  http://arxiv.org/abs/1507.01698  | author:Aniruddh Nath, Pedro Domingos category:cs.SE cs.LG published:2015-07-07 summary:In recent years, several probabilistic techniques have been applied tovarious debugging problems. However, most existing probabilistic debuggingsystems use relatively simple statistical models, and fail to generalize acrossmultiple programs. In this work, we propose Tractable Fault Localization Models(TFLMs) that can be learned from data, and probabilistically infer the locationof the bug. While most previous statistical debugging methods generalize overmany executions of a single program, TFLMs are trained on a corpus ofpreviously seen buggy programs, and learn to identify recurring patterns ofbugs. Widely-used fault localization techniques such as TARANTULA evaluate thesuspiciousness of each line in isolation; in contrast, a TFLM defines a jointprobability distribution over buggy indicator variables for each line. Jointdistributions with rich dependency structure are often computationallyintractable; TFLMs avoid this by exploiting recent developments in tractableprobabilistic models (specifically, Relational SPNs). Further, TFLMs canincorporate additional sources of information, including coverage-basedfeatures such as TARANTULA. We evaluate the fault localization performance ofTFLMs that include TARANTULA scores as features in the probabilistic model. Ourstudy shows that the learned TFLMs isolate bugs more effectively than previousstatistical methods or using TARANTULA directly.
arxiv-1507-01687 | Developing Postfix-GP Framework for Symbolic Regression Problems |  http://arxiv.org/abs/1507.01687  | author:Vipul K. Dabhi, Sanjay Chaudhary category:cs.NE published:2015-07-07 summary:This paper describes Postfix-GP system, postfix notation based GeneticProgramming (GP), for solving symbolic regression problems. It presents anobject-oriented architecture of Postfix-GP framework. It assists the user inunderstanding of the implementation details of various components ofPostfix-GP. Postfix-GP provides graphical user interface which allows user toconfigure the experiment, to visualize evolved solutions, to analyze GP run,and to perform out-of-sample predictions. The use of Postfix-GP is demonstratedby solving the benchmark symbolic regression problem. Finally, features ofPostfix-GP framework are compared with that of other GP systems.
arxiv-1507-01661 | Semiblind Hyperspectral Unmixing in the Presence of Spectral Library Mismatches |  http://arxiv.org/abs/1507.01661  | author:Xiao Fu, Wing-Kin Ma, José Bioucas-Dias, Tsung-Han Chan category:stat.ML published:2015-07-07 summary:The dictionary-aided sparse regression (SR) approach has recently emerged asa promising alternative to hyperspectral unmixing (HU) in remote sensing. Byusing an available spectral library as a dictionary, the SR approach identifiesthe underlying materials in a given hyperspectral image by selecting a smallsubset of spectral samples in the dictionary to represent the whole image. Adrawback with the current SR developments is that an actual spectral signaturein the scene is often assumed to have zero mismatch with its correspondingdictionary sample, and such an assumption is considered too ideal in practice.In this paper, we tackle the spectral signature mismatch problem by proposing adictionary-adjusted nonconvex sparsity-encouraging regression (DANSER)framework. The main idea is to incorporate dictionary correcting variables inan SR formulation. A simple and low per-iteration complexity algorithm istailor-designed for practical realization of DANSER. Using the same dictionarycorrecting idea, we also propose a robust subspace solution for dictionarypruning. Extensive simulations and real-data experiments show that the proposedmethod is effective in mitigating the undesirable spectral signature mismatcheffects.
arxiv-1507-01892 | A linear approach for sparse coding by a two-layer neural network |  http://arxiv.org/abs/1507.01892  | author:Alessandro Montalto, Giovanni Tessitore, Roberto Prevete category:cs.LG published:2015-07-06 summary:Many approaches to transform classification problems from non-linear tolinear by feature transformation have been recently presented in theliterature. These notably include sparse coding methods and deep neuralnetworks. However, many of these approaches require the repeated application ofa learning process upon the presentation of unseen data input vectors, or elseinvolve the use of large numbers of parameters and hyper-parameters, which mustbe chosen through cross-validation, thus increasing running time dramatically.In this paper, we propose and experimentally investigate a new approach for thepurpose of overcoming limitations of both kinds. The proposed approach makesuse of a linear auto-associative network (called SCNN) with just one hiddenlayer. The combination of this architecture with a specific error function tobe minimized enables one to learn a linear encoder computing a sparse codewhich turns out to be as similar as possible to the sparse coding that oneobtains by re-training the neural network. Importantly, the linearity of SCNNand the choice of the error function allow one to achieve reduced running timein the learning phase. The proposed architecture is evaluated on the basis oftwo standard machine learning tasks. Its performances are compared with thoseof recently proposed non-linear auto-associative neural networks. The overallresults suggest that linear encoders can be profitably used to obtain sparsedata representations in the context of machine learning problems, provided thatan appropriate error function is used during the learning phase.
arxiv-1507-01442 | Learning Better Encoding for Approximate Nearest Neighbor Search with Dictionary Annealing |  http://arxiv.org/abs/1507.01442  | author:Shicong Liu, Hongtao Lu category:cs.CV published:2015-07-06 summary:We introduce a novel dictionary optimization method for high-dimensionalvector quantization employed in approximate nearest neighbor (ANN) search.Vector quantization methods first seek a series of dictionaries, thenapproximate each vector by a sum of elements selected from these dictionaries.An optimal series of dictionaries should be mutually independent, and eachdictionary should generate a balanced encoding for the target dataset. Existingmethods did not explicitly consider this. To achieve these goals along withminimizing the quantization error (residue), we propose a novel dictionaryoptimization method called \emph{Dictionary Annealing} that alternatively"heats up" a single dictionary by generating an intermediate dataset withresidual vectors, "cools down" the dictionary by fitting the intermediatedataset, then extracts the new residual vectors for the next iteration. Bettercodes can be learned by DA for the ANN search tasks. DA is easily implementedon GPU to utilize the latest computing technology, and can easily extended toan online dictionary learning scheme. We show by experiments that our optimizeddictionaries substantially reduce the overall quantization error. Jointly usedwith residual vector quantization, our optimized dictionaries lead to a betterapproximate nearest neighbor search performance compared to thestate-of-the-art methods.
arxiv-1507-01890 | Community detection in multiplex networks using locally adaptive random walks |  http://arxiv.org/abs/1507.01890  | author:Zhana Kuncheva, Giovanni Montana category:cs.SI physics.soc-ph stat.ML published:2015-07-06 summary:Multiplex networks, a special type of multilayer networks, are increasinglyapplied in many domains ranging from social media analytics to biology. Acommon task in these applications concerns the detection of communitystructures. Many existing algorithms for community detection in multiplexesattempt to detect communities which are shared by all layers. In this articlewe propose a community detection algorithm, LART (Locally Adaptive RandomTransitions), for the detection of communities that are shared by either someor all the layers in the multiplex. The algorithm is based on a random walk onthe multiplex, and the transition probabilities defining the random walk areallowed to depend on the local topological similarity between layers at anygiven node so as to facilitate the exploration of communities across layers.Based on this random walk, a node dissimilarity measure is derived and nodesare clustered based on this distance in a hierarchical fashion. We presentexperimental results using networks simulated under various scenarios toshowcase the performance of LART in comparison to related community detectionalgorithms.
arxiv-1507-01563 | A Simple Algorithm for Maximum Margin Classification, Revisited |  http://arxiv.org/abs/1507.01563  | author:Sariel Har-Peled category:cs.LG published:2015-07-06 summary:In this note, we revisit the algorithm of Har-Peled et. al. [HRZ07] forcomputing a linear maximum margin classifier. Our presentation is selfcontained, and the algorithm itself is slightly simpler than the originalalgorithm. The algorithm itself is a simple Perceptron like iterativealgorithm. For more details and background, the reader is referred to theoriginal paper.
arxiv-1507-01529 | Correspondence Factor Analysis of Big Data Sets: A Case Study of 30 Million Words; and Contrasting Analytics using Apache Solr and Correspondence Analysis in R |  http://arxiv.org/abs/1507.01529  | author:Fionn Murtagh category:cs.CL 62H25, 62.07 G.3; H.2.8 published:2015-07-06 summary:We consider a large number of text data sets. These are cooking recipes. Termdistribution and other distributional properties of the data are investigated.Our aim is to look at various analytical approaches which allow for mining ofinformation on both high and low detail scales. Metric space embedding isfundamental to our interest in the semantic properties of this data. Weconsider the projection of all data into analyses of aggregated versions of thedata. We contrast that with projection of aggregated versions of the data intoanalyses of all the data. Analogously for the term set, we look at analysis ofselected terms. We also look at inherent term associations such as betweensingular and plural. In addition to our use of Correspondence Analysis in R,for latent semantic space mapping, we also use Apache Solr. Setting up the Solrserver and carrying out querying is described. A further novelty is thatquerying is supported in Solr based on the principal factor plane mapping ofall the data. This uses a bounding box query, based on factor projections.
arxiv-1507-01636 | Reflections on Sentiment/Opinion Analysis |  http://arxiv.org/abs/1507.01636  | author:Jiwei Li, Eduard Hovy category:cs.CL published:2015-07-06 summary:In this paper, we described possible directions for deeper understanding,helping bridge the gap between psychology / cognitive science and computationalapproaches in sentiment/opinion analysis literature. We focus on the opinionholder's underlying needs and their resultant goals, which, in a utilitarianmodel of sentiment, provides the basis for explaining the reason a sentimentvalence is held. While these thoughts are still immature, scattered,unstructured, and even imaginary, we believe that these perspectives mightsuggest fruitful avenues for various kinds of future work.
arxiv-1507-01569 | Emphatic Temporal-Difference Learning |  http://arxiv.org/abs/1507.01569  | author:A. Rupam Mahmood, Huizhen Yu, Martha White, Richard S. Sutton category:cs.LG cs.AI published:2015-07-06 summary:Emphatic algorithms are temporal-difference learning algorithms that changetheir effective state distribution by selectively emphasizing andde-emphasizing their updates on different time steps. Recent works by Sutton,Mahmood and White (2015), and Yu (2015) show that by varying the emphasis in aparticular way, these algorithms become stable and convergent under off-policytraining with linear function approximation. This paper serves as a unifiedsummary of the available results from both works. In addition, we demonstratethe empirical benefits from the flexibility of emphatic algorithms, includingstate-dependent discounting, state-dependent bootstrapping, and theuser-specified allocation of function approximation resources.
arxiv-1507-01330 | Visual Data Deblocking using Structural Layer Priors |  http://arxiv.org/abs/1507.01330  | author:Xiaojie Guo category:cs.CV published:2015-07-06 summary:The blocking artifact frequently appears in compressed real-world images orvideo sequences, especially coded at low bit rates, which is visually annoyingand likely hurts the performance of many computer vision algorithms. Acompressed frame can be viewed as the superimposition of an intrinsic layer andan artifact one. Recovering the two layers from such frames seems to be aseverely ill-posed problem since the number of unknowns to recover is twice asmany as the given measurements. In this paper, we propose a simple and robustmethod to separate these two layers, which exploits structural layer priorsincluding the gradient sparsity of the intrinsic layer, and the independence ofthe gradient fields of the two layers. A novel Augmented Lagrangian Multiplierbased algorithm is designed to efficiently and effectively solve the recoveryproblem. Extensive experimental results demonstrate the superior performance ofour method over the state of the arts, in terms of visual quality andsimplicity.
arxiv-1507-01461 | Revisiting Large Scale Distributed Machine Learning |  http://arxiv.org/abs/1507.01461  | author:Radu Cristian Ionescu category:cs.DC cs.LG published:2015-07-06 summary:Nowadays, with the widespread of smartphones and other portable gadgetsequipped with a variety of sensors, data is ubiquitous available and the focusof machine learning has shifted from being able to infer from small trainingsamples to dealing with large scale high-dimensional data. In domains such aspersonal healthcare applications, which motivates this survey, distributedmachine learning is a promising line of research, both for scaling up learningalgorithms, but mostly for dealing with data which is inherently produced atdifferent locations. This report offers a thorough overview of andstate-of-the-art algorithms for distributed machine learning, for bothsupervised and unsupervised learning, ranging from simple linear logisticregression to graphical models and clustering. We propose future directions formost categories, specific to the potential personal healthcare applications.With this in mind, the report focuses on how security and low communicationoverhead can be assured in the specific case of a strictly client-serverarchitectural model. As particular directions we provides an exhaustivepresentation of an empirical clustering algorithm, k-windows, and proposed anasynchronous distributed machine learning algorithm that would scale well andalso would be computationally cheap and easy to implement.
arxiv-1507-01307 | Subspace-Sparse Representation |  http://arxiv.org/abs/1507.01307  | author:C. You, R. Vidal category:stat.ML cs.IT math.IT published:2015-07-06 summary:Given an overcomplete dictionary $A$ and a signal $b$ that is a linearcombination of a few linearly independent columns of $A$, classical sparserecovery theory deals with the problem of recovering the unique sparserepresentation $x$ such that $b = A x$. It is known that under certainconditions on $A$, $x$ can be recovered by the Basis Pursuit (BP) and theOrthogonal Matching Pursuit (OMP) algorithms. In this work, we consider themore general case where $b$ lies in a low-dimensional subspace spanned by somecolumns of $A$, which are possibly linearly dependent. In this case, thesparsest solution $x$ is generally not unique, and we study the problem thatthe representation $x$ identifies the subspace, i.e. the nonzero entries of $x$correspond to dictionary atoms that are in the subspace. Such a representation$x$ is called subspace-sparse. We present sufficient conditions forguaranteeing subspace-sparse recovery, which have clear geometricinterpretations and explain properties of subspace-sparse recovery. We alsoshow that the sufficient conditions can be satisfied under a randomized model.Our results are applicable to the traditional sparse recovery problem and weget conditions for sparse recovery that are less restrictive than the canonicalmutual coherent condition. We also use the results to analyze the sparserepresentation based classification (SRC) method, for which we get conditionsto show its correctness.
arxiv-1507-01581 | Joint Calibration for Semantic Segmentation |  http://arxiv.org/abs/1507.01581  | author:Holger Caesar, Jasper Uijlings, Vittorio Ferrari category:cs.CV 68T45 published:2015-07-06 summary:Semantic segmentation is the task of assigning a class-label to each pixel inan image. We propose a region-based semantic segmentation framework whichhandles both full and weak supervision, and addresses three common problems:(1) Objects occur at multiple scales and therefore we should use regions atmultiple scales. However, these regions are overlapping which createsconflicting class predictions at the pixel-level. (2) Class frequencies arehighly imbalanced in realistic datasets. (3) Each pixel can only be assigned toa single class, which creates competition between classes. We address all threeproblems with a joint calibration method which optimizes a multi-class lossdefined over the final pixel-level output labeling, as opposed to simply regionclassification. Our method outperforms the state-of-the-art on the popular SIFTFlow [18] dataset in both the fully and weakly supervised setting by aconsiderably margin (+6% and +10%, respectively).
