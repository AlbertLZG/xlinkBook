arxiv-13800-1 | A Graph Traversal Based Approach to Answer Non-Aggregation Questions Over DBpedia | http://arxiv.org/pdf/1510.04780v1.pdf | author:Chenhao Zhu, Kan Ren, Xuan Liu, Haofen Wang, Yiding Tian, Yong Yu category:cs.CL cs.IR published:2015-10-16 summary:We present a question answering system over DBpedia, filling the gap betweenuser information needs expressed in natural language and a structured queryinterface expressed in SPARQL over the underlying knowledge base (KB). Giventhe KB, our goal is to comprehend a natural language query and providecorresponding accurate answers. Focusing on solving the non-aggregationquestions, in this paper, we construct a subgraph of the knowledge base fromthe detected entities and propose a graph traversal method to solve both thesemantic item mapping problem and the disambiguation problem in a joint way.Compared with existing work, we simplify the process of query intentionunderstanding and pay more attention to the answer path ranking. We evaluateour method on a non-aggregation question dataset and further on a completedataset. Experimental results show that our method achieves best performancecompared with several state-of-the-art systems.
arxiv-13800-2 | You-Do, I-Learn: Unsupervised Multi-User egocentric Approach Towards Video-Based Guidance | http://arxiv.org/pdf/1510.04862v2.pdf | author:Dima Damen, Teesid Leelasawassuk, Walterio Mayol-Cuevas category:cs.CV published:2015-10-16 summary:This paper presents an unsupervised approach towards automatically extractingvideo-based guidance on object usage, from egocentric video and wearable gazetracking, collected from multiple users while performing tasks. The approach i)discovers task relevant objects, ii) builds a model for each, iii)distinguishes different ways in which each discovered object has been used andiv) discovers the dependencies between object interactions. The workinvestigates using appearance, position, motion and attention, and presentsresults using each and a combination of relevant features. Moreover, an onlinescalable approach is presented and is compared to offline results. The paperproposes a method for selecting a suitable video guide to be displayed to anovice user indicating how to use an object, purely triggered by the user'sgaze. The potential assistive mode can also recommend an object to be used nextbased on the learnt sequence of object interactions. The approach was tested ona variety of daily tasks such as initialising a printer, preparing a coffee andsetting up a gym machine.
arxiv-13800-3 | Multiresolution hierarchy co-clustering for semantic segmentation in sequences with small variations | http://arxiv.org/pdf/1510.04842v1.pdf | author:David Varas, Mónica Alfaro, Ferran Marques category:cs.CV published:2015-10-16 summary:This paper presents a co-clustering technique that, given a collection ofimages and their hierarchies, clusters nodes from these hierarchies to obtain acoherent multiresolution representation of the image collection. We formalizethe co-clustering as a Quadratic Semi-Assignment Problem and solve it with alinear programming relaxation approach that makes effective use of informationfrom hierarchies. Initially, we address the problem of generating an optimal,coherent partition per image and, afterwards, we extend this method to amultiresolution framework. Finally, we particularize this framework to aniterative multiresolution video segmentation algorithm in sequences with smallvariations. We evaluate the algorithm on the Video Occlusion/Object BoundaryDetection Dataset, showing that it produces state-of-the-art results in thesescenarios.
arxiv-13800-4 | SGD with Variance Reduction beyond Empirical Risk Minimization | http://arxiv.org/pdf/1510.04822v2.pdf | author:Massil Achab, Agathe Guilloux, Stéphane Gaïffas, Emmanuel Bacry category:stat.ML cs.LG published:2015-10-16 summary:We introduce a doubly stochastic proximal gradient algorithm for optimizing afinite average of smooth convex functions, whose gradients depend onnumerically expensive expectations. Our main motivation is the acceleration ofthe optimization of the regularized Cox partial-likelihood (the core model usedin survival analysis), but our algorithm can be used in different settings aswell. The proposed algorithm is doubly stochastic in the sense that gradientsteps are done using stochastic gradient descent (SGD) with variance reduction,where the inner expectations are approximated by a Monte-Carlo Markov-Chain(MCMC) algorithm. We derive conditions on the MCMC number of iterationsguaranteeing convergence, and obtain a linear rate of convergence under strongconvexity and a sublinear rate without this assumption. We illustrate the factthat our algorithm improves the state-of-the-art solver for regularized Coxpartial-likelihood on several datasets from survival analysis.
arxiv-13800-5 | Measurement of Road Traffic Parameters Based on Multi-Vehicle Tracking | http://arxiv.org/pdf/1510.04860v1.pdf | author:Kristian Kovačić, Edouard Ivanjko, Niko Jelušić category:cs.CV published:2015-10-16 summary:Development of computing power and cheap video cameras enabled today'straffic management systems to include more cameras and computer visionapplications for transportation system monitoring and control. Combined withimage processing algorithms cameras are used as sensors to measure road trafficparameters like flow volume, origin-destination matrices, classify vehicles,etc. In this paper we propose a system for measurement of road trafficparameters (basic motion model parameters and macro-scopic traffic parameters).The system is based on Local Binary Pattern (LBP) image features classificationwith a cascade of Gentle Adaboost (GAB) classifiers to determine vehicleexistence and its location in an image. Additionally, vehicle tracking andcounting in a road traffic video is performed by using Extended Kalman Filter(EKF) and virtual markers. The newly proposed system is compared with a systembased on background subtraction. Comparison is performed by the means ofexecution time and accuracy.
arxiv-13800-6 | Towards Reversible De-Identification in Video Sequences Using 3D Avatars and Steganography | http://arxiv.org/pdf/1510.04861v1.pdf | author:Martin Blažević, Karla Brkić, Tomislav Hrkać category:cs.CV cs.MM published:2015-10-16 summary:We propose a de-identification pipeline that protects the privacy of humansin video sequences by replacing them with rendered 3D human models, henceconcealing their identity while retaining the naturalness of the scene. Theoriginal images of humans are steganographically encoded in the carrier image,i.e. the image containing the original scene and the rendered 3D human models.We qualitatively explore the feasibility of our approach, utilizing the Kinectsensor and its libraries to detect and localize human joints. A 3D avatar isrendered into the scene using the obtained joint positions, and the originalhuman image is steganographically encoded in the new scene. Our qualitativeevaluation shows reasonably good results that merit further exploration.
arxiv-13800-7 | A Survey: Time Travel in Deep Learning Space: An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas | http://arxiv.org/pdf/1510.04781v2.pdf | author:Haohan Wang, Bhiksha Raj category:cs.LG cs.NE published:2015-10-16 summary:This report will show the history of deep learning evolves. It will traceback as far as the initial belief of connectionism modelling of brain, and comeback to look at its early stage realization: neural networks. With thebackground of neural network, we will gradually introduce how convolutionalneural network, as a representative of deep discriminative models, is developedfrom neural networks, together with many practical techniques that can help inoptimization of neural networks. On the other hand, we will also trace back tosee the evolution history of deep generative models, to see how researchersbalance the representation power and computation complexity to reach RestrictedBoltzmann Machine and eventually reach Deep Belief Nets. Further, we will alsolook into the development history of modelling time series data with neuralnetworks. We start with Time Delay Neural Networks and move further tocurrently famous model named Recurrent Neural Network and its extension LongShort Term Memory. We will also briefly look into how to construct deeprecurrent neural networks. Finally, we will conclude this report with someinteresting open-ended questions of deep neural networks.
arxiv-13800-8 | An Extension to Hough Transform Based on Gradient Orientation | http://arxiv.org/pdf/1510.04863v1.pdf | author:Tomislav Petković, Sven Lončarić category:cs.CV published:2015-10-16 summary:The Hough transform is one of the most common methods for line detection. Inthis paper we propose a novel extension of the regular Hough transform. Theproposed extension combines the extension of the accumulator space and thelocal gradient orientation resulting in clutter reduction and yielding moreprominent peaks, thus enabling better line identification. We demonstratebenefits in applications such as visual quality inspection and rectangledetection.
arxiv-13800-9 | Quantification in-the-wild: data-sets and baselines | http://arxiv.org/pdf/1510.04811v2.pdf | author:Oscar Beijbom, Judy Hoffman, Evan Yao, Trevor Darrell, Alberto Rodriguez-Ramirez, Manuel Gonzalez-Rivero, Ove Hoegh - Guldberg category:cs.LG published:2015-10-16 summary:Quantification is the task of estimating the class-distribution of adata-set. While typically considered as a parameter estimation problem withstrict assumptions on the data-set shift, we consider quantificationin-the-wild, on two large scale data-sets from marine ecology: a survey ofCaribbean coral reefs, and a plankton time series from Martha's VineyardCoastal Observatory. We investigate several quantification methods from theliterature and indicate opportunities for future work. In particular, we showthat a deep neural network can be fine-tuned on a very limited amount of data(25 - 100 samples) to outperform alternative methods.
arxiv-13800-10 | Holographic Embeddings of Knowledge Graphs | http://arxiv.org/pdf/1510.04935v2.pdf | author:Maximilian Nickel, Lorenzo Rosasco, Tomaso Poggio category:cs.AI cs.LG stat.ML I.2.6; I.2.4 published:2015-10-16 summary:Learning embeddings of entities and relations is an efficient and versatilemethod to perform machine learning on relational data such as knowledge graphs.In this work, we propose holographic embeddings (HolE) to learn compositionalvector space representations of entire knowledge graphs. The proposed method isrelated to holographic models of associative memory in that it employs circularcorrelation to create compositional representations. By using correlation asthe compositional operator HolE can capture rich interactions butsimultaneously remains efficient to compute, easy to train, and scalable tovery large datasets. In extensive experiments we show that holographicembeddings are able to outperform state-of-the-art methods for link predictionin knowledge graphs and relational learning benchmark datasets.
arxiv-13800-11 | Normalization of Relative and Incomplete Temporal Expressions in Clinical Narratives | http://arxiv.org/pdf/1510.04972v1.pdf | author:Weiyi Sun, Anna Rumshisky, Ozlem Uzuner category:cs.CL cs.AI cs.IR published:2015-10-16 summary:We analyze the RI-TIMEXes in temporally annotated corpora and propose twohypotheses regarding the normalization of RI-TIMEXes in the clinical narrativedomain: the anchor point hypothesis and the anchor relation hypothesis. Weannotate the RI-TIMEXes in three corpora to study the characteristics ofRI-TMEXes in different domains. This informed the design of our RI-TIMEXnormalization system for the clinical domain, which consists of an anchor pointclassifier, an anchor relation classifier and a rule-based RI-TIMEX text spanparser. We experiment with different feature sets and perform error analysisfor each system component. The annotation confirmed the hypotheses that we cansimplify the RI-TIMEXes normalization task using two multi-label classifiers.Our system achieves anchor point classification, anchor relation classificationand rule-based parsing accuracy of 74.68%, 87.71% and 57.2% (82.09% underrelaxed matching criteria) respectively on the held-out test set of the 2012i2b2 temporal relation challenge. Experiments with feature sets reveals someinteresting findings such as the verbal tense feature does not inform theanchor relation classification in clinical narratives as much as the tokensnear the RI-TIMEX. Error analysis shows that underrepresented anchor point andanchor relation classes are difficult to detect. We formulate the RI-TIMEXnormalization problem as a pair of multi-label classification problems.Considering only the RI-TIMEX extraction and normalization, the system achievesstatistically significant improvement over the RI-TIMEX results of the bestsystems in the 2012 i2b2 challenge.
arxiv-13800-12 | Optimizing and Contrasting Recurrent Neural Network Architectures | http://arxiv.org/pdf/1510.04953v1.pdf | author:Ben Krause category:stat.ML cs.LG cs.NE published:2015-10-16 summary:Recurrent Neural Networks (RNNs) have long been recognized for theirpotential to model complex time series. However, it remains to be determinedwhat optimization techniques and recurrent architectures can be used to bestrealize this potential. The experiments presented take a deep look into Hessianfree optimization, a powerful second order optimization method that has shownpromising results, but still does not enjoy widespread use. This algorithm wasused to train to a number of RNN architectures including standard RNNs, longshort-term memory, multiplicative RNNs, and stacked RNNs on the task ofcharacter prediction. The insights from these experiments led to the creationof a new multiplicative LSTM hybrid architecture that outperformed both LSTMand multiplicative RNNs. When tested on a larger scale, multiplicative LSTMachieved character level modelling results competitive with the state of theart for RNNs using very different methodology.
arxiv-13800-13 | Robust Partially-Compressed Least-Squares | http://arxiv.org/pdf/1510.04905v1.pdf | author:Stephen Becker, Ban Kawas, Marek Petrik, Karthikeyan N. Ramamurthy category:stat.ML cs.LG published:2015-10-16 summary:Randomized matrix compression techniques, such as the Johnson-Lindenstrausstransform, have emerged as an effective and practical way for solvinglarge-scale problems efficiently. With a focus on computational efficiency,however, forsaking solutions quality and accuracy becomes the trade-off. Inthis paper, we investigate compressed least-squares problems and propose newmodels and algorithms that address the issue of error and noise introduced bycompression. While maintaining computational efficiency, our models providerobust solutions that are more accurate--relative to solutions of uncompressedleast-squares--than those of classical compressed variants. We introduce toolsfrom robust optimization together with a form of partial compression to improvethe error-time trade-offs of compressed least-squares solvers. We develop anefficient solution algorithm for our Robust Partially-Compressed (RPC) modelbased on a reduction to a one-dimensional search. We also derive the firstapproximation error bounds for Partially-Compressed least-squares solutions.Empirical results comparing numerous alternatives suggest that robust andpartially compressed solutions are effectively insulated against aggressiverandomized transforms.
arxiv-13800-14 | Scalable MCMC for Mixed Membership Stochastic Blockmodels | http://arxiv.org/pdf/1510.04815v2.pdf | author:Wenzhe Li, Sungjin Ahn, Max Welling category:cs.LG stat.ML published:2015-10-16 summary:We propose a stochastic gradient Markov chain Monte Carlo (SG-MCMC) algorithmfor scalable inference in mixed-membership stochastic blockmodels (MMSB). Ouralgorithm is based on the stochastic gradient Riemannian Langevin sampler andachieves both faster speed and higher accuracy at every iteration than thecurrent state-of-the-art algorithm based on stochastic variational inference.In addition we develop an approximation that can handle models that entertain avery large number of communities. The experimental results show that SG-MCMCstrictly dominates competing algorithms in all cases.
arxiv-13800-15 | Bad Universal Priors and Notions of Optimality | http://arxiv.org/pdf/1510.04931v1.pdf | author:Jan Leike, Marcus Hutter category:cs.AI cs.LG published:2015-10-16 summary:A big open question of algorithmic information theory is the choice of theuniversal Turing machine (UTM). For Kolmogorov complexity and Solomonoffinduction we have invariance theorems: the choice of the UTM changes boundsonly by a constant. For the universally intelligent agent AIXI (Hutter, 2005)no invariance theorem is known. Our results are entirely negative: we discusscases in which unlucky or adversarial choices of the UTM cause AIXI tomisbehave drastically. We show that Legg-Hutter intelligence and thus balancedPareto optimality is entirely subjective, and that every policy is Paretooptimal in the class of all computable environments. This undermines allexisting optimality properties for AIXI. While it may still serve as a goldstandard for AI, our results imply that AIXI is a relative theory, dependent onthe choice of the UTM.
arxiv-13800-16 | No Spare Parts: Sharing Part Detectors for Image Categorization | http://arxiv.org/pdf/1510.04908v1.pdf | author:Pascal Mettes, Jan C. van Gemert, Cees G. M. Snoek category:cs.CV published:2015-10-16 summary:This work aims for image categorization using a representation of distinctiveparts. Different from existing part-based work, we argue that parts arenaturally shared between image categories and should be modeled as such. Wemotivate our approach with a quantitative and qualitative analysis bybacktracking where selected parts come from. Our analysis shows that inaddition to the category parts defining the class, the parts coming from thebackground context and parts from other image categories improve categorizationperformance. Part selection should not be done separately for each category,but instead be shared and optimized over all categories. To incorporate partsharing between categories, we present an algorithm based on AdaBoost tojointly optimize part sharing and selection, as well as fusion with the globalimage representation. We achieve results competitive to the state-of-the-art onobject, scene, and action categories, further improving over deep convolutionalneural networks.
arxiv-13800-17 | Beyond Spatial Pyramid Matching: Space-time Extended Descriptor for Action Recognition | http://arxiv.org/pdf/1510.04565v1.pdf | author:Zhenzhong Lan, Alexander G. Hauptmann category:cs.CV published:2015-10-15 summary:We address the problem of generating video features for action recognition.The spatial pyramid and its variants have been very popular feature models dueto their success in balancing spatial location encoding and spatial invariance.Although it seems straightforward to extend spatial pyramid to the temporaldomain (spatio-temporal pyramid), the large spatio-temporal diversity ofunconstrained videos and the resulting significantly higher dimensionalrepresentations make it less appealing. This paper introduces the space-timeextended descriptor, a simple but efficient alternative way to include thespatio-temporal location into the video features. Instead of only coding motioninformation and leaving the spatio-temporal location to be represented at thepooling stage, location information is used as part of the encoding step. Thismethod is a much more effective and efficient location encoding method ascompared to the fixed grid model because it avoids the danger of overcommitting to artificial boundaries and its dimension is relatively low.Experimental results on several benchmark datasets show that, despite itssimplicity, this method achieves comparable or better results thanspatio-temporal pyramid.
arxiv-13800-18 | Elasticity-based Matching by Minimizing the Symmetric Difference of Shapes | http://arxiv.org/pdf/1510.04563v1.pdf | author:Konrad Simon, Ronen Basri category:cs.CV cs.CG published:2015-10-15 summary:We consider the problem of matching two shapes assuming these shapes arerelated by an elastic deformation. Using linearized elasticity theory and thefinite element method we seek an elastic deformation that is caused by simpleexternal boundary forces and accounts for the difference between the twoshapes. Our main contribution is in proposing a cost function and anoptimization procedure to minimize the symmetric difference between thedeformed and the target shapes as an alternative to point matches that guidethe matching in other techniques. We show how to approximate the nonlinearoptimization problem by a sequence of convex problems. We demonstrate theutility of our method in experiments and compare it to an ICP-like matchingalgorithm.
arxiv-13800-19 | A Brief Survey of Image Processing Algorithms in Electrical Capacitance Tomography | http://arxiv.org/pdf/1510.04585v1.pdf | author:Kezhi Li category:cs.CV published:2015-10-15 summary:To study the fundamental physics of complex multiphase flow systems usingadvanced measurement techniques, especially the electrical capacitancetomography (ECT) approach, this article carries out an initial literaturereview of the ECT method from a point of view of signal processing andalgorithm design. After introducing the physical laws governing the ECT system,we will focus on various reconstruction techniques that are capable to recoverthe image of the internal characteristics of a specified region based on themeasuring capacitances of multi-electrode sensors surrounding the region. Eachtechnique has its own advantages and limitations, and many algorithms have beenexamined by simulations or experiments. Future researches in 3D reconstructionand other potential improvements of the system are discussed in the end.
arxiv-13800-20 | A Picture is Worth a Billion Bits: Real-Time Image Reconstruction from Dense Binary Pixels | http://arxiv.org/pdf/1510.04601v2.pdf | author:Tal Remez, Or Litany, Alex Bronstein category:cs.CV published:2015-10-15 summary:The pursuit of smaller pixel sizes at ever increasing resolution in digitalimage sensors is mainly driven by the stringent price and form-factorrequirements of sensors and optics in the cellular phone market. Recently, EricFossum proposed a novel concept of an image sensor with dense sub-diffractionlimit one-bit pixels jots, which can be considered a digital emulation ofsilver halide photographic film. This idea has been recently embodied as theEPFL Gigavision camera. A major bottleneck in the design of such sensors is theimage reconstruction process, producing a continuous high dynamic range imagefrom oversampled binary measurements. The extreme quantization of the Poissonstatistics is incompatible with the assumptions of most standard imageprocessing and enhancement frameworks. The recently proposed maximum-likelihood(ML) approach addresses this difficulty, but suffers from image artifacts andhas impractically high computational complexity. In this work, we study avariant of a sensor with binary threshold pixels and propose a reconstructionalgorithm combining an ML data fitting term with a sparse synthesis prior. Wealso show an efficient hardware-friendly real-time approximation of thisinverse operator.Promising results are shown on synthetic data as well as onHDR data emulated using multiple exposures of a regular CMOS sensor.
arxiv-13800-21 | Telemedicine as a special case of Machine Translation | http://arxiv.org/pdf/1510.04600v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek, Wojciech Glinkowski category:cs.CL published:2015-10-15 summary:Machine translation is evolving quite rapidly in terms of quality. Nowadays,we have several machine translation systems available in the web, which providereasonable translations. However, these systems are not perfect, and theirquality may decrease in some specific domains. This paper examines the effectsof different training methods when it comes to Polish - English StatisticalMachine Translation system used for the medical data. Numerous elements of theEMEA parallel text corpora and not related OPUS Open Subtitles project wereused as the ground for creation of phrase tables and different language modelsincluding the development, tuning and testing of these translation systems. TheBLEU, NIST, METEOR, and TER metrics have been used in order to evaluate theresults of various systems. Our experiments deal with the systems that includePOS tagging, factored phrase models, hierarchical models, syntactic taggers,and other alignment methods. We also executed a deep analysis of Polish data aspreparatory work before automatized data processing such as true casing orpunctuation normalization phase. Normalized metrics was used to compareresults. Scores lower than 15% mean that Machine Translation engine is unableto provide satisfying quality, scores greater than 30% mean that translationsshould be understandable without problems and scores over 50 reflect adequatetranslations. The average results of Polish to English translations scores forBLEU, NIST, METEOR, and TER were relatively high and ranged from 70,58 to82,72. The lowest score was 64,38. The average results ranges for English toPolish translations were little lower (67,58 - 78,97). The real-lifeimplementations of presented high quality Machine Translation Systems areanticipated in general medical practice and telemedicine.
arxiv-13800-22 | Noisy-parallel and comparable corpora filtering methodology for the extraction of bi-lingual equivalent data at sentence level | http://arxiv.org/pdf/1510.04500v1.pdf | author:Krzysztof Wołk category:cs.CL published:2015-10-15 summary:Text alignment and text quality are critical to the accuracy of MachineTranslation (MT) systems, some NLP tools, and any other text processing tasksrequiring bilingual data. This research proposes a language independentbi-sentence filtering approach based on Polish (not a position-sensitivelanguage) to English experiments. This cleaning approach was developed on theTED Talks corpus and also initially tested on the Wikipedia comparable corpus,but it can be used for any text domain or language pair. The proposed approachimplements various heuristics for sentence comparison. Some of them leveragesynonyms and semantic and structural analysis of text as additionalinformation. Minimization of data loss was ensured. An improvement in MT systemscore with text processed using the tool is discussed.
arxiv-13800-23 | Sparsity-aware Possibilistic Clustering Algorithms | http://arxiv.org/pdf/1510.04493v1.pdf | author:Spyridoula D. Xenaki, Konstantinos D. Koutroumbas, Athanasios A. Rontogiannis category:cs.CV published:2015-10-15 summary:In this paper two novel possibilistic clustering algorithms are presented,which utilize the concept of sparsity. The first one, called sparsepossibilistic c-means, exploits sparsity and can deal well with closely locatedclusters that may also be of significantly different densities. The second one,called sparse adaptive possibilistic c-means, is an extension of the first,where now the involved parameters are dynamically adapted. The latter can dealwell with even more challenging cases, where, in addition to the above,clusters may be of significantly different variances. More specifically, itprovides improved estimates of the cluster representatives, while, in addition,it has the ability to estimate the actual number of clusters, given anoverestimate of it. Extensive experimental results on both synthetic and realdata sets support the previous statements.
arxiv-13800-24 | Layer-Specific Adaptive Learning Rates for Deep Networks | http://arxiv.org/pdf/1510.04609v1.pdf | author:Bharat Singh, Soham De, Yangmuzi Zhang, Thomas Goldstein, Gavin Taylor category:cs.CV cs.AI cs.LG cs.NE published:2015-10-15 summary:The increasing complexity of deep learning architectures is resulting intraining time requiring weeks or even months. This slow training is due in partto vanishing gradients, in which the gradients used by back-propagation areextremely large for weights connecting deep layers (layers near the outputlayer), and extremely small for shallow layers (near the input layer); thisresults in slow learning in the shallow layers. Additionally, it has also beenshown that in highly non-convex problems, such as deep neural networks, thereis a proliferation of high-error low curvature saddle points, which slows downlearning dramatically. In this paper, we attempt to overcome the two aboveproblems by proposing an optimization method for training deep neural networkswhich uses learning rates which are both specific to each layer in the networkand adaptive to the curvature of the function, increasing the learning rate atlow curvature points. This enables us to speed up learning in the shallowlayers of the network and quickly escape high-error low curvature saddlepoints. We test our method on standard image classification datasets such asMNIST, CIFAR10 and ImageNet, and demonstrate that our method increases accuracyas well as reduces the required training time over standard algorithms.
arxiv-13800-25 | Multilingual Image Description with Neural Sequence Models | http://arxiv.org/pdf/1510.04709v2.pdf | author:Desmond Elliott, Stella Frank, Eva Hasler category:cs.CL cs.CV cs.LG cs.NE published:2015-10-15 summary:In this paper we present an approach to multi-language image descriptionbringing together insights from neural machine translation and neural imagedescription. To create a description of an image for a given target language,our sequence generation models condition on feature vectors from the image, thedescription from the source language, and/or a multimodal vector computed overthe image and a description in the source language. In image descriptionexperiments on the IAPR-TC12 dataset of images aligned with English and Germansentences, we find significant and substantial improvements in BLEU4 and Meteorscores for models trained over multiple languages, compared to a monolingualbaseline.
arxiv-13800-26 | Online Markov decision processes with policy iteration | http://arxiv.org/pdf/1510.04454v1.pdf | author:Yao Ma, Hao Zhang, Masashi Sugiyama category:cs.LG published:2015-10-15 summary:The online Markov decision process (MDP) is a generalization of the classicalMarkov decision process that incorporates changing reward functions. In thispaper, we propose practical online MDP algorithms with policy iteration andtheoretically establish a sublinear regret bound. A notable advantage of theproposed algorithm is that it can be easily combined with functionapproximation, and thus large and possibly continuous state spaces can beefficiently handled. Through experiments, we demonstrate the usefulness of theproposed algorithm.
arxiv-13800-27 | DeepProposal: Hunting Objects by Cascading Deep Convolutional Layers | http://arxiv.org/pdf/1510.04445v1.pdf | author:Amir Ghodrati, Ali Diba, Marco Pedersoli, Tinne Tuytelaars, Luc Van Gool category:cs.CV published:2015-10-15 summary:In this paper we evaluate the quality of the activation layers of aconvolutional neural network (CNN) for the gen- eration of object proposals. Wegenerate hypotheses in a sliding-window fashion over different activationlayers and show that the final convolutional layers can find the object ofinterest with high recall but poor localization due to the coarseness of thefeature maps. Instead, the first layers of the network can better localize theobject of interest but with a reduced recall. Based on this observation wedesign a method for proposing object locations that is based on CNN featuresand that combines the best of both worlds. We build an inverse cascade that,going from the final to the initial convolutional layers of the CNN, selectsthe most promising object locations and refines their boxes in a coarse-to-finemanner. The method is efficient, because i) it uses the same features extractedfor detection, ii) it aggregates features using integral images, and iii) itavoids a dense evaluation of the proposals due to the inverse coarse-to-finecascade. The method is also accurate; it outperforms most of the previouslyproposed object proposals approaches and when plugged into a CNN-based detectorproduces state-of-the- art detection performance.
arxiv-13800-28 | Tensor vs Matrix Methods: Robust Tensor Decomposition under Block Sparse Perturbations | http://arxiv.org/pdf/1510.04747v7.pdf | author:Animashree Anandkumar, Prateek Jain, Yang Shi, U. N. Niranjan category:cs.LG cs.IT math.IT stat.ML published:2015-10-15 summary:Robust tensor CP decomposition involves decomposing a tensor into low rankand sparse components. We propose a novel non-convex iterative algorithm withguaranteed recovery. It alternates between low-rank CP decomposition throughgradient ascent (a variant of the tensor power method), and hard thresholdingof the residual. We prove convergence to the globally optimal solution undernatural incoherence conditions on the low rank component, and bounded level ofsparse perturbations. We compare our method with natural baselines which applyrobust matrix PCA either to the {\em flattened} tensor, or to the matrix slicesof the tensor. Our method can provably handle a far greater level ofperturbation when the sparse tensor is block-structured. This naturally occursin many applications such as the activity detection task in videos. Ourexperiments validate these findings. Thus, we establish that tensor methods cantolerate a higher level of gross corruptions compared to matrix methods.
arxiv-13800-29 | Group-Invariant Subspace Clustering | http://arxiv.org/pdf/1510.04356v1.pdf | author:Shuchin Aeron, Eric Kernfeld category:cs.IT cs.LG math.IT stat.ML published:2015-10-15 summary:In this paper we consider the problem of group invariant subspace clusteringwhere the data is assumed to come from a union of group-invariant subspaces ofa vector space, i.e. subspaces which are invariant with respect to action of agiven group. Algebraically, such group-invariant subspaces are also referred toas submodules. Similar to the well known Sparse Subspace Clustering approachwhere the data is assumed to come from a union of subspaces, we analyze analgorithm which, following a recent work [1], we refer to as Sparse Sub-moduleClustering (SSmC). The method is based on finding group-sparseself-representation of data points. In this paper we primarily derive generalconditions under which such a group-invariant subspace identification ispossible. In particular we extend the geometric analysis in [2] and in theprocess we identify a related problem in geometric functional analysis.
arxiv-13800-30 | Scatter Component Analysis: A Unified Framework for Domain Adaptation and Domain Generalization | http://arxiv.org/pdf/1510.04373v1.pdf | author:Muhammad Ghifary, David Balduzzi, W. Bastiaan Kleijn, Mengjie Zhang category:cs.CV published:2015-10-15 summary:This paper addresses classification tasks on a particular target domain inwhich labeled training data are only available from source domains differentfrom (but related to) the target. Two closely related frameworks, domainadaptation and domain generalization, are concerned with such tasks, where theonly difference between those frameworks is the availability of the unlabeledtarget data: domain adaptation can leverage unlabeled target information, whiledomain generalization cannot. We propose Scatter Component Analyis (SCA), a fast representation learningalgorithm that can be applied to both domain adaptation and domaingeneralization. SCA is based on a simple geometrical measure, i.e., scatter,which operates on reproducing kernel Hilbert space. SCA finds a representationthat trades between maximizing the separability of classes, minimizing themismatch between domains, and maximizing the separability of data; each ofwhich is quantified through scatter. The optimization problem of SCA can bereduced to a generalized eigenvalue problem, which results in a fast and exactsolution. Comprehensive experiments on benchmark cross-domain object recognitiondatasets verify that SCA performs much faster than several state-of-the-artalgorithms and also provides state-of-the-art classification accuracy in bothdomain adaptation and domain generalization. We also show that scatter can beused to establish a theoretical generalization bound in the case of domainadaptation.
arxiv-13800-31 | Robust Learning for Optimal Treatment Decision with NP-Dimensionality | http://arxiv.org/pdf/1510.04378v1.pdf | author:Chengchun Shi, Rui Song, Wenbin Lu category:stat.ML published:2015-10-15 summary:In order to identify important variables that are involved in making optimaltreatment decision, Lu et al. (2013) proposed a penalized least squaredregression framework for a fixed number of predictors, which is robust againstthe misspecification of the conditional mean model. Two problems arise: (i) ina world of explosively big data, effective methods are needed to handleultra-high dimensional data set, for example, with the dimension of predictorsis of the non-polynomial (NP) order of the sample size; (ii) both thepropensity score and conditional mean models need to be estimated from dataunder NP dimensionality. In this paper, we propose a two-step estimation procedure for deriving theoptimal treatment regime under NP dimensionality. In both steps, penalizedregressions are employed with the non-concave penalty function, where theconditional mean model of the response given predictors may be misspecified.The asymptotic properties, such as weak oracle properties, selectionconsistency and oracle distributions, of the proposed estimators areinvestigated. In addition, we study the limiting distribution of the estimatedvalue function for the obtained optimal treatment regime. The empiricalperformance of the proposed estimation method is evaluated by simulations andan application to a depression dataset from the STAR*D study.
arxiv-13800-32 | Sketch-based Manga Retrieval using Manga109 Dataset | http://arxiv.org/pdf/1510.04389v1.pdf | author:Yusuke Matsui, Kota Ito, Yuji Aramaki, Toshihiko Yamasaki, Kiyoharu Aizawa category:cs.CV cs.IR cs.MM published:2015-10-15 summary:Manga (Japanese comics) are popular worldwide. However, current e-mangaarchives offer very limited search support, including keyword-based search bytitle or author, or tag-based categorization. To make the manga searchexperience more intuitive, efficient, and enjoyable, we propose a content-basedmanga retrieval system. First, we propose a manga-specific image-describingframework. It consists of efficient margin labeling, edge orientation histogramfeature description, and approximate nearest-neighbor search using productquantization. Second, we propose a sketch-based interface as a natural way tointeract with manga content. The interface provides sketch-based querying,relevance feedback, and query retouch. For evaluation, we built a novel datasetof manga images, Manga109, which consists of 109 comic books of 21,142 pagesdrawn by professional manga artists. To the best of our knowledge, Manga109 iscurrently the biggest dataset of manga images available for research. Weconducted a comparative study, a localization evaluation, and a large-scalequalitative study. From the experiments, we verified that: (1) the retrievalaccuracy of the proposed method is higher than those of previous methods; (2)the proposed method can localize an object instance with reasonable runtime andaccuracy; and (3) sketch querying is useful for manga search.
arxiv-13800-33 | Dual Principal Component Pursuit | http://arxiv.org/pdf/1510.04390v1.pdf | author:Manolis C. Tsakiris, Rene Vidal category:cs.CV cs.LG published:2015-10-15 summary:We consider the problem of outlier rejection in single subspace learning.Classical approaches work directly with a low-dimensional representation of thesubspace. Our approach works with a dual representation of the subspace andhence aims to find its orthogonal complement. We pose this problem as an$\ell_1$-minimization problem on the sphere and show that, under certainconditions on the distribution of the data, any global minimizer of thisnon-convex problem gives a vector orthogonal to the subspace. Moreover, we showthat such a vector can still be found by relaxing the non-convex problem with asequence of linear programs. Experiments on synthetic and real data show thatthe proposed approach, which we call Dual Principal Component Pursuit (DPCP),outperforms state-of-the art methods, especially in the case ofhigh-dimensional subspaces.
arxiv-13800-34 | Filtrated Spectral Algebraic Subspace Clustering | http://arxiv.org/pdf/1510.04396v1.pdf | author:Manolis C. Tsakiris, Rene Vidal category:cs.CV cs.LG published:2015-10-15 summary:Algebraic Subspace Clustering (ASC) is a simple and elegant method based onpolynomial fitting and differentiation for clustering noiseless data drawn froman arbitrary union of subspaces. In practice, however, ASC is limited toequi-dimensional subspaces because the estimation of the subspace dimension viaalgebraic methods is sensitive to noise. This paper proposes a new ASCalgorithm that can handle noisy data drawn from subspaces of arbitrarydimensions. The key ideas are (1) to construct, at each point, a decreasingsequence of subspaces containing the subspace passing through that point; (2)to use the distances from any other point to each subspace in the sequence toconstruct a subspace clustering affinity, which is superior to alternativeaffinities both in theory and in practice. Experiments on the Hopkins 155dataset demonstrate the superiority of the proposed method with respect tosparse and low rank subspace clustering methods.
arxiv-13800-35 | A Novel Approach for Human Action Recognition from Silhouette Images | http://arxiv.org/pdf/1510.04437v1.pdf | author:Satyabrata Maity, Debotosh Bhattacharjee, Amlan Chakrabarti category:cs.CV published:2015-10-15 summary:In this paper, a novel human action recognition technique from video ispresented. Any action of human is a combination of several micro actionsequences performed by one or more body parts of the human. The proposedapproach uses spatio-temporal body parts movement (STBPM) features extractedfrom foreground silhouette of the human objects. The newly proposed STBPMfeature estimates the movements of different body parts for any given timesegment to classify actions. We also proposed a rule based logic named ruleaction classifier (RAC), which uses a series of condition action rules based onprior knowledge and hence does not required training to classify any action.Since we don't require training to classify actions, the proposed approach isview independent. The experimental results on publicly available Wizeman andMuHVAi datasets are compared with that of the related research work in terms ofaccuracy in the human action detection, and proposed technique outperforms theothers.
arxiv-13800-36 | Shape Complexes in Continuous Max-Flow Hierarchical Multi-Labeling Problems | http://arxiv.org/pdf/1510.04706v1.pdf | author:John S. H. Baxter, Jing Yuan, Terry M. Peters category:cs.CV published:2015-10-15 summary:Although topological considerations amongst multiple labels have beenpreviously investigated in the context of continuous max-flow imagesegmentation, similar investigations have yet to be made about shapeconsiderations in a general and extendable manner. This paper presents shapecomplexes for segmentation, which capture more complex shapes by combiningmultiple labels and super-labels constrained by geodesic star convexity. Shapecomplexes combine geodesic star convexity constraints with hierarchical labelorganization, which together allow for more complex shapes to be represented.This framework avoids the use of co-ordinate system warping techniques toconvert shape constraints into topological constraints, which may be ambiguousor ill-defined for certain segmentation problems.
arxiv-13800-37 | A Method for Modeling Co-Occurrence Propensity of Clinical Codes with Application to ICD-10-PCS Auto-Coding | http://arxiv.org/pdf/1510.04734v1.pdf | author:Michael Subotin, Anthony R. Davis category:cs.CL published:2015-10-15 summary:Objective. Natural language processing methods for medical auto-coding, orautomatic generation of medical billing codes from electronic health records,generally assign each code independently of the others. They may thus assigncodes for closely related procedures or diagnoses to the same document, evenwhen they do not tend to occur together in practice, simply because the rightchoice can be difficult to infer from the clinical narrative. Materials and Methods. We propose a method that injects awareness of thepropensities for code co-occurrence into this process. First, a model istrained to estimate the conditional probability that one code is assigned by ahuman coder, given than another code is known to have been assigned to the samedocument. Then, at runtime, an iterative algorithm is used to apply this modelto the output of an existing statistical auto-coder to modify the confidencescores of the codes. Results. We tested this method in combination with a primary auto-coder forICD-10 procedure codes, achieving a 12% relative improvement in F-score overthe primary auto-coder baseline. Discussion. The proposed method can be used, with appropriate features, incombination with any auto-coder that generates codes with different levels ofconfidence. Conclusion. The promising results obtained for ICD-10 procedure codes suggestthat the proposed method may have wider applications in auto-coding.
arxiv-13800-38 | Structured Memory for Neural Turing Machines | http://arxiv.org/pdf/1510.03931v3.pdf | author:Wei Zhang, Yang Yu, Bowen Zhou category:cs.AI cs.NE I.2.6 published:2015-10-14 summary:Neural Turing Machines (NTM) contain memory component that simulates "workingmemory" in the brain to store and retrieve information to ease simplealgorithms learning. So far, only linearly organized memory is proposed, andduring experiments, we observed that the model does not always converge, andoverfits easily when handling certain tasks. We think memory component is keyto some faulty behaviors of NTM, and better organization of memory componentcould help fight those problems. In this paper, we propose several differentstructures of memory for NTM, and we proved in experiments that two of ourproposed structured-memory NTMs could lead to better convergence, in term ofspeed and prediction accuracy on copy task and associative recall task as in(Graves et al. 2014).
arxiv-13800-39 | An Omnibus Nonparametric Test of Equality in Distribution for Unknown Functions | http://arxiv.org/pdf/1510.04195v2.pdf | author:Alexander R. Luedtke, Marco Carone, Mark J. van der Laan category:math.ST stat.ML stat.TH 62G10 published:2015-10-14 summary:We present a novel family of nonparametric omnibus tests of the hypothesisthat two unknown but estimable functions are equal in distribution when appliedto the observed data structure. We developed these tests, which represent ageneralization of the maximum mean discrepancy tests described in Gretton etal. [2006], using recent developments from the higher-order pathwisedifferentiability literature. Despite their complex derivation, the associatedtest statistics can be expressed rather simply as U-statistics. We study theasymptotic behavior of the proposed tests under the null hypothesis and underboth fixed and local alternatives. We provide examples to which our tests canbe applied and show that they perform well in a simulation study. As animportant special case, our proposed tests can be used to determine whether anunknown function, such as the conditional average treatment effect, is equal tozero almost surely.
arxiv-13800-40 | Estimation and Inference of Heterogeneous Treatment Effects using Random Forests | http://arxiv.org/pdf/1510.04342v2.pdf | author:Stefan Wager, Susan Athey category:stat.ME math.ST stat.ML stat.TH published:2015-10-14 summary:Many scientific and engineering challenges---ranging from personalizedmedicine to customized marketing recommendations---require an understanding oftreatment effect heterogeneity. In this paper, we develop a non-parametriccausal forest for estimating heterogeneous treatment effects that extendsBreiman's widely used random forest algorithm. Given a potential outcomesframework with unconfoundedness, we show that causal forests are pointwiseconsistent for the true treatment effect, and have an asymptotically Gaussianand centered sampling distribution. We also discuss a practical method forconstructing asymptotic confidence intervals for the true treatment effect thatare centered at the causal forest estimates. Our theoretical results rely on ageneric Gaussian theory for a large family of random forest algorithms, to ourknowledge, this is the first set of results that allows any type of randomforest, including classification and regression forests, to be used forprovably valid statistical inference. In experiments, we find causal forests tobe substantially more powerful than classical methods based on nearest-neighbormatching, especially as the number of covariates increases.
arxiv-13800-41 | Dynamical spectral unmixing of multitemporal hyperspectral images | http://arxiv.org/pdf/1510.04238v1.pdf | author:Simon Henrot, Jocelyn Chanussot, Christian Jutten category:cs.CV published:2015-10-14 summary:In this paper, we consider the problem of unmixing a time series ofhyperspectral images. We propose a dynamical model based on linear mixingprocesses at each time instant. The spectral signatures and fractionalabundances of the pure materials in the scene are seen as latent variables, andassumed to follow a general dynamical structure. Based on a simplified versionof this model, we derive an efficient spectral unmixing algorithm to estimatethe latent variables by performing alternating minimizations. The performanceof the proposed approach is demonstrated on synthetic and real multitemporalhyperspectral images.
arxiv-13800-42 | Embarrassingly Parallel Variational Inference in Nonconjugate Models | http://arxiv.org/pdf/1510.04163v1.pdf | author:Willie Neiswanger, Chong Wang, Eric Xing category:stat.ML cs.AI cs.DC cs.LG stat.CO published:2015-10-14 summary:We develop a parallel variational inference (VI) procedure for use indata-distributed settings, where each machine only has access to a subset ofdata and runs VI independently, without communicating with other machines. Thistype of "embarrassingly parallel" procedure has recently been developed forMCMC inference algorithms; however, in many cases it is not possible todirectly extend this procedure to VI methods without requiring certainrestrictive exponential family conditions on the form of the model.Furthermore, most existing (nonparallel) VI methods are restricted to use onconditionally conjugate models, which limits their applicability. To combatthese issues, we make use of the recently proposed nonparametric VI tofacilitate an embarrassingly parallel VI procedure that can be applied to awider scope of models, including to nonconjugate models. We derive ourembarrassingly parallel VI algorithm, analyze our method theoretically, anddemonstrate our method empirically on a few nonconjugate models.
arxiv-13800-43 | Improving Back-Propagation by Adding an Adversarial Gradient | http://arxiv.org/pdf/1510.04189v2.pdf | author:Arild Nøkland category:stat.ML cs.LG published:2015-10-14 summary:The back-propagation algorithm is widely used for learning in artificialneural networks. A challenge in machine learning is to create models thatgeneralize to new data samples not seen in the training data. Recently, acommon flaw in several machine learning algorithms was discovered: smallperturbations added to the input data lead to consistent misclassification ofdata samples. Samples that easily mislead the model are called adversarialexamples. Training a "maxout" network on adversarial examples has shown todecrease this vulnerability, but also increase classification performance. Thispaper shows that adversarial training has a regularizing effect also innetworks with logistic, hyperbolic tangent and rectified linear units. A simpleextension to the back-propagation method is proposed, that adds an adversarialgradient to the training. The extension requires an additional forward andbackward pass to calculate a modified input sample, or mini batch, used asinput for standard back-propagation learning. The first experimental results onMNIST show that the "adversarial back-propagation" method increases theresistance to adversarial examples and boosts the classification performance.The extension reduces the classification error on the permutation invariantMNIST from 1.60% to 0.95% in a logistic network, and from 1.40% to 0.78% in anetwork with rectified linear units. Results on CIFAR-10 indicate that themethod has a regularizing effect similar to dropout in fully connectednetworks. Based on these promising results, adversarial back-propagation isproposed as a stand-alone regularizing method that should be furtherinvestigated.
arxiv-13800-44 | A Bayesian Network Model for Interesting Itemsets | http://arxiv.org/pdf/1510.04130v1.pdf | author:Jaroslav Fowkes, Charles Sutton category:stat.ML cs.DB cs.LG published:2015-10-14 summary:Mining itemsets that are the most interesting under a statistical model ofthe underlying data is a frequently used and well-studied technique forexploratory data analysis. The most recent models of interestingness arepredominantly based on maximum entropy distributions over items or tile entrieswith itemset constraints, and while computationally tractable are not easilyinterpretable. We therefore propose the first, to the best of our knowledge,generative model over itemsets, in the form of a Bayesian network, and anassociated novel measure of interestingness. Our model is able to efficientlyinfer interesting itemsets directly from the transaction database usingstructural EM, in which the E-step employs the greedy approximation to weightedset cover. Our approach is theoretically simple, straightforward to implement,trivially parallelizable and exhibits competitive performance as we demonstrateon both synthetic and real-world examples.
arxiv-13800-45 | Fine-Grained Product Class Recognition for Assisted Shopping | http://arxiv.org/pdf/1510.04074v1.pdf | author:Marian George, Dejan Mircic, Gábor Sörös, Christian Floerkemeier, Friedemann Mattern category:cs.CV published:2015-10-14 summary:Assistive solutions for a better shopping experience can improve the qualityof life of people, in particular also of visually impaired shoppers. We presenta system that visually recognizes the fine-grained product classes of items ona shopping list, in shelves images taken with a smartphone in a grocery store.Our system consists of three components: (a) We automatically recognize usefultext on product packaging, e.g., product name and brand, and build a mapping ofwords to product classes based on the large-scale GroceryProducts dataset. Whenthe user populates the shopping list, we automatically infer the product classof each entered word. (b) We perform fine-grained product class recognitionwhen the user is facing a shelf. We discover discriminative patches on productpackaging to differentiate between visually similar product classes and toincrease the robustness against continuous changes in product design. (c) Wecontinuously improve the recognition accuracy through active learning. Ourexperiments show the robustness of the proposed method against cross-domainchallenges, and the scalability to an increasing number of products withminimal re-training.
arxiv-13800-46 | Multiresolution Search of the Rigid Motion Space for Intensity Based Registration | http://arxiv.org/pdf/1510.04004v1.pdf | author:Behrooz Nasihatkon, Fredrik Kahl category:cs.CV published:2015-10-14 summary:We study the relation between the target functions of low-resolution andhigh-resolution intensity-based registration for the class of rigidtransformations. Our results show that low resolution target values can tightlybound the high-resolution target function in natural images. This can help withanalyzing and better understanding the process of multiresolution imageregistration. It also gives a guideline for designing multiresolutionalgorithms in which the search space in higher resolution registration isrestricted given the fitness values for lower resolution image pairs. Todemonstrate this, we incorporate our multiresolution technique into a Lipschitzglobal optimization framework. We show that using the multiresolution schemecan result in large gains in the efficiency of such algorithms. The method isevaluated by applying to 2D and 3D registration problems as well as thedetection of reflective symmetry in 2D and 3D images.
arxiv-13800-47 | Better Exploiting OS-CNNs for Better Event Recognition in Images | http://arxiv.org/pdf/1510.03979v1.pdf | author:Limin Wang, Zhe Wang, Sheng Guo, Yu Qiao category:cs.CV published:2015-10-14 summary:Event recognition from still images is one of the most important problems forimage understanding. However, compared with object recognition and scenerecognition, event recognition has received much less research attention incomputer vision community. This paper addresses the problem of cultural eventrecognition in still images and focuses on applying deep learning methods onthis problem. In particular, we utilize the successful architecture ofObject-Scene Convolutional Neural Networks (OS-CNNs) to perform eventrecognition. OS-CNNs are composed of object nets and scene nets, which transferthe learned representations from the pre-trained models on large-scale objectand scene recognition datasets, respectively. We propose four types ofscenarios to explore OS-CNNs for event recognition by treating them as either"end-to-end event predictors" or "generic feature extractors". Our experimentalresults demonstrate that the global and local representations of OS-CNNs arecomplementary to each other. Finally, based on our investigation of OS-CNNs, wecome up with a solution for the cultural event recognition track at the ICCVChaLearn Looking at People (LAP) challenge 2015. Our team secures the thirdplace at this challenge and our result is very close to the best performance.
arxiv-13800-48 | $\ell_1$-regularized Neural Networks are Improperly Learnable in Polynomial Time | http://arxiv.org/pdf/1510.03528v1.pdf | author:Yuchen Zhang, Jason D. Lee, Michael I. Jordan category:cs.LG published:2015-10-13 summary:We study the improper learning of multi-layer neural networks. Suppose thatthe neural network to be learned has $k$ hidden layers and that the$\ell_1$-norm of the incoming weights of any neuron is bounded by $L$. Wepresent a kernel-based method, such that with probability at least $1 -\delta$, it learns a predictor whose generalization error is at most $\epsilon$worse than that of the neural network. The sample complexity and the timecomplexity of the presented method are polynomial in the input dimension and in$(1/\epsilon,\log(1/\delta),F(k,L))$, where $F(k,L)$ is a function depending on$(k,L)$ and on the activation function, independent of the number of neurons.The algorithm applies to both sigmoid-like activation functions and ReLU-likeactivation functions. It implies that any sufficiently sparse neural network islearnable in polynomial time.
arxiv-13800-49 | Dual Control for Approximate Bayesian Reinforcement Learning | http://arxiv.org/pdf/1510.03591v1.pdf | author:Edgar D. Klenske, Philipp Hennig category:stat.ML cs.SY math.OC published:2015-10-13 summary:Control of non-episodic, finite-horizon dynamical systems with uncertaindynamics poses a tough and elementary case of the exploration-exploitationtrade-off. Bayesian reinforcement learning, reasoning about the effect ofactions and future observations, offers a principled solution, but isintractable. We review, then extend an old approximate approach from controltheory---where the problem is known as dual control---in the context of modernregression methods, specifically generalized linear regression. Experiments onsimulated systems show that this framework offers a useful approximation to theintractable aspects of Bayesian RL, producing structured exploration strategiesthat differ from standard RL approaches. We provide simple examples for the useof this framework in (approximate) Gaussian process regression and feedforwardneural networks for the control of exploration.
arxiv-13800-50 | A language model based approach towards large scale and lightweight language identification systems | http://arxiv.org/pdf/1510.03602v1.pdf | author:Brij Mohan Lal Srivastava, Hari Krishna Vydana, Anil Kumar Vuppala, Manish Shrivastava category:cs.SD cs.CL published:2015-10-13 summary:Multilingual spoken dialogue systems have gained prominence in the recentpast necessitating the requirement for a front-end Language Identification(LID) system. Most of the existing LID systems rely on modeling the languagediscriminative information from low-level acoustic features. Due to thevariabilities of speech (speaker and emotional variabilities, etc.),large-scale LID systems developed using low-level acoustic features suffer froma degradation in the performance. In this approach, we have attempted to modelthe higher level language discriminative phonotactic information for developingan LID system. In this paper, the input speech signal is tokenized to phonesequences by using a language independent phone recognizer. The languagediscriminative phonotactic information in the obtained phone sequences aremodeled using statistical and recurrent neural network based language modelingapproaches. As this approach, relies on higher level phonotactical informationit is more robust to variabilities of speech. Proposed approach iscomputationally light weight, highly scalable and it can be used in complementwith the existing LID systems.
arxiv-13800-51 | SemanticPaint: A Framework for the Interactive Segmentation of 3D Scenes | http://arxiv.org/pdf/1510.03727v1.pdf | author:Stuart Golodetz, Michael Sapienza, Julien P. C. Valentin, Vibhav Vineet, Ming-Ming Cheng, Anurag Arnab, Victor A. Prisacariu, Olaf Kähler, Carl Yuheng Ren, David W. Murray, Shahram Izadi, Philip H. S. Torr category:cs.CV I.2.10 published:2015-10-13 summary:We present an open-source, real-time implementation of SemanticPaint, asystem for geometric reconstruction, object-class segmentation and learning of3D scenes. Using our system, a user can walk into a room wearing a depth cameraand a virtual reality headset, and both densely reconstruct the 3D scene andinteractively segment the environment into object classes such as 'chair','floor' and 'table'. The user interacts physically with the real-world scene,touching objects and using voice commands to assign them appropriate labels.These user-generated labels are leveraged by an online random forest-basedmachine learning algorithm, which is used to predict labels for previouslyunseen parts of the scene. The entire pipeline runs in real time, and the userstays 'in the loop' throughout the process, receiving immediate feedback aboutthe progress of the labelling and interacting with the scene as necessary torefine the predicted segmentation.
arxiv-13800-52 | Fast sequential forensic camera identification | http://arxiv.org/pdf/1510.03730v1.pdf | author:Fernando Pérez-González, Iria González-Iglesias, Miguel Masciopinto, Pedro Comesaña category:cs.CR cs.CV published:2015-10-13 summary:Two sequential camera source identification methods are proposed. Sequentialtests implement a log-likelihood ratio test in an incremental way, thusenabling a reliable decision with a minimal number of observations. One of ourmethods adapts Goljan et al.'s to sequential operation. The second, whichoffers better performance in terms of error probabilities and average number oftest observations, is based on treating the alternative hypothesis as a doublystochastic model. We also discuss how the standard sequential test can becorrected to account for the event of weak fingerprints. Finally, we validatethe goodness of our methods with experiments.
arxiv-13800-53 | Wide-Area Image Geolocalization with Aerial Reference Imagery | http://arxiv.org/pdf/1510.03743v1.pdf | author:Scott Workman, Richard Souvenir, Nathan Jacobs category:cs.CV published:2015-10-13 summary:We propose to use deep convolutional neural networks to address the problemof cross-view image geolocalization, in which the geolocation of a ground-levelquery image is estimated by matching to georeferenced aerial images. We usestate-of-the-art feature representations for ground-level images and introducea cross-view training approach for learning a joint semantic featurerepresentation for aerial images. We also propose a network architecture thatfuses features extracted from aerial images at multiple spatial scales. Tosupport training these networks, we introduce a massive database that containspairs of aerial and ground-level images from across the United States. Ourmethods significantly out-perform the state of the art on two benchmarkdatasets. We also show, qualitatively, that the proposed featurerepresentations are discriminative at both local and continental spatialscales.
arxiv-13800-54 | Complex Politics: A Quantitative Semantic and Topological Analysis of UK House of Commons Debates | http://arxiv.org/pdf/1510.03797v1.pdf | author:Stefano Gurciullo, Michael Smallegan, María Pereda, Federico Battiston, Alice Patania, Sebastian Poledna, Daniel Hedblom, Bahattin Tolga Oztan, Alexander Herzog, Peter John, Slava Mikhaylov category:physics.soc-ph cs.CL cs.SI 91F10 published:2015-10-13 summary:This study is a first, exploratory attempt to use quantitative semanticstechniques and topological analysis to analyze systemic patterns arising in acomplex political system. In particular, we use a rich data set covering allspeeches and debates in the UK House of Commons between 1975 and 2014. By theuse of dynamic topic modeling (DTM) and topological data analysis (TDA) we showthat both members and parties feature specific roles within the system,consistent over time, and extract global patterns indicating levels ofpolitical cohesion. Our results provide a wide array of novel hypotheses aboutthe complex dynamics of political systems, with valuable policy applications.
arxiv-13800-55 | Nonlinear memory capacity of parallel time-delay reservoir computers in the processing of multidimensional signals | http://arxiv.org/pdf/1510.03891v1.pdf | author:Lyudmila Grigoryeva, Julie Henriques, Laurent Larger, Juan-Pablo Ortega category:cs.NE published:2015-10-13 summary:This paper addresses the reservoir design problem in the context ofdelay-based reservoir computers for multidimensional input signals, parallelarchitectures, and real-time multitasking. First, an approximating reservoirmodel is presented in those frameworks that provides an explicit functionallink between the reservoir parameters and architecture and its performance inthe execution of a specific task. Second, the inference properties of the ridgeregression estimator in the multivariate context is used to assess the impactof finite sample training on the decrease of the reservoir capacity. Finally,an empirical study is conducted that shows the adequacy of the theoreticalresults with the empirical performances exhibited by various reservoirarchitectures in the execution of several nonlinear tasks with multidimensionalinputs. Our results confirm the robustness properties of the parallel reservoirarchitecture with respect to task misspecification and parameter choice thathad already been documented in the literature.
arxiv-13800-56 | Variable-state Latent Conditional Random Fields for Facial Expression Recognition and Action Unit Detection | http://arxiv.org/pdf/1510.03909v1.pdf | author:Robert Walecki, Ognjen Rudovic, Vladimir Pavlovic, Maja Pantic category:cs.CV cs.HC published:2015-10-13 summary:Automated recognition of facial expressions of emotions, and detection offacial action units (AUs), from videos depends critically on modeling of theirdynamics. These dynamics are characterized by changes in temporal phases(onset-apex-offset) and intensity of emotion expressions and AUs, theappearance of which may vary considerably among target subjects, making therecognition/detection task very challenging. The state-of-the-art LatentConditional Random Fields (L-CRF) framework allows one to efficiently encodethese dynamics through the latent states accounting for the temporalconsistency in emotion expression and ordinal relationships between itsintensity levels, these latent states are typically assumed to be eitherunordered (nominal) or fully ordered (ordinal). Yet, such an approach is oftentoo restrictive. For instance, in the case of AU detection, the goal is todiscriminate between the segments of an image sequence in which this AU isactive or inactive. While the sequence segments containing activation of thetarget AU may better be described using ordinal latent states, the inactivesegments better be described using unordered (nominal) latent states, as noassumption can be made about their underlying structure (since they can containeither neutral faces or activations of non-target AUs). To address this, wepropose the variable-state L-CRF (VSL-CRF) model that automatically selects theoptimal latent states for the target image sequence. To reduce the modeloverfitting either the nominal or ordinal latent states, we propose a novelgraph-Laplacian regularization of the latent states. Our experiments on threepublic expression databases show that the proposed model achieves bettergeneralization performance compared to traditional L-CRFs and other relatedstate-of-the-art models.
arxiv-13800-57 | On Equivalence of Martingale Tail Bounds and Deterministic Regret Inequalities | http://arxiv.org/pdf/1510.03925v1.pdf | author:Alexander Rakhlin, Karthik Sridharan category:math.PR cs.LG stat.ML published:2015-10-13 summary:We study an equivalence of (i) deterministic pathwise statements appearing inthe online learning literature (termed \emph{regret bounds}), (ii)high-probability tail bounds for the supremum of a collection of martingales(of a specific form arising from uniform laws of large numbers formartingales), and (iii) in-expectation bounds for the supremum. By virtue ofthe equivalence, we prove exponential tail bounds for norms of Banach spacevalued martingales via deterministic regret bounds for the online mirrordescent algorithm with an adaptive step size. We extend these results beyondthe linear structure of the Banach space: we define a notion of\emph{martingale type} for general classes of real-valued functions and showits equivalence (up to a logarithmic factor) to various sequential complexitiesof the class (in particular, the sequential Rademacher complexity and itsoffset version). For classes with the general martingale type 2, we exhibit afiner notion of variation that allows partial adaptation to the functionindexing the martingale. Our proof technique rests on sequential symmetrizationand on certifying the \emph{existence} of regret minimization strategies forcertain online prediction problems.
arxiv-13800-58 | The intrinsic value of HFO features as a biomarker of epileptic activity | http://arxiv.org/pdf/1510.03507v1.pdf | author:Stephen V. Gliske, Kevin R. Moon, William C. Stacey, Alfred O. Hero III category:q-bio.NC cs.LG stat.ML published:2015-10-13 summary:High frequency oscillations (HFOs) are a promising biomarker of epilepticbrain tissue and activity. HFOs additionally serve as a prototypical example ofchallenges in the analysis of discrete events in high-temporal resolution,intracranial EEG data. Two primary challenges are 1) dimensionality reduction,and 2) assessing feasibility of classification. Dimensionality reductionassumes that the data lie on a manifold with dimension less than that of thefeature space. However, previous HFO analyses have assumed a linear manifold,global across time, space (i.e. recording electrode/channel), and individualpatients. Instead, we assess both a) whether linear methods are appropriate andb) the consistency of the manifold across time, space, and patients. We alsoestimate bounds on the Bayes classification error to quantify the distinctionbetween two classes of HFOs (those occurring during seizures and thoseoccurring due to other processes). This analysis provides the foundation forfuture clinical use of HFO features and buides the analysis for other discreteevents, such as individual action potentials or multi-unit activity.
arxiv-13800-59 | Consistent Estimation of Low-Dimensional Latent Structure in High-Dimensional Data | http://arxiv.org/pdf/1510.03497v1.pdf | author:Xiongzhi Chen, John D. Storey category:stat.ML published:2015-10-13 summary:We consider the problem of extracting a low-dimensional, linear latentvariable structure from high-dimensional random variables. Specifically, weshow that under mild conditions and when this structure manifests itself as alinear space that spans the conditional means, it is possible to consistentlyrecover the structure using only information up to the second moments of theserandom variables. This finding, specialized to one-parameter exponentialfamilies whose variance function is quadratic in their means, allows for thederivation of an explicit estimator of such latent structure. This approachserves as a latent variable model estimator and as a tool for dimensionreduction for a high-dimensional matrix of data composed of many relatedvariables. Our theoretical results are verified by simulation studies and anapplication to genomic data.
arxiv-13800-60 | Adopting Robustness and Optimality in Fitting and Learning | http://arxiv.org/pdf/1510.03826v3.pdf | author:Zhiguang Wang, Tim Oates, James Lo category:cs.LG cs.NE math.OC published:2015-10-13 summary:We generalized a modified exponentialized estimator by pushing therobust-optimal (RO) index $\lambda$ to $-\infty$ for achieving robustness tooutliers by optimizing a quasi-Minimin function. The robustness is realized andcontrolled adaptively by the RO index without any predefined threshold.Optimality is guaranteed by expansion of the convexity region in the Hessianmatrix to largely avoid local optima. Detailed quantitative analysis on bothrobustness and optimality are provided. The results of proposed experiments onfitting tasks for three noisy non-convex functions and the digits recognitiontask on the MNIST dataset consolidate the conclusions.
arxiv-13800-61 | Elastic regularization in restricted Boltzmann machines: Dealing with $p\gg N$ | http://arxiv.org/pdf/1510.03623v2.pdf | author:Sai Zhang category:cs.LG published:2015-10-13 summary:Restricted Boltzmann machines (RBMs) are endowed with the universal power ofmodeling (binary) joint distributions. Meanwhile, as a result of theirconfining network structure, training RBMs confronts less difficulties(compared with more complicated models, e.g., Boltzmann machines) when dealingwith approximation and inference issues. However, in certain computationalbiology scenarios, such as the cancer data analysis, employing RBMs to modeldata features may lose its efficacy due to the "$p\gg N$" problem, in which thenumber of features/predictors is much larger than the sample size. The "$p\ggN$" problem puts the bias-variance trade-off in a more crucial place whendesigning statistical learning methods. In this manuscript, we try to addressthis problem by proposing a novel RBM model, called elastic restrictedBoltzmann machine (eRBM), which incorporates the elastic regularization terminto the likelihood/cost function. We provide several theoretical analysis onthe superiority of our model. Furthermore, attributed to the classiccontrastive divergence (CD) algorithm, eRBMs can be trained efficiently. Ournovel model is a promising method for future cancer data analysis.
arxiv-13800-62 | Bridge Correlational Neural Networks for Multilingual Multimodal Representation Learning | http://arxiv.org/pdf/1510.03519v2.pdf | author:Janarthanan Rajendran, Mitesh M. Khapra, Sarath Chandar, Balaraman Ravindran category:cs.CL published:2015-10-13 summary:Recently there has been a lot of interest in learning common representationsfor multiple views of data. These views could belong to different modalities orlanguages. Typically, such common representations are learned using a parallelcorpus between the two views (say, 1M images and their English captions). Inthis work, we address a real-world scenario where no direct parallel data isavailable between two views of interest (say, V1 and V2) but parallel data isavailable between each of these views and a pivot view (V3). We propose a modelfor learning a common representation for V1, V2 and V3 using only the paralleldata available between V1V3 and V2V3. The proposed model is generic and evenworks when there are n views of interest and only one pivot view which acts asa bridge between them. There are two specific downstream applications that wefocus on (i) Transfer learning between languages L1,L2,...,Ln using a pivotlanguage L and (ii) cross modal access between images and a language L1 using apivot language L2. We evaluate our model using two datasets : (i) publiclyavailable multilingual TED corpus and (ii) a new multilingual multimodaldataset created and released as a part of this work. On both these datasets,our model outperforms state of the art approaches.
arxiv-13800-63 | Improved Deep Learning Baselines for Ubuntu Corpus Dialogs | http://arxiv.org/pdf/1510.03753v2.pdf | author:Rudolf Kadlec, Martin Schmid, Jan Kleindienst category:cs.CL published:2015-10-13 summary:This paper presents results of our experiments for the next utterance rankingon the Ubuntu Dialog Corpus -- the largest publicly available multi-turn dialogcorpus. First, we use an in-house implementation of previously reported modelsto do an independent evaluation using the same data. Second, we evaluate theperformances of various LSTMs, Bi-LSTMs and CNNs on the dataset. Third, wecreate an ensemble by averaging predictions of multiple models. The ensemblefurther improves the performance and it achieves a state-of-the-art result forthe next utterance ranking on this dataset. Finally, we discuss our futureplans using this corpus.
arxiv-13800-64 | A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification | http://arxiv.org/pdf/1510.03820v4.pdf | author:Ye Zhang, Byron Wallace category:cs.CL cs.LG cs.NE published:2015-10-13 summary:Convolutional Neural Networks (CNNs) have recently achieved remarkably strongperformance on the practically important task of sentence classification (kim2014, kalchbrenner 2014, johnson 2014). However, these models requirepractitioners to specify an exact model architecture and set accompanyinghyperparameters, including the filter region size, regularization parameters,and so on. It is currently unknown how sensitive model performance is tochanges in these configurations for the task of sentence classification. Wethus conduct a sensitivity analysis of one-layer CNNs to explore the effect ofarchitecture components on model performance; our aim is to distinguish betweenimportant and comparatively inconsequential design decisions for sentenceclassification. We focus on one-layer CNNs (to the exclusion of more complexmodels) due to their comparative simplicity and strong empirical performance,which makes it a modern standard baseline method akin to Support Vector Machine(SVMs) and logistic regression. We derive practical advice from our extensiveempirical results for those interested in getting the most out of CNNs forsentence classification in real world settings.
arxiv-13800-65 | Deep convolutional neural networks for pedestrian detection | http://arxiv.org/pdf/1510.03608v5.pdf | author:Denis Tomè, Federico Monti, Luca Baroffio, Luca Bondi, Marco Tagliasacchi, Stefano Tubaro category:cs.CV published:2015-10-13 summary:Pedestrian detection is a popular research topic due to its paramountimportance for a number of applications, especially in the fields ofautomotive, surveillance and robotics. Despite the significant improvements,pedestrian detection is still an open challenge that calls for more and moreaccurate algorithms. In the last few years, deep learning and in particularconvolutional neural networks emerged as the state of the art in terms ofaccuracy for a number of computer vision tasks such as image classification,object detection and segmentation, often outperforming the previous goldstandards by a large margin. In this paper, we propose a pedestrian detectionsystem based on deep learning, adapting a general-purpose convolutional networkto the task at hand. By thoroughly analyzing and optimizing each step of thedetection pipeline we propose an architecture that outperforms traditionalmethods, achieving a task accuracy close to that of state-of-the-artapproaches, while requiring a low computational time. Finally, we tested thesystem on an NVIDIA Jetson TK1, a 192-core platform that is envisioned to be aforerunner computational brain of future self-driving cars.
arxiv-13800-66 | Hybrid Dialog State Tracker | http://arxiv.org/pdf/1510.03710v3.pdf | author:Miroslav Vodolán, Rudolf Kadlec, Jan Kleindienst category:cs.CL published:2015-10-13 summary:This paper presents a hybrid dialog state tracker that combines a rule basedand a machine learning based approach to belief state tracking. Therefore, wecall it a hybrid tracker. The machine learning in our tracker is realized by aLong Short Term Memory (LSTM) network. To our knowledge, our hybrid trackersets a new state-of-the-art result for the Dialog State Tracking Challenge(DSTC) 2 dataset when the system uses only live SLU as its input.
arxiv-13800-67 | On Correcting Inputs: Inverse Optimization for Online Structured Prediction | http://arxiv.org/pdf/1510.03130v1.pdf | author:Hal Daumé III, Samir Khuller, Manish Purohit, Gregory Sanders category:cs.LG published:2015-10-12 summary:Algorithm designers typically assume that the input data is correct, and thenproceed to find "optimal" or "sub-optimal" solutions using this input data.However this assumption of correct data does not always hold in practice,especially in the context of online learning systems where the objective is tolearn appropriate feature weights given some training samples. Such scenariosnecessitate the study of inverse optimization problems where one is given aninput instance as well as a desired output and the task is to adjust the inputdata so that the given output is indeed optimal. Motivated by learningstructured prediction models, in this paper we consider inverse optimizationwith a margin, i.e., we require the given output to be better than all otherfeasible outputs by a desired margin. We consider such inverse optimizationproblems for maximum weight matroid basis, matroid intersection, perfectmatchings, minimum cost maximum flows, and shortest paths and derive the firstknown results for such problems with a non-zero margin. The effectiveness ofthese algorithmic approaches to online learning for structured prediction isalso discussed.
arxiv-13800-68 | Towards Meaningful Maps of Polish Case Law | http://arxiv.org/pdf/1510.03421v2.pdf | author:Michal Jungiewicz, Michał Łopuszyński category:cs.CL published:2015-10-12 summary:In this work, we analyze the utility of two dimensional document maps forexploratory analysis of Polish case law. We start by comparing two methods ofgenerating such visualizations. First is based on linear principal componentanalysis (PCA). Second makes use of the modern nonlinear t-DistributedStochastic Neighbor Embedding method (t-SNE). We apply both PCA and t-SNE to acorpus of judgments from different courts in Poland. It emerges that t-SNEprovides better, more interpretable results than PCA. As a next test, we applyt-SNE to randomly selected sample of common court judgments corresponding todifferent keywords. We show that t-SNE, in this case, reveals hidden topicalstructure of the documents related to keyword,,pension". In conclusion, we findthat the t-SNE method could be a promising tool to facilitate the exploitativeanalysis of legal texts, e.g., by complementing search or browse functionalityin legal databases.
arxiv-13800-69 | Interactive multiclass segmentation using superpixel classification | http://arxiv.org/pdf/1510.03199v1.pdf | author:Bérengère Mathieu, Alain Crouzil, Jean-Baptiste Puel category:cs.CV published:2015-10-12 summary:This paper adresses the problem of interactive multiclass segmentation. Wepropose a fast and efficient new interactive segmentation method calledSuperpixel Classification-based Interactive Segmentation (SCIS). From a fewstrokes drawn by a human user over an image, this method extracts relevantsemantic objects. To get a fast calculation and an accurate segmentation, SCISuses superpixel over-segmentation and support vector machine classification. Inthis paper, we demonstrate that SCIS significantly outperfoms competingalgorithms by evaluating its performances on the reference benchmarks ofMcGuinness and Santner.
arxiv-13800-70 | Using Anatomical Markers for Left Ventricular Segmentation of Long Axis Ultrasound Images | http://arxiv.org/pdf/1510.03250v1.pdf | author:Yael Petrank, Nahum Smirin, Yossi Tsadok, Zvi Friedman, Peter Lysiansky, Dan Adam category:cs.CV published:2015-10-12 summary:Left ventricular segmentation is essential for measuring left ventricularfunction indices. Segmentation of one or several images requires an initialguess of the contour. It is hypothesized here that creating an initial guess byfirst detecting anatomical markers, would lead to correct detection of theendocardium. The first step of the algorithm presented here includes automaticdetection of the mitral valve. Next, the apex is detected in the same frame.The valve is then tracked throughout the cardiac cycle. Contours passing fromthe apex to each valve corner are then found using a dynamic programmingalgorithm. The resulting contour is used as an input to an active contouralgorithm. The algorithm was tested on 21 long axis ultrasound clips and showedgood agreement with manually traced contours. Thus, this study demonstratesthat detection of anatomic markers leads to a reliable initial guess of theleft ventricle border.
arxiv-13800-71 | On the Robustness of Regularized Pairwise Learning Methods Based on Kernels | http://arxiv.org/pdf/1510.03267v1.pdf | author:Andreas Christmann, Ding-Xuan Zhou category:math.ST math.FA stat.ML stat.TH published:2015-10-12 summary:Regularized empirical risk minimization including support vector machinesplays an important role in machine learning theory. In this paper regularizedpairwise learning (RPL) methods based on kernels will be investigated. Oneexample is regularized minimization of the error entropy loss which hasrecently attracted quite some interest from the viewpoint of consistency andlearning rates. This paper shows that such RPL methods have additionally goodstatistical robustness properties, if the loss function and the kernel arechosen appropriately. We treat two cases of particular interest: (i) a boundedand non-convex loss function and (ii) an unbounded convex loss functionsatisfying a certain Lipschitz type condition.
arxiv-13800-72 | Penalized estimation in large-scale generalized linear array models | http://arxiv.org/pdf/1510.03298v1.pdf | author:Adam Lund, Martin Vincent, Niels Richard Hansen category:stat.CO stat.ML published:2015-10-12 summary:Large-scale generalized linear array models (GLAMs) can be challenging tofit. Computation and storage of its tensor product design matrix can beimpossible due to time and memory constraints, and previously considered designmatrix free algorithms do not scale well with the dimension of the parametervector. A new design matrix free algorithm is proposed for computing thepenalized maximum likelihood estimate for GLAMs, which, in particular, handlesnondifferentiable penalty functions. The proposed algorithm is implemented andavailable via the R package \verb+glamlasso+. It combines several ideas --previously considered separately -- to obtain sparse estimates while at thesame time efficiently exploiting the GLAM structure. In this paper theconvergence of the algorithm is treated and the performance of itsimplementation is investigated and compared to that of \verb+glmnet+ onsimulated as well as real data. It is shown that the computation time for
arxiv-13800-73 | The Inductive Constraint Programming Loop | http://arxiv.org/pdf/1510.03317v1.pdf | author:Christian Bessiere, Luc De Raedt, Tias Guns, Lars Kotthoff, Mirco Nanni, Siegfried Nijssen, Barry O'Sullivan, Anastasia Paparrizou, Dino Pedreschi, Helmut Simonis category:cs.AI cs.LG published:2015-10-12 summary:Constraint programming is used for a variety of real-world optimisationproblems, such as planning, scheduling and resource allocation problems. At thesame time, one continuously gathers vast amounts of data about these problems.Current constraint programming software does not exploit such data to updateschedules, resources and plans. We propose a new framework, that we call theInductive Constraint Programming loop. In this approach data is gathered andanalyzed systematically, in order to dynamically revise and adapt constraintsand optimization criteria. Inductive Constraint Programming aims at bridgingthe gap between the areas of data mining and machine learning on the one hand,and constraint programming on the other hand.
arxiv-13800-74 | Context-Aware Bandits | http://arxiv.org/pdf/1510.03164v2.pdf | author:Shuai Li, Alexandros Karatzoglou category:cs.LG cs.AI stat.ML published:2015-10-12 summary:In this paper, we present a simple and efficient Context-Aware Bandit (CAB)algorithm. With CAB we attempt to craft a bandit algorithm that can capturecollaborative effects and that can be easily deployed in a real-worldrecommendation system, where the multi-armed bandits have been shown to performwell in particular with respect to the cold-start problem. CAB utilizes acontext-aware clustering technique augmenting exploration-exploitationstrategies. CAB dynamically clusters the users based on the content universeunder consideration. We provide a theoretical analysis in the standardstochastic multi-armed bandits setting. We demonstrate the efficiency of ourapproach on production and real-world datasets, showing the scalability and,more importantly, the significantly increased prediction performance againstseveral existing state-of-the-art methods.
arxiv-13800-75 | Toward a Better Understanding of Leaderboard | http://arxiv.org/pdf/1510.03349v1.pdf | author:Wenjie Zheng category:stat.ML cs.LG stat.AP published:2015-10-12 summary:The leaderboard in machine learning competitions is a tool to show theperformance of various participants and to compare them. However, theleaderboard quickly becomes no longer accurate, due to hack or overfitting.This article gives two advices to avoid this. It also points out that theLadder leaderboard successfully prevents this with $\tilde{O}(\epsilon^{-3})$samples in the validation set.
arxiv-13800-76 | Fast detection of multiple objects in traffic scenes with a common detection framework | http://arxiv.org/pdf/1510.03125v1.pdf | author:Qichang Hu, Sakrapee Paisitkriangkrai, Chunhua Shen, Anton van den Hengel, Fatih Porikli category:cs.CV published:2015-10-12 summary:Traffic scene perception (TSP) aims to real-time extract accurate on-roadenvironment information, which in- volves three phases: detection of objects ofinterest, recognition of detected objects, and tracking of objects in motion.Since recognition and tracking often rely on the results from detection, theability to detect objects of interest effectively plays a crucial role in TSP.In this paper, we focus on three important classes of objects: traffic signs,cars, and cyclists. We propose to detect all the three important objects in asingle learning based detection framework. The proposed framework consists of adense feature extractor and detectors of three important classes. Once thedense features have been extracted, these features are shared with alldetectors. The advantage of using one common framework is that the detectionspeed is much faster, since all dense features need only to be evaluated oncein the testing phase. In contrast, most previous works have designed specificdetectors using different features for each of these objects. To enhance thefeature robustness to noises and image deformations, we introduce spatiallypooled features as a part of aggregated channel features. In order to furtherimprove the generalization performance, we propose an object subcategorizationmethod as a means of capturing intra-class variation of objects. Weexperimentally demonstrate the effectiveness and efficiency of the proposedframework in three detection applications: traffic sign detection, cardetection, and cyclist detection. The proposed framework achieves thecompetitive performance with state-of- the-art approaches on several benchmarkdatasets.
arxiv-13800-77 | Asymptotic Logical Uncertainty and The Benford Test | http://arxiv.org/pdf/1510.03370v1.pdf | author:Scott Garrabrant, Siddharth Bhaskar, Abram Demski, Joanna Garrabrant, George Koleszarik, Evan Lloyd category:cs.LG cs.AI F.4.1 published:2015-10-12 summary:We give an algorithm A which assigns probabilities to logical sentences. Forany simple infinite sequence of sentences whose truth-values appearindistinguishable from a biased coin that outputs "true" with probability p, wehave that the sequence of probabilities that A assigns to these sentencesconverges to p.
arxiv-13800-78 | VB calibration to improve the interface between phone recognizer and i-vector extractor | http://arxiv.org/pdf/1510.03203v2.pdf | author:Niko Brümmer category:stat.ML cs.LG published:2015-10-12 summary:The EM training algorithm of the classical i-vector extractor is oftenincorrectly described as a maximum-likelihood method. The i-vector model ishowever intractable: the likelihood itself and the hidden-variable posteriorsneeded for the EM algorithm cannot be computed in closed form. We show herethat the classical i-vector extractor recipe is actually a mean-fieldvariational Bayes (VB) recipe. This theoretical VB interpretation turns out to be of further use, because italso offers an interpretation of the newer phonetic i-vector extractor recipe,thereby unifying the two flavours of extractor. More importantly, the VB interpretation is also practically useful: itsuggests ways of modifying existing i-vector extractors to make them moreaccurate. In particular, in existing methods, the approximate VB posterior forthe GMM states is fixed, while only the parameters of the generative model areadapted. Here we explore the possibility of also mildly adjusting (calibrating)those posteriors, so that they better fit the generative model.
arxiv-13800-79 | Text-Attentional Convolutional Neural Networks for Scene Text Detection | http://arxiv.org/pdf/1510.03283v2.pdf | author:Tong He, Weilin Huang, Yu Qiao, Jian Yao category:cs.CV published:2015-10-12 summary:Recent deep learning models have demonstrated strong capabilities forclassifying text and non-text components in natural images. They extract ahigh-level feature computed globally from a whole image component (patch),where the cluttered background information may dominate true text features inthe deep representation. This leads to less discriminative power and poorerrobustness. In this work, we present a new system for scene text detection byproposing a novel Text-Attentional Convolutional Neural Network (Text-CNN) thatparticularly focuses on extracting text-related regions and features from theimage components. We develop a new learning mechanism to train the Text-CNNwith multi-level and rich supervised information, including text region mask,character label, and binary text/nontext information. The rich supervisioninformation enables the Text-CNN with a strong capability for discriminatingambiguous texts, and also increases its robustness against complicatedbackground components. The training process is formulated as a multi-tasklearning problem, where low-level supervised information greatly facilitatesmain task of text/non-text classification. In addition, a powerful low-leveldetector called Contrast- Enhancement Maximally Stable Extremal Regions(CE-MSERs) is developed, which extends the widely-used MSERs by enhancingintensity contrast between text patterns and background. This allows it todetect highly challenging text patterns, resulting in a higher recall. Ourapproach achieved promising results on the ICDAR 2013 dataset, with a F-measureof 0.82, improving the state-of-the-art results substantially.
arxiv-13800-80 | Evaluating Real-time Anomaly Detection Algorithms - the Numenta Anomaly Benchmark | http://arxiv.org/pdf/1510.03336v4.pdf | author:Alexander Lavin, Subutai Ahmad category:cs.AI cs.LG published:2015-10-12 summary:Much of the world's data is streaming, time-series data, where anomalies givesignificant information in critical situations; examples abound in domains suchas finance, IT, security, medical, and energy. Yet detecting anomalies instreaming data is a difficult task, requiring detectors to process data inreal-time, not batches, and learn while simultaneously making predictions.There are no benchmarks to adequately test and score the efficacy of real-timeanomaly detectors. Here we propose the Numenta Anomaly Benchmark (NAB), whichattempts to provide a controlled and repeatable environment of open-sourcetools to test and measure anomaly detection algorithms on streaming data. Theperfect detector would detect all anomalies as soon as possible, trigger nofalse alarms, work with real-world time-series data across a variety ofdomains, and automatically adapt to changing statistics. Rewarding thesecharacteristics is formalized in NAB, using a scoring algorithm designed forstreaming data. NAB evaluates detectors on a benchmark dataset with labeled,real-world time-series data. We present these components, and give results andanalyses for several open source, commercially-used algorithms. The goal forNAB is to provide a standard, open source framework with which the researchcommunity can compare and evaluate different algorithms for detecting anomaliesin streaming data.
arxiv-13800-81 | Kernel Sequential Monte Carlo | http://arxiv.org/pdf/1510.03105v3.pdf | author:Ingmar Schuster, Heiko Strathmann, Brooks Paige, Dino Sejdinovic category:stat.CO stat.ML published:2015-10-11 summary:Bayesian posterior inference with Monte Carlo methods has a fundamental rolein statistics and probabilistic machine learning. Target posteriordistributions arising in increasingly complex models often exhibit high degreesof nonlinearity and multimodality and pose substantial challenges totraditional samplers. We propose the Kernel Sequential Monte Carlo (KSMC) framework for buildingemulator models of the current particle system in a Reproducing Kernel HilbertSpace and use the emulator's geometry to inform local proposals. KSMC isapplicable when gradients are unknown or prohibitively expensive and inheritsthe superior performance of SMC on multi-modal targets and its ability toestimate model evidence. Strengths of the proposed methodology are demonstratedon a series of challenging synthetic and real-world examples.
arxiv-13800-82 | ParallelPC: an R package for efficient constraint based causal exploration | http://arxiv.org/pdf/1510.03042v1.pdf | author:Thuc Duy Le, Tao Hoang, Jiuyong Li, Lin Liu, Shu Hu category:cs.AI stat.ML published:2015-10-11 summary:Discovering causal relationships from data is the ultimate goal of manyresearch areas. Constraint based causal exploration algorithms, such as PC,FCI, RFCI, PC-simple, IDA and Joint-IDA have achieved significant progress andhave many applications. A common problem with these methods is the highcomputational complexity, which hinders their applications in real world highdimensional datasets, e.g gene expression datasets. In this paper, we presentan R package, ParallelPC, that includes the parallelised versions of thesecausal exploration algorithms. The parallelised algorithms help speed up theprocedure of experimenting big datasets and reduce the memory used when runningthe algorithms. The package is not only suitable for super-computers orclusters, but also convenient for researchers using personal computers withmulti core CPUs. Our experiment results on real world datasets show that usingthe parallelised algorithms it is now practical to explore causal relationshipsin high dimensional datasets with thousands of variables in a single multicorecomputer. ParallelPC is available in CRAN repository athttps://cran.rproject.org/web/packages/ParallelPC/index.html.
arxiv-13800-83 | Neural Networks with Few Multiplications | http://arxiv.org/pdf/1510.03009v3.pdf | author:Zhouhan Lin, Matthieu Courbariaux, Roland Memisevic, Yoshua Bengio category:cs.LG cs.NE published:2015-10-11 summary:For most deep learning algorithms training is notoriously time consuming.Since most of the computation in training neural networks is typically spent onfloating point multiplications, we investigate an approach to training thateliminates the need for most of these. Our method consists of two parts: Firstwe stochastically binarize weights to convert multiplications involved incomputing hidden states to sign changes. Second, while back-propagating errorderivatives, in addition to binarizing the weights, we quantize therepresentations at each layer to convert the remaining multiplications intobinary shifts. Experimental results across 3 popular datasets (MNIST, CIFAR10,SVHN) show that this approach not only does not hurt classification performancebut can result in even better performance than standard stochastic gradientdescent training, paving the way to fast, hardware-friendly training of neuralnetworks.
arxiv-13800-84 | Textual Analysis for Studying Chinese Historical Documents and Literary Novels | http://arxiv.org/pdf/1510.03021v1.pdf | author:Chao-Lin Liu, Guan-Tao Jin, Hongsu Wang, Qing-Feng Liu, Wen-Huei Cheng, Wei-Yun Chiu, Richard Tzong-Han Tsai, Yu-Chun Wang category:cs.CL cs.DL published:2015-10-11 summary:We analyzed historical and literary documents in Chinese to gain insightsinto research issues, and overview our studies which utilized four differentsources of text materials in this paper. We investigated the history ofconcepts and transliterated words in China with the Database for the Study ofModern China Thought and Literature, which contains historical documents aboutChina between 1830 and 1930. We also attempted to disambiguate names that wereshared by multiple government officers who served between 618 and 1912 and wererecorded in Chinese local gazetteers. To showcase the potentials and challengesof computer-assisted analysis of Chinese literatures, we explored someinteresting yet non-trivial questions about two of the Four Great ClassicalNovels of China: (1) Which monsters attempted to consume the Buddhist monkXuanzang in the Journey to the West (JTTW), which was published in the 16thcentury, (2) Which was the most powerful monster in JTTW, and (3) Which majorrole smiled the most in the Dream of the Red Chamber, which was published inthe 18th century. Similar approaches can be applied to the analysis and studyof modern documents, such as the newspaper articles published about the 228incident that occurred in 1947 in Taiwan.
arxiv-13800-85 | A Diversity-Promoting Objective Function for Neural Conversation Models | http://arxiv.org/pdf/1510.03055v2.pdf | author:Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, Bill Dolan category:cs.CL published:2015-10-11 summary:Sequence-to-sequence neural network models for generation of conversationalresponses tend to generate safe, commonplace responses (e.g., \textit{I don'tknow}) regardless of the input. We suggest that the traditional objectivefunction, i.e., the likelihood of output (responses) given input (messages) isunsuited to response generation tasks. Instead we propose using Maximum MutualInformation (MMI) as objective function in neural models. Experimental resultsdemonstrate that the proposed objective function produces more diverse,interesting, and appropriate responses, yielding substantive gains in \bleuscores on two conversational datasets.
arxiv-13800-86 | Evaluation of Joint Multi-Instance Multi-Label Learning For Breast Cancer Diagnosis | http://arxiv.org/pdf/1510.02942v1.pdf | author:Baris Gecer, Ozge Yalcinkaya, Onur Tasar, Selim Aksoy category:cs.CV cs.LG published:2015-10-10 summary:Multi-instance multi-label (MIML) learning is a challenging problem in manyaspects. Such learning approaches might be useful for many medical diagnosisapplications including breast cancer detection and classification. In thisstudy subset of digiPATH dataset (whole slide digital breast cancerhistopathology images) are used for training and evaluation of sixstate-of-the-art MIML methods. At the end, performance comparison of these approaches are given by means ofeffective evaluation metrics. It is shown that MIML-kNN achieve the bestperformance that is %65.3 average precision, where most of other methods attainacceptable results as well.
arxiv-13800-87 | Fast and Accurate Poisson Denoising with Optimized Nonlinear Diffusion | http://arxiv.org/pdf/1510.02930v1.pdf | author:Wensen Feng, Yunjin Chen category:cs.CV published:2015-10-10 summary:The degradation of the acquired signal by Poisson noise is a common problemfor various imaging applications, such as medical imaging, night vision andmicroscopy. Up to now, many state-of-the-art Poisson denoising techniquesmainly concentrate on achieving utmost performance, with little considerationfor the computation efficiency. Therefore, in this study we aim to propose anefficient Poisson denoising model with both high computational efficiency andrecovery quality. To this end, we exploit the newly-developed trainablenonlinear reaction diffusion model which has proven an extremely fast imagerestoration approach with performance surpassing recent state-of-the-arts. Weretrain the model parameters, including the linear filters and influencefunctions by taking into account the Poisson noise statistics, and end up withan optimized nonlinear diffusion model specialized for Poisson denoising. Thetrained model provides strongly competitive results against state-of-the-artapproaches, meanwhile bearing the properties of simple structure and highefficiency. Furthermore, our proposed model comes along with an additionaladvantage, that the diffusion process is well-suited for parallel computationon GPUs. For images of size $512 \times 512$, our GPU implementation takes lessthan 0.1 seconds to produce state-of-the-art Poisson denoising performance.
arxiv-13800-88 | DeepFix: A Fully Convolutional Neural Network for predicting Human Eye Fixations | http://arxiv.org/pdf/1510.02927v1.pdf | author:Srinivas S. S. Kruthiventi, Kumar Ayush, R. Venkatesh Babu category:cs.CV published:2015-10-10 summary:Understanding and predicting the human visual attentional mechanism is anactive area of research in the fields of neuroscience and computer vision. Inthis work, we propose DeepFix, a first-of-its-kind fully convolutional neuralnetwork for accurate saliency prediction. Unlike classical works whichcharacterize the saliency map using various hand-crafted features, our modelautomatically learns features in a hierarchical fashion and predicts saliencymap in an end-to-end manner. DeepFix is designed to capture semantics atmultiple scales while taking global context into account using network layerswith very large receptive fields. Generally, fully convolutional nets arespatially invariant which prevents them from modeling location dependentpatterns (e.g. centre-bias). Our network overcomes this limitation byincorporating a novel Location Biased Convolutional layer. We evaluate ourmodel on two challenging eye fixation datasets -- MIT300, CAT2000 and show thatit outperforms other recent approaches by a significant margin.
arxiv-13800-89 | On 1-Laplacian Elliptic Equations Modeling Magnetic Resonance Image Rician Denoising | http://arxiv.org/pdf/1510.02923v1.pdf | author:Adrian Martin, Emanuele Schiavi, Sergio Segura de Leon category:math.AP cs.CV math.NA published:2015-10-10 summary:Modeling magnitude Magnetic Resonance Images (MRI) rician denoising in aBayesian or generalized Tikhonov framework using Total Variation (TV) leadsnaturally to the consideration of nonlinear elliptic equations. These involvethe so called $1$-Laplacian operator and special care is needed to properlyformulate the problem. The rician statistics of the data are introduced througha singular equation with a reaction term defined in terms of modified firstorder Bessel functions. An existence theory is provided here together withother qualitative properties of the solutions. Remarkably, each positive globalminimum of the associated functional is one of such solutions. Moreover, wedirectly solve this non--smooth non--convex minimization problem using aconvergent Proximal Point Algorithm. Numerical results based on synthetic andreal MRI demonstrate a better performance of the proposed method when comparedto previous TV based models for rician denoising which regularize or convexifythe problem. Finally, an application on real Diffusion Tensor Images, astrongly affected by rician noise MRI modality, is presented and discussed.
arxiv-13800-90 | Spatial Semantic Regularisation for Large Scale Object Detection | http://arxiv.org/pdf/1510.02949v1.pdf | author:Damian Mrowca, Marcus Rohrbach, Judy Hoffman, Ronghang Hu, Kate Saenko, Trevor Darrell category:cs.CV published:2015-10-10 summary:Large scale object detection with thousands of classes introduces the problemof many contradicting false positive detections, which have to be suppressed.Class-independent non-maximum suppression has traditionally been used for thisstep, but it does not scale well as the number of classes grows. Traditionalnon-maximum suppression does not consider label- and instance-levelrelationships nor does it allow an exploitation of the spatial layout ofdetection proposals. We propose a new multi-class spatial semanticregularisation method based on affinity propagation clustering, whichsimultaneously optimises across all categories and all proposed locations inthe image, to improve both the localisation and categorisation of selecteddetection proposals. Constraints are shared across the labels through thesemantic WordNet hierarchy. Our approach proves to be especially useful inlarge scale settings with thousands of classes, where spatial and semanticinteractions are very frequent and only weakly supervised detectors can bebuilt due to a lack of bounding box annotations. Detection experiments areconducted on the ImageNet and COCO dataset, and in settings with thousands ofdetected categories. Our method provides a significant precision improvement byreducing false positives, while simultaneously improving the recall.
arxiv-13800-91 | Temporal Dynamic Appearance Modeling for Online Multi-Person Tracking | http://arxiv.org/pdf/1510.02906v1.pdf | author:Min Yang, Yunde Jia category:cs.CV published:2015-10-10 summary:Robust online multi-person tracking requires the correct associations ofonline detection responses with existing trajectories. We address this problemby developing a novel appearance modeling approach to provide accurateappearance affinities to guide data association. In contrast to most existingalgorithms that only consider the spatial structure of human appearances, weexploit the temporal dynamic characteristics within temporal appearancesequences to discriminate different persons. The temporal dynamic makes asufficient complement to the spatial structure of varying appearances in thefeature space, which significantly improves the affinity measurement betweentrajectories and detections. We propose a feature selection algorithm todescribe the appearance variations with mid-level semantic features, anddemonstrate its usefulness in terms of temporal dynamic appearance modeling.Moreover, the appearance model is learned incrementally by alternativelyevaluating newly-observed appearances and adjusting the model parameters to besuitable for online tracking. Reliable tracking of multiple persons in complexscenes is achieved by incorporating the learned model into an onlinetracking-by-detection framework. Our experiments on the challenging benchmarkMOTChallenge 2015 demonstrate that our method outperforms the state-of-the-artmulti-person tracking algorithms.
arxiv-13800-92 | TagBook: A Semantic Video Representation without Supervision for Event Detection | http://arxiv.org/pdf/1510.02899v2.pdf | author:Masoud Mazloom, Xirong Li, Cees G. M. Snoek category:cs.CV cs.MM published:2015-10-10 summary:We consider the problem of event detection in video for scenarios where onlyfew, or even zero examples are available for training. For this challengingsetting, the prevailing solutions in the literature rely on a semantic videorepresentation obtained from thousands of pre-trained concept detectors.Different from existing work, we propose a new semantic video representationthat is based on freely available social tagged videos only, without the needfor training any intermediate concept detectors. We introduce a simplealgorithm that propagates tags from a video's nearest neighbors, similar inspirit to the ones used for image retrieval, but redesign it for video eventdetection by including video source set refinement and varying the video tagassignment. We call our approach TagBook and study its construction,descriptiveness and detection performance on the TRECVID 2013 and 2014multimedia event detection datasets and the Columbia Consumer Video dataset.Despite its simple nature, the proposed TagBook video representation isremarkably effective for few-example and zero-example event detection, evenoutperforming very recent state-of-the-art alternatives building on supervisedrepresentations.
arxiv-13800-93 | Survey on Feature Selection | http://arxiv.org/pdf/1510.02892v1.pdf | author:Tarek Amr Abdallah, Beatriz de La Iglesia category:cs.LG published:2015-10-10 summary:Feature selection plays an important role in the data mining process. It isneeded to deal with the excessive number of features, which can become acomputational burden on the learning algorithms. It is also necessary, evenwhen computational resources are not scarce, since it improves the accuracy ofthe machine learning tasks, as we will see in the upcoming sections. In thisreview, we discuss the different feature selection approaches, and the relationbetween them and the various machine learning algorithms.
arxiv-13800-94 | Learn to Evaluate Image Perceptual Quality Blindly from Statistics of Self-similarity | http://arxiv.org/pdf/1510.02884v1.pdf | author:Wufeng Xue, Xuanqin Mou, Lei Zhang category:cs.CV published:2015-10-10 summary:Among the various image quality assessment (IQA) tasks, blind IQA (BIQA) isparticularly challenging due to the absence of knowledge about the referenceimage and distortion type. Features based on natural scene statistics (NSS)have been successfully used in BIQA, while the quality relevance of the featureplays an essential role to the quality prediction performance. Motivated by thefact that the early processing stage in human visual system aims to remove thesignal redundancies for efficient visual coding, we propose a simple but veryeffective BIQA method by computing the statistics of self-similarity (SOS) inan image. Specifically, we calculate the inter-scale similarity and intra-scalesimilarity of the distorted image, extract the SOS features from thesesimilarities, and learn a regression model to map the SOS features to thesubjective quality score. Extensive experiments demonstrate very competitivequality prediction performance and generalization ability of the proposed SOSbased BIQA method.
arxiv-13800-95 | TSEB: More Efficient Thompson Sampling for Policy Learning | http://arxiv.org/pdf/1510.02874v1.pdf | author:P. Prasanna, Sarath Chandar, Balaraman Ravindran category:cs.LG published:2015-10-10 summary:In model-based solution approaches to the problem of learning in an unknownenvironment, exploring to learn the model parameters takes a toll on theregret. The optimal performance with respect to regret or PAC bounds isachievable, if the algorithm exploits with respect to reward or explores withrespect to the model parameters, respectively. In this paper, we propose TSEB,a Thompson Sampling based algorithm with adaptive exploration bonus that aimsto solve the problem with tighter PAC guarantees, while being cautious on theregret as well. The proposed approach maintains distributions over the modelparameters which are successively refined with more experience. At any giventime, the agent solves a model sampled from this distribution, and the sampledreward distribution is skewed by an exploration bonus in order to generate moreinformative exploration. The policy by solving is then used for generating moreexperience that helps in updating the posterior over the model parameters. Weprovide a detailed analysis of the PAC guarantees, and convergence of theproposed approach. We show that our adaptive exploration bonus encourages theadditional exploration required for better PAC bounds on the algorithm. Weprovide empirical analysis on two different simulated domains.
arxiv-13800-96 | Optimal Piecewise Linear Function Approximation for GPU-based Applications | http://arxiv.org/pdf/1510.02975v1.pdf | author:Daniel Berjón, Guillermo Gallego, Carlos Cuevas, Francisco Morán, Narciso García category:math.OC cs.CV cs.DC cs.NA cs.SY published:2015-10-10 summary:Many computer vision and human-computer interaction applications developed inrecent years need evaluating complex and continuous mathematical functions asan essential step toward proper operation. However, rigorous evaluation of thiskind of functions often implies a very high computational cost, unacceptable inreal-time applications. To alleviate this problem, functions are commonlyapproximated by simpler piecewise-polynomial representations. Following thisidea, we propose a novel, efficient, and practical technique to evaluatecomplex and continuous functions using a nearly optimal design of two types ofpiecewise linear approximations in the case of a large budget of evaluationsubintervals. To this end, we develop a thorough error analysis that yieldsasymptotically tight bounds to accurately quantify the approximationperformance of both representations. It provides an improvement upon previouserror estimates and allows the user to control the trade-off between theapproximation error and the number of evaluation subintervals. To guaranteereal-time operation, the method is suitable for, but not limited to, anefficient implementation in modern Graphics Processing Units (GPUs), where itoutperforms previous alternative approaches by exploiting the fixed-functioninterpolation routines present in their texture units. The proposed techniqueis a perfect match for any application requiring the evaluation of continuousfunctions, we have measured in detail its quality and efficiency on severalfunctions, and, in particular, the Gaussian function because it is extensivelyused in many areas of computer vision and cybernetics, and it is expensive toevaluate.
arxiv-13800-97 | Do Deep Neural Networks Learn Facial Action Units When Doing Expression Recognition? | http://arxiv.org/pdf/1510.02969v1.pdf | author:Pooya Khorrami, Tom Le Paine, Thomas S. Huang category:cs.CV cs.LG cs.NE published:2015-10-10 summary:Despite being the appearance-based classifier of choice in recent years,relatively few works have examined how much convolutional neural networks(CNNs) can improve performance on accepted expression recognition benchmarksand, more importantly, examine what it is they actually learn. In this work,not only do we show that CNNs can achieve strong performance, but we alsointroduce an approach to decipher which portions of the face influence theCNN's predictions. First, we train a zero-bias CNN on facial expression dataand achieve, to our knowledge, state-of-the-art performance on two expressionrecognition benchmarks: the extended Cohn-Kanade (CK+) dataset and the TorontoFace Dataset (TFD). We then qualitatively analyze the network by visualizingthe spatial patterns that maximally excite different neurons in theconvolutional layers and show how they resemble Facial Action Units (FAUs).Finally, we use the FAU labels provided in the CK+ dataset to verify that theFAUs observed in our filter visualizations indeed align with the subject'sfacial movements.
arxiv-13800-98 | ADAAPT: A Deep Architecture for Adaptive Policy Transfer from Multiple Sources | http://arxiv.org/pdf/1510.02879v2.pdf | author:Janarthanan Rajendran, P Prasanna, Balaraman Ravindran, Mitesh M. Khapra category:cs.AI cs.LG published:2015-10-10 summary:The ability to transfer knowledge from learnt source tasks to a new targettask can be very useful in speeding up the learning process of a ReinforcementLearning agent. This has been receiving a lot of attention, but the applicationof transfer poses two serious challenges which have not been adequatelyaddressed in the past. First, the agent should be able to avoid negativetransfer, which happens when the transfer hampers or slows down the learninginstead of speeding it up. Secondly, the agent should be able to do selectivetransfer which is the ability to select and transfer from different andmultiple source tasks for different parts of the state space of the targettask. We propose ADAAPT: A Deep Architecture for Adaptive Policy Transfer,which addresses these challenges. We test ADAAPT using two differentinstantiations: One as ADAAPTive REINFORCE algorithm for direct policy searchand another as ADAAPTive Actor-Critic where the actor uses ADAAPT. Empiricalevaluations on simulated domains show that ADAAPT can be effectively used forpolicy transfer from multiple source MDPs sharing the same state and actionspace.
arxiv-13800-99 | Tract Orientation and Angular Dispersion Deviation Indicator (TOADDI): A framework for single-subject analysis in diffusion tensor imaging | http://arxiv.org/pdf/1510.02934v2.pdf | author:Cheng Guan Koay, Ping-Hong Yeh, John M. Ollinger, M. Okan İrfanoğlu, Carlo Pierpaoli, Peter J. Basser, Terrence R. Oakes, Gerard Riedy category:physics.med-ph cs.CV stat.AP stat.CO stat.ME published:2015-10-10 summary:The purpose of this work is to develop a framework for single-subjectanalysis of diffusion tensor imaging (DTI) data. This framework (termed TOADDI)is capable of testing whether an individual tract as represented by the majoreigenvector of the diffusion tensor and its corresponding angular dispersionare significantly different from a group of tracts on a voxel-by-voxel basis.This work develops two complementary statistical tests based on the ellipticalcone of uncertainty (COU), which is a model of uncertainty or dispersion of themajor eigenvector of the diffusion tensor. The orientation deviation testexamines whether the major eigenvector from a single subject is within theaverage elliptical COU formed by a collection of elliptical COUs. The shapedeviation test is based on the two-tailed Wilcoxon-Mann-Whitney two-sample testbetween the normalized shape measures (area and circumference) of theelliptical cones of uncertainty of the single subject against a group ofcontrols. The False Discovery Rate (FDR) and False Non-discovery Rate (FNR)were incorporated in the orientation deviation test. The shape deviation testuses FDR only. TOADDI was found to be numerically accurate and statisticallyeffective. Clinical data from two Traumatic Brain Injury (TBI) patients and onenon-TBI subject were tested against the data obtained from a group of 45non-TBI controls to illustrate the application of the proposed framework insingle-subject analysis. The frontal portion of the superior longitudinalfasciculus seemed to be implicated in both tests as significantly differentfrom that of the control group. The TBI patients and the single non-TBI subjectwere well separated under the shape deviation test at the chosen FDR level of0.0005. TOADDI is a simple but novel geometrically based statistical frameworkfor analyzing DTI data.
arxiv-13800-100 | Wavelet Frame Based Image Restoration Using Sparsity, Nonlocal and Support Prior of Frame Coefficients | http://arxiv.org/pdf/1510.02866v1.pdf | author:Liangtian He, Yilun Wang category:cs.CV 90-08 I.4.4 published:2015-10-10 summary:The wavelet frame systems have been widely investigated and applied for imagerestoration and many other image processing problems over the past decades,attributing to their good capability of sparsely approximating piece-wisesmooth functions such as images. Most wavelet frame based models exploit the$l_1$ norm of frame coefficients for a sparsity constraint in the past. Theauthors in \cite{ZhangY2013, Dong2013} proposed an $l_0$ minimization model,where the $l_0$ norm of wavelet frame coefficients is penalized instead, andhave demonstrated that significant improvements can be achieved compared to thecommonly used $l_1$ minimization model. Very recently, the authors in\cite{Chen2015} proposed $l_0$-$l_2$ minimization model, where the nonlocalprior of frame coefficients is incorporated. This model proved to outperformthe single $l_0$ minimization based model in terms of better recovered imagequality. In this paper, we propose a truncated $l_0$-$l_2$ minimization modelwhich combines sparsity, nonlocal and support prior of the frame coefficients.The extensive experiments have shown that the recovery results from theproposed regularization method performs better than existing state-of-the-artwavelet frame based methods, in terms of edge enhancement and texturepreserving performance.
arxiv-13800-101 | OmniGraph: Rich Representation and Graph Kernel Learning | http://arxiv.org/pdf/1510.02983v1.pdf | author:Boyi Xie, Rebecca J. Passonneau category:cs.CL cs.LG published:2015-10-10 summary:OmniGraph, a novel representation to support a range of NLP classificationtasks, integrates lexical items, syntactic dependencies and frame semanticparses into graphs. Feature engineering is folded into the learning throughconvolution graph kernel learning to explore different extents of the graph. Ahigh-dimensional space of features includes individual nodes as well as complexsubgraphs. In experiments on a text-forecasting problem that predicts stockprice change from news for company mentions, OmniGraph beats several benchmarksbased on bag-of-words, syntactic dependencies, and semantic trees. The highlyexpressive features OmniGraph discovers provide insights into the semanticsacross distinct market sectors. To demonstrate the method's generality, we alsoreport its high performance results on a fine-grained sentiment corpus.
arxiv-13800-102 | AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery | http://arxiv.org/pdf/1510.02855v1.pdf | author:Izhar Wallach, Michael Dzamba, Abraham Heifets category:cs.LG cs.NE q-bio.BM stat.ML published:2015-10-10 summary:Deep convolutional neural networks comprise a subclass of deep neuralnetworks (DNN) with a constrained architecture that leverages the spatial andtemporal structure of the domain they model. Convolutional networks achieve thebest predictive performance in areas such as speech and image recognition byhierarchically composing simple local features into complex models. AlthoughDNNs have been used in drug discovery for QSAR and ligand-based bioactivitypredictions, none of these models have benefited from this powerfulconvolutional architecture. This paper introduces AtomNet, the firststructure-based, deep convolutional neural network designed to predict thebioactivity of small molecules for drug discovery applications. We demonstratehow to apply the convolutional concepts of feature locality and hierarchicalcomposition to the modeling of bioactivity and chemical interactions. Infurther contrast to existing DNN techniques, we show that AtomNet's applicationof local convolutional filters to structural target information successfullypredicts new active molecules for targets with no previously known modulators.Finally, we show that AtomNet outperforms previous docking approaches on adiverse set of benchmarks by a large margin, achieving an AUC greater than 0.9on 57.8% of the targets in the DUDE benchmark.
arxiv-13800-103 | Feedforward Sequential Memory Neural Networks without Recurrent Feedback | http://arxiv.org/pdf/1510.02693v1.pdf | author:ShiLiang Zhang, Hui Jiang, Si Wei, LiRong Dai category:cs.NE cs.CL cs.LG published:2015-10-09 summary:We introduce a new structure for memory neural networks, called feedforwardsequential memory networks (FSMN), which can learn long-term dependency withoutusing recurrent feedback. The proposed FSMN is a standard feedforward neuralnetworks equipped with learnable sequential memory blocks in the hidden layers.In this work, we have applied FSMN to several language modeling (LM) tasks.Experimental results have shown that the memory blocks in FSMN can learneffective representations of long history. Experiments have shown that FSMNbased language models can significantly outperform not only feedforward neuralnetwork (FNN) based LMs but also the popular recurrent neural network (RNN)LMs.
arxiv-13800-104 | Some Theory For Practical Classifier Validation | http://arxiv.org/pdf/1510.02676v1.pdf | author:Eric Bax, Ya Le category:stat.ML cs.LG published:2015-10-09 summary:We compare and contrast two approaches to validating a trained classifierwhile using all in-sample data for training. One is simultaneous validationover an organized set of hypotheses (SVOOSH), the well-known method that beganwith VC theory. The other is withhold and gap (WAG). WAG withholds a validationset, trains a holdout classifier on the remaining data, uses the validationdata to validate that classifier, then adds the rate of disagreement betweenthe holdout classifier and one trained using all in-sample data, which is anupper bound on the difference in error rates. We show that complex hypothesisclasses and limited training data can make WAG a favorable alternative.
arxiv-13800-105 | Large-scale Artificial Neural Network: MapReduce-based Deep Learning | http://arxiv.org/pdf/1510.02709v1.pdf | author:Kairan Sun, Xu Wei, Gengtao Jia, Risheng Wang, Ruizhi Li category:cs.DC cs.LG cs.NE published:2015-10-09 summary:Faced with continuously increasing scale of data, original back-propagationneural network based machine learning algorithm presents two non-trivialchallenges: huge amount of data makes it difficult to maintain both efficiencyand accuracy; redundant data aggravates the system workload. This project ismainly focused on the solution to the issues above, combining deep learningalgorithm with cloud computing platform to deal with large-scale data. AMapReduce-based handwriting character recognizer will be designed in thisproject to verify the efficiency improvement this mechanism will achieve ontraining and practical large-scale data. Careful discussion and experiment willbe developed to illustrate how deep learning algorithm works to trainhandwritten digits data, how MapReduce is implemented on deep learning neuralnetwork, and why this combination accelerates computation. Besides performance,the scalability and robustness will be mentioned in this report as well. Oursystem comes with two demonstration software that visually illustrates ourhandwritten digit recognition/encoding application.
arxiv-13800-106 | Procams-Based Cybernetics | http://arxiv.org/pdf/1510.02710v1.pdf | author:Kosuke Sato, Daisuke Iwai, Sei Ikeda, Noriko Takemura category:cs.CV cs.GR cs.HC published:2015-10-09 summary:Procams-based cybernetics is a unique, emerging research field, which aims atenhancing and supporting our activities by naturally connecting human andcomputers/machines as a cooperative integrated system via projector-camerasystems (procams). It rests on various research domains such asvirtual/augmented reality, computer vision, computer graphics, projectiondisplay, human computer interface, human robot interaction and so on. Thislaboratory presentation provides a brief history including recent achievementsof our procams-based cybernetics project.
arxiv-13800-107 | Technical Report of Participation in Higgs Boson Machine Learning Challenge | http://arxiv.org/pdf/1510.02674v1.pdf | author:S. Raza Ahmad category:cs.LG published:2015-10-09 summary:This report entails the detailed description of the approach andmethodologies taken as part of competing in the Higgs Boson Machine LearningCompetition hosted by Kaggle Inc. and organized by CERN et al. It brieflydescribes the theoretical background of the problem and the motivation fortaking part in the competition. Furthermore, the various machine learningmodels and algorithms analyzed and implemented during the 4 month period ofparticipation are discussed and compared. Special attention is paid to the DeepLearning techniques and architectures implemented from scratch using Python andNumPy for this competition.
arxiv-13800-108 | Free-hand Sketch Synthesis with Deformable Stroke Models | http://arxiv.org/pdf/1510.02644v1.pdf | author:Yi Li, Yi-Zhe Song, Timothy Hospedales, Shaogang Gong category:cs.CV published:2015-10-09 summary:We present a generative model which can automatically summarize the strokecomposition of free-hand sketches of a given category. When our model is fit toa collection of sketches with similar poses, it discovers and learns thestructure and appearance of a set of coherent parts, with each part representedby a group of strokes. It represents both consistent (topology) as well asdiverse aspects (structure and appearance variations) of each sketch category.Key to the success of our model are important insights learned from acomprehensive study performed on human stroke data. By fitting this model toimages, we are able to synthesize visually similar and pleasant free-handsketches.
arxiv-13800-109 | Human Head Pose Estimation by Facial Features Location | http://arxiv.org/pdf/1510.02774v1.pdf | author:Eugene Borovikov category:cs.CV published:2015-10-09 summary:We describe a method for estimating human head pose in a color image thatcontains enough of information to locate the head silhouette and detectnon-trivial color edges of individual facial features. The method works byspotting the human head on an arbitrary background, extracting the headoutline, and locating facial features necessary to describe the headorientation in the 3D space. It is robust enough to work with both color andgray-level images featuring quasi-frontal views of a human head under variablelighting conditions.
arxiv-13800-110 | Where is my puppy? Retrieving lost dogs by facial features | http://arxiv.org/pdf/1510.02781v1.pdf | author:Thierry Pinheiro Moreira, Mauricio Lisboa Perez, Rafael de Oliveira Werneck, Eduardo Valle category:cs.CV 68T45 I.5.4 published:2015-10-09 summary:A pet that goes missing is among many people's worst fears. A moment ofdistraction is enough for a dog or a cat wandering off from home. Animalmanagement services collect stray animals and try to find their owners, but notalways successfully. Some measures may improve the chances of matching lostanimals to their owners; but automated visual recognition is one that --although convenient, highly available, and low-cost -- is surprisinglyoverlooked. In this paper, we inaugurate that promising avenue by pursuing facerecognition for dogs. We contrast three ready-to-use human facial recognizers(EigenFaces, FisherFaces and LBPH) to two original solutions based uponexisting convolutional neural networks: BARK (inspired inarchitecture-optimized networks employed for human facial recognition) and WOOF(based upon off-the-shelf OverFeat features). Human facial recognizers performpoorly for dogs (up to 56.1% accuracy), showing that dog facial recognition isnot a trivial extension of human facial recognition. The convolutional networksolutions work much better, with BARK attaining up to 81.1% accuracy, and WOOF,89.4%. The tests were conducted in two datasets: Flickr-dog, with 42 dogs oftwo breeds (pugs and huskies); and Snoopybook, with 18 mongrel dogs.
arxiv-13800-111 | Recovering a Hidden Community Beyond the Spectral Limit in $O(E \log^*V)$ Time | http://arxiv.org/pdf/1510.02786v1.pdf | author:Bruce Hajek, Yihong Wu, Jiaming Xu category:stat.ML cs.CC cs.SI math.PR published:2015-10-09 summary:The stochastic block model for one community with parameters $n, K, p,$ and$q$ is considered: $K$ out of $n$ vertices are in the community; two verticesare connected by an edge with probability $p$ if they are both in the communityand with probability $q$ otherwise, where $p > q > 0$ and $p/q$ is assumed tobe bounded. An estimator based on observation of the graph $G=(V,E)$ is said toachieve weak recovery if the mean number of misclassified vertices is $o(K)$ as$n \to \infty$. A critical role is played by the effective signal-to-noiseratio $\lambda=K^2(p-q)^2/((n-K)q).$ In the regime $K=\Theta(n)$, a na\"{i}vedegree-thresholding algorithm achieves weak recovery in $O(E)$ time if$\lambda \to \infty$, which coincides with the information theoreticpossibility of weak recovery. The main focus of the paper is on weak recovery in the sublinear regime$K=o(n)$ and $np = n^{o(1)}.$ It is shown that weak recovery is provided by abelief propagation algorithm running for $\log^\ast(n)+O(1) $ iterations, if$\lambda > 1/e,$ with the total time complexity $O(E \log^*n)$. Conversely,no local algorithm with radius $t$ of interaction satisfying $t = o(\frac{\logn}{\log(2+np)})$ can asymptotically outperform trivial random guessing if$\lambda \leq 1/e.$ By analyzing a linear message-passing algorithm thatcorresponds to applying power iteration to the non-backtracking matrix of thegraph, we provide evidence to suggest that spectral methods fail to provideweak recovery if $\lambda \leq 1.$
arxiv-13800-112 | Dreaming More Data: Class-dependent Distributions over Diffeomorphisms for Learned Data Augmentation | http://arxiv.org/pdf/1510.02795v1.pdf | author:Søren Hauberg, Oren Freifeld, Anders Boesen Lindbo Larsen, John W. Fisher III, Lars Kai Hansen category:cs.CV published:2015-10-09 summary:Data augmentation is a key element in training high-dimensional models. Inthis approach, one synthesizes new observations by applying pre-specifiedtransformations to the original training data; e.g. new images are formed byrotating old ones. Current augmentation schemes, however, rely on manualspecification of the applied transformations, making data augmentation animplicit form of feature engineering. Working towards true end-to-end learning,we suggest to learn the applied transformations on a per-class basis.Particularly, we align image pairs within each class under the assumption thatthe spatial transformation between images belongs to a large class ofdiffeomorphisms. For each class, we then build a probabilistic generative modelof the transformations in a Riemannian submanifold of the Lie group ofdiffeomorphisms. We demonstrate significant performance improvements intraining deep neural nets over manually-specified augmentation schemes.
arxiv-13800-113 | Functional Frank-Wolfe Boosting for General Loss Functions | http://arxiv.org/pdf/1510.02558v1.pdf | author:Chu Wang, Yingfei Wang, Weinan E, Robert Schapire category:stat.ML cs.LG published:2015-10-09 summary:Boosting is a generic learning method for classification and regression. Yet,as the number of base hypotheses becomes larger, boosting can lead to adeterioration of test performance. Overfitting is an important and ubiquitousphenomenon, especially in regression settings. To avoid overfitting, weconsider using $l_1$ regularization. We propose a novel Frank-Wolfe typeboosting algorithm (FWBoost) applied to general loss functions. By usingexponential loss, the FWBoost algorithm can be rewritten as a variant ofAdaBoost for binary classification. FWBoost algorithms have exactly the sameform as existing boosting methods, in terms of making calls to a base learningalgorithm with different weights update. This direct connection betweenboosting and Frank-Wolfe yields a new algorithm that is as practical asexisting boosting methods but with new guarantees and rates of convergence.Experimental results show that the test performance of FWBoost is not degradedwith larger rounds in boosting, which is consistent with the theoreticalanalysis.
arxiv-13800-114 | On the Complexity of Inner Product Similarity Join | http://arxiv.org/pdf/1510.02824v3.pdf | author:Thomas D. Ahle, Rasmus Pagh, Ilya Razenshteyn, Francesco Silvestri category:cs.DS cs.DB cs.LG published:2015-10-09 summary:A number of tasks in classification, information retrieval, recommendationsystems, and record linkage reduce to the core problem of inner productsimilarity join (IPS join): identifying pairs of vectors in a collection thathave a sufficiently large inner product. IPS join is well understood whenvectors are normalized and some approximation of inner products is allowed.However, the general case where vectors may have any length appears much morechallenging. Recently, new upper bounds based on asymmetric locality-sensitivehashing (ALSH) and asymmetric embeddings have emerged, but little has beenknown on the lower bound side. In this paper we initiate a systematic study ofinner product similarity join, showing new lower and upper bounds. Our mainresults are: * Approximation hardness of IPS join in subquadratic time, assuming thestrong exponential time hypothesis. * New upper and lower bounds for (A)LSH-based algorithms. In particular, weshow that asymmetry can be avoided by relaxing the LSH definition to onlyconsider the collision probability of distinct elements. * A new indexing method for IPS based on linear sketches, implying that ourhardness results are not far from being tight. Our technical contributions include new asymmetric embeddings that may be ofindependent interest. At the conceptual level we strive to provide greaterclarity, for example by distinguishing among signed and unsigned variants ofIPS join and shedding new light on the effect of asymmetry.
arxiv-13800-115 | Early Inference in Energy-Based Models Approximates Back-Propagation | http://arxiv.org/pdf/1510.02777v2.pdf | author:Yoshua Bengio, Asja Fischer category:cs.LG published:2015-10-09 summary:We show that Langevin MCMC inference in an energy-based model with latentvariables has the property that the early steps of inference, starting from astationary point, correspond to propagating error gradients into internallayers, similarly to back-propagation. The error that is back-propagated iswith respect to visible units that have received an outside driving forcepushing them away from the stationary point. Back-propagated error gradientscorrespond to temporal derivatives of the activation of hidden units. Thisobservation could be an element of a theory for explaining how brains performcredit assignment in deep hierarchies as efficiently as back-propagation does.In this theory, the continuous-valued latent variables correspond to averagedvoltage potential (across time, spikes, and possibly neurons in the sameminicolumn), and neural computation corresponds to approximate inference anderror back-propagation at the same time.
arxiv-13800-116 | New Optimisation Methods for Machine Learning | http://arxiv.org/pdf/1510.02533v2.pdf | author:Aaron Defazio category:cs.LG stat.ML published:2015-10-09 summary:A thesis submitted for the degree of Doctor of Philosophy of The AustralianNational University. In this work we introduce several new optimisation methods for problems inmachine learning. Our algorithms broadly fall into two categories: optimisationof finite sums and of graph structured objectives. The finite sum problem issimply the minimisation of objective functions that are naturally expressed asa summation over a large number of terms, where each term has a similar oridentical weight. Such objectives most often appear in machine learning in theempirical risk minimisation framework in the non-online learning setting. Thesecond category, that of graph structured objectives, consists of objectivesthat result from applying maximum likelihood to Markov random field models.Unlike the finite sum case, all the non-linearity is contained within apartition function term, which does not readily decompose into a summation. For the finite sum problem, we introduce the Finito and SAGA algorithms, aswell as variants of each. For graph-structured problems, we take three complementary approaches. Welook at learning the parameters for a fixed structure, learning the structureindependently, and learning both simultaneously. Specifically, for the combinedapproach, we introduce a new method for encouraging graph structures with the"scale-free" property. For the structure learning problem, we establishSHORTCUT, a O(n^{2.5}) expected time approximate structure learning method forGaussian graphical models. For problems where the structure is known but theparameters unknown, we introduce an approximate maximum likelihood learningalgorithm that is capable of learning a useful subclass of Gaussian graphicalmodels.
arxiv-13800-117 | Conditional Risk Minimization for Stochastic Processes | http://arxiv.org/pdf/1510.02706v2.pdf | author:Alexander Zimin, Christoph H. Lampert category:stat.ML cs.LG published:2015-10-09 summary:We study the task of learning from non-i.i.d. data. In particular, we aim atlearning predictors that minimize the conditional risk for a stochasticprocess, i.e. the expected loss of the predictor on the next point conditionedon the set of training samples observed so far. For non-i.i.d. data, thetraining set contains information about the upcoming samples, so learning withrespect to the conditional distribution can be expected to yield betterpredictors than one obtains from the classical setting of minimizing themarginal risk. Our main contribution is a practical estimator for theconditional risk based on the theory of non-parametric time-series prediction,and a finite sample concentration bound that establishes uniform convergence ofthe estimator to the true conditional risk under certain regularity assumptionson the process.
arxiv-13800-118 | Human languages order information efficiently | http://arxiv.org/pdf/1510.02823v1.pdf | author:Daniel Gildea, T. Florian Jaeger category:cs.CL published:2015-10-09 summary:Most languages use the relative order between words to encode meaningrelations. Languages differ, however, in what orders they use and how theseorders are mapped onto different meanings. We test the hypothesis that, despitethese differences, human languages might constitute different `solutions' tocommon pressures of language use. Using Monte Carlo simulations over data fromfive languages, we find that their word orders are efficient for processing interms of both dependency length and local lexical probability. This suggeststhat biases originating in how the brain understands language stronglyconstrain how human languages change over generations.
arxiv-13800-119 | Controlled Experiments for Word Embeddings | http://arxiv.org/pdf/1510.02675v2.pdf | author:Benjamin J. Wilson, Adriaan M. J. Schakel category:cs.CL 68T50 I.2.7 published:2015-10-09 summary:An experimental approach to studying the properties of word embeddings isproposed. Controlled experiments, achieved through modifications of thetraining corpus, permit the demonstration of direct relations between wordproperties and word vector direction and length. The approach is demonstratedusing the word2vec CBOW model with experiments that independently vary wordfrequency and word co-occurrence noise. The experiments reveal that word vectorlength depends more or less linearly on both word frequency and the level ofnoise in the co-occurrence distribution of the word. The coefficients oflinearity depend upon the word. The special point in feature space, defined bythe (artificial) word with pure noise in its co-occurrence distribution, isfound to be small but non-zero.
arxiv-13800-120 | p-Markov Gaussian Processes for Scalable and Expressive Online Bayesian Nonparametric Time Series Forecasting | http://arxiv.org/pdf/1510.02830v1.pdf | author:Yves-Laurent Kom Samo, Stephen J. Roberts category:stat.ML published:2015-10-09 summary:In this paper we introduce a novel online time series forecasting model werefer to as the pM-GP filter. We show that our model is equivalent to Gaussianprocess regression, with the advantage that both online forecasting and onlinelearning of the hyper-parameters have a constant (rather than cubic) timecomplexity and a constant (rather than squared) memory requirement in thenumber of observations, without resorting to approximations. Moreover, theproposed model is expressive in that the family of covariance functions of theimplied latent process, namely the spectral Matern kernels, have recently beenproven to be capable of approximating arbitrarily well anytranslation-invariant covariance function. The benefit of our approach comparedto competing models is demonstrated using experiments on several real-lifedatasets.
arxiv-13800-121 | Earth Mover's Distance Yields Positive Definite Kernels For Certain Ground Distances | http://arxiv.org/pdf/1510.02833v1.pdf | author:Andrew Gardner, Christian A. Duncan, Jinko Kanno, Rastko R. Selmic category:cs.LG stat.ML published:2015-10-09 summary:Positive definite kernels are an important tool in machine learning thatenable efficient solutions to otherwise difficult or intractable problems byimplicitly linearizing the problem geometry. In this paper we develop aset-theoretic interpretation of the Earth Mover's Distance (EMD) that naturallyyields metric and kernel forms of EMD as generalizations of elementary setoperations. In particular, EMD is generalized to sets of unequal size. We alsooffer the first proof of positive definite kernels based directly on EMD, andprovide propositions and conjectures concerning what properties are necessaryand sufficient for EMD to be conditionally negative definite. In particular, weshow that three distinct positive definite kernels -- intersection, minimum,and Jaccard index -- can be derived from EMD with various ground distances. Inthe process we show that the Jaccard index is simply the result of a positivedefinite preserving transformation that can be applied to any kernel. Finally,we evaluate the proposed kernels in various computer vision tasks.
arxiv-13800-122 | Active Learning from Weak and Strong Labelers | http://arxiv.org/pdf/1510.02847v2.pdf | author:Chicheng Zhang, Kamalika Chaudhuri category:cs.LG stat.ML published:2015-10-09 summary:An active learner is given a hypothesis class, a large set of unlabeledexamples and the ability to interactively query labels to an oracle of a subsetof these examples; the goal of the learner is to learn a hypothesis in theclass that fits the data well by making as few label queries as possible. This work addresses active learning with labels obtained from strong and weaklabelers, where in addition to the standard active learning setting, we have anextra weak labeler which may occasionally provide incorrect labels. An exampleis learning to classify medical images where either expensive labels may beobtained from a physician (oracle or strong labeler), or cheaper butoccasionally incorrect labels may be obtained from a medical resident (weaklabeler). Our goal is to learn a classifier with low error on data labeled bythe oracle, while using the weak labeler to reduce the number of label queriesmade to this labeler. We provide an active learning algorithm for this setting,establish its statistical consistency, and analyze its label complexity tocharacterize when it can provide label savings over using the strong labeleralone.
arxiv-13800-123 | Data-Efficient Learning of Feedback Policies from Image Pixels using Deep Dynamical Models | http://arxiv.org/pdf/1510.02173v2.pdf | author:John-Alexander M. Assael, Niklas Wahlström, Thomas B. Schön, Marc Peter Deisenroth category:cs.AI cs.CV cs.LG stat.ML published:2015-10-08 summary:Data-efficient reinforcement learning (RL) in continuous state-action spacesusing very high-dimensional observations remains a key challenge in developingfully autonomous systems. We consider a particularly important instance of thischallenge, the pixels-to-torques problem, where an RL agent learns aclosed-loop control policy ("torques") from pixel information only. Weintroduce a data-efficient, model-based reinforcement learning algorithm thatlearns such a closed-loop policy directly from pixel information. The keyingredient is a deep dynamical model for learning a low-dimensional featureembedding of images jointly with a predictive model in this low-dimensionalfeature space. Joint learning is crucial for long-term predictions, which lieat the core of the adaptive nonlinear model predictive control strategy that weuse for closed-loop control. Compared to state-of-the-art RL methods forcontinuous states and actions, our approach learns quickly, scales tohigh-dimensional state spaces, is lightweight and an important step towardfully autonomous end-to-end learning from pixels to torques.
arxiv-13800-124 | The Knowledge Gradient with Logistic Belief Models for Binary Classification | http://arxiv.org/pdf/1510.02354v1.pdf | author:Yingfei Wang, Chu Wang, Warren Powell category:stat.ML published:2015-10-08 summary:We consider sequential decision making problems for binary classificationscenario in which the learner takes an active role in repeatedly selectingsamples from the action pool and receives the binary label of the selectedalternatives. Our problem is motivated by applications where observations aretime consuming and/or expensive, resulting in small samples. The goal is toidentify the best alternative with the highest response. We use Bayesianlogistic regression to predict the response of each alternative. By formulatingthe problem as a Markov decision process, we develop a knowledge-gradient typepolicy to guide the experiment by maximizing the expected value of informationof labeling each alternative and provide a finite-time analysis on theestimated error. Experiments on benchmark UCI datasets demonstrate theeffectiveness of the proposed method.
arxiv-13800-125 | Reduced-Order Modeling Of Hidden Dynamics | http://arxiv.org/pdf/1510.02267v1.pdf | author:Patrick Héas, Cédric Herzet category:stat.ML stat.AP published:2015-10-08 summary:The objective of this paper is to investigate how noisy and incompleteobservations can be integrated in the process of building a reduced-ordermodel. This problematic arises in many scientific domains where there exists a needfor accurate low-order descriptions of highly-complex phenomena, which can notbe directly and/or deterministically observed. Within this context, the paperproposes a probabilistic framework for the construction of "POD-Galerkin"reduced-order models. Assuming a hidden Markov chain, the inference integratesthe uncertainty of the hidden states relying on their posterior distribution.Simulations show the benefits obtained by exploiting the proposed framework.
arxiv-13800-126 | Differential Evolution with Generalized Mutation Operator for Parameters Optimization in Gene Selection for Cancer Classification | http://arxiv.org/pdf/1510.02516v2.pdf | author:H. Sharifi Noghabi, H. Rajabi Mashhadi, K. Shojaei category:cs.NE published:2015-10-08 summary:Differential Evolution (DE) proved to be one of the most successfulevolutionary algorithms for global optimization purposes in continuousproblems. The core operator in DE is mutation which can provide the algorithmwith both exploration and exploitation. In this article, a new notation for DEis proposed which has a formula that can be utilized for generating andextracting novel mutations and by applying this new notation, four novelmutations are proposed. More importantly, by combining these novel trial vectorgeneration strategies and four other well-known ones, we proposed GeneralizedMutation Differential Evolution (GMDE) that takes advantage of two mutationpools that have both explorative and exploitative strategies inside them.Results and experimental analysis are performed on CEC2005 benchmarks and theresults stated that GMDE is surprisingly competitive and significantly improvedthe performance of this algorithm. Finally, GMDE is also applied to parametersoptimization, modification and improvement of a feature selection method forcancer classification purposes over gene expression microarray profiles.
arxiv-13800-127 | Simultaneous Deep Transfer Across Domains and Tasks | http://arxiv.org/pdf/1510.02192v1.pdf | author:Eric Tzeng, Judy Hoffman, Trevor Darrell, Kate Saenko category:cs.CV published:2015-10-08 summary:Recent reports suggest that a generic supervised deep CNN model trained on alarge-scale dataset reduces, but does not remove, dataset bias. Fine-tuningdeep models in a new domain can require a significant amount of labeled data,which for many applications is simply not available. We propose a new CNNarchitecture to exploit unlabeled and sparsely labeled target domain data. Ourapproach simultaneously optimizes for domain invariance to facilitate domaintransfer and uses a soft label distribution matching loss to transferinformation between tasks. Our proposed adaptation method offers empiricalperformance which exceeds previously published results on two standardbenchmark visual domain adaptation tasks, evaluated across supervised andsemi-supervised adaptation settings.
arxiv-13800-128 | Statistical Analysis of Persistence Intensity Functions | http://arxiv.org/pdf/1510.02502v1.pdf | author:Yen-Chi Chen, Daren Wang, Alessandro Rinaldo, Larry Wasserman category:stat.ME stat.ML published:2015-10-08 summary:Persistence diagrams are two-dimensional plots that summarize the topologicalfeatures of functions and are an important part of topological data analysis. Aproblem that has received much attention is how deal with sets of persistencediagrams. How do we summarize them, average them or cluster them? One approach-- the persistence intensity function -- was introduced informally byEdelsbrunner, Ivanov, and Karasev (2012). Here we provide a modification andformalization of this approach. Using the persistence intensity function, wecan visualize multiple diagrams, perform clustering and conduct two-sampletests.
arxiv-13800-129 | A novel mutation operator based on the union of fitness and design spaces information for Differential Evolution | http://arxiv.org/pdf/1510.02513v2.pdf | author:H. Sharifi Noghabi, H. Rajabi Mashhadi, K. Shojaei category:cs.NE published:2015-10-08 summary:Differential Evolution (DE) is one of the most successful and powerfulevolutionary algorithms for global optimization problem. The most importantoperator in this algorithm is mutation operator which parents are selectedrandomly to participate in it. Recently, numerous papers are tried to make thisoperator more intelligent by selection of parents for mutation intelligently.The intelligent selection for mutation vectors is performed by applying designspace (also known as decision space) criterion or fitness space criterion,however, in both cases, half of valuable information of the problem space isdisregarded. In this article, a Universal Differential Evolution (UDE) isproposed which takes advantage of both design and fitness spaces criteria forintelligent selection of mutation vectors. The experimental analysis on UDE areperformed on CEC2005 benchmarks and the results stated that UDE significantlyimproved the performance of differential evolution in comparison with othermethods that only use one criterion for intelligent selection.
arxiv-13800-130 | Texture Modelling with Nested High-order Markov-Gibbs Random Fields | http://arxiv.org/pdf/1510.02364v1.pdf | author:Ralph Versteegen, Georgy Gimel'farb, Patricia Riddle category:cs.CV cs.LG stat.ML published:2015-10-08 summary:Currently, Markov-Gibbs random field (MGRF) image models which includehigh-order interactions are almost always built by modelling responses of astack of local linear filters. Actual interaction structure is specifiedimplicitly by the filter coefficients. In contrast, we learn an explicithigh-order MGRF structure by considering the learning process in terms ofgeneral exponential family distributions nested over base models, so thatpotentials added later can build on previous ones. We relatively rapidly addnew features by skipping over the costly optimisation of parameters. We introduce the use of local binary patterns as features in MGRF texturemodels, and generalise them by learning offsets to the surrounding pixels.These prove effective as high-order features, and are fast to compute. Severalschemes for selecting high-order features by composition or search of a smallsubclass are compared. Additionally we present a simple modification of themaximum likelihood as a texture modelling-specific objective function whichaims to improve generalisation by local windowing of statistics. The proposed method was experimentally evaluated by learning high-order MGRFmodels for a broad selection of complex textures and then performing texturesynthesis, and succeeded on much of the continuum from stochastic throughirregularly structured to near-regular textures. Learning interaction structureis very beneficial for textures with large-scale structure, although those withcomplex irregular structure still provide difficulties. The texture models werealso quantitatively evaluated on two tasks and found to be competitive withother works: grading of synthesised textures by a panel of observers; andcomparison against several recent MGRF models by evaluation on a constrainedinpainting task.
arxiv-13800-131 | Uniform Learning in a Deep Neural Network via "Oddball" Stochastic Gradient Descent | http://arxiv.org/pdf/1510.02442v1.pdf | author:Andrew J. R. Simpson category:cs.LG 68Txx published:2015-10-08 summary:When training deep neural networks, it is typically assumed that the trainingexamples are uniformly difficult to learn. Or, to restate, it is assumed thatthe training error will be uniformly distributed across the training examples.Based on these assumptions, each training example is used an equal number oftimes. However, this assumption may not be valid in many cases. "Oddball SGD"(novelty-driven stochastic gradient descent) was recently introduced to drivetraining probabilistically according to the error distribution - trainingfrequency is proportional to training error magnitude. In this article, using adeep neural network to encode a video, we show that oddball SGD can be used toenforce uniform error across the training set.
arxiv-13800-132 | Distilling Model Knowledge | http://arxiv.org/pdf/1510.02437v1.pdf | author:George Papamakarios category:stat.ML cs.LG published:2015-10-08 summary:Top-performing machine learning systems, such as deep neural networks, largeensembles and complex probabilistic graphical models, can be expensive tostore, slow to evaluate and hard to integrate into larger systems. Ideally, wewould like to replace such cumbersome models with simpler models that performequally well. In this thesis, we study knowledge distillation, the idea of extracting theknowledge contained in a complex model and injecting it into a more convenientmodel. We present a general framework for knowledge distillation, whereby aconvenient model of our choosing learns how to mimic a complex model, byobserving the latter's behaviour and being penalized whenever it fails toreproduce it. We develop our framework within the context of three distinct machinelearning applications: (a) model compression, where we compress largediscriminative models, such as ensembles of neural networks, into models ofmuch smaller size; (b) compact predictive distributions for Bayesian inference,where we distil large bags of MCMC samples into compact predictivedistributions in closed form; (c) intractable generative models, where wedistil unnormalizable models such as RBMs into tractable models such as NADEs. We contribute to the state of the art with novel techniques and ideas. Inmodel compression, we describe and implement derivative matching, which allowsfor better distillation when data is scarce. In compact predictivedistributions, we introduce online distillation, which allows for significantsavings in memory. Finally, in intractable generative models, we show how touse distilled models to robustly estimate intractable quantities of theoriginal model, such as its intractable partition function.
arxiv-13800-133 | Exact Inference Techniques for the Dynamic Analysis of Attack Graphs | http://arxiv.org/pdf/1510.02427v1.pdf | author:Luis Muñoz-González, Daniele Sgandurra, Martín Barrère, Emil Lupu category:cs.CR stat.AP stat.ML 62F15 published:2015-10-08 summary:Attack graphs are a powerful tool for security risk assessment by analysingnetwork vulnerabilities and the paths attackers can use to compromise valuablenetwork resources. The uncertainty about the attacker's behaviour andcapabilities make Bayesian networks suitable to model attack graphs to performstatic and dynamic analysis. Previous approaches have focused on theformalization of traditional attack graphs into a Bayesian model rather thanproposing mechanisms for their analysis. In this paper we propose to useefficient algorithms to make exact inference in Bayesian attack graphs,enabling the static and dynamic network risk assessments. To support thevalidity of our proposed approach we have performed an extensive experimentalevaluation on synthetic Bayesian attack graphs with different topologies,showing the computational advantages in terms of time and memory use of theproposed techniques when compared to existing approaches.
arxiv-13800-134 | Learning Data-driven Reflectance Priors for Intrinsic Image Decomposition | http://arxiv.org/pdf/1510.02413v1.pdf | author:Tinghui Zhou, Philipp Krähenbühl, Alexei A. Efros category:cs.CV published:2015-10-08 summary:We propose a data-driven approach for intrinsic image decomposition, which isthe process of inferring the confounding factors of reflectance and shading inan image. We pose this as a two-stage learning problem. First, we train a modelto predict relative reflectance ordering between image patches (`brighter',`darker', `same') from large-scale human annotations, producing a data-drivenreflectance prior. Second, we show how to naturally integrate this learnedprior into existing energy minimization frameworks for intrinsic imagedecomposition. We compare our method to the state-of-the-art approach of Bellet al. on both decomposition and image relighting tasks, demonstrating thebenefits of the simple relative reflectance prior, especially for scenes underchallenging lighting conditions.
arxiv-13800-135 | Mapping Unseen Words to Task-Trained Embedding Spaces | http://arxiv.org/pdf/1510.02387v1.pdf | author:Pranava Swaroop Madhyastha, Mohit Bansal, Kevin Gimpel, Karen Livescu category:cs.CL cs.LG published:2015-10-08 summary:We consider the setting in which we train a supervised model that learnstask-specific word representations. We assume that we have access to someinitial word representations (e.g., unsupervised embeddings), and that thesupervised learning procedure updates them to task-specific representations forwords contained in the training data. But what about words not contained in thesupervised training data? When such unseen words are encountered at test time,they are typically represented by either their initial vectors or a singleunknown vector, which often leads to errors. In this paper, we address thisissue by learning to map from initial representations to task-specific ones. Wepresent a general technique that uses a neural network mapper with a weightedmultiple-loss criterion. This allows us to use the same learned modelparameters at test time but now with appropriate task-specific representationsfor unseen words. We consider the task of dependency parsing and reportimprovements in performance (and reductions in out-of-vocabulary rates) acrossmultiple domains such as news, Web, and speech. We also achieve downstreamimprovements on the task of parsing-based sentiment analysis.
arxiv-13800-136 | Learning Summary Statistic for Approximate Bayesian Computation via Deep Neural Network | http://arxiv.org/pdf/1510.02175v1.pdf | author:Bai Jiang, Tung-yu Wu, Charles Zheng, Wing H. Wong category:stat.ME stat.CO stat.ML published:2015-10-08 summary:Approximate Bayesian Computation (ABC) methods are used to approximateposterior distributions in models with unknown or computationally intractablelikelihoods. Both the accuracy and computational efficiency of ABC depend onthe choice of summary statistic, but outside of special cases where the optimalsummary statistics are known, it is unclear which guiding principles can beused to construct effective summary statistics. In this paper we explore thepossibility of automating the process of constructing summary statistics bytraining deep neural networks to predict the parameters from artificiallygenerated data: the resulting summary statistics are approximately posteriormeans of the parameters. With minimal model-specific tuning, our methodconstructs summary statistics for the Ising model and the moving-average model,which match or exceed theoretically-motivated summary statistics in terms ofthe accuracies of the resulting posteriors.
arxiv-13800-137 | Automata networks for multi-party communication in the Naming Game | http://arxiv.org/pdf/1510.02358v2.pdf | author:Javier Vera, Pedro Montealegre, Eric Goles category:cs.CL published:2015-10-08 summary:The Naming Game has been studied to explore the role of self-organization inthe development and negotiation of linguistic conventions. In this paper, wedefine an automata networks approach to the Naming Game. Two problems arefaced: (1) the definition of an automata networks for multi-party communicativeinteractions; and (2) the proof of convergence for three different orders inwhich the individuals are updated (updating schemes). Finally, computersimulations are explored in two-dimensional lattices with the purpose torecover the main features of the Naming Game and to describe the dynamics underdifferent updating schemes.
arxiv-13800-138 | Empirical Analysis of Sampling Based Estimators for Evaluating RBMs | http://arxiv.org/pdf/1510.02255v1.pdf | author:Vidyadhar Upadhya, P. S. Sastry category:cs.LG stat.ML published:2015-10-08 summary:The Restricted Boltzmann Machines (RBM) can be used either as classifiers oras generative models. The quality of the generative RBM is measured through theaverage log-likelihood on test data. Due to the high computational complexityof evaluating the partition function, exact calculation of test log-likelihoodis very difficult. In recent years some estimation methods are suggested forapproximate computation of test log-likelihood. In this paper we present anempirical comparison of the main estimation methods, namely, the AIS algorithmfor estimating the partition function, the CSL method for directly estimatingthe log-likelihood, and the RAISE algorithm that combines these two ideas. Weuse the MNIST data set to learn the RBM and then compare these methods forestimating the test log-likelihood.
arxiv-13800-139 | Leveraging Context to Support Automated Food Recognition in Restaurants | http://arxiv.org/pdf/1510.02078v1.pdf | author:Vinay Bettadapura, Edison Thomaz, Aman Parnami, Gregory Abowd, Irfan Essa category:cs.CV published:2015-10-07 summary:The pervasiveness of mobile cameras has resulted in a dramatic increase infood photos, which are pictures reflecting what people eat. In this paper, westudy how taking pictures of what we eat in restaurants can be used for thepurpose of automating food journaling. We propose to leverage the context ofwhere the picture was taken, with additional information about the restaurant,available online, coupled with state-of-the-art computer vision techniques torecognize the food being consumed. To this end, we demonstrate image-basedrecognition of foods eaten in restaurants by training a classifier with imagesfrom restaurant's online menu databases. We evaluate the performance of oursystem in unconstrained, real-world settings with food images taken in 10restaurants across 5 different types of food (American, Indian, Italian,Mexican and Thai).
arxiv-13800-140 | Efficient Per-Example Gradient Computations | http://arxiv.org/pdf/1510.01799v2.pdf | author:Ian Goodfellow category:stat.ML cs.LG published:2015-10-07 summary:This technical report describes an efficient technique for computing the normof the gradient of the loss function for a neural network with respect to itsparameters. This gradient norm can be computed efficiently for every example.
arxiv-13800-141 | Egocentric Field-of-View Localization Using First-Person Point-of-View Devices | http://arxiv.org/pdf/1510.02073v1.pdf | author:Vinay Bettadapura, Irfan Essa, Caroline Pantofaru category:cs.CV published:2015-10-07 summary:We present a technique that uses images, videos and sensor data taken fromfirst-person point-of-view devices to perform egocentric field-of-view (FOV)localization. We define egocentric FOV localization as capturing the visualinformation from a person's field-of-view in a given environment andtransferring this information onto a reference corpus of images and videos ofthe same space, hence determining what a person is attending to. Our methodmatches images and video taken from the first-person perspective with thereference corpus and refines the results using the first-person's headorientation information obtained using the device sensors. We demonstratesingle and multi-user egocentric FOV localization in different indoor andoutdoor environments with applications in augmented reality, eventunderstanding and studying social interactions.
arxiv-13800-142 | Augmenting Bag-of-Words: Data-Driven Discovery of Temporal and Structural Information for Activity Recognition | http://arxiv.org/pdf/1510.02071v1.pdf | author:Vinay Bettadapura, Grant Schindler, Thomaz Plotz, Irfan Essa category:cs.CV published:2015-10-07 summary:We present data-driven techniques to augment Bag of Words (BoW) models, whichallow for more robust modeling and recognition of complex long-term activities,especially when the structure and topology of the activities are not known apriori. Our approach specifically addresses the limitations of standard BoWapproaches, which fail to represent the underlying temporal and causalinformation that is inherent in activity streams. In addition, we also proposethe use of randomly sampled regular expressions to discover and encode patternsin activities. We demonstrate the effectiveness of our approach in experimentalevaluations where we successfully recognize activities and detect anomalies infour complex datasets.
arxiv-13800-143 | DeepLogo: Hitting Logo Recognition with the Deep Neural Network Hammer | http://arxiv.org/pdf/1510.02131v1.pdf | author:Forrest N. Iandola, Anting Shen, Peter Gao, Kurt Keutzer category:cs.CV published:2015-10-07 summary:Recently, there has been a flurry of industrial activity around logorecognition, such as Ditto's service for marketers to track their brands inuser-generated images, and LogoGrab's mobile app platform for logo recognition.However, relatively little academic or open-source logo recognition progresshas been made in the last four years. Meanwhile, deep convolutional neuralnetworks (DCNNs) have revolutionized a broad range of object recognitionapplications. In this work, we apply DCNNs to logo recognition. We proposeseveral DCNN architectures, with which we surpass published state-of-artaccuracy on a popular logo recognition dataset.
arxiv-13800-144 | Diverse Large-Scale ITS Dataset Created from Continuous Learning for Real-Time Vehicle Detection | http://arxiv.org/pdf/1510.02055v1.pdf | author:Justin A. Eichel, Akshaya Mishra, Nicholas Miller, Nicholas Jankovic, Mohan A. Thomas, Tyler Abbott, Douglas Swanson, Joel Keller category:cs.CV published:2015-10-07 summary:In traffic engineering, vehicle detectors are trained on limited datasetsresulting in poor accuracy when deployed in real world applications. Annotatinglarge-scale high quality datasets is challenging. Typically, these datasetshave limited diversity; they do not reflect the real-world operatingenvironment. There is a need for a large-scale, cloud based positive andnegative mining (PNM) process and a large-scale learning and evaluation systemfor the application of traffic event detection. The proposed positive andnegative mining process addresses the quality of crowd sourced ground truthdata through machine learning review and human feedback mechanisms. Theproposed learning and evaluation system uses a distributed cloud computingframework to handle data-scaling issues associated with large numbers ofsamples and a high-dimensional feature space. The system is trained usingAdaBoost on $1,000,000$ Haar-like features extracted from $70,000$ annotatedvideo frames. The trained real-time vehicle detector achieves an accuracy of atleast $95\%$ for $1/2$ and about $78\%$ for $19/20$ of the time when tested onapproximately $7,500,000$ video frames. At the end of 2015, the dataset isexpect to have over one billion annotated video frames.
arxiv-13800-145 | Resolving References to Objects in Photographs using the Words-As-Classifiers Model | http://arxiv.org/pdf/1510.02125v2.pdf | author:David Schlangen, Sina Zarriess, Casey Kennington category:cs.CL published:2015-10-07 summary:A common use of language is to refer to visually present objects. Modellingit in computers requires modelling the link between language and perception.The "words as classifiers" model of grounded semantics views words asclassifiers of perceptual contexts, and composes the meaning of a phrasethrough composition of the denotations of its component words. It was recentlyshown to perform well in a game-playing scenario with a small number of objecttypes. We apply it to two large sets of real-world photographs that contain amuch larger variety of types and for which referring expressions are available.Using a pre-trained convolutional neural network to extract image features, andaugmenting these with in-picture positional information, we show that the modelachieves performance competitive with the state of the art in a referenceresolution task (given expression, find bounding box of its referent), while,as we argue, being conceptually simpler and more flexible.
arxiv-13800-146 | Stochastic Optimization for Deep CCA via Nonlinear Orthogonal Iterations | http://arxiv.org/pdf/1510.02054v1.pdf | author:Weiran Wang, Raman Arora, Karen Livescu, Nathan Srebro category:cs.LG published:2015-10-07 summary:Deep CCA is a recently proposed deep neural network extension to thetraditional canonical correlation analysis (CCA), and has been successful formulti-view representation learning in several domains. However, stochasticoptimization of the deep CCA objective is not straightforward, because it doesnot decouple over training examples. Previous optimizers for deep CCA areeither batch-based algorithms or stochastic optimization using largeminibatches, which can have high memory consumption. In this paper, we tacklethe problem of stochastic optimization for deep CCA with small minibatches,based on an iterative solution to the CCA objective, and show that we canachieve as good performance as previous optimizers and thus alleviate thememory requirement.
arxiv-13800-147 | Using Ontology-Based Context in the Portuguese-English Translation of Homographs in Textual Dialogues | http://arxiv.org/pdf/1510.01886v1.pdf | author:Diego Moussallem, Ricardo Choren category:cs.CL published:2015-10-07 summary:This paper introduces a novel approach to tackle the existing gap on messagetranslations in dialogue systems. Currently, submitted messages to the dialoguesystems are considered as isolated sentences. Thus, missing context informationimpede the disambiguation of homographs words in ambiguous sentences. Ourapproach solves this disambiguation problem by using concepts over existingontologies.
arxiv-13800-148 | Assisting Composition of Email Responses: a Topic Prediction Approach | http://arxiv.org/pdf/1510.02049v1.pdf | author:Spandana Gella, Marc Dymetman, Jean Michel Renders, Sriram Venkatapathy category:cs.CL published:2015-10-07 summary:We propose an approach for helping agents compose email replies to customerrequests. To enable that, we use LDA to extract latent topics from a collectionof email exchanges. We then use these latent topics to label our data,obtaining a so-called "silver standard" topic labelling. We exploit thislabelled set to train a classifier to: (i) predict the topic distribution ofthe entire agent's email response, based on features of the customer's email;and (ii) predict the topic distribution of the next sentence in the agent'sreply, based on the customer's email features and on features of the agent'scurrent sentence. The experimental results on a large email collection from acontact center in the tele- com domain show that the proposed ap- proach iseffective in predicting the best topic of the agent's next sentence. In 80% ofthe cases, the correct topic is present among the top five recommended topics(out of fifty possible ones). This shows the potential of this method to beapplied in an interactive setting, where the agent is presented a small list oflikely topics to choose from for the next sentence.
arxiv-13800-149 | Event-based Camera Pose Tracking using a Generative Event Model | http://arxiv.org/pdf/1510.01972v1.pdf | author:Guillermo Gallego, Christian Forster, Elias Mueggler, Davide Scaramuzza category:cs.CV cs.RO published:2015-10-07 summary:Event-based vision sensors mimic the operation of biological retina and theyrepresent a major paradigm shift from traditional cameras. Instead of providingframes of intensity measurements synchronously, at artificially chosen rates,event-based cameras provide information on brightness changes asynchronously,when they occur. Such non-redundant pieces of information are called "events".These sensors overcome some of the limitations of traditional cameras (responsetime, bandwidth and dynamic range) but require new methods to deal with thedata they output. We tackle the problem of event-based camera localization in aknown environment, without additional sensing, using a probabilistic generativeevent model in a Bayesian filtering framework. Our main contribution is thedesign of the likelihood function used in the filter to process the observedevents. Based on the physical characteristics of the sensor and on empiricalevidence of the Gaussian-like distribution of spiked events with respect to thebrightness change, we propose to use the contrast residual as a measure of howwell the estimated pose of the event-based camera and the environment explainthe observed events. The filter allows for localization in the general case ofsix degrees-of-freedom motions.
arxiv-13800-150 | Asymptotically Optimal Sequential Experimentation Under Generalized Ranking | http://arxiv.org/pdf/1510.02041v3.pdf | author:Wesley Cowan, Michael N. Katehakis category:stat.ML published:2015-10-07 summary:We consider the \mnk{classical} problem of a controller activating (orsampling) sequentially from a finite number of $N \geq 2$ populations,specified by unknown distributions. Over some time horizon, at each time $n =1, 2, \ldots$, the controller wishes to select a population to sample, with thegoal of sampling from a population that optimizes some "score" function of itsdistribution, e.g., maximizing the expected sum of outcomes or minimizingvariability. We define a class of \textit{Uniformly Fast (UF)} samplingpolicies and show, under mild regularity conditions, that there is anasymptotic lower bound for the expected total number of sub-optimal populationactivations. Then, we provide sufficient conditions under which a UCB policy isUF and asymptotically optimal, since it attains this lower bound. Explicitsolutions are provided for a number of examples of interest, including generalscore functionals on unconstrained Pareto distributions (of potentiallyinfinite mean), and uniform distributions of unknown support. Additionalresults on bandits of Normal distributions are also provided.
arxiv-13800-151 | Hierarchical Representation of Prosody for Statistical Speech Synthesis | http://arxiv.org/pdf/1510.01949v1.pdf | author:Antti Suni, Daniel Aalto, Martti Vainio category:cs.CL cs.SD published:2015-10-07 summary:Prominences and boundaries are the essential constituents of prosodicstructure in speech. They provide for means to chunk the speech stream intolinguistically relevant units by providing them with relative saliences anddemarcating them within coherent utterance structures. Prominences andboundaries have both been widely used in both basic research on prosody as wellas in text-to-speech synthesis. However, there are no representation schemesthat would provide for both estimating and modelling them in a unified fashion.Here we present an unsupervised unified account for estimating and representingprosodic prominences and boundaries using a scale-space analysis based oncontinuous wavelet transform. The methods are evaluated and compared to earlierwork using the Boston University Radio News corpus. The results show that theproposed method is comparable with the best published supervised annotationmethods.
arxiv-13800-152 | Helping Domain Experts Build Speech Translation Systems | http://arxiv.org/pdf/1510.01942v1.pdf | author:Manny Rayner, Alejandro Armando, Pierrette Bouillon, Sarah Ebling, Johanna Gerlach, Sonia Halimi, Irene Strasly, Nikos Tsourakis category:cs.HC cs.CL published:2015-10-07 summary:We present a new platform, "Regulus Lite", which supports rapid developmentand web deployment of several types of phrasal speech translation systems usinga minimal formalism. A distinguishing feature is that most development work canbe performed directly by domain experts. We motivate the need for platforms ofthis type and discuss three specific cases: medical speech translation,speech-to-sign-language translation and voice questionnaires. We brieflydescribe initial experiences in developing practical systems.
arxiv-13800-153 | Stochastic subGradient Methods with Linear Convergence for Polyhedral Convex Optimization | http://arxiv.org/pdf/1510.01444v5.pdf | author:Tianbao Yang, Qihang Lin category:cs.LG math.OC published:2015-10-06 summary:In this paper, we show that simple {Stochastic} subGradient Decent methodswith multiple Restarting, named {\bf RSGD}, can achieve a \textit{linearconvergence rate} for a class of non-smooth and non-strongly convexoptimization problems where the epigraph of the objective function is apolyhedron, to which we refer as {\bf polyhedral convex optimization}. Itsapplications in machine learning include $\ell_1$ constrained or regularizedpiecewise linear loss minimization and submodular function minimization. To thebest of our knowledge, this is the first result on the linear convergence rateof stochastic subgradient methods for non-smooth and non-strongly convexoptimization problems.
arxiv-13800-154 | Population-Contrastive-Divergence: Does Consistency help with RBM training? | http://arxiv.org/pdf/1510.01624v3.pdf | author:Oswin Krause, Asja Fischer, Christian Igel category:cs.LG cs.NE stat.ML published:2015-10-06 summary:Estimating the log-likelihood gradient with respect to the parameters of aRestricted Boltzmann Machine (RBM) typically requires sampling using MarkovChain Monte Carlo (MCMC) techniques. To save computation time, the Markovchains are only run for a small number of steps, which leads to a biasedestimate. This bias can cause RBM training algorithms such as ContrastiveDivergence (CD) learning to deteriorate. We adopt the idea behind PopulationMonte Carlo (PMC) methods to devise a new RBM training algorithm termedPopulation-Contrastive-Divergence (pop-CD). Compared to CD, it leads to aconsistent estimate and may have a significantly lower bias. Its computationaloverhead is negligible compared to CD. However, the variance of the gradientestimate increases. We experimentally show that pop-CD can significantlyoutperform CD. In many cases, we observed a smaller bias and achieved higherlog-likelihood values. However, when the RBM distribution has many hiddenneurons, the consistent estimate of pop-CD may still have a considerable biasand the variance of the gradient estimate requires a smaller learning rate.Thus, despite its superior theoretical properties, it is not advisable to usepop-CD in its current form on large problems.
arxiv-13800-155 | SentiCap: Generating Image Descriptions with Sentiments | http://arxiv.org/pdf/1510.01431v2.pdf | author:Alexander Mathews, Lexing Xie, Xuming He category:cs.CV cs.CL published:2015-10-06 summary:The recent progress on image recognition and language modeling is makingautomatic description of image content a reality. However, stylized,non-factual aspects of the written description are missing from the currentsystems. One such style is descriptions with emotions, which is commonplace ineveryday communication, and influences decision-making and interpersonalrelationships. We design a system to describe an image with emotions, andpresent a model that automatically generates captions with positive or negativesentiments. We propose a novel switching recurrent neural network withword-level regularization, which is able to produce emotional image captionsusing only 2000+ training sentences containing sentiments. We evaluate thecaptions with different automatic and crowd-sourcing metrics. Our modelcompares favourably in common quality metrics for image captioning. In 84.6% ofcases the generated positive captions were judged as being at least asdescriptive as the factual captions. Of these positive captions 88% wereconfirmed by the crowd-sourced workers as having the appropriate sentiment.
arxiv-13800-156 | Quantifying Emergent Behavior of Autonomous Robots | http://arxiv.org/pdf/1510.01495v1.pdf | author:Georg Martius, Eckehard Olbrich category:cs.IT cs.LG cs.RO math.DS math.IT H.1.1; I.2.9 published:2015-10-06 summary:Quantifying behaviors of robots which were generated autonomously fromtask-independent objective functions is an important prerequisite for objectivecomparisons of algorithms and movements of animals. The temporal sequence ofsuch a behavior can be considered as a time series and hence complexitymeasures developed for time series are natural candidates for itsquantification. The predictive information and the excess entropy are suchcomplexity measures. They measure the amount of information the past containsabout the future and thus quantify the nonrandom structure in the temporalsequence. However, when using these measures for systems with continuous statesone has to deal with the fact that their values will depend on the resolutionwith which the systems states are observed. For deterministic systems bothmeasures will diverge with increasing resolution. We therefore propose a newdecomposition of the excess entropy in resolution dependent and resolutionindependent parts and discuss how they depend on the dimensionality of thedynamics, correlations and the noise level. For the practical estimation wepropose to use estimates based on the correlation integral instead of thedirect estimation of the mutual information using the algorithm by Kraskov etal. (2004) which is based on next neighbor statistics because the latter allowsless control of the scale dependencies. Using our algorithm we are able to showhow autonomous learning generates behavior of increasing complexity withincreasing learning duration.
arxiv-13800-157 | Directional Global Three-part Image Decomposition | http://arxiv.org/pdf/1510.01490v1.pdf | author:Duy Hoang Thai, Carsten Gottschlich category:cs.CV published:2015-10-06 summary:We consider the task of image decomposition and we introduce a new modelcoined directional global three-part decomposition (DG3PD) for solving it. Askey ingredients of the DG3PD model, we introduce a discrete multi-directionaltotal variation norm and a discrete multi-directional G-norm. Using these novelnorms, the proposed discrete DG3PD model can decompose an image into two partsor into three parts. Existing models for image decomposition by Vese and Osher,by Aujol and Chambolle, by Starck et al., and by Thai and Gottschlich areincluded as special cases in the new model. Decomposition of an image by DG3PDresults in a cartoon image, a texture image and a residual image. Advantages ofthe DG3PD model over existing ones lie in the properties enforced on thecartoon and texture images. The geometric objects in the cartoon image have avery smooth surface and sharp edges. The texture image yields oscillatingpatterns on a defined scale which is both smooth and sparse. Moreover, theDG3PD method achieves the goal of perfect reconstruction by summation of allcomponents better than the other considered methods. Relevant applications ofDG3PD are a novel way of image compression as well as feature extraction forapplications such as latent fingerprint processing and optical characterrecognition.
arxiv-13800-158 | Bayesian Markov Blanket Estimation | http://arxiv.org/pdf/1510.01485v1.pdf | author:Dinu Kaufmann, Sonali Parbhoo, Aleksander Wieczorek, Sebastian Keller, David Adametz, Volker Roth category:stat.ML cs.LG published:2015-10-06 summary:This paper considers a Bayesian view for estimating a sub-network in a Markovrandom field. The sub-network corresponds to the Markov blanket of a set ofquery variables, where the set of potential neighbours here is big. Wefactorize the posterior such that the Markov blanket is conditionallyindependent of the network of the potential neighbours. By exploiting thisblockwise decoupling, we derive analytic expressions for posteriorconditionals. Subsequently, we develop an inference scheme which makes use ofthe factorization. As a result, estimation of a sub-network is possible withoutinferring an entire network. Since the resulting Gibbs sampler scales linearlywith the number of variables, it can handle relatively large neighbourhoods.The proposed scheme results in faster convergence and superior mixing of theMarkov chain than existing Bayesian network estimation techniques.
arxiv-13800-159 | Local Rademacher Complexity Bounds based on Covering Numbers | http://arxiv.org/pdf/1510.01463v1.pdf | author:Yunwen Lei, Lixin Ding, Yingzhou Bi category:cs.AI cs.LG stat.ML published:2015-10-06 summary:This paper provides a general result on controlling local Rademachercomplexities, which captures in an elegant form to relate the complexities withconstraint on the expected norm to the corresponding ones with constraint onthe empirical norm. This result is convenient to apply in real applications andcould yield refined local Rademacher complexity bounds for function classessatisfying general entropy conditions. We demonstrate the power of ourcomplexity bounds by applying them to derive effective generalization errorbounds.
arxiv-13800-160 | Structured Transforms for Small-Footprint Deep Learning | http://arxiv.org/pdf/1510.01722v1.pdf | author:Vikas Sindhwani, Tara N. Sainath, Sanjiv Kumar category:stat.ML cs.CV cs.LG published:2015-10-06 summary:We consider the task of building compact deep learning pipelines suitable fordeployment on storage and power constrained mobile devices. We propose aunified framework to learn a broad family of structured parameter matrices thatare characterized by the notion of low displacement rank. Our structuredtransforms admit fast function and gradient evaluation, and span a rich rangeof parameter sharing configurations whose statistical modeling capacity can beexplicitly tuned along a continuum from structured to unstructured.Experimental results show that these transforms can significantly accelerateinference and forward/backward passes during training, and offer superioraccuracy-compactness-speed tradeoffs in comparison to a number of existingtechniques. In keyword spotting applications in mobile speech recognition, ourmethods are much more effective than standard linear low-rank bottleneck layersand nearly retain the performance of state of the art models, while providingmore than 3.5-fold compression.
arxiv-13800-161 | Language Segmentation | http://arxiv.org/pdf/1510.01717v1.pdf | author:David Alfter category:cs.CL published:2015-10-06 summary:Language segmentation consists in finding the boundaries where one languageends and another language begins in a text written in more than one language.This is important for all natural language processing tasks. The problem can besolved by training language models on language data. However, in the case oflow- or no-resource languages, this is problematic. I therefore investigatewhether unsupervised methods perform better than supervised methods when it isdifficult or impossible to train supervised approaches. A special focus isgiven to difficult texts, i.e. texts that are rather short (one sentence),containing abbreviations, low-resource languages and non-standard language. Icompare three approaches: supervised n-gram language models, unsupervisedclustering and weakly supervised n-gram language model induction. I devised theweakly supervised approach in order to deal with difficult text specifically.In order to test the approach, I compiled a small corpus of different texttypes, ranging from one-sentence texts to texts of about 300 words. The weaklysupervised language model induction approach works well on short and difficulttexts, outperforming the clustering algorithm and reaching scores in thevicinity of the supervised approach. The results look promising, but there isroom for improvement and a more thorough investigation should be undertaken.
arxiv-13800-162 | A Waveform Representation Framework for High-quality Statistical Parametric Speech Synthesis | http://arxiv.org/pdf/1510.01443v1.pdf | author:Bo Fan, Siu Wa Lee, Xiaohai Tian, Lei Xie, Minghui Dong category:cs.SD cs.LG 68T10 published:2015-10-06 summary:State-of-the-art statistical parametric speech synthesis (SPSS) generallyuses a vocoder to represent speech signals and parameterize them into featuresfor subsequent modeling. Magnitude spectrum has been a dominant feature overthe years. Although perceptual studies have shown that phase spectrum isessential to the quality of synthesized speech, it is often ignored by using aminimum phase filter during synthesis and the speech quality suffers. To bypassthis bottleneck in vocoded speech, this paper proposes a phase-embeddedwaveform representation framework and establishes a magnitude-phase jointmodeling platform for high-quality SPSS. Our experiments on waveformreconstruction show that the performance is better than that of the widely-usedSTRAIGHT. Furthermore, the proposed modeling and synthesis platform outperformsa leading-edge, vocoded, deep bidirectional long short-term memory recurrentneural network (DBLSTM-RNN)-based baseline system in various objectiveevaluation metrics conducted.
arxiv-13800-163 | Euclidean Auto Calibration of Camera Networks: Baseline Constraint Removes Scale Ambiguity | http://arxiv.org/pdf/1510.01663v1.pdf | author:Kiran Kumar Vupparaboina, Kamala Raghavan, Soumya Jana category:cs.CV published:2015-10-06 summary:Metric auto calibration of a camera network from multiple views has beenreported by several authors. Resulting 3D reconstruction recovers shapefaithfully, but not scale. However, preservation of scale becomes critical inapplications, such as multi-party telepresence, where multiple 3D scenes needto be fused into a single coordinate system. In this context, we propose acamera network configuration that includes a stereo pair with known baselineseparation, and analytically demonstrate Euclidean auto calibration of suchnetwork under mild conditions. Further, we experimentally validate our theoryusing a four-camera network. Importantly, our method not only recovers scale,but also compares favorably with the well known Zhang and Pollefeys methods interms of shape recovery.
arxiv-13800-164 | A Latent Source Model for Patch-Based Image Segmentation | http://arxiv.org/pdf/1510.01648v1.pdf | author:George Chen, Devavrat Shah, Polina Golland category:cs.CV published:2015-10-06 summary:Despite the popularity and empirical success of patch-based nearest-neighborand weighted majority voting approaches to medical image segmentation, therehas been no theoretical development on when, why, and how well thesenonparametric methods work. We bridge this gap by providing a theoreticalperformance guarantee for nearest-neighbor and weighted majority votingsegmentation under a new probabilistic model for patch-based imagesegmentation. Our analysis relies on a new local property for how similarnearby patches are, and fuses existing lines of work on modeling naturalimagery patches and theory for nonparametric classification. We use the modelto derive a new patch-based segmentation algorithm that iterates betweeninferring local label patches and merging these local segmentations to producea globally consistent image segmentation. Many existing patch-based algorithmsarise as special cases of the new algorithm.
arxiv-13800-165 | DC Decomposition of Nonconvex Polynomials with Algebraic Techniques | http://arxiv.org/pdf/1510.01518v1.pdf | author:Amir Ali Ahmadi, Georgina Hall category:math.OC cs.DS stat.ML published:2015-10-06 summary:We consider the problem of decomposing a multivariate polynomial as thedifference of two convex polynomials. We introduce algebraic techniques whichreduce this task to linear, second order cone, and semidefinite programming.This allows us to optimize over subsets of valid difference of convexdecompositions (dcds) and find ones that speed up the convex-concave procedure(CCP). We prove, however, that optimizing over the entire set of dcds isNP-hard.
arxiv-13800-166 | Large-scale subspace clustering using sketching and validation | http://arxiv.org/pdf/1510.01628v1.pdf | author:Panagiotis A. Traganitis, Konstantinos Slavakis, Georgios B. Giannakis category:cs.LG cs.CV stat.ML published:2015-10-06 summary:The nowadays massive amounts of generated and communicated data present majorchallenges in their processing. While capable of successfully classifyingnonlinearly separable objects in various settings, subspace clustering (SC)methods incur prohibitively high computational complexity when processinglarge-scale data. Inspired by the random sampling and consensus (RANSAC)approach to robust regression, the present paper introduces a randomized schemefor SC, termed sketching and validation (SkeVa-)SC, tailored for large-scaledata. At the heart of SkeVa-SC lies a randomized scheme for approximating theunderlying probability density function of the observed data by kernelsmoothing arguments. Sparsity in data representations is also exploited toreduce the computational burden of SC, while achieving high clusteringaccuracy. Performance analysis as well as extensive numerical tests onsynthetic and real data corroborate the potential of SkeVa-SC and itscompetitive performance relative to state-of-the-art scalable SC approaches.Keywords: Subspace clustering, big data, kernel smoothing, randomization,sketching, validation, sparsity.
arxiv-13800-167 | Unsupervised Extraction of Video Highlights Via Robust Recurrent Auto-encoders | http://arxiv.org/pdf/1510.01442v1.pdf | author:Huan Yang, Baoyuan Wang, Stephen Lin, David Wipf, Minyi Guo, Baining Guo category:cs.CV published:2015-10-06 summary:With the growing popularity of short-form video sharing platforms such as\em{Instagram} and \em{Vine}, there has been an increasing need for techniquesthat automatically extract highlights from video. Whereas prior works haveapproached this problem with heuristic rules or supervised learning, we presentan unsupervised learning approach that takes advantage of the abundance ofuser-edited videos on social media websites such as YouTube. Based on the ideathat the most significant sub-events within a video class are commonly presentamong edited videos while less interesting ones appear less frequently, weidentify the significant sub-events via a robust recurrent auto-encoder trainedon a collection of user-edited videos queried for each particular class ofinterest. The auto-encoder is trained using a proposed shrinking exponentialloss function that makes it robust to noise in the web-crawled training data,and is configured with bidirectional long short term memory(LSTM)~\cite{LSTM:97} cells to better model the temporal structure of highlightsegments. Different from supervised techniques, our method can infer highlightsusing only a set of downloaded edited videos, without also needing theirpre-edited counterparts which are rarely available online. Extensiveexperiments indicate the promise of our proposed solution in this challengingunsupervised settin
arxiv-13800-168 | Harvesting Discriminative Meta Objects with Deep CNN Features for Scene Classification | http://arxiv.org/pdf/1510.01440v1.pdf | author:Ruobing Wu, Baoyuan Wang, Wenping Wang, Yizhou Yu category:cs.CV published:2015-10-06 summary:Recent work on scene classification still makes use of generic CNN featuresin a rudimentary manner. In this ICCV 2015 paper, we present a novel pipelinebuilt upon deep CNN features to harvest discriminative visual objects and partsfor scene classification. We first use a region proposal technique to generatea set of high-quality patches potentially containing objects, and apply apre-trained CNN to extract generic deep features from these patches. Then weperform both unsupervised and weakly supervised learning to screen thesepatches and discover discriminative ones representing category-specific objectsand parts. We further apply discriminative clustering enhanced with local CNNfine-tuning to aggregate similar objects and parts into groups, called metaobjects. A scene image representation is constructed by pooling the featureresponse maps of all the learned meta objects at multiple spatial scales. Wehave confirmed that the scene image representation obtained using this newpipeline is capable of delivering state-of-the-art performance on two popularscene benchmark datasets, MIT Indoor 67~\cite{MITIndoor67} andSun397~\cite{Sun397}
arxiv-13800-169 | Improved Estimation of Class Prior Probabilities through Unlabeled Data | http://arxiv.org/pdf/1510.01422v1.pdf | author:Norman Matloff category:stat.ML cs.LG published:2015-10-06 summary:Work in the classification literature has shown that in computing aclassification function, one need not know the class membership of allobservations in the training set; the unlabeled observations still provideinformation on the marginal distribution of the feature set, and can thuscontribute to increased classification accuracy for future observations. Thepresent paper will show that this scheme can also be used for the estimation ofclass prior probabilities, which would be very useful in applications in whichit is difficult or expensive to determine class membership. Both parametric andnonparametric estimators are developed. Asymptotic distributions of theestimators are derived, and it is proven that the use of the unlabeledobservations does reduce asymptotic variance. This methodology is also extendedto the estimation of subclass probabilities.
arxiv-13800-170 | Predicting Daily Activities From Egocentric Images Using Deep Learning | http://arxiv.org/pdf/1510.01576v1.pdf | author:Daniel Castro, Steven Hickson, Vinay Bettadapura, Edison Thomaz, Gregory Abowd, Henrik Christensen, Irfan Essa category:cs.CV I.5; J.4; J.3 published:2015-10-06 summary:We present a method to analyze images taken from a passive egocentricwearable camera along with the contextual information, such as time and day ofweek, to learn and predict everyday activities of an individual. We collected adataset of 40,103 egocentric images over a 6 month period with 19 activityclasses and demonstrate the benefit of state-of-the-art deep learningtechniques for learning and predicting daily activities. Classification isconducted using a Convolutional Neural Network (CNN) with a classificationmethod we introduce called a late fusion ensemble. This late fusion ensembleincorporates relevant contextual information and increases our classificationaccuracy. Our technique achieves an overall accuracy of 83.07% in predicting aperson's activity across the 19 activity classes. We also demonstrate somepromising results from two additional users by fine-tuning the classifier withone day of training data.
arxiv-13800-171 | Analyzer and generator for Pali | http://arxiv.org/pdf/1510.01570v1.pdf | author:David Alfter category:cs.CL published:2015-10-06 summary:This work describes a system that performs morphological analysis andgeneration of Pali words. The system works with regular inflectional paradigmsand a lexical database. The generator is used to build a collection ofinflected and derived words, which in turn is used by the analyzer. Generatingand storing morphological forms along with the corresponding morphologicalinformation allows for efficient and simple look up by the analyzer. Indeed, bylooking up a word and extracting the attached morphological information, theanalyzer does not have to compute this information. As we must, however, assumethe lexical database to be incomplete, the system can also work without thedictionary component, using a rule-based approach.
arxiv-13800-172 | Active Transfer Learning with Zero-Shot Priors: Reusing Past Datasets for Future Tasks | http://arxiv.org/pdf/1510.01544v1.pdf | author:Efstratios Gavves, Thomas Mensink, Tatiana Tommasi, Cees G. M. Snoek, Tinne Tuytelaars category:cs.CV published:2015-10-06 summary:How can we reuse existing knowledge, in the form of available datasets, whensolving a new and apparently unrelated target task from a set of unlabeleddata? In this work we make a first contribution to answer this question in thecontext of image classification. We frame this quest as an active learningproblem and use zero-shot classifiers to guide the learning process by linkingthe new task to the existing classifiers. By revisiting the dual formulation ofadaptive SVM, we reveal two basic conditions to choose greedily only the mostrelevant samples to be annotated. On this basis we propose an effective activelearning algorithm which learns the best possible target classification modelwith minimum human labeling effort. Extensive experiments on two challengingdatasets show the value of our approach compared to the state-of-the-art activelearning methodologies, as well as its potential to reuse past datasets withminimal effort for future tasks.
arxiv-13800-173 | Parameterized Neural Network Language Models for Information Retrieval | http://arxiv.org/pdf/1510.01562v1.pdf | author:Benjamin Piwowarski, Sylvain Lamprier, Nicolas Despres category:cs.IR cs.CL H.3.3; I.2.6 published:2015-10-06 summary:Information Retrieval (IR) models need to deal with two difficult issues,vocabulary mismatch and term dependencies. Vocabulary mismatch corresponds tothe difficulty of retrieving relevant documents that do not contain exact queryterms but semantically related terms. Term dependencies refers to the need ofconsidering the relationship between the words of the query when estimating therelevance of a document. A multitude of solutions has been proposed to solveeach of these two problems, but no principled model solve both. In parallel, inthe last few years, language models based on neural networks have been used tocope with complex natural language processing tasks like emotion and paraphrasedetection. Although they present good abilities to cope with both termdependencies and vocabulary mismatch problems, thanks to the distributedrepresentation of words they are based upon, such models could not be usedreadily in IR, where the estimation of one language model per document (orquery) is required. This is both computationally unfeasible and prone toover-fitting. Based on a recent work that proposed to learn a generic languagemodel that can be modified through a set of document-specific parameters, weexplore use of new neural network models that are adapted to ad-hoc IR tasks.Within the language model IR framework, we propose and study the use of ageneric language model as well as a document-specific language model. Both canbe used as a smoothing component, but the latter is more adapted to thedocument at hand and has the potential of being used as a full documentlanguage model. We experiment with such models and analyze their results onTREC-1 to 8 datasets.
arxiv-13800-174 | On the Existence of Epipolar Matrices | http://arxiv.org/pdf/1510.01401v1.pdf | author:Sameer Agarwal, Hon-Leung Lee, Bernd Sturmfels, Rekha R. Thomas category:cs.CV math.AG published:2015-10-06 summary:This paper considers the foundational question of the existence of afundamental (resp. essential) matrix given $m$ point correspondences in twoviews. We present a complete answer for the existence of fundamental matricesfor any value of $m$. Using examples we disprove the widely held beliefs thatfundamental matrices always exist whenever $m \leq 7$. At the same time, weprove that they exist unconditionally when $m \leq 5$. Under a mild genericitycondition, we show that an essential matrix always exists when $m \leq 4$. Wealso characterize the six and seven point configurations in two views for whichall matrices satisfying the epipolar constraint have rank at most one.
arxiv-13800-175 | Learning Deep Representations of Appearance and Motion for Anomalous Event Detection | http://arxiv.org/pdf/1510.01553v1.pdf | author:Dan Xu, Elisa Ricci, Yan Yan, Jingkuan Song, Nicu Sebe category:cs.CV published:2015-10-06 summary:We present a novel unsupervised deep learning framework for anomalous eventdetection in complex video scenes. While most existing works merely usehand-crafted appearance and motion features, we propose Appearance and MotionDeepNet (AMDN) which utilizes deep neural networks to automatically learnfeature representations. To exploit the complementary information of bothappearance and motion patterns, we introduce a novel double fusion framework,combining both the benefits of traditional early fusion and late fusionstrategies. Specifically, stacked denoising autoencoders are proposed toseparately learn both appearance and motion features as well as a jointrepresentation (early fusion). Based on the learned representations, multipleone-class SVM models are used to predict the anomaly scores of each input,which are then integrated with a late fusion strategy for final anomalydetection. We evaluate the proposed method on two publicly available videosurveillance datasets, showing competitive performance with respect to state ofthe art approaches.
arxiv-13800-176 | Relaxed Multiple-Instance SVM with Application to Object Discovery | http://arxiv.org/pdf/1510.01027v1.pdf | author:Xinggang Wang, Zhuotun Zhu, Cong Yao, Xiang Bai category:cs.CV cs.LG published:2015-10-05 summary:Multiple-instance learning (MIL) has served as an important tool for a widerange of vision applications, for instance, image classification, objectdetection, and visual tracking. In this paper, we propose a novel method tosolve the classical MIL problem, named relaxed multiple-instance SVM (RMI-SVM).We treat the positiveness of instance as a continuous variable, use Noisy-ORmodel to enforce the MIL constraints, and jointly optimize the bag label andinstance label in a unified framework. The optimization problem can beefficiently solved using stochastic gradient decent. The extensive experimentsdemonstrate that RMI-SVM consistently achieves superior performance on variousbenchmarks for MIL. Moreover, we simply applied RMI-SVM to a challenging visiontask, common object discovery. The state-of-the-art results of object discoveryon Pascal VOC datasets further confirm the advantages of the proposed method.
arxiv-13800-177 | Calculating entropy at different scales among diverse communication systems | http://arxiv.org/pdf/1510.01026v1.pdf | author:Gerardo Febres, Klaus Jaffe category:cs.IT cs.CL math.IT published:2015-10-05 summary:We evaluated the impact of changing the observation scale over the entropymeasures for text descriptions. MIDI coded Music, computer code and two humannatural languages were studied at the scale of characters, words, and at theFundamental Scale resulting from adjusting the symbols length used to interpreteach text-description until it produced minimum entropy. The results show thatthe Fundamental Scale method is comparable with the use of words when measuringentropy levels in written texts. However, this method can also be used incommunication systems lacking words such as music. Measuring symbolic entropyat the fundamental scale allows to calculate quantitatively, relative levels ofcomplexity for different communication systems. The results open novel visionon differences among the structure of the communication systems studied.
arxiv-13800-178 | GPU-Based Computation of 2D Least Median of Squares with Applications to Fast and Robust Line Detection | http://arxiv.org/pdf/1510.01041v1.pdf | author:Gil Shapira, Tal Hassner category:cs.CV published:2015-10-05 summary:The 2D Least Median of Squares (LMS) is a popular tool in robust regressionbecause of its high breakdown point: up to half of the input data can becontaminated with outliers without affecting the accuracy of the LMS estimator.The complexity of 2D LMS estimation has been shown to be $\Omega(n^2)$ where$n$ is the total number of points. This high theoretical complexity along withthe availability of graphics processing units (GPU) motivates the developmentof a fast, parallel, GPU-based algorithm for LMS computation. We present a CUDAbased algorithm for LMS computation and show it to be much faster than theoptimal state of the art single threaded CPU algorithm. We begin by describingthe proposed method and analyzing its performance. We then demonstrate how itcan be used to modify the well-known Hough Transform (HT) in order toefficiently detect image lines in noisy images. Our method is compared withstandard HT-based line detection methods and shown to overcome theirshortcomings in terms of both efficiency and accuracy.
arxiv-13800-179 | Boosting in the presence of outliers: adaptive classification with non-convex loss functions | http://arxiv.org/pdf/1510.01064v1.pdf | author:Alexander Hanbo Li, Jelena Bradic category:stat.ML cs.LG math.ST stat.TH published:2015-10-05 summary:This paper examines the role and efficiency of the non-convex loss functionsfor binary classification problems. In particular, we investigate how to designa simple and effective boosting algorithm that is robust to the outliers in thedata. The analysis of the role of a particular non-convex loss for predictionaccuracy varies depending on the diminishing tail properties of the gradient ofthe loss -- the ability of the loss to efficiently adapt to the outlying data,the local convex properties of the loss and the proportion of the contaminateddata. In order to use these properties efficiently, we propose a new family ofnon-convex losses named $\gamma$-robust losses. Moreover, we present a newboosting framework, {\it Arch Boost}, designed for augmenting the existing worksuch that its corresponding classification algorithm is significantly moreadaptable to the unknown data contamination. Along with the Arch Boostingframework, the non-convex losses lead to the new class of boosting algorithms,named adaptive, robust, boosting (ARB). Furthermore, we present theoreticalexamples that demonstrate the robustness properties of the proposed algorithms.In particular, we develop a new breakdown point analysis and a new influencefunction analysis that demonstrate gains in robustness. Moreover, we presentnew theoretical results, based only on local curvatures, which may be used toestablish statistical and optimization properties of the proposed Arch boostingalgorithms with highly non-convex loss functions. Extensive numericalcalculations are used to illustrate these theoretical properties and revealadvantages over the existing boosting methods when data exhibits a number ofoutliers.
arxiv-13800-180 | Quadratic Optimization with Orthogonality Constraints: Explicit Lojasiewicz Exponent and Linear Convergence of Line-Search Methods | http://arxiv.org/pdf/1510.01025v1.pdf | author:Huikang Liu, Weijie Wu, Anthony Man-Cho So category:math.OC cs.LG cs.NA math.NA published:2015-10-05 summary:A fundamental class of matrix optimization problems that arise in many areasof science and engineering is that of quadratic optimization with orthogonalityconstraints. Such problems can be solved using line-search methods on theStiefel manifold, which are known to converge globally under mild conditions.To determine the convergence rate of these methods, we give an explicitestimate of the exponent in a Lojasiewicz inequality for the (non-convex) setof critical points of the aforementioned class of problems. By combining suchan estimate with known arguments, we are able to establish the linearconvergence of a large class of line-search methods. A key step in our proof isto establish a local error bound for the set of critical points, which may beof independent interest.
arxiv-13800-181 | Single Image Dehazing through Improved Atmospheric Light Estimation | http://arxiv.org/pdf/1510.01018v1.pdf | author:Huimin Lu, Yujie Li, Shota Nakashima, Seiichi Serikawa category:cs.CV published:2015-10-05 summary:Image contrast enhancement for outdoor vision is important for smart carauxiliary transport systems. The video frames captured in poor weatherconditions are often characterized by poor visibility. Most image dehazingalgorithms consider to use a hard threshold assumptions or user input toestimate atmospheric light. However, the brightest pixels sometimes are objectssuch as car lights or streetlights, especially for smart car auxiliarytransport systems. Simply using a hard threshold may cause a wrong estimation.In this paper, we propose a single optimized image dehazing method thatestimates atmospheric light efficiently and removes haze through the estimationof a semi-globally adaptive filter. The enhanced images are characterized withlittle noise and good exposure in dark regions. The textures and edges of theprocessed images are also enhanced significantly.
arxiv-13800-182 | Accuracy of Bayesian Latent Variable Estimation with Redundant Dimension | http://arxiv.org/pdf/1510.01003v1.pdf | author:Keisuke Yamazaki category:stat.ML published:2015-10-05 summary:Hierarchical learning models such as mixture models and Bayesian networks arewidely employed for unsupervised learning tasks such as clustering analysis.They consist of two variables: observable and hidden variables, which representthe given data and their hidden generation process, respectively. It has beenpointed out that the conventional statistical analysis is not applicable tothese models because singularities exist in the parameter space. In recentyears, a method based on algebraic geometry allows us to analyze accuracy ofobservable variable prediction on the Bayes estimation. However, analysis forthe latent variable has not been studied well though one of the main issues inunsupervised learning is how precisely the latent variable is estimated. Aprevious study proposed a method for the latent variable when the range of alatent variable has redundancy compared with the model generating data. Thepresent paper extends the method to another redundancy; there are redundantlatent variables instead of the variable range. We formulate two types of theerror function, and derive the asymptotic forms of both types. Moreover,calculation on the error functions is demonstrated in two-layered Bayesiannetworks.
arxiv-13800-183 | Nonlinear Spectral Analysis via One-homogeneous Functionals - Overview and Future Prospects | http://arxiv.org/pdf/1510.01077v1.pdf | author:Guy Gilboa, Michael Moeller, Martin Burger category:math.SP cs.CV cs.NA math.NA published:2015-10-05 summary:We present in this paper the motivation and theory of nonlinear spectralrepresentations, based on convex regularizing functionals. Some comparisons andanalogies are drawn to the fields of signal processing, harmonic analysis andsparse representations. The basic approach, main results and initialapplications are shown. A discussion of open problems and future directionsconcludes this work.
arxiv-13800-184 | Bregman Iteration for Correspondence Problems: A Study of Optical Flow | http://arxiv.org/pdf/1510.01130v1.pdf | author:Laurent Hoeltgen, Michael Breuß category:math.OC cs.CV 65Kxx, 65Nxx published:2015-10-05 summary:Bregman iterations are known to yield excellent results for denoising,deblurring and compressed sensing tasks, but so far this technique has rarelybeen used for other image processing problems. In this paper we give a thoroughdescription of the Bregman iteration, unifying thereby results of differentauthors within a common framework. Then we show how to adapt the split Bregmaniteration, originally developed by Goldstein and Osher for image restorationpurposes, to optical flow which is a fundamental correspondence problem incomputer vision. We consider some classic and modern optical flow models andpresent detailed algorithms that exhibit the benefits of the Bregman iteration.By making use of the results of the Bregman framework, we address the issues ofconvergence and error estimation for the algorithms. Numerical examplescomplement the theoretical part.
arxiv-13800-185 | Convergence Analysis of a Stochastic Projection-free Algorithm | http://arxiv.org/pdf/1510.01171v1.pdf | author:Jean Lafond, Hoi-To Wai, Eric Moulines category:stat.ML cs.LG published:2015-10-05 summary:This paper presents and analyzes a stochastic version of the Frank-Wolfealgorithm (a.k.a. conditional gradient method or projection-free algorithm) forconstrained convex optimization. We first prove that when the quality ofgradient estimate improves as ${\cal O}( \sqrt{ \eta_t^{\Delta} / t } )$, where$t$ is the iteration index and $\eta_t^{\Delta}$ is an increasing sequence,then the objective value of the stochastic Frank-Wolfe algorithm converges inat least the same order. When the optimal solution lies in the interior of theconstraint set, the convergence rate is accelerated to ${\calO}(\eta_t^{\Delta} /t)$. Secondly, we study how the stochastic Frank-Wolfealgorithm can be applied to a few practical machine learning problems. Tightbounds on the gradient estimate errors for these examples are established.Numerical simulations support our findings.
arxiv-13800-186 | Cross-Device Tracking: Matching Devices and Cookies | http://arxiv.org/pdf/1510.01175v1.pdf | author:Roberto Díaz-Morales category:cs.LG cs.CY published:2015-10-05 summary:The number of computers, tablets and smartphones is increasing rapidly, whichentails the ownership and use of multiple devices to perform online tasks. Aspeople move across devices to complete these tasks, their identities becomesfragmented. Understanding the usage and transition between those devices isessential to develop efficient applications in a multi-device world. In thispaper we present a solution to deal with the cross-device identification ofusers based on semi-supervised machine learning methods to identify whichcookies belong to an individual using a device. The method proposed in thispaper scored third in the ICDM 2015 Drawbridge Cross-Device Connectionschallenge proving its good performance.
arxiv-13800-187 | Bayesian Inference via Approximation of Log-likelihood for Priors in Exponential Family | http://arxiv.org/pdf/1510.01225v1.pdf | author:Tohid Ardeshiri, Umut Orguner, Fredrik Gustafsson category:cs.LG stat.ML published:2015-10-05 summary:In this paper, a Bayesian inference technique based on Taylor seriesapproximation of the logarithm of the likelihood function is presented. Theproposed approximation is devised for the case, where the prior distributionbelongs to the exponential family of distributions. The logarithm of thelikelihood function is linearized with respect to the sufficient statistic ofthe prior distribution in exponential family such that the posterior obtainsthe same exponential family form as the prior. Similarities between theproposed method and the extended Kalman filter for nonlinear filtering areillustrated. Furthermore, an extended target measurement update for targetmodels where the target extent is represented by a random matrix having aninverse Wishart distribution is derived. The approximate update covers theimportant case where the spread of measurement is due to the target extent aswell as the measurement noise in the sensor.
arxiv-13800-188 | Efficient Object Detection for High Resolution Images | http://arxiv.org/pdf/1510.01257v1.pdf | author:Yongxi Lu, Tara Javidi category:cs.CV published:2015-10-05 summary:Efficient generation of high-quality object proposals is an essential step instate-of-the-art object detection systems based on deep convolutional neuralnetworks (DCNN) features. Current object proposal algorithms arecomputationally inefficient in processing high resolution images containingsmall objects, which makes them the bottleneck in object detection systems. Inthis paper we present effective methods to detect objects for high resolutionimages. We combine two complementary strategies. The first approach is topredict bounding boxes based on adjacent visual features. The second approachuses high level image features to guide a two-step search process thatadaptively focuses on regions that are likely to contain small objects. Weextract features required for the two strategies by utilizing a pre-trainedDCNN model known as AlexNet. We demonstrate the effectiveness of our algorithmby showing its performance on a high-resolution image subset of the SUN 2012object detection dataset.
arxiv-13800-189 | Learning in Unlabeled Networks - An Active Learning and Inference Approach | http://arxiv.org/pdf/1510.01270v1.pdf | author:Tomasz Kajdanowicz, Radosław Michalski, Katarzyna Musiał, Przemysław Kazienko category:stat.ML cs.LG cs.SI published:2015-10-05 summary:The task of determining labels of all network nodes based on the knowledgeabout network structure and labels of some training subset of nodes is calledthe within-network classification. It may happen that none of the labels of thenodes is known and additionally there is no information about number of classesto which nodes can be assigned. In such a case a subset of nodes has to beselected for initial label acquisition. The question that arises is: "labels ofwhich nodes should be collected and used for learning in order to provide thebest classification accuracy for the whole network?". Active learning andinference is a practical framework to study this problem. A set of methods for active learning and inference for within networkclassification is proposed and validated. The utility score calculation foreach node based on network structure is the first step in the process. Thescores enable to rank the nodes. Based on the ranking, a set of nodes, forwhich the labels are acquired, is selected (e.g. by taking top or bottom N fromthe ranking). The new measure-neighbour methods proposed in the paper suggestnot obtaining labels of nodes from the ranking but rather acquiring labels oftheir neighbours. The paper examines 29 distinct formulations of utility scoreand selection methods reporting their impact on the results of two collectiveclassification algorithms: Iterative Classification Algorithm and Loopy BeliefPropagation. We advocate that the accuracy of presented methods depends on the structuralproperties of the examined network. We claim that measure-neighbour methodswill work better than the regular methods for networks with higher clusteringcoefficient and worse than regular methods for networks with low clusteringcoefficient. According to our hypothesis, based on clustering coefficient weare able to recommend appropriate active learning and inference method.
arxiv-13800-190 | Stochastic model for phonemes uncovers an author-dependency of their usage | http://arxiv.org/pdf/1510.01315v2.pdf | author:Weibing Deng, Armen E. Allahverdyan category:cs.CL nlin.AO published:2015-10-05 summary:We study rank-frequency relations for phonemes, the minimal units that stillrelate to linguistic meaning. We show that these relations can be described bythe Dirichlet distribution, a direct analogue of the ideal-gas model instatistical mechanics. This description allows us to demonstrate that therank-frequency relations for phonemes of a text do depend on its author. Theauthor-dependency effect is not caused by the author's vocabulary (common wordsused in different texts), and is confirmed by several alternative means. Thissuggests that it can be directly related to phonemes. These features contrastto rank-frequency relations for words, which are both author and textindependent and are governed by the Zipf's law.
arxiv-13800-191 | Tight Variational Bounds via Random Projections and I-Projections | http://arxiv.org/pdf/1510.01308v1.pdf | author:Lun-Kai Hsu, Tudor Achim, Stefano Ermon category:cs.LG published:2015-10-05 summary:Information projections are the key building block of variational inferencealgorithms and are used to approximate a target probabilistic model byprojecting it onto a family of tractable distributions. In general, there is noguarantee on the quality of the approximation obtained. To overcome this issue,we introduce a new class of random projections to reduce the dimensionality andhence the complexity of the original model. In the spirit of randomprojections, the projection preserves (with high probability) key properties ofthe target distribution. We show that information projections can be combinedwith random projections to obtain provable guarantees on the quality of theapproximation obtained, regardless of the complexity of the original model. Wedemonstrate empirically that augmenting mean field with a random projectionstep dramatically improves partition function and marginal probabilityestimates, both on synthetic and real world data.
arxiv-13800-192 | Deep convolutional acoustic word embeddings using word-pair side information | http://arxiv.org/pdf/1510.01032v2.pdf | author:Herman Kamper, Weiran Wang, Karen Livescu category:cs.CL published:2015-10-05 summary:Recent studies have been revisiting whole words as the basic modelling unitin speech recognition and query applications, instead of phonetic units. Suchwhole-word segmental systems rely on a function that maps a variable-lengthspeech segment to a vector in a fixed-dimensional space; the resulting acousticword embeddings need to allow for accurate discrimination between differentword types, directly in the embedding space. We compare several old and newapproaches in a word discrimination task. Our best approach uses sideinformation in the form of known word pairs to train a Siamese convolutionalneural network (CNN): a pair of tied networks that take two speech segments asinput and produce their embeddings, trained with a hinge loss that separatessame-word pairs and different-word pairs by some margin. A word classifier CNNperforms similarly, but requires much stronger supervision. Both types of CNNsyield large improvements over the best previously published results on the worddiscrimination task.
arxiv-13800-193 | Batch Normalized Recurrent Neural Networks | http://arxiv.org/pdf/1510.01378v1.pdf | author:César Laurent, Gabriel Pereyra, Philémon Brakel, Ying Zhang, Yoshua Bengio category:stat.ML cs.LG cs.NE published:2015-10-05 summary:Recurrent Neural Networks (RNNs) are powerful models for sequential data thathave the potential to learn long-term dependencies. However, they arecomputationally expensive to train and difficult to parallelize. Recent workhas shown that normalizing intermediate representations of neural networks cansignificantly improve convergence rates in feedforward neural networks . Inparticular, batch normalization, which uses mini-batch statistics tostandardize features, was shown to significantly reduce training time. In thispaper, we show that applying batch normalization to the hidden-to-hiddentransitions of our RNNs doesn't help the training procedure. We also show thatwhen applied to the input-to-hidden transitions, batch normalization can leadto a faster convergence of the training criterion but doesn't seem to improvethe generalization performance on both our language modelling and speechrecognition tasks. All in all, applying batch normalization to RNNs turns outto be more challenging than applying it to feedforward networks, but certainvariants of it can still be beneficial.
arxiv-13800-194 | Within-Brain Classification for Brain Tumor Segmentation | http://arxiv.org/pdf/1510.01344v1.pdf | author:Mohammad Havaei, Hugo Larochelle, Philippe Poulin, Pierre-Marc Jodoin category:cs.CV cs.AI published:2015-10-05 summary:Purpose: In this paper, we investigate a framework for interactive braintumor segmentation which, at its core, treats the problem of interactive braintumor segmentation as a machine learning problem. Methods: This method has an advantage over typical machine learning methodsfor this task where generalization is made across brains. The problem withthese methods is that they need to deal with intensity bias correction andother MRI-specific noise. In this paper, we avoid these issues by approachingthe problem as one of within brain generalization. Specifically, we propose asemi-automatic method that segments a brain tumor by training and generalizingwithin that brain only, based on some minimum user interaction. Conclusion: We investigate how adding spatial feature coordinates (i.e. $i$,$j$, $k$) to the intensity features can significantly improve the performanceof different classification methods such as SVM, kNN and random forests. Thiswould only be possible within an interactive framework. We also investigate theuse of a more appropriate kernel and the adaptation of hyper-parametersspecifically for each brain. Results: As a result of these experiments, we obtain an interactive methodwhose results reported on the MICCAI-BRATS 2013 dataset are the second mostaccurate compared to published methods, while using significantly less memoryand processing power than most state-of-the-art methods.
arxiv-13800-195 | Intensity-only optical compressive imaging using a multiply scattering material and a double phase retrieval approach | http://arxiv.org/pdf/1510.01098v2.pdf | author:Boshra Rajaei, Eric W. Tramel, Sylvain Gigan, Florent Krzakala, Laurent Daudet category:cs.CV published:2015-10-05 summary:In this paper, the problem of compressive imaging is addressed using naturalrandomization by means of a multiply scattering medium. To utilize the mediumin this way, its corresponding transmission matrix must be estimated. Tocalibrate the imager, we use a digital micromirror device (DMD) as a simple,cheap, and high-resolution binary intensity modulator. We propose a phaseretrieval algorithm which is well adapted to intensity-only measurements on thecamera, and to the input binary intensity patterns, both to estimate thecomplex transmission matrix as well as image reconstruction. We demonstratepromising experimental results for the proposed algorithm using the MNISTdataset of handwritten digits as example images.
arxiv-13800-196 | Monitoring Potential Drug Interactions and Reactions via Network Analysis of Instagram User Timelines | http://arxiv.org/pdf/1510.01006v2.pdf | author:Rion Brattig Correia, Lang Li, Luis M. Rocha category:cs.SI cs.CY cs.IR q-bio.QM stat.ML published:2015-10-05 summary:Much recent research aims to identify evidence for Drug-Drug Interactions(DDI) and Adverse Drug reactions (ADR) from the biomedical scientificliterature. In addition to this "Bibliome", the universe of social mediaprovides a very promising source of large-scale data that can help identify DDIand ADR in ways that have not been hitherto possible. Given the large number ofusers, analysis of social media data may be useful to identify under-reported,population-level pathology associated with DDI, thus further contributing toimprovements in population health. Moreover, tapping into this data allows usto infer drug interactions with natural products--including cannabis--whichconstitute an array of DDI very poorly explored by biomedical research thusfar. Our goal is to determine the potential of Instagram for public healthmonitoring and surveillance for DDI, ADR, and behavioral pathology at large.Using drug, symptom, and natural product dictionaries for identification of thevarious types of DDI and ADR evidence, we have collected ~7000 timelines. Wereport on 1) the development of a monitoring tool to easily observe user-leveltimelines associated with drug and symptom terms of interest, and 2)population-level behavior via the analysis of co-occurrence networks computedfrom user timelines at three different scales: monthly, weekly, and dailyoccurrences. Analysis of these networks further reveals 3) drug and symptomdirect and indirect associations with greater support in user timelines, aswell as 4) clusters of symptoms and drugs revealed by the collective behaviorof the observed population. This demonstrates that Instagram contains muchdrug- and pathology specific data for public health monitoring of DDI and ADR,and that complex network analysis provides an important toolbox to extracthealth-related associations and their support from large-scale social mediadata.
arxiv-13800-197 | Visual Tracking via Nonnegative Regularization Multiple Locality Coding | http://arxiv.org/pdf/1510.01148v3.pdf | author:Fanghui Liu, Tao Zhou, Irene Y. H. Gu, Jie Yang category:cs.CV published:2015-10-05 summary:This paper presents a novel object tracking method based on approximatedLocality-constrained Linear Coding (LLC). Rather than using a non-negativityconstraint on encoding coefficients to guarantee these elements nonnegative, inthis paper, the non-negativity constraint is substituted for a conventional$\ell_2$ norm regularization term in approximated LLC to obtain the similarnonnegative effect. And we provide a detailed and adequate explanation intheoretical analysis to clarify the rationality of this replacement. Instead ofspecifying fixed K nearest neighbors to construct the local dictionary, aseries of different dictionaries with pre-defined numbers of nearest neighborsare selected. Weights of these various dictionaries are also learned fromapproximated LLC in the similar framework. In order to alleviate trackingdrifts, we propose a simple and efficient occlusion detection method. Theocclusion detection criterion mainly depends on whether negative templates areselected to represent the severe occluded target. Both qualitative andquantitative evaluations on several challenging sequences show that theproposed tracking algorithm achieves favorable performance compared with otherstate-of-the-art methods.
arxiv-13800-198 | RAID: A Relation-Augmented Image Descriptor | http://arxiv.org/pdf/1510.01113v2.pdf | author:Paul Guerrero, Niloy J. Mitra, Peter Wonka category:cs.GR cs.CV I.4.8; I.4.7 published:2015-10-05 summary:As humans, we regularly interpret images based on the relations between imageregions. For example, a person riding object X, or a plank bridging twoobjects. Current methods provide limited support to search for images based onsuch relations. We present RAID, a relation-augmented image descriptor thatsupports queries based on inter-region relations. The key idea of ourdescriptor is to capture the spatial distribution of simple point-to-regionrelationships to describe more complex relationships between two image regions.We evaluate the proposed descriptor by querying into a large subset of theMicrosoft COCO database and successfully extract nontrivial imagesdemonstrating complex inter-region relations, which are easily missed orerroneously classified by existing methods.
arxiv-13800-199 | Implicit stochastic approximation | http://arxiv.org/pdf/1510.00967v2.pdf | author:Panos Toulis, Edoardo M. Airoldi category:math.ST stat.ML stat.TH published:2015-10-04 summary:The need to carry out parameter estimation from massive data hasreinvigorated interest in iterative estimation methods, in statistics andmachine learning. Classic work includes deterministic gradient-based methods,such as quasi-Newton, and stochastic gradient descent and its variants,including adaptive learning rates, acceleration and averaging. Current workincreasingly relies on methods that employ proximal operators, leading toupdates defined through implicit equations, which need to be solved at eachiteration. Such methods are especially attractive in modern problems withmassive data because they are numerically stable and converge with minimalassumptions, among other reasons. However, while the majority of existingmethods can be subsumed into the gradient-free stochastic approximationframework developed by Robbins and Monro (1951), there is no such framework formethods with implicit updates. Here, we conceptualize a gradient-free implicitstochastic approximation procedure, and develop asymptotic and non-asymptotictheory for it. This new framework provides a theoretical foundation forgradient-based procedures that rely on implicit updates, and opens the door toiterative estimation methods that do not require a gradient, nor a fully knownlikelihood.
arxiv-13800-200 | A Novel Approach to Document Classification using WordNet | http://arxiv.org/pdf/1510.02755v2.pdf | author:Koushiki Sarkar, Ritwika Law category:cs.IR cs.CL published:2015-10-04 summary:Content based Document Classification is one of the biggest challenges in thecontext of free text mining. Current algorithms on document classificationsmostly rely on cluster analysis based on bag-of-words approach. However thatmethod is still being applied to many modern scientific dilemmas. It hasestablished a strong presence in fields like economics and social science tomerit serious attention from the researchers. In this paper we would like topropose and explore an alternative grounded more securely on the dictionaryclassification and correlatedness of words and phrases. It is expected thatapplication of our existing knowledge about the underlying classificationstructure may lead to improvement of the classifier's performance.
arxiv-13800-201 | Cross-convolutional-layer Pooling for Generic Visual Recognition | http://arxiv.org/pdf/1510.00921v1.pdf | author:Lingqiao Liu, Chunhua Shen, Anton van den Hengel category:cs.CV published:2015-10-04 summary:Recent studies have shown that a Deep Convolutional Neural Network (DCNN)pretrained on a large image dataset can be used as a universal imagedescriptor, and that doing so leads to impressive performance for a variety ofimage classification tasks. Most of these studies adopt activations from asingle DCNN layer, usually the fully-connected layer, as the imagerepresentation. In this paper, we proposed a novel way to extract imagerepresentations from two consecutive convolutional layers: one layer isutilized for local feature extraction and the other serves as guidance to poolthe extracted features. By taking different viewpoints of convolutional layers,we further develop two schemes to realize this idea. The first one directlyuses convolutional layers from a DCNN. The second one applies the pretrainedCNN on densely sampled image regions and treats the fully-connected activationsof each image region as convolutional feature activations. We then trainanother convolutional layer on top of that as the pooling-guidanceconvolutional layer. By applying our method to three popular visualclassification tasks, we find our first scheme tends to perform better on theapplications which need strong discrimination on subtle object patterns withinsmall regions while the latter excels in the cases that require discriminationon category-level patterns. Overall, the proposed method achieves superiorperformance over existing ways of extracting image representations from a DCNN.
arxiv-13800-202 | Background Image Generation Using Boolean Operations | http://arxiv.org/pdf/1510.00889v1.pdf | author:Kardi Teknomo, Proceso Fernandez category:cs.CV I.4.6 published:2015-10-04 summary:Tracking moving objects from a video sequence requires segmentation of theseobjects from the background image. However, getting the actual background imageautomatically without object detection and using only the video is difficult.In this paper, we describe a novel algorithm that generates background fromreal world images without foreground detection. The algorithm assumes that thebackground image is shown in the majority of the video. Given this simpleassumption, the method described in this paper is able to accurately generate,with high probability, the background image from a video using only a smallnumber of binary operations.
arxiv-13800-203 | Efficient Hand Articulations Tracking using Adaptive Hand Model and Depth map | http://arxiv.org/pdf/1510.00981v3.pdf | author:Byeongkeun Kang, Yeejin Lee, Truong Q. Nguyen category:cs.CV published:2015-10-04 summary:Real-time hand articulations tracking is important for many applications suchas interacting with virtual / augmented reality devices or tablets. However,most of existing algorithms highly rely on expensive and high power-consumingGPUs to achieve real-time processing. Consequently, these systems areinappropriate for mobile and wearable devices. In this paper, we propose anefficient hand tracking system which does not require high performance GPUs. Inour system, we track hand articulations by minimizing discrepancy between depthmap from sensor and computer-generated hand model. We also initialize hand poseat each frame using finger detection and classification. Our contributions are:(a) propose adaptive hand model to consider different hand shapes of userswithout generating personalized hand model; (b) improve the highly efficientframe initialization for robust tracking and automatic initialization; (c)propose hierarchical random sampling of pixels from each depth map to improvetracking accuracy while limiting required computations. To the best of ourknowledge, it is the first system that achieves both automatic hand modeladjustment and real-time tracking without using GPUs.
arxiv-13800-204 | Design and Analysis of a Single-Camera Omnistereo Sensor for Quadrotor Micro Aerial Vehicles (MAVs) | http://arxiv.org/pdf/1510.00771v1.pdf | author:Carlos Jaramillo category:cs.CV cs.RO cs.SY published:2015-10-03 summary:We describe the design and 3D sensing performance of an omnidirectionalstereo-vision system (omnistereo) as applied to Micro Aerial Vehicles (MAVs).The proposed omnistereo model employs a monocular camera that is co-axiallyaligned with a pair of hyperboloidal mirrors (folded catadioptricconfiguration). We show that this arrangement is practical for performingstereo-vision when mounted on top of propeller-based MAVs characterized by lowpayloads. The theoretical single viewpoint (SVP) constraint helps us deriveanalytical solutions for the sensor's projective geometry and generateSVP-compliant panoramic images to compute 3D information from stereocorrespondences (in a truly synchronous fashion). We perform an extensiveanalysis on various system characteristics such as its size, catadioptricspatial resolution, field-of-view. In addition, we pose a probabilistic modelfor uncertainty estimation of the depth from triangulation for skewback-projection rays. We expect to motivate the reproducibility of our solutionsince it can be adapted (optimally) to other catadioptric-based omnistereovision applications.
arxiv-13800-205 | Machine Learning for Machine Data from a CATI Network | http://arxiv.org/pdf/1510.00772v1.pdf | author:Sou-Cheng T. Choi category:cs.LG published:2015-10-03 summary:This is a machine learning application paper involving big data. We presenthigh-accuracy prediction methods of rare events in semi-structured machine logfiles, which are produced at high velocity and high volume by NORC'scomputer-assisted telephone interviewing (CATI) network for conducting surveys.We judiciously apply natural language processing (NLP) techniques anddata-mining strategies to train effective learning and prediction models forclassifying uncommon error messages in the log---without access to source code,updated documentation or dictionaries. In particular, our simple but effectiveapproach of features preallocation for learning from imbalanced data coupledwith naive Bayes classifiers can be conceivably generalized to supervised orsemi-supervised learning and prediction methods for other critical events suchas cyberattack detection.
arxiv-13800-206 | P-trac Procedure: The Dispersion and Neutralization of Contrasts in Lexicon | http://arxiv.org/pdf/1510.00760v1.pdf | author:Afshin Rahimi, Bahram Vazirnezhad, Moharram Eslami category:cs.CL published:2015-10-03 summary:Cognitive acoustic cues have an important role in shaping the phonologicalstructure of language as a means to optimal communication. In this paper weintroduced P-trac procedure in order to track dispersion of contrasts indifferent contexts in lexicon. The results of applying P-trac procedure to thecase of dispersion of contrasts in pre- consonantal contexts and in consonantalpositions of CVCC sequences in Persian provide Evidence in favor of phoneticbasis of dispersion argued by Licensing by Cue hypothesis and the DispersionTheory of Contrast. The P- trac procedure is proved to be very effective inrevealing the dispersion of contrasts in lexicon especially when comparing thedispersion of contrasts in different contexts.
arxiv-13800-207 | Distributed Parameter Map-Reduce | http://arxiv.org/pdf/1510.00817v1.pdf | author:Qi Li category:cs.DC cs.LG stat.ML published:2015-10-03 summary:This paper describes how to convert a machine learning problem into a seriesof map-reduce tasks. We study logistic regression algorithm. In logisticregression algorithm, it is assumed that samples are independent and eachsample is assigned a probability. Parameters are obtained by maxmizing theproduct of all sample probabilities. Rapid expansion of training samples bringschallenges to machine learning method. Training samples are so many that theycan be only stored in distributed file system and driven by map-reduce styleprograms. The main step of logistic regression is inference. According tomap-reduce spirit, each sample makes inference through a separate mapprocedure. But the premise of inference is that the map procedure holdsparameters for all features in the sample. In this paper, we proposeDistributed Parameter Map-Reduce, in which not only samples, but alsoparameters are distributed in nodes of distributed filesystem. Through a seriesof map-reduce tasks, we assign each sample parameters for its features, makeinference for the sample and update paramters of the model. The above processesare excuted looply until convergence. We test the proposed algorithm in actualhadoop production environment. Experiments show that the acceleration of thealgorithm is in linear relationship with the number of cluster nodes.
arxiv-13800-208 | It is not all downhill from here: Syllable Contact Law in Persian | http://arxiv.org/pdf/1510.00759v1.pdf | author:Afshin Rahimi, Moharram Eslami, Bahram Vazirnezhad category:cs.CL published:2015-10-03 summary:Syllable contact pairs crosslinguistically tend to have a falling sonorityslope a constraint which is called the Syllable Contact Law SCL In this studythe phonotactics of syllable contacts in 4202 CVCCVC words of Persian lexiconis investigated The consonants of Persian were divided into five sonoritycategories and the frequency of all possible sonority slopes is computed bothin lexicon type frequency and in corpus token frequency Since an unmarkedphonological structure has been shown to diachronically become more frequent weexpect to see the same pattern for syllable contact pairs with falling sonorityslope The correlation of sonority categories of the two consonants in asyllable contact pair is measured using Pointwise Mutual Information
arxiv-13800-209 | Approximate Fisher Kernels of non-iid Image Models for Image Categorization | http://arxiv.org/pdf/1510.00857v1.pdf | author:Ramazan Gokberk Cinbis, Jakob Verbeek, Cordelia Schmid category:cs.CV cs.LG published:2015-10-03 summary:The bag-of-words (BoW) model treats images as sets of local descriptors andrepresents them by visual word histograms. The Fisher vector (FV)representation extends BoW, by considering the first and second orderstatistics of local descriptors. In both representations local descriptors areassumed to be identically and independently distributed (iid), which is a poorassumption from a modeling perspective. It has been experimentally observedthat the performance of BoW and FV representations can be improved by employingdiscounting transformations such as power normalization. In this paper, weintroduce non-iid models by treating the model parameters as latent variableswhich are integrated out, rendering all local regions dependent. Using theFisher kernel principle we encode an image by the gradient of the datalog-likelihood w.r.t. the model hyper-parameters. Our models naturally generatediscounting effects in the representations; suggesting that suchtransformations have proven successful because they closely correspond to therepresentations obtained for non-iid models. To enable tractable computation,we rely on variational free-energy bounds to learn the hyper-parameters and tocompute approximate Fisher kernels. Our experimental evaluation resultsvalidate that our models lead to performance improvements comparable to usingpower normalization, as employed in state-of-the-art feature aggregationmethods.
arxiv-13800-210 | Client Profiling for an Anti-Money Laundering System | http://arxiv.org/pdf/1510.00878v2.pdf | author:Claudio Alexandre, João Balsa category:cs.LG cs.AI stat.ML published:2015-10-03 summary:We present a data mining approach for profiling bank clients in order tosupport the process of detection of anti-money laundering operations. We firstpresent the overall system architecture, and then focus on the relevantcomponent for this paper. We detail the experiments performed on real worlddata from a financial institution, which allowed us to group clients inclusters and then generate a set of classification rules. We discuss therelevance of the founded client profiles and of the generated classificationrules. According to the defined overall agent-based architecture, these ruleswill be incorporated in the knowledge base of the intelligent agentsresponsible for the signaling of suspicious transactions.
arxiv-13800-211 | Spectral Clustering over the Logistic Random Dot Product Graph | http://arxiv.org/pdf/1510.00850v2.pdf | author:Luke O'Connor, Muriel Médard, Soheil Feizi category:stat.ML published:2015-10-03 summary:Inference of clusters over networks is a central problem in machine learning.Commonly, it is formulated as a discrete optimization, and a continuousrelaxation is used to obtain a spectral algorithm. An alternative problemformulation arises by considering a latent space model, in which edgeprobabilities are determined by continuous latent positions. A model ofparticular interest is the Random Dot Product Graph (RDPG), which can be fitusing an efficient spectral method; however, this method is based on aheuristic that can fail, even in simple cases. In this paper, we consider aclosely related latent space model, the Logistic RDPG, which uses a logisticlink function to map from latent position inner products to edge likelihoods.Over this model, we show that asymptotically exact maximum likelihood inferenceof the latent position vectors can be achieved using a spectral method. Ourmethod involves computing the top eigenvectors of a normalized adjacency matrixand scaling the eigenvectors using a regression step. Through simulations, weshow that this method is more accurate and more robust than existing spectraland semidefinite network clustering methods. In particular, the novelregression scaling step is essential to the performance gain of the proposedmethod.
arxiv-13800-212 | Local Higher-Order Statistics (LHS) describing images with statistics of local non-binarized pixel patterns | http://arxiv.org/pdf/1510.00542v1.pdf | author:Gaurav Sharma, Frederic Jurie category:cs.CV published:2015-10-02 summary:We propose a new image representation for texture categorization and facialanalysis, relying on the use of higher-order local differential statistics asfeatures. It has been recently shown that small local pixel patterndistributions can be highly discriminative while being extremely efficient tocompute, which is in contrast to the models based on the global structure ofimages. Motivated by such works, we propose to use higher-order statistics oflocal non-binarized pixel patterns for the image description. The proposedmodel does not require either (i) user specified quantization of the space (ofpixel patterns) or (ii) any heuristics for discarding low occupancy volumes ofthe space. We propose to use a data driven soft quantization of the space, withparametric mixture models, combined with higher-order statistics, based onFisher scores. We demonstrate that this leads to a more expressiverepresentation which, when combined with discriminatively learned classifiersand metrics, achieves state-of-the-art performance on challenging texture andfacial analysis datasets, in low complexity setup. Further, it is complementaryto higher complexity features and when combined with them improves performance.
arxiv-13800-213 | Effective Object Tracking in Unstructured Crowd Scenes | http://arxiv.org/pdf/1510.00479v1.pdf | author:Ishan Jindal, Shanmuganathan Raman category:cs.CV published:2015-10-02 summary:In this paper, we are presenting a rotation variant Oriented Texture Curve(OTC) descriptor based mean shift algorithm for tracking an object in anunstructured crowd scene. The proposed algorithm works by first obtaining theOTC features for a manually selected object target, then a visual vocabulary iscreated by using all the OTC features of the target. The target histogram isobtained using codebook encoding method which is then used in mean shiftframework to perform similarity search. Results are obtained on differentvideos of challenging scenes and the comparison of the proposed approach withseveral state-of-the-art approaches are provided. The analysis shows theadvantages and limitations of the proposed approach for tracking an object inunstructured crowd scenes.
arxiv-13800-214 | Learning a Discriminative Model for the Perception of Realism in Composite Images | http://arxiv.org/pdf/1510.00477v1.pdf | author:Jun-Yan Zhu, Philipp Krähenbühl, Eli Shechtman, Alexei A. Efros category:cs.CV published:2015-10-02 summary:What makes an image appear realistic? In this work, we are answering thisquestion from a data-driven perspective by learning the perception of visualrealism directly from large amounts of data. In particular, we train aConvolutional Neural Network (CNN) model that distinguishes natural photographsfrom automatically generated composite images. The model learns to predictvisual realism of a scene in terms of color, lighting and texturecompatibility, without any human annotations pertaining to it. Our modeloutperforms previous works that rely on hand-crafted heuristics, for the taskof classifying realistic vs. unrealistic photos. Furthermore, we apply ourlearned model to compute optimal parameters of a compositing method, tomaximize the visual realism score predicted by our CNN model. We demonstrateits advantage against existing methods via a human perception study.
arxiv-13800-215 | Human Action Recognition using Factorized Spatio-Temporal Convolutional Networks | http://arxiv.org/pdf/1510.00562v1.pdf | author:Lin Sun, Kui Jia, Dit-Yan Yeung, Bertram E. Shi category:cs.CV published:2015-10-02 summary:Human actions in video sequences are three-dimensional (3D) spatio-temporalsignals characterizing both the visual appearance and motion dynamics of theinvolved humans and objects. Inspired by the success of convolutional neuralnetworks (CNN) for image classification, recent attempts have been made tolearn 3D CNNs for recognizing human actions in videos. However, partly due tothe high complexity of training 3D convolution kernels and the need for largequantities of training videos, only limited success has been reported. This hastriggered us to investigate in this paper a new deep architecture which canhandle 3D signals more effectively. Specifically, we propose factorizedspatio-temporal convolutional networks (FstCN) that factorize the original 3Dconvolution kernel learning as a sequential process of learning 2D spatialkernels in the lower layers (called spatial convolutional layers), followed bylearning 1D temporal kernels in the upper layers (called temporal convolutionallayers). We introduce a novel transformation and permutation operator to makefactorization in FstCN possible. Moreover, to address the issue of sequencealignment, we propose an effective training and inference strategy based onsampling multiple video clips from a given action video sequence. We havetested FstCN on two commonly used benchmark datasets (UCF-101 and HMDB-51).Without using auxiliary training videos to boost the performance, FstCNoutperforms existing CNN based methods and achieves comparable performance witha recent method that benefits from using auxiliary training videos.
arxiv-13800-216 | A Survey of Online Experiment Design with the Stochastic Multi-Armed Bandit | http://arxiv.org/pdf/1510.00757v4.pdf | author:Giuseppe Burtini, Jason Loeppky, Ramon Lawrence category:stat.ML cs.LG published:2015-10-02 summary:Adaptive and sequential experiment design is a well-studied area in numerousdomains. We survey and synthesize the work of the online statistical learningparadigm referred to as multi-armed bandits integrating the existing researchas a resource for a certain class of online experiments. We first explore thetraditional stochastic model of a multi-armed bandit, then explore a taxonomicscheme of complications to that model, for each complication relating it to aspecific requirement or consideration of the experiment design context.Finally, at the end of the paper, we present a table of known upper-bounds ofregret for all studied algorithms providing both perspectives for futuretheoretical work and a decision-making tool for practitioners looking fortheoretical guarantees.
arxiv-13800-217 | A Bayesian approach to constrained single- and multi-objective optimization | http://arxiv.org/pdf/1510.00503v3.pdf | author:Paul Feliot, Julien Bect, Emmanuel Vazquez category:stat.CO stat.ML published:2015-10-02 summary:This article addresses the problem of derivative-free (single- ormulti-objective) optimization subject to multiple inequality constraints. Boththe objective and constraint functions are assumed to be smooth, non-linear andexpensive to evaluate. As a consequence, the number of evaluations that can beused to carry out the optimization is very limited, as in complex industrialdesign optimization problems. The method we propose to overcome this difficultyhas its roots in both the Bayesian and the multi-objective optimizationliteratures. More specifically, an extended domination rule is used to handleobjectives and constraints in a unified way, and a corresponding expectedhyper-volume improvement sampling criterion is proposed. This new criterion isnaturally adapted to the search of a feasible point when none is available, andreduces to existing Bayesian sampling criteria---the classical ExpectedImprovement (EI) criterion and some of its constrained/multi-objectiveextensions---as soon as at least one feasible point is available. Thecalculation and optimization of the criterion are performed using SequentialMonte Carlo techniques. In particular, an algorithm similar to the subsetsimulation method, which is well known in the field of structural reliability,is used to estimate the criterion. The method, which we call BMOO (for BayesianMulti-Objective Optimization), is compared to state-of-the-art algorithms forsingle- and multi-objective constrained optimization.
arxiv-13800-218 | Multi-armed Bandits with Application to 5G Small Cells | http://arxiv.org/pdf/1510.00627v1.pdf | author:Setareh Maghsudi, Ekram Hossain category:cs.LG cs.DC cs.NI published:2015-10-02 summary:Due to the pervasive demand for mobile services, next generation wirelessnetworks are expected to be able to deliver high date rates while wirelessresources become more and more scarce. This requires the next generationwireless networks to move towards new networking paradigms that are able toefficiently support resource-demanding applications such as personalized mobileservices. Examples of such paradigms foreseen for the emerging fifth generation(5G) cellular networks include very densely deployed small cells anddevice-to-device communications. For 5G networks, it will be imperative tosearch for spectrum and energy-efficient solutions to the resource allocationproblems that i) are amenable to distributed implementation, ii) are capable ofdealing with uncertainty and lack of information, and iii) can cope with users'selfishness. The core objective of this article is to investigate and toestablish the potential of multi-armed bandit (MAB) framework to address thischallenge. In particular, we provide a brief tutorial on bandit problems,including different variations and solution approaches. Furthermore, we discussrecent applications as well as future research directions. In addition, weprovide a detailed example of using an MAB model for energy-efficient smallcell planning in 5G networks.
arxiv-13800-219 | Distributed Multitask Learning | http://arxiv.org/pdf/1510.00633v1.pdf | author:Jialei Wang, Mladen Kolar, Nathan Srebro category:stat.ML cs.LG published:2015-10-02 summary:We consider the problem of distributed multi-task learning, where eachmachine learns a separate, but related, task. Specifically, each machine learnsa linear predictor in high-dimensional space,where all tasks share the samesmall support. We present a communication-efficient estimator based on thedebiased lasso and show that it is comparable with the optimal centralizedmethod.
arxiv-13800-220 | Rapidly Mixing Gibbs Sampling for a Class of Factor Graphs Using Hierarchy Width | http://arxiv.org/pdf/1510.00756v1.pdf | author:Christopher De Sa, Ce Zhang, Kunle Olukotun, Christopher Ré category:cs.LG published:2015-10-02 summary:Gibbs sampling on factor graphs is a widely used inference technique, whichoften produces good empirical results. Theoretical guarantees for itsperformance are weak: even for tree structured graphs, the mixing time of Gibbsmay be exponential in the number of variables. To help understand the behaviorof Gibbs sampling, we introduce a new (hyper)graph property, called hierarchywidth. We show that under suitable conditions on the weights, bounded hierarchywidth ensures polynomial mixing time. Our study of hierarchy width is in partmotivated by a class of factor graph templates, hierarchical templates, whichhave bounded hierarchy width---regardless of the data used to instantiate them.We demonstrate a rich application from natural language processing in whichGibbs sampling provably mixes rapidly and achieves accuracy that exceeds humanvolunteers.
arxiv-13800-221 | Minimax Lower Bounds for Noisy Matrix Completion Under Sparse Factor Models | http://arxiv.org/pdf/1510.00701v1.pdf | author:Abhinav V. Sambasivan, Jarvis D. Haupt category:cs.IT math.IT stat.ML published:2015-10-02 summary:This paper examines fundamental error characteristics for a general class ofmatrix completion problems, where matrix of interest is a product of two apriori unknown matrices, one of which is sparse, and the observations arenoisy. Our main contributions come in the form of minimax lower bounds for theexpected per-element squared error for these problems under severalnoise/corruption models; specifically, we analyze scenarios where thecorruptions are characterized by additive Gaussian noise or additiveheavier-tailed (Laplace) noise, Poisson-distributed observations, andhighly-quantized (e.g., one-bit) observations. Our results establish that theerror bounds derived in (Soni et al., 2014) for complexity-regularized maximumlikelihood estimators achieve, up to multiplicative constant and logarithmicfactors, the minimax error rates in each of these noise scenarios, provided thesparse factor exhibits linear sparsity.
arxiv-13800-222 | WHOI-Plankton- A Large Scale Fine Grained Visual Recognition Benchmark Dataset for Plankton Classification | http://arxiv.org/pdf/1510.00745v1.pdf | author:Eric C. Orenstein, Oscar Beijbom, Emily E. Peacock, Heidi M. Sosik category:cs.CV published:2015-10-02 summary:Planktonic organisms are of fundamental importance to marine ecosystems: theyform the basis of the food web, provide the link between the atmosphere and thedeep ocean, and influence global-scale biogeochemical cycles. Scientists areincreasingly using imaging-based technologies to study these creatures in theirnatural habit. Images from such systems provide an unique opportunity to modeland understand plankton ecosystems, but the collected datasets can be enormous.The Imaging FlowCytobot (IFCB) at Woods Hole Oceanographic Institution, forexample, is an \emph{in situ} system that has been continuously imagingplankton since 2006. To date, it has generated more than 700 million samples.Manual classification of such a vast image collection is impractical due to thesize of the data set. In addition, the annotation task is challenging due tothe large space of relevant classes, intra-class variability, and inter-classsimilarity. Methods for automated classification exist, but the accuracy isoften below that of human experts. Here we introduce WHOI-Plankton: a largescale, fine-grained visual recognition dataset for plankton classification,which comprises over 3.4 million expert-labeled images across 70 classes. Thelabeled image set is complied from over 8 years of near continuous datacollection with the IFCB at the Martha's Vineyard Coastal Observatory (MVCO).We discuss relevant metrics for evaluation of classification performance andprovide results for a traditional method based on hand-engineered features andtwo methods based on convolutional neural networks.
arxiv-13800-223 | A Primer on Neural Network Models for Natural Language Processing | http://arxiv.org/pdf/1510.00726v1.pdf | author:Yoav Goldberg category:cs.CL published:2015-10-02 summary:Over the past few years, neural networks have re-emerged as powerfulmachine-learning models, yielding state-of-the-art results in fields such asimage recognition and speech processing. More recently, neural network modelsstarted to be applied also to textual natural language signals, again with verypromising results. This tutorial surveys neural network models from theperspective of natural language processing research, in an attempt to bringnatural-language researchers up to speed with the neural techniques. Thetutorial covers input encoding for natural language tasks, feed-forwardnetworks, convolutional networks, recurrent networks and recursive networks, aswell as the computation graph abstraction for automatic gradient computation.
arxiv-13800-224 | Autonomous Perceptron Neural Network Inspired from Quantum computing | http://arxiv.org/pdf/1510.00556v2.pdf | author:M. Zidan, A. Sagheer, N. Metwally category:quant-ph cs.NE published:2015-10-02 summary:This abstract will be modified after correcting the minor error in Eq.(2)
arxiv-13800-225 | Automatic Taxonomy Extraction from Query Logs with no Additional Sources of Information | http://arxiv.org/pdf/1510.00618v2.pdf | author:Miguel Fernandez-Fernandez, Daniel Gayo-Avello category:cs.CL published:2015-10-02 summary:Search engine logs store detailed information on Web users interactions.Thus, as more and more people use search engines on a daily basis, importanttrails of users common knowledge are being recorded in those files. Previousresearch has shown that it is possible to extract concept taxonomies from fulltext documents, while other scholars have proposed methods to obtain similarqueries from query logs. We propose a mixture of both lines of research, thatis, mining query logs not to find related queries nor query hierarchies, butactual term taxonomies that could be used to improve search engineeffectiveness and efficiency. As a result, in this study we have developed amethod that combines lexical heuristics with a supervised classification modelto successfully extract hyponymy relations from specialization search patternsrevealed from log missions, with no additional sources of information, and in alanguage independent way.
arxiv-13800-226 | RDF Knowledge Graph Visualization From a Knowledge Extraction System | http://arxiv.org/pdf/1510.00244v1.pdf | author:Fadhela Kerdjoudj, Olivier Curé category:cs.HC cs.CL published:2015-10-01 summary:In this paper, we present a system to visualize RDF knowledge graphs. Thesegraphs are obtained from a knowledge extraction system designed byGEOLSemantics. This extraction is performed using natural language processingand trigger detection. The user can visualize subgraphs by selecting someontology features like concepts or individuals. The system is alsomultilingual, with the use of the annotated ontology in English, French, Arabicand Chinese.
arxiv-13800-227 | Determination of the Internet Anonymity Influence on the Level of Aggression and Usage of Obscene Lexis | http://arxiv.org/pdf/1510.00240v1.pdf | author:Rodmonga Potapova, Denis Gordeev category:cs.CL published:2015-10-01 summary:This article deals with the analysis of the semantic content of the anonymousRussian-speaking forum 2ch.hk, different verbal means of expressing of theemotional state of aggression are revealed for this site, and aggression isclassified by its directions. The lexis of different Russian-and English-speaking anonymous forums (2ch.hk and iichan.hk, 4chan.org) and publiccommunity "MDK" of the Russian-speaking social network VK is analyzed andcompared with the Open Corpus of the Russian language (Opencorpora.org andBrown corpus). The analysis shows that anonymity has no influence on the amountof invective items usage. The effectiveness of moderation was shown foranonymous forums. It was established that Russian obscene lexis was used toexpress the emotional state of aggression only in 60.4% of cases for 2ch.hk.These preliminary results show that the Russian obscene lexis on the Internetdoes not have direct dependence on the emotional state of aggression.
arxiv-13800-228 | Data Association for an Adaptive Multi-target Particle Filter Tracking System | http://arxiv.org/pdf/1510.00203v1.pdf | author:R. Alampay, K. Teknomo category:cs.CV I.5.4 published:2015-10-01 summary:This paper presents a novel approach to improve the accuracy of trackingmultiple objects in a static scene using a particle filter system byintroducing a data association step, a state queue for the collection oftracked objects and adaptive parameters to the system. The data associationstep makes use of the object detection phase and appearance model to determineif the approximated targets given by the particle filter step match the givenset of detected objects. The remaining detected objects are used as informationto instantiate new objects for tracking. State queues are also used for eachtracked object to deal with occlusion events and occlusion recovery. Finally wepresent how the parameters adjust to occlusion events. The adaptive property ofthe system is also used for possible occlusion recovery. Results of the systemare then compared to a ground truth data set for performance evaluation. Oursystem produced accurate results and was able to handle partially occludedobjects as well as proper occlusion recovery from tracking multiple objects
arxiv-13800-229 | Transfer Learning from Deep Features for Remote Sensing and Poverty Mapping | http://arxiv.org/pdf/1510.00098v2.pdf | author:Michael Xie, Neal Jean, Marshall Burke, David Lobell, Stefano Ermon category:cs.CV cs.CY published:2015-10-01 summary:The lack of reliable data in developing countries is a major obstacle tosustainable development, food security, and disaster relief. Poverty data, forexample, is typically scarce, sparse in coverage, and labor-intensive toobtain. Remote sensing data such as high-resolution satellite imagery, on theother hand, is becoming increasingly available and inexpensive. Unfortunately,such data is highly unstructured and currently no techniques exist toautomatically extract useful insights to inform policy decisions and helpdirect humanitarian efforts. We propose a novel machine learning approach toextract large-scale socioeconomic indicators from high-resolution satelliteimagery. The main challenge is that training data is very scarce, making itdifficult to apply modern techniques such as Convolutional Neural Networks(CNN). We therefore propose a transfer learning approach where nighttime lightintensities are used as a data-rich proxy. We train a fully convolutional CNNmodel to predict nighttime lights from daytime imagery, simultaneously learningfeatures that are useful for poverty prediction. The model learns filtersidentifying different terrains and man-made structures, including roads,buildings, and farmlands, without any supervision beyond nighttime lights. Wedemonstrate that these learned features are highly informative for povertymapping, even approaching the predictive performance of survey data collectedin the field.
arxiv-13800-230 | An Asynchronous Implementation of the Limited Memory CMA-ES | http://arxiv.org/pdf/1510.00419v1.pdf | author:Viktor Arkhipov, Maxim Buzdalov, Anatoly Shalyto category:cs.NE 90C56 G.1.6; I.2.8 published:2015-10-01 summary:We present our asynchronous implementation of the LM-CMA-ES algorithm, whichis a modern evolution strategy for solving complex large-scale continuousoptimization problems. Our implementation brings the best results when thenumber of cores is relatively high and the computational complexity of thefitness function is also high. The experiments with benchmark functions showthat it is able to overcome its origin on the Sphere function, reaches certainthresholds faster on the Rosenbrock and Ellipsoid function, and surprisinglyperforms much better than the original version on the Rastrigin function.
arxiv-13800-231 | Using consumer behavior data to reduce energy consumption in smart homes | http://arxiv.org/pdf/1510.00165v1.pdf | author:Daniel Schweizer, Michael Zehnder, Holger Wache, Hans-Friedrich Witschel, Danilo Zanatta, Miguel Rodriguez category:cs.CY stat.ML published:2015-10-01 summary:This paper discusses how usage patterns and preferences of inhabitants can belearned efficiently to allow smart homes to autonomously achieve energysavings. We propose a frequent sequential pattern mining algorithm suitable forreal-life smart home event data. The performance of the proposed algorithm iscompared to existing algorithms regarding completeness/correctness of theresults, run times as well as memory consumption and elaborates on theshortcomings of the different solutions. We also present a recommender systembased on the developed algorithm that provides recommendations to the users toreduce their energy consumption. The recommender system was deployed to a setof test homes. The test participants rated the impact of the recommendations ontheir comfort. We used this feedback to adjust the system parameters and makeit more accurate during a second test phase.
arxiv-13800-232 | A Generative Model of Words and Relationships from Multiple Sources | http://arxiv.org/pdf/1510.00259v2.pdf | author:Stephanie L. Hyland, Theofanis Karaletsos, Gunnar Rätsch category:cs.CL cs.LG stat.ML published:2015-10-01 summary:Neural language models are a powerful tool to embed words into semanticvector spaces. However, learning such models generally relies on theavailability of abundant and diverse training examples. In highly specialiseddomains this requirement may not be met due to difficulties in obtaining alarge corpus, or the limited range of expression in average use. Such domainsmay encode prior knowledge about entities in a knowledge base or ontology. Wepropose a generative model which integrates evidence from diverse data sources,enabling the sharing of semantic information. We achieve this by generalisingthe concept of co-occurrence from distributional semantics to include otherrelationships between entities or words, which we model as affinetransformations on the embedding space. We demonstrate the effectiveness ofthis approach by outperforming recent models on a link prediction task anddemonstrating its ability to profit from partially or fully unobserved datatraining labels. We further demonstrate the usefulness of learning fromdifferent data sources with overlapping vocabularies.
arxiv-13800-233 | Disk storage management for LHCb based on Data Popularity estimator | http://arxiv.org/pdf/1510.00132v1.pdf | author:Mikhail Hushchyn, Philippe Charpentier, Andrey Ustyuzhanin category:cs.DC cs.LG published:2015-10-01 summary:This paper presents an algorithm providing recommendations for optimizing theLHCb data storage. The LHCb data storage system is a hybrid system. Alldatasets are kept as archives on magnetic tapes. The most popular datasets arekept on disks. The algorithm takes the dataset usage history and metadata(size, type, configuration etc.) to generate a recommendation report. Thisarticle presents how we use machine learning algorithms to predict future datapopularity. Using these predictions it is possible to estimate which datasetsshould be removed from disk. We use regression algorithms and time seriesanalysis to find the optimal number of replicas for datasets that are kept ondisk. Based on the data popularity and the number of replicas optimization, thealgorithm minimizes a loss function to find the optimal data distribution. Theloss function represents all requirements for data distribution in the datastorage system. We demonstrate how our algorithm helps to save disk space andto reduce waiting times for jobs using this data.
arxiv-13800-234 | Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding | http://arxiv.org/pdf/1510.00149v5.pdf | author:Song Han, Huizi Mao, William J. Dally category:cs.CV cs.NE published:2015-10-01 summary:Neural networks are both computationally intensive and memory intensive,making them difficult to deploy on embedded systems with limited hardwareresources. To address this limitation, we introduce "deep compression", a threestage pipeline: pruning, trained quantization and Huffman coding, that worktogether to reduce the storage requirement of neural networks by 35x to 49xwithout affecting their accuracy. Our method first prunes the network bylearning only the important connections. Next, we quantize the weights toenforce weight sharing, finally, we apply Huffman coding. After the first twosteps we retrain the network to fine tune the remaining connections and thequantized centroids. Pruning, reduces the number of connections by 9x to 13x;Quantization then reduces the number of bits that represent each connectionfrom 32 to 5. On the ImageNet dataset, our method reduced the storage requiredby AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our methodreduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss ofaccuracy. This allows fitting the model into on-chip SRAM cache rather thanoff-chip DRAM memory. Our compression method also facilitates the use ofcomplex neural networks in mobile applications where application size anddownload bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU,compressed network has 3x to 4x layerwise speedup and 3x to 7x better energyefficiency.
arxiv-13800-235 | Response to Liu, Xu, and Liang (2015) and Ferrer-i-Cancho and Gómez-Rodríguez (2015) on Dependency Length Minimization | http://arxiv.org/pdf/1510.00436v1.pdf | author:Richard Futrell, Kyle Mahowald, Edward Gibson category:cs.CL published:2015-10-01 summary:We address recent criticisms (Liu et al., 2015; Ferrer-i-Cancho andG\'omez-Rodr\'iguez, 2015) of our work on empirical evidence of dependencylength minimization across languages (Futrell et al., 2015). First, weacknowledge error in failing to acknowledge Liu (2008)'s previous work oncorpora of 20 languages with similar aims. A correction will appear in PNAS.Nevertheless, we argue that our work provides novel, strong evidence fordependency length minimization as a universal quantitative property oflanguages, beyond this previous work, because it provides baselines which focuson word order preferences. Second, we argue that our choices of baselines wereappropriate because they control for alternative theories.
arxiv-13800-236 | Similarity of symbol frequency distributions with heavy tails | http://arxiv.org/pdf/1510.00277v2.pdf | author:Martin Gerlach, Francesc Font-Clos, Eduardo G. Altmann category:physics.soc-ph cs.CL published:2015-10-01 summary:Quantifying the similarity between symbolic sequences is a traditionalproblem in Information Theory which requires comparing the frequencies ofsymbols in different sequences. In numerous modern applications, ranging fromDNA over music to texts, the distribution of symbol frequencies ischaracterized by heavy-tailed distributions (e.g., Zipf's law). The largenumber of low-frequency symbols in these distributions poses major difficultiesto the estimation of the similarity between sequences, e.g., they hinder anaccurate finite-size estimation of entropies. Here we show analytically how thesystematic (bias) and statistical (fluctuations) errors in these estimationsdepend on the sample size~$N$ and on the exponent~$\gamma$ of the heavy-taileddistribution. Our results are valid for the Shannon entropy $(\alpha=1)$, itscorresponding similarity measures (e.g., the Jensen-Shanon divergence), andalso for measures based on the generalized entropy of order $\alpha$. For small$\alpha$'s, including $\alpha=1$, the errors decay slower than the $1/N$-decayobserved in short-tailed distributions. For $\alpha$ larger than a criticalvalue $\alpha^* = 1+1/\gamma \leq 2$, the $1/N$-decay is recovered. We show thepractical significance of our results by quantifying the evolution of theEnglish language over the last two centuries using a complete $\alpha$-spectrumof measures. We find that frequent words change more slowly than less frequentwords and that $\alpha=2$ provides the most robust measure to quantify languagechange.
arxiv-13800-237 | Fast Single Image Super-Resolution | http://arxiv.org/pdf/1510.00143v3.pdf | author:Ningning Zhao, Qi Wei, Adrian Basarab, Nicolas Dobigeon, Denis Kouame, Jean-Yves Tourneret category:cs.CV published:2015-10-01 summary:This paper addresses the problem of single image super-resolution (SR), whichconsists of recovering a high resolution image from its blurred, decimated andnoisy version. The existing algorithms for single image SR use differentstrategies to handle the decimation and blurring operators. In addition to thetraditional first-order gradient methods, recent techniques investigatesplitting-based methods dividing the SR problem into up-sampling anddeconvolution steps that can be easily solved. Instead of following thissplitting strategy, we propose to deal with the decimation and blurringoperators simultaneously by taking advantage of their particular properties inthe frequency domain, leading to a new fast SR approach. Specifically, ananalytical solution can be obtained and implemented efficiently for theGaussian prior or any other regularization that can be formulated into an$\ell_2$-regularized quadratic model, i.e., an $\ell_2$-$\ell_2$ optimizationproblem. Furthermore, the flexibility of the proposed SR scheme is shownthrough the use of various priors/regularizations, ranging from generic imagepriors to learning-based approaches. In the case of non-Gaussian priors, weshow how the analytical solution derived from the Gaussian case can be embeddedintotraditional splitting frameworks, allowing the computation cost of existingalgorithms to be decreased significantly. Simulation results conducted onseveral images with different priors illustrate the effectiveness of our fastSR approach compared with the existing techniques.
arxiv-13800-238 | Off-the-Grid Recovery of Piecewise Constant Images from Few Fourier Samples | http://arxiv.org/pdf/1510.00384v2.pdf | author:Greg Ongie, Mathews Jacob category:cs.CV published:2015-10-01 summary:We introduce a method to recover a continuous domain representation of apiecewise constant two-dimensional image from few low-pass Fourier samples.Assuming the edge set of the image is localized to the zero set of atrigonometric polynomial, we show the Fourier coefficients of the partialderivatives of the image satisfy a linear annihilation relation. We presentnecessary and sufficient conditions for unique recovery of the image fromfinite low-pass Fourier samples using the annihilation relation. We alsopropose a practical two-stage recovery algorithm which is robust tomodel-mismatch and noise. In the first stage we estimate a continuous domainrepresentation of the edge set of the image. In the second stage we perform anextrapolation in Fourier domain by a least squares two-dimensional linearprediction, which recovers the exact Fourier coefficients of the underlyingimage. We demonstrate our algorithm on the super-resolution recovery of MRIphantoms and real MRI data from low-pass Fourier samples, which shows benefitsover standard approaches for single-image super-resolution MRI.
arxiv-13800-239 | Supporting Regularized Logistic Regression Privately and Efficiently | http://arxiv.org/pdf/1510.00095v1.pdf | author:Wenfa Li, Hongzhe Liu, Peng Yang, Wei Xie category:cs.LG cs.CR q-bio.GN published:2015-10-01 summary:As one of the most popular statistical and machine learning models, logisticregression with regularization has found wide adoption in biomedicine, socialsciences, information technology, and so on. These domains often involve dataof human subjects that are contingent upon strict privacy regulations.Increasing concerns over data privacy make it more and more difficult tocoordinate and conduct large-scale collaborative studies, which typically relyon cross-institution data sharing and joint analysis. Our work here focuses onsafeguarding regularized logistic regression, a widely-used machine learningmodel in various disciplines while at the same time has not been investigatedfrom a data security and privacy perspective. We consider a common use scenarioof multi-institution collaborative studies, such as in the form of researchconsortia or networks as widely seen in genetics, epidemiology, socialsciences, etc. To make our privacy-enhancing solution practical, we demonstratea non-conventional and computationally efficient method leveraging distributingcomputing and strong cryptography to provide comprehensive protection overindividual-level and summary data. Extensive empirical evaluation on severalstudies validated the privacy guarantees, efficiency and scalability of ourproposal. We also discuss the practical implications of our solution forlarge-scale studies and applications from various disciplines, includinggenetic and biomedical studies, smart grid, network analysis, etc.
arxiv-13800-240 | Clamping Improves TRW and Mean Field Approximations | http://arxiv.org/pdf/1510.00087v1.pdf | author:Adrian Weller, Justin Domke category:cs.LG cs.AI stat.ML published:2015-10-01 summary:We examine the effect of clamping variables for approximate inference inundirected graphical models with pairwise relationships and discrete variables.For any number of variable labels, we demonstrate that clamping and summingapproximate sub-partition functions can lead only to a decrease in thepartition function estimate for TRW, and an increase for the naive mean fieldmethod, in each case guaranteeing an improvement in the approximation andbound. We next focus on binary variables, add the Bethe approximation toconsideration and examine ways to choose good variables to clamp, introducingnew methods. We show the importance of identifying highly frustrated cycles,and of checking the singleton entropy of a variable. We explore the value ofour methods by empirical analysis and draw lessons to guide practitioners.
arxiv-13800-241 | QUDA: A Direct Approach for Sparse Quadratic Discriminant Analysis | http://arxiv.org/pdf/1510.00084v2.pdf | author:Binyan Jiang, Xiangyu Wang, Chenlei Leng category:stat.ME stat.CO stat.ML published:2015-10-01 summary:Quadratic discriminant analysis (QDA) is a standard tool for classificationdue to its simplicity and flexibility. Because the number of its parametersscales quadratically with the number of the variables, QDA is not practical,however, when the dimensionality is relatively large. To address this, wepropose a novel procedure named QUDA for QDA in analyzing high-dimensionaldata. Formulated in a simple and coherent framework, QUDA aims to directlyestimate the key quantities in the Bayes discriminant function includingquadratic interactions and a linear index of the variables for classification.Under appropriate sparsity assumptions, we establish consistency results forestimating the interactions and the linear index, and further demonstrate thatthe misclassification rate of our procedure converges to the optimal Bayesrisk, even when the dimensionality is exponentially high with respect to thesample size. An efficient algorithm based on the alternating direction methodof multipliers (ADMM) is developed for finding interactions, which is muchfaster than its competitor in the literature. The promising performance of QUDAis illustrated via extensive simulation studies and the analysis of twodatasets.
arxiv-13800-242 | Optimal Binary Classifier Aggregation for General Losses | http://arxiv.org/pdf/1510.00452v4.pdf | author:Akshay Balsubramani, Yoav Freund category:cs.LG stat.ML published:2015-10-01 summary:We address the problem of aggregating an ensemble of binary classifiers in asemi-supervised setting. Recently, this problem was solved optimally using agame-theoretic approach, but that analysis was specific to the 0-1 loss. Inthis paper, we generalize the minimax optimal algorithm of the previous work toa very general, novel class of loss functions, including but not limited to allconvex surrogates, while extending its performance and efficiency guarantees. The result is a family of parameter-free ensemble aggregation algorithmswhich use labeled and unla- beled data; these are as efficient as linearlearning and prediction for convex risk minimization, but work without anyrelaxations on many non-convex loss functions. The prediction algorithms take aform familiar in decision theory, applying sigmoid functions to a generalizednotion of ensemble margin, but without the assumptions typically made inmargin-based learning.
arxiv-13800-243 | Higher-order asymptotics for the parametric complexity | http://arxiv.org/pdf/1510.00112v3.pdf | author:James G. Dowty category:cs.IT math.IT stat.ME stat.ML published:2015-10-01 summary:The parametric complexity is the key quantity in the minimum descriptionlength (MDL) approach to statistical model selection. Rissanen and others haveshown that the parametric complexity of a statistical model approaches a simplefunction of the Fisher information volume of the model as the sample size $n$goes to infinity. This paper derives higher-order asymptotic expansions for theparametric complexity, in the case of exponential families and independent andidentically distributed data. These higher-order approximations are calculatedfor some examples and are shown to have better finite-sample behaviour thanRissanen's approximation. The higher-order terms are given as expressionsinvolving cumulants (or, more naturally, the Amari-Chentsov tensors), and theseterms are likely to be interesting in themselves since they arise naturallyfrom the general information-theoretic principles underpinning MDL. Thederivation given here specializes to an alternative and arguably simpler proofof Rissanen's result (for the case considered here), proving for the first timethat his approximation is $O(n^{-1})$.
arxiv-13800-244 | Multimodal Hierarchical Dirichlet Process-based Active Perception | http://arxiv.org/pdf/1510.00331v3.pdf | author:Tadahiro Taniguchi, Toshiaki Takano, Ryo Yoshino category:cs.RO cs.AI stat.ML published:2015-10-01 summary:In this paper, we propose an active perception method for recognizing objectcategories based on the multimodal hierarchical Dirichlet process (MHDP). TheMHDP enables a robot to form object categories using multimodal information,e.g., visual, auditory, and haptic information, which can be observed byperforming actions on an object. However, performing many actions on a targetobject requires a long time. In a real-time scenario, i.e., when the time islimited, the robot has to determine the set of actions that is most effectivefor recognizing a target object. We propose an MHDP-based active perceptionmethod that uses the information gain (IG) maximization criterion and lazygreedy algorithm. We show that the IG maximization criterion is optimal in thesense that the criterion is equivalent to a minimization of the expectedKullback--Leibler divergence between a final recognition state and therecognition state after the next set of actions. However, a straightforwardcalculation of IG is practically impossible. Therefore, we derive an efficientMonte Carlo approximation method for IG by making use of a property of theMHDP. We also show that the IG has submodular and non-decreasing properties asa set function because of the structure of the graphical model of the MHDP.Therefore, the IG maximization problem is reduced to a submodular maximizationproblem. This means that greedy and lazy greedy algorithms are effective andhave a theoretical justification for their performance. We conducted anexperiment using an upper-torso humanoid robot and a second one using syntheticdata. The experimental results show that the method enables the robot to selecta set of actions that allow it to recognize target objects quickly andaccurately. The results support our theoretical outcomes.
arxiv-13800-245 | Convolutional Networks on Graphs for Learning Molecular Fingerprints | http://arxiv.org/pdf/1509.09292v2.pdf | author:David Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael Gómez-Bombarelli, Timothy Hirzel, Alán Aspuru-Guzik, Ryan P. Adams category:cs.LG cs.NE stat.ML published:2015-09-30 summary:We introduce a convolutional neural network that operates directly on graphs.These networks allow end-to-end learning of prediction pipelines whose inputsare graphs of arbitrary size and shape. The architecture we present generalizesstandard molecular feature extraction methods based on circular fingerprints.We show that these data-driven features are more interpretable, and have betterpredictive performance on a variety of tasks.
arxiv-13800-246 | Convergence of Stochastic Gradient Descent for PCA | http://arxiv.org/pdf/1509.09002v2.pdf | author:Ohad Shamir category:cs.LG math.OC stat.ML published:2015-09-30 summary:We consider the problem of principal component analysis (PCA) in a streamingstochastic setting, where our goal is to find a direction of approximatemaximal variance, based on a stream of i.i.d. data points in $\reals^d$. Asimple and computationally cheap algorithm for this is stochastic gradientdescent (SGD), which incrementally updates its estimate based on each new datapoint. However, due to the non-convex nature of the problem, analyzing itsperformance has been a challenge. In particular, existing guarantees rely on anon-trivial eigengap assumption on the covariance matrix, which is intuitivelyunnecessary. In this paper, we provide (to the best of our knowledge) the firsteigengap-free convergence guarantees for SGD in the context of PCA. This alsopartially resolves an open problem posed in \cite{hardt2014noisy}. Moreover,under an eigengap assumption, we show that the same techniques lead to new SGDconvergence guarantees with better dependence on the eigengap.
arxiv-13800-247 | A spatial compositional model (SCM) for linear unmixing and endmember uncertainty estimation | http://arxiv.org/pdf/1509.09243v1.pdf | author:Yuan Zhou, Anand Rangarajan, Paul Gader category:cs.CV published:2015-09-30 summary:The normal compositional model (NCM) has been extensively used inhyperspectral unmixing. However, most of the previous research has focused onestimation of endmembers and/or their variability. Also, little work hasemployed spatial information in NCM. In this paper, we show that NCM can beused for calculating the uncertainty of the estimated endmembers with spatialpriors incorporated for better unmixing. This results in a spatialcompositional model (SCM) which features (i) spatial priors that forceneighboring abundances to be similar based on their pixel similarity and (ii) aposterior that is obtained from a likelihood model which does not assume pixelindependence. The resulting algorithm turns out to be easy to implement andefficient to run. We compared SCM with current state-of-the-art algorithms onsynthetic and real images. The results show that SCM can in the main providemore accurate endmembers and abundances. Moreover, the estimated uncertaintycan serve as a prediction of endmember error under certain conditions.
arxiv-13800-248 | Generative Adversarial Networks in Estimation of Distribution Algorithms for Combinatorial Optimization | http://arxiv.org/pdf/1509.09235v1.pdf | author:Malte Probst category:cs.NE published:2015-09-30 summary:Estimation of Distribution Algorithms (EDAs) require flexible probabilitymodels that can be efficiently learned and sampled. Generative AdversarialNetworks (GAN) are generative neural networks which can be trained toimplicitly model the probability distribution of given data, and it is possibleto sample this distribution. We integrate a GAN into an EDA and evaluate theperformance of this system when solving combinatorial optimization problemswith a single objective. We use several standard benchmark problems and comparethe results to state-of-the-art multivariate EDAs. GAN-EDA doe not yieldcompetitive results - the GAN lacks the ability to quickly learn a goodapproximation of the probability distribution. A key reason seems to be thelarge amount of noise present in the first EDA generations.
arxiv-13800-249 | Fault Tolerance in Distributed Neural Computing | http://arxiv.org/pdf/1509.09199v1.pdf | author:Anton Kulakov, Mark Zwolinski, Jeff Reeve category:cs.NE cs.DC published:2015-09-30 summary:With the increasing complexity of computing systems, complete hardwarereliability can no longer be guaranteed. We need, however, to ensure overallsystem reliability. One of the most important features of artificial neuralnetworks is their intrinsic fault-tolerance. The aim of this work is toinvestigate whether such networks have features that can be applied to widercomputational systems. This paper presents an analysis, in both the learningand operational phases, of a distributed feed-forward neural network withdecentralised event-driven time management, which is insensitive tointermittent faults caused by unreliable communication or faulty hardwarecomponents. The learning rules used in the model are local in space and time,which allows efficient scalable distributed implementation. We investigate theoverhead caused by injected faults and analyse the sensitivity to limitedfailures in the computational hardware in different areas of the network.
arxiv-13800-250 | Deep Haar Scattering Networks | http://arxiv.org/pdf/1509.09187v1.pdf | author:Xiuyuan Cheng, Xu Chen, Stephane Mallat category:cs.LG published:2015-09-30 summary:An orthogonal Haar scattering transform is a deep network, computed with ahierarchy of additions, subtractions and absolute values, over pairs ofcoefficients. It provides a simple mathematical model for unsupervised deepnetwork learning. It implements non-linear contractions, which are optimizedfor classification, with an unsupervised pair matching algorithm, of polynomialcomplexity. A structured Haar scattering over graph data computes permutationinvariant representations of groups of connected points in the graph. If thegraph connectivity is unknown, unsupervised Haar pair learning can provide aconsistent estimation of connected dyadic groups of points. Classificationresults are given on image data bases, defined on regular grids or graphs, witha connectivity which may be known or unknown.
arxiv-13800-251 | Towards Trainable Media: Using Waves for Neural Network-Style Training | http://arxiv.org/pdf/1510.03776v1.pdf | author:Michiel Hermans, Thomas Van Vaerenbergh category:cs.NE physics.optics published:2015-09-30 summary:In this paper we study the concept of using the interaction between waves anda trainable medium in order to construct a matrix-vector multiplier. Inparticular we study such a device in the context of the backpropagationalgorithm, which is commonly used for training neural networks. Here, theweights of the connections between neurons are trained by multiplying a`forward' signal with a backwards propagating `error' signal. We show that thisconcept can be extended to trainable media, where the gradient for the localwave number is given by multiplying signal waves and error waves. We provide anumerical example of such a system with waves traveling freely in a trainablemedium, and we discuss a potential way to build such a device in an integratedphotonics chip.
arxiv-13800-252 | Learning From Missing Data Using Selection Bias in Movie Recommendation | http://arxiv.org/pdf/1509.09130v1.pdf | author:Claire Vernade, Olivier Cappé category:stat.ML cs.IR cs.LG cs.SI published:2015-09-30 summary:Recommending items to users is a challenging task due to the large amount ofmissing information. In many cases, the data solely consist of ratings or tagsvoluntarily contributed by each user on a very limited subset of the availableitems, so that most of the data of potential interest is actually missing.Current approaches to recommendation usually assume that the unobserved data ismissing at random. In this contribution, we provide statistical evidence thatexisting movie recommendation datasets reveal a significant positiveassociation between the rating of items and the propensity to select theseitems. We propose a computationally efficient variational approach that makesit possible to exploit this selection bias so as to improve the estimation ofratings from small populations of users. Results obtained with this approachapplied to neighborhood-based collaborative filtering illustrate its potentialfor improving the reliability of the recommendation.
arxiv-13800-253 | Maximum Likelihood Learning With Arbitrary Treewidth via Fast-Mixing Parameter Sets | http://arxiv.org/pdf/1509.08992v2.pdf | author:Justin Domke category:cs.LG stat.ML published:2015-09-30 summary:Inference is typically intractable in high-treewidth undirected graphicalmodels, making maximum likelihood learning a challenge. One way to overcomethis is to restrict parameters to a tractable set, most typically the set oftree-structured parameters. This paper explores an alternative notion of atractable set, namely a set of "fast-mixing parameters" where Markov chainMonte Carlo (MCMC) inference can be guaranteed to quickly converge to thestationary distribution. While it is common in practice to approximate thelikelihood gradient using samples obtained from MCMC, such procedures lacktheoretical guarantees. This paper proves that for any exponential family withbounded sufficient statistics, (not just graphical models) when parameters areconstrained to a fast-mixing set, gradient descent with gradients approximatedby sampling will approximate the maximum likelihood solution inside the setwith high-probability. When unregularized, to find a solution epsilon-accuratein log-likelihood requires a total amount of effort cubic in 1/epsilon,disregarding logarithmic factors. When ridge-regularized, strong convexityallows a solution epsilon-accurate in parameter distance with effort quadraticin 1/epsilon. Both of these provide of a fully-polynomial time randomizedapproximation scheme.
arxiv-13800-254 | The "handedness" of language: Directional symmetry breaking of sign usage in words | http://arxiv.org/pdf/1509.09121v1.pdf | author:Md Izhar Ashraf, Sitabhra Sinha category:cs.CL published:2015-09-30 summary:Using large written corpora for many different scripts, we show that theoccurrence probability distributions of signs at the left and right ends ofwords have a distinct heterogeneous nature. Characterizing this asymmetry usingquantitative inequality measures, we show that the beginning of a word is lessrestrictive in sign usage than the end. The asymmetry is also seen inundeciphered inscriptions and we use this to infer the direction of writingwhich agrees with archaeological evidence. Unlike traditional investigations ofphonotactic constraints which focus on language-specific patterns, our studyreveals a property valid across languages and writing systems. As both languageand writing are unique aspects of our species, this universal signature mayreflect an innate feature of the human cognitive phenomenon.
arxiv-13800-255 | Online Object Tracking with Proposal Selection | http://arxiv.org/pdf/1509.09114v1.pdf | author:Yang Hua, Karteek Alahari, Cordelia Schmid category:cs.CV published:2015-09-30 summary:Tracking-by-detection approaches are some of the most successful objecttrackers in recent years. Their success is largely determined by the detectormodel they learn initially and then update over time. However, underchallenging conditions where an object can undergo transformations, e.g.,severe rotation, these methods are found to be lacking. In this paper, weaddress this problem by formulating it as a proposal selection task and makingtwo contributions. The first one is introducing novel proposals estimated fromthe geometric transformations undergone by the object, and building a richcandidate set for predicting the object location. The second one is devising anovel selection strategy using multiple cues, i.e., detection score andedgeness score computed from state-of-the-art object edges and motionboundaries. We extensively evaluate our approach on the visual object tracking2014 challenge and online tracking benchmark datasets, and show the bestperformance.
arxiv-13800-256 | General Dynamic Scene Reconstruction from Multiple View Video | http://arxiv.org/pdf/1509.09294v1.pdf | author:Armin Mustafa, Hansung Kim, Jean-Yves Guillemaut, Adrian Hilton category:cs.CV published:2015-09-30 summary:This paper introduces a general approach to dynamic scene reconstruction frommultiple moving cameras without prior knowledge or limiting constraints on thescene structure, appearance, or illumination. Existing techniques for dynamicscene reconstruction from multiple wide-baseline camera views primarily focuson accurate reconstruction in controlled environments, where the cameras arefixed and calibrated and background is known. These approaches are not robustfor general dynamic scenes captured with sparse moving cameras. Previousapproaches for outdoor dynamic scene reconstruction assume prior knowledge ofthe static background appearance and structure. The primary contributions ofthis paper are twofold: an automatic method for initial coarse dynamic scenesegmentation and reconstruction without prior knowledge of backgroundappearance or structure; and a general robust approach for joint segmentationrefinement and dense reconstruction of dynamic scenes from multiplewide-baseline static or moving cameras. Evaluation is performed on a variety ofindoor and outdoor scenes with cluttered backgrounds and multiple dynamicnon-rigid objects such as people. Comparison with state-of-the-art approachesdemonstrates improved accuracy in both multiple view segmentation and densereconstruction. The proposed approach also eliminates the requirement for priorknowledge of scene structure and appearance.
arxiv-13800-257 | Polish to English Statistical Machine Translation | http://arxiv.org/pdf/1510.00001v1.pdf | author:Krzysztof Wołk category:cs.CL stat.ML published:2015-09-30 summary:This research explores the effects of various training settings on a Polishto English Statistical Machine Translation system for spoken language. Variouselements of the TED, Europarl, and OPUS parallel text corpora were used as thebasis for training of language models, for development, tuning and testing ofthe translation system. The BLEU, NIST, METEOR and TER metrics were used toevaluate the effects of the data preparations on the translation results.
arxiv-13800-258 | Polish - English Speech Statistical Machine Translation Systems for the IWSLT 2013 | http://arxiv.org/pdf/1509.09097v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL stat.ML published:2015-09-30 summary:This research explores the effects of various training settings from Polishto English Statistical Machine Translation system for spoken language. Variouselements of the TED parallel text corpora for the IWSLT 2013 evaluationcampaign were used as the basis for training of language models, and fordevelopment, tuning and testing of the translation system. The BLEU, NIST,METEOR and TER metrics were used to evaluate the effects of data preparationson translation results. Our experiments included systems, which use stems andmorphological information on Polish words. We also conducted a deep analysis ofprovided Polish data as preparatory work for the automatic data correction andcleaning phase.
arxiv-13800-259 | A Sentence Meaning Based Alignment Method for Parallel Text Corpora Preparation | http://arxiv.org/pdf/1509.09093v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL cs.IR published:2015-09-30 summary:Text alignment is crucial to the accuracy of Machine Translation (MT)systems, some NLP tools or any other text processing tasks requiring bilingualdata. This research proposes a language independent sentence alignment approachbased on Polish (not position-sensitive language) to English experiments. Thisalignment approach was developed on the TED Talks corpus, but can be used forany text domain or language pair. The proposed approach implements variousheuristics for sentence recognition. Some of them value synonyms and semantictext structure analysis as a part of additional information. Minimization ofdata loss was ensured. The solution is compared to other sentence alignmentimplementations. Also an improvement in MT system score with text processedwith described tool is shown.
arxiv-13800-260 | Multi-objective Differential Evolution with Helper Functions for Constrained Optimization | http://arxiv.org/pdf/1509.09060v2.pdf | author:Tao Xu, Jun He category:cs.NE published:2015-09-30 summary:Solving constrained optimization problems by multi-objective evolutionaryalgorithms has scored tremendous achievements in the last decade. Standardmulti-objective schemes usually aim at minimizing the objective function andalso the degree of constraint violation simultaneously. This paper proposes anew multi-objective method for solving constrained optimization problems. Thenew method keeps two standard objectives: the original objective function andthe sum of degrees of constraint violation. But besides them, four moreobjectives are added. One is based on the feasible rule. The other three comefrom the penalty functions. This paper conducts an initial experimental studyon thirteen benchmark functions. A simplified version of CMODE is applied tosolving multi-objective optimization problems. Our initial experimental resultsconfirm our expectation that adding more helper functions could be useful. Theperformance of SMODE with more helper functions (four or six) is better thanthat with only two helper functions.
arxiv-13800-261 | On the Complexity of Robust PCA and $\ell_1$-norm Low-Rank Matrix Approximation | http://arxiv.org/pdf/1509.09236v2.pdf | author:Nicolas Gillis, Stephen A. Vavasis category:cs.LG cs.CC math.NA math.OC published:2015-09-30 summary:The low-rank matrix approximation problem with respect to the component-wise$\ell_1$-norm ($\ell_1$-LRA), which is closely related to robust principalcomponent analysis (PCA), has become a very popular tool in data mining andmachine learning. Robust PCA aims at recovering a low-rank matrix that wasperturbed with sparse noise, with applications for example inforeground-background video separation. Although $\ell_1$-LRA is stronglybelieved to be NP-hard, there is, to the best of our knowledge, no formal proofof this fact. In this paper, we prove that $\ell_1$-LRA is NP-hard, already inthe rank-one case, using a reduction from MAX CUT. Our derivations drawinteresting connections between $\ell_1$-LRA and several other well-knownproblems, namely, robust PCA, $\ell_0$-LRA, binary matrix factorization, aparticular densest bipartite subgraph problem, the computation of the cut normof $\{-1,+1\}$ matrices, and the discrete basis problem, which we all prove tobe NP-hard.
arxiv-13800-262 | Distributionally Robust Logistic Regression | http://arxiv.org/pdf/1509.09259v3.pdf | author:Soroosh Shafieezadeh-Abadeh, Peyman Mohajerin Esfahani, Daniel Kuhn category:math.OC stat.ML published:2015-09-30 summary:This paper proposes a distributionally robust approach to logisticregression. We use the Wasserstein distance to construct a ball in the space ofprobability distributions centered at the uniform distribution on the trainingsamples. If the radius of this ball is chosen judiciously, we can guaranteethat it contains the unknown data-generating distribution with high confidence.We then formulate a distributionally robust logistic regression model thatminimizes a worst-case expected logloss function, where the worst case is takenover all distributions in the Wasserstein ball. We prove that this optimizationproblem admits a tractable reformulation and encapsulates the classical as wellas the popular regularized logistic regression problems as special cases. Wefurther propose a distributionally robust approach based on Wasserstein ballsto compute upper and lower confidence bounds on the misclassificationprobability of the resulting classifier. These bounds are given by the optimalvalues of two highly tractable linear programs. We validate our theoreticalout-of-sample guarantees through simulated and empirical experiments.
arxiv-13800-263 | Real-Time Statistical Speech Translation | http://arxiv.org/pdf/1509.09090v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL stat.ML published:2015-09-30 summary:This research investigates the Statistical Machine Translation approaches totranslate speech in real time automatically. Such systems can be used in apipeline with speech recognition and synthesis software in order to produce areal-time voice communication system between foreigners. We obtained three maindata sets from spoken proceedings that represent three different types of humanspeech. TED, Europarl, and OPUS parallel text corpora were used as the basisfor training of language models, for developmental tuning and testing of thetranslation system. We also conducted experiments involving part of speechtagging, compound splitting, linear language model interpolation, TrueCasingand morphosyntactic analysis. We evaluated the effects of variety of datapreparations on the translation results using the BLEU, NIST, METEOR and TERmetrics and tried to give answer which metric is most suitable for PL-ENlanguage pair.
arxiv-13800-264 | Stats-Calculus Pose Descriptor Feeding A Discrete HMM Low-latency Detection and Recognition System For 3D Skeletal Actions | http://arxiv.org/pdf/1509.09014v4.pdf | author:Rofael Emil Fayez Behnam category:cs.CV published:2015-09-30 summary:Recognition of human actions, under low observational latency, is a growinginterest topic, nowadays. Many approaches have been represented based on aprovided set of 3D Cartesian coordinates system originated at a certainspecific point located on a root joint. In this paper, We will present astatistical detection and recognition system using Hidden Markov Model using 7types of pose descriptors. * Cartesian Calculus Pose descriptor. * AngularCalculus Pose descriptor. * Mixed-mode Stats-Calculus Pose descriptor. *Centro-Stats-Calculus Pose descriptor. * Rela-Centro-Stats-Calculus Posedescriptor. * Rela-Centro-Stats-Calculus DCT Pose descriptor. *Rela-Centro-Stats-Calculus DCT-AMDF Pose descriptor. Stats-Calculus is afeature extracting technique, that is developed on Moving Pose descriptor , butusing a combination of Statistics measures and Calculus measures.
arxiv-13800-265 | Moving Object Detection in Video Using Saliency Map and Subspace Learning | http://arxiv.org/pdf/1509.09089v1.pdf | author:Yanwei Pang, Li Ye, Xuelong Li, Jing Pan category:cs.CV published:2015-09-30 summary:Moving object detection is a key to intelligent video analysis. On the onehand, what moves is not only interesting objects but also noise and clutteredbackground. On the other hand, moving objects without rich texture are pronenot to be detected. So there are undesirable false alarms and missed alarms inmany algorithms of moving object detection. To reduce the false alarms andmissed alarms, in this paper, we propose to incorporate a saliency map into anincremental subspace analysis framework where the saliency map makes estimatedbackground has less chance than foreground (i.e., moving objects) to containsalient objects. The proposed objective function systematically takes accountinto the properties of sparsity, low-rank, connectivity, and saliency. Analternative minimization algorithm is proposed to seek the optimal solutions.Experimental results on the Perception Test Images Sequences demonstrate thatthe proposed method is effective in reducing false alarms and missed alarms.
arxiv-13800-266 | Fast Discrete Distribution Clustering Using Wasserstein Barycenter with Sparse Support | http://arxiv.org/pdf/1510.00012v2.pdf | author:Jianbo Ye, Panruo Wu, James Z. Wang, Jia Li category:stat.CO cs.LG stat.ML published:2015-09-30 summary:In a variety of research areas, the bag of weighted vectors and the histogramare widely used descriptors for complex objects. Both can be expressed asdiscrete distributions. D2-clustering pursues the minimum total within-clustervariation for a set of discrete distributions subject to theKantorovich-Wasserstein metric. D2-clustering has a severe scalability issue,the bottleneck being the computation of a centroid distribution, calledWasserstein barycenter, that minimizes its sum of squared distances to thecluster members. In this paper, we develop a modified Bregman ADMM approach forcomputing the approximate discrete Wasserstein barycenter of large clusters. Inthe case when the support points of the barycenters are unknown and of lowcardinality, our method achieves high accuracy empirically at a much reducedcomputational cost. The strengths and weaknesses of our method and itsalternatives are examined through experiments; and scenarios for theirrespective usage are recommended. Moreover, we develop both serial andparallelized versions of the algorithm. By experimenting with large-scale data,we demonstrate the computational efficiency of the new methods and investigatetheir convergence properties and numerical stability. The clustering resultsobtained on several datasets in different domains are highly competitive incomparison with some widely used methods' in the corresponding areas.
arxiv-13800-267 | Enhanced Bilingual Evaluation Understudy | http://arxiv.org/pdf/1509.09088v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL stat.ML published:2015-09-30 summary:Our research extends the Bilingual Evaluation Understudy (BLEU) evaluationtechnique for statistical machine translation to make it more adjustable androbust. We intend to adapt it to resemble human evaluation more. We performexperiments to evaluate the performance of our technique against the primaryexisting evaluation methods. We describe and show the improvements it makesover existing methods as well as correlation to them. When human translatorstranslate a text, they often use synonyms, different word orders or style, andother similar variations. We propose an SMT evaluation technique that enhancesthe BLEU metric to consider variations such as those.
arxiv-13800-268 | Distributed Weighted Parameter Averaging for SVM Training on Big Data | http://arxiv.org/pdf/1509.09030v1.pdf | author:Ayan Das, Sourangshu Bhattacharya category:cs.LG published:2015-09-30 summary:Two popular approaches for distributed training of SVMs on big data areparameter averaging and ADMM. Parameter averaging is efficient but suffers fromloss of accuracy with increase in number of partitions, while ADMM in thefeature space is accurate but suffers from slow convergence. In this paper, wereport a hybrid approach called weighted parameter averaging (WPA), whichoptimizes the regularized hinge loss with respect to weights on parameters. Theproblem is shown to be same as solving SVM in a projected space. We alsodemonstrate an $O(\frac{1}{N})$ stability bound on final hypothesis given byWPA, using novel proof techniques. Experimental results on a variety of toy andreal world datasets show that our approach is significantly more accurate thanparameter averaging for high number of partitions. It is also seen the proposedmethod enjoys much faster convergence compared to ADMM in features space.
arxiv-13800-269 | Regret Lower Bound and Optimal Algorithm in Finite Stochastic Partial Monitoring | http://arxiv.org/pdf/1509.09011v1.pdf | author:Junpei Komiyama, Junya Honda, Hiroshi Nakagawa category:stat.ML cs.LG published:2015-09-30 summary:Partial monitoring is a general model for sequential learning with limitedfeedback formalized as a game between two players. In this game, the learnerchooses an action and at the same time the opponent chooses an outcome, thenthe learner suffers a loss and receives a feedback signal. The goal of thelearner is to minimize the total loss. In this paper, we study partialmonitoring with finite actions and stochastic outcomes. We derive a logarithmicdistribution-dependent regret lower bound that defines the hardness of theproblem. Inspired by the DMED algorithm (Honda and Takemura, 2010) for themulti-armed bandit problem, we propose PM-DMED, an algorithm that minimizes thedistribution-dependent regret. PM-DMED significantly outperformsstate-of-the-art algorithms in numerical experiments. To show the optimality ofPM-DMED with respect to the regret bound, we slightly modify the algorithm byintroducing a hinge function (PM-DMED-Hinge). Then, we derive an asymptoticallyoptimal regret upper bound of PM-DMED-Hinge that matches the lower bound.
arxiv-13800-270 | Learning without Recall: A Case for Log-Linear Learning | http://arxiv.org/pdf/1509.08990v1.pdf | author:Mohammad Amin Rahimian, Ali Jadbabaie category:cs.SI cs.LG cs.SY math.OC stat.ML published:2015-09-30 summary:We analyze a model of learning and belief formation in networks in whichagents follow Bayes rule yet they do not recall their history of pastobservations and cannot reason about how other agents' beliefs are formed. Theydo so by making rational inferences about their observations which include asequence of independent and identically distributed private signals as well asthe beliefs of their neighboring agents at each time. Fully rational agentswould successively apply Bayes rule to the entire history of observations. Thisleads to forebodingly complex inferences due to lack of knowledge about theglobal network structure that causes those observations. To address thesecomplexities, we consider a Learning without Recall model, which in addition toproviding a tractable framework for analyzing the behavior of rational agentsin social networks, can also provide a behavioral foundation for the variety ofnon-Bayesian update rules in the literature. We present the implications ofvarious choices for time-varying priors of such agents and how this choiceaffects learning and its rate.
arxiv-13800-271 | Fast Algorithms for Convolutional Neural Networks | http://arxiv.org/pdf/1509.09308v2.pdf | author:Andrew Lavin, Scott Gray category:cs.NE cs.LG I.2.6; F.2.1 published:2015-09-30 summary:Deep convolutional neural networks take GPU days of compute time to train onlarge data sets. Pedestrian detection for self driving cars requires very lowlatency. Image recognition for mobile phones is constrained by limitedprocessing resources. The success of convolutional neural networks in thesesituations is limited by how fast we can compute them. Conventional FFT basedconvolution is fast for large filters, but state of the art convolutionalneural networks use small, 3x3 filters. We introduce a new class of fastalgorithms for convolutional neural networks using Winograd's minimal filteringalgorithms. The algorithms compute minimal complexity convolution over smalltiles, which makes them fast with small filters and small batch sizes. Webenchmark a GPU implementation of our algorithm with the VGG network and showstate of the art throughput at batch sizes from 1 to 64.
arxiv-13800-272 | Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree | http://arxiv.org/pdf/1509.08985v2.pdf | author:Chen-Yu Lee, Patrick W. Gallagher, Zhuowen Tu category:stat.ML cs.LG cs.NE published:2015-09-30 summary:We seek to improve deep neural networks by generalizing the poolingoperations that play a central role in current architectures. We pursue acareful exploration of approaches to allow pooling to learn and to adapt tocomplex and variable patterns. The two primary directions lie in (1) learning apooling function via (two strategies of) combining of max and average pooling,and (2) learning a pooling function in the form of a tree-structured fusion ofpooling filters that are themselves learned. In our experiments everygeneralized pooling operation we explore improves performance when used inplace of average or max pooling. We experimentally demonstrate that theproposed pooling operations provide a boost in invariance properties relativeto conventional pooling and set the state of the art on several widely adoptedbenchmark datasets; they are also easy to implement, and can be applied withinvarious deep neural network architectures. These benefits come with only alight increase in computational overhead during training and a very modestincrease in the number of model parameters.
arxiv-13800-273 | Symbol Emergence in Robotics: A Survey | http://arxiv.org/pdf/1509.08973v1.pdf | author:Tadahiro Taniguchi, Takayuki Nagai, Tomoaki Nakamura, Naoto Iwahashi, Tetsuya Ogata, Hideki Asoh category:cs.AI cs.CL cs.CV cs.RO published:2015-09-29 summary:Humans can learn the use of language through physical interaction with theirenvironment and semiotic communication with other people. It is very importantto obtain a computational understanding of how humans can form a symbol systemand obtain semiotic skills through their autonomous mental development.Recently, many studies have been conducted on the construction of roboticsystems and machine-learning methods that can learn the use of language throughembodied multimodal interaction with their environment and other systems.Understanding human social interactions and developing a robot that cansmoothly communicate with human users in the long term, requires anunderstanding of the dynamics of symbol systems and is crucially important. Theembodied cognition and social interaction of participants gradually change asymbol system in a constructive manner. In this paper, we introduce a field ofresearch called symbol emergence in robotics (SER). SER is a constructiveapproach towards an emergent symbol system. The emergent symbol system issocially self-organized through both semiotic communications and physicalinteractions with autonomous cognitive developmental agents, i.e., humans anddevelopmental robots. Specifically, we describe some state-of-art researchtopics concerning SER, e.g., multimodal categorization, word discovery, and adouble articulation analysis, that enable a robot to obtain words and theirembodied meanings from raw sensory--motor information, including visualinformation, haptic information, auditory information, and acoustic speechsignals, in a totally unsupervised manner. Finally, we suggest futuredirections of research in SER.
arxiv-13800-274 | VLSI Implementation of Deep Neural Network Using Integral Stochastic Computing | http://arxiv.org/pdf/1509.08972v1.pdf | author:Arash Ardakani, François Leduc-Primeau, Naoya Onizawa, Takahiro Hanyu, Warren J. Gross category:cs.NE cs.AR published:2015-09-29 summary:The hardware implementation of deep neural networks (DNNs) has recentlyreceived tremendous attention: many applications in fact require high-speedoperations that suit a hardware implementation. However, numerous elements andcomplex interconnections are usually required, leading to a large areaoccupation and copious power consumption. Stochastic computing has shownpromising results for low-power area-efficient hardware implementations, eventhough existing stochastic algorithms require long streams that cause longlatencies. In this paper, we propose an integer form of stochastic computationand introduce some elementary circuits. We then propose an efficientimplementation of a DNN based on integral stochastic computing. The proposedarchitecture uses integer stochastic streams and a modified Finite StateMachine-based tanh function to perform computations and even reduce the latencycompared to conventional stochastic computation. The proposed architecture hasbeen implemented on a Virtex7 FPGA, resulting in 44.96% and 62.36% averagereductions in area and latency compared to the best reported architecture inliterature. We also synthesize the circuits in a 65 nm CMOS technology and showthat they can tolerate a fault rate of up to 20% on some computations whentiming violations are allowed to occur, resulting in power savings. Thefault-tolerance property of the proposed architectures make them suitable forinherently unreliable advanced process technologies such as memristortechnology.
arxiv-13800-275 | Light Field Reconstruction Using Shearlet Transform | http://arxiv.org/pdf/1509.08969v1.pdf | author:Suren Vagharshakyan, Robert Bregovic, Atanas Gotchev category:cs.CV published:2015-09-29 summary:In this article we develop an image based rendering technique based on lightfield reconstruction from a limited set of perspective views acquired bycameras. Our approach utilizes sparse representation of epipolar-plane imagesin a directionally sensitive transform domain, obtained by an adapted discreteshearlet transform. The used iterative thresholding algorithm provideshigh-quality reconstruction results for relatively big disparities betweenneighboring views. The generated densely sampled light field of a given 3Dscene is thus suitable for all applications which requires light fieldreconstruction. The proposed algorithm is compared favorably against state ofthe art depth image based rendering techniques.
arxiv-13800-276 | Polish -English Statistical Machine Translation of Medical Texts | http://arxiv.org/pdf/1509.08909v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL cs.IR stat.ML published:2015-09-29 summary:This new research explores the effects of various training methods on aPolish to English Statistical Machine Translation system for medical texts.Various elements of the EMEA parallel text corpora from the OPUS project wereused as the basis for training of phrase tables and language models and fordevelopment, tuning and testing of the translation system. The BLEU, NIST,METEOR, RIBES and TER metrics have been used to evaluate the effects of varioussystem and data preparations on translation results. Our experiments includedsystems that used POS tagging, factored phrase models, hierarchical models,syntactic taggers, and many different alignment methods. We also conducted adeep analysis of Polish data as preparatory work for automatic data correctionsuch as true casing and punctuation normalization phase.
arxiv-13800-277 | Foundations of Coupled Nonlinear Dimensionality Reduction | http://arxiv.org/pdf/1509.08880v2.pdf | author:Mehryar Mohri, Afshin Rostamizadeh, Dmitry Storcheus category:stat.ML cs.LG published:2015-09-29 summary:In this paper we introduce and analyze the learning scenario of \emph{couplednonlinear dimensionality reduction}, which combines two major steps of machinelearning pipeline: projection onto a manifold and subsequent supervisedlearning. First, we present new generalization bounds for this scenario and,second, we introduce an algorithm that follows from these bounds. Thegeneralization error bound is based on a careful analysis of the empiricalRademacher complexity of the relevant hypothesis set. In particular, we show anupper bound on the Rademacher complexity that is in $\widetildeO(\sqrt{\Lambda_{(r)}/m})$, where $m$ is the sample size and $\Lambda_{(r)}$the upper bound on the Ky-Fan $r$-norm of the associated kernel matrix. We giveboth upper and lower bound guarantees in terms of that Ky-Fan $r$-norm, whichstrongly justifies the definition of our hypothesis set. To the best of ourknowledge, these are the first learning guarantees for the problem of coupleddimensionality reduction. Our analysis and learning guarantees further apply toseveral special cases, such as that of using a fixed kernel with superviseddimensionality reduction or that of unsupervised learning of a kernel fordimensionality reduction followed by a supervised learning algorithm. Based ontheoretical analysis, we suggest a structural risk minimization algorithmconsisting of the coupled fitting of a low dimensional manifold and aseparation function on that manifold.
arxiv-13800-278 | Scalable Nonlinear Embeddings for Semantic Category-based Image Retrieval | http://arxiv.org/pdf/1509.08902v1.pdf | author:Gaurav Sharma, Bernt Schiele category:cs.CV published:2015-09-29 summary:We propose a novel algorithm for the task of supervised discriminativedistance learning by nonlinearly embedding vectors into a low dimensionalEuclidean space. We work in the challenging setting where supervision is withconstraints on similar and dissimilar pairs while training. The proposed methodis derived by an approximate kernelization of a linear Mahalanobis-likedistance metric learning algorithm and can also be seen as a kernel neuralnetwork. The number of model parameters and test time evaluation complexity ofthe proposed method are O(dD) where D is the dimensionality of the inputfeatures and d is the dimension of the projection space - this is in contrastto the usual kernelization methods as, unlike them, the complexity does notscale linearly with the number of training examples. We propose a stochasticgradient based learning algorithm which makes the method scalable (w.r.t. thenumber of training examples), while being nonlinear. We train the method withup to half a million training pairs of 4096 dimensional CNN features. We giveempirical comparisons with relevant baselines on seven challenging datasets forthe task of low dimensional semantic category based image retrieval.
arxiv-13800-279 | A Semi-Supervised Method for Predicting Cancer Survival Using Incomplete Clinical Data | http://arxiv.org/pdf/1509.08888v1.pdf | author:Hamid Reza Hassanzadeh, John H. Phan, May D. Wang category:cs.LG published:2015-09-29 summary:Prediction of survival for cancer patients is an open area of research.However, many of these studies focus on datasets with a large number ofpatients. We present a novel method that is specifically designed to addressthe challenge of data scarcity, which is often the case for cancer datasets.Our method is able to use unlabeled data to improve classification by adoptinga semi-supervised training approach to learn an ensemble classifier. Theresults of applying our method to three cancer datasets show the promise ofsemi-supervised learning for prediction of cancer survival.
arxiv-13800-280 | Building Subject-aligned Comparable Corpora and Mining it for Truly Parallel Sentence Pairs | http://arxiv.org/pdf/1509.08881v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL cs.IR stat.ML published:2015-09-29 summary:Parallel sentences are a relatively scarce but extremely useful resource formany applications including cross-lingual retrieval and statistical machinetranslation. This research explores our methodology for mining such data frompreviously obtained comparable corpora. The task is highly practical sincenon-parallel multilingual data exist in far greater quantities than parallelcorpora, but parallel sentences are a much more useful resource. Here wepropose a web crawling method for building subject-aligned comparable corporafrom Wikipedia articles. We also introduce a method for extracting trulyparallel sentences that are filtered out from noisy or just comparable sentencepairs. We describe our implementation of a specialized tool for this task aswell as training and adaption of a machine translation system that supplies ourfilter with additional information about the similarity of comparable sentencepairs.
arxiv-13800-281 | Polish - English Speech Statistical Machine Translation Systems for the IWSLT 2014 | http://arxiv.org/pdf/1509.08874v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL published:2015-09-29 summary:This research explores effects of various training settings between Polishand English Statistical Machine Translation systems for spoken language.Various elements of the TED parallel text corpora for the IWSLT 2014 evaluationcampaign were used as the basis for training of language models, and fordevelopment, tuning and testing of the translation system as well as Wikipediabased comparable corpora prepared by us. The BLEU, NIST, METEOR and TER metricswere used to evaluate the effects of data preparations on translation results.Our experiments included systems, which use lemma and morphological informationon Polish words. We also conducted a deep analysis of provided Polish data aspreparatory work for the automatic data correction and cleaning phase.
arxiv-13800-282 | Very Deep Multilingual Convolutional Neural Networks for LVCSR | http://arxiv.org/pdf/1509.08967v2.pdf | author:Tom Sercu, Christian Puhrsch, Brian Kingsbury, Yann LeCun category:cs.CL cs.NE published:2015-09-29 summary:Convolutional neural networks (CNNs) are a standard component of many currentstate-of-the-art Large Vocabulary Continuous Speech Recognition (LVCSR)systems. However, CNNs in LVCSR have not kept pace with recent advances inother domains where deeper neural networks provide superior performance. Inthis paper we propose a number of architectural advances in CNNs for LVCSR.First, we introduce a very deep convolutional network architecture with up to14 weight layers. There are multiple convolutional layers before each poolinglayer, with small 3x3 kernels, inspired by the VGG Imagenet 2014 architecture.Then, we introduce multilingual CNNs with multiple untied layers. Finally, weintroduce multi-scale input features aimed at exploiting more context atnegligible computational cost. We evaluate the improvements first on a Babeltask for low resource speech recognition, obtaining an absolute 5.77% WERimprovement over the baseline PLP DNN by training our CNN on the combined dataof six different languages. We then evaluate the very deep CNNs on the Hub5'00benchmark (using the 262 hours of SWB-1 training data) achieving a word errorrate of 11.8% after cross-entropy training, a 1.4% WER improvement (10.6%relative) over the best published CNN result so far.
arxiv-13800-283 | Energy-Efficient Object Detection using Semantic Decomposition | http://arxiv.org/pdf/1509.08970v2.pdf | author:Priyadarshini Panda, Swagath Venkataramani, Abhronil Sengupta, Anand Raghunathan, Kaushik Roy category:cs.CV published:2015-09-29 summary:Machine-learning algorithms offer immense possibilities in the development ofseveral cognitive applications. In fact, large scale machine-learningclassifiers now represent the state-of-the-art in a wide range of objectdetection/classification problems. However, the network complexities oflarge-scale classifiers present them as one of the most challenging and energyintensive workloads across the computing spectrum. In this paper, we present anew approach to optimize energy efficiency of object detection tasks usingsemantic decomposition to build a hierarchical classification framework. Weobserve that certain semantic information like color/texture are common acrossvarious images in real-world datasets for object detection applications. Weexploit these common semantic features to distinguish the objects of interestfrom the remaining inputs (non-objects of interest) in a dataset at a lowercomputational effort. We propose a 2-stage hierarchical classificationframework, with increasing levels of complexity, wherein the first stage istrained to recognize the broad representative semantic features relevant to theobject of interest. The first stage rejects the input instances that do nothave the representative features and passes only the relevant instances to thesecond stage. Our methodology thus allows us to reject certain information atlower complexity and utilize the full computational effort of a network only ona smaller fraction of inputs to perform detection. We use color and texture asdistinctive traits to carry out several experiments for object detection. Ourexperiments on the Caltech101/CIFAR10 dataset show that the proposed methodyields 1.93x/1.46x improvement in average energy, respectively, over thetraditional single classifier model.
arxiv-13800-284 | Automatically Segmenting Oral History Transcripts | http://arxiv.org/pdf/1509.08842v1.pdf | author:Ryan Shaw category:cs.CL published:2015-09-29 summary:Dividing oral histories into topically coherent segments can make them moreaccessible online. People regularly make judgments about where coherentsegments can be extracted from oral histories. But making these judgments canbe taxing, so automated assistance is potentially attractive to speed the taskof extracting segments from open-ended interviews. When different people areasked to extract coherent segments from the same oral histories, they often donot agree about precisely where such segments begin and end. This low agreementmakes the evaluation of algorithmic segmenters challenging, but there is reasonto believe that for segmenting oral history transcripts, some approaches aremore promising than others. The BayesSeg algorithm performs slightly betterthan TextTiling, while TextTiling does not perform significantly better than auniform segmentation. BayesSeg might be used to suggest boundaries to someonesegmenting oral histories, but this segmentation task needs to be betterdefined.
arxiv-13800-285 | Conditional Deep Learning for Energy-Efficient and Enhanced Pattern Recognition | http://arxiv.org/pdf/1509.08971v6.pdf | author:Priyadarshini Panda, Abhronil Sengupta, Kaushik Roy category:cs.CV published:2015-09-29 summary:Deep learning neural networks have emerged as one of the most powerfulclassification tools for vision related applications. However, thecomputational and energy requirements associated with such deep nets can bequite high, and hence their energy-efficient implementation is of greatinterest. Although traditionally the entire network is utilized for therecognition of all inputs, we observe that the classification difficulty varieswidely across inputs in real-world datasets; only a small fraction of inputsrequire the full computational effort of a network, while a large majority canbe classified correctly with very low effort. In this paper, we proposeConditional Deep Learning (CDL) where the convolutional layer features are usedto identify the variability in the difficulty of input instances andconditionally activate the deeper layers of the network. We achieve this bycascading a linear network of output neurons for each convolutional layer andmonitoring the output of the linear network to decide whether classificationcan be terminated at the current stage or not. The proposed methodology thusenables the network to dynamically adjust the computational effort dependingupon the difficulty of the input data while maintaining competitiveclassification accuracy. We evaluate our approach on the MNIST dataset. Ourexperiments demonstrate that our proposed CDL yields 1.91x reduction in averagenumber of operations per input, which translates to 1.84x improvement inenergy. In addition, our results show an improvement in classification accuracyfrom 97.5% to 98.9% as compared to the original network.
arxiv-13800-286 | Compression of Deep Neural Networks on the Fly | http://arxiv.org/pdf/1509.08745v5.pdf | author:Guillaume Soulié, Vincent Gripon, Maëlys Robert category:cs.LG cs.CV cs.NE published:2015-09-29 summary:Thanks to their state-of-the-art performance, deep neural networks areincreasingly used for object recognition. To achieve these results, they usemillions of parameters to be trained. However, when targeting embeddedapplications the size of these models becomes problematic. As a consequence,their usage on smartphones or other resource limited devices is prohibited. Inthis paper we introduce a novel compression method for deep neural networksthat is performed during the learning phase. It consists in adding an extraregularization term to the cost function of fully-connected layers. We combinethis method with Product Quantization (PQ) of the trained weights for highersavings in storage consumption. We evaluate our method on two data sets (MNISTand CIFAR10), on which we achieve significantly larger compression rates thanstate-of-the-art methods.
arxiv-13800-287 | Estimating network edge probabilities by neighborhood smoothing | http://arxiv.org/pdf/1509.08588v2.pdf | author:Yuan Zhang, Elizaveta Levina, Ji Zhu category:stat.ML published:2015-09-29 summary:The problem of estimating probabilities of network edges from the observedadjacency matrix has important applications to predicting missing links andnetwork denoising. It has usually been addressed by estimating the graphon, afunction that determines the matrix of edge probabilities, but is ill-definedwithout strong assumptions on the network structure. Here we propose a novelcomputationally efficient method based on neighborhood smoothing to estimatethe expectation of the adjacency matrix directly, without making the strongstructural assumptions graphon estimation requires. The neighborhood smoothingmethod requires little tuning, has a competitive mean-squared error rate, andoutperforms many benchmark methods on the task of link prediction in bothsimulated and real networks.
arxiv-13800-288 | How to Formulate and Solve Statistical Recognition and Learning Problems | http://arxiv.org/pdf/1509.08830v1.pdf | author:Michail Schlesinger, Evgeniy Vodolazskiy category:cs.LG published:2015-09-29 summary:We formulate problems of statistical recognition and learning in a commonframework of complex hypothesis testing. Based on arguments from multi-criteriaoptimization, we identify strategies that are improper for solving theseproblems and derive a common form of the remaining strategies. We show thatsome widely used approaches to recognition and learning are improper in thissense. We then propose a generalized formulation of the recognition andlearning problem which embraces the whole range of sizes of the learningsample, including the zero size. Learning becomes a special case of recognitionwithout learning. We define the concept of closest to optimal strategy, being asolution to the formulated problem, and describe a technique for finding such astrategy. On several illustrative cases, the strategy is shown to be superiorto the widely used learning methods based on maximal likelihood estimation.
arxiv-13800-289 | Semantics, Representations and Grammars for Deep Learning | http://arxiv.org/pdf/1509.08627v1.pdf | author:David Balduzzi category:cs.LG cs.NE stat.ML published:2015-09-29 summary:Deep learning is currently the subject of intensive study. However,fundamental concepts such as representations are not formally defined --researchers "know them when they see them" -- and there is no common languagefor describing and analyzing algorithms. This essay proposes an abstractframework that identifies the essential features of current practice and mayprovide a foundation for future developments. The backbone of almost all deep learning algorithms is backpropagation, whichis simply a gradient computation distributed over a neural network. The mainingredients of the framework are thus, unsurprisingly: (i) game theory, toformalize distributed optimization; and (ii) communication protocols, to trackthe flow of zeroth and first-order information. The framework allows naturaldefinitions of semantics (as the meaning encoded in functions), representations(as functions whose semantics is chosen to optimized a criterion) and grammars(as communication protocols equipped with first-order convergence guarantees). Much of the essay is spent discussing examples taken from the literature. Theultimate aim is to develop a graphical language for describing the structure ofdeep learning algorithms that backgrounds the details of the optimizationprocedure and foregrounds how the components interact. Inspiration is takenfrom probabilistic graphical models and factor graphs, which capture theessential structural features of multivariate distributions.
arxiv-13800-290 | Learning dynamic Boltzmann machines with spike-timing dependent plasticity | http://arxiv.org/pdf/1509.08634v1.pdf | author:Takayuki Osogami, Makoto Otsuka category:cs.NE cs.AI cs.LG stat.ML published:2015-09-29 summary:We propose a particularly structured Boltzmann machine, which we refer to asa dynamic Boltzmann machine (DyBM), as a stochastic model of amulti-dimensional time-series. The DyBM can have infinitely many layers ofunits but allows exact and efficient inference and learning when its parametershave a proposed structure. This proposed structure is motivated by postulatesand observations, from biological neural networks, that the synaptic weight isstrengthened or weakened, depending on the timing of spikes (i.e., spike-timingdependent plasticity or STDP). We show that the learning rule of updating theparameters of the DyBM in the direction of maximizing the likelihood of giventime-series can be interpreted as STDP with long term potentiation and longterm depression. The learning rule has a guarantee of convergence and can beperformed in a distributed matter (i.e., local in space) with limited memory(i.e., local in time).
arxiv-13800-291 | Censoring Diffusion for Harvesting WSNs | http://arxiv.org/pdf/1509.08660v1.pdf | author:Jesus Fernandez-Bes, Rocío Arroyo-Valles, Jerónimo Arenas-García, Jesús Cid-Sueiro category:cs.SY cs.MA math.OC stat.ML published:2015-09-29 summary:In this paper, we analyze energy-harvesting adaptive diffusion networks for adistributed estimation problem. In order to wisely manage the available energyresources, we propose a scheme where a censoring algorithm is jointly appliedover the diffusion strategy. An energy-aware variation of a diffusion algorithmis used, and a new way of measuring the relevance of the estimates in diffusionnetworks is proposed in order to apply a subsequent censoring mechanism.Simulation results show the potential benefit of integrating censoring schemesin energy-constrained diffusion networks.
arxiv-13800-292 | Tractable Fully Bayesian Inference via Convex Optimization and Optimal Transport Theory | http://arxiv.org/pdf/1509.08582v1.pdf | author:Sanggyun Kim, Diego Mesa, Rui Ma, Todd P. Coleman category:stat.ML published:2015-09-29 summary:We consider the problem of transforming samples from one continuous sourcedistribution into samples from another target distribution. We demonstrate withoptimal transport theory that when the source distribution can be easilysampled from and the target distribution is log-concave, this can be tractablysolved with convex optimization. We show that a special case of this, when thesource is the prior and the target is the posterior, is Bayesian inference.Here, we can tractably calculate the normalization constant and draw posteriori.i.d. samples. Remarkably, our Bayesian tractability criterion is simply logconcavity of the prior and likelihood: the same criterion for tractablecalculation of the maximum a posteriori point estimate. With simulated data, wedemonstrate how we can attain the Bayes risk in simulations. With physiologicdata, we demonstrate improvements over point estimation in intensive care unitoutcome prediction and electroencephalography-based sleep staging.
arxiv-13800-293 | Retinex filtering of foggy images: generation of a bulk set with selection and ranking | http://arxiv.org/pdf/1509.08715v1.pdf | author:Roberto Marazzato, Amelia Carolina Sparavigna category:cs.CV published:2015-09-29 summary:In this paper we are proposing the use of GIMP Retinex, a filter of the GNUImage Manipulation Program, for enhancing foggy images. This filter involvesadjusting four different parameters to find the output image which has to bepreferred according to some specific purposes. Aiming to obtain a processing,which is able of choosing automatically the best image from a given set, we areproposing a method for the generation a bulk set of GIMP Retinex filteredimages and a preliminary approach for selecting and ranking them.
arxiv-13800-294 | Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning | http://arxiv.org/pdf/1509.08731v1.pdf | author:Shakir Mohamed, Danilo Jimenez Rezende category:stat.ML cs.AI cs.LG published:2015-09-29 summary:The mutual information is a core statistical quantity that has applicationsin all areas of machine learning, whether this is in training of density modelsover multiple data modalities, in maximising the efficiency of noisytransmission channels, or when learning behaviour policies for exploration byartificial agents. Most learning algorithms that involve optimisation of themutual information rely on the Blahut-Arimoto algorithm --- an enumerativealgorithm with exponential complexity that is not suitable for modern machinelearning applications. This paper provides a new approach for scalableoptimisation of the mutual information by merging techniques from variationalinference and deep learning. We develop our approach by focusing on the problemof intrinsically-motivated learning, where the mutual information forms thedefinition of a well-known internal drive known as empowerment. Using avariational lower bound on the mutual information, combined with convolutionalnetworks for handling visual input streams, we develop a stochasticoptimisation algorithm that allows for scalable information maximisation andempowerment-based reasoning directly from pixels to actions.
arxiv-13800-295 | Long-Range Trajectories from Global and Local Motion Representations | http://arxiv.org/pdf/1509.08647v1.pdf | author:Eduardo M. Pereira, Jaime S. Cardoso, Ricardo Morla category:cs.CV published:2015-09-29 summary:Motion is a fundamental cue for scene analysis and human activity understan-ding in videos. It can be encoded in trajectories for tracking objects and foraction recognition, or in form of flow to address behaviour analysis in crowdedscenes. Each approach can only be applied on limited scenarios. We propose amotion-based system that represents the spatial and temporal features of theflow in terms of long-range trajectories. The novelty resides on the systemformulation, its generic approach to handle scene variability and motionvariations, motion integration from local and global representations, and theresulting long-range trajectories that overcome trajectory-based approachproblems. We report the results and conclusions that state its pertinence ondifferent scenarios, comparing and correlating the extracted trajectories ofindividual pedestrians, manually annotated. We also propose an evaluationframework and stress the diverse system characteristics that can be used forhuman activity tasks, namely on motion segmentation.
arxiv-13800-296 | Tuned and GPU-accelerated parallel data mining from comparable corpora | http://arxiv.org/pdf/1509.08639v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL cs.AI cs.DS published:2015-09-29 summary:The multilingual nature of the world makes translation a crucial requirementtoday. Parallel dictionaries constructed by humans are a widely-availableresource, but they are limited and do not provide enough coverage for goodquality translation purposes, due to out-of-vocabulary words and neologisms.This motivates the use of statistical translation systems, which areunfortunately dependent on the quantity and quality of training data. Such hasa very limited availability especially for some languages and very narrow textdomains. Is this research we present our improvements to Yalign miningmethodology by reimplementing the comparison algorithm, introducing a tuningscripts and by improving performance using GPU computing acceleration. Theexperiments are conducted on various text domains and bi-data is extracted fromthe Wikipedia dumps.
arxiv-13800-297 | Neural-based machine translation for medical text domain. Based on European Medicines Agency leaflet texts | http://arxiv.org/pdf/1509.08644v1.pdf | author:Krzysztof Wołk, Krzysztof Marasek category:cs.CL cs.CY cs.NE stat.ML published:2015-09-29 summary:The quality of machine translation is rapidly evolving. Today one can findseveral machine translation systems on the web that provide reasonabletranslations, although the systems are not perfect. In some specific domains,the quality may decrease. A recently proposed approach to this domain is neuralmachine translation. It aims at building a jointly-tuned single neural networkthat maximizes translation performance, a very different approach fromtraditional statistical machine translation. Recently proposed neural machinetranslation models often belong to the encoder-decoder family in which a sourcesentence is encoded into a fixed length vector that is, in turn, decoded togenerate a translation. The present research examines the effects of differenttraining methods on a Polish-English Machine Translation system used formedical data. The European Medicines Agency parallel text corpus was used asthe basis for training of neural and statistical network-based translationsystems. The main machine translation evaluation metrics have also been used inanalysis of the systems. A comparison and implementation of a real-time medicaltranslator is the main focus of our experiments.
arxiv-13800-298 | Optimization over Sparse Symmetric Sets via a Nonmonotone Projected Gradient Method | http://arxiv.org/pdf/1509.08581v3.pdf | author:Zhaosong Lu category:math.OC cs.LG cs.NA stat.CO stat.ML published:2015-09-29 summary:We consider the problem of minimizing a Lipschitz differentiable functionover a class of sparse symmetric sets that has wide applications in engineeringand science. For this problem, it is known that any accumulation point of theclassical projected gradient (PG) method with a constant stepsize $1/L$satisfies the $L$-stationarity optimality condition that was introduced in [3].In this paper we introduce a new optimality condition that is stronger than the$L$-stationarity optimality condition. We also propose a nonmonotone projectedgradient (NPG) method for this problem by incorporating some support-changingand coordintate-swapping strategies into a projected gradient method withvariable stepsizes. It is shown that any accumulation point of NPG satisfiesthe new optimality condition and moreover it is a coordinatewise stationarypoint. Under some suitable assumptions, we further show that it is a global ora local minimizer of the problem. Numerical experiments are conducted tocompare the performance of PG and NPG. The computational results demonstratethat NPG has substantially better solution quality than PG, and moreover, it isat least comparable to, but sometimes can be much faster than PG in terms ofspeed.
arxiv-13800-299 | Boolean Matrix Factorization and Noisy Completion via Message Passing | http://arxiv.org/pdf/1509.08535v3.pdf | author:Siamak Ravanbakhsh, Barnabas Poczos, Russell Greiner category:math.ST cs.AI cs.DM stat.ML stat.TH published:2015-09-28 summary:Boolean matrix factorization and Boolean matrix completion from noisyobservations are desirable unsupervised data-analysis methods due to theirinterpretability, but hard to perform due to their NP-hardness. We treat theseproblems as maximum a posteriori inference problems in a graphical model andpresent a message passing approach that scales linearly with the number ofobservations and factors. Our empirical study demonstrates that message passingis able to recover low-rank Boolean matrices, in the boundaries oftheoretically possible recovery and compares favorably with state-of-the-art inreal-world applications, such collaborative filtering with large-scale Booleandata.
arxiv-13800-300 | Unbiased Bayesian Inference for Population Markov Jump Processes via Random Truncations | http://arxiv.org/pdf/1509.08327v2.pdf | author:Anastasis Georgoulas, Jane Hillston, Guido Sanguinetti category:stat.ML published:2015-09-28 summary:We consider continuous time Markovian processes where populations ofindividual agents interact stochastically according to kinetic rules. Despitethe increasing prominence of such models in fields ranging from biology tosmart cities, Bayesian inference for such systems remains challenging, as theseare continuous time, discrete state systems with potentially infinitestate-space. Here we propose a novel efficient algorithm for joint state /parameter posterior sampling in population Markov Jump processes. We introducea class of pseudo-marginal sampling algorithms based on a random truncationmethod which enables a principled treatment of infinite state spaces. Extensiveevaluation on a number of benchmark models shows that this approach achievesconsiderable savings compared to state of the art methods, retaining accuracyand fast convergence. We also present results on a synthetic biology data setshowing the potential for practical usefulness of our work.
