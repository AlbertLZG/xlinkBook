arxiv-13800-1 | Confusing Deep Convolution Networks by Relabelling | http://arxiv.org/pdf/1510.06925v2.pdf | author:Leigh Robinson, Benjamin Graham category:cs.CV cs.NE published:2015-10-23 summary:Deep convolutional neural networks have become the gold standard for imagerecognition tasks, demonstrating many current state-of-the-art results and evenachieving near-human level performance on some tasks. Despite this fact it hasbeen shown that their strong generalisation qualities can be fooled tomisclassify previously correctly classified natural images and give erroneoushigh confidence classifications to nonsense synthetic images. In this paper weextend that work, by presenting a straightforward way to perturb an image insuch a way as to cause it to acquire any other label from within the datasetwhile leaving this perturbed image visually indistinguishable from theoriginal.
arxiv-13800-2 | The Human Kernel | http://arxiv.org/pdf/1510.07389v3.pdf | author:Andrew Gordon Wilson, Christoph Dann, Christopher G. Lucas, Eric P. Xing category:cs.LG cs.AI stat.ML published:2015-10-26 summary:Bayesian nonparametric models, such as Gaussian processes, provide acompelling framework for automatic statistical modelling: these models have ahigh degree of flexibility, and automatically calibrated complexity. However,automating human expertise remains elusive; for example, Gaussian processeswith standard kernels struggle on function extrapolation problems that aretrivial for human learners. In this paper, we create function extrapolationproblems and acquire human responses, and then design a kernel learningframework to reverse engineer the inductive biases of human learners across aset of behavioral experiments. We use the learned kernels to gain psychologicalinsights and to extrapolate in human-like ways that go beyond traditionalstationary and polynomial kernels. Finally, we investigate Occam's razor inhuman and Gaussian process based function learning.
arxiv-13800-3 | Building Memory with Concept Learning Capabilities from Large-scale Knowledge Base | http://arxiv.org/pdf/1512.01173v1.pdf | author:Jiaxin Shi, Jun Zhu category:cs.CL cs.AI cs.LG published:2015-12-03 summary:We present a new perspective on neural knowledge base (KB) embeddings, fromwhich we build a framework that can model symbolic knowledge in the KB togetherwith its learning process. We show that this framework well regularizesprevious neural KB embedding model for superior performance in reasoning tasks,while having the capabilities of dealing with unseen entities, that is, tolearn their embeddings from natural language descriptions, which is very likehuman's behavior of learning semantic concepts.
arxiv-13800-4 | Towards Principled Unsupervised Learning | http://arxiv.org/pdf/1511.06440v2.pdf | author:Ilya Sutskever, Rafal Jozefowicz, Karol Gregor, Danilo Rezende, Tim Lillicrap, Oriol Vinyals category:cs.LG published:2015-11-19 summary:General unsupervised learning is a long-standing conceptual problem inmachine learning. Supervised learning is successful because it can be solved bythe minimization of the training error cost function. Unsupervised learning isnot as successful, because the unsupervised objective may be unrelated to thesupervised task of interest. For an example, density modelling andreconstruction have often been used for unsupervised learning, but they did notproduced the sought-after performance gains, because they have no knowledge ofthe supervised tasks. In this paper, we present an unsupervised cost function which we name theOutput Distribution Matching (ODM) cost, which measures a divergence betweenthe distribution of predictions and distributions of labels. The ODM cost isappealing because it is consistent with the supervised cost in the followingsense: a perfect supervised classifier is also perfect according to the ODMcost. Therefore, by aggressively optimizing the ODM cost, we are almostguaranteed to improve our supervised performance whenever the space of possiblepredictions is exponentially large. We demonstrate that the ODM cost works well on number of small andsemi-artificial datasets using no (or almost no) labelled training cases.Finally, we show that the ODM cost can be used for one-shot domain adaptation,which allows the model to classify inputs that differ from the inputdistribution in significant ways without the need for prior exposure to the newdomain.
arxiv-13800-5 | A Generative Model of Words and Relationships from Multiple Sources | http://arxiv.org/pdf/1510.00259v2.pdf | author:Stephanie L. Hyland, Theofanis Karaletsos, Gunnar RÃ¤tsch category:cs.CL cs.LG stat.ML published:2015-10-01 summary:Neural language models are a powerful tool to embed words into semanticvector spaces. However, learning such models generally relies on theavailability of abundant and diverse training examples. In highly specialiseddomains this requirement may not be met due to difficulties in obtaining alarge corpus, or the limited range of expression in average use. Such domainsmay encode prior knowledge about entities in a knowledge base or ontology. Wepropose a generative model which integrates evidence from diverse data sources,enabling the sharing of semantic information. We achieve this by generalisingthe concept of co-occurrence from distributional semantics to include otherrelationships between entities or words, which we model as affinetransformations on the embedding space. We demonstrate the effectiveness ofthis approach by outperforming recent models on a link prediction task anddemonstrating its ability to profit from partially or fully unobserved datatraining labels. We further demonstrate the usefulness of learning fromdifferent data sources with overlapping vocabularies.
arxiv-13800-6 | Kalman-based Stochastic Gradient Method with Stop Condition and Insensitivity to Conditioning | http://arxiv.org/pdf/1512.01139v1.pdf | author:Vivak Patel category:math.OC stat.CO stat.ML published:2015-12-03 summary:Proximal and stochastic gradient descent (SGD) methods are believed toefficiently minimize large composite objective functions, but such methods havetwo algorithmic challenges: (1) a lack of fast or justified stoppingconditions, and (2) sensitivity to the problem's conditioning. Second order SGDmethods show promise in solving these problems, but they are (3) marred by thecomplexity of their analysis. In this work, we address these three issues onthe limited, but important, linear regression problem by introducing andanalyzing a second order proximal/SGD method based on Kalman Filtering (kSGD).Through our analysis, we develop a fast algorithm with a justified stoppingcondition, prove that kSGD is insensitive to the problem's conditioning, anddevelop a unique approach for analyzing the complex second order dynamics. Ourtheoretical results are supported by numerical experiments on a large publicuse data set from the Center for Medicare and Medicaid. Byproducts of ouranalysis include, primarily, a foundation for extending kSGD to other problemtypes, parallel implementations with convergence guarantees and low memoryapplications, and, secondarily, extensions to Kalman Filtering theory.
arxiv-13800-7 | Target-Dependent Sentiment Classification with Long Short Term Memory | http://arxiv.org/pdf/1512.01100v1.pdf | author:Duyu Tang, Bing Qin, Xiaocheng Feng, Ting Liu category:cs.CL published:2015-12-03 summary:Target-dependent sentiment classification remains a challenge: modeling thesemantic relatedness of a target with its context words in a sentence.Different context words have different influences on determining the sentimentpolarity of a sentence towards the target. Therefore, it is desirable tointegrate the connections between target word and context words when building alearning system. In this paper, we develop two target dependent long short-termmemory (LSTM) models, where target information is automatically taken intoaccount. We evaluate our methods on a benchmark dataset from Twitter. Empiricalresults show that modeling sentence representation with standard LSTM does notperform well. Incorporating target information into LSTM can significantlyboost the classification accuracy. The target-dependent LSTM models achievestate-of-the-art performances without using syntactic parser or externalsentiment lexicons.
arxiv-13800-8 | Occlusion-Aware Human Pose Estimation with Mixtures of Sub-Trees | http://arxiv.org/pdf/1512.01055v1.pdf | author:Ibrahim Radwan, Abhinav Dhall, Roland Goecke category:cs.CV published:2015-12-03 summary:In this paper, we study the problem of learning a model for human poseestimation as mixtures of compositional sub-trees in two layers of prediction.This involves estimating the pose of a sub-tree followed by identifying therelationships between sub-trees that are used to handle occlusions betweendifferent parts. The mixtures of the sub-trees are learnt utilising bothgeometric and appearance distances. The Chow-Liu (CL) algorithm is recursivelyapplied to determine the inter-relations between the nodes and to build thestructure of the sub-trees. These structures are used to learn the latentparameters of the sub-trees and the inference is done using a standard beliefpropagation technique. The proposed method handles occlusions during theinference process by identifying overlapping regions between differentsub-trees and introducing a penalty term for overlapping parts. Experiments areperformed on three different datasets: the Leeds Sports, Image Parse and UIUCPeople datasets. The results show the robustness of the proposed method toocclusions over the state-of-the-art approaches.
arxiv-13800-9 | Approaches for Sentiment Analysis on Twitter: A State-of-Art study | http://arxiv.org/pdf/1512.01043v1.pdf | author:Harsh Thakkar, Dhiren Patel category:cs.SI cs.CL cs.IR published:2015-12-03 summary:Microbloging is an extremely prevalent broadcast medium amidst the Internetfraternity these days. People share their opinions and sentiments about varietyof subjects like products, news, institutions, etc., every day on microblogingwebsites. Sentiment analysis plays a key role in prediction systems, opinionmining systems, etc. Twitter, one of the microbloging platforms allows a limitof 140 characters to its users. This restriction stimulates users to be veryconcise about their opinion and twitter an ocean of sentiments to analyze.Twitter also provides developer friendly streaming API for data retrievalpurpose allowing the analyst to search real time tweets from various users. Inthis paper, we discuss the state-of-art of the works which are focused onTwitter, the online social network platform, for sentiment analysis. We surveyvarious lexical, machine learning and hybrid approaches for sentiment analysison Twitter.
arxiv-13800-10 | Simulations for Validation of Vision Systems | http://arxiv.org/pdf/1512.01030v1.pdf | author:V S R Veeravasarapu, Rudra Narayan Hota, Constantin Rothkopf, Ramesh Visvanathan category:cs.CV published:2015-12-03 summary:As the computer vision matures into a systems science and engineeringdiscipline, there is a trend in leveraging latest advances in computer graphicssimulations for performance evaluation, learning, and inference. However, thereis an open question on the utility of graphics simulations for vision withapparently contradicting views in the literature. In this paper, we place theresults from the recent literature in the context of performancecharacterization methodology outlined in the 90's and note that insightsderived from simulations can be qualitative or quantitative depending on thedegree of fidelity of models used in simulation and the nature of the questionposed by the experimenter. We describe a simulation platform that incorporateslatest graphics advances and use it for systematic performance characterizationand trade-off analysis for vision system design. We verify the utility of theplatform in a case study of validating a generative model inspired visionhypothesis, Rank-Order consistency model, in the contexts of global and localillumination changes, and bad weather, and high-frequency noise. Our approachestablishes the link between alternative viewpoints, involving models withphysics based semantics and signal and perturbation semantics and confirmsinsights in literature on robust change detection.
arxiv-13800-11 | Good parts first - a new algorithm for approximate search in lexica and string databases | http://arxiv.org/pdf/1301.0722v2.pdf | author:Stefan Gerdjikov, Stoyan Mihov, Petar Mitankin, Klaus U. Schulz category:cs.CL cs.DS published:2013-01-04 summary:We present a new efficient method for approximate search in electroniclexica. Given an input string (the pattern) and a similarity threshold, thealgorithm retrieves all entries of the lexicon that are sufficiently similar tothe pattern. Search is organized in subsearches that always start with an exactpartial match where a substring of the input pattern is aligned with asubstring of a lexicon word. Afterwards this partial match is extended stepwiseto larger substrings. For aligning further parts of the pattern withcorresponding parts of lexicon entries, more errors are tolerated at eachsubsequent step. For supporting this alignment order, which may start at anypart of the pattern, the lexicon is represented as a structure that enablesimmediate access to any substring of a lexicon word and permits the extensionof such substrings in both directions. Experimental evaluations of theapproximate search procedure are given that show significant efficiencyimprovements compared to existing techniques. Since the technique can be usedfor large error bounds it offers interesting possibilities for approximatesearch in special collections of "long" strings, such as phrases, sentences, orbook ti
arxiv-13800-12 | Principled Parallel Mean-Field Inference for Discrete Random Fields | http://arxiv.org/pdf/1511.06103v2.pdf | author:Pierre BaquÃ©, Timur Bagautdinov, FranÃ§ois Fleuret, Pascal Fua category:cs.CV cs.LG published:2015-11-19 summary:Mean-field variational inference is one of the most popular approaches toinference in discrete random fields. Standard mean-field optimization is basedon coordinate descent and in many situations can be impractical. Thus, inpractice, various parallel techniques are used, which either rely on ad-hocsmoothing with heuristically set parameters, or put strong constraints on thetype of models. In this paper, we propose a novel proximal gradient-basedapproach to optimizing the variational objective. It is naturallyparallelizable and easy to implement. We prove its convergence, and thendemonstrate that, in practice, it yields faster convergence and often findsbetter optima than more traditional mean-field optimization techniques.Moreover, our method is less sensitive to the choice of parameters.
arxiv-13800-13 | The quasispecies regime for the simple genetic algorithm with roulette-wheel selection | http://arxiv.org/pdf/1506.09081v2.pdf | author:RaphaÃ«l Cerf category:cs.NE math.PR published:2015-06-30 summary:We introduce a new parameter to discuss the behavior of a genetic algorithm.This parameter is the mean number of exact copies of the best fit chromosomesfrom one generation to the next. We argue that the genetic algorithm shouldoperate efficiently when this parameter is slightly larger than $1$. Weconsider the case of the simple genetic algorithm with the roulette--wheelselection mechanism. We denote by $\ell$ the length of the chromosomes, by $m$the population size, by $p_C$ the crossover probability and by $p_M$ themutation probability. We start the genetic algorithm with an initial populationwhose maximal fitness is equal to $f_0^*$ and whose mean fitness is equal to${\overline{f_0}}$. We show that, in the limit of large populations, thedynamics of the genetic algorithm depends in a critical way on the parameter$\pi \,=\,\big({f_0^*}/{\overline{f_0}}\big) (1-p_C)(1-p_M)^\ell\,.$ Ourresults suggest that the mutation and crossover probabilities should be tunedso that, at each generation, $\text{maximal fitness} \times (1-p_C)(1-p_M)^\ell > \text{mean fitness}$.
arxiv-13800-14 | Learning to Generate Chairs, Tables and Cars with Convolutional Networks | http://arxiv.org/pdf/1411.5928v3.pdf | author:Alexey Dosovitskiy, Jost Tobias Springenberg, Maxim Tatarchenko, Thomas Brox category:cs.CV cs.LG cs.NE published:2014-11-21 summary:We train generative 'up-convolutional' neural networks which are able togenerate images of objects given object style, viewpoint, and color. We trainthe networks on rendered 3D models of chairs, tables, and cars. Our experimentsshow that the networks do not merely learn all images by heart, but rather finda meaningful representation of 3D models allowing them to assess the similarityof different models, interpolate between given views to generate the missingones, extrapolate views, and invent new objects not present in the training setby recombining training instances, or even two different object classes.Moreover, we show that such generative networks can be used to findcorrespondences between different objects from the dataset, outperformingexisting approaches on this task.
arxiv-13800-15 | Weighted Schatten $p$-Norm Minimization for Image Denoising with Local and Nonlocal Regularization | http://arxiv.org/pdf/1501.01372v4.pdf | author:Yuan Xie category:cs.CV published:2015-01-07 summary:This paper presents a patch-wise low-rank based image denoising method withconstrained variational model involving local and nonlocal regularization. Onone hand, recent patch-wise methods can be represented as a low-rank matrixapproximation problem whose convex relaxation usually depends on nuclear normminimization (NNM). Here, we extend the NNM to the nonconvex schatten p-normminimization with additional weights assigned to different singular values,which is referred to as the Weighted Schatten p-Norm Minimization (WSNM). Anefficient algorithm is also proposed to solve the WSNM problem. The proposedWSNM not only gives better approximation to the original low-rank assumption,but also considers physical meanings of different data components. On the otherhand, due to the naive aggregation schema which integrates all the denoisedpatches into a whole image, current patch-wise denoising methods always producevarious degree of artifacts in denoised results. Therefore, to further reduceartifacts, a data-driven regularizer called Steering Total Variation (STV)combined with nonlocal TV is derived for a variational model, which imposeslocal and nonlocal consistency constraints on the patch-wise denoised image. Ahighly simple but efficient algorithm is proposed to solve this variationalmodel with convergence guarantee. Both WSNM and local \& nonlocal consistentregularization are integrated into an iterative restoration framework toproduce final results. Extensive experimental testing shows, both qualitativelyand quantitatively, that the proposed method can effectively remove noise, aswell as reduce artifacts compared with state-of-the-art methods.
arxiv-13800-16 | Weighted Schatten $p$-Norm Minimization for Image Denoising and Background Subtraction | http://arxiv.org/pdf/1512.01003v1.pdf | author:Yuan Xie, Shuhang Gu, Yan Liu, Wangmeng Zuo, Wensheng Zhang, Lei Zhang category:cs.CV published:2015-12-03 summary:Low rank matrix approximation (LRMA), which aims to recover the underlyinglow rank matrix from its degraded observation, has a wide range of applicationsin computer vision. The latest LRMA methods resort to using the nuclear normminimization (NNM) as a convex relaxation of the nonconvex rank minimization.However, NNM tends to over-shrink the rank components and treats the differentrank components equally, limiting its flexibility in practical applications. Wepropose a more flexible model, namely the Weighted Schatten $p$-NormMinimization (WSNM), to generalize the NNM to the Schatten $p$-normminimization with weights assigned to different singular values. The proposedWSNM not only gives better approximation to the original low-rank assumption,but also considers the importance of different rank components. We analyze thesolution of WSNM and prove that, under certain weights permutation, WSNM can beequivalently transformed into independent non-convex $l_p$-norm subproblems,whose global optimum can be efficiently solved by generalized iteratedshrinkage algorithm. We apply WSNM to typical low-level vision problems, e.g.,image denoising and background subtraction. Extensive experimental resultsshow, both qualitatively and quantitatively, that the proposed WSNM can moreeffectively remove noise, and model complex and dynamic scenes compared withstate-of-the-art methods.
arxiv-13800-17 | Bag Reference Vector for Multi-instance Learning | http://arxiv.org/pdf/1512.00994v1.pdf | author:Hanqiang Song, Zhuotun Zhu, Xinggang Wang category:stat.ML cs.LG published:2015-12-03 summary:Multi-instance learning (MIL) has a wide range of applications due to itsdistinctive characteristics. Although many state-of-the-art algorithms haveachieved decent performances, a plurality of existing methods solve the problemonly in instance level rather than excavating relations among bags. In thispaper, we propose an efficient algorithm to describe each bag by acorresponding feature vector via comparing it with other bags. In other words,the crucial information of a bag is extracted from the similarity between thatbag and other reference bags. In addition, we apply extensions of Hausdorffdistance to representing the similarity, to a certain extent, overcoming thekey challenge of MIL problem, the ambiguity of instances' labels in positivebags. Experimental results on benchmarks and text categorization tasks showthat the proposed method outperforms the previous state-of-the-art by a largemargin.
arxiv-13800-18 | Fast Low-Rank Matrix Learning with Nonconvex Regularization | http://arxiv.org/pdf/1512.00984v1.pdf | author:Quanming Yao, James T. Kwok, Wenliang Zhong category:cs.NA cs.LG stat.ML published:2015-12-03 summary:Low-rank modeling has a lot of important applications in machine learning,computer vision and social network analysis. While the matrix rank is oftenapproximated by the convex nuclear norm, the use of nonconvex low-rankregularizers has demonstrated better recovery performance. However, theresultant optimization problem is much more challenging. A very recentstate-of-the-art is based on the proximal gradient algorithm. However, itrequires an expensive full SVD in each proximal step. In this paper, we showthat for many commonly-used nonconvex low-rank regularizers, a cutoff can bederived to automatically threshold the singular values obtained from theproximal operator. This allows the use of power method to approximate the SVDefficiently. Besides, the proximal operator can be reduced to that of a muchsmaller matrix projected onto this leading subspace. Convergence, with a rateof O(1/T) where T is the number of iterations, can be guaranteed. Extensiveexperiments are performed on matrix completion and robust principal componentanalysis. The proposed method achieves significant speedup over thestate-of-the-art. Moreover, the matrix solution obtained is more accurate andhas a lower rank than that of the traditional nuclear norm regularizer.
arxiv-13800-19 | A New Statistical Framework for Genetic Pleiotropic Analysis of High Dimensional Phenotype Data | http://arxiv.org/pdf/1512.00947v1.pdf | author:Panpan Wang, Mohammad Rahman, Li Jin, Momiao Xiong category:stat.ML q-bio.GN stat.ME published:2015-12-03 summary:The widely used genetic pleiotropic analysis of multiple phenotypes are oftendesigned for examining the relationship between common variants and a fewphenotypes. They are not suited for both high dimensional phenotypes and highdimensional genotype (next-generation sequencing) data. To overcome theselimitations, we develop sparse structural equation models (SEMs) as a generalframework for a new paradigm of genetic analysis of multiple phenotypes. Toincorporate both common and rare variants into the analysis, we extend thetraditional multivariate SEMs to sparse functional SEMs. To deal with highdimensional phenotype and genotype data, we employ functional data analysis andthe alternative direction methods of multiplier (ADMM) techniques to reducedata dimension and improve computational efficiency. Using large scalesimulations we showed that the proposed methods have higher power to detecttrue causal genetic pleiotropic structure than other existing methods.Simulations also demonstrate that the gene-based pleiotropic analysis hashigher power than the single variant-based pleiotropic analysis. The proposedmethod is applied to exome sequence data from the NHLBI Exome SequencingProject (ESP) with 11 phenotypes, which identifies a network with 137 genesconnected to 11 phenotypes and 341 edges. Among them, 114 genes showedpleiotropic genetic effects and 45 genes were reported to be associated withphenotypes in the analysis or other cardiovascular disease (CVD) relatedphenotypes in the literature.
arxiv-13800-20 | A Literature Survey of various Fingerprint De-noising Techniques to justify the need of a new De-noising model based upon Pixel Component Analysis | http://arxiv.org/pdf/1512.00939v1.pdf | author:Siddharth Choubey, Deepika Banchhor category:cs.CV published:2015-12-03 summary:Image Preprocessing is a vital step in the field of image processing forbiometric pattern recognition. This paper studies and reviews various classicaland modern fingerprint image de-noising models. The various model used forde-noising ranges widely from transform matrix using frequency, histogram modelde-noising, de-noising by introducing Gabor filter and its types to enhancefingerprint images. The output efficiency of various de-noising model proposed earlier iscalculated on the basis of SNR (signal to noise ratio) and MSE (mean squareerror rate). Our simulated experimental results indicates that incorporatingthe de-noising model based on Gabor filter inside domain of wavelet ranges withcomposite method only betters MSE (Mean Square Error). Improved MSE withoutsignificant improvement in SNR improves the fingerprint images only by a littlemargin which is non-optimal in nature. Thus the objective of this researchpaper is to build an optimal de-noising model for fingerprint images so thatits usage in biometric authentication can be more robust in nature.
arxiv-13800-21 | The Indian Spontaneous Expression Database for Emotion Recognition | http://arxiv.org/pdf/1512.00932v1.pdf | author:S L Happy, Priyadarshi Patnaik, Aurobinda Routray, Rajlakshmi Guha category:cs.CV published:2015-12-03 summary:Automatic recognition of spontaneous facial expressions is a major challengein the field of affective computing. Head rotation, face pose, illuminationvariation, occlusion etc. are the attributes that increase the complexity ofrecognition of spontaneous expressions in practical applications. Effectiverecognition of expressions depends significantly on the quality of the databaseused. Most well-known facial expression databases consist of posed expressions.However, currently there is a huge demand for spontaneous expression databasesfor the pragmatic implementation of the facial expression recognitionalgorithms. In this paper, we propose and establish a new facial expressiondatabase containing spontaneous expressions of both male and femaleparticipants of Indian origin. The database consists of 428 segmented videoclips of the spontaneous facial expressions of 50 participants. In ourexperiment, emotions were induced among the participants by using emotionalvideos and simultaneously their self-ratings were collected for eachexperienced emotion. Facial expression clips were annotated carefully by fourtrained decoders, which were further validated by the nature of stimuli usedand self-report of emotions. An extensive analysis was carried out on thedatabase using several machine learning algorithms and the results are providedfor future reference. Such a spontaneous database will help in the developmentand validation of algorithms for recognition of spontaneous expressions.
arxiv-13800-22 | Bayesian inference via rejection filtering | http://arxiv.org/pdf/1511.06458v2.pdf | author:Nathan Wiebe, Christopher Granade, Ashish Kapoor, Krysta M Svore category:cs.LG quant-ph stat.ML published:2015-11-20 summary:We provide a method for approximating Bayesian inference using rejectionsampling. We not only make the process efficient, but also dramatically reducethe memory required relative to conventional methods by combining rejectionsampling with particle filtering. We also provide an approximate form ofrejection sampling that makes rejection filtering tractable in cases whereexact rejection sampling is not efficient. Finally, we present severalnumerical examples of rejection filtering that show its ability to track timedependent parameters in online settings and also benchmark its performance onMNIST classification problems.
arxiv-13800-23 | Innovation Pursuit: A New Approach to Subspace Clustering | http://arxiv.org/pdf/1512.00907v1.pdf | author:Mostafa Rahmani, George Atia category:cs.CV cs.IR cs.IT cs.LG math.IT stat.ML published:2015-12-02 summary:In subspace clustering, a group of data points belonging to a union ofsubspaces are assigned membership to their respective subspaces. This paperpresents a new approach dubbed Innovation Pursuit (iPursuit) to the problem ofsubspace clustering using a new geometrical idea whereby each subspace isidentified based on its novelty with respect to the other subspaces. Theproposed approach finds the subspaces consecutively by solving a series ofsimple linear optimization problems, each searching for some direction in thespan of the data that is potentially orthogonal to all subspaces except for theone to be identified in one step of the algorithm. A detailed mathematicalanalysis is provided establishing sufficient conditions for the proposedapproach to correctly cluster the data points. Remarkably, the proposedapproach can provably yield exact clustering even when the subspaces havesignificant intersections under mild conditions on the distribution of the datapoints in the subspaces. Moreover, It is shown that the complexity of iPursuitis almost independent of the dimension of the data. The numerical simulationsdemonstrate that iPursuit can often outperform the state-of-the-art subspaceclustering algorithms, more so for subspaces with significant intersections.
arxiv-13800-24 | Compressive hyperspectral imaging via adaptive sampling and dictionary learning | http://arxiv.org/pdf/1512.00901v1.pdf | author:Mingrui Yang, Frank de Hoog, Yuqi Fan, Wen Hu category:cs.CV published:2015-12-02 summary:In this paper, we propose a new sampling strategy for hyperspectral signalsthat is based on dictionary learning and singular value decomposition (SVD).Specifically, we first learn a sparsifying dictionary from training spectraldata using dictionary learning. We then perform an SVD on the dictionary anduse the first few left singular vectors as the rows of the measurement matrixto obtain the compressive measurements for reconstruction. The proposed methodprovides significant improvement over the conventional compressive sensingapproaches. The reconstruction performance is further improved byreconditioning the sensing matrix using matrix balancing. We also demonstratethat the combination of dictionary learning and SVD is robust by applying themto different datasets.
arxiv-13800-25 | Cleaning Schedule Optimization of Heat Exchanger Networks Using Particle Swarm Optimization | http://arxiv.org/pdf/1512.00883v1.pdf | author:Totok R. Biyanto, Sumitra Wira Suganda, Matraji, Yerry Susatio, Heri Justiono, Sarwono category:cs.NE published:2015-12-02 summary:Oil refinery is one of industries that require huge energy consumption. Thetoday technology advance requires energy saving. Heat integration is a methodused to minimize the energy comsumption though the implementation of HeatExchanger Network (HEN). CPT is one of types of Heat Exchanger Network (HEN)that functions to recover the heat in the flow of product or waste. HENcomprises a number of heat exchangers (HEs) that are serially connected.However, the presence of fouling in the heat exchanger has caused the declineof the performance of both heat exchangers and all heat exchanger networks.Fouling can not be avoided. However, it can be mitigated. In industry, periodicheat exchanger cleaning is the most effective and widely used mitigationtechnique. On the other side, a very frequent cleaning of heat exchanger can bemuch costly in maintenance and lost of production. In this way, an accurateoptimization technique of cleaning schedule interval of heat exchanger is veryessential. Commonly, this technique involves three elements: model to simulatethe heat exchanger network, representative fouling model to describe thefouling behavior and suitable optimization algorithm to solve the problem ofclening schedule interval for heat exchanger network. This paper describe theoptimization of interval cleaning schedule of HEN within the 44-month periodusing PSO (particle swarm optimization). The number of iteration used toachieve the convergent is 100 iterations and the fitness value in PSOcorrelated with the amount of heat recovery, cleaning cost, and additionalpumping cost. The saving after the optimization of cleaning schedule of HEN inthis research achieved at $ 1.236 millions or 23% of maximum potential savings.
arxiv-13800-26 | Optimization Monte Carlo: Efficient and Embarrassingly Parallel Likelihood-Free Inference | http://arxiv.org/pdf/1506.03693v2.pdf | author:Edward Meeds, Max Welling category:cs.LG stat.ML published:2015-06-11 summary:We describe an embarrassingly parallel, anytime Monte Carlo method forlikelihood-free models. The algorithm starts with the view that thestochasticity of the pseudo-samples generated by the simulator can becontrolled externally by a vector of random numbers u, in such a way that theoutcome, knowing u, is deterministic. For each instantiation of u we run anoptimization procedure to minimize the distance between summary statistics ofthe simulator and the data. After reweighing these samples using the prior andthe Jacobian (accounting for the change of volume in transforming from thespace of summary statistics to the space of parameters) we show that thisweighted ensemble represents a Monte Carlo estimate of the posteriordistribution. The procedure can be run embarrassingly parallel (each nodehandling one sample) and anytime (by allocating resources to the worstperforming sample). The procedure is validated on six experiments.
arxiv-13800-27 | Optimal whitening and decorrelation | http://arxiv.org/pdf/1512.00809v1.pdf | author:Agnan Kessy, Alex Lewin, Korbinian Strimmer category:stat.ME stat.ML published:2015-12-02 summary:Whitening, or sphering, is a common preprocessing step in statisticalanalysis to transform random variables to orthogonality. However, due torotational freedom there are infinitely many possible whitening procedures.Consequently, there is a diverse range of sphering methods in use, for examplebased on principal component analysis, Cholesky matrix decomposition andMahalanobis transformation, among others. Here we provide an overview of the underlying theory and discuss five naturalwhitening procedures. Subsequently, we demonstrate that investigating thecross-covariance and the cross-correlation matrix between sphered and originalvariables allows to break the rotational invariance of whitening and toidentify optimal transformations. As a result we recommended two particularwhitening approaches: CAT-CAR whitening to produce sphered variables that aremaximally similar to the original variables, and PCA-whitening based on thecorrelation matrix to obtain maximally compressed whitened variables.
arxiv-13800-28 | Actions ~ Transformations | http://arxiv.org/pdf/1512.00795v1.pdf | author:Xiaolong Wang, Ali Farhadi, Abhinav Gupta category:cs.CV published:2015-12-02 summary:What defines an action like "kicking ball"? We argue that the true meaning ofan action lies in the change or transformation an action brings to theenvironment. In this paper, we propose a novel representation for actions bymodeling action as a transformation which changes the state of the environmentbefore the action happens (precondition) to the state after the action(effect). Motivated by the recent advancement of video representation usingdeep learning, we design a Siamese network which models the action as thetransformation on a high-level feature space. We show that our model givesimprovements on standard action recognition datasets including UCF101 andHMDB51. More importantly, our approach is able to generalize beyond learnedaction categories and shows significant performance improvement oncross-category generalization on our new ACT dataset.
arxiv-13800-29 | Microclustering: When the Cluster Sizes Grow Sublinearly with the Size of the Data Set | http://arxiv.org/pdf/1512.00792v1.pdf | author:Jeffrey Miller, Brenda Betancourt, Abbas Zaidi, Hanna Wallach, Rebecca C. Steorts category:stat.ME stat.AP stat.CO stat.ML published:2015-12-02 summary:Most generative models for clustering implicitly assume that the number ofdata points in each cluster grows linearly with the total number of datapoints. Finite mixture models, Dirichlet process mixture models, andPitman--Yor process mixture models make this assumption, as do all otherinfinitely exchangeable clustering models. However, for some tasks, thisassumption is undesirable. For example, when performing entity resolution, thesize of each cluster is often unrelated to the size of the data set.Consequently, each cluster contains a negligible fraction of the total numberof data points. Such tasks therefore require models that yield clusters whosesizes grow sublinearly with the size of the data set. We address thisrequirement by defining the \emph{microclustering property} and introducing anew model that exhibits this property. We compare this model to severalcommonly used clustering models by checking model fit using real and simulateddata sets.
arxiv-13800-30 | An Introduction to Convolutional Neural Networks | http://arxiv.org/pdf/1511.08458v2.pdf | author:Keiron O'Shea, Ryan Nash category:cs.NE cs.CV cs.LG published:2015-11-26 summary:The field of machine learning has taken a dramatic twist in recent times,with the rise of the Artificial Neural Network (ANN). These biologicallyinspired computational models are able to far exceed the performance ofprevious forms of artificial intelligence in common machine learning tasks. Oneof the most impressive forms of ANN architecture is that of the ConvolutionalNeural Network (CNN). CNNs are primarily used to solve difficult image-drivenpattern recognition tasks and with their precise yet simple architecture,offers a simplified method of getting started with ANNs. This document provides a brief introduction to CNNs, discussing recentlypublished papers and newly formed techniques in developing these brilliantlyfantastic image recognition models. This introduction assumes you are familiarwith the fundamentals of ANNs and machine learning.
arxiv-13800-31 | Multi-Image Matching via Fast Alternating Minimization | http://arxiv.org/pdf/1505.04845v2.pdf | author:Xiaowei Zhou, Menglong Zhu, Kostas Daniilidis category:cs.CV published:2015-05-19 summary:In this paper we propose a global optimization-based approach to jointlymatching a set of images. The estimated correspondences simultaneously maximizepairwise feature affinities and cycle consistency across multiple images.Unlike previous convex methods relying on semidefinite programming, weformulate the problem as a low-rank matrix recovery problem and show that thedesired semidefiniteness of a solution can be spontaneously fulfilled. Thelow-rank formulation enables us to derive a fast alternating minimizationalgorithm in order to handle practical problems with thousands of features.Both simulation and real experiments demonstrate that the proposed algorithmcan achieve a competitive performance with an order of magnitude speedupcompared to the state-of-the-art algorithm. In the end, we demonstrate theapplicability of the proposed method to match the images of different objectinstances and as a result the potential to reconstruct category-specific objectmodels from those images.
arxiv-13800-32 | Learning Semantic Similarity for Very Short Texts | http://arxiv.org/pdf/1512.00765v1.pdf | author:Cedric De Boom, Steven Van Canneyt, Steven Bohez, Thomas Demeester, Bart Dhoedt category:cs.IR cs.CL published:2015-12-02 summary:Levering data on social media, such as Twitter and Facebook, requiresinformation retrieval algorithms to become able to relate very short textfragments to each other. Traditional text similarity methods such as tf-idfcosine-similarity, based on word overlap, mostly fail to produce good resultsin this case, since word overlap is little or non-existent. Recently,distributed word representations, or word embeddings, have been shown tosuccessfully allow words to match on the semantic level. In order to pair shorttext fragments - as a concatenation of separate words - an adequate distributedsentence representation is needed, in existing literature often obtained bynaively combining the individual word representations. We thereforeinvestigated several text representations as a combination of word embeddingsin the context of semantic pair matching. This paper investigates theeffectiveness of several such naive techniques, as well as traditional tf-idfsimilarity, for fragments of different lengths. Our main contribution is afirst step towards a hybrid method that combines the strength of densedistributed representations - as opposed to sparse term matching - with thestrength of tf-idf based methods to automatically reduce the impact of lessinformative terms. Our new approach outperforms the existing techniques in atoy experimental set-up, leading to the conclusion that the combination of wordembeddings and tf-idf information might lead to a better model for semanticcontent within very short text fragments.
arxiv-13800-33 | Active Learning for Delineation of Curvilinear Structures | http://arxiv.org/pdf/1512.00747v1.pdf | author:Agata Mosinska, Raphael Sznitman, PrzemysÅaw GÅowacki, Pascal Fua category:cs.CV published:2015-12-02 summary:Many recent delineation techniques owe much of their increased effectivenessto path classification algorithms that make it possible to distinguishpromising paths from others. The downside of this development is that theyrequire annotated training data, which is tedious to produce. In this paper, we propose an Active Learning approach that considerablyspeeds up the annotation process. Unlike standard ones, it takes advantage ofthe specificities of the delineation problem. It operates on a graph and canreduce the training set size by up to 80% without compromising thereconstruction quality. We will show that our approach outperforms conventional ones on variousbiomedical and natural image datasets, thus showing that it is broadlyapplicable.
arxiv-13800-34 | Recognizing Semantic Features in Faces using Deep Learning | http://arxiv.org/pdf/1512.00743v1.pdf | author:Amogh Gudi category:cs.LG cs.CV stat.ML published:2015-12-02 summary:The human face constantly conveys information, both consciously andsubconsciously. However, as basic as it is for humans to visually interpretthis information, it is quite a big challenge for machines. Conventionalsemantic facial feature recognition and analysis techniques are already in useand are based on physiological heuristics, but they suffer from lack ofrobustness and high computation time. This thesis aims to explore ways formachines to learn to interpret semantic information available in faces in anautomated manner without requiring manual design of feature detectors, usingthe approach of Deep Learning. This thesis provides a study of the effects ofvarious factors and hyper-parameters of deep neural networks in the process ofdetermining an optimal network configuration for the task of semantic facialfeature recognition. This thesis explores the effectiveness of the system torecognize the various semantic features (like emotions, age, gender, ethnicityetc.) present in faces. Furthermore, the relation between the effect ofhigh-level concepts on low level features is explored through an analysis ofthe similarities in low-level descriptors of different semantic features. Thisthesis also demonstrates a novel idea of using a deep network to generate 3-DActive Appearance Models of faces from real-world 2-D images.
arxiv-13800-35 | Annotating Character Relationships in Literary Texts | http://arxiv.org/pdf/1512.00728v1.pdf | author:Philip Massey, Patrick Xia, David Bamman, Noah A. Smith category:cs.CL published:2015-12-02 summary:We present a dataset of manually annotated relationships between charactersin literary texts, in order to support the training and evaluation of automaticmethods for relation type prediction in this domain (Makazhanov et al., 2014;Kokkinakis, 2013) and the broader computational analysis of literary character(Elson et al., 2010; Bamman et al., 2014; Vala et al., 2015; Flekova andGurevych, 2015). In this work, we solicit annotations from workers on AmazonMechanical Turk for 109 texts ranging from Homer's _Iliad_ to Joyce's _Ulysses_on four dimensions of interest: for a given pair of characters, we collectjudgments as to the coarse-grained category (professional, social, familial),fine-grained category (friend, lover, parent, rival, employer), and affinity(positive, negative, neutral) that describes their primary relationship in atext. We do not assume that this relationship is static; we also collectjudgments as to whether it changes at any point in the course of the text.
arxiv-13800-36 | MMSE Estimation for Poisson Noise Removal in Images | http://arxiv.org/pdf/1512.00717v1.pdf | author:Stanislav Pyatykh, JÃ¼rgen Hesser category:cs.CV cs.DS published:2015-12-02 summary:Poisson noise suppression is an important preprocessing step in severalapplications, such as medical imaging, microscopy, and astronomical imaging. Inthis work, we propose a novel patch-wise Poisson noise removal strategy, inwhich the MMSE estimator is utilized in order to produce the denoising resultfor each image patch. Fast and accurate computation of the MMSE estimator iscarried out using k-d tree search followed by search in the K-nearest neighborgraph. Our experiments show that the proposed method is the preferable choicefor low signal-to-noise ratios.
arxiv-13800-37 | Duelist Algorithm: An Algorithm Inspired by How Duelist Improve Their Capabilities in a Duel | http://arxiv.org/pdf/1512.00708v1.pdf | author:Totok Ruki Biyanto, Henokh Yernias Fibrianto, Gunawan Nugroho, Erny Listijorini, Titik Budiati, Hairul Huda category:cs.NE published:2015-12-02 summary:This paper proposes an optimization algorithm based on how human fight andlearn from each duelist. Since this algorithm is based on population, theproposed algorithm starts with an initial set of duelists. The duel is todetermine the winner and loser. The loser learns from the winner, while thewinner try their new skill or technique that may improve their fightingcapabilities. A few duelists with highest fighting capabilities are called aschampion. The champion train a new duelists such as their capabilities. The newduelist will join the tournament as a representative of each champion. Allduelist are re-evaluated, and the duelists with worst fighting capabilities iseliminated to maintain the amount of duelists. Two optimization problem isapplied for the proposed algorithm, together with genetic algorithm, particleswarm optimization and imperialist competitive algorithm. The results show thatthe proposed algorithm is able to find the better global optimum and fasteriteration.
arxiv-13800-38 | Hybrid Approach for Inductive Semi Supervised Learning using Label Propagation and Support Vector Machine | http://arxiv.org/pdf/1512.01568v1.pdf | author:Aruna Govada, Pravin Joshi, Sahil Mittal, Sanjay K Sahay category:cs.LG cs.DC published:2015-12-02 summary:Semi supervised learning methods have gained importance in today's worldbecause of large expenses and time involved in labeling the unlabeled data byhuman experts. The proposed hybrid approach uses SVM and Label Propagation tolabel the unlabeled data. In the process, at each step SVM is trained tominimize the error and thus improve the prediction quality. Experiments areconducted by using SVM and logistic regression(Logreg). Results prove that SVMperforms tremendously better than Logreg. The approach is tested using 12datasets of different sizes ranging from the order of 1000s to the order of10000s. Results show that the proposed approach outperforms Label Propagationby a large margin with F-measure of almost twice on average. The parallelversion of the proposed approach is also designed and implemented, the analysisshows that the training time decreases significantly when parallel version isused.
arxiv-13800-39 | Centroid Based Binary Tree Structured SVM for Multi Classification | http://arxiv.org/pdf/1512.00659v1.pdf | author:Aruna Govada, Bhavul Gauri, S. K. Sahay category:cs.LG published:2015-12-02 summary:Support Vector Machines (SVMs) were primarily designed for 2-classclassification. But they have been extended for N-class classification alsobased on the requirement of multiclasses in the practical applications.Although N-class classification using SVM has considerable research attention,getting minimum number of classifiers at the time of training and testing isstill a continuing research. We propose a new algorithm CBTS-SVM (Centroidbased Binary Tree Structured SVM) which addresses this issue. In this we builda binary tree of SVM models based on the similarity of the class labels byfinding their distance from the corresponding centroids at the root level. Theexperimental results demonstrates the comparable accuracy for CBTS with OVOwith reasonable gamma and cost values. On the other hand when CBTS is comparedwith OVA, it gives the better accuracy with reduced training time and testingtime. Furthermore CBTS is also scalable as it is able to handle the large datasets.
arxiv-13800-40 | Multiple-Instance Learning: Radon-Nikodym Approach to Distribution Regression Problem | http://arxiv.org/pdf/1511.09058v2.pdf | author:Vladislav Gennadievich Malyshkin category:cs.LG published:2015-11-29 summary:For distribution regression problem, where a bag of $x$--observations ismapped to a single $y$ value, a one--step solution is proposed. The problem ofrandom distribution to random value is transformed to random vector to randomvalue by taking distribution moments of $x$ observations in a bag as randomvector. Then Radon--Nikodym or least squares theory can be applied, what give$y(x)$ estimator. The probability distribution of $y$ is also obtained, whatrequires solving generalized eigenvalues problem, matrix spectrum (notdepending on $x$) give possible $y$ outcomes and depending on $x$ probabilitiesof outcomes can be obtained by projecting the distribution with fixed $x$ value(delta--function) to corresponding eigenvector. A library providing numericallystable polynomial basis for these calculations is available, what make theproposed approach practical.
arxiv-13800-41 | Continuous and Simultaneous Gesture and Posture Recognition for Commanding a Robotic Wheelchair; Towards Spotting the Signal Patterns | http://arxiv.org/pdf/1512.00622v1.pdf | author:Ali Boyali, Naohisa Hashimoto, Manolya Kavakli category:cs.RO cs.CV published:2015-12-02 summary:Spotting signal patterns with varying lengths has been still an open problemin the literature. In this study, we describe a signal pattern recognitionapproach for continuous and simultaneous classification of a tracked hand'sposture and gestures and map them to steering commands for control of a roboticwheelchair. The developed methodology not only affords 100\% recognitionaccuracy on a streaming signal for continuous recognition, but also bringsabout a new perspective for building a training dictionary which eliminateshuman intervention to spot the gesture or postures on a training signal. In thetraining phase we employ a state of art subspace clustering method to find themost representative state samples. The recognition and training frameworkreveal boundaries of the patterns on the streaming signal with a successivedecision tree structure intrinsically. We make use of the Collaborative ansBlock Sparse Representation based classification methods for continuous gestureand posture recognition.
arxiv-13800-42 | Multi-user lax communications: a multi-armed bandit approach | http://arxiv.org/pdf/1504.08167v2.pdf | author:Orly Avner, Shie Mannor category:cs.LG cs.MA published:2015-04-30 summary:Inspired by cognitive radio networks, we consider a setting where multipleusers share several channels modeled as a multi-user multi-armed bandit (MAB)problem. The characteristics of each channel are unknown and are different foreach user. Each user can choose between the channels, but her success dependson the particular channel chosen as well as on the selections of other users:if two users select the same channel their messages collide and none of themmanages to send any data. Our setting is fully distributed, so there is nocentral control. As in many communication systems, the users cannot set up adirect communication protocol, so information exchange must be limited to aminimum. We develop an algorithm for learning a stable configuration for themulti-user MAB problem. We further offer both convergence guarantees andexperiments inspired by real communication networks, including comparison tostate-of-the-art algorithms.
arxiv-13800-43 | Double Sparse Multi-Frame Image Super Resolution | http://arxiv.org/pdf/1512.00607v1.pdf | author:Toshiyuki Kato, Hideitsu Hino, Noboru Murata category:cs.CV published:2015-12-02 summary:A large number of image super resolution algorithms based on the sparsecoding are proposed, and some algorithms realize the multi-frame superresolution. In multi-frame super resolution based on the sparse coding, bothaccurate image registration and sparse coding are required. Previous study onmulti-frame super resolution based on sparse coding firstly apply blockmatching for image registration, followed by sparse coding to enhance the imageresolution. In this paper, these two problems are solved by optimizing a singleobjective function. The results of numerical experiments support theeffectiveness of the proposed approch.
arxiv-13800-44 | The MegaFace Benchmark: 1 Million Faces for Recognition at Scale | http://arxiv.org/pdf/1512.00596v1.pdf | author:Ira Kemelmacher-Shlizerman, Steve Seitz, Daniel Miller, Evan Brossard category:cs.CV published:2015-12-02 summary:Recent face recognition experiments on a major benchmark LFW show stunningperformance--a number of algorithms achieve near to perfect score, surpassinghuman recognition rates. In this paper, we advocate evaluations at the millionscale (LFW includes only 13K photos of 5K people). To this end, we haveassembled the MegaFace dataset and created the first MegaFace challenge. Ourdataset includes One Million photos that capture more than 690K differentindividuals. The challenge evaluates performance of algorithms with increasingnumbers of distractors (going from 10 to 1M) in the gallery set. We presentboth identification and verification performance, evaluate performance withrespect to pose and a person's age, and compare as a function of training datasize (number of photos and people). We report results of state of the art andbaseline algorithms. Our key observations are that testing at the million scalereveals big performance differences (of algorithms that perform similarly wellon smaller scale) and that age invariant recognition as well as pose are stillchallenging for most. The MegaFace dataset, baseline code, and evaluationscripts, are all publicly released for further experimentations at:megaface.cs.washington.edu.
arxiv-13800-45 | Klasifikasi Komponen Argumen Secara Otomatis pada Dokumen Teks berbentuk Esai Argumentatif | http://arxiv.org/pdf/1512.00578v1.pdf | author:Derwin Suhartono category:cs.CL cs.IR published:2015-12-02 summary:By automatically recognize argument component, essay writers can do someinspections to texts that they have written. It will assist essay scoringprocess objectively and precisely because essay grader is able to see how wellthe argument components are constructed. Some reseachers have tried to doargument detection and classification along with its implementation in somedomains. The common approach is by doing feature extraction to the text.Generally, the features are structural, lexical, syntactic, indicator, andcontextual. In this research, we add new feature to the existing features. Itadopts keywords list by Knott and Dale (1993). The experiment result shows theargument classification achieves 72.45% accuracy. Moreover, we still get thesame accuracy without the keyword lists. This concludes that the keyword listsdo not affect significantly to the features. All features are still weak toclassify major claim and claim, so we need other features which are useful todifferentiate those two kind of argument components.
arxiv-13800-46 | Probabilistic Latent Semantic Analysis (PLSA) untuk Klasifikasi Dokumen Teks Berbahasa Indonesia | http://arxiv.org/pdf/1512.00576v1.pdf | author:Derwin Suhartono category:cs.CL cs.IR published:2015-12-02 summary:One task that is included in managing documents is how to find substantialinformation inside. Topic modeling is a technique that has been developed toproduce document representation in form of keywords. The keywords will be usedin the indexing process and document retrieval as needed by users. In thisresearch, we will discuss specifically about Probabilistic Latent SemanticAnalysis (PLSA). It will cover PLSA mechanism which involves ExpectationMaximization (EM) as the training algorithm, how to conduct testing, and obtainthe accuracy result.
arxiv-13800-47 | Object-based World Modeling in Semi-Static Environments with Dependent Dirichlet-Process Mixtures | http://arxiv.org/pdf/1512.00573v1.pdf | author:Lawson L. S. Wong, Thanard Kurutach, Leslie Pack Kaelbling, TomÃ¡s Lozano-PÃ©rez category:cs.AI cs.LG cs.RO published:2015-12-02 summary:To accomplish tasks in human-centric indoor environments, robots need torepresent and understand the world in terms of objects and their attributes. Werefer to this attribute-based representation as a world model, and consider howto acquire it via noisy perception and maintain it over time, as objects areadded, changed, and removed in the world. Previous work has framed this asmultiple-target tracking problem, where objects are potentially in motion atall times. Although this approach is general, it is computationally expensive.We argue that such generality is not needed in typical world modeling tasks,where objects only change state occasionally. More efficient approaches areenabled by restricting ourselves to such semi-static environments. We consider a previously-proposed clustering-based world modeling approachthat assumed static environments, and extend it to semi-static domains byapplying a dependent Dirichlet-process (DDP) mixture model. We derive a novelMAP inference algorithm under this model, subject to data associationconstraints. We demonstrate our approach improves computational performance insemi-static environments.
arxiv-13800-48 | Attribute2Image: Conditional Image Generation from Visual Attributes | http://arxiv.org/pdf/1512.00570v1.pdf | author:Xinchen Yan, Jimei Yang, Kihyuk Sohn, Honglak Lee category:cs.LG cs.AI cs.CV published:2015-12-02 summary:This paper investigates a problem of generating images from visualattributes. Given the prevalent research for image recognition, the conditionalimage generation problem is relatively under-explored due to the challenges oflearning a good generative model and handling rendering uncertainties inimages. To address this, we propose a variety of attribute-conditioned deepvariational auto-encoders that enjoy both effective representation learning andBayesian modeling, from which images can be generated from specified attributesand sampled latent factors. We experiment with natural face images anddemonstrate that the proposed models are capable of generating realistic faceswith diverse appearance. We further evaluate the proposed models by performingattribute-conditioned image progression, transfer and retrieval. In particular,our generation method achieves superior performance in the retrieval experimentagainst traditional nearest-neighbor-based methods both qualitatively andquantitatively.
arxiv-13800-49 | Convergence rates of sub-sampled Newton methods | http://arxiv.org/pdf/1508.02810v2.pdf | author:Murat A. Erdogdu, Andrea Montanari category:stat.ML published:2015-08-12 summary:We consider the problem of minimizing a sum of $n$ functions over a convexparameter set $\mathcal{C} \subset \mathbb{R}^p$ where $n\gg p\gg 1$. In thisregime, algorithms which utilize sub-sampling techniques are known to beeffective. In this paper, we use sub-sampling techniques together with low-rankapproximation to design a new randomized batch algorithm which possessescomparable convergence rate to Newton's method, yet has much smallerper-iteration cost. The proposed algorithm is robust in terms of starting pointand step size, and enjoys a composite convergence rate, namely, quadraticconvergence at start and linear convergence when the iterate is close to theminimizer. We develop its theoretical analysis which also allows us to selectnear-optimal algorithm parameters. Our theoretical results can be used toobtain convergence rates of previously proposed sub-sampling based algorithmsas well. We demonstrate how our results apply to well-known machine learningproblems. Lastly, we evaluate the performance of our algorithm on severaldatasets under various scenarios.
arxiv-13800-50 | Seeing the Unseen Network: Inferring Hidden Social Ties from Respondent-Driven Sampling | http://arxiv.org/pdf/1511.04137v2.pdf | author:Lin Chen, Forrest W. Crawford, Amin Karbasi category:cs.SI cs.AI cs.LG published:2015-11-13 summary:Learning about the social structure of hidden and hard-to-reach populations--- such as drug users and sex workers --- is a major goal of epidemiologicaland public health research on risk behaviors and disease prevention.Respondent-driven sampling (RDS) is a peer-referral process widely used by manyhealth organizations, where research subjects recruit other subjects from theirsocial network. In such surveys, researchers observe who recruited whom, alongwith the time of recruitment and the total number of acquaintances (networkdegree) of respondents. However, due to privacy concerns, the identities ofacquaintances are not disclosed. In this work, we show how to reconstruct theunderlying network structure through which the subjects are recruited. Weformulate the dynamics of RDS as a continuous-time diffusion process over theunderlying graph and derive the likelihood for the recruitment time seriesunder an arbitrary recruitment time distribution. We develop an efficientstochastic optimization algorithm called RENDER (REspoNdent-Driven nEtworkReconstruction) that finds the network that best explains the collected data.We support our analytical results through an exhaustive set of experiments onboth synthetic and real data.
arxiv-13800-51 | Benchmarking sentiment analysis methods for large-scale texts: A case for using continuum-scored words and word shift graphs | http://arxiv.org/pdf/1512.00531v1.pdf | author:Andrew Reagan, Brian Tivnan, Jake Ryland Williams, Christopher M. Danforth, Peter Sheridan Dodds category:cs.CL published:2015-12-02 summary:The emergence and global adoption of social media has rendered possible thereal-time estimation of population-scale sentiment, bearing profoundimplications for our understanding of human behavior. Given the growingassortment of sentiment measuring instruments, comparisons between them areevidently required. Here, we perform detailed tests of 6 dictionary-basedmethods applied to 4 different corpora, and briefly examine a further 8methods. We show that a dictionary-based method will only perform both reliablyand meaningfully if (1) the dictionary covers a sufficiently large enoughportion of a given text's lexicon when weighted by word usage frequency; and(2) words are scored on a continuous scale.
arxiv-13800-52 | Labeling the Features Not the Samples: Efficient Video Classification with Minimal Supervision | http://arxiv.org/pdf/1512.00517v1.pdf | author:Marius Leordeanu, Alexandra Radu, Shumeet Baluja, Rahul Sukthankar category:cs.CV published:2015-12-01 summary:Feature selection is essential for effective visual recognition. We proposean efficient joint classifier learning and feature selection method thatdiscovers sparse, compact representations of input features from a vast sea ofcandidates, with an almost unsupervised formulation. Our method requires onlythe following knowledge, which we call the \emph{feature sign}---whether or nota particular feature has on average stronger values over positive samples thanover negatives. We show how this can be estimated using as few as a singlelabeled training sample per class. Then, using these feature signs, we extendan initial supervised learning problem into an (almost) unsupervised clusteringformulation that can incorporate new data without requiring ground truthlabels. Our method works both as a feature selection mechanism and as a fullycompetitive classifier. It has important properties, low computational cost andexcellent accuracy, especially in difficult cases of very limited trainingdata. We experiment on large-scale recognition in video and show superior speedand performance to established feature selection approaches such as AdaBoost,Lasso, greedy forward-backward selection, and powerful classifiers such as SVM.
arxiv-13800-53 | Character-Aware Neural Language Models | http://arxiv.org/pdf/1508.06615v4.pdf | author:Yoon Kim, Yacine Jernite, David Sontag, Alexander M. Rush category:cs.CL cs.NE stat.ML published:2015-08-26 summary:We describe a simple neural language model that relies only oncharacter-level inputs. Predictions are still made at the word-level. Our modelemploys a convolutional neural network (CNN) and a highway network overcharacters, whose output is given to a long short-term memory (LSTM) recurrentneural network language model (RNN-LM). On the English Penn Treebank the modelis on par with the existing state-of-the-art despite having 60% fewerparameters. On languages with rich morphology (Arabic, Czech, French, German,Spanish, Russian), the model outperforms word-level/morpheme-level LSTMbaselines, again with fewer parameters. The results suggest that on manylanguages, character inputs are sufficient for language modeling. Analysis ofword representations obtained from the character composition part of the modelreveals that the model is able to encode, from characters only, both semanticand orthographic information.
arxiv-13800-54 | Adaptive Sampling of RF Fingerprints for Fine-grained Indoor Localization | http://arxiv.org/pdf/1508.02324v2.pdf | author:Xiao-Yang Liu, Shuchin Aeron, Vaneet Aggarwal, Xiaodong Wang, Min-You Wu category:cs.IT math.IT math.OC stat.ML published:2015-08-10 summary:Indoor localization is a supporting technology for a broadening range ofpervasive wireless applications. One promis- ing approach is to locate userswith radio frequency fingerprints. However, its wide adoption in real-worldsystems is challenged by the time- and manpower-consuming site survey process,which builds a fingerprint database a priori for localization. To address thisproblem, we visualize the 3-D RF fingerprint data as a function of locations(x-y) and indices of access points (fingerprint), as a tensor and use tensoralgebraic methods for an adaptive tubal-sampling of this fingerprint space. Inparticular using a recently proposed tensor algebraic framework in [1] wecapture the complexity of the fingerprint space as a low-dimensionaltensor-column space. In this formulation the proposed scheme exploitsadaptivity to identify reference points which are highly informative forlearning this low-dimensional space. Further, under certain incoherencyconditions we prove that the proposed scheme achieves bounded recovery errorand near-optimal sampling complexity. In contrast to several existing work thatrely on random sampling, this paper shows that adaptivity in sampling can leadto significant improvements in localization accuracy. The approach is validatedon both data generated by the ray-tracing indoor model which accounts for thefloor plan and the impact of walls and the real world data. Simulation resultsshow that, while maintaining the same localization accuracy of existingapproaches, the amount of samples can be cut down by 71% for the high SNR caseand 55% for the low SNR case.
arxiv-13800-55 | Efficient Edge Detection on Low-Cost FPGAs | http://arxiv.org/pdf/1512.00504v1.pdf | author:Jamie Schiel, Andrew Bainbridge-Smith category:cs.AR cs.CV published:2015-12-01 summary:Improving the efficiency of edge detection in embedded applications, such asUAV control, is critical for reducing system cost and power dissipation. Fieldprogrammable gate arrays (FPGA) are a good platform for making improvementsbecause of their specialised internal structure. However, current FPGA edgedetectors do not exploit this structure well. A new edge detection architectureis proposed that is better optimised for FPGAs. The basis of the architectureis the Sobel edge kernels that are shown to be the most suitable because oftheir separability and absence of multiplications. Edge intensities arecalculated with a new 4:2 compressor that consists of two custom-designed 3:2compressors. Addition speed is increased by breaking carry propagation chainswith look-ahead logic. Testing of the design showed it gives a 28% increase inspeed and 4.4% reduction in area over previous equivalent designs, whichdemonstrated that it will lower the cost of edge detection systems, dissipateless power and still maintain high-speed control.
arxiv-13800-56 | Sharp Finite-Time Iterated-Logarithm Martingale Concentration | http://arxiv.org/pdf/1405.2639v4.pdf | author:Akshay Balsubramani category:math.PR cs.LG stat.ML published:2014-05-12 summary:We give concentration bounds for martingales that are uniform over finitetimes and extend classical Hoeffding and Bernstein inequalities. We alsodemonstrate our concentration bounds to be optimal with a matchinganti-concentration inequality, proved using the same method. Together theseconstitute a finite-time version of the law of the iterated logarithm, and shedlight on the relationship between it and the central limit theorem.
arxiv-13800-57 | Fast k-Nearest Neighbour Search via Dynamic Continuous Indexing | http://arxiv.org/pdf/1512.00442v1.pdf | author:Ke Li, Jitendra Malik category:cs.DS cs.AI cs.IR cs.LG stat.ML published:2015-12-01 summary:Existing methods for retrieving k-nearest neighbours suffer from the curse ofdimensionality. We argue this is caused in part by inherent deficiencies ofspace partitioning, which is the underlying strategy used by almost allexisting methods. We devise a new strategy that avoids partitioning the vectorspace and present a novel randomized algorithm that runs in time linear indimensionality and sub-linear in the size of the dataset and takes spaceconstant in dimensionality and linear in the size of the dataset. The proposedalgorithm allows fine-grained control over accuracy and speed on a per-querybasis, automatically adapts to variations in dataset density, supports dynamicupdates to the dataset and is easy-to-implement. We show appealing theoreticalproperties and demonstrate empirically that the proposed algorithm outperformslocality-sensitivity hashing (LSH) in terms of approximation quality and speed.
arxiv-13800-58 | Taxonomy grounded aggregation of classifiers with different label sets | http://arxiv.org/pdf/1512.00355v1.pdf | author:Amrita Saha, Sathish Indurthi, Shantanu Godbole, Subendhu Rongali, Vikas C. Raykar category:cs.AI cs.LG published:2015-12-01 summary:We describe the problem of aggregating the label predictions of diverseclassifiers using a class taxonomy. Such a taxonomy may not have been availableor referenced when the individual classifiers were designed and trained, yetmapping the output labels into the taxonomy is desirable to integrate theeffort spent in training the constituent classifiers. A hierarchical taxonomyrepresenting some domain knowledge may be different from, but partiallymappable to, the label sets of the individual classifiers. We present aheuristic approach and a principled graphical model to aggregate the labelpredictions by grounding them into the available taxonomy. Our model aggregatesthe labels using the taxonomy structure as constraints to find the most likelyhierarchically consistent class. We experimentally validate our proposed methodon image and text classification tasks.
arxiv-13800-59 | Discriminative and Efficient Label Propagation on Complementary Graphs for Multi-Object Tracking | http://arxiv.org/pdf/1504.01124v3.pdf | author:Amit Kumar K. C., Laurent Jacques, Christophe De Vleeschouwer category:cs.CV published:2015-04-05 summary:Given a set of detections, detected at each time instant independently, weinvestigate how to associate them across time. This is done by propagatinglabels on a set of graphs, each graph capturing how either the spatio-temporalor the appearance cues promote the assignment of identical or distinct labelsto a pair of detections. The graph construction is motivated by a locallylinear embedding of the detection features. Interestingly, the neighborhood ofa node in appearance graph is defined to include all the nodes for which theappearance feature is available (even if they are temporally distant). Thisgives our framework the uncommon ability to exploit the appearance featuresthat are available only sporadically. Once the graphs have been defined,multi-object tracking is formulated as the problem of finding a labelassignment that is consistent with the constraints captured each graph, whichresults into a difference of convex (DC) program. We propose to decompose theglobal objective function into node-wise sub-problems. This not only allows acomputationally efficient solution, but also supports an incremental andscalable construction of the graph, thereby making the framework applicable tolarge graphs and practical tracking scenarios. Moreover, it opens thepossibility of parallel implementation.
arxiv-13800-60 | Highly Scalable Tensor Factorization for Prediction of Drug-Protein Interaction Type | http://arxiv.org/pdf/1512.00315v1.pdf | author:Adam Arany, Jaak Simm, Pooya Zakeri, Tom Haber, JÃ¶rg K. Wegner, Vladimir Chupakhin, Hugo Ceulemans, Yves Moreau category:stat.ML published:2015-12-01 summary:The understanding of the type of inhibitory interaction plays an importantrole in drug design. Therefore, researchers are interested to know whether adrug has competitive or non-competitive interaction to particular proteintargets. Method: to analyze the interaction types we propose factorization methodMacau which allows us to combine different measurement types into a singletensor together with proteins and compounds. The compounds are characterized byhigh dimensional 2D ECFP fingerprints. The novelty of the proposed method isthat using a specially designed noise injection MCMC sampler it can incorporatehigh dimensional side information, i.e., millions of unique 2D ECFP compoundfeatures, even for large scale datasets of millions of compounds. Without theside information, in this case, the tensor factorization would be practicallyfutile. Results: using public IC50 and Ki data from ChEMBL we trained a model fromwhere we can identify the latent subspace separating the two measurement types(IC50 and Ki). The results suggest the proposed method can detect thecompetitive inhibitory activity between compounds and proteins.
arxiv-13800-61 | On Optical Flow Models for Variational Motion Estimation | http://arxiv.org/pdf/1512.00298v1.pdf | author:Martin Burger, Hendrik Dirks, Lena Frerking category:math.NA cs.CV math.OC published:2015-12-01 summary:The aim of this paper is to discuss and evaluate total variation basedregularization methods for motion estimation, with particular focus on opticalflow models. In addition to standard $L^2$ and $L^1$ data fidelities we give anoverview of different variants of total variation regularization obtained fromcombination with higher order models and a unified computational optimizationapproach based on primal-dual methods. Moreover, we extend the models byBregman iterations and provide an inverse problems perspective to the analysisof variational optical flow models. A particular focus of the paper is thequantitative evaluation of motion estimation, which is a difficult and oftenunderestimated task. We discuss several approaches for quality measures ofmotion estimation and apply them to compare the previously discussedregularization approaches.
arxiv-13800-62 | Towards Dropout Training for Convolutional Neural Networks | http://arxiv.org/pdf/1512.00242v1.pdf | author:Haibing Wu, Xiaodong Gu category:cs.LG cs.CV cs.NE published:2015-12-01 summary:Recently, dropout has seen increasing use in deep learning. For deepconvolutional neural networks, dropout is known to work well in fully-connectedlayers. However, its effect in convolutional and pooling layers is still notclear. This paper demonstrates that max-pooling dropout is equivalent torandomly picking activation based on a multinomial distribution at trainingtime. In light of this insight, we advocate employing our proposedprobabilistic weighted pooling, instead of commonly used max-pooling, to act asmodel averaging at test time. Empirical evidence validates the superiority ofprobabilistic weighted pooling. We also empirically show that the effect ofconvolutional dropout is not trivial, despite the dramatically reducedpossibility of over-fitting due to the convolutional architecture. Elaboratelydesigning dropout training simultaneously in max-pooling and fully-connectedlayers, we achieve state-of-the-art performance on MNIST, and very competitiveresults on CIFAR-10 and CIFAR-100, relative to other approaches without dataaugmentation. Finally, we compare max-pooling dropout and stochastic pooling,both of which introduce stochasticity based on multinomial distributions atpooling stage.
arxiv-13800-63 | Fast and High Quality Highlight Removal from A Single Image | http://arxiv.org/pdf/1512.00237v1.pdf | author:Dongsheng An, Jinli Suo, Xiangyang Ji, Haoqian Wang, Qionghai Dai category:cs.CV published:2015-12-01 summary:Specular reflection exists widely in photography and causes the recordedcolor deviating from its true value, so fast and high quality highlight removalfrom a single nature image is of great importance. In spite of the progress inthe past decades in highlight removal, achieving wide applicability to thelarge diversity of nature scenes is quite challenging. To handle this problem,we propose an analytic solution to highlight removal based on an L2chromaticity definition and corresponding dichromatic model. Specifically, thispaper derives a normalized dichromatic model for the pixels with identicaldiffuse color: a unit circle equation of projection coefficients in twosubspaces that are orthogonal to and parallel with the illumination,respectively. In the former illumination orthogonal subspace, which isspecular-free, we can conduct robust clustering with an explicit criterion todetermine the cluster number adaptively. In the latter illumination parallelsubspace, a property called pure diffuse pixels distribution rule (PDDR) helpsmap each specular-influenced pixel to its diffuse component. In terms ofefficiency, the proposed approach involves few complex calculation, and thuscan remove highlight from high resolution images fast. Experiments show thatthis method is of superior performance in various challenging cases.
arxiv-13800-64 | Distributionally Robust Logistic Regression | http://arxiv.org/pdf/1509.09259v3.pdf | author:Soroosh Shafieezadeh-Abadeh, Peyman Mohajerin Esfahani, Daniel Kuhn category:math.OC stat.ML published:2015-09-30 summary:This paper proposes a distributionally robust approach to logisticregression. We use the Wasserstein distance to construct a ball in the space ofprobability distributions centered at the uniform distribution on the trainingsamples. If the radius of this ball is chosen judiciously, we can guaranteethat it contains the unknown data-generating distribution with high confidence.We then formulate a distributionally robust logistic regression model thatminimizes a worst-case expected logloss function, where the worst case is takenover all distributions in the Wasserstein ball. We prove that this optimizationproblem admits a tractable reformulation and encapsulates the classical as wellas the popular regularized logistic regression problems as special cases. Wefurther propose a distributionally robust approach based on Wasserstein ballsto compute upper and lower confidence bounds on the misclassificationprobability of the resulting classifier. These bounds are given by the optimalvalues of two highly tractable linear programs. We validate our theoreticalout-of-sample guarantees through simulated and empirical experiments.
arxiv-13800-65 | Bayesian Manifold Learning: The Locally Linear Latent Variable Model (LL-LVM) | http://arxiv.org/pdf/1410.6791v4.pdf | author:Mijung Park, Wittawat Jitkrittum, Ahmad Qamar, Zoltan Szabo, Lars Buesing, Maneesh Sahani category:stat.ML 62F15 G.3; I.2.6 published:2014-10-24 summary:We introduce the Locally Linear Latent Variable Model (LL-LVM), aprobabilistic model for non-linear manifold discovery that describes a jointdistribution over observations, their manifold coordinates and locally linearmaps conditioned on a set of neighbourhood relationships. The model allowsstraightforward variational optimisation of the posterior distribution oncoordinates and locally linear maps from the latent space to the observationspace given the data. Thus, the LL-LVM encapsulates the local-geometrypreserving intuitions that underlie non-probabilistic methods such as locallylinear embedding (LLE). Its probabilistic semantics make it easy to evaluatethe quality of hypothesised neighbourhood relationships, select the intrinsicdimensionality of the manifold, construct out-of-sample extensions and tocombine the manifold model with additional probabilistic models that capturethe structure of coordinates within the manifold.
arxiv-13800-66 | What Players do with the Ball: A Physically Constrained Interaction Modeling | http://arxiv.org/pdf/1511.06181v2.pdf | author:Andrii Maksai, Xinchao Wang, Pascal Fua category:cs.CV published:2015-11-19 summary:Tracking the ball is critical for video-based analysis of team sports.However, it is difficult, especially in low-resolution images, due to the smallsize of the ball, its speed that creates motion blur, and its often beingoccluded by players. In this paper, we propose a generic and principledapproach to modeling the interaction between the ball and the players whilealso imposing appropriate physical constraints on the ball's trajectory. Weshow that our approach, formulated in terms of a Mixed Integer Program, is morerobust and more accurate than several state-of-the-art approaches on real-lifevolleyball, basketball, and soccer sequences.
arxiv-13800-67 | Noisy Submodular Maximization via Adaptive Sampling with Applications to Crowdsourced Image Collection Summarization | http://arxiv.org/pdf/1511.07211v2.pdf | author:Adish Singla, Sebastian Tschiatschek, Andreas Krause category:cs.AI cs.LG stat.ML published:2015-11-23 summary:We address the problem of maximizing an unknown submodular function that canonly be accessed via noisy evaluations. Our work is motivated by the task ofsummarizing content, e.g., image collections, by leveraging users' feedback inform of clicks or ratings. For summarization tasks with the goal of maximizingcoverage and diversity, submodular set functions are a natural choice. When theunderlying submodular function is unknown, users' feedback can provide noisyevaluations of the function that we seek to maximize. We provide a genericalgorithm -- \submM{} -- for maximizing an unknown submodular function undercardinality constraints. This algorithm makes use of a novel exploration module-- \blbox{} -- that proposes good elements based on adaptively sampling noisyfunction evaluations. \blbox{} is able to accommodate different kinds ofobservation models such as value queries and pairwise comparisons. We providePAC-style guarantees on the quality and sampling cost of the solution obtainedby \submM{}. We demonstrate the effectiveness of our approach in aninteractive, crowdsourced image collection summarization application.
arxiv-13800-68 | Positive Neural Networks in Discrete Time Implement Monotone-Regular Behaviors | http://arxiv.org/pdf/1502.06094v2.pdf | author:Tom J. Ameloot, Jan Van den Bussche category:cs.NE published:2015-02-21 summary:We study the expressive power of positive neural networks. The model usespositive connection weights and multiple input neurons. Different behaviors canbe expressed by varying the connection weights. We show that in discrete time,and in absence of noise, the class of positive neural networks captures theso-called monotone-regular behaviors, that are based on regular languages. Afiner picture emerges if one takes into account the delay by which amonotone-regular behavior is implemented. Each monotone-regular behavior can beimplemented by a positive neural network with a delay of one time unit. Somemonotone-regular behaviors can be implemented with zero delay. And,interestingly, some simple monotone-regular behaviors can not be implementedwith zero delay.
arxiv-13800-69 | Analyzing Classifiers: Fisher Vectors and Deep Neural Networks | http://arxiv.org/pdf/1512.00172v1.pdf | author:Sebastian Bach, Alexander Binder, GrÃ©goire Montavon, Klaus-Robert MÃ¼ller, Wojciech Samek category:cs.CV published:2015-12-01 summary:Fisher Vector classifiers and Deep Neural Networks (DNNs) are popular andsuccessful algorithms for solving image classification problems. However, bothare generally considered `black box' predictors as the non-lineartransformations involved have so far prevented transparent and interpretablereasoning. Recently, a principled technique, Layer-wise Relevance Propagation(LRP), has been developed in order to better comprehend the inherent structuredreasoning of complex nonlinear classification models such as Bag of Featuremodels or DNNs. In this paper we (1) extend the LRP framework also for FisherVector classifiers and then use it as analysis tool to (2) quantify theimportance of context for classification, (3) qualitatively compare DNNsagainst FV classifiers in terms of important image regions and (4) detectpotential flaws and biases in data. All experiments are performed on the PASCALVOC 2007 data set.
arxiv-13800-70 | Augmenting Phrase Table by Employing Lexicons for Pivot-based SMT | http://arxiv.org/pdf/1512.00170v1.pdf | author:Yiming Cui, Conghui Zhu, Xiaoning Zhu, Tiejun Zhao category:cs.CL published:2015-12-01 summary:Pivot language is employed as a way to solve the data sparseness problem inmachine translation, especially when the data for a particular language pairdoes not exist. The combination of source-to-pivot and pivot-to-targettranslation models can induce a new translation model through the pivotlanguage. However, the errors in two models may compound as noise, and still,the combined model may suffer from a serious phrase sparsity problem. In thispaper, we directly employ the word lexical model in IBM models as an additionalresource to augment pivot phrase table. In addition, we also propose a phrasetable pruning method which takes into account both of the source and targetphrasal coverage. Experimental result shows that our pruning methodsignificantly outperforms the conventional one, which only considers sourceside phrasal coverage. Furthermore, by including the entries in the lexiconmodel, the phrase coverage increased, and we achieved improved results inChinese-to-Japanese translation using English as pivot language.
arxiv-13800-71 | Learning Using 1-Local Membership Queries | http://arxiv.org/pdf/1512.00165v1.pdf | author:Galit Bary category:cs.LG cs.AI published:2015-12-01 summary:Classic machine learning algorithms learn from labelled examples. Forexample, to design a machine translation system, a typical training set willconsist of English sentences and their translation. There is a stronger model,in which the algorithm can also query for labels of new examples it creates.E.g, in the translation task, the algorithm can create a new English sentence,and request its translation from the user during training. This combination ofexamples and queries has been widely studied. Yet, despite many theoreticalresults, query algorithms are almost never used. One of the main causes forthis is a report (Baum and Lang, 1992) on very disappointing empiricalperformance of a query algorithm. These poor results were mainly attributed tothe fact that the algorithm queried for labels of examples that are artificial,and impossible to interpret by humans. In this work we study a new model of local membership queries (Awasthi etal., 2012), which tries to resolve the problem of artificial queries. In thismodel, the algorithm is only allowed to query the labels of examples which areclose to examples from the training set. E.g., in translation, the algorithmcan change individual words in a sentence it has already seen, and then ask forthe translation. In this model, the examples queried by the algorithm will beclose to natural examples and hence, hopefully, will not appear as artificialor random. We focus on 1-local queries (i.e., queries of distance 1 from anexample in the training sample). We show that 1-local membership queries arealready stronger than the standard learning model. We also present anexperiment on a well known NLP task of sentiment analysis. In this experiment,the users were asked to provide more information than merely indicating thelabel. We present results that illustrate that this extra information isbeneficial in practice.
arxiv-13800-72 | Optimal Estimation and Completion of Matrices with Biclustering Structures | http://arxiv.org/pdf/1512.00150v1.pdf | author:Chao Gao, Yu Lu, Zongming Ma, Harrison H. Zhou category:math.ST stat.ML stat.TH published:2015-12-01 summary:Biclustering structures in data matrices were first formalized in a seminalpaper by John Hartigan (1972) where one seeks to cluster cases and variablessimultaneously. Such structures are also prevalent in block modeling ofnetworks. In this paper, we develop a unified theory for the estimation andcompletion of matrices with biclustering structures, where the data is apartially observed and noise contaminated data matrix with a certainbiclustering structure. In particular, we show that a constrained least squaresestimator achieves minimax rate-optimal performance in several of the mostimportant scenarios. To this end, we derive unified high probability upperbounds for all sub-Gaussian data and also provide matching minimax lower boundsin both Gaussian and binary cases. Due to the close connection of graphon tostochastic block models, an immediate consequence of our general results is aminimax rate-optimal estimator for sparse graphons.
arxiv-13800-73 | Implicit Sparse Code Hashing | http://arxiv.org/pdf/1512.00130v1.pdf | author:Tsung-Yu Lin, Tsung-Wei Ke, Tyng-Luh Liu category:cs.CV published:2015-12-01 summary:We address the problem of converting large-scale high-dimensional image datainto binary codes so that approximate nearest-neighbor search over them can beefficiently performed. Different from most of the existing unsupervisedapproaches for yielding binary codes, our method is based on adimensionality-reduction criterion that its resulting mapping is designed topreserve the image relationships entailed by the inner products of sparsecodes, rather than those implied by the Euclidean distances in the ambientspace. While the proposed formulation does not require computing any sparsecodes, the underlying computation model still inevitably involves solving anunmanageable eigenproblem when extremely high-dimensional descriptors are used.To overcome the difficulty, we consider the column-sampling technique andpresume a special form of rotation matrix to facilitate subproblemdecomposition. We test our method on several challenging image datasets anddemonstrate its effectiveness by comparing with state-of-the-art binary codingtechniques.
arxiv-13800-74 | A Bennett Inequality for the Missing Mass | http://arxiv.org/pdf/1503.06134v2.pdf | author:Bahman Yari Saeed Khanloo category:stat.ML published:2015-03-20 summary:Novel concentration inequalities are obtained for the missing mass, i.e. thetotal probability mass of the outcomes not observed in the sample. We derivedistribution-free deviation bounds with sublinear exponents in deviation sizefor missing mass and improve the results of Berend and Kontorovich (2013) andYari Saeed Khanloo and Haffari (2015) for small deviations which is the mostimportant case in learning theory.
arxiv-13800-75 | Inferring Interpersonal Relations in Narrative Summaries | http://arxiv.org/pdf/1512.00112v1.pdf | author:Shashank Srivastava, Snigdha Chaturvedi, Tom Mitchell category:cs.CL cs.AI cs.SI published:2015-12-01 summary:Characterizing relationships between people is fundamental for theunderstanding of narratives. In this work, we address the problem of inferringthe polarity of relationships between people in narrative summaries. Weformulate the problem as a joint structured prediction for each narrative, andpresent a model that combines evidence from linguistic and semantic features,as well as features based on the structure of the social community in the text.We also provide a clustering-based approach that can exploit regularities innarrative types. e.g., learn an affinity for love-triangles in romanticstories. On a dataset of movie summaries from Wikipedia, our structured modelsprovide more than a 30% error-reduction over a competitive baseline thatconsiders pairs of characters in isolation.
arxiv-13800-76 | Dynamic Parallel and Distributed Graph Cuts | http://arxiv.org/pdf/1512.00101v1.pdf | author:Miao Yu, Shuhan Shen, Zhanyi Hu category:cs.DS cs.CV published:2015-12-01 summary:Graph-cuts are widely used in computer vision. In order to speed up theoptimization process and improve the scalability for large graphs, Strandmarkand Kahl introduced a splitting method to split a graph into multiple subgraphsfor parallel computation in both shared and distributed memory models. However,this parallel algorithm (parallel BK-algorithm) does not have a polynomialbound on the number of iterations and is found non-convergent in some cases dueto the possible multiple optimal solutions of its sub-problems. To remedy this non-convergence problem, in this work we first introduce amerging method capable of merging any number of those adjacent sub-graphs whichcould hardly reach an agreement on their overlapped region in the parallelBKalgorithm. Based on the pseudo-boolean representations of graphcuts,ourmerging method is shown able to effectively reuse all the computed flows inthese sub-graphs. Through both the splitting and merging, we further propose adynamic parallel and distributed graph-cuts algorithm with guaranteedconvergence to the globally optimal solutions within a predefined number ofiterations. In essence, this work provides a general framework to allow moresophisticated splitting and merging strategies to be employed to further boostperformance. Our dynamic parallel algorithm is validated with extensiveexperimental results.
arxiv-13800-77 | Preconditioned Data Sparsification for Big Data with Applications to PCA and K-means | http://arxiv.org/pdf/1511.00152v2.pdf | author:Farhad Pourkamali-Anaraki, Stephen Becker category:stat.ML cs.LG published:2015-10-31 summary:We analyze a compression scheme for large data sets that randomly keeps asmall percentage of the components of each data sample. The benefit is that theoutput is a sparse matrix and therefore subsequent processing, such as PCA orK-means, is significantly faster, especially in a distributed-data setting.Furthermore, the sampling is single-pass and applicable to streaming data. Thesampling mechanism is a variant of previous methods proposed in the literaturecombined with a randomized preconditioning to smooth the data. We provideguarantees for PCA in terms of the covariance matrix, and guarantees forK-means in terms of the error in the center estimators at a given step. Wepresent numerical evidence to show both that our bounds are nearly tight andthat our algorithms provide a real benefit when applied to standard test datasets, as well as providing certain benefits over related sampling approaches.
arxiv-13800-78 | Spatio-temporal video autoencoder with differentiable memory | http://arxiv.org/pdf/1511.06309v2.pdf | author:Viorica Patraucean, Ankur Handa, Roberto Cipolla category:cs.LG cs.CV published:2015-11-19 summary:We describe a new spatio-temporal video autoencoder, based on a classicspatial image autoencoder and a novel nested temporal autoencoder. The temporalencoder is represented by a differentiable visual memory composed ofconvolutional long short-term memory (LSTM) cells that integrate changes overtime. Here we target motion changes and use as temporal decoder a robustoptical flow prediction module together with an image sampler serving asbuilt-in feedback loop. The architecture is end-to-end differentiable. At eachtime step, the system receives as input a video frame, predicts the opticalflow based on the current observation and the LSTM memory state as a densetransformation map, and applies it to the current frame to generate the nextframe. By minimising the reconstruction error between the predicted next frameand the corresponding ground truth next frame, we train the whole system toextract features useful for motion estimation without any supervision effort.We believe these features can in turn facilitate learning high-level tasks suchas path planning, semantic segmentation, or action recognition, reducing theoverall supervision effort.
arxiv-13800-79 | Optimization theory of Hebbian/anti-Hebbian networks for PCA and whitening | http://arxiv.org/pdf/1511.09468v1.pdf | author:Cengiz Pehlevan, Dmitri B. Chklovskii category:q-bio.NC cs.NE published:2015-11-30 summary:In analyzing information streamed by sensory organs, our brains facechallenges similar to those solved in statistical signal processing. Thissuggests that biologically plausible implementations of online signalprocessing algorithms may model neural computation. Here, we focus on suchworkhorses of signal processing as Principal Component Analysis (PCA) andwhitening which maximize information transmission in the presence of noise. Weadopt the similarity matching framework, recently developed for principalsubspace extraction, but modify the existing objective functions by adding adecorrelating term. From the modified objective functions, we derive online PCAand whitening algorithms which are implementable by neural networks with locallearning rules, i.e. synaptic weight updates that depend on the activity ofonly pre- and postsynaptic neurons. Our theory offers a principled model ofneural computations and makes testable predictions such as the dropout ofunderutilized neurons.
arxiv-13800-80 | Estimation with Norm Regularization | http://arxiv.org/pdf/1505.02294v3.pdf | author:Arindam Banerjee, Sheng Chen, Farideh Fazayeli, Vidyashankar Sivakumar category:stat.ML cs.LG published:2015-05-09 summary:Analysis of non-asymptotic estimation error and structured statisticalrecovery based on norm regularized regression, such as Lasso, needs to considerfour aspects: the norm, the loss function, the design matrix, and the noisemodel. This paper presents generalizations of such estimation error analysis onall four aspects compared to the existing literature. We characterize therestricted error set where the estimation error vector lies, establishrelations between error sets for the constrained and regularized problems, andpresent an estimation error bound applicable to any norm. Precisecharacterizations of the bound is presented for isotropic as well asanisotropic subGaussian design matrices, subGaussian noise models, and convexloss functions, including least squares and generalized linear models. Genericchaining and associated results play an important role in the analysis. A keyresult from the analysis is that the sample complexity of all such estimatorsdepends on the Gaussian width of a spherical cap corresponding to therestricted error set. Further, once the number of samples $n$ crosses therequired sample complexity, the estimation error decreases as$\frac{c}{\sqrt{n}}$, where $c$ depends on the Gaussian width of the unit normball.
arxiv-13800-81 | Ask, and shall you receive?: Understanding Desire Fulfillment in Natural Language Text | http://arxiv.org/pdf/1511.09460v1.pdf | author:Snigdha Chaturvedi, Dan Goldwasser, Hal Daume III category:cs.AI cs.CL published:2015-11-30 summary:The ability to comprehend wishes or desires and their fulfillment isimportant to Natural Language Understanding. This paper introduces the task ofidentifying if a desire expressed by a subject in a given short piece of textwas fulfilled. We propose various unstructured and structured models thatcapture fulfillment cues such as the subject's emotional state and actions. Ourexperiments with two different datasets demonstrate the importance ofunderstanding the narrative and discourse structure to address this task.
arxiv-13800-82 | Universality laws for randomized dimension reduction, with applications | http://arxiv.org/pdf/1511.09433v1.pdf | author:Samet Oymak, Joel A. Tropp category:math.PR cs.DS cs.IT math.IT math.ST stat.ML stat.TH published:2015-11-30 summary:Dimension reduction is the process of embedding high-dimensional data into alower dimensional space to facilitate its analysis. In the Euclidean setting,one fundamental technique for dimension reduction is to apply a random linearmap to the data. This dimension reduction procedure succeeds when it preservescertain geometric features of the set. The question is how large the embeddingdimension must be to ensure that randomized dimension reduction succeeds withhigh probability. This paper studies a natural family of randomized dimension reduction mapsand a large class of data sets. It proves that there is a phase transition inthe success probability of the dimension reduction map as the embeddingdimension increases. For a given data set, the location of the phase transitionis the same for all maps in this family. Furthermore, each map has the samestability properties, as quantified through the restricted minimum singularvalue. These results can be viewed as new universality laws in high-dimensionalstochastic geometry. Universality laws for randomized dimension reduction have many applicationsin applied mathematics, signal processing, and statistics. They yield designprinciples for numerical linear algebra algorithms, for compressed sensingmeasurement ensembles, and for random linear codes. Furthermore, these resultshave implications for the performance of statistical estimation methods under alarge class of random experimental designs.
arxiv-13800-83 | A General Framework for Constrained Bayesian Optimization using Information-based Search | http://arxiv.org/pdf/1511.09422v1.pdf | author:JosÃ© Miguel HernÃ¡ndez-Lobato, Michael A. Gelbart, Ryan P. Adams, Matthew W. Hoffman, Zoubin Ghahramani category:stat.ML published:2015-11-30 summary:We present an information-theoretic framework for solving global black-boxoptimization problems that also have black-box constraints. Of particularinterest to us is to efficiently solve problems with decoupled constraints, inwhich subsets of the objective and constraint functions may be evaluatedindependently. For example, when the objective is evaluated on a CPU and theconstraints are evaluated independently on a GPU. These problems require anacquisition function that can be separated into the contributions of theindividual function evaluations. We develop one such acquisition function andcall it Predictive Entropy Search with Constraints (PESC). PESC is anapproximation to the expected information gain criterion and it comparesfavorably to alternative approaches based on improvement in several syntheticand real-world problems. In addition to this, we consider problems with a mixof functions that are fast and slow to evaluate. These problems requirebalancing the amount of time spent in the meta-computation of PESC and in theactual evaluation of the target objective. We take a bounded rationalityapproach and develop a partial update for PESC which trades off accuracyagainst speed. We then propose a method for adaptively switching between thepartial and full updates for PESC. This allows us to interpolate betweenversions of PESC that are efficient in terms of function evaluations and thosethat are efficient in terms of wall-clock time. Overall, we demonstrate thatPESC is an effective algorithm that provides a promising direction towards aunified solution for constrained Bayesian optimization.
arxiv-13800-84 | Unsupervised Learning from Narrated Instruction Videos | http://arxiv.org/pdf/1506.09215v3.pdf | author:Jean-Baptiste Alayrac, Piotr Bojanowski, Nishant Agrawal, Josef Sivic, Ivan Laptev, Simon Lacoste-Julien category:cs.CV cs.LG published:2015-06-30 summary:We address the problem of automatically learning the main steps to complete acertain task, such as changing a car tire, from a set of narrated instructionvideos. The contributions of this paper are three-fold. First, we develop a newunsupervised learning approach that takes advantage of the complementary natureof the input video and the associated narration. The method solves twoclustering problems, one in text and one in video, applied one after each otherand linked by joint constraints to obtain a single coherent sequence of stepsin both modalities. Second, we collect and annotate a new challenging datasetof real-world instruction videos from the Internet. The dataset contains about800,000 frames for five different tasks that include complex interactionsbetween people and objects, and are captured in a variety of indoor and outdoorsettings. Third, we experimentally demonstrate that the proposed method canautomatically discover, in an unsupervised manner, the main steps to achievethe task and locate the steps in the input videos.
arxiv-13800-85 | A Hebbian/Anti-Hebbian Network for Online Sparse Dictionary Learning Derived from Symmetric Matrix Factorization | http://arxiv.org/pdf/1503.00690v2.pdf | author:Tao Hu, Cengiz Pehlevan, Dmitri B. Chklovskii category:q-bio.NC cs.NE stat.ML published:2015-03-02 summary:Olshausen and Field (OF) proposed that neural computations in the primaryvisual cortex (V1) can be partially modeled by sparse dictionary learning. Byminimizing the regularized representation error they derived an onlinealgorithm, which learns Gabor-filter receptive fields from a natural imageensemble in agreement with physiological experiments. Whereas the OF algorithmcan be mapped onto the dynamics and synaptic plasticity in a single-layerneural network, the derived learning rule is nonlocal - the synaptic weightupdate depends on the activity of neurons other than just pre- and postsynapticones - and hence biologically implausible. Here, to overcome this problem, wederive sparse dictionary learning from a novel cost-function - a regularizederror of the symmetric factorization of the input's similarity matrix. Ouralgorithm maps onto a neural network of the same architecture as OF but usingonly biologically plausible local learning rules. When trained on naturalimages our network learns Gabor-filter receptive fields and reproduces thecorrelation among synaptic weights hard-wired in the OF network. Therefore,online symmetric matrix factorization may serve as an algorithmic theory ofneural computation.
arxiv-13800-86 | Circulant temporal encoding for video retrieval and temporal alignment | http://arxiv.org/pdf/1506.02588v2.pdf | author:Matthijs Douze, JÃ©rÃ´me Revaud, Jakob Verbeek, HervÃ© JÃ©gou, Cordelia Schmid category:cs.CV published:2015-06-08 summary:We address the problem of specific video event retrieval. Given a query videoof a specific event, e.g., a concert of Madonna, the goal is to retrieve othervideos of the same event that temporally overlap with the query. Our approachencodes the frame descriptors of a video to jointly represent their appearanceand temporal order. It exploits the properties of circulant matrices toefficiently compare the videos in the frequency domain. This offers asignificant gain in complexity and accurately localizes the matching parts ofvideos. The descriptors can be compressed in the frequency domain with aproduct quantizer adapted to complex numbers. In this case, video retrieval isperformed without decompressing the descriptors. We also consider the temporalalignment of a set of videos. We exploit the matching confidence and anestimate of the temporal offset computed for all pairs of videos by ourretrieval approach. Our robust algorithm aligns the videos on a global timelineby maximizing the set of temporally consistent matches. The global temporalalignment enables synchronous playback of the videos of a given scene.
arxiv-13800-87 | Modeling Dynamic Relationships Between Characters in Literary Novels | http://arxiv.org/pdf/1511.09376v1.pdf | author:Snigdha Chaturvedi, Shashank Srivastava, Hal Daume III, Chris Dyer category:cs.CL cs.AI published:2015-11-30 summary:Studying characters plays a vital role in computationally representing andinterpreting narratives. Unlike previous work, which has focused on inferringcharacter roles, we focus on the problem of modeling their relationships.Rather than assuming a fixed relationship for a character pair, we hypothesizethat relationships are dynamic and temporally evolve with the progress of thenarrative, and formulate the problem of relationship modeling as a structuredprediction problem. We propose a semi-supervised framework to learnrelationship sequences from fully as well as partially labeled data. We presenta Markovian model capable of accumulating historical beliefs about therelationship and status changes. We use a set of rich linguistic andsemantically motivated features that incorporate world knowledge to investigatethe textual content of narrative. We empirically demonstrate that such aframework outperforms competitive baselines.
arxiv-13800-88 | Pattern Recognition of Bearing Faults using Smoother Statistical Features | http://arxiv.org/pdf/1503.04444v2.pdf | author:Muhammad Masood Tahir, Ayyaz Hussain category:cs.CV published:2015-03-15 summary:A pattern recognition (PR) based diagnostic scheme is presented to identifybearing faults, using time domain features. Vibration data is acquired fromfaulty bearings using a test rig. The features are extracted from the data, andprocessed prior to utilize in the PR process. The processing involves smoothingof feature distributions. This reduces the undesired impact of vibrationrandomness on the PR process, and thus enhances the diagnostic accuracy of themodel.
arxiv-13800-89 | Behavior Discovery and Alignment of Articulated Object Classes from Unstructured Video | http://arxiv.org/pdf/1511.09319v1.pdf | author:Luca Del Pero, Susanna Ricco, Rahul Sukthankar, Vittorio Ferrari category:cs.CV published:2015-11-30 summary:Internet videos provide a wealth of data that could be used to learn theappearance or expected behaviors of many object classes. However, mostsupervised methods cannot exploit this data directly, as they require a largeamount of time-consuming manual annotations. As a step towards solving thisproblem, we propose an automatic system for organizing the content of acollection of videos of an articulated object class (e.g. tiger, horse). Byexploiting the recurring motion patterns of the class across videos, oursystem: 1) identifies its characteristic behaviors; and 2) recoverspixel-to-pixel alignments across different instances. The behavior discovery stage generates temporal video intervals, eachautomatically trimmed to one instance of the discovered behavior, clustered bytype. It relies on our novel motion representation for articulated motion basedon the displacement of ordered pairs of trajectories (PoTs). The alignmentstage aligns hundreds of instances of the class to a great accuracy despiteconsiderable appearance variations (e.g. an adult tiger and a cub). It uses aflexible Thin Plate Spline deformation model that can vary through time. Wecarefully evaluate each step of our system on a new, fully annotated dataset.On behavior discovery, we outperform the state-of-the-art Improved DTFdescriptor. On spatial alignment, we outperform the popular SIFT Flowalgorithm.
arxiv-13800-90 | On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models | http://arxiv.org/pdf/1511.09249v1.pdf | author:Juergen Schmidhuber category:cs.AI cs.LG cs.NE published:2015-11-30 summary:This paper addresses the general problem of reinforcement learning (RL) inpartially observable environments. In 2013, our large RL recurrent neuralnetworks (RNNs) learned from scratch to drive simulated cars fromhigh-dimensional video input. However, real brains are more powerful in manyways. In particular, they learn a predictive model of their initially unknownenvironment, and somehow use it for abstract (e.g., hierarchical) planning andreasoning. Guided by algorithmic information theory, we describe RNN-based AIs(RNNAIs) designed to do the same. Such an RNNAI can be trained on never-endingsequences of tasks, some of them provided by the user, others invented by theRNNAI itself in a curious, playful fashion, to improve its RNN-based worldmodel. Unlike our previous model-building RNN-based RL machines dating back to1990, the RNNAI learns to actively query its model for abstract reasoning andplanning and decision making, essentially "learning to think." The basic ideasof this report can be applied to many other cases where one RNN-like systemexploits the algorithmic information content of another. They are taken from agrant proposal submitted in Fall 2014, and also explain concepts such as"mirror neurons." Experimental results will be described in separate papers.
arxiv-13800-91 | Fine-Grained Classification via Mixture of Deep Convolutional Neural Networks | http://arxiv.org/pdf/1511.09209v1.pdf | author:ZongYuan Ge, Alex Bewley, Christopher McCool, Ben Upcroft, Peter Corke, Conrad Sanderson category:cs.CV published:2015-11-30 summary:We present a novel deep convolutional neural network (DCNN) system forfine-grained image classification, called a mixture of DCNNs (MixDCNN). Thefine-grained image classification problem is characterised by large intra-classvariations and small inter-class variations. To overcome these problems ourproposed MixDCNN system partitions images into K subsets of similar images andlearns an expert DCNN for each subset. The output from each of the K DCNNs iscombined to form a single classification decision. In contrast to previoustechniques, we provide a formulation to perform joint end-to-end training ofthe K DCNNs simultaneously. Extensive experiments, on three datasets using twonetwork structures (AlexNet and GoogLeNet), show that the proposed MixDCNNsystem consistently outperforms other methods. It provides a relativeimprovement of 12.7% and achieves state-of-the-art results on two datasets.
arxiv-13800-92 | Category Enhanced Word Embedding | http://arxiv.org/pdf/1511.08629v2.pdf | author:Chunting Zhou, Chonglin Sun, Zhiyuan Liu, Francis C. M. Lau category:cs.CL published:2015-11-27 summary:Distributed word representations have been demonstrated to be effective incapturing semantic and syntactic regularities. Unsupervised representationlearning from large unlabeled corpora can learn similar representations forthose words that present similar co-occurrence statistics. Besides localoccurrence statistics, global topical information is also important knowledgethat may help discriminate a word from another. In this paper, we incorporatecategory information of documents in the learning of word representations andto learn the proposed models in a document-wise manner. Our models outperformseveral state-of-the-art models in word analogy and word similarity tasks.Moreover, we evaluate the learned word vectors on sentiment analysis and textclassification tasks, which shows the superiority of our learned word vectors.We also learn high-quality category embeddings that reflect topical meanings.
arxiv-13800-93 | A C-LSTM Neural Network for Text Classification | http://arxiv.org/pdf/1511.08630v2.pdf | author:Chunting Zhou, Chonglin Sun, Zhiyuan Liu, Francis C. M. Lau category:cs.CL published:2015-11-27 summary:Neural network models have been demonstrated to be capable of achievingremarkable performance in sentence and document modeling. Convolutional neuralnetwork (CNN) and recurrent neural network (RNN) are two mainstreamarchitectures for such modeling tasks, which adopt totally different ways ofunderstanding natural languages. In this work, we combine the strengths of botharchitectures and propose a novel and unified model called C-LSTM for sentencerepresentation and text classification. C-LSTM utilizes CNN to extract asequence of higher-level phrase representations, and are fed into a longshort-term memory recurrent neural network (LSTM) to obtain the sentencerepresentation. C-LSTM is able to capture both local features of phrases aswell as global and temporal sentence semantics. We evaluate the proposedarchitecture on sentiment classification and question classification tasks. Theexperimental results show that the C-LSTM outperforms both CNN and LSTM and canachieve excellent performance on these tasks.
arxiv-13800-94 | Asynchronous adaptive networks | http://arxiv.org/pdf/1511.09180v1.pdf | author:Ali H. Sayed, Xiaochuan Zhao category:math.OC cs.LG cs.MA published:2015-11-30 summary:In a recent article [1] we surveyed advances related to adaptation, learning,and optimization over synchronous networks. Various distributed strategies werediscussed that enable a collection of networked agents to interact locally inresponse to streaming data and to continually learn and adapt to track driftsin the data and models. Under reasonable technical conditions on the data, theadaptive networks were shown to be mean-square stable in the slow adaptationregime, and their mean-square-error performance and convergence rate werecharacterized in terms of the network topology and data statistical moments[2]. Classical results for single-agent adaptation and learning were recoveredas special cases. Following the works [3]-[5], this chapter complements theexposition from [1] and extends the results to asynchronous networks. Theoperation of this class of networks can be subject to various sources ofuncertainties that influence their dynamic behavior, including randomlychanging topologies, random link failures, random data arrival times, andagents turning on and off randomly. In an asynchronous environment, agents maystop updating their solutions or may stop sending or receiving information in arandom manner and without coordination with other agents. The presentation willreveal that the mean-square-error performance of asynchronous networks remainslargely unaltered compared to synchronous networks. The results justify theremarkable resilience of cooperative networks in the face of random events.
arxiv-13800-95 | Recognizing Temporal Linguistic Expression Pattern of Individual with Suicide Risk on Social Media | http://arxiv.org/pdf/1511.09173v1.pdf | author:Aiqi Zhang, Ang Li, Tingshao Zhu category:cs.SI cs.CL published:2015-11-30 summary:Suicide is a global public health problem. Early detection of individualsuicide risk plays a key role in suicide prevention. In this paper, we proposeto look into individual suicide risk through time series analysis of personallinguistic expression on social media (Weibo). We examined temporal patterns ofthe linguistic expression of individuals on Chinese social media (Weibo). Then,we used such temporal patterns as predictor variables to build classificationmodels for estimating levels of individual suicide risk. Characteristics oftime sequence curves to linguistic features including parentheses, auxiliaryverbs, personal pronouns and body words are reported to affect performance ofsuicide most, and the predicting model has a accuracy higher than 0.60, shownby the results. This paper confirms the efficiency of the social media data indetecting individual suicide risk. Results of this study may be insightful forimproving the performance of suicide prevention programs.
arxiv-13800-96 | ELM-Based Distributed Cooperative Learning Over Networks | http://arxiv.org/pdf/1504.00981v2.pdf | author:Wu Ai, Weisheng Chen category:cs.LG math.OC published:2015-04-04 summary:This paper investigates distributed cooperative learning algorithms for dataprocessing in a network setting. Specifically, the extreme learning machine(ELM) is introduced to train a set of data distributed across severalcomponents, and each component runs a program on a subset of the entire data.In this scheme, there is no requirement for a fusion center in the network dueto e.g., practical limitations, security, or privacy reasons. We firstreformulate the centralized ELM training problem into a separable form amongnodes with consensus constraints. Then, we solve the equivalent problem usingdistributed optimization tools. A new distributed cooperative learningalgorithm based on ELM, called DC-ELM, is proposed. The architecture of thisalgorithm differs from that of some existing parallel/distributed ELMs based onMapReduce or cloud computing. We also present an online version of the proposedalgorithm that can learn data sequentially in a one-by-one or chunk-by-chunkmode. The novel algorithm is well suited for potential applications such asartificial intelligence, computational biology, finance, wireless sensornetworks, and so on, involving datasets that are often extremely large,high-dimensional and located on distributed data sources. We show simulationresults on both synthetic and real-world data sets.
arxiv-13800-97 | Proximal gradient method for huberized support vector machine | http://arxiv.org/pdf/1511.09159v1.pdf | author:Yangyang Xu, Ioannis Akrotirianakis, Amit Chakraborty category:stat.ML cs.LG cs.NA math.NA published:2015-11-30 summary:The Support Vector Machine (SVM) has been used in a wide variety ofclassification problems. The original SVM uses the hinge loss function, whichis non-differentiable and makes the problem difficult to solve in particularfor regularized SVMs, such as with $\ell_1$-regularization. This paperconsiders the Huberized SVM (HSVM), which uses a differentiable approximationof the hinge loss function. We first explore the use of the Proximal Gradient(PG) method to solving binary-class HSVM (B-HSVM) and then generalize it tomulti-class HSVM (M-HSVM). Under strong convexity assumptions, we show that ouralgorithm converges linearly. In addition, we give a finite convergence resultabout the support of the solution, based on which we further accelerate thealgorithm by a two-stage method. We present extensive numerical experiments onboth synthetic and real datasets which demonstrate the superiority of ourmethods over some state-of-the-art methods for both binary- and multi-classSVMs.
arxiv-13800-98 | Alternating direction method of multipliers for regularized multiclass support vector machines | http://arxiv.org/pdf/1511.09153v1.pdf | author:Yangyang Xu, Ioannis Akrotirianakis, Amit Chakraborty category:stat.ML math.OC published:2015-11-30 summary:The support vector machine (SVM) was originally designed for binaryclassifications. A lot of effort has been put to generalize the binary SVM tomulticlass SVM (MSVM) which are more complex problems. Initially, MSVMs weresolved by considering their dual formulations which are quadratic programs andcan be solved by standard second-order methods. However, the duals of MSVMswith regularizers are usually more difficult to formulate and computationallyvery expensive to solve. This paper focuses on several regularized MSVMs andextends the alternating direction method of multiplier (ADMM) to these MSVMs.Using a splitting technique, all considered MSVMs are written as two-blockconvex programs, for which the ADMM has global convergence guarantees.Numerical experiments on synthetic and real data demonstrate the highefficiency and accuracy of our algorithms.
arxiv-13800-99 | Hierarchical Invariant Feature Learning with Marginalization for Person Re-Identification | http://arxiv.org/pdf/1511.09150v1.pdf | author:Rahul Rama Varior, Gang Wang category:cs.CV published:2015-11-30 summary:This paper addresses the problem of matching pedestrians across multiplecamera views, known as person re-identification. Variations in lightingconditions, environment and pose changes across camera views makere-identification a challenging problem. Previous methods address thesechallenges by designing specific features or by learning a distance function.We propose a hierarchical feature learning framework that learns invariantrepresentations from labeled image pairs. A mapping is learned such that theextracted features are invariant for images belonging to same individual acrossviews. To learn robust representations and to achieve better generalization tounseen data, the system has to be trained with a large amount of data.Critically, most of the person re-identification datasets are small. Manuallyaugmenting the dataset by partial corruption of input data introducesadditional computational burden as it requires several training epochs toconverge. We propose a hierarchical network which incorporates amarginalization technique that can reap the benefits of training on largedatasets without explicit augmentation. We compare our approach with severalbaseline algorithms as well as popular linear and non-linear metric learningalgorithms and demonstrate improved performance on challenging publiclyavailable datasets, VIPeR, CUHK01, CAVIAR4REID and iLIDS. Our approach alsoachieves the stateof-the-art results on these datasets.
arxiv-13800-100 | Complete Dictionary Recovery over the Sphere II: Recovery by Riemannian Trust-region Method | http://arxiv.org/pdf/1511.04777v2.pdf | author:Ju Sun, Qing Qu, John Wright category:cs.IT cs.CV math.IT math.OC stat.ML published:2015-11-15 summary:We consider the problem of recovering a complete (i.e., square andinvertible) matrix $\mathbf A_0$, from $\mathbf Y \in \mathbb{R}^{n \times p}$with $\mathbf Y = \mathbf A_0 \mathbf X_0$, provided $\mathbf X_0$ issufficiently sparse. This recovery problem is central to the theoreticalunderstanding of dictionary learning, which seeks a sparse representation for acollection of input signals, and finds numerous applications in modern signalprocessing and machine learning. We give the first efficient algorithm thatprovably recovers $\mathbf A_0$ when $\mathbf X_0$ has $O(n)$ nonzeros percolumn, under suitable probability model for $\mathbf X_0$. Our algorithmic pipeline centers around solving a certain nonconvexoptimization problem with a spherical constraint, and hence is naturallyphrased in the language of manifold optimization. In a companion paper(arXiv:1511.03607), we have showed that with high probability our nonconvexformulation has no "spurious" local minimizers and any saddle point present issecond-order. In this paper, we take advantage of the particular geometricstructure and design a Riemannian trust region algorithm over the sphere thatprovably converges to a local minimizer with an arbitrary initialization. Suchminimizers give excellent approximations to rows of $\mathbf X_0$. The rows arerecovered by linear programming rounding and deflation.
arxiv-13800-101 | Complete Dictionary Recovery over the Sphere I: Overview and the Geometric Picture | http://arxiv.org/pdf/1511.03607v2.pdf | author:Ju Sun, Qing Qu, John Wright category:cs.IT cs.CV math.IT math.OC stat.ML published:2015-11-11 summary:We consider the problem of recovering a complete (i.e., square andinvertible) matrix $\mathbf A_0$, from $\mathbf Y \in \mathbb{R}^{n \times p}$with $\mathbf Y = \mathbf A_0 \mathbf X_0$, provided $\mathbf X_0$ issufficiently sparse. This recovery problem is central to the theoreticalunderstanding of dictionary learning, which seeks a sparse representation for acollection of input signals, and finds numerous applications in modern signalprocessing and machine learning. We give the first efficient algorithm thatprovably recovers $\mathbf A_0$ when $\mathbf X_0$ has $O(n)$ nonzeros percolumn, under suitable probability model for $\mathbf X_0$. In contrast, priorresults based on efficient algorithms provide recovery guarantees when $\mathbfX_0$ has only $O(n^{1-\delta})$ nonzeros per column for any constant $\delta\in (0, 1)$. Our algorithmic pipeline centers around solving a certain nonconvexoptimization problem with a spherical constraint. In this paper, we provide ageometric characterization of the high-dimensional objective landscape. Inparticular, we show that the problem is highly structured: with highprobability there are no "spurious" local minimizers and all saddle points aresecond-order. This distinctive structure makes the problem amenable toefficient algorithms. In a companion paper (arXiv:1511.04777), we design asecond-order trust-region algorithm over the sphere that provably converges toa local minimizer with an arbitrary initialization, despite the presence ofsaddle points.
arxiv-13800-102 | Clustering is Efficient for Approximate Maximum Inner Product Search | http://arxiv.org/pdf/1507.05910v3.pdf | author:Alex Auvolat, Sarath Chandar, Pascal Vincent, Hugo Larochelle, Yoshua Bengio category:cs.LG cs.CL stat.ML published:2015-07-21 summary:Efficient Maximum Inner Product Search (MIPS) is an important task that has awide applicability in recommendation systems and classification with a largenumber of classes. Solutions based on locality-sensitive hashing (LSH) as wellas tree-based solutions have been investigated in the recent literature, toperform approximate MIPS in sublinear time. In this paper, we compare these toanother extremely simple approach for solving approximate MIPS, based onvariants of the k-means clustering algorithm. Specifically, we propose to traina spherical k-means, after having reduced the MIPS problem to a Maximum CosineSimilarity Search (MCSS). Experiments on two standard recommendation systembenchmarks as well as on large vocabulary word embeddings, show that thissimple approach yields much higher speedups, for the same retrieval precision,than current state-of-the-art hashing-based and tree-based methods. This simplemethod also yields more robust retrievals when the query is corrupted by noise.
arxiv-13800-103 | Aspect-based Opinion Summarization with Convolutional Neural Networks | http://arxiv.org/pdf/1511.09128v1.pdf | author:Haibing Wu, Yiwei Gu, Shangdi Sun, Xiaodong Gu category:cs.CL cs.IR cs.LG published:2015-11-30 summary:This paper considers Aspect-based Opinion Summarization (AOS) of reviews onparticular products. To enable real applications, an AOS system needs toaddress two core subtasks, aspect extraction and sentiment classification. Mostexisting approaches to aspect extraction, which use linguistic analysis ortopic modeling, are general across different products but not precise enough orsuitable for particular products. Instead we take a less general but moreprecise scheme, directly mapping each review sentence into pre-defined aspects.To tackle aspect mapping and sentiment classification, we propose twoConvolutional Neural Network (CNN) based methods, cascaded CNN and multitaskCNN. Cascaded CNN contains two levels of convolutional networks. Multiple CNNsat level 1 deal with aspect mapping task, and a single CNN at level 2 dealswith sentiment classification. Multitask CNN also contains multiple aspect CNNsand a sentiment CNN, but different networks share the same word embeddings.Experimental results indicate that both cascaded and multitask CNNs outperformSVM-based methods by large margins. Multitask CNN generally performs betterthan cascaded CNN.
arxiv-13800-104 | Optimal prediction for sparse linear models? Lower bounds for coordinate-separable M-estimators | http://arxiv.org/pdf/1503.03188v2.pdf | author:Yuchen Zhang, Martin J. Wainwright, Michael I. Jordan category:math.ST stat.ML stat.TH published:2015-03-11 summary:For the problem of high-dimensional sparse linear regression, it is knownthat an $\ell_0$-based estimator can achieve a $1/n$ "fast" rate on theprediction error without any conditions on the design matrix, whereas inabsence of restrictive conditions on the design matrix, popular polynomial-timemethods only guarantee the $1/\sqrt{n}$ "slow" rate. In this paper, we showthat the slow rate is intrinsic to a broad class of M-estimators. Inparticular, for estimators based on minimizing a least-squares cost functiontogether with a (possibly non-convex) coordinate-wise separable regularizer,there is always a "bad" local optimum such that the associated prediction erroris lower bounded by a constant multiple of $1/\sqrt{n}$. For convexregularizers, this lower bound applies to all global optima. The theory isapplicable to many popular estimators, including convex $\ell_1$-based methodsas well as M-estimators based on nonconvex regularizers, including the SCADpenalty or the MCP regularizer. In addition, for a broad class of nonconvexregularizers, we show that the bad local optima are very common, in that abroad class of local minimization algorithms with random initialization willtypically converge to a bad solution.
arxiv-13800-105 | Tracking Randomly Moving Objects on Edge Box Proposals | http://arxiv.org/pdf/1507.08085v2.pdf | author:Gao Zhu, Fatih Porikli, Hongdong Li category:cs.CV published:2015-07-29 summary:Most tracking-by-detection methods employ a local search window around thepredicted object location in the current frame assuming the previous locationis accurate, the trajectory is smooth, and the computational capacity permits asearch radius that can accommodate the maximum speed yet small enough to reducemismatches. These, however, may not be valid always, in particular for fast andirregularly moving objects. Here, we present an object tracker that is notlimited to a local search window and has ability to probe efficiently theentire frame. Our method generates a small number of "high-quality" proposalsby a novel instance-specific objectness measure and evaluates them against theobject model that can be adopted from an existing tracking-by-detectionapproach as a core tracker. During the tracking process, we update the objectmodel concentrating on hard false-positives supplied by the proposals, whichhelp suppressing distractors caused by difficult background clutters, and learnhow to re-rank proposals according to the object model. Since we reducesignificantly the number of hypotheses the core tracker evaluates, we can usericher object descriptors and stronger detector. Our method outperforms mostrecent state-of-the-art trackers on popular tracking benchmarks, and providesimproved robustness for fast moving objects as well as for ultra low-frame-ratevideos.
arxiv-13800-106 | Exploring Models and Data for Image Question Answering | http://arxiv.org/pdf/1505.02074v4.pdf | author:Mengye Ren, Ryan Kiros, Richard Zemel category:cs.LG cs.AI cs.CL cs.CV published:2015-05-08 summary:This work aims to address the problem of image-based question-answering (QA)with new models and datasets. In our work, we propose to use neural networksand visual semantic embeddings, without intermediate stages such as objectdetection and image segmentation, to predict answers to simple questions aboutimages. Our model performs 1.8 times better than the only published results onan existing image QA dataset. We also present a question generation algorithmthat converts image descriptions, which are widely available, into QA form. Weused this algorithm to produce an order-of-magnitude larger dataset, with moreevenly distributed answers. A suite of baseline results on this new dataset arealso presented.
arxiv-13800-107 | Machine Learning Sentiment Prediction based on Hybrid Document Representation | http://arxiv.org/pdf/1511.09107v1.pdf | author:Panagiotis Stalidis, Maria Giatsoglou, Konstantinos Diamantaras, George Sarigiannidis, Konstantinos Ch. Chatzisavvas category:cs.CL cs.AI stat.ML published:2015-11-29 summary:Automated sentiment analysis and opinion mining is a complex processconcerning the extraction of useful subjective information from text. Theexplosion of user generated content on the Web, especially the fact thatmillions of users, on a daily basis, express their opinions on products andservices to blogs, wikis, social networks, message boards, etc., render thereliable, automated export of sentiments and opinions from unstructured textcrucial for several commercial applications. In this paper, we present a novelhybrid vectorization approach for textual resources that combines a weightedvariant of the popular Word2Vec representation (based on Term Frequency-InverseDocument Frequency) representation and with a Bag- of-Words representation anda vector of lexicon-based sentiment values. The proposed text representationapproach is assessed through the application of several machine learningclassification algorithms on a dataset that is used extensively in literaturefor sentiment detection. The classification accuracy derived through theproposed hybrid vectorization approach is higher than when its individualcomponents are used for text represenation, and comparable withstate-of-the-art sentiment detection methodologies.
arxiv-13800-108 | Position paper: a general framework for applying machine learning techniques in operating room | http://arxiv.org/pdf/1511.09099v1.pdf | author:Filippo Maria Bianchi, Enrico De Santis, Hedieh Montazeri, Parisa Naraei, Alireza Sadeghian category:cs.CY cs.LG published:2015-11-29 summary:In this position paper we describe a general framework for applying machinelearning and pattern recognition techniques in healthcare. In particular, weare interested in providing an automated tool for monitoring and incrementingthe level of awareness in the operating room and for identifying human errorswhich occur during the laparoscopy surgical operation. The framework that wepresent is divided in three different layers: each layer implements algorithmswhich have an increasing level of complexity and which perform functionalitywith an higher degree of abstraction. In the first layer, raw data collectedfrom sensors in the operating room during surgical operation, they arepre-processed and aggregated. The results of this initial phase are transferredto a second layer, which implements pattern recognition techniques and extractrelevant features from the data. Finally, in the last layer, expert systems areemployed to take high level decisions, which represent the final output of thesystem.
arxiv-13800-109 | Neural Network with Unbounded Activation Functions is Universal Approximator | http://arxiv.org/pdf/1505.03654v2.pdf | author:Sho Sonoda, Noboru Murata category:cs.NE cs.LG math.FA published:2015-05-14 summary:This paper presents an investigation of the approximation property of neuralnetworks with unbounded activation functions, such as the rectified linear unit(ReLU), which is the new de-facto standard of deep learning. The ReLU networkcan be analyzed by the ridgelet transform with respect to Lizorkindistributions. By showing three reconstruction formulas by using the Fourierslice theorem, the Radon transform, and Parseval's relation, it is shown that aneural network with unbounded activation functions still satisfies theuniversal approximation property. As an additional consequence, the ridgelettransform, or the backprojection filter in the Radon domain, is what thenetwork learns after backpropagation. Subject to a constructive admissibilitycondition, the trained network can be obtained by simply discretizing theridgelet transform, without backpropagation. Numerical examples not onlysupport the consistency of the admissibility condition but also imply that somenon-admissible cases result in low-pass filtering.
arxiv-13800-110 | Sparse Coral Classification Using Deep Convolutional Neural Networks | http://arxiv.org/pdf/1511.09067v1.pdf | author:Mohamed Elawady category:cs.CV published:2015-11-29 summary:Autonomous repair of deep-sea coral reefs is a recent proposed idea tosupport the oceans ecosystem in which is vital for commercial fishing, tourismand other species. This idea can be operated through using many smallautonomous underwater vehicles (AUVs) and swarm intelligence techniques tolocate and replace chunks of coral which have been broken off, thus enablingre-growth and maintaining the habitat. The aim of this project is developingmachine vision algorithms to enable an underwater robot to locate a coral reefand a chunk of coral on the seabed and prompt the robot to pick it up. Althoughthere is no literature on this particular problem, related work on fishcounting may give some insight into the problem. The technical challenges areprincipally due to the potential lack of clarity of the water and platformstabilization as well as spurious artifacts (rocks, fish, and crabs). Wepresent an efficient sparse classification for coral species using superviseddeep learning method called Convolutional Neural Networks (CNNs). We computeWeber Local Descriptor (WLD), Phase Congruency (PC), and Zero ComponentAnalysis (ZCA) Whitening to extract shape and texture feature descriptors,which are employed to be supplementary channels (feature-based maps) besidesbasic spatial color channels (spatial-based maps) of coral input image, we alsoexperiment state-of-art preprocessing underwater algorithms for imageenhancement and color normalization and color conversion adjustment. Ourproposed coral classification method is developed under MATLAB platform, andevaluated by two different coral datasets (University of California San Diego'sMoorea Labeled Corals, and Heriot-Watt University's Atlantic Deep Sea).
arxiv-13800-111 | Multimodal Skip-gram Using Convolutional Pseudowords | http://arxiv.org/pdf/1511.04024v2.pdf | author:Zachary Seymour, Yingming Li, Zhongfei Zhang category:cs.CL cs.CV published:2015-11-12 summary:This work studies the representational mapping across multimodal data suchthat given a piece of the raw data in one modality the corresponding semanticdescription in terms of the raw data in another modality is immediatelyobtained. Such a representational mapping can be found in a wide spectrum ofreal-world applications including image/video retrieval, object recognition,action/behavior recognition, and event understanding and prediction. To thatend, we introduce a simplified training objective for learning multimodalembeddings using the skip-gram architecture by introducing convolutional"pseudowords:" embeddings composed of the additive combination of distributedword representations and image features from convolutional neural networksprojected into the multimodal space. We present extensive results of therepresentational properties of these embeddings on various word similaritybenchmarks to show the promise of this approach.
arxiv-13800-112 | Optimization over Sparse Symmetric Sets via a Nonmonotone Projected Gradient Method | http://arxiv.org/pdf/1509.08581v3.pdf | author:Zhaosong Lu category:math.OC cs.LG cs.NA stat.CO stat.ML published:2015-09-29 summary:We consider the problem of minimizing a Lipschitz differentiable functionover a class of sparse symmetric sets that has wide applications in engineeringand science. For this problem, it is known that any accumulation point of theclassical projected gradient (PG) method with a constant stepsize $1/L$satisfies the $L$-stationarity optimality condition that was introduced in [3].In this paper we introduce a new optimality condition that is stronger than the$L$-stationarity optimality condition. We also propose a nonmonotone projectedgradient (NPG) method for this problem by incorporating some support-changingand coordintate-swapping strategies into a projected gradient method withvariable stepsizes. It is shown that any accumulation point of NPG satisfiesthe new optimality condition and moreover it is a coordinatewise stationarypoint. Under some suitable assumptions, we further show that it is a global ora local minimizer of the problem. Numerical experiments are conducted tocompare the performance of PG and NPG. The computational results demonstratethat NPG has substantially better solution quality than PG, and moreover, it isat least comparable to, but sometimes can be much faster than PG in terms ofspeed.
arxiv-13800-113 | Reinforcement Learning Applied to an Electric Water Heater: From Theory to Practice | http://arxiv.org/pdf/1512.00408v1.pdf | author:Frederik Ruelens, Bert Claessens, Salman Quaiyum, Bart De Schutter, Robert Babuska, Ronnie Belmans category:cs.LG published:2015-11-29 summary:Electric water heaters have the ability to store energy in their water bufferwithout impacting the comfort of the end user. This feature makes them a primecandidate for residential demand response. However, the stochastic andnonlinear dynamics of electric water heaters, makes it challenging to harnesstheir flexibility. Driven by this challenge, this paper formulates theunderlying sequential decision-making problem as a Markov decision process anduses techniques from reinforcement learning. Specifically, we apply anauto-encoder network to find a compact feature representation of the sensormeasurements, which helps to mitigate the curse of dimensionality. A wellknownbatch reinforcement learning technique, fitted Q-iteration, is used to find acontrol policy, given this feature representation. In a simulation-basedexperiment using an electric water heater with 50 temperature sensors, theproposed method was able to achieve good policies much faster than when usingthe full state information. In a lab experiment, we apply fitted Q-iteration toan electric water heater with eight temperature sensors. Further reducing thestate vector did not improve the results of fitted Q-iteration. The results ofthe lab experiment, spanning 40 days, indicate that compared to a thermostatcontroller, the presented approach was able to reduce the total cost of energyconsumption of the electric water heater by 15%.
arxiv-13800-114 | On-line Recognition of Handwritten Mathematical Symbols | http://arxiv.org/pdf/1511.09030v1.pdf | author:Martin Thoma category:cs.CV published:2015-11-29 summary:Finding the name of an unknown symbol is often hard, but writing the symbolis easy. This bachelor's thesis presents multiple systems that use the pentrajectory to classify handwritten symbols. Five preprocessing steps, one dataaugmentation algorithm, five features and five variants for multilayerPerceptron training were evaluated using 166898 recordings which were collectedwith two crowdsourcing projects. The evaluation results of these 21 experimentswere used to create an optimized recognizer which has a TOP1 error of less than17.5% and a TOP3 error of 4.0%. This is an improvement of 18.5% for the TOP1error and 29.7% for the TOP3 error.
arxiv-13800-115 | How do the naive Bayes classifier and the Support Vector Machine compare in their ability to forecast the Stock Exchange of Thailand? | http://arxiv.org/pdf/1511.08987v1.pdf | author:Napas Udomsak category:cs.LG published:2015-11-29 summary:This essay investigates the question of how the naive Bayes classifier andthe support vector machine compare in their ability to forecast the StockExchange of Thailand. The theory behind the SVM and the naive Bayes classifieris explored. The algorithms are trained using data from the month of January2010, extracted from the MarketWatch.com website. Input features are selectedbased on previous studies of the SET100 Index. The Weka 3 software is used tocreate models from the labeled training data. Mean squared error and proportionof correctly classified instances, and a number of other error measurements arethe used to compare the two algorithms. This essay shows that these twoalgorithms are currently not advanced enough to accurately model the stockexchange. Nevertheless, the naive Bayes is better than the support vectormachine at predicting the Stock Exchange of Thailand.
arxiv-13800-116 | False Discoveries Occur Early on the Lasso Path | http://arxiv.org/pdf/1511.01957v3.pdf | author:Weijie Su, Malgorzata Bogdan, Emmanuel Candes category:math.ST cs.IT math.IT stat.ML stat.TH published:2015-11-05 summary:In regression settings where explanatory variables have very low correlationsand where there are relatively few effects each of large magnitude, it iscommonly believed that the Lasso shall be able to find the important variableswith few errors---if any. In contrast, this paper shows that this is not thecase even when the design variables are stochastically independent. In a regimeof linear sparsity, we demonstrate that true features and null features arealways interspersed on the Lasso path, and that this phenomenon occurs nomatter how strong the effect sizes are. We derive a sharp asymptotic trade-offbetween false and true positive rates or, equivalently, between measures oftype I and type II errors along the Lasso path. This trade-off states that ifwe ever want to achieve a type II error (false negative rate) under a giventhreshold, then anywhere on the Lasso path the type I error (false positiverate) will need to exceed a given threshold so that we can never have botherrors at a low level at the same time. Our analysis uses tools fromapproximate message passing (AMP) theory as well as novel elements to deal witha possibly adaptive selection of the Lasso regularizing parameter.
arxiv-13800-117 | Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks | http://arxiv.org/pdf/1502.05698v10.pdf | author:Jason Weston, Antoine Bordes, Sumit Chopra, Alexander M. Rush, Bart van MerriÃ«nboer, Armand Joulin, Tomas Mikolov category:cs.AI cs.CL stat.ML published:2015-02-19 summary:One long-term goal of machine learning research is to produce methods thatare applicable to reasoning and natural language, in particular building anintelligent dialogue agent. To measure progress towards that goal, we argue forthe usefulness of a set of proxy tasks that evaluate reading comprehension viaquestion answering. Our tasks measure understanding in several ways: whether asystem is able to answer questions via chaining facts, simple induction,deduction and many more. The tasks are designed to be prerequisites for anysystem that aims to be capable of conversing with a human. We believe manyexisting learning systems can currently not solve them, and hence our aim is toclassify these tasks into skill sets, so that researchers can identify (andthen rectify) the failings of their systems. We also extend and improve therecently introduced Memory Networks model, and show it is able to solve some,but not all, of the tasks.
arxiv-13800-118 | Robotic Search & Rescue via Online Multi-task Reinforcement Learning | http://arxiv.org/pdf/1511.08967v1.pdf | author:Lisa Lee category:cs.AI cs.LG cs.RO published:2015-11-29 summary:Reinforcement learning (RL) is a general and well-known method that a robotcan use to learn an optimal control policy to solve a particular task. We wouldlike to build a versatile robot that can learn multiple tasks, but using RL foreach of them would be prohibitively expensive in terms of both time andwear-and-tear on the robot. To remedy this problem, we use the Policy GradientEfficient Lifelong Learning Algorithm (PG-ELLA), an online multi-task RLalgorithm that enables the robot to efficiently learn multiple consecutivetasks by sharing knowledge between these tasks to accelerate learning andimprove performance. We implemented and evaluated three RL methods--Q-learning,policy gradient RL, and PG-ELLA--on a ground robot whose task is to find atarget object in an environment under different surface conditions. In thispaper, we discuss our implementations as well as present an empirical analysisof their learning performance.
arxiv-13800-119 | Sparseness helps: Sparsity Augmented Collaborative Representation for Classification | http://arxiv.org/pdf/1511.08956v1.pdf | author:Naveed Akhtar, Faisal Shafait, Ajmal Mian category:cs.CV published:2015-11-29 summary:Many classification approaches first represent a test sample using thetraining samples of all the classes. This collaborative representation is thenused to label the test sample. It was a common belief that sparseness of therepresentation is the key to success for this classification scheme. However,more recently, it has been claimed that it is the collaboration and not thesparseness that makes the scheme effective. This claim is attractive as itallows to relinquish the computationally expensive sparsity constraint over therepresentation. In this paper, we first extend the analysis supporting thisclaim and then show that sparseness explicitly contributes to improvedclassification, hence it should not be completely ignored for computationalgains. Inspired by this result, we augment a dense collaborative representationwith a sparse representation and propose an efficient classification methodthat capitalizes on the resulting representation. The augmented representationand the classification method work together meticulously to achieve higheraccuracy and lower computational time compared to state-of-the-artcollaborative representation based classification approaches. Experiments onbenchmark face, object and action databases show the efficacy of our approach.
arxiv-13800-120 | k-Nearest Neighbour Classification of Datasets with a Family of Distances | http://arxiv.org/pdf/1512.00001v1.pdf | author:Stan Hatko category:stat.ML cs.LG published:2015-11-29 summary:The $k$-nearest neighbour ($k$-NN) classifier is one of the oldest and mostimportant supervised learning algorithms for classifying datasets.Traditionally the Euclidean norm is used as the distance for the $k$-NNclassifier. In this thesis we investigate the use of alternative distances forthe $k$-NN classifier. We start by introducing some background notions in statistical machinelearning. We define the $k$-NN classifier and discuss Stone's theorem and theproof that $k$-NN is universally consistent on the normed space $R^d$. We thenprove that $k$-NN is universally consistent if we take a sequence of randomnorms (that are independent of the sample and the query) from a family of normsthat satisfies a particular boundedness condition. We extend this result byreplacing norms with distances based on uniformly locally Lipschitz functionsthat satisfy certain conditions. We discuss the limitations of Stone's lemmaand Stone's theorem, particularly with respect to quasinorms and adaptivelychoosing a distance for $k$-NN based on the labelled sample. We show theuniversal consistency of a two stage $k$-NN type classifier where we select thedistance adaptively based on a split labelled sample and the query. We concludeby giving some examples of improvements of the accuracy of classifying variousdatasets using the above techniques.
arxiv-13800-121 | Bootstrapping Ternary Relation Extractors | http://arxiv.org/pdf/1511.08952v1.pdf | author:Ndapandula Nakashole category:cs.CL cs.AI 68T50 published:2015-11-29 summary:Binary relation extraction methods have been widely studied in recent years.However, few methods have been developed for higher n-ary relation extraction.One limiting factor is the effort required to generate training data. Forbinary relations, one only has to provide a few dozen pairs of entities perrelation, as training data. For ternary relations (n=3), each training instanceis a triplet of entities, placing a greater cognitive load on people. Forexample, many people know that Google acquired Youtube but not the dollaramount or the date of the acquisition and many people know that Hillary Clintonis married to Bill Clinton by not the location or date of their wedding. Thismakes higher n-nary training data generation a time consuming exercise insearching the Web. We present a resource for training ternary relationextractors. This was generated using a minimally supervised yet effectiveapproach. We present statistics on the size and the quality of the dataset.
arxiv-13800-122 | MidRank: Learning to rank based on subsequences | http://arxiv.org/pdf/1511.08951v1.pdf | author:Basura Fernando, Efstratios Gavves, Damien Muselet, Tinne Tuytelaars category:cs.CV cs.LG published:2015-11-29 summary:We present a supervised learning to rank algorithm that effectively ordersimages by exploiting the structure in image sequences. Most often in thesupervised learning to rank literature, ranking is approached either byanalyzing pairs of images or by optimizing a list-wise surrogate loss functionon full sequences. In this work we propose MidRank, which learns frommoderately sized sub-sequences instead. These sub-sequences contain usefulstructural ranking information that leads to better learnability duringtraining and better generalization during testing. By exploiting sub-sequences,the proposed MidRank improves ranking accuracy considerably on an extensivearray of image ranking applications and datasets.
arxiv-13800-123 | Sliding-Window Optimization on an Ambiguity-Clearness Graph for Multi-object Tracking | http://arxiv.org/pdf/1511.08913v1.pdf | author:Qi Guo, Le Dan, Dong Yin, Xiangyang Ji category:cs.CV published:2015-11-28 summary:Multi-object tracking remains challenging due to frequent occurrence ofocclusions and outliers. In order to handle this problem, we propose anApproximation-Shrink Scheme for sequential optimization. This scheme isrealized by introducing an Ambiguity-Clearness Graph to avoid conflicts andmaintain sequence independent, as well as a sliding window optimizationframework to constrain the size of state space and guarantee convergence. Basedon this window-wise framework, the states of targets are clustered in aself-organizing manner. Moreover, we show that the traditional online and batchtracking methods can be embraced by the window-wise framework. Experimentsindicate that with only a small window, the optimization performance can bemuch better than online methods and approach to batch methods.
arxiv-13800-124 | On the Depth of Deep Neural Networks: A Theoretical View | http://arxiv.org/pdf/1506.05232v2.pdf | author:Shizhao Sun, Wei Chen, Liwei Wang, Xiaoguang Liu, Tie-Yan Liu category:cs.LG published:2015-06-17 summary:People believe that depth plays an important role in success of deep neuralnetworks (DNN). However, this belief lacks solid theoretical justifications asfar as we know. We investigate role of depth from perspective of margin bound.In margin bound, expected error is upper bounded by empirical margin error plusRademacher Average (RA) based capacity term. First, we derive an upper boundfor RA of DNN, and show that it increases with increasing depth. This indicatesnegative impact of depth on test performance. Second, we show that deepernetworks tend to have larger representation power (measured by Betti numbersbased complexity) than shallower networks in multi-class setting, and thus canlead to smaller empirical margin error. This implies positive impact of depth.The combination of these two results shows that for DNN with restricted numberof hidden units, increasing depth is not always good since there is a tradeoffbetween positive and negative impacts. These results inspire us to seekalternative ways to achieve positive impact of depth, e.g., imposingmargin-based penalty terms to cross entropy loss so as to reduce empiricalmargin error without increasing depth. Our experiments show that in this way,we achieve significantly better test performance.
arxiv-13800-125 | Applying deep learning to classify pornographic images and videos | http://arxiv.org/pdf/1511.08899v1.pdf | author:Mohamed Moustafa category:cs.CV cs.MM cs.NE published:2015-11-28 summary:It is no secret that pornographic material is now a one-click-away fromeveryone, including children and minors. General social media networks arestriving to isolate adult images and videos from normal ones. Intelligent imageanalysis methods can help to automatically detect and isolate questionableimages in media. Unfortunately, these methods require vast experience to designthe classifier including one or more of the popular computer vision featuredescriptors. We propose to build a classifier based on one of the recentlyflourishing deep learning techniques. Convolutional neural networks containmany layers for both automatic features extraction and classification. Thebenefit is an easier system to build (no need for hand-crafting features andclassifiers). Additionally, our experiments show that it is even more accuratethan the state of the art methods on the most recent benchmark dataset.
arxiv-13800-126 | Newton-Stein Method: An optimization method for GLMs via Stein's Lemma | http://arxiv.org/pdf/1511.08895v1.pdf | author:Murat A. Erdogdu category:stat.ML math.OC published:2015-11-28 summary:We consider the problem of efficiently computing the maximum likelihoodestimator in Generalized Linear Models (GLMs) when the number of observationsis much larger than the number of coefficients ($n \gg p \gg 1$). In thisregime, optimization algorithms can immensely benefit from approximate secondorder information. We propose an alternative way of constructing the curvatureinformation by formulating it as an estimation problem and applying aStein-type lemma, which allows further improvements through sub-sampling andeigenvalue thresholding. Our algorithm enjoys fast convergence rates,resembling that of second order methods, with modest per-iteration cost. Weprovide its convergence analysis for the general case where the rows of thedesign matrix are samples from a sub-gaussian distribution. We show that theconvergence has two phases, a quadratic phase followed by a linear phase.Finally, we empirically demonstrate that our algorithm achieves the highestperformance compared to various algorithms on several datasets.
arxiv-13800-127 | Quantification in-the-wild: data-sets and baselines | http://arxiv.org/pdf/1510.04811v2.pdf | author:Oscar Beijbom, Judy Hoffman, Evan Yao, Trevor Darrell, Alberto Rodriguez-Ramirez, Manuel Gonzalez-Rivero, Ove Hoegh - Guldberg category:cs.LG published:2015-10-16 summary:Quantification is the task of estimating the class-distribution of adata-set. While typically considered as a parameter estimation problem withstrict assumptions on the data-set shift, we consider quantificationin-the-wild, on two large scale data-sets from marine ecology: a survey ofCaribbean coral reefs, and a plankton time series from Martha's VineyardCoastal Observatory. We investigate several quantification methods from theliterature and indicate opportunities for future work. In particular, we showthat a deep neural network can be fine-tuned on a very limited amount of data(25 - 100 samples) to outperform alternative methods.
arxiv-13800-128 | Designing high-fidelity single-shot three-qubit gates: A machine learning approach | http://arxiv.org/pdf/1511.08862v1.pdf | author:Ehsan Zahedinejad, Joydip Ghosh, Barry C. Sanders category:quant-ph cs.LG published:2015-11-28 summary:Three-qubit quantum gates are crucial for quantum error correction andquantum information processing. We generate policies for quantum controlprocedures to design three types of three-qubit gates, namely Toffoli,Controlled-Not-Not and Fredkin gates. The design procedures are applicable toan architecture of nearest-neighbor-coupled superconducting artificial atoms.The resultant fidelity for each gate is above 99.9%, which is an acceptedthreshold fidelity for fault-tolerant quantum computing. We test our policy inthe presence of decoherence-induced noise as well as show its robustnessagainst random external noise generated by the control electronics. Thethree-qubit gates are designed via our machine learning algorithm calledSubspace-Selective Self-Adaptive Differential Evolution (SuSSADE).
arxiv-13800-129 | Is L2 a Good Loss Function for Neural Networks for Image Processing? | http://arxiv.org/pdf/1511.08861v1.pdf | author:Hang Zhao, Orazio Gallo, Iuri Frosio, Jan Kautz category:cs.CV published:2015-11-28 summary:Neural networks are becoming central in several areas of computer vision andimage processing. Different architectures have been proposed to solve specificproblems. The impact of the loss layer of neural networks, however, has notreceived much attention by the research community: the default and most commonchoice is L2. This can be particularly limiting in the context of imageprocessing, since L2 correlates poorly with perceived image quality. In this paper we bring attention to alternative choices. We study theperformance of several losses, including perceptually-motivated losses, andpropose a novel, differentiable error function. We show that the quality of theresults improves significantly with better loss functions, even for the samenetwork architecture.
arxiv-13800-130 | Generating ordered list of Recommended Items: a Hybrid Recommender System of Microblog | http://arxiv.org/pdf/1208.4147v3.pdf | author:Yingzhen Li, Ye Zhang category:cs.IR cs.LG cs.SI published:2012-08-21 summary:Precise recommendation of followers helps in improving the user experienceand maintaining the prosperity of twitter and microblog platforms. In thispaper, we design a hybrid recommender system of microblog as a solution of KDDCup 2012, track 1 task, which requires predicting users a user might follow inTencent Microblog. We describe the background of the problem and present thealgorithm consisting of keyword analysis, user taxonomy, (potential)interestsextraction and item recommendation. Experimental result shows the highperformance of our algorithm. Some possible improvements are discussed, whichleads to further study.
arxiv-13800-131 | Efficient Sum of Outer Products Dictionary Learning (SOUP-DIL) - The $\ell_0$ Method | http://arxiv.org/pdf/1511.08842v1.pdf | author:Saiprasad Ravishankar, Raj Rao Nadakuditi, Jeffrey A. Fessler category:cs.LG published:2015-11-27 summary:The sparsity of natural signals and images in a transform domain ordictionary has been extensively exploited in several applications such ascompression, denoising and inverse problems. More recently, data-drivenadaptation of synthesis dictionaries has shown promise in many applicationscompared to fixed or analytical dictionary models. However, dictionary learningproblems are typically non-convex and NP-hard, and the usual alternatingminimization approaches for these problems are often computationally expensive,with the computations dominated by the NP-hard synthesis sparse coding step. Inthis work, we investigate an efficient method for $\ell_{0}$ "norm"-baseddictionary learning by first approximating the training data set with a sum ofsparse rank-one matrices and then using a block coordinate descent approach toestimate the unknowns. The proposed block coordinate descent algorithm involvesefficient closed-form solutions. In particular, the sparse coding step involvesa simple form of thresholding. We provide a convergence analysis for theproposed block coordinate descent approach. Our numerical experiments show thepromising performance and significant speed-ups provided by our method over theclassical K-SVD scheme in sparse signal representation and image denoising.
arxiv-13800-132 | Multiagent Cooperation and Competition with Deep Reinforcement Learning | http://arxiv.org/pdf/1511.08779v1.pdf | author:Ardi Tampuu, Tambet Matiisen, Dorian Kodelja, Ilya Kuzovkin, Kristjan Korjus, Juhan Aru, Jaan Aru, Raul Vicente category:cs.AI cs.LG q-bio.NC published:2015-11-27 summary:Multiagent systems appear in most social, economical, and politicalsituations. In the present work we extend the Deep Q-Learning Networkarchitecture proposed by Google DeepMind to multiagent environments andinvestigate how two agents controlled by independent Deep Q-Networks interactin the classic videogame Pong. By manipulating the classical rewarding schemeof Pong we demonstrate how competitive and collaborative behaviors emerge.Competitive agents learn to play and score efficiently. Agents trained undercollaborative rewarding schemes find an optimal strategy to keep the ball inthe game as long as possible. We also describe the progression from competitiveto collaborative behavior. The present work demonstrates that Deep Q-Networkscan become a practical tool for studying the decentralized learning ofmultiagent systems living in highly complex environments.
arxiv-13800-133 | Gradient Estimation with Simultaneous Perturbation and Compressive Sensing | http://arxiv.org/pdf/1511.08768v1.pdf | author:Vivek S. Borkar, Vikranth R. Dwaracherla, Neeraja Sahasrabudhe category:stat.ML published:2015-11-27 summary:This paper aims at achieving a "good" estimator for the gradient of afunction on a high-dimensional space. Often such functions are not sensitive inall coordinates and the gradient of the function is almost sparse. We propose amethod for gradient estimation that combines ideas from Spall's SimultaneousPerturbation Stochastic Approximation with compressive sensing. The aim is toobtain \good" estimator without too many function evaluations. Application toestimating gradient outer product matrix as well as standard optimizationproblems are illustrated via simulations.
arxiv-13800-134 | Informative Data Projections: A Framework and Two Examples | http://arxiv.org/pdf/1511.08762v1.pdf | author:Tijl De Bie, Jefrey Lijffijt, Raul Santos-Rodriguez, Bo Kang category:cs.LG cs.IR math.ST stat.TH published:2015-11-27 summary:Methods for Projection Pursuit aim to facilitate the visual exploration ofhigh-dimensional data by identifying interesting low-dimensional projections. Amajor challenge is the design of a suitable quality metric of projections,commonly referred to as the projection index, to be maximized by the ProjectionPursuit algorithm. In this paper, we introduce a new information-theoreticstrategy for tackling this problem, based on quantifying the amount ofinformation the projection conveys to a user given their prior beliefs aboutthe data. The resulting projection index is a subjective quantity, explicitlydependent on the intended user. As a useful illustration, we developed thisidea for two particular kinds of prior beliefs. The first kind leads to PCA(Principal Component Analysis), shining new light on when PCA is (not)appropriate. The second kind leads to a novel projection index, themaximization of which can be regarded as a robust variant of PCA. We show howthis projection index, though non-convex, can be effectively maximized using amodified power method as well as using a semidefinite programming relaxation.The usefulness of this new projection index is demonstrated in comparativeempirical experiments against PCA and a popular Projection Pursuit method.
arxiv-13800-135 | Domain-Adversarial Training of Neural Networks | http://arxiv.org/pdf/1505.07818v3.pdf | author:Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FranÃ§ois Laviolette, Mario Marchand, Victor Lempitsky category:stat.ML cs.LG cs.NE published:2015-05-28 summary:We introduce a new representation learning approach for domain adaptation, inwhich data at training and test time come from similar but differentdistributions. Our approach is directlyinspired by the theory on domainadaptation suggesting that, for effective domain transfer to be achieved,predictions must be made based on features that cannot discriminate between thetraining (source) and test (target) domains. The approach implements this idea in the context of neural networkarchitectures that are trained on labeled data from the source domain andunlabeled data from the target domain (no labeled target-domain data isnecessary). As the training progresses, the approach promotes the emergence offeatures that are (i) discriminative for the main learning task on the sourcedomain and (ii) indiscriminate with respect to the shift between the domains.We show that this adaptation behaviour can be achieved in almost anyfeed-forward model by augmenting it with few standard layers and a new gradientreversal layer. The resulting augmented architecture can be trained usingstandard backpropagation and stochastic gradient descent, and can thus beimplemented with little effort using any of the deep learning packages. We demonstrate the success of our approach for two distinct classificationproblems (document sentiment analysis and image classification), wherestate-of-the-art domain adaptation performance on standard benchmarks isachieved. We also validate the approach for descriptor learning task in thecontext of person re-identification application.
arxiv-13800-136 | Algorithms for Differentially Private Multi-Armed Bandits | http://arxiv.org/pdf/1511.08681v1.pdf | author:Aristide Tossou, Christos Dimitrakakis category:stat.ML cs.CR cs.LG published:2015-11-27 summary:We present differentially private algorithms for the stochastic Multi-ArmedBandit (MAB) problem. This is a problem for applications such as adaptiveclinical trials, experiment design, and user-targeted advertising where privateinformation is connected to individual rewards. Our major contribution is toshow that there exist $(\epsilon, \delta)$ differentially private variants ofUpper Confidence Bound algorithms which have optimal regret, $O(\epsilon^{-1} +\log T)$. This is a significant improvement over previous results, which onlyachieve poly-log regret $O(\epsilon^{-2} \log^{2} T)$, because of our use of anovel interval-based mechanism. We also substantially improve the bounds ofprevious family of algorithms which use a continual release mechanism.Experiments clearly validate our theoretical bounds.
arxiv-13800-137 | Visual Learning of Arithmetic Operations | http://arxiv.org/pdf/1506.02264v2.pdf | author:Yedid Hoshen, Shmuel Peleg category:cs.LG cs.AI cs.CV published:2015-06-07 summary:A simple Neural Network model is presented for end-to-end visual learning ofarithmetic operations from pictures of numbers. The input consists of twopictures, each showing a 7-digit number. The output, also a picture, displaysthe number showing the result of an arithmetic operation (e.g., addition orsubtraction) on the two input numbers. The concepts of a number, or of anoperator, are not explicitly introduced. This indicates that addition is asimple cognitive task, which can be learned visually using a very small numberof neurons. Other operations, e.g., multiplication, were not learnable using thisarchitecture. Some tasks were not learnable end-to-end (e.g., addition withRoman numerals), but were easily learnable once broken into two separatesub-tasks: a perceptual \textit{Character Recognition} and cognitive\textit{Arithmetic} sub-tasks. This indicates that while some tasks may beeasily learnable end-to-end, other may need to be broken into sub-tasks.
arxiv-13800-138 | Shaping Proto-Value Functions via Rewards | http://arxiv.org/pdf/1511.08589v1.pdf | author:Chandrashekar Lakshmi Narayanan, Raj Kumar Maity, Shalabh Bhatnagar category:cs.AI cs.LG published:2015-11-27 summary:In this paper, we combine task-dependent reward shaping and task-independentproto-value functions to obtain reward dependent proto-value functions (RPVFs).In constructing the RPVFs we are making use of the immediate rewards which areavailable during the sampling phase but are not used in the PVF construction.We show via experiments that learning with an RPVF based representation isbetter than learning with just reward shaping or PVFs. In particular, when thestate space is symmetrical and the rewards are asymmetrical, the RPVF capturethe asymmetry better than the PVFs.
arxiv-13800-139 | Generalized Emphatic Temporal Difference Learning: Bias-Variance Analysis | http://arxiv.org/pdf/1509.05172v2.pdf | author:Assaf Hallak, Aviv Tamar, Remi Munos, Shie Mannor category:stat.ML cs.LG published:2015-09-17 summary:We consider the off-policy evaluation problem in Markov decision processeswith function approximation. We propose a generalization of the recentlyintroduced \emph{emphatic temporal differences} (ETD) algorithm\citep{SuttonMW15}, which encompasses the original ETD($\lambda$), as well asseveral other off-policy evaluation algorithms as special cases. We call thisframework \ETD, where our introduced parameter $\beta$ controls the decay rateof an importance-sampling term. We study conditions under which the projectedfixed-point equation underlying \ETD\ involves a contraction operator, allowingus to present the first asymptotic error bounds (bias) for \ETD. Our resultsshow that the original ETD algorithm always involves a contraction operator,and its bias is bounded. Moreover, by controlling $\beta$, our proposedgeneralization allows trading-off bias for variance reduction, therebyachieving a lower total error.
arxiv-13800-140 | Empirical Evaluation of Rectified Activations in Convolutional Network | http://arxiv.org/pdf/1505.00853v2.pdf | author:Bing Xu, Naiyan Wang, Tianqi Chen, Mu Li category:cs.LG cs.CV stat.ML published:2015-05-05 summary:In this paper we investigate the performance of different types of rectifiedactivation functions in convolutional neural network: standard rectified linearunit (ReLU), leaky rectified linear unit (Leaky ReLU), parametric rectifiedlinear unit (PReLU) and a new randomized leaky rectified linear units (RReLU).We evaluate these activation function on standard image classification task.Our experiments suggest that incorporating a non-zero slope for negative partin rectified activation units could consistently improve the results. Thus ourfindings are negative on the common belief that sparsity is the key of goodperformance in ReLU. Moreover, on small scale dataset, using deterministicnegative slope or learning it are both prone to overfitting. They are not aseffective as using their randomized counterpart. By using RReLU, we achieved75.68\% accuracy on CIFAR-100 test set without multiple test or ensemble.
arxiv-13800-141 | Simultaneous Private Learning of Multiple Concepts | http://arxiv.org/pdf/1511.08552v1.pdf | author:Mark Bun, Kobbi Nissim, Uri Stemmer category:cs.DS cs.CR cs.LG published:2015-11-27 summary:We investigate the direct-sum problem in the context of differentiallyprivate PAC learning: What is the sample complexity of solving $k$ learningtasks simultaneously under differential privacy, and how does this cost compareto that of solving $k$ learning tasks without privacy? In our setting, anindividual example consists of a domain element $x$ labeled by $k$ unknownconcepts $(c_1,\ldots,c_k)$. The goal of a multi-learner is to output $k$hypotheses $(h_1,\ldots,h_k)$ that generalize the input examples. Without concern for privacy, the sample complexity needed to simultaneouslylearn $k$ concepts is essentially the same as needed for learning a singleconcept. Under differential privacy, the basic strategy of learning eachhypothesis independently yields sample complexity that grows polynomially with$k$. For some concept classes, we give multi-learners that require fewersamples than the basic strategy. Unfortunately, however, we also give lowerbounds showing that even for very simple concept classes, the sample cost ofprivate multi-learning must grow polynomially in $k$.
arxiv-13800-142 | Quantitative Analysis of Particles Segregation | http://arxiv.org/pdf/1511.06106v2.pdf | author:Ting Peng, Aiping Qu, Xiaoling Wang category:cs.CV published:2015-11-19 summary:Segregation is a popular phenomenon. It has considerable effects on materialperformance. To the author's knowledge, there is still no automated objectivequantitative indicator for segregation. In order to full fill this task,segregation of particles is analyzed. Edges of the particles are extracted fromthe digital picture. Then, the whole picture of particles is splintered tosmall rectangles with the same shape. Statistical index of the edges in eachrectangle is calculated. Accordingly, segregation between the indexescorresponding to the rectangles is evaluated. The results show coincident withsubjective evaluated results. Further more, it can be implemented as anautomated system, which would facilitate the materials quality controlmechanism during production process.
arxiv-13800-143 | Structured learning of metric ensembles with application to person re-identification | http://arxiv.org/pdf/1511.08531v1.pdf | author:Sakrapee Paisitkriangkrai, Lin Wu, Chunhua Shen, Anton van den Hengel category:cs.CV published:2015-11-27 summary:Matching individuals across non-overlapping camera networks, known as personre-identification, is a fundamentally challenging problem due to the largevisual appearance changes caused by variations of viewpoints, lighting, andocclusion. Approaches in literature can be categoried into two streams: Thefirst stream is to develop reliable features against realistic conditions bycombining several visual features in a pre-defined way; the second stream is tolearn a metric from training data to ensure strong inter-class differences andintra-class similarities. However, seeking an optimal combination of visualfeatures which is generic yet adaptive to different benchmarks is a unsovedproblem, and metric learning models easily get over-fitted due to the scarcityof training data in person re-identification. In this paper, we propose twoeffective structured learning based approaches which explore the adaptiveeffects of visual features in recognizing persons in different benchmark datasets. Our framework is built on the basis of multiple low-level visual featureswith an optimal ensemble of their metrics. We formulate two optimizationalgorithms, CMCtriplet and CMCstruct, which directly optimize evaluationmeasures commonly used in person re-identification, also known as theCumulative Matching Characteristic (CMC) curve.
arxiv-13800-144 | TennisVid2Text: Fine-grained Descriptions for Domain Specific Videos | http://arxiv.org/pdf/1511.08522v1.pdf | author:Mohak Sukhwani, C. V. Jawahar category:cs.CV published:2015-11-26 summary:Automatically describing videos has ever been fascinating. In this work, weattempt to describe videos from a specific domain - broadcast videos of lawntennis matches. Given a video shot from a tennis match, we intend to generate atextual commentary similar to what a human expert would write on a sportswebsite. Unlike many recent works that focus on generating short captions, weare interested in generating semantically richer descriptions. This demands adetailed low-level analysis of the video content, specially the actions andinteractions among subjects. We address this by limiting our domain to the gameof lawn tennis. Rich descriptions are generated by leveraging a large corpus ofhuman created descriptions harvested from Internet. We evaluate our method on anewly created tennis video data set. Extensive analysis demonstrate that ourapproach addresses both semantic correctness as well as readability aspectsinvolved in the task.
arxiv-13800-145 | SceneNet: Understanding Real World Indoor Scenes With Synthetic Data | http://arxiv.org/pdf/1511.07041v2.pdf | author:Ankur Handa, Viorica Patraucean, Vijay Badrinarayanan, Simon Stent, Roberto Cipolla category:cs.CV published:2015-11-22 summary:Scene understanding is a prerequisite to many high level tasks for anyautomated intelligent machine operating in real world environments. Recentattempts with supervised learning have shown promise in this direction but alsohighlighted the need for enormous quantity of supervised data --- performanceincreases in proportion to the amount of data used. However, this quicklybecomes prohibitive when considering the manual labour needed to collect suchdata. In this work, we focus our attention on depth based semantic per-pixellabelling as a scene understanding problem and show the potential of computergraphics to generate virtually unlimited labelled data from synthetic 3Dscenes. By carefully synthesizing training data with appropriate noise modelswe show comparable performance to state-of-the-art RGBD systems on NYUv2dataset despite using only depth data as input and set a benchmark ondepth-based segmentation on SUN RGB-D dataset. Additionally, we offer a routeto generating synthesized frame or video data, and understanding of differentfactors influencing performance gains.
arxiv-13800-146 | Distributed Machine Learning via Sufficient Factor Broadcasting | http://arxiv.org/pdf/1511.08486v1.pdf | author:Pengtao Xie, Jin Kyu Kim, Yi Zhou, Qirong Ho, Abhimanu Kumar, Yaoliang Yu, Eric Xing category:cs.LG cs.DC published:2015-11-26 summary:Matrix-parametrized models, including multiclass logistic regression andsparse coding, are used in machine learning (ML) applications ranging fromcomputer vision to computational biology. When these models are applied tolarge-scale ML problems starting at millions of samples and tens of thousandsof classes, their parameter matrix can grow at an unexpected rate, resulting inhigh parameter synchronization costs that greatly slow down distributedlearning. To address this issue, we propose a Sufficient Factor Broadcasting(SFB) computation model for efficient distributed learning of a large family ofmatrix-parameterized models, which share the following property: the parameterupdate computed on each data sample is a rank-1 matrix, i.e., the outer productof two "sufficient factors" (SFs). By broadcasting the SFs among workermachines and reconstructing the update matrices locally at each worker, SFBimproves communication efficiency --- communication costs are linear in theparameter matrix's dimensions, rather than quadratic --- without affectingcomputational correctness. We present a theoretical convergence analysis ofSFB, and empirically corroborate its efficiency on four differentmatrix-parametrized ML models.
arxiv-13800-147 | An analysis of the factors affecting keypoint stability in scale-space | http://arxiv.org/pdf/1511.08478v1.pdf | author:Ives Rey-Otero, Jean-Michel Morel, Mauricio Delbracio category:cs.CV published:2015-11-26 summary:The most popular image matching algorithm SIFT, introduced by D. Lowe adecade ago, has proven to be sufficiently scale invariant to be used innumerous applications. In practice, however, scale invariance may be weakenedby various sources of error inherent to the SIFT implementation affecting thestability and accuracy of keypoint detection. The density of the sampling ofthe Gaussian scale-space and the level of blur in the input image are two ofthese sources. This article presents a numerical analysis of their impact onthe extracted keypoints stability. Such an analysis has both methodological andpractical implications, on how to compare feature detectors and on how toimprove SIFT. We show that even with a significantly oversampled scale-spacenumerical errors prevent from achieving perfect stability. Usual strategies tofilter out unstable detections are shown to be inefficient. We also prove thatthe effect of the error in the assumption on the initial blur is asymmetric andthat the method is strongly degraded in presence of aliasing or without acorrect assumption on the camera blur.
arxiv-13800-148 | Towards Automatic Image Editing: Learning to See another You | http://arxiv.org/pdf/1511.08446v1.pdf | author:Amir Ghodrati, Xu Jia, Marco Pedersoli, Tinne Tuytelaars category:cs.CV published:2015-11-26 summary:Learning the distribution of images in order to generate new samples is achallenging task due to the high dimensionality of the data and the highlynon-linear relations that are involved. Nevertheless, some promising resultshave been reported in the literature recently,building on deep networkarchitectures. In this work, we zoom in on a specific type of image generation:given an image and knowing the category of objects it belongs to (e.g. faces),our goal is to generate a similar and plausible image, but with some alteredattributes. This is particularly challenging, as the model needs to learn todisentangle the effect of each attribute and to apply a desired attributechange to a given input image, while keeping the other attributes and overallobject appearance intact. To this end, we learn a convolutional network, wherethe desired attribute information is encoded then merged with the encoded imageat feature map level. We show promising results, both qualitatively as well asquantitatively, in the context of a retrieval experiment, on two face datasets(MultiPie and CAS-PEAL-R1).
arxiv-13800-149 | TGSum: Build Tweet Guided Multi-Document Summarization Dataset | http://arxiv.org/pdf/1511.08417v1.pdf | author:Ziqiang Cao, Chengyao Chen, Wenjie Li, Sujian Li, Furu Wei, Ming Zhou category:cs.IR cs.CL published:2015-11-26 summary:The development of summarization research has been significantly hampered bythe costly acquisition of reference summaries. This paper proposes an effectiveway to automatically collect large scales of news-related multi-documentsummaries with reference to social media's reactions. We utilize two types ofsocial labels in tweets, i.e., hashtags and hyper-links. Hashtags are used tocluster documents into different topic sets. Also, a tweet with a hyper-linkoften highlights certain key points of the corresponding document. Wesynthesize a linked document cluster to form a reference summary which cancover most key points. To this aim, we adopt the ROUGE metrics to measure thecoverage ratio, and develop an Integer Linear Programming solution to discoverthe sentence set reaching the upper bound of ROUGE. Since we allow summarysentences to be selected from both documents and high-quality tweets, thegenerated reference summaries could be abstractive. Both informativeness andreadability of the collected summaries are verified by manual judgment. Inaddition, we train a Support Vector Regression summarizer on DUC genericmulti-document summarization benchmarks. With the collected data as extratraining resource, the performance of the summarizer improves a lot on all thetest sets. We release this dataset for further research.
arxiv-13800-150 | OntoSeg: a Novel Approach to Text Segmentation using Ontological Similarity | http://arxiv.org/pdf/1511.08411v1.pdf | author:Mostafa Bayomi, Killian Levacher, M. Rami Ghorab, SÃ©amus Lawless category:cs.CL published:2015-11-26 summary:Text segmentation (TS) aims at dividing long text into coherent segmentswhich reflect the subtopic structure of the text. It is beneficial to manynatural language processing tasks, such as Information Retrieval (IR) anddocument summarisation. Current approaches to text segmentation are similar inthat they all use word-frequency metrics to measure the similarity between tworegions of text, so that a document is segmented based on the lexical cohesionbetween its words. Various NLP tasks are now moving towards the semantic weband ontologies, such as ontology-based IR systems, to capture theconceptualizations associated with user needs and contents. Text segmentationbased on lexical cohesion between words is hence not sufficient anymore forsuch tasks. This paper proposes OntoSeg, a novel approach to text segmentationbased on the ontological similarity between text blocks. The proposed methoduses ontological similarity to explore conceptual relations between textsegments and a Hierarchical Agglomerative Clustering (HAC) algorithm torepresent the text as a tree-like hierarchy that is conceptually structured.The rich structure of the created tree further allows the segmentation of textin a linear fashion at various levels of granularity. The proposed method wasevaluated on a wellknown dataset, and the results show that using ontologicalsimilarity in text segmentation is very promising. Also we enhance the proposedmethod by combining ontological similarity with lexical similarity and theresults show an enhancement of the segmentation quality.
arxiv-13800-151 | Gains and Losses are Fundamentally Different in Regret Minimization: The Sparse Case | http://arxiv.org/pdf/1511.08405v1.pdf | author:Joon Kwon, Vianney Perchet category:cs.LG stat.ML published:2015-11-26 summary:We demonstrate that, in the classical non-stochastic regret minimizationproblem with $d$ decisions, gains and losses to be respectively maximized orminimized are fundamentally different. Indeed, by considering the additionalsparsity assumption (at each stage, at most $s$ decisions incur a nonzerooutcome), we derive optimal regret bounds of different orders. Specifically,with gains, we obtain an optimal regret guarantee after $T$ stages of order$\sqrt{T\log s}$, so the classical dependency in the dimension is replaced bythe sparsity size. With losses, we provide matching upper and lower bounds oforder $\sqrt{Ts\log(d)/d}$, which is decreasing in $d$. Eventually, we alsostudy the bandit setting, and obtain an upper bound of order $\sqrt{Ts\log(d/s)}$ when outcomes are losses. This bound is proven to be optimal up to thelogarithmic factor $\sqrt{\log(d/s)}$.
arxiv-13800-152 | QBDC: Query by dropout committee for training deep supervised architecture | http://arxiv.org/pdf/1511.06412v2.pdf | author:Melanie Ducoffe, Frederic Precioso category:cs.LG cs.CV published:2015-11-19 summary:While the current trend is to increase the depth of neural networks toincrease their performance, the size of their training database has to growaccordingly. We notice an emergence of tremendous databases, although providinglabels to build a training set still remains a very expensive task. We tacklethe problem of selecting the samples to be labelled in an online fashion. Inthis paper, we present an active learning strategy based on query by committeeand dropout technique to train a Convolutional Neural Network (CNN). We derivea commmittee of partial CNNs resulting from batchwise dropout runs on theinitial CNN. We evaluate our active learning strategy for CNN on MNISTbenchmark, showing in particular that selecting less than 30 % from theannotated database is enough to get similar error rate as using the fulltraining set on MNIST. We also studied the robustness of our method againstadversarial examples.
arxiv-13800-153 | On randomization of neural networks as a form of post-learning strategy | http://arxiv.org/pdf/1511.08366v1.pdf | author:K. G. Kapanova, I. Dimov, J. M. Sellier category:cs.NE published:2015-11-26 summary:Today artificial neural networks are applied in various fields - engineering,data analysis, robotics. While they represent a successful tool for a varietyof relevant applications, mathematically speaking they are still far from beingconclusive. In particular, they suffer from being unable to find the bestconfiguration possible during the training process (local minimum problem). Inthis paper, we focus on this issue and suggest a simple, but effective,post-learning strategy to allow the search for improved set of weights at arelatively small extra computational cost. Therefore, we introduce a noveltechnique based on analogy with quantum effects occurring in nature as a way toimprove (and sometimes overcome) this problem. Several numerical experimentsare presented to validate the approach.
arxiv-13800-154 | Reinforcement Learning with Parameterized Actions | http://arxiv.org/pdf/1509.01644v4.pdf | author:Warwick Masson, Pravesh Ranchod, George Konidaris category:cs.AI cs.LG published:2015-09-05 summary:We introduce a model-free algorithm for learning in Markov decision processeswith parameterized actions-discrete actions with continuous parameters. At eachstep the agent must select both which action to use and which parameters to usewith that action. We introduce the Q-PAMDP algorithm for learning in thesedomains, show that it converges to a local optimum, and compare it to directpolicy search in the goal-scoring and Platform domains.
arxiv-13800-155 | Random Forests for Big Data | http://arxiv.org/pdf/1511.08327v1.pdf | author:Robin Genuer, Jean-Michel Poggi, Christine Tuleau-Malot, Nathalie Villa-Vialaneix category:stat.ML cs.LG published:2015-11-26 summary:Big Data is one of the major challenges of statistical science and hasnumerous consequences from algorithmic and theoretical viewpoints. Big Dataalways involve massive data but they also often include data streams and dataheterogeneity. Recently some statistical methods have been adapted to processBig Data, like linear regression models, clustering methods and bootstrappingschemes. Based on decision trees combined with aggregation and bootstrap ideas,random forests were introduced by Breiman in 2001. They are a powerfulnonparametric statistical method allowing to consider in a single and versatileframework regression problems, as well as two-class and multi-classclassification problems. Focusing on classification problems, this paperreviews available proposals about random forests in parallel environments aswell as about online random forests. Then, we formulate various remarks forrandom forests in the Big Data context. Finally, we experiment three variantsinvolving subsampling, Big Data-bootstrap and MapReduce respectively, on twomassive datasets (15 and 120 millions of observations), a simulated one as wellas real world data.
arxiv-13800-156 | Deep Neural Network for Real-Time Autonomous Indoor Navigation | http://arxiv.org/pdf/1511.04668v2.pdf | author:Dong Ki Kim, Tsuhan Chen category:cs.CV published:2015-11-15 summary:Autonomous indoor navigation of Micro Aerial Vehicles (MAVs) possesses manychallenges. One main reason is that GPS has limited precision in indoorenvironments. The additional fact that MAVs are not able to carry heavy weightor power consuming sensors, such as range finders, makes indoor autonomousnavigation a challenging task. In this paper, we propose a practical system inwhich a quadcopter autonomously navigates indoors and finds a specific target,i.e., a book bag, by using a single camera. A deep learning model,Convolutional Neural Network (ConvNet), is used to learn a controller strategythat mimics an expert pilot's choice of action. We show our system'sperformance through real-time experiments in diverse indoor locations. Tounderstand more about our trained network, we use several visualizationtechniques.
arxiv-13800-157 | Hierarchical classification of e-commerce related social media | http://arxiv.org/pdf/1511.08299v1.pdf | author:Matthew Long, Aditya Jami, Ashutosh Saxena category:cs.SI cs.CL cs.IR cs.LG published:2015-11-26 summary:In this paper, we attempt to classify tweets into root categories of theAmazon browse node hierarchy using a set of tweets with browse node ID labels,a much larger set of tweets without labels, and a set of Amazon reviews.Examining twitter data presents unique challenges in that the samples are short(under 140 characters) and often contain misspellings or abbreviations that aretrivial for a human to decipher but difficult for a computer to parse. Avariety of query and document expansion techniques are implemented in an effortto improve information retrieval to modest success.
arxiv-13800-158 | A Deep Architecture for Semantic Matching with Multiple Positional Sentence Representations | http://arxiv.org/pdf/1511.08277v1.pdf | author:Shengxian Wan, Yanyan Lan, Jiafeng Guo, Jun Xu, Liang Pang, Xueqi Cheng category:cs.AI cs.CL cs.NE published:2015-11-26 summary:Matching natural language sentences is central for many applications such asinformation retrieval and question answering. Existing deep models rely on asingle sentence representation or multiple granularity representations formatching. However, such methods cannot well capture the contextualized localinformation in the matching process. To tackle this problem, we present a newdeep architecture to match two sentences with multiple positional sentencerepresentations. Specifically, each positional sentence representation is asentence representation at this position, generated by a bidirectional longshort term memory (Bi-LSTM). The matching score is finally produced byaggregating interactions between these different positional sentencerepresentations, through $k$-Max pooling and a multi-layer perceptron. Ourmodel has several advantages: (1) By using Bi-LSTM, rich context of the wholesentence is leveraged to capture the contextualized local information in eachpositional sentence representation; (2) By matching with multiple positionalsentence representations, it is flexible to aggregate different importantcontextualized local information in a sentence to support the matching; (3)Experiments on different tasks such as question answering and sentencecompletion demonstrate the superiority of our model.
arxiv-13800-159 | Fingerprint Recognition Using Translation Invariant Scattering Network | http://arxiv.org/pdf/1509.03542v3.pdf | author:Shervin Minaee, Yao Wang category:cs.CV published:2015-09-11 summary:Fingerprint recognition has drawn a lot of attention during last decades.Different features and algorithms have been used for fingerprint recognition inthe past. In this paper, a powerful image representation called scatteringtransform/network, is used for recognition. Scattering network is aconvolutional network where its architecture and filters are predefined wavelettransforms. The first layer of scattering representation is similar to siftdescriptors and the higher layers capture higher frequency content of thesignal. After extraction of scattering features, their dimensionality isreduced by applying principal component analysis (PCA). At the end, multi-classSVM is used to perform template matching for the recognition task. The proposedscheme is tested on a well-known fingerprint database and has shown promisingresults with the best accuracy rate of 98\%.
arxiv-13800-160 | Hierarchical Latent Semantic Mapping for Automated Topic Generation | http://arxiv.org/pdf/1511.03546v4.pdf | author:Guorui Zhou, Guang Chen category:cs.LG cs.CL cs.IR published:2015-11-11 summary:Much of information sits in an unprecedented amount of text data. Managingallocation of these large scale text data is an important problem for manyareas. Topic modeling performs well in this problem. The traditional generativemodels (PLSA,LDA) are the state-of-the-art approaches in topic modeling andmost recent research on topic generation has been focusing on improving orextending these models. However, results of traditional generative models aresensitive to the number of topics K, which must be specified manually. Theproblem of generating topics from corpus resembles community detection innetworks. Many effective algorithms can automatically detect communities fromnetworks without a manually specified number of the communities. Inspired bythese algorithms, in this paper, we propose a novel method named HierarchicalLatent Semantic Mapping (HLSM), which automatically generates topics fromcorpus. HLSM calculates the association between each pair of words in thelatent topic space, then constructs a unipartite network of words with thisassociation and hierarchically generates topics from this network. We applyHLSM to several document collections and the experimental comparisons againstseveral state-of-the-art approaches demonstrate the promising performance.
arxiv-13800-161 | On The Power of Joint Wavelet-DCT Features for Multispectral Palmprint Recognition | http://arxiv.org/pdf/1409.7818v2.pdf | author:Shervin Minaee, AmirAli Abdolrashidi category:cs.CV published:2014-09-27 summary:Biometric-based identification has drawn a lot of attention in the recentyears. Among all biometrics, palmprint is known to possess a rich set offeatures. In this paper we have proposed to use DCT-based features in parallelwith wavelet-based ones for palmprint identification. PCA is applied to thefeatures to reduce their dimensionality and the majority voting algorithm isused to perform classification. The features introduced here result in anear-perfectly accurate identification. This method is tested on a well-knownmultispectral palmprint database and an accuracy rate of 99.97-100\% isachieved, outperforming all previous methods in similar conditions.
arxiv-13800-162 | Learning Sparse High Dimensional Filters: Image Filtering, Dense CRFs and Bilateral Neural Networks | http://arxiv.org/pdf/1503.04949v3.pdf | author:Varun Jampani, Martin Kiefel, Peter V. Gehler category:cs.CV published:2015-03-17 summary:Bilateral filters have wide spread use due to their edge-preservingproperties. The common use case is to manually choose a parametric filter type,usually a Gaussian filter. In this paper, we will generalize theparametrization and in particular derive a gradient descent algorithm so thefilter parameters can be learned from data. This derivation allows to learnhigh dimensional linear filters that operate in sparsely populated featurespaces. We build on the permutohedral lattice construction for efficientfiltering. The ability to learn more general forms of high-dimensional filterscan be used in several diverse applications. First, we demonstrate the use inapplications where single filter applications are desired for runtime reasons.Further, we show how this algorithm can be used to learn the pairwisepotentials in densely connected conditional random fields and apply these todifferent image segmentation tasks. Finally, we introduce layers of bilateralfilters in CNNs and propose bilateral neural networks for the use ofhigh-dimensional sparse data. This view provides new ways to encode modelstructure into network architectures. A diverse set of experiments empiricallyvalidates the usage of general forms of filters.
arxiv-13800-163 | Multi-view Metric Learning for Multi-view Video Summarization | http://arxiv.org/pdf/1405.6434v2.pdf | author:Yanwei Fu, Lingbo Wang, Yanwen Guo category:cs.CV cs.LG cs.MM published:2014-05-25 summary:Traditional methods on video summarization are designed to generate summariesfor single-view video records; and thus they cannot fully exploit theredundancy in multi-view video records. In this paper, we present a multi-viewmetric learning framework for multi-view video summarization that combines theadvantages of maximum margin clustering with the disagreement minimizationcriterion. The learning framework thus has the ability to find a metric thatbest separates the data, and meanwhile to force the learned metric to maintainoriginal intrinsic information between data points, for example geometricinformation. Facilitated by such a framework, a systematic solution to themulti-view video summarization problem is developed. To the best of ourknowledge, it is the first time to address multi-view video summarization fromthe viewpoint of metric learning. The effectiveness of the proposed method isdemonstrated by experiments.
arxiv-13800-164 | Deep Kalman Filters | http://arxiv.org/pdf/1511.05121v2.pdf | author:Rahul G. Krishnan, Uri Shalit, David Sontag category:stat.ML cs.LG published:2015-11-16 summary:Kalman Filters are one of the most influential models of time-varyingphenomena. They admit an intuitive probabilistic interpretation, have a simplefunctional form, and enjoy widespread adoption in a variety of disciplines.Motivated by recent variational methods for learning deep generative models, weintroduce a unified algorithm to efficiently learn a broad spectrum of Kalmanfilters. Of particular interest is the use of temporal generative models forcounterfactual inference. We investigate the efficacy of such models forcounterfactual inference, and to that end we introduce the "Healing MNIST"dataset where long-term structure, noise and actions are applied to sequencesof digits. We show the efficacy of our method for modeling this dataset. Wefurther show how our model can be used for counterfactual inference forpatients, based on electronic health record data of 8,000 patients over 4.5years.
arxiv-13800-165 | Exploring Person Context and Local Scene Context for Object Detection | http://arxiv.org/pdf/1511.08177v1.pdf | author:Saurabh Gupta, Bharath Hariharan, Jitendra Malik category:cs.CV published:2015-11-25 summary:In this paper we explore two ways of using context for object detection. Thefirst model focusses on people and the objects they commonly interact with,such as fashion and sports accessories. The second model considers more generalobject detection and uses the spatial relationships between objects and betweenobjects and scenes. Our models are able to capture precise spatialrelationships between the context and the object of interest, and makeeffective use of the appearance of the contextual region. On the newly releasedCOCO dataset, our models provide relative improvements of up to 5% overCNN-based state-of-the-art detectors, with the gains concentrated on hard casessuch as small objects (10% relative improvement).
arxiv-13800-166 | First Step toward Model-Free, Anonymous Object Tracking with Recurrent Neural Networks | http://arxiv.org/pdf/1511.06425v2.pdf | author:Quan Gan, Qipeng Guo, Zheng Zhang, Kyunghyun Cho category:cs.CV cs.LG published:2015-11-19 summary:In this paper, we propose and study a novel visual object tracking approachbased on convolutional networks and recurrent networks. The proposed approachis distinct from the existing approaches to visual object tracking, such asfiltering-based ones and tracking-by-detection ones, in the sense that thetracking system is explicitly trained off-line to track anonymous objects in anoisy environment. The proposed visual tracking model is end-to-end trainable,minimizing any adversarial effect from mismatches in object representation andbetween the true underlying dynamics and learning dynamics. We empirically showthat the proposed tracking approach works well in various scenarios bygenerating artificial video sequences with varying conditions; the number ofobjects, amount of noise and the match between the training shapes and testshapes.
arxiv-13800-167 | Tracking Motion and Proxemics using Thermal-sensor Array | http://arxiv.org/pdf/1511.08166v1.pdf | author:Chandrayee Basu, Anthony Rowe category:cs.CV published:2015-11-25 summary:Indoor tracking has all-pervasive applications beyond mere surveillance, forexample in education, health monitoring, marketing, energy management and soon. Image and video based tracking systems are intrusive. Thermal array sensorson the other hand can provide coarse-grained tracking while preserving privacyof the subjects. The goal of the project is to facilitate motion detection andgroup proxemics modeling using an 8 x 8 infrared sensor array. Each of the 8 x8 pixels is a temperature reading in Fahrenheit. We refer to each 8 x 8 matrixas a scene. We collected approximately 902 scenes with different configurationsof human groups and different walking directions. We infer direction of motionof a subject across a set of scenes as left-to-right, right-to-left, up-to-downand down-to-up using cross-correlation analysis. We used features fromconnected component analysis of each background subtracted scene and performedSupport Vector Machine classification to estimate number of instances of humansubjects in the scene.
arxiv-13800-168 | Barrier Frank-Wolfe for Marginal Inference | http://arxiv.org/pdf/1511.02124v2.pdf | author:Rahul G. Krishnan, Simon Lacoste-Julien, David Sontag category:stat.ML cs.LG math.OC published:2015-11-06 summary:We introduce a globally-convergent algorithm for optimizing thetree-reweighted (TRW) variational objective over the marginal polytope. Thealgorithm is based on the conditional gradient method (Frank-Wolfe) and movespseudomarginals within the marginal polytope through repeated maximum aposteriori (MAP) calls. This modular structure enables us to leverage black-boxMAP solvers (both exact and approximate) for variational inference, and obtainsmore accurate results than tree-reweighted algorithms that optimize over thelocal consistency relaxation. Theoretically, we bound the sub-optimality forthe proposed algorithm despite the TRW objective having unbounded gradients atthe boundary of the marginal polytope. Empirically, we demonstrate theincreased quality of results found by tightening the relaxation over themarginal polytope as well as the spanning tree polytope on synthetic andreal-world instances.
arxiv-13800-169 | Unsupervised Deep Feature Extraction for Remote Sensing Image Classification | http://arxiv.org/pdf/1511.08131v1.pdf | author:Adriana Romero, Carlo Gatta, Gustau Camps-Valls category:cs.CV published:2015-11-25 summary:This paper introduces the use of single layer and deep convolutional networksfor remote sensing data analysis. Direct application to multi- andhyper-spectral imagery of supervised (shallow or deep) convolutional networksis very challenging given the high input data dimensionality and the relativelysmall amount of available labeled data. Therefore, we propose the use of greedylayer-wise unsupervised pre-training coupled with a highly efficient algorithmfor unsupervised learning of sparse features. The algorithm is rooted on sparserepresentations and enforces both population and lifetime sparsity of theextracted features, simultaneously. We successfully illustrate the expressivepower of the extracted representations in several scenarios: classification ofaerial scenes, as well as land-use classification in very high resolution(VHR), or land-cover classification from multi- and hyper-spectral images. Theproposed algorithm clearly outperforms standard Principal Component Analysis(PCA) and its kernel counterpart (kPCA), as well as current state-of-the-artalgorithms of aerial classification, while being extremely computationallyefficient at learning representations of data. Results show that single layerconvolutional networks can extract powerful discriminative features only whenthe receptive field accounts for neighboring pixels, and are preferred when theclassification requires high resolution and detailed results. However, deeparchitectures significantly outperform single layers variants, capturingincreasing levels of abstraction and complexity throughout the featurehierarchy.
arxiv-13800-170 | Foundations of Coupled Nonlinear Dimensionality Reduction | http://arxiv.org/pdf/1509.08880v2.pdf | author:Mehryar Mohri, Afshin Rostamizadeh, Dmitry Storcheus category:stat.ML cs.LG published:2015-09-29 summary:In this paper we introduce and analyze the learning scenario of \emph{couplednonlinear dimensionality reduction}, which combines two major steps of machinelearning pipeline: projection onto a manifold and subsequent supervisedlearning. First, we present new generalization bounds for this scenario and,second, we introduce an algorithm that follows from these bounds. Thegeneralization error bound is based on a careful analysis of the empiricalRademacher complexity of the relevant hypothesis set. In particular, we show anupper bound on the Rademacher complexity that is in $\widetildeO(\sqrt{\Lambda_{(r)}/m})$, where $m$ is the sample size and $\Lambda_{(r)}$the upper bound on the Ky-Fan $r$-norm of the associated kernel matrix. We giveboth upper and lower bound guarantees in terms of that Ky-Fan $r$-norm, whichstrongly justifies the definition of our hypothesis set. To the best of ourknowledge, these are the first learning guarantees for the problem of coupleddimensionality reduction. Our analysis and learning guarantees further apply toseveral special cases, such as that of using a fixed kernel with superviseddimensionality reduction or that of unsupervised learning of a kernel fordimensionality reduction followed by a supervised learning algorithm. Based ontheoretical analysis, we suggest a structural risk minimization algorithmconsisting of the coupled fitting of a low dimensional manifold and aseparation function on that manifold.
arxiv-13800-171 | Strategic Dialogue Management via Deep Reinforcement Learning | http://arxiv.org/pdf/1511.08099v1.pdf | author:Heriberto CuayÃ¡huitl, Simon Keizer, Oliver Lemon category:cs.AI cs.LG published:2015-11-25 summary:Artificially intelligent agents equipped with strategic skills that cannegotiate during their interactions with other natural or artificial agents arestill underdeveloped. This paper describes a successful application of DeepReinforcement Learning (DRL) for training intelligent agents with strategicconversational skills, in a situated dialogue setting. Previous studies havemodelled the behaviour of strategic agents using supervised learning andtraditional reinforcement learning techniques, the latter using tabularrepresentations or learning with linear function approximation. In this study,we apply DRL with a high-dimensional state space to the strategic board game ofSettlers of Catan---where players can offer resources in exchange for othersand they can also reply to offers made by other players. Our experimentalresults report that the DRL-based learnt policies significantly outperformedseveral baselines including random, rule-based, and supervised-basedbehaviours. The DRL-based policy has a 53% win rate versus 3 automated players(`bots'), whereas a supervised player trained on a dialogue corpus in thissetting achieved only 27%, versus the same 3 bots. This result supports theclaim that DRL is a promising framework for training dialogue systems, andstrategic agents with negotiation abilities.
arxiv-13800-172 | Relaxed Majorization-Minimization for Non-smooth and Non-convex Optimization | http://arxiv.org/pdf/1511.08062v1.pdf | author:Chen Xu, Zhouchen Lin, Zhenyu Zhao, Hongbin Zha category:math.OC cs.LG cs.NA published:2015-11-25 summary:We propose a new majorization-minimization (MM) method for non-smooth andnon-convex programs, which is general enough to include the existing MMmethods. Besides the local majorization condition, we only require that thedifference between the directional derivatives of the objective function andits surrogate function vanishes when the number of iterations approachesinfinity, which is a very weak condition. So our method can use a surrogatefunction that directly approximates the non-smooth objective function. Incomparison, all the existing MM methods construct the surrogate function byapproximating the smooth component of the objective function. We apply ourrelaxed MM methods to the robust matrix factorization (RMF) problem withdifferent regularizations, where our locally majorant algorithm showsadvantages over the state-of-the-art approaches for RMF. This is the firstalgorithm for RMF ensuring, without extra assumptions, that any limit point ofthe iterates is a stationary point.
arxiv-13800-173 | Pedestrian Detection Inspired by Appearance Constancy and Shape Symmetry | http://arxiv.org/pdf/1511.08058v1.pdf | author:Jiale Cao, Yanwei Pang, Xuelong Li category:cs.CV published:2015-11-25 summary:The discrimination and simplicity of features are very important foreffective and efficient pedestrian detection. However, most state-of-the-artmethods are unable to achieve good tradeoff between accuracy and efficiency.Inspired by some simple inherent attributes of pedestrians (i.e., appearanceconstancy and shape symmetry), we propose two new types of non-neighboringfeatures (NNF): side-inner difference features (SIDF) and symmetricalsimilarity features (SSF). SIDF can characterize the difference between thebackground and pedestrian and the difference between the pedestrian contour andits inner part. SSF can capture the symmetrical similarity of pedestrian shape.However, it's difficult for neighboring features to have such abovecharacterization abilities. Finally, we propose to combine both non-neighboringand neighboring features for pedestrian detection. It's found thatnon-neighboring features can further decrease the average miss rate by 4.44%.Experimental results on INRIA and Caltech pedestrian datasets demonstrate theeffectiveness and efficiency of the proposed method. Compared to thestate-of-the-art methods without using CNN, our method achieves the bestdetection performance on Caltech, outperforming the second best method (i.e.,Checkboards) by 1.63%.
arxiv-13800-174 | Learning to detect video events from zero or very few video examples | http://arxiv.org/pdf/1511.08032v1.pdf | author:Christos Tzelepis, Damianos Galanopoulos, Vasileios Mezaris, Ioannis Patras category:cs.LG cs.CV published:2015-11-25 summary:In this work we deal with the problem of high-level event detection in video.Specifically, we study the challenging problems of i) learning to detect videoevents from solely a textual description of the event, without using anypositive video examples, and ii) additionally exploiting very few positivetraining samples together with a small number of ``related'' videos. Forlearning only from an event's textual description, we first identify a generallearning framework and then study the impact of different design choices forvarious stages of this framework. For additionally learning from examplevideos, when true positive training samples are scarce, we employ an extensionof the Support Vector Machine that allows us to exploit ``related'' eventvideos by automatically introducing different weights for subsets of the videosin the overall training set. Experimental evaluations performed on thelarge-scale TRECVID MED 2014 video dataset provide insight on the effectivenessof the proposed methods.
arxiv-13800-175 | Fast and Simple PCA via Convex Optimization | http://arxiv.org/pdf/1509.05647v4.pdf | author:Dan Garber, Elad Hazan category:math.OC cs.LG cs.NA math.NA published:2015-09-18 summary:The problem of principle component analysis (PCA) is traditionally solved byspectral or algebraic methods. We show how computing the leading principalcomponent could be reduced to solving a \textit{small} number ofwell-conditioned {\it convex} optimization problems. This gives rise to a newefficient method for PCA based on recent advances in stochastic methods forconvex optimization. In particular we show that given a $d\times d$ matrix $\X =\frac{1}{n}\sum_{i=1}^n\x_i\x_i^{\top}$ with top eigenvector $\u$ and topeigenvalue $\lambda_1$ it is possible to: \begin{itemize} \item compute a unitvector $\w$ such that $(\w^{\top}\u)^2 \geq 1-\epsilon$ in$\tilde{O}\left({\frac{d}{\delta^2}+N}\right)$ time, where $\delta = \lambda_1- \lambda_2$ and $N$ is the total number of non-zero entries in$\x_1,...,\x_n$, \item compute a unit vector $\w$ such that $\w^{\top}\X\w \geq\lambda_1-\epsilon$ in $\tilde{O}(d/\epsilon^2)$ time. \end{itemize} To thebest of our knowledge, these bounds are the fastest to date for a wide regimeof parameters. These results could be further accelerated when $\delta$ (in thefirst case) and $\epsilon$ (in the second case) are smaller than $\sqrt{d/N}$.
arxiv-13800-176 | Cross Modal Distillation for Supervision Transfer | http://arxiv.org/pdf/1507.00448v2.pdf | author:Saurabh Gupta, Judy Hoffman, Jitendra Malik category:cs.CV published:2015-07-02 summary:In this work we propose a technique that transfers supervision between imagesfrom different modalities. We use learned representations from a large labeledmodality as a supervisory signal for training representations for a newunlabeled paired modality. Our method enables learning of rich representationsfor unlabeled modalities and can be used as a pre-training procedure for newmodalities with limited labeled data. We show experimental results where wetransfer supervision from labeled RGB images to unlabeled depth and opticalflow images and demonstrate large improvements for both these cross modalsupervision transfers. Code, data and pre-trained models are available athttps://github.com/s-gupta/fast-rcnn/tree/distillation
arxiv-13800-177 | A Short Survey on Data Clustering Algorithms | http://arxiv.org/pdf/1511.09123v1.pdf | author:Ka-Chun Wong category:cs.DS cs.CV cs.LG stat.CO stat.ML published:2015-11-25 summary:With rapidly increasing data, clustering algorithms are important tools fordata analytics in modern research. They have been successfully applied to awide range of domains; for instance, bioinformatics, speech recognition, andfinancial analysis. Formally speaking, given a set of data instances, aclustering algorithm is expected to divide the set of data instances into thesubsets which maximize the intra-subset similarity and inter-subsetdissimilarity, where a similarity measure is defined beforehand. In this work,the state-of-the-arts clustering algorithms are reviewed from design concept tomethodology; Different clustering paradigms are discussed. Advanced clusteringalgorithms are also discussed. After that, the existing clustering evaluationmetrics are reviewed. A summary with future insights is provided at the end.
arxiv-13800-178 | Calculate distance to object in the area where car, using video analysis | http://arxiv.org/pdf/1511.07963v1.pdf | author:Elena Legchekova, Oleg Titov category:cs.CV published:2015-11-25 summary:The method of using video cameras installed on the car, to calculate thedistance to the object in its area of movement.
arxiv-13800-179 | MOOCs Meet Measurement Theory: A Topic-Modelling Approach | http://arxiv.org/pdf/1511.07961v1.pdf | author:Jiazhen He, Benjamin I. P. Rubinstein, James Bailey, Rui Zhang, Sandra Milligan, Jeffrey Chan category:cs.LG cs.CY published:2015-11-25 summary:This paper adapts topic models to the psychometric testing of MOOC studentsbased on their online forum postings. Measurement theory from education andpsychology provides statistical models for quantifying a person's attainment ofintangible attributes such as attitudes, abilities or intelligence. Such modelsinfer latent skill levels by relating them to individuals' observed responseson a series of items such as quiz questions. The set of items can be used tomeasure a latent skill if individuals' responses on them conform to a Guttmanscale. Such well-scaled items differentiate between individuals and inferredlevels span the entire range from most basic to the advanced. In practice,education researchers manually devise items (quiz questions) while optimisingwell-scaled conformance. Due to the costly nature and expert requirements ofthis process, psychometric testing has found limited use in everyday teaching.We aim to develop usable measurement models for highly-instrumented MOOCdelivery platforms, by using participation in automatically-extracted onlineforum topics as items. The challenge is to formalise the Guttman scaleeducational constraint and incorporate it into topic models. To favour topicsthat automatically conform to a Guttman scale, we introduce a novelregularisation into non-negative matrix factorisation-based topic modelling. Wedemonstrate the suitability of our approach with both quantitative experimentson three Coursera MOOCs, and with a qualitative survey of topicinterpretability on two MOOCs by domain expert interviews.
arxiv-13800-180 | Exploring Correlation between Labels to improve Multi-Label Classification | http://arxiv.org/pdf/1511.07953v1.pdf | author:Amit Garg, Jonathan Noyola, Romil Verma, Ashutosh Saxena, Aditya Jami category:cs.LG cs.SI published:2015-11-25 summary:This paper attempts multi-label classification by extending the idea ofindependent binary classification models for each output label, and exploringhow the inherent correlation between output labels can be used to improvepredictions. Logistic Regression, Naive Bayes, Random Forest, and SVM modelswere constructed, with SVM giving the best results: an improvement of 12.9\%over binary models was achieved for hold out cross validation by augmentingwith pairwise correlation probabilities of the labels.
arxiv-13800-181 | PASCAL Boundaries: A Class-Agnostic Semantic Boundary Dataset | http://arxiv.org/pdf/1511.07951v1.pdf | author:Vittal Premachandran, Boyan Bonev, Alan L. Yuille category:cs.CV published:2015-11-25 summary:In this paper, we address the boundary detection task motivated by theambiguities in current definition of edge detection. To this end, we generate alarge database consisting of more than 10k images (which is 20x bigger thanexisting edge detection databases) along with ground truth boundaries between459 semantic classes including both foreground objects and different types ofbackground, and call it the PASCAL Boundaries dataset, which will be releasedto the community. In addition, we propose a novel deep network-basedmulti-scale semantic boundary detector and name it Multi-scale Deep SemanticBoundary Detector (M-DSBD). We provide baselines using models that were trainedon edge detection and show that they transfer reasonably to the task ofboundary detection. Finally, we point to various important research problemsthat this dataset can be used for.
arxiv-13800-182 | Learning Halfspaces and Neural Networks with Random Initialization | http://arxiv.org/pdf/1511.07948v1.pdf | author:Yuchen Zhang, Jason D. Lee, Martin J. Wainwright, Michael I. Jordan category:cs.LG published:2015-11-25 summary:We study non-convex empirical risk minimization for learning halfspaces andneural networks. For loss functions that are $L$-Lipschitz continuous, wepresent algorithms to learn halfspaces and multi-layer neural networks thatachieve arbitrarily small excess risk $\epsilon>0$. The time complexity ispolynomial in the input dimension $d$ and the sample size $n$, but exponentialin the quantity $(L/\epsilon^2)\log(L/\epsilon)$. These algorithms run multiplerounds of random initialization followed by arbitrary optimization steps. Wefurther show that if the data is separable by some neural network with constantmargin $\gamma>0$, then there is a polynomial-time algorithm for learning aneural network that separates the training data with margin $\Omega(\gamma)$.As a consequence, the algorithm achieves arbitrary generalization error$\epsilon>0$ with ${\rm poly}(d,1/\epsilon)$ sample and time complexity. Weestablish the same learnability result when the labels are randomly flippedwith probability $\eta<1/2$.
arxiv-13800-183 | Towards Biologically Plausible Deep Learning | http://arxiv.org/pdf/1502.04156v2.pdf | author:Yoshua Bengio, Dong-Hyun Lee, Jorg Bornschein, Zhouhan Lin category:cs.LG published:2015-02-14 summary:Neuroscientists have long criticised deep learning algorithms as incompatiblewith current knowledge of neurobiology. We explore more biologically plausibleversions of deep representation learning, focusing here mostly on unsupervisedlearning but developing a learning mechanism that could account for supervised,unsupervised and reinforcement learning. The starting point is that the basiclearning rule believed to govern synaptic weight updates(Spike-Timing-Dependent Plasticity) can be interpreted as gradient descent onsome objective function so long as the neuronal dynamics push firing ratestowards better values of the objective function (be it supervised,unsupervised, or reward-driven). The second main idea is that this correspondsto a form of the variational EM algorithm, i.e., with approximate rather thanexact posteriors, implemented by neural dynamics. Another contribution of thispaper is that the gradients required for updating the hidden states in theabove variational interpretation can be estimated using an approximation thatonly requires propagating activations forward and backward, with pairs oflayers learning to form a denoising auto-encoder. Finally, we extend the theoryabout the probabilistic interpretation of auto-encoders to justify improvedsampling schemes based on the generative interpretation of denoisingauto-encoders, and we validate all these ideas on generative learning tasks.
arxiv-13800-184 | Maximum Likelihood Estimation for Single Linkage Hierarchical Clustering | http://arxiv.org/pdf/1511.07944v1.pdf | author:Dekang Zhu, Dan P. Guralnik, Xuezhi Wang, Xiang Li, Bill Moran category:stat.ML published:2015-11-25 summary:We derive a statistical model for estimation of a dendrogram from singlelinkage hierarchical clustering (SLHC) that takes account of uncertaintythrough noise or corruption in the measurements of separation of data. Ourfocus is on just the estimation of the hierarchy of partitions afforded by thedendrogram, rather than the heights in the latter. The concept of estimatingthis "dendrogram structure'' is introduced, and an approximate maximumlikelihood estimator (MLE) for the dendrogram structure is described. Theseideas are illustrated by a simple Monte Carlo simulation that, at least forsmall data sets, suggests the method outperforms SLHC in the presence of noise.
arxiv-13800-185 | Video Tracking Using Learned Hierarchical Features | http://arxiv.org/pdf/1511.07940v1.pdf | author:Li Wang, Ting Liu, Gang Wang, Kap Luk Chan, Qingxiong Yang category:cs.CV published:2015-11-25 summary:In this paper, we propose an approach to learn hierarchical features forvisual object tracking. First, we offline learn features robust to diversemotion patterns from auxiliary video sequences. The hierarchical features arelearned via a two-layer convolutional neural network. Embedding the temporalslowness constraint in the stacked architecture makes the learned featuresrobust to complicated motion transformations, which is important for visualobject tracking. Then, given a target video sequence, we propose a domainadaptation module to online adapt the pre-learned features according to thespecific target object. The adaptation is conducted in both layers of the deepfeature learning module so as to include appearance information of the specifictarget object. As a result, the learned hierarchical features can be robust toboth complicated motion transformations and appearance changes of targetobjects. We integrate our feature learning algorithm into three trackingmethods. Experimental results demonstrate that significant improvement can beachieved using our learned hierarchical features, especially on video sequenceswith complicated motion transformations.
arxiv-13800-186 | Difference Target Propagation | http://arxiv.org/pdf/1412.7525v5.pdf | author:Dong-Hyun Lee, Saizheng Zhang, Asja Fischer, Yoshua Bengio category:cs.LG cs.NE published:2014-12-23 summary:Back-propagation has been the workhorse of recent successes of deep learningbut it relies on infinitesimal effects (partial derivatives) in order toperform credit assignment. This could become a serious issue as one considersdeeper and more non-linear functions, e.g., consider the extreme case ofnonlinearity where the relation between parameters and cost is actuallydiscrete. Inspired by the biological implausibility of back-propagation, a fewapproaches have been proposed in the past that could play a similar creditassignment role. In this spirit, we explore a novel approach to creditassignment in deep networks that we call target propagation. The main idea isto compute targets rather than gradients, at each layer. Like gradients, theyare propagated backwards. In a way that is related but different frompreviously proposed proxies for back-propagation which rely on a backwardsnetwork with symmetric weights, target propagation relies on auto-encoders ateach layer. Unlike back-propagation, it can be applied even when units exchangestochastic bits rather than real numbers. We show that a linear correction forthe imperfectness of the auto-encoders, called difference target propagation,is very effective to make target propagation actually work, leading to resultscomparable to back-propagation for deep networks with discrete and continuousunits and denoising auto-encoders and achieving state of the art for stochasticnetworks.
arxiv-13800-187 | Pose-Guided Human Parsing with Deep Learned Features | http://arxiv.org/pdf/1508.03881v2.pdf | author:Fangting Xia, Jun Zhu, Peng Wang, Alan Yuille category:cs.CV published:2015-08-17 summary:Parsing human body into semantic regions is crucial to human-centricanalysis. In this paper, we propose a segment-based parsing pipeline thatexplores human pose information, i.e. the joint location of a human model,which improves the part proposal, accelerates the inference and regularizes theparsing process at the same time. Specifically, we first generate part segmentproposals with respect to human joints predicted by a deep model, then part-specific ranking models are trained for segment selection using both pose-basedfeatures and deep-learned part potential features. Finally, the best ensembleof the proposed part segments are inferred though an And-Or Graph. We evaluate our approach on the popular Penn-Fudan pedestrian parsingdataset, and demonstrate the effectiveness of using the pose information foreach stage of the parsing pipeline. Finally, we show that our approach yieldssuperior part segmentation accuracy comparing to the state-of-the-art methods.
arxiv-13800-188 | Shape and Symmetry Induction for 3D Objects | http://arxiv.org/pdf/1511.07845v2.pdf | author:Shubham Tulsiani, Abhishek Kar, Qixing Huang, JoÃ£o Carreira, Jitendra Malik category:cs.CV published:2015-11-24 summary:Actions as simple as grasping an object or navigating around it require arich understanding of that object's 3D shape from a given viewpoint. In thispaper we repurpose powerful learning machinery, originally developed for objectclassification, to discover image cues relevant for recovering the 3D shape ofpotentially unfamiliar objects. We cast the problem as one of local predictionof surface normals and global detection of 3D reflection symmetry planes, whichopen the door for extrapolating occluded surfaces from visible ones. Wedemonstrate that our method is able to recover accurate 3D shape informationfor classes of objects it was not trained on, in both synthetic and realimages.
arxiv-13800-189 | Principal Basis Analysis in Sparse Representation | http://arxiv.org/pdf/1511.07927v1.pdf | author:Hong Sun, Cheng-Wei Sang, Chen-Guang Liu category:cs.CV published:2015-11-25 summary:This article introduces a new signal analysis method, which can beinterpreted as a principal component analysis in sparse decomposition of thesignal. The method, called principal basis analysis, is based on a novelcriterion: reproducibility of component which is an intrinsic characteristic ofregularity in natural signals. We show how to measure reproducibility. Then wepresent the principal basis analysis method, which chooses, in a sparserepresentation of the signal, the components optimizing the reproducibilitydegree to build the so-called principal basis. With this principal basis, weshow that the underlying signal pattern could be effectively extracted fromcorrupted data. As illustration, we apply the principal basis analysis to imagedenoising corrupted by Gaussian and non-Gaussian noises, showing betterperformances than some reference methods at suppressing strong noise and atpreserving signal details.
arxiv-13800-190 | Differentially Private Ordinary Least Squares: $t$-Values, Confidence Intervals and Rejecting Null-Hypotheses | http://arxiv.org/pdf/1507.02482v3.pdf | author:Or Sheffet category:cs.DS cs.CR cs.LG published:2015-07-09 summary:Linear regression is one of the most prevalent techniques in data analysis.Given a large collection of samples composed of features $\vec x$ and a label$y$, linear regression is used to find the best prediction of the label as alinear combination of the features. However, it is also common to use linearregression for its \emph{explanatory} capabilities rather than labelprediction. Ordinary Least Squares (OLS) is often used in statistics toestablish a correlation between an attribute (e.g. gender) and a label (e.g.income) in the presence of other features. Under the assumption of a certainrandom generative model for the data, OLS derives \emph{$t$-values} ---representing the likelihood of each real value to be the true correlation inthe underlying distribution. Using $t$-values, OLS can release a\emph{confidence interval} that is likely to contain the true correlation. Whenthis interval does not intersect the origin, we can \emph{reject the nullhypothesis} as it is likely that $x_j$ indeed has a non-zero correlation with$y$. Our work aims at achieving similar guarantees on data under differentiallyprivate estimators. We use the Gaussian Johnson-Lindenstrauss transform, whichhas been shown to satisfy differential privacy if the given data has largesingular values. We analyze the result of projecting the data using JLT underthe OLS model and derive approximated $t$-values, confidence intervals andbound the number of samples needed to reject the null hypothesis when the datais drawn i.i.d from a multivariate Gaussian. When not all singular values ofthe data are sufficiently large, we increase the singular values, thus ourprojected data yields an approximation for the Ridge Regression problem. Wederive, under certain conditions, confidence intervals in this case as well. Wealso derive confidence intervals for the "Analyze Gauss" algorithm of Dwork etal.
arxiv-13800-191 | Learning Depth from Single Monocular Images Using Deep Convolutional Neural Fields | http://arxiv.org/pdf/1502.07411v6.pdf | author:Fayao Liu, Chunhua Shen, Guosheng Lin, Ian Reid category:cs.CV published:2015-02-26 summary:In this article, we tackle the problem of depth estimation from singlemonocular images. Compared with depth estimation using multiple images such asstereo depth perception, depth from monocular images is much more challenging.Prior work typically focuses on exploiting geometric priors or additionalsources of information, most using hand-crafted features. Recently, there ismounting evidence that features from deep convolutional neural networks (CNN)set new records for various vision applications. On the other hand, consideringthe continuous characteristic of the depth values, depth estimations can benaturally formulated as a continuous conditional random field (CRF) learningproblem. Therefore, here we present a deep convolutional neural field model forestimating depths from single monocular images, aiming to jointly explore thecapacity of deep CNN and continuous CRF. In particular, we propose a deepstructured learning scheme which learns the unary and pairwise potentials ofcontinuous CRF in a unified deep CNN framework. We then further propose anequally effective model based on fully convolutional networks and a novelsuperpixel pooling method, which is $\sim 10$ times faster, to speedup thepatch-wise convolutions in the deep model. With this more efficient model, weare able to design deeper networks to pursue better performance. Experiments onboth indoor and outdoor scene datasets demonstrate that the proposed methodoutperforms state-of-the-art depth estimation approaches.
arxiv-13800-192 | Context-aware CNNs for person head detection | http://arxiv.org/pdf/1511.07917v1.pdf | author:Tuan-Hung Vu, Anton Osokin, Ivan Laptev category:cs.CV cs.LG published:2015-11-24 summary:Person detection is a key problem for many computer vision tasks. While facedetection has reached maturity, detecting people under a full variation ofcamera view-points, human poses, lighting conditions and occlusions is still adifficult challenge. In this work we focus on detecting human heads in naturalscenes. Starting from the recent local R-CNN object detector, we extend it withtwo types of contextual cues. First, we leverage person-scene relations andpropose a Global CNN model trained to predict positions and scales of headsdirectly from the full image. Second, we explicitly model pairwise relationsamong objects and train a Pairwise CNN model using a structured-outputsurrogate loss. The Local, Global and Pairwise models are combined into a jointCNN framework. To train and test our full model, we introduce a large datasetcomposed of 369,846 human heads annotated in 224,740 movie frames. We evaluateour method and demonstrate improvements of person head detection againstseveral recent baselines in three datasets. We also show improvements of thedetection speed provided by our model.
arxiv-13800-193 | Natural Language Understanding with Distributed Representation | http://arxiv.org/pdf/1511.07916v1.pdf | author:Kyunghyun Cho category:cs.CL stat.ML published:2015-11-24 summary:This is a lecture note for the course DS-GA 3001 <Natural LanguageUnderstanding with Distributed Representation> at the Center for Data Science ,New York University in Fall, 2015. As the name of the course suggests, thislecture note introduces readers to a neural network based approach to naturallanguage understanding/processing. In order to make it as self-contained aspossible, I spend much time on describing basics of machine learning and neuralnetworks, only after which how they are used for natural languages isintroduced. On the language front, I almost solely focus on language modellingand machine translation, two of which I personally find most fascinating andmost fundamental to natural language understanding.
arxiv-13800-194 | Private Posterior distributions from Variational approximations | http://arxiv.org/pdf/1511.07896v1.pdf | author:Vishesh Karwa, Dan Kifer, Aleksandra B. SlavkoviÄ category:stat.ML cs.CR cs.LG published:2015-11-24 summary:Privacy preserving mechanisms such as differential privacy inject additionalrandomness in the form of noise in the data, beyond the sampling mechanism.Ignoring this additional noise can lead to inaccurate and invalid inferences.In this paper, we incorporate the privacy mechanism explicitly into thelikelihood function by treating the original data as missing, with an end goalof estimating posterior distributions over model parameters. This leads to aprincipled way of performing valid statistical inference using private data,however, the corresponding likelihoods are intractable. In this paper, wederive fast and accurate variational approximations to tackle such intractablelikelihoods that arise due to privacy. We focus on estimating posteriordistributions of parameters of the naive Bayes log-linear model, where thesufficient statistics of this model are shared using a differentially privateinterface. Using a simulation study, we show that the posterior approximationsoutperform the naive method of ignoring the noise addition mechanism.
arxiv-13800-195 | Compact CNN for Indexing Egocentric Videos | http://arxiv.org/pdf/1504.07469v2.pdf | author:Yair Poleg, Ariel Ephrat, Shmuel Peleg, Chetan Arora category:cs.CV published:2015-04-28 summary:While egocentric video is becoming increasingly popular, browsing it is verydifficult. In this paper we present a compact 3D Convolutional Neural Network(CNN) architecture for long-term activity recognition in egocentric videos.Recognizing long-term activities enables us to temporally segment (index) longand unstructured egocentric videos. Existing methods for this task are based onhand tuned features derived from visible objects, location of hands, as well asoptical flow. Given a sparse optical flow volume as input, our CNN classifies the camerawearer's activity. We obtain classification accuracy of 89%, which outperformsthe current state-of-the-art by 19%. Additional evaluation is performed on anextended egocentric video dataset, classifying twice the amount of categoriesthan current state-of-the-art. Furthermore, our CNN is able to recognizewhether a video is egocentric or not with 99.2% accuracy, up by 24% fromcurrent state-of-the-art. To better understand what the network actuallylearns, we propose a novel visualization of CNN kernels as flow fields.
arxiv-13800-196 | Super-Linear Gate and Super-Quadratic Wire Lower Bounds for Depth-Two and Depth-Three Threshold Circuits | http://arxiv.org/pdf/1511.07860v1.pdf | author:Daniel M. Kane, Ryan Williams category:cs.CC cs.NE 68Q17 C.1.3; F.1.3 published:2015-11-24 summary:In order to formally understand the power of neural computing, we first needto crack the frontier of threshold circuits with two and three layers, a regimethat has been surprisingly intractable to analyze. We prove the firstsuper-linear gate lower bounds and the first super-quadratic wire lower boundsfor depth-two linear threshold circuits with arbitrary weights, and depth-threemajority circuits computing an explicit function. $\bullet$ We prove that for all $\epsilon\gg \sqrt{\log(n)/n}$, thelinear-time computable Andreev's function cannot be computed on a$(1/2+\epsilon)$-fraction of $n$-bit inputs by depth-two linear thresholdcircuits of $o(\epsilon^3 n^{3/2}/\log^3 n)$ gates, nor can it be computed with$o(\epsilon^{3} n^{5/2}/\log^{7/2} n)$ wires. This establishes an average-case``size hierarchy'' for threshold circuits, as Andreev's function is computableby uniform depth-two circuits of $o(n^3)$ linear threshold gates, and byuniform depth-three circuits of $O(n)$ majority gates. $\bullet$ We present a new function in $P$ based on small-biased sets, whichwe prove cannot be computed by a majority vote of depth-two linear thresholdcircuits with $o(n^{3/2}/\log^3 n)$ gates, nor with $o(n^{5/2}/\log^{7/2}n)$wires. $\bullet$ We give tight average-case (gate and wire) complexity results forcomputing PARITY with depth-two threshold circuits; the answer turns out to bethe same as for depth-two majority circuits. The key is a new random restriction lemma for linear threshold functions. Ourmain analytical tool is the Littlewood-Offord Lemma from additivecombinatorics.
arxiv-13800-197 | Evolution of swarming behavior is shaped by how predators attack | http://arxiv.org/pdf/1310.6012v2.pdf | author:Randal S. Olson, David B. Knoester, Christoph Adami category:q-bio.PE cs.NE published:2013-10-22 summary:Animal grouping behaviors have been widely studied due to their implicationsfor understanding social intelligence, collective cognition, and potentialapplications in engineering, artificial intelligence, and robotics. Animportant biological aspect of these studies is discerning which selectionpressures favor the evolution of grouping behavior. In the past decade,researchers have begun using evolutionary computation to study the evolutionaryeffects of these selection pressures in predator-prey models. The selfish herdhypothesis states that concentrated groups arise because prey selfishly attemptto place their conspecifics between themselves and the predator, thus causingan endless cycle of movement toward the center of the group. Using anevolutionary model of a predator-prey system, we show that how predators attackis critical to the evolution of the selfish herd. Following this discovery, weshow that density-dependent predation provides an abstraction of Hamilton'soriginal formulation of ``domains of danger.'' Finally, we verify thatdensity-dependent predation provides a sufficient selective advantage for preyto evolve the selfish herd in response to predation by coevolving predators.Thus, our work corroborates Hamilton's selfish herd hypothesis in a digitalevolutionary model, refines the assumptions of the selfish herd hypothesis, andgeneralizes the domain of danger concept to density-dependent predation.
arxiv-13800-198 | End-To-End Memory Networks | http://arxiv.org/pdf/1503.08895v5.pdf | author:Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus category:cs.NE cs.CL published:2015-03-31 summary:We introduce a neural network with a recurrent attention model over apossibly large external memory. The architecture is a form of Memory Network(Weston et al., 2015) but unlike the model in that work, it is trainedend-to-end, and hence requires significantly less supervision during training,making it more generally applicable in realistic settings. It can also be seenas an extension of RNNsearch to the case where multiple computational steps(hops) are performed per output symbol. The flexibility of the model allows usto apply it to tasks as diverse as (synthetic) question answering and tolanguage modeling. For the former our approach is competitive with MemoryNetworks, but with less supervision. For the latter, on the Penn TreeBank andText8 datasets our approach demonstrates comparable performance to RNNs andLSTMs. In both cases we show that the key concept of multiple computationalhops yields improved results.
arxiv-13800-199 | A CMOS Spiking Neuron for Brain-Inspired Neural Networks with Resistive Synapses and In-Situ Learning | http://arxiv.org/pdf/1505.07814v2.pdf | author:Xinyu Wu, Vishal Saxena, Kehan Zhu, Sakkarapani Balagopal category:cs.NE published:2015-05-28 summary:Nanoscale resistive memories are expected to fuel dense integration ofelectronic synapses for large-scale neuromorphic system. To realize such abrain-inspired computing chip, a compact CMOS spiking neuron that performsin-situ learning and computing while driving a large number of resistivesynapses is desired. This work presents a novel leaky integrate-and-fire neurondesign which implements the dual-mode operation of current integration andsynaptic drive, with a single opamp and enables in-situ learning with crossbarresistive synapses. The proposed design was implemented in a 0.18 $\mu$m CMOStechnology. Measurements show neuron's ability to drive a thousand resistivesynapses, and demonstrate an in-situ associative learning. The neuron circuitoccupies a small area of 0.01 mm$^2$ and has an energy-efficiency of 9.3pJ$/$spike$/$synapse.
arxiv-13800-200 | Schatten-$p$ Quasi-Norm Regularized Matrix Optimization via Iterative Reweighted Singular Value Minimization | http://arxiv.org/pdf/1401.0869v2.pdf | author:Zhaosong Lu, Yong Zhang category:math.OC cs.LG math.NA stat.CO stat.ML published:2014-01-05 summary:In this paper we study general Schatten-$p$ quasi-norm (SPQN) regularizedmatrix minimization problems. In particular, we first introduce a class offirst-order stationary points for them, and show that the first-orderstationary points introduced in [11] for an SPQN regularized $vector$minimization problem are equivalent to those of an SPQN regularized $matrix$minimization reformulation. We also show that any local minimizer of the SPQNregularized matrix minimization problems must be a first-order stationarypoint. Moreover, we derive lower bounds for nonzero singular values of thefirst-order stationary points and hence also of the local minimizers of theSPQN regularized matrix minimization problems. The iterative reweightedsingular value minimization (IRSVM) methods are then proposed to solve theseproblems, whose subproblems are shown to have a closed-form solution. Incontrast to the analogous methods for the SPQN regularized $vector$minimization problems, the convergence analysis of these methods issignificantly more challenging. We develop a novel approach to establishing theconvergence of these methods, which makes use of the expression of a specificsolution of their subproblems and avoids the intricate issue of finding theexplicit expression for the Clarke subdifferential of the objective of theirsubproblems. In particular, we show that any accumulation point of the sequencegenerated by the IRSVM methods is a first-order stationary point of theproblems. Our computational results demonstrate that the IRSVM methodsgenerally outperform some recently developed state-of-the-art methods in termsof solution quality and/or speed.
arxiv-13800-201 | Do Multi-Sense Embeddings Improve Natural Language Understanding? | http://arxiv.org/pdf/1506.01070v3.pdf | author:Jiwei Li, Dan Jurafsky category:cs.CL published:2015-06-02 summary:Learning a distinct representation for each sense of an ambiguous word couldlead to more powerful and fine-grained models of vector-space representations.Yet while `multi-sense' methods have been proposed and tested on artificialword-similarity tasks, we don't know if they improve real natural languageunderstanding tasks. In this paper we introduce a multi-sense embedding modelbased on Chinese Restaurant Processes that achieves state of the artperformance on matching human word similarity judgments, and propose apipelined architecture for incorporating multi-sense embeddings into languageunderstanding. We then test the performance of our model on part-of-speech tagging, namedentity recognition, sentiment analysis, semantic relation identification andsemantic relatedness, controlling for embedding dimensionality. We find thatmulti-sense embeddings do improve performance on some tasks (part-of-speechtagging, semantic relation identification, semantic relatedness) but not onothers (named entity recognition, various forms of sentiment analysis). Wediscuss how these differences may be caused by the different role of word senseinformation in each of the tasks. The results highlight the importance oftesting embedding models in real applications.
arxiv-13800-202 | Alternative structures for character-level RNNs | http://arxiv.org/pdf/1511.06303v2.pdf | author:Piotr Bojanowski, Armand Joulin, Tomas Mikolov category:cs.LG cs.CL published:2015-11-19 summary:Recurrent neural networks are convenient and efficient models for languagemodeling. However, when applied on the level of characters instead of words,they suffer from several problems. In order to successfully model long-termdependencies, the hidden representation needs to be large. This in turn implieshigher computational costs, which can become prohibitive in practice. Wepropose two alternative structural modifications to the classical RNN model.The first one consists on conditioning the character level representation onthe previous word representation. The other one uses the character history tocondition the output probability. We evaluate the performance of the twoproposed modifications on challenging, multi-lingual real world data.
arxiv-13800-203 | Weakly Supervised Object Boundaries | http://arxiv.org/pdf/1511.07803v1.pdf | author:Anna Khoreva, Rodrigo Benenson, Mohamed Omran, Matthias Hein, Bernt Schiele category:cs.CV published:2015-11-24 summary:State-of-the-art learning based boundary detection methods require extensivetraining data. Since labelling object boundaries is one of the most expensivetypes of annotations, there is a need to relax the requirement to carefullyannotate images to make both the training more affordable and to extend theamount of training data. In this paper we propose a technique to generateweakly supervised annotations and show that bounding box annotations alonesuffice to reach high-quality object boundaries without using anyobject-specific boundary annotations. With the proposed weak supervisiontechniques we achieve the top performance on the object boundary detectiontask, outperforming by a large margin the current fully supervisedstate-of-the-art methods.
arxiv-13800-204 | Spoken Language Translation for Polish | http://arxiv.org/pdf/1511.07788v1.pdf | author:Krzysztof Marasek, Åukasz Brocki, Danijel Korzinek, Krzysztof WoÅk, Ryszard Gubrynowicz category:cs.CL published:2015-11-24 summary:Spoken language translation (SLT) is becoming more important in theincreasingly globalized world, both from a social and economic point of view.It is one of the major challenges for automatic speech recognition (ASR) andmachine translation (MT), driving intense research activities in these areas.While past research in SLT, due to technology limitations, dealt mostly withspeech recorded under controlled conditions, today's major challenge is thetranslation of spoken language as it can be found in real life. Consideredapplication scenarios range from portable translators for tourists, lecturesand presentations translation, to broadcast news and shows with livecaptioning. We would like to present PJIIT's experiences in the SLT gained fromthe Eu-Bridge 7th framework project and the U-Star consortium activities forthe Polish/English language pair. Presented research concentrates on ASRadaptation for Polish (state-of-the-art acoustic models: DBN-BLSTM training,Kaldi: LDA+MLLT+SAT+MMI), language modeling for ASR & MT (text normalization,RNN-based LMs, n-gram model domain interpolation) and statistical translationtechniques (hierarchical models, factored translation models, automatic casingand punctuation, comparable and bilingual corpora preparation). While resultsfor the well-defined domains (phrases for travelers, parliament speeches,medical documentation, movie subtitling) are very encouraging, less defineddomains (presentation, lectures) still form a challenge. Our progress in theIWSLT TED task (MT only) will be presented, as well as current progress in thePolish ASR.
arxiv-13800-205 | Rendering refraction and reflection of eyeglasses for synthetic eye tracker images | http://arxiv.org/pdf/1511.07299v2.pdf | author:Thomas C. KÃ¼bler, Tobias Rittig, Judith Ungewiss, Christina Krauss, Enkelejda Kasneci category:cs.CV published:2015-11-23 summary:While for the evaluation of robustness of eye tracking algorithms the use ofreal-world data is essential, there are many applications where simulated,synthetic eye images are of advantage. They can generate labelled ground-truthdata for appearance based gaze estimation algorithms or enable the developmentof model based gaze estimation techniques by showing the influence on gazeestimation error of different model factors that can then be simplified orextended. We extend the generation of synthetic eye images by a simulation ofrefraction and reflection for eyeglasses. On the one hand this allows for thetesting of pupil and glint detection algorithms under different illuminationand reflection conditions, on the other hand the error of gaze estimationroutines can be estimated in conjunction with different eyeglasses. We show howa polynomial function fitting calibration performs equally well with andwithout eyeglasses, and how a geometrical eye model behaves when exposed toglasses.
arxiv-13800-206 | Bayesian Identification of Fixations, Saccades, and Smooth Pursuits | http://arxiv.org/pdf/1511.07732v1.pdf | author:Thiago Santini, Wolfgang Fuhl, Thomas KÃ¼bler, Enkelejda Kasneci category:cs.CV published:2015-11-24 summary:Smooth pursuit eye movements provide meaningful insights and information onsubject's behavior and health and may, in particular situations, disturb theperformance of typical fixation/saccade classification algorithms. Thus, anautomatic and efficient algorithm to identify these eye movements is paramountfor eye-tracking research involving dynamic stimuli. In this paper, we proposethe Bayesian Decision Theory Identification (I-BDT) algorithm, a novelalgorithm for ternary classification of eye movements that is able to reliablyseparate fixations, saccades, and smooth pursuits in an online fashion, evenfor low-resolution eye trackers. The proposed algorithm is evaluated on fourdatasets with distinct mixtures of eye movements, including fixations,saccades, as well as straight and circular smooth pursuits; data was collectedwith a sample rate of 30 Hz from six subjects, totaling 24 evaluation datasets.The algorithm exhibits high and consistent performance across all datasets andmovements relative to a manual annotation by a domain expert (recall: \mu =91.42%, \sigma = 9.52%; precision: \mu = 95.60%, \sigma = 5.29%; specificity\mu = 95.41%, \sigma = 7.02%) and displays a significant improvement whencompared to I-VDT, an state-of-the-art algorithm (recall: \mu = 87.67%, \sigma= 14.73%; precision: \mu = 89.57%, \sigma = 8.05%; specificity \mu = 92.10%,\sigma = 11.21%). For algorithm implementation and annotated datasets, pleasecontact the first author.
arxiv-13800-207 | Deep Learning for Semantic Part Segmentation with High-Level Guidance | http://arxiv.org/pdf/1505.02438v2.pdf | author:S. Tsogkas, I. Kokkinos, G. Papandreou, A. Vedaldi category:cs.CV published:2015-05-10 summary:In this work we address the task of segmenting an object into its parts, orsemantic part segmentation. We start by adapting a state-of-the-art semanticsegmentation system to this task, and show that a combination of afully-convolutional Deep CNN system coupled with Dense CRF labelling providesexcellent results for a broad range of object categories. Still, this approachremains agnostic to high-level constraints between object parts. We introducesuch prior information by means of the Restricted Boltzmann Machine, adapted toour task and train our model in an discriminative fashion, as a hidden CRF,demonstrating that prior information can yield additional improvements. We alsoinvestigate the performance of our approach ``in the wild'', withoutinformation concerning the objects' bounding boxes, using an object detector toguide a multi-scale segmentation scheme. We evaluate the performance of ourapproach on the Penn-Fudan and LFW datasets for the tasks of pedestrian parsingand face labelling respectively. We show superior performance with respect tocompetitive methods that have been extensively engineered on these benchmarks,as well as realistic qualitative results on part segmentation, even foroccluded or deformable objects. We also provide quantitative and extensivequalitative results on three classes from the PASCAL Parts dataset. Finally, weshow that our multi-scale segmentation scheme can boost accuracy, recoveringsegmentations for finer parts.
arxiv-13800-208 | Camera Calibration from Dynamic Silhouettes Using Motion Barcodes | http://arxiv.org/pdf/1506.07866v3.pdf | author:Gil Ben-Artzi, Yoni Kasten, Shmuel Peleg, Michael Werman category:cs.CV published:2015-06-25 summary:Computing the epipolar geometry between cameras with very differentviewpoints is often problematic as matching points are hard to find. In thesecases, it has been proposed to use information from dynamic objects in thescene for suggesting point and line correspondences. We propose a speed up of about two orders of magnitude, as well as anincrease in robustness and accuracy, to methods computing epipolar geometryfrom dynamic silhouettes. This improvement is based on a new temporalsignature: motion barcode for lines. Motion barcode is a binary temporalsequence for lines, indicating for each frame the existence of at least oneforeground pixel on that line. The motion barcodes of two correspondingepipolar lines are very similar, so the search for corresponding epipolar linescan be limited only to lines having similar barcodes. The use of motionbarcodes leads to increased speed, accuracy, and robustness in computing theepipolar geometry.
arxiv-13800-209 | Statistical Properties of the Single Linkage Hierarchical Clustering Estimator | http://arxiv.org/pdf/1511.07715v1.pdf | author:Dekang Zhu, Dan P. Guralnik, Xuezhi Wang, Xiang Li, Bill Moran category:stat.ML published:2015-11-24 summary:Distance-based hierarchical clustering (HC) methods are widely used inunsupervised data analysis but few authors take account of uncertainty in thedistance data. We incorporate a statistical model of the uncertainty throughcorruption or noise in the pairwise distances and investigate the problem ofestimating the HC as unknown parameters from measurements. Specifically, wefocus on single linkage hierarchical clustering (SLHC) and study its geometry.We prove that under fairly reasonable conditions on the probabilitydistribution governing measurements, SLHC is equivalent to maximum partialprofile likelihood estimation (MPPLE) with some of the information contained inthe data ignored. At the same time, we show that direct evaluation of SLHC onmaximum likelihood estimation (MLE) of pairwise distances yields a consistentestimator. Consequently, a full MLE is expected to perform better than SLHC ingetting the correct HC results for the ground truth metric.
arxiv-13800-210 | Searching for Objects using Structure in Indoor Scenes | http://arxiv.org/pdf/1511.07710v1.pdf | author:Varun K. Nagaraja, Vlad I. Morariu, Larry S. Davis category:cs.CV cs.AI published:2015-11-24 summary:To identify the location of objects of a particular class, a passive computervision system generally processes all the regions in an image to finally outputfew regions. However, we can use structure in the scene to search for objectswithout processing the entire image. We propose a search technique thatsequentially processes image regions such that the regions that are more likelyto correspond to the query class object are explored earlier. We frame theproblem as a Markov decision process and use an imitation learning algorithm tolearn a search strategy. Since structure in the scene is essential for search,we work with indoor scene images as they contain both unary scene contextinformation and object-object context in the scene. We perform experiments onthe NYU-depth v2 dataset and show that the unary scene context features alonecan achieve a significantly high average precision while processing only20-25\% of the regions for classes like bed and sofa. By consideringobject-object context along with the scene context features, the performance isfurther improved for classes like counter, lamp, pillow and sofa.
arxiv-13800-211 | Gradient-free Hamiltonian Monte Carlo with Efficient Kernel Exponential Families | http://arxiv.org/pdf/1506.02564v2.pdf | author:Heiko Strathmann, Dino Sejdinovic, Samuel Livingstone, Zoltan Szabo, Arthur Gretton category:stat.ML published:2015-06-08 summary:We propose Kernel Hamiltonian Monte Carlo (KMC), a gradient-free adaptiveMCMC algorithm based on Hamiltonian Monte Carlo (HMC). On target densitieswhere classical HMC is not an option due to intractable gradients, KMCadaptively learns the target's gradient structure by fitting an exponentialfamily model in a Reproducing Kernel Hilbert Space. Computational costs arereduced by two novel efficient approximations to this gradient. While beingasymptotically exact, KMC mimics HMC in terms of sampling efficiency, andoffers substantial mixing improvements over state-of-the-art gradient freesamplers. We support our claims with experimental studies on both toy andreal-world applications, including Approximate Bayesian Computation andexact-approximate MCMC.
arxiv-13800-212 | A new hybrid stemming algorithm for Persian | http://arxiv.org/pdf/1507.03077v2.pdf | author:Adel Rahimi category:cs.CL cs.IR published:2015-07-11 summary:Stemming has been an influential part in Information retrieval and searchengines. There have been tremendous endeavours in making stemmer that are bothefficient and accurate. Stemmers can have three method in stemming, Dictionarybased stemmer, statistical-based stemmers, and rule-based stemmers. This paperaims at building a hybrid stemmer that uses both Dictionary based method andrule-based method for stemming. This ultimately helps the efficacy andaccurateness of the stemmer.
arxiv-13800-213 | A pilot study on the daily control capability of s-EMG prosthetic hands by amputees | http://arxiv.org/pdf/1511.06001v2.pdf | author:Francesca Giordaniello category:cs.LG cs.HC published:2015-11-18 summary:Surface electromyography is a valid tool to gather muscular contractionsignals from intact and amputated subjects. Electromyographic signals can beused to control prosthetic devices in a noninvasive way distinguishing themovements performed by the particular EMG electrodes activity. According to theliterature, several algorithms have been used to control prosthetic handsthrough s-EMG signals. The main issue is to correctly classify the signalsacquired as the movement actually performed. This work presents a study on theSupport Vector Machine's performance in a short-time period, gained using twodifferent feature representation (Mean Absolute Value and Waveform Length) ofthe sEMG signals. In particular, we paid close attention to the repeatabilityproblem, that is the capability to achieve a stable and satisfactory level ofaccuracy in repeated experiments. Results on a limited setting are encouraging,as they show an average accuracy above 73% even in the worst case scenario.
arxiv-13800-214 | Semi-Supervised Learning with Ladder Networks | http://arxiv.org/pdf/1507.02672v2.pdf | author:Antti Rasmus, Harri Valpola, Mikko Honkala, Mathias Berglund, Tapani Raiko category:cs.NE cs.LG stat.ML published:2015-07-09 summary:We combine supervised learning with unsupervised learning in deep neuralnetworks. The proposed model is trained to simultaneously minimize the sum ofsupervised and unsupervised cost functions by backpropagation, avoiding theneed for layer-wise pre-training. Our work builds on the Ladder networkproposed by Valpola (2015), which we extend by combining the model withsupervision. We show that the resulting model reaches state-of-the-artperformance in semi-supervised MNIST and CIFAR-10 classification, in additionto permutation-invariant MNIST classification with all labels.
arxiv-13800-215 | Near-Optimal Active Learning of Multi-Output Gaussian Processes | http://arxiv.org/pdf/1511.06891v2.pdf | author:Yehong Zhang, Trong Nghia Hoang, Kian Hsiang Low, Mohan Kankanhalli category:stat.ML cs.AI cs.LG published:2015-11-21 summary:This paper addresses the problem of active learning of a multi-outputGaussian process (MOGP) model representing multiple types of coexistingcorrelated environmental phenomena. In contrast to existing works, our activelearning problem involves selecting not just the most informative samplinglocations to be observed but also the types of measurements at each selectedlocation for minimizing the predictive uncertainty (i.e., posterior jointentropy) of a target phenomenon of interest given a sampling budget.Unfortunately, such an entropy criterion scales poorly in the numbers ofcandidate sampling locations and selected observations when optimized. Toresolve this issue, we first exploit a structure common to sparse MOGP modelsfor deriving a novel active learning criterion. Then, we exploit a relaxed formof submodularity property of our new criterion for devising a polynomial-timeapproximation algorithm that guarantees a constant-factor approximation of thatachieved by the optimal set of selected observations. Empirical evaluation onreal-world datasets shows that our proposed approach outperforms existingalgorithms for active learning of MOGP and single-output GP models.
arxiv-13800-216 | Mouse Pose Estimation From Depth Images | http://arxiv.org/pdf/1511.07611v1.pdf | author:Ashwin Nanjappa, Li Cheng, Wei Gao, Chi Xu, Adam Claridge-Chang, Zoe Bichler category:cs.CV published:2015-11-24 summary:We focus on the challenging problem of efficient mouse 3D pose estimationbased on static images, and especially single depth images. We introduce anapproach to discriminatively train the split nodes of trees in random forest toimprove their performance on estimation of 3D joint positions of mouse. Ouralgorithm is capable of working with different types of rodents and withdifferent types of depth cameras and imaging setups. In particular, it isdemonstrated in this paper that when a top-mounted depth camera is combinedwith a bottom-mounted color camera, the final system is capable of deliveringfull-body pose estimation including four limbs and the paws. Empiricalexaminations on synthesized and real-world depth images confirm theapplicability of our approach on mouse pose estimation, as well as the closelyrelated task of part-based labeling of mouse.
arxiv-13800-217 | Picking a Conveyor Clean by an Autonomously Learning Robot | http://arxiv.org/pdf/1511.07608v1.pdf | author:Janne V. Kujala, Tuomas J. Lukka, Harri Holopainen category:cs.RO cs.CV cs.LG published:2015-11-24 summary:We present a research picking prototype related to our company's industrialwaste sorting application. The goal of the prototype is to be as autonomous aspossible and it both calibrates itself and improves its picking with minimalhuman intervention. The system learns to pick objects better based on afeedback sensor in its gripper and uses machine learning to choosing the bestproposal from a random sample produced by simple hard-coded geometric models.We show experimentally the system improving its picking autonomously bymeasuring the pick success rate as function of time. We also show how thissystem can pick a conveyor belt clean, depositing 70 out of 80 objects in adifficult to manipulate pile of novel objects into the correct chute. Wediscuss potential improvements and next steps in this direction.
arxiv-13800-218 | Fine-Grain Annotation of Cricket Videos | http://arxiv.org/pdf/1511.07607v1.pdf | author:Rahul Anand Sharma, Pramod Sankar K, CV Jawahar category:cs.MM cs.CL cs.CV published:2015-11-24 summary:The recognition of human activities is one of the key problems in videounderstanding. Action recognition is challenging even for specific categoriesof videos, such as sports, that contain only a small set of actions.Interestingly, sports videos are accompanied by detailed commentaries availableonline, which could be used to perform action annotation in a weakly-supervisedsetting. For the specific case of Cricket videos, we address the challenge oftemporal segmentation and annotation of ctions with semantic descriptions. Oursolution consists of two stages. In the first stage, the video is segmentedinto "scenes", by utilizing the scene category information extracted fromtext-commentary. The second stage consists of classifying video-shots as wellas the phrases in the textual description into various categories. The relevantphrases are then suitably mapped to the video-shots. The novel aspect of thiswork is the fine temporal scale at which semantic information is assigned tothe video. As a result of our approach, we enable retrieval of specific actionsthat last only a few seconds, from several hours of video. This solution yieldsa large number of labeled exemplars, with no manual effort, that could be usedby machine learning algorithms to learn complex actions.
arxiv-13800-219 | Parsing Occluded People by Flexible Compositions | http://arxiv.org/pdf/1412.1526v2.pdf | author:Xianjie Chen, Alan Yuille category:cs.CV published:2014-12-04 summary:This paper presents an approach to parsing humans when there is significantocclusion. We model humans using a graphical model which has a tree structurebuilding on recent work [32, 6] and exploit the connectivity prior that, evenin presence of occlusion, the visible nodes form a connected subtree of thegraphical model. We call each connected subtree a flexible composition ofobject parts. This involves a novel method for learning occlusion cues. Duringinference we need to search over a mixture of different flexible models. Byexploiting part sharing, we show that this inference can be done extremelyefficiently requiring only twice as many computations as searching for theentire object (i.e., not modeling occlusion). We evaluate our model on thestandard benchmarked "We Are Family" Stickmen dataset and obtain significantperformance improvements over the best alternative algorithms.
arxiv-13800-220 | Context-Aware Bandits | http://arxiv.org/pdf/1510.03164v2.pdf | author:Shuai Li, Alexandros Karatzoglou category:cs.LG cs.AI stat.ML published:2015-10-12 summary:In this paper, we present a simple and efficient Context-Aware Bandit (CAB)algorithm. With CAB we attempt to craft a bandit algorithm that can capturecollaborative effects and that can be easily deployed in a real-worldrecommendation system, where the multi-armed bandits have been shown to performwell in particular with respect to the cold-start problem. CAB utilizes acontext-aware clustering technique augmenting exploration-exploitationstrategies. CAB dynamically clusters the users based on the content universeunder consideration. We provide a theoretical analysis in the standardstochastic multi-armed bandits setting. We demonstrate the efficiency of ourapproach on production and real-world datasets, showing the scalability and,more importantly, the significantly increased prediction performance againstseveral existing state-of-the-art methods.
arxiv-13800-221 | DenseCap: Fully Convolutional Localization Networks for Dense Captioning | http://arxiv.org/pdf/1511.07571v1.pdf | author:Justin Johnson, Andrej Karpathy, Li Fei-Fei category:cs.CV cs.LG published:2015-11-24 summary:We introduce the dense captioning task, which requires a computer visionsystem to both localize and describe salient regions in images in naturallanguage. The dense captioning task generalizes object detection when thedescriptions consist of a single word, and Image Captioning when one predictedregion covers the full image. To address the localization and description taskjointly we propose a Fully Convolutional Localization Network (FCLN)architecture that processes an image with a single, efficient forward pass,requires no external regions proposals, and can be trained end-to-end with asingle round of optimization. The architecture is composed of a ConvolutionalNetwork, a novel dense localization layer, and Recurrent Neural Networklanguage model that generates the label sequences. We evaluate our network onthe Visual Genome dataset, which comprises 94,000 images and 4,100,000region-grounded captions. We observe both speed and accuracy improvements overbaselines based on current state of the art approaches in both generation andretrieval settings.
arxiv-13800-222 | Learning Simple Algorithms from Examples | http://arxiv.org/pdf/1511.07275v2.pdf | author:Wojciech Zaremba, Tomas Mikolov, Armand Joulin, Rob Fergus category:cs.AI cs.LG published:2015-11-23 summary:We present an approach for learning simple algorithms such as copying,multi-digit addition and single digit multiplication directly from examples.Our framework consists of a set of interfaces, accessed by a controller.Typical interfaces are 1-D tapes or 2-D grids that hold the input and outputdata. For the controller, we explore a range of neural network-based modelswhich vary in their ability to abstract the underlying algorithm from traininginstances and generalize to test examples with many thousands of digits. Thecontroller is trained using $Q$-learning with several enhancements and we showthat the bottleneck is in the capabilities of the controller rather than in thesearch incurred by $Q$-learning.
arxiv-13800-223 | Finding a sparse vector in a subspace: Linear sparsity using alternating directions | http://arxiv.org/pdf/1412.4659v2.pdf | author:Qing Qu, Ju Sun, John Wright category:cs.IT cs.CV cs.LG math.IT math.OC stat.ML published:2014-12-15 summary:We consider the problem of recovering the sparsest vector in a genericsubspace $\mathcal{S} \subseteq \mathbb{R}^p$ with $\mathrm{dim}(\mathcal{S})=n < p$. This problem can be considered a homogeneous variant of the sparserecovery problem, and finds applications in sparse dictionary learning, sparsePCA, and many other problems in signal processing and machine learning. Simpleconvex heuristics for this problem provably break down when the fraction ofnonzero entries in the target sparse vector substantially exceeds$O(1/\sqrt{n})$. In contrast, we exhibit a relatively simple nonconvex approachbased on alternating directions, which provably succeeds even when the fractionof nonzero entries is $\Omega(1)$. To the best of our knowledge, this is thefirst practical algorithm to achieve this linear scaling. This result assumes aplanted sparse model for the subspace, in which the target sparse vector isembedded in an otherwise random subspace. Empirically, our proposed algorithmalso succeeds in more challenging data models, e.g., sparse dictionarylearning.
arxiv-13800-224 | Functional Gaussian Process Model for Bayesian Nonparametric Analysis | http://arxiv.org/pdf/1502.03042v2.pdf | author:Leo L. Duan, Xia Wang, Rhonda D. Szczesniak category:stat.ML stat.CO stat.ME published:2015-02-10 summary:Gaussian process is a theoretically appealing model for nonparametricanalysis, but its computational cumbersomeness hinders its use in large scaleand the existing reduced-rank solutions are usually heuristic. In this work, wepropose a novel construction of Gaussian process as a projection from fixeddiscrete frequencies to any continuous location. This leads to a validstochastic process that has a theoretic support with the reduced rank in thespectral density, as well as a high-speed computing algorithm. Our methodprovides accurate estimates for the covariance parameters and concise form ofpredictive distribution for spatial prediction. For non-stationary data, weadopt the mixture framework with a customized spectral dependency structure.This enables clustering based on local stationarity, while maintains the jointGaussianness. Our work is directly applicable in solving some of the challengesin the spatial data, such as large scale computation, anisotropic covariance,spatio-temporal modeling, etc. We illustrate the uses of the model viasimulations and an application on a massive dataset.
arxiv-13800-225 | Generalized Product of Experts for Automatic and Principled Fusion of Gaussian Process Predictions | http://arxiv.org/pdf/1410.7827v2.pdf | author:Yanshuai Cao, David J. Fleet category:cs.LG cs.AI stat.ML published:2014-10-28 summary:In this work, we propose a generalized product of experts (gPoE) frameworkfor combining the predictions of multiple probabilistic models. We identifyfour desirable properties that are important for scalability, expressivenessand robustness, when learning and inferring with a combination of multiplemodels. Through analysis and experiments, we show that gPoE of Gaussianprocesses (GP) have these qualities, while no other existing combinationschemes satisfy all of them at the same time. The resulting GP-gPoE is highlyscalable as individual GP experts can be independently learned in parallel;very expressive as the way experts are combined depends on the input ratherthan fixed; the combined prediction is still a valid probabilistic model withnatural interpretation; and finally robust to unreliable predictions fromindividual experts.
arxiv-13800-226 | Transductive Log Opinion Pool of Gaussian Process Experts | http://arxiv.org/pdf/1511.07551v1.pdf | author:Yanshuai Cao, David J. Fleet category:cs.LG stat.ML published:2015-11-24 summary:We introduce a framework for analyzing transductive combination of Gaussianprocess (GP) experts, where independently trained GP experts are combined in away that depends on test point location, in order to scale GPs to big data. Theframework provides some theoretical justification for the generalized productof GP experts (gPoE-GP) which was previously shown to work well in practice butlacks theoretical basis. Based on the proposed framework, an improvement overgPoE-GP is introduced and empirically validated.
arxiv-13800-227 | Constrained Deep Metric Learning for Person Re-identification | http://arxiv.org/pdf/1511.07545v1.pdf | author:Hailin Shi, Xiangyu Zhu, Shengcai Liao, Zhen Lei, Yang Yang, Stan Z. Li category:cs.CV published:2015-11-24 summary:Person re-identification aims to re-identify the probe image from a given setof images under different camera views. It is challenging due to largevariations of pose, illumination, occlusion and camera view. Since theconvolutional neural networks (CNN) have excellent capability of featureextraction, certain deep learning methods have been recently applied in personre-identification. However, in person re-identification, the deep networksoften suffer from the over-fitting problem. In this paper, we propose a novelCNN-based method to learn a discriminative metric with good robustness to theover-fitting problem in person re-identification. Firstly, a novel deeparchitecture is built where the Mahalanobis metric is learned with a weightconstraint. This weight constraint is used to regularize the learning, so thatthe learned metric has a better generalization ability. Secondly, we find thatthe selection of intra-class sample pairs is crucial for learning but hasreceived little attention. To cope with the large intra-class variations inpedestrian images, we propose a novel training strategy named moderate positivemining to prevent the training process from over-fitting to the extreme samplesin intra-class pairs. Experiments show that our approach significantlyoutperforms state-of-the-art methods on several benchmarks of personre-identification.
arxiv-13800-228 | Skip-Thought Memory Networks | http://arxiv.org/pdf/1511.06420v2.pdf | author:Ethan Caballero category:cs.NE cs.CL cs.LG published:2015-11-19 summary:Question Answering (QA) is fundamental to natural language processing in thatmost nlp problems can be phrased as QA (Kumar et al., 2015). Current weaklysupervised memory network models that have been proposed so far struggle atanswering questions that involve relations among multiple entities (such asfacebook's bAbi qa5-three-arg-relations in (Weston et al., 2015)). To addressthis problem of learning multi-argument multi-hop semantic relations for thepurpose of QA, we propose a method that combines the jointly learned long-termread-write memory and attentive inference components of end-to-end memorynetworks (MemN2N) (Sukhbaatar et al., 2015) with distributed sentence vectorrepresentations encoded by a Skip-Thought model (Kiros et al., 2015). Thischoice to append Skip-Thought Vectors to the existing MemN2N framework ismotivated by the fact that Skip-Thought Vectors have been shown to accuratelymodel multi-argument semantic relations (Kiros et al., 2015).
arxiv-13800-229 | The Limitations of Deep Learning in Adversarial Settings | http://arxiv.org/pdf/1511.07528v1.pdf | author:Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, Ananthram Swami category:cs.CR cs.LG cs.NE stat.ML published:2015-11-24 summary:Deep learning takes advantage of large datasets and computationally efficienttraining algorithms to outperform other approaches at various machine learningtasks. However, imperfections in the training phase of deep neural networksmake them vulnerable to adversarial samples: inputs crafted by adversaries withthe intent of causing deep neural networks to misclassify. In this work, weformalize the space of adversaries against deep neural networks (DNNs) andintroduce a novel class of algorithms to craft adversarial samples based on aprecise understanding of the mapping between inputs and outputs of DNNs. In anapplication to computer vision, we show that our algorithms can reliablyproduce samples correctly classified by human subjects but misclassified inspecific targets by a DNN with a 97% adversarial success rate while onlymodifying on average 4.02% of the input features per sample. We then evaluatethe vulnerability of different sample classes to adversarial perturbations bydefining a hardness measure. Finally, we describe preliminary work outliningdefenses against adversarial samples by defining a predictive measure ofdistance between a benign input and a target classification.
arxiv-13800-230 | Noise-adaptive Margin-based Active Learning and Lower Bounds under Tsybakov Noise Condition | http://arxiv.org/pdf/1406.5383v3.pdf | author:Yining Wang, Aarti Singh category:stat.ML cs.LG published:2014-06-20 summary:We present a simple noise-robust margin-based active learning algorithm tofind homogeneous (passing the origin) linear separators and analyze its errorconvergence when labels are corrupted by noise. We show that when the imposednoise satisfies the Tsybakov low noise condition (Mammen, Tsybakov, and others1999; Tsybakov 2004) the algorithm is able to adapt to unknown level of noiseand achieves optimal statistical rate up to poly-logarithmic factors. We alsoderive lower bounds for margin based active learning algorithms under Tsybakovnoise conditions (TNC) for the membership query synthesis scenario (Angluin1988). Our result implies lower bounds for the stream based selective samplingscenario (Cohn 1990) under TNC for some fairly simple data distributions. Quitesurprisingly, we show that the sample complexity cannot be improved even if theunderlying data distribution is as simple as the uniform distribution on theunit ball. Our proof involves the construction of a well separated hypothesisset on the d-dimensional unit ball along with carefully designed labeldistributions for the Tsybakov noise condition. Our analysis might provideinsights for other forms of lower bounds as well.
arxiv-13800-231 | Constrained Structured Regression with Convolutional Neural Networks | http://arxiv.org/pdf/1511.07497v1.pdf | author:Deepak Pathak, Philipp KrÃ¤henbÃ¼hl, Stella X. Yu, Trevor Darrell category:cs.CV cs.LG published:2015-11-23 summary:Convolutional Neural Networks (CNNs) have recently emerged as the dominantmodel in computer vision. If provided with enough training data, they predictalmost any visual quantity. In a discrete setting, such as classification, CNNsare not only able to predict a label but often predict a confidence in the formof a probability distribution over the output space. In continuous regressiontasks, such a probability estimate is often lacking. We present a regressionframework which models the output distribution of neural networks. This outputdistribution allows us to infer the most likely labeling following a set ofphysical or modeling constraints. These constraints capture the intricateinterplay between different input and output variables, and complement theoutput of a CNN. However, they may not hold everywhere. Our setup furtherallows to learn a confidence with which a constraint holds, in the form of adistribution of the constrain satisfaction. We evaluate our approach on theproblem of intrinsic image decomposition, and show that constrained structuredregression significantly increases the state-of-the-art.
arxiv-13800-232 | Predicting People's 3D Poses from Short Sequences | http://arxiv.org/pdf/1504.08200v4.pdf | author:Bugra Tekin, Xiaolu Sun, Xinchao Wang, Vincent Lepetit, Pascal Fua category:cs.CV published:2015-04-30 summary:We propose an efficient approach to exploiting motion information fromconsecutive frames of a video sequence to recover the 3D pose of people.Instead of computing candidate poses in individual frames and then linkingthem, as is often done, we regress directly from a spatio-temporal block offrames to a 3D pose in the central one. We will demonstrate that this approachallows us to effectively overcome ambiguities and to improve upon thestate-of-the-art on challenging sequences.
arxiv-13800-233 | Symmetric Tensor Completion from Multilinear Entries and Learning Product Mixtures over the Hypercube | http://arxiv.org/pdf/1506.03137v3.pdf | author:Tselil Schramm, Benjamin Weitz category:cs.DS cs.LG stat.ML published:2015-06-09 summary:We give an algorithm for completing an order-$m$ symmetric low-rank tensorfrom its multilinear entries in time roughly proportional to the number oftensor entries. We apply our tensor completion algorithm to the problem oflearning mixtures of product distributions over the hypercube, obtaining newalgorithmic results. If the centers of the product distribution are linearlyindependent, then we recover distributions with as many as $\Omega(n)$ centersin polynomial time and sample complexity. In the general case, we recoverdistributions with as many as $\tilde\Omega(n)$ centers in quasi-polynomialtime, answering an open problem of Feldman et al. (SIAM J. Comp.) for thespecial case of distributions with incoherent bias vectors. Our main algorithmic tool is the iterated application of a low-rank matrixcompletion algorithm for matrices with adversarially missing entries.
arxiv-13800-234 | On the Structure, Covering, and Learning of Poisson Multinomial Distributions | http://arxiv.org/pdf/1504.08363v3.pdf | author:Constantinos Daskalakis, Gautam Kamath, Christos Tzamos category:cs.DS cs.LG math.PR math.ST stat.TH published:2015-04-30 summary:An $(n,k)$-Poisson Multinomial Distribution (PMD) is the distribution of thesum of $n$ independent random vectors supported on the set ${\calB}_k=\{e_1,\ldots,e_k\}$ of standard basis vectors in $\mathbb{R}^k$. We provea structural characterization of these distributions, showing that, for all$\varepsilon >0$, any $(n, k)$-Poisson multinomial random vector is$\varepsilon$-close, in total variation distance, to the sum of a discretizedmultidimensional Gaussian and an independent $(\text{poly}(k/\varepsilon),k)$-Poisson multinomial random vector. Our structural characterization extendsthe multi-dimensional CLT of Valiant and Valiant, by simultaneously applying toall approximation requirements $\varepsilon$. In particular, it overcomesfactors depending on $\log n$ and, importantly, the minimum eigenvalue of thePMD's covariance matrix from the distance to a multidimensional Gaussian randomvariable. We use our structural characterization to obtain an $\varepsilon$-cover, intotal variation distance, of the set of all $(n, k)$-PMDs, significantlyimproving the cover size of Daskalakis and Papadimitriou, and obtaining thesame qualitative dependence of the cover size on $n$ and $\varepsilon$ as the$k=2$ cover of Daskalakis and Papadimitriou. We further exploit this structureto show that $(n,k)$-PMDs can be learned to within $\varepsilon$ in totalvariation distance from $\tilde{O}_k(1/\varepsilon^2)$ samples, which isnear-optimal in terms of dependence on $\varepsilon$ and independent of $n$. Inparticular, our result generalizes the single-dimensional result of Daskalakis,Diakonikolas, and Servedio for Poisson Binomials to arbitrary dimension.
arxiv-13800-235 | Stick-Breaking Policy Learning in Dec-POMDPs | http://arxiv.org/pdf/1505.00274v2.pdf | author:Miao Liu, Christopher Amato, Xuejun Liao, Lawrence Carin, Jonathan P. How category:cs.AI cs.SY stat.ML published:2015-05-01 summary:Expectation maximization (EM) has recently been shown to be an efficientalgorithm for learning finite-state controllers (FSCs) in large decentralizedPOMDPs (Dec-POMDPs). However, current methods use fixed-size FSCs and oftenconverge to maxima that are far from optimal. This paper considers avariable-size FSC to represent the local policy of each agent. Thesevariable-size FSCs are constructed using a stick-breaking prior, leading to anew framework called \emph{decentralized stick-breaking policy representation}(Dec-SBPR). This approach learns the controller parameters with a variationalBayesian algorithm without having to assume that the Dec-POMDP model isavailable. The performance of Dec-SBPR is demonstrated on several benchmarkproblems, showing that the algorithm scales to large problems whileoutperforming other state-of-the-art methods.
arxiv-13800-236 | Convolutional Pseudo-Prior for Structured Labeling | http://arxiv.org/pdf/1511.07409v1.pdf | author:Saining Xie, Xun Huang, Zhuowen Tu category:cs.CV cs.LG published:2015-11-23 summary:Current practice in convolutional neural networks (CNN) remains largelybottom-up and the role of top-down process in CNN for pattern analysis andvisual inference is not very clear. In this paper, we propose a new method forstructured labeling by developing convolutional pseudo-prior (ConvPP) on theground-truth labels. Our method has several interesting properties: (1)compared with classical machine learning algorithms like CRFs and StructuralSVM, ConvPP automatically learns rich convolutional kernels to capture bothshort- and long- range contexts; (2) compared with cascade classifiers likeAuto-Context, ConvPP avoids the iterative steps of learning a series ofdiscriminative classifiers and automatically learns contextual configurations;(3) compared with recent efforts combing CNN models with CRFs and RNNs, ConvPPlearns convolution in the labeling space with much improved modeling capabilityand less manual specification; (4) compared with Bayesian models like MRFs,ConvPP capitalizes on the rich representation power of convolution byautomatically learning priors built on convolutional filters. We accomplish ourtask using pseudo-likelihood approximation to the prior under a novelfixed-point network structure that facilitates an end-to-end learning process.We show state-of-the-art results on sequential labeling and image labelingbenchmarks.
arxiv-13800-237 | Compact Convolutional Neural Network Cascade for Face Detection | http://arxiv.org/pdf/1508.01292v3.pdf | author:Ilya Kalinovskii, Vladimir Spitsyn category:cs.CV published:2015-08-06 summary:The problem of faces detection in images or video streams is a classicalproblem of computer vision. The multiple solutions of this problem have beenproposed, but the question of their optimality is still open. Many algorithmsachieve a high quality face detection, but at the cost of high computationalcomplexity. This restricts their application in the real-time systems. Thispaper presents a new solution of the frontal face detection problem based oncompact convolutional neural networks cascade. The test results on FDDB datasetshow that it is competitive with state-of-the-art algorithms. This proposeddetector is implemented using three technologies: SSE/AVX/AVX2 instruction setsfor Intel CPUs, Nvidia CUDA, OpenCL. The detection speed of our approachconsiderably exceeds all the existing CPU-based and GPU-based algorithms.Because of high computational efficiency, our detector can processing 4K UltraHD video stream in real time (up to 27 fps) on mobile platforms (Intel IvyBridge CPUs and Nvidia Kepler GPUs) in searching objects with the dimension60x60 pixels or higher. At the same time its performance weakly dependent onthe background and number of objects in scene. This is achieved by theasynchronous computation of stages in the cascade.
arxiv-13800-238 | GPU-based Acceleration of Deep Convolutional Neural Networks on Mobile Platforms | http://arxiv.org/pdf/1511.07376v1.pdf | author:Seyyed Salar Latifi Oskouei, Hossein Golestani, Mohamad Kachuee, Matin Hashemi, Hoda Mohammadzade, Soheil Ghiasi category:cs.DC cs.CV published:2015-11-23 summary:Mobile applications running on wearable devices and smartphones can greatlybenefit from accurate and scalable deep CNN-based machine learning algorithms.While mobile CPU performance does not match the intensive computationalrequirement of deep CNNs, the embedded GPU which already exists in many mobileplatforms can be leveraged for acceleration of CNN computations on the localdevice and without the use of a cloud service. We present a GPU-basedaccelerated deep CNN engine for mobile platforms with upto 60X speedup.
arxiv-13800-239 | Black box variational inference for state space models | http://arxiv.org/pdf/1511.07367v1.pdf | author:Evan Archer, Il Memming Park, Lars Buesing, John Cunningham, Liam Paninski category:stat.ML published:2015-11-23 summary:Latent variable time-series models are among the most heavily used tools frommachine learning and applied statistics. These models have the advantage oflearning latent structure both from noisy observations and from the temporalordering in the data, where it is assumed that meaningful correlation structureexists across time. A few highly-structured models, such as the lineardynamical system with linear-Gaussian observations, have closed-form inferenceprocedures (e.g. the Kalman Filter), but this case is an exception to thegeneral rule that exact posterior inference in more complex generative modelsis intractable. Consequently, much work in time-series modeling focuses onapproximate inference procedures for one particular class of models. Here, weextend recent developments in stochastic variational inference to develop a`black-box' approximate inference technique for latent variable models withlatent dynamical structure. We propose a structured Gaussian variationalapproximate posterior that carries the same intuition as the standard Kalmanfilter-smoother but, importantly, permits us to use the same inference approachto approximate the posterior of much more general, nonlinear latent variablegenerative models. We show that our approach recovers accurate estimates in thecase of basic models with closed-form posteriors, and more interestinglyperforms well in comparison to variational approaches that were designed in abespoke fashion for specific non-conjugate models.
arxiv-13800-240 | Interpretable Two-level Boolean Rule Learning for Classification | http://arxiv.org/pdf/1511.07361v1.pdf | author:Guolong Su, Dennis Wei, Kush R. Varshney, Dmitry M. Malioutov category:cs.LG cs.AI published:2015-11-23 summary:This paper proposes algorithms for learning two-level Boolean rules inConjunctive Normal Form (CNF, i.e. AND-of-ORs) or Disjunctive Normal Form (DNF,i.e. OR-of-ANDs) as a type of human-interpretable classification model, aimingfor a favorable trade-off between the classification accuracy and thesimplicity of the rule. Two formulations are proposed. The first is an integerprogram whose objective function is a combination of the total number of errorsand the total number of features used in the rule. We generalize a previouslyproposed linear programming (LP) relaxation from one-level to two-level rules.The second formulation replaces the 0-1 classification error with the Hammingdistance from the current two-level rule to the closest rule that correctlyclassifies a sample. Based on this second formulation, block coordinate descentand alternating minimization algorithms are developed. Experiments show thatthe two-level rules can yield noticeably better performance than one-levelrules due to their dramatically larger modeling capacity, and the twoalgorithms based on the Hamming distance formulation are generally superior tothe other two-level rule learning methods in our comparison. A proposedapproach to binarize any fractional values in the optimal solutions of LPrelaxations is also shown to be effective.
arxiv-13800-241 | Node Specificity in Convolutional Deep Nets Depends on Receptive Field Position and Size | http://arxiv.org/pdf/1511.07347v1.pdf | author:Karl Zipser category:cs.CV published:2015-11-23 summary:In convolutional deep neural networks, receptive field (RF) size increaseswith hierarchical depth. When RF size approaches full coverage of the inputimage, different RF positions result in RFs with different specificity, asportions of the RF fall out of the input space. This leads to a departure fromthe convolutional concept of positional invariance and opens the possibilityfor complex forms of context specificity.
arxiv-13800-242 | Modular Autoencoders for Ensemble Feature Extraction | http://arxiv.org/pdf/1511.07340v1.pdf | author:Henry W J Reeve, Gavin Brown category:cs.LG published:2015-11-23 summary:We introduce the concept of a Modular Autoencoder (MAE), capable of learninga set of diverse but complementary representations from unlabelled data, thatcan later be used for supervised tasks. The learning of the representations iscontrolled by a trade off parameter, and we show on six benchmark datasets theoptimum lies between two extremes: a set of smaller, independent autoencoderseach with low capacity, versus a single monolithic encoding, outperforming anappropriate baseline. In the present paper we explore the special case oflinear MAE, and derive an SVD-based algorithm which converges several orders ofmagnitude faster than gradient descent.
arxiv-13800-243 | Switched Dynamical Latent Force Models for Modelling Transcriptional Regulation | http://arxiv.org/pdf/1511.07334v1.pdf | author:AndrÃ©s F. LÃ³pez-Lopera, Mauricio A. Ãlvarez category:physics.bio-ph stat.ML published:2015-11-23 summary:In order to develop statistical approaches for transcription networks,statistical community has proposed several methods to infer activity levels ofproteins, from time-series measurements of targets' expression levels. A fewnumber of approaches have been proposed in order to outperform therepresentation of fast switching time instants, but computational overheads aresignificant due to complex inference algorithms. Using the theory related tolatent force models (LFM), the development of this project provide a switcheddynamical hybrid model based on Gaussian processes (GPs). To deal withdiscontinuities in dynamical systems (or latent driving force), an extension ofthe single input motif approach is introduced, that switches between differentprotein concentrations, and different dynamical systems. This creates aversatile representation for transcription networks that can capture discretechanges and non-linearities in the dynamics. The proposed method is evaluatedon both simulated data and real data, concluding that our framework provides acomputationally efficient statistical inference module of continuous-timeconcentration profiles, and allows an easy estimation of the associated modelparameters.
arxiv-13800-244 | Unveiling the Dreams of Word Embeddings: Towards Language-Driven Image Generation | http://arxiv.org/pdf/1506.03500v2.pdf | author:Angeliki Lazaridou, Dat Tien Nguyen, Raffaella Bernardi, Marco Baroni category:cs.CV cs.CL published:2015-06-10 summary:We introduce language-driven image generation, the task of generating animage visualizing the semantic contents of a word embedding, e.g., given theword embedding of grasshopper, we generate a natural image of a grasshopper. Weimplement a simple method based on two mapping functions. The first takes asinput a word embedding (as produced, e.g., by the word2vec toolkit) and maps itonto a high-level visual space (e.g., the space defined by one of the toplayers of a Convolutional Neural Network). The second function maps thisabstract visual representation to pixel space, in order to generate the targetimage. Several user studies suggest that the current system produces imagesthat capture general visual properties of the concepts encoded in the wordembedding, such as color or typical environment, and are sufficient todiscriminate between general categories of objects.
arxiv-13800-245 | Training Very Deep Networks | http://arxiv.org/pdf/1507.06228v2.pdf | author:Rupesh Kumar Srivastava, Klaus Greff, JÃ¼rgen Schmidhuber category:cs.LG cs.NE 68T01 I.2.6; G.1.6 published:2015-07-22 summary:Theoretical and empirical evidence indicates that the depth of neuralnetworks is crucial for their success. However, training becomes more difficultas depth increases, and training of very deep networks remains an open problem.Here we introduce a new architecture designed to overcome this. Our so-calledhighway networks allow unimpeded information flow across many layers oninformation highways. They are inspired by Long Short-Term Memory recurrentnetworks and use adaptive gating units to regulate the information flow. Evenwith hundreds of layers, highway networks can be trained directly throughsimple gradient descent. This enables the study of extremely deep and efficientarchitectures.
arxiv-13800-246 | Stochastic Parallel Block Coordinate Descent for Large-scale Saddle Point Problems | http://arxiv.org/pdf/1511.07294v1.pdf | author:Zhanxing Zhu, Amos J. Storkey category:stat.ML published:2015-11-23 summary:We consider convex-concave saddle point problems with a separable structureand non-strongly convex functions. We propose an efficient stochastic blockcoordinate descent method using adaptive primal-dual updates, which enablesflexible parallel optimization for large-scale problems. Our method shares theefficiency and flexibility of block coordinate descent methods with thesimplicity of primal-dual methods and utilizing the structure of the separableconvex-concave saddle point problem. It is capable of solving a wide range ofmachine learning applications, including robust principal component analysis,Lasso, and feature selection by group Lasso, etc. Theoretically andempirically, we demonstrate significantly better performance thanstate-of-the-art methods in all these applications.
arxiv-13800-247 | Sparse Recovery via Partial Regularization: Models, Theory and Algorithms | http://arxiv.org/pdf/1511.07293v1.pdf | author:Zhaosong Lu, Xiaorui Li category:math.OC cs.IT cs.LG math.IT stat.ME stat.ML published:2015-11-23 summary:In the context of sparse recovery, it is known that most of existingregularizers such as $\ell_1$ suffer from some bias incurred by some leadingentries (in magnitude) of the associated vector. To neutralize this bias, wepropose a class of models with partial regularizers for recovering a sparsesolution of a linear system. We show that every local minimizer of these modelsis sufficiently sparse or the magnitude of all its nonzero entries is above auniform constant depending only on the data of the linear system. Moreover, fora class of partial regularizers, any global minimizer of these models is asparsest solution to the linear system. We also establish some sufficientconditions for local or global recovery of the sparsest solution to the linearsystem, among which one of the conditions is weaker than the best knownrestricted isometry property (RIP) condition for sparse recovery by $\ell_1$.In addition, a first-order feasible augmented Lagrangian (FAL) method isproposed for solving these models, in which each subproblem is solved by anonmonotone proximal gradient (NPG) method. Despite the complication of thepartial regularizers, we show that each proximal subproblem in NPG can besolved as a certain number of one-dimensional optimization problems, whichusually have a closed-form solution. We also show that any accumulation pointof the sequence generated by FAL is a first-order stationary point of themodels. Numerical results on compressed sensing and sparse logistic regressiondemonstrate that the proposed models substantially outperform the widely usedones in the literature in terms of solution quality.
arxiv-13800-248 | Sparse Linear Models applied to Power Quality Disturbance Classification | http://arxiv.org/pdf/1511.07281v1.pdf | author:AndrÃ©s F. LÃ³pez-Lopera, Mauricio A. Ãlvarez, Ãvaro A. Orozco category:stat.AP stat.ML published:2015-11-23 summary:Power quality (PQ) analysis describes the non-pure electric signals that areusually present in electric power systems. The automatic recognition of PQdisturbances can be seen as a pattern recognition problem, in which differenttypes of waveform distortion are differentiated based on their features.Similar to other quasi-stationary signals, PQ disturbances can be decomposedinto time-frequency dependent components by using time-frequency or time-scaletransforms, also known as dictionaries. These dictionaries are used in thefeature extraction step in pattern recognition systems. Short-time Fourier,Wavelets and Stockwell transforms are some of the most common dictionaries usedin the PQ community, aiming to achieve a better signal representation. To thebest of our knowledge, previous works about PQ disturbance classification havebeen restricted to the use of one among several available dictionaries. Takingadvantage of the theory behind sparse linear models (SLM), we introduce asparse method for PQ representation, starting from overcomplete dictionaries.In particular, we apply Group Lasso. We employ different types oftime-frequency (or time-scale) dictionaries to characterize the PQdisturbances, and evaluate their performance under different patternrecognition algorithms. We show that the SLM reduce the PQ classificationcomplexity promoting sparse basis selection, and improving the classificationaccuracy.
arxiv-13800-249 | Ridge Leverage Scores for Low-Rank Approximation | http://arxiv.org/pdf/1511.07263v1.pdf | author:Michael B. Cohen, Cameron Musco, Christopher Musco category:cs.DS cs.LG published:2015-11-23 summary:Often used as importance sampling probabilities, leverage scores have becomeindispensable in randomized algorithms for linear algebra, optimization, graphtheory, and machine learning. A major body of work seeks to adapt these scoresto low-rank approximation problems. However, existing "low-rank leveragescores" can be difficult to compute, often work for just a single application,and are sensitive to matrix perturbations. We show how to avoid these issues by exploiting connections between low-rankapproximation and regularization. Specifically, we employ ridge leveragescores, which are simply standard leverage scores computed with respect to an$\ell_2$ regularized input. Importance sampling by these scores gives the firstunified solution to two of the most important low-rank sampling problems:$(1+\epsilon)$ error column subset selection and $(1+\epsilon)$ errorprojection-cost preservation. Moreover, ridge leverage scores satisfy a key monotonicity property that doesnot hold for any prior low-rank leverage scores. Their resulting robustnessleads to two sought-after results in randomized linear algebra. 1) We give thefirst input-sparsity time low-rank approximation algorithm based on iterativecolumn sampling, resolving an open question posed in [LMP13], [CLM+15], and[AM15]. 2) We give the first single-pass streaming column subset selectionalgorithm whose real-number space complexity has no dependence on streamlength.
arxiv-13800-250 | Ãber die Klassifizierung von Knoten in dynamischen Netzwerken mit Inhalt | http://arxiv.org/pdf/1512.04469v1.pdf | author:Martin Thoma category:cs.LG published:2015-11-23 summary:This paper explains the DYCOS-Algorithm as it was introduced in by Aggarwaland Li in 2011. It operates on graphs whichs nodes are partially labeled andautomatically adds missing labels to nodes. To do so, the DYCOS algorithm makesuse of the structure of the graph as well as content which is assigned to thenode. Aggarwal and Li measured in an experimental analysis that DYCOS adds themissing labels to a Graph with 19396 nodes of which 14814 are labeled andanother Graph with 806635 nodes of which 18999 are labeld on one core of anIntel Xeon 2.5 GHz CPU with 32 G RAM within less than a minute. Additionally,extensions of the DYCOS algorithm are proposed. ----- In dieser Arbeit wird der DYCOS-Algorithmus, wie er 2011 von Aggarwal und Livorgestellt wurde, erkl\"art. Er arbeitet auf Graphen, deren Knoten teilweisemit Beschriftungen versehen sind und erg\"anzt automatisch Beschriftungen f\"urKnoten, die bisher noch keine Beschriftung haben. Dieser Vorgang wird"Klassifizierung" genannt. Dazu verwendet er die Struktur des Graphen sowietextuelle Informationen, die den Knoten zugeordnet sind. Die von Aggarwal undLi beschriebene experimentelle Analyse ergab, dass er auch auf dynamischenGraphen mit 19396 bzw. 806635 Knoten, von denen nur 14814 bzw. 18999beschriftet waren, innerhalb von weniger als einer Minute auf einem Kern einerIntel Xeon 2.5 GHz CPU mit 32 G RAM ausgef\"uhrt werden kann. Zus\"atzlich wirddie Ver\"offentlichung von Aggarwal und Li kritisch er\"ortert und und eswerden m\"ogliche Erweiterungen des DYCOS-Algorithmus vorgeschlagen.
arxiv-13800-251 | Face Alignment Across Large Poses: A 3D Solution | http://arxiv.org/pdf/1511.07212v1.pdf | author:Xiangyu Zhu, Zhen Lei, Xiaoming Liu, Hailin Shi, Stan Z. Li category:cs.CV published:2015-11-23 summary:Face alignment, which fits a face model to an image and extracts the semanticmeanings of facial pixels, has been an important topic in CV community.However, most algorithms are designed for faces in small to medium poses (below45 degree), lacking the ability to align faces in large poses up to 90 degree.The challenges are three-fold: Firstly, the commonly used landmark-based facemodel assumes that all the landmarks are visible and is therefore not suitablefor profile views. Secondly, the face appearance varies more dramaticallyacross large poses, ranging from frontal view to profile view. Thirdly,labelling landmarks in large poses is extremely challenging since the invisiblelandmarks have to be guessed. In this paper, we propose a solution to the threeproblems in an new alignment framework, called 3D Dense Face Alignment (3DDFA),in which a dense 3D face model is fitted to the image via convolutional neutralnetwork (CNN). We also propose a method to synthesize large-scale trainingsamples in profile views to solve the third problem of data labelling.Experiments on the challenging AFLW database show that our approach achievessignificant improvements over state-of-the-art methods.
arxiv-13800-252 | DAG-Recurrent Neural Networks For Scene Labeling | http://arxiv.org/pdf/1509.00552v2.pdf | author:Bing Shuai, Zhen Zuo, Gang Wang, Bing Wang category:cs.CV published:2015-09-02 summary:In image labeling, local representations for image units are usuallygenerated from their surrounding image patches, thus long-range contextualinformation is not effectively encoded. In this paper, we introduce recurrentneural networks (RNNs) to address this issue. Specifically, directed acyclicgraph RNNs (DAG-RNNs) are proposed to process DAG-structured images, whichenables the network to model long-range semantic dependencies among imageunits. Our DAG-RNNs are capable of tremendously enhancing the discriminativepower of local representations, which significantly benefits the localclassification. Meanwhile, we propose a novel class weighting function thatattends to rare classes, which phenomenally boosts the recognition accuracy fornon-frequent classes. Integrating with convolution and deconvolution layers,our DAG-RNNs achieve new state-of-the-art results on the challenging SiftFlow,CamVid and Barcelona benchmarks.
arxiv-13800-253 | A PAC Approach to Application-Specific Algorithm Selection | http://arxiv.org/pdf/1511.07147v1.pdf | author:Rishi Gupta, Tim Roughgarden category:cs.LG cs.DS I.2.6; F.2.0 published:2015-11-23 summary:The best algorithm for a computational problem generally depends on the"relevant inputs," a concept that depends on the application domain and oftendefies formal articulation. While there is a large literature on empiricalapproaches to selecting the best algorithm for a given application domain,there has been surprisingly little theoretical analysis of the problem. This paper adapts concepts from statistical and online learning theory toreason about application-specific algorithm selection. Our models captureseveral state-of-the-art empirical and theoretical approaches to the problem,ranging from self-improving algorithms to empirical performance models, and ourresults identify conditions under which these approaches are guaranteed toperform well. We present one framework that models algorithm selection as astatistical learning problem, and our work here shows that dimension notionsfrom statistical learning theory, historically used to measure the complexityof classes of binary- and real-valued functions, are relevant in a much broaderalgorithmic context. We also study the online version of the algorithmselection problem, and give possibility and impossibility results for theexistence of no-regret learning algorithms.
arxiv-13800-254 | No penalty no tears: Least squares in high-dimensional linear models | http://arxiv.org/pdf/1506.02222v4.pdf | author:Xiangyu Wang, David Dunson, Chenlei Leng category:stat.ME cs.LG math.ST stat.ML stat.TH published:2015-06-07 summary:Ordinary least squares (OLS) is the default method for fitting linear models,but is not applicable for problems with dimensionality larger than the samplesize. For these problems, we advocate the use of a generalized version of OLSmotivated by ridge regression, and propose two novel three-step algorithmsinvolving least squares fitting and hard thresholding. The algorithms aremethodologically simple to understand intuitively, computationally easy toimplement efficiently, and theoretically appealing for choosing modelsconsistently. Numerical exercises comparing our methods with penalization-basedapproaches in simulations and data analyses illustrate the great potential ofthe proposed algorithms.
arxiv-13800-255 | Poisson Subsampling Algorithms for Large Sample Linear Regression in Massive Data | http://arxiv.org/pdf/1509.02116v3.pdf | author:Rong Zhu category:stat.ML published:2015-09-07 summary:Large sample size brings the computation bottleneck for modern data analysis.Subsampling is one of efficient strategies to handle this problem. In previousstudies, researchers make more fo- cus on subsampling with replacement (SSR)than on subsampling without replacement (SSWR). In this paper we investigate akind of SSWR, poisson subsampling (PSS), for fast algorithm in ordinaryleast-square problem. We establish non-asymptotic property, i.e, the errorbound of the correspond- ing subsample estimator, which provide a tradeoffbetween computation cost and approximation efficiency. Besides thenon-asymptotic result, we provide asymptotic consistency and normality of thesubsample estimator. Methodologically, we propose a two-step subsamplingalgorithm, which is efficient with respect to a statistical objective andindependent on the linear model assumption.. Synthetic and real data are usedto empirically study our proposed subsampling strategies. We argue by theseempirical studies that, (1) our proposed two-step algorithm has obviousadvantage when the assumed linear model does not accurate, and (2) the PSSstrategy performs obviously better than SSR when the subsampling ratioincreases.
arxiv-13800-256 | Parallel Predictive Entropy Search for Batch Global Optimization of Expensive Objective Functions | http://arxiv.org/pdf/1511.07130v1.pdf | author:Amar Shah, Zoubin Ghahramani category:cs.LG stat.ML published:2015-11-23 summary:We develop parallel predictive entropy search (PPES), a novel algorithm forBayesian optimization of expensive black-box objective functions. At eachiteration, PPES aims to select a batch of points which will maximize theinformation gain about the global maximizer of the objective. Well knownstrategies exist for suggesting a single evaluation point based on previousobservations, while far fewer are known for selecting batches of points toevaluate in parallel. The few batch selection schemes that have been studiedall resort to greedy methods to compute an optimal batch. To the best of ourknowledge, PPES is the first non-greedy batch Bayesian optimization strategy.We demonstrate the benefit of this approach in optimization performance on bothsynthetic and real world applications, including problems in machine learning,rocket science and robotics.
arxiv-13800-257 | What Happened to My Dog in That Network: Unraveling Top-down Generators in Convolutional Neural Networks | http://arxiv.org/pdf/1511.07125v1.pdf | author:Patrick W. Gallagher, Shuai Tang, Zhuowen Tu category:cs.NE cs.CV cs.LG stat.ML published:2015-11-23 summary:Top-down information plays a central role in human perception, but playsrelatively little role in many current state-of-the-art deep networks, such asConvolutional Neural Networks (CNNs). This work seeks to explore a path bywhich top-down information can have a direct impact within current deepnetworks. We explore this path by learning and using "generators" correspondingto the network internal effects of three types of transformation (each arestriction of a general affine transformation): rotation, scaling, andtranslation. We demonstrate how these learned generators can be used totransfer top-down information to novel settings, as mediated by the "featureflows" that the transformations (and the associated generators) correspond toinside the network. Specifically, we explore three aspects: 1) using generatorsas part of a method for synthesizing transformed images --- given a previouslyunseen image, produce versions of that image corresponding to one or morespecified transformations, 2) "zero-shot learning" --- when provided with afeature flow corresponding to the effect of a transformation of unknown amount,leverage learned generators as part of a method by which to perform an accuratecategorization of the amount of transformation, even for amounts never observedduring training, and 3) (inside-CNN) "data augmentation" --- improve theclassification performance of an existing network by using the learnedgenerators to directly provide additional training "inside the CNN".
arxiv-13800-258 | Hierarchical Spatial Sum-Product Networks for action recognition in Still Images | http://arxiv.org/pdf/1511.05292v2.pdf | author:Jinghua Wang, Gang Wang category:cs.CV published:2015-11-17 summary:Recognizing actions from still images is popularly studied recently. In thispaper, we model an action class as a flexible number of spatial configurationsof body parts by proposing a new spatial SPN (Sum-Product Networks). First, wediscover a set of parts in image collections via unsupervised learning. Then,our new spatial SPN is applied to model the spatial relationship and also thehigh-order correlations of parts. To learn robust networks, we further developa hierarchical spatial SPN method, which models pairwise spatial relationshipbetween parts inside sub-images and models the correlation of sub-images viaextra layers of SPN. Our method is shown to be effective on two benchmarkdatasets.
arxiv-13800-259 | Towards Predicting the Likeability of Fashion Images | http://arxiv.org/pdf/1511.05296v2.pdf | author:Jinghua Wang, Abrar Abdul Nabi, Gang Wang, Chengde Wan, Tian-Tsong Ng category:cs.CV published:2015-11-17 summary:In this paper, we propose a method for ranking fashion images to find theones which might be liked by more people. We collect two new datasets fromimage sharing websites (Pinterest and Polyvore). We represent fashion imagesbased on attributes: semantic attributes and data-driven attributes. To learnsemantic attributes from limited training data, we use an algorithm onmulti-task convolutional neural networks to share visual knowledge amongdifferent semantic attribute categories. To discover data-driven attributesunsupervisedly, we propose an algorithm to simultaneously discover visualclusters and learn fashion-specific feature representations. Given attributesas representations, we propose to learn a ranking SPN (sum product networks) torank pairs of fashion images. The proposed ranking SPN can capture thehigh-order correlations of the attributes. We show the effectiveness of ourmethod on our two newly collected datasets.
arxiv-13800-260 | Object-Proposal Evaluation Protocol is 'Gameable' | http://arxiv.org/pdf/1505.05836v4.pdf | author:Neelima Chavali, Harsh Agrawal, Aroma Mahendru, Dhruv Batra category:cs.CV published:2015-05-21 summary:Object proposals have quickly become the de-facto pre-processing step in anumber of vision pipelines (for object detection, object discovery, and othertasks). Their performance is usually evaluated on partially annotated datasets.In this paper, we argue that the choice of using a partially annotated datasetfor evaluation of object proposals is problematic -- as we demonstrate via athought experiment, the evaluation protocol is 'gameable', in the sense thatprogress under this protocol does not necessarily correspond to a "better"category independent object proposal algorithm. To alleviate this problem, we: (1) Introduce a nearly-fully annotated versionof PASCAL VOC dataset, which serves as a test-bed to check if object proposaltechniques are overfitting to a particular list of categories. (2) Perform anexhaustive evaluation of object proposal methods on our introduced nearly-fullyannotated PASCAL dataset and perform cross-dataset generalization experiments;and (3) Introduce a diagnostic experiment to detect the bias capacity in anobject proposal algorithm. This tool circumvents the need to collect a denselyannotated dataset, which can be expensive and cumbersome to collect. Finally,we plan to release an easy-to-use toolbox which combines various publiclyavailable implementations of object proposal algorithms which standardizes theproposal generation and evaluation so that new methods can be added andevaluated on different datasets. We hope that the results presented in thepaper will motivate the community to test the category independence of variousobject proposal methods by carefully choosing the evaluation protocol.
arxiv-13800-261 | Bayesian Evidence and Model Selection | http://arxiv.org/pdf/1411.3013v2.pdf | author:Kevin H. Knuth, Michael Habeck, Nabin K. Malakar, Asim M. Mubeen, Ben Placek category:stat.ME astro-ph.IM stat.AP stat.CO stat.ML published:2014-11-11 summary:In this paper we review the concepts of Bayesian evidence and Bayes factors,also known as log odds ratios, and their application to model selection. Thetheory is presented along with a discussion of analytic, approximate andnumerical techniques. Specific attention is paid to the Laplace approximation,variational Bayes, importance sampling, thermodynamic integration, and nestedsampling and its recent variants. Analogies to statistical physics, from whichmany of these techniques originate, are discussed in order to provide readerswith deeper insights that may lead to new techniques. The utility of Bayesianmodel testing in the domain sciences is demonstrated by presenting fourspecific practical examples considered within the context of signal processingin the areas of signal detection, sensor characterization, scientific modelselection and molecular force characterization.
arxiv-13800-262 | Optimal Learning via the Fourier Transform for Sums of Independent Integer Random Variables | http://arxiv.org/pdf/1505.00662v2.pdf | author:Ilias Diakonikolas, Daniel M. Kane, Alistair Stewart category:cs.DS cs.IT cs.LG math.IT math.ST stat.TH published:2015-05-04 summary:We study the structure and learnability of sums of independent integer randomvariables (SIIRVs). For $k \in \mathbb{Z}_{+}$, a $k$-SIIRV of order $n \in\mathbb{Z}_{+}$ is the probability distribution of the sum of $n$ independentrandom variables each supported on $\{0, 1, \dots, k-1\}$. We denote by ${\calS}_{n,k}$ the set of all $k$-SIIRVs of order $n$. In this paper, we tightly characterize the sample and computationalcomplexity of learning $k$-SIIRVs. More precisely, we design a computationallyefficient algorithm that uses $\widetilde{O}(k/\epsilon^2)$ samples, and learnsan arbitrary $k$-SIIRV within error $\epsilon,$ in total variation distance.Moreover, we show that the {\em optimal} sample complexity of this learningproblem is $\Theta((k/\epsilon^2)\sqrt{\log(1/\epsilon)}).$ Our algorithmproceeds by learning the Fourier transform of the target $k$-SIIRV in itseffective support. Its correctness relies on the {\em approximate sparsity} ofthe Fourier transform of $k$-SIIRVs -- a structural property that we establish,roughly stating that the Fourier transform of $k$-SIIRVs has small magnitudeoutside a small set. Along the way we prove several new structural results about $k$-SIIRVs. Asone of our main structural contributions, we give an efficient algorithm toconstruct a sparse {\em proper} $\epsilon$-cover for ${\cal S}_{n,k},$ in totalvariation distance. We also obtain a novel geometric characterization of thespace of $k$-SIIRVs. Our characterization allows us to prove a tight lowerbound on the size of $\epsilon$-covers for ${\cal S}_{n,k}$, and is the keyingredient in our tight sample complexity lower bound. Our approach of exploiting the sparsity of the Fourier transform indistribution learning is general, and has recently found additionalapplications.
arxiv-13800-263 | ElSe: Ellipse Selection for Robust Pupil Detection in Real-World Environments | http://arxiv.org/pdf/1511.06575v2.pdf | author:Wolfgang Fuhl, Thiago C. Santini, Thomas Kuebler, Enkelejda Kasneci category:cs.CV I.4.3; I.4.8 published:2015-11-20 summary:Fast and robust pupil detection is an essential prerequisite for video-basedeye-tracking in real-world settings. Several algorithms for image-based pupildetection have been proposed, their applicability is mostly limited tolaboratory conditions. In realworld scenarios, automated pupil detection has toface various challenges, such as illumination changes, reflections (onglasses), make-up, non-centered eye recording, and physiological eyecharacteristics. We propose ElSe, a novel algorithm based on ellipse evaluationof a filtered edge image. We aim at a robust, resource-saving approach that canbe integrated in embedded architectures e.g. driving. The proposed algorithmwas evaluated against four state-of-the-art methods on over 93,000 hand-labeledimages from which 55,000 are new images contributed by this work. On average,the proposed method achieved a 14.53% improvement on the detection raterelative to the best state-of-the-art performer.download:ftp://emmapupildata@messor.informatik.unituebingen. de(password:eyedata).
arxiv-13800-264 | Deep Compositional Question Answering with Neural Module Networks | http://arxiv.org/pdf/1511.02799v2.pdf | author:Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein category:cs.CV cs.CL cs.LG cs.NE published:2015-11-09 summary:Visual question answering is fundamentally compositional in nature---aquestion like "where is the dog?" shares substructure with questions like "whatcolor is the dog?" and "where is the cat?" This paper seeks to simultaneouslyexploit the representational capacity of deep networks and the compositionallinguistic structure of questions. We describe a procedure for constructing andlearning *neural module networks*, which compose collections of jointly-trainedneural "modules" into deep networks for question answering. Our approachdecomposes questions into their linguistic substructures, and uses thesestructures to dynamically instantiate modular networks (with reusablecomponents for recognizing dogs, classifying colors, etc.). The resultingcompound networks are jointly trained. We evaluate our approach on twochallenging datasets for visual question answering, achieving state-of-the-artresults on both the VQA natural image dataset and a new dataset of complexquestions about abstract shapes.
arxiv-13800-265 | Cascading Denoising Auto-Encoder as a Deep Directed Generative Model | http://arxiv.org/pdf/1511.07118v1.pdf | author:Dong-Hyun Lee category:cs.LG published:2015-11-23 summary:Recent work (Bengio et al., 2013) has shown howDenoising Auto-Encoders(DAE)become gener-ative models as a density estimator. However,in practice, theframework suffers from a mixingproblem in the MCMC sampling process andnodirect method to estimate the test log-likelihood.We consider a directedmodel with an stochas-tic identity mapping (simple corruption pro-cess) as aninference model and a DAE as agenerative model. By cascading these mod-els, wepropose Cascading Denoising Auto-Encoders(CDAE) which can generate samplesofdata distribution from tractable prior distributionunder the assumption thatprobabilistic distribu-tion of corrupted data approaches tractablepriordistribution as the level of corruption increases.This work tries toanswer two questions. On theone hand, can deep directed models be success-fullytrained without intractable posterior infer-ence and difficult optimization ofvery deep neu-ral networks in inference and generative mod-els? These areunavoidable when recent suc-cessful directed model like VAE (Kingma &Welling,2014) is trained on complex dataset likereal images. On the other hand, canDAEs getclean samples of data distribution from heavilycorrupted samples whichcan be considered oftractable prior distribution far from data mani-fold?so-called global denoising scheme.Our results show positive responses ofthesequestions and this work can provide fairly simpleframework for generativemodels of very com-plex dataset.
arxiv-13800-266 | On the Generalization Error Bounds of Neural Networks under Diversity-Inducing Mutual Angular Regularization | http://arxiv.org/pdf/1511.07110v1.pdf | author:Pengtao Xie, Yuntian Deng, Eric Xing category:cs.LG published:2015-11-23 summary:Recently diversity-inducing regularization methods for latent variable models(LVMs), which encourage the components in LVMs to be diverse, have been studiedto address several issues involved in latent variable modeling: (1) how tocapture long-tail patterns underlying data; (2) how to reduce model complexitywithout sacrificing expressivity; (3) how to improve the interpretability oflearned patterns. While the effectiveness of diversity-inducing regularizerssuch as the mutual angular regularizer has been demonstrated empirically, arigorous theoretical analysis of them is still missing. In this paper, we aimto bridge this gap and analyze how the mutual angular regularizer (MAR) affectsthe generalization performance of supervised LVMs. We use neural network (NN)as a model instance to carry out the study and the analysis shows thatincreasing the diversity of hidden units in NN would reduce estimation errorand increase approximation error. In addition to theoretical analysis, we alsopresent empirical study which demonstrates that the MAR can greatly improve theperformance of NN and the empirical observations are in accordance with thetheoretical analysis.
arxiv-13800-267 | A Likelihood Ratio Framework for High Dimensional Semiparametric Regression | http://arxiv.org/pdf/1412.2295v2.pdf | author:Yang Ning, Tianqi Zhao, Han Liu category:stat.ML published:2014-12-06 summary:We propose a likelihood ratio based inferential framework for highdimensional semiparametric generalized linear models. This framework addressesa variety of challenging problems in high dimensional data analysis, includingincomplete data, selection bias, and heterogeneous multitask learning. Our workhas three main contributions. (i) We develop a regularized statisticalchromatography approach to infer the parameter of interest under the proposedsemiparametric generalized linear model without the need of estimating theunknown base measure function. (ii) We propose a new framework to constructpost-regularization confidence regions and tests for the low dimensionalcomponents of high dimensional parameters. Unlike existing post-regularizationinferential methods, our approach is based on a novel directional likelihood.In particular, the framework naturally handles generic regularized estimatorswith nonconvex penalty functions and it can be used to infer least falseparameters under misspecified models. (iii) We develop new concentrationinequalities and normal approximation results for U-statistics with unboundedkernels, which are of independent interest. We demonstrate the consequences ofthe general theory by using an example of missing data problem. Extensivesimulation studies and real data analysis are provided to illustrate ourproposed approach.
arxiv-13800-268 | Multi-Volume High Resolution RGB-D Mapping with Dynamic Volume Placement | http://arxiv.org/pdf/1511.07106v1.pdf | author:Michael Salvato, Ross Finman, John Leonard category:cs.RO cs.CV published:2015-11-23 summary:We present a novel RGB-D mapping system for generating 3D maps over spatiallyextended regions with higher resolution than current methods using multiple,dynamically placed mapping volumes. Our method takes in RGB-D frames anddynamically assigns multiple mapping volumes to the environment, exchangingmapping volumes between the CPU and GPU. Mapping volumes are added or removedas needed to allow for spatially extended, high resolution mapping. Our systemis designed to maximize the resolution possible for such volumetric methods,while working on an unbounded space.
arxiv-13800-269 | Optimal Subsampling Approaches for Large Sample Linear Regression | http://arxiv.org/pdf/1509.05111v2.pdf | author:Rong Zhu, Ping Ma, Michael W. Mahoney, Bin Yu category:stat.ME stat.ML published:2015-09-17 summary:A significant hurdle for analyzing large sample data is the lack of effectivestatistical computing and inference methods. An emerging powerful approach foranalyzing large sample data is subsampling, by which one takes a randomsubsample from the original full sample and uses it as a surrogate forsubsequent computation and estimation. In this paper, we study subsamplingmethods under two scenarios: approximating the full sample ordinaryleast-square (OLS) estimator and estimating the coefficients in linearregression. We present two algorithms, weighted estimation algorithm andunweighted estimation algorithm, and analyze asymptotic behaviors of theirresulting subsample estimators under general conditions. For the weightedestimation algorithm, we propose a criterion for selecting the optimal samplingprobability by making use of the asymptotic results. On the basis of thecriterion, we provide two novel subsampling methods, the optimal subsamplingand the predictor- length subsampling methods. The predictor-length subsamplingmethod is based on the L2 norm of predictors rather than leverage scores. Itscomputational cost is scalable. For unweighted estimation algorithm, we showthat its resulting subsample estimator is not consistent to the full sample OLSestimator. However, it has better performance than the weighted estimationalgorithm for estimating the coefficients. Simulation studies and a real dataexample are used to demonstrate the effectiveness of our proposed subsamplingmethods.
arxiv-13800-270 | Multiple--Instance Learning: Christoffel Function Approach to Distribution Regression Problem | http://arxiv.org/pdf/1511.07085v1.pdf | author:Vladislav Gennadievich Malyshkin category:cs.LG published:2015-11-22 summary:A two--step Christoffel function based solution is proposed to distributionregression problem. On the first step, to model distribution of observationsinside a bag, build Christoffel function for each bag of observations. Then, onthe second step, build outcome variable Christoffel function, but use the bag'sChristoffel function value at given point as the weight for the bag's outcome.The approach allows the result to be obtained in closed form and then to beevaluated numerically. While most of existing approaches minimize some kind anerror between outcome and prediction, the proposed approach is conceptuallydifferent, because it uses Christoffel function for knowledge representation,what is conceptually equivalent working with probabilities only. To receivepossible outcomes and their probabilities Gauss quadrature for second--stepmeasure can be built, then the nodes give possible outcomes and normalizedweights -- outcome probabilities. A library providing numerically stablepolynomial basis for these calculations is available, what make the proposedapproach practical.
arxiv-13800-271 | A Plausible Memristor Implementation of Deep Learning Neural Networks | http://arxiv.org/pdf/1511.07076v1.pdf | author:D. V. Negrov, I. M. Karandashev, V. V. Shakirov, Yu. A. Matveyev, W. L. Dunin-Barkowski, A. V. Zenkevich category:cs.NE cs.ET published:2015-11-22 summary:A possible method for hardware implementation of multilayer neural networkswith the back-propagation learning algorithm employing memristor cross-barmatrices for weight storage is modeled. The proposed approach offers anefficient way to perform both learning and recognition operations. The solutionof several arising problems, such as the representation and multiplication ofsignals as well as error propagation is proposed.
arxiv-13800-272 | Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings Using Abstract Scenes | http://arxiv.org/pdf/1511.07067v1.pdf | author:Satwik Kottur, Ramakrishna Vedantam, JosÃ© M. F. Moura, Devi Parikh category:cs.CV cs.CL published:2015-11-22 summary:We propose a model to learn visually grounded word embeddings (vis-w2v) tocapture visual notions of semantic relatedness. While word embeddings trainedusing text have been extremely successful, they cannot uncover notions ofsemantic relatedness implicit in our visual world. For instance, visualgrounding can help us realize that concepts like eating and staring at arerelated, since when people are eating something, they also tend to stare at thefood. Grounding a rich variety of relations like eating and stare at in visionis a challenging task, despite recent progress in vision. We realize the visualgrounding for words depends on the semantics of our visual world, and not theliteral pixels. We thus use abstract scenes created from clipart to provide thevisual grounding. We find that the embeddings we learn capture fine-grainedvisually grounded notions of semantic relatedness. We show improvements overtext only word embeddings (word2vec) on three tasks: common-sense assertionclassification, visual paraphrasing and text-based image retrieval. Our codeand datasets will be available online.
arxiv-13800-273 | Fine-grained pose prediction, normalization, and recognition | http://arxiv.org/pdf/1511.07063v1.pdf | author:Ning Zhang, Evan Shelhamer, Yang Gao, Trevor Darrell category:cs.CV published:2015-11-22 summary:Pose variation and subtle differences in appearance are key challenges tofine-grained classification. While deep networks have markedly improved generalrecognition, many approaches to fine-grained recognition rely on anchoringnetworks to parts for better accuracy. Identifying parts to find correspondencediscounts pose variation so that features can be tuned to appearance. To thisend previous methods have examined how to find parts and extractpose-normalized features. These methods have generally separated fine-grainedrecognition into stages which first localize parts using hand-engineered andcoarsely-localized proposal features, and then separately learn deepdescriptors centered on inferred part positions. We unify these steps in anend-to-end trainable network supervised by keypoint locations and class labelsthat localizes parts by a fully convolutional network to focus the learning offeature representations for the fine-grained classification task. Experimentson the popular CUB200 dataset show that our method is state-of-the-art andsuggest a continuing role for strong supervision.
arxiv-13800-274 | Strategic Classification | http://arxiv.org/pdf/1506.06980v2.pdf | author:Moritz Hardt, Nimrod Megiddo, Christos Papadimitriou, Mary Wootters category:cs.LG published:2015-06-23 summary:Machine learning relies on the assumption that unseen test instances of aclassification problem follow the same distribution as observed training data.However, this principle can break down when machine learning is used to makeimportant decisions about the welfare (employment, education, health) ofstrategic individuals. Knowing information about the classifier, suchindividuals may manipulate their attributes in order to obtain a betterclassification outcome. As a result of this behavior---often referred to asgaming---the performance of the classifier may deteriorate sharply. Indeed,gaming is a well-known obstacle for using machine learning methods in practice;in financial policy-making, the problem is widely known as Goodhart's law. Inthis paper, we formalize the problem, and pursue algorithms for learningclassifiers that are robust to gaming. We model classification as a sequential game between a player named "Jury"and a player named "Contestant." Jury designs a classifier, and Contestantreceives an input to the classifier, which he may change at some cost. Jury'sgoal is to achieve high classification accuracy with respect to Contestant'soriginal input and some underlying target classification function. Contestant'sgoal is to achieve a favorable classification outcome while taking into accountthe cost of achieving it. For a natural class of cost functions, we obtain computationally efficientlearning algorithms which are near-optimal. Surprisingly, our algorithms areefficient even on concept classes that are computationally hard to learn. Forgeneral cost functions, designing an approximately optimal strategy-proofclassifier, for inverse-polynomial approximation, is NP-hard.
arxiv-13800-275 | Learning Deep $\ell_0$ Encoders | http://arxiv.org/pdf/1509.00153v2.pdf | author:Zhangyang Wang, Qing Ling, Thomas S. Huang category:cs.LG stat.ML published:2015-09-01 summary:Despite its nonconvex nature, $\ell_0$ sparse approximation is desirable inmany theoretical and application cases. We study the $\ell_0$ sparseapproximation problem with the tool of deep learning, by proposing Deep$\ell_0$ Encoders. Two typical forms, the $\ell_0$ regularized problem and the$M$-sparse problem, are investigated. Based on solid iterative algorithms, wemodel them as feed-forward neural networks, through introducing novel neuronsand pooling functions. Enforcing such structural priors acts as an effectivenetwork regularization. The deep encoders also enjoy faster inference, largerlearning capacity, and better scalability compared to conventional sparsecoding solutions. Furthermore, under task-driven losses, the models can beconveniently optimized from end to end. Numerical results demonstrate theimpressive performances of the proposed encoders.
arxiv-13800-276 | Anvaya: An Algorithm and Case-Study on Improving the Goodness of Software Process Models generated by Mining Event-Log Data in Issue Tracking System | http://arxiv.org/pdf/1511.07023v1.pdf | author:Prerna Juneja, Divya Kundra, Ashish Sureka category:cs.SE cs.LG published:2015-11-22 summary:Issue Tracking Systems (ITS) such as Bugzilla can be viewed as Process AwareInformation Systems (PAIS) generating event-logs during the life-cycle of a bugreport. Process Mining consists of mining event logs generated from PAIS forprocess model discovery, conformance and enhancement. We apply process mapdiscovery techniques to mine event trace data generated from ITS of open sourceFirefox browser project to generate and study process models. Bug life-cycleconsists of diversity and variance. Therefore, the process models generatedfrom the event-logs are spaghetti-like with large number of edges,inter-connections and nodes. Such models are complex to analyse and difficultto comprehend by a process analyst. We improve the Goodness (fitness andstructural complexity) of the process models by splitting the event-log intohomogeneous subsets by clustering structurally similar traces. We adapt theK-Medoid clustering algorithm with two different distance metrics: LongestCommon Subsequence (LCS) and Dynamic Time Warping (DTW). We evaluate thegoodness of the process models generated from the clusters using complexity andfitness metrics. We study back-forth \& self-loops, bug reopening, andbottleneck in the clusters obtained and show that clustering enables betteranalysis. We also propose an algorithm to automate the clustering process -thealgorithm takes as input the event log and returns the best cluster set.
arxiv-13800-277 | Principal Geodesic Analysis for Probability Measures under the Optimal Transport Metric | http://arxiv.org/pdf/1506.07944v2.pdf | author:Vivien Seguy, Marco Cuturi category:stat.ML published:2015-06-26 summary:Given a family of probability measures in P(X), the space of probabilitymeasures on a Hilbert space X, our goal in this paper is to highlight one oremore curves in P(X) that summarize efficiently that family. We propose to studythis problem under the optimal transport (Wasserstein) geometry, using curvesthat are restricted to be geodesic segments under that metric. We show thatconcepts that play a key role in Euclidean PCA, such as data centering ororthogonality of principal directions, find a natural equivalent in the optimaltransport geometry, using Wasserstein means and differential geometry. Theimplementation of these ideas is, however, computationally challenging. Toachieve scalable algorithms that can handle thousands of measures, we proposeto use a relaxed definition for geodesics and regularized optimal transportdistances. The interest of our approach is demonstrated on images seen eitheras shapes or color histograms.
arxiv-13800-278 | Analysis of a Play by Means of CHAPLIN, the Characters and Places Interaction Network Software | http://arxiv.org/pdf/1511.07001v1.pdf | author:A. C. Sparavigna, R. Marazzato category:cs.CY cs.CL cs.SI published:2015-11-22 summary:Recently, we have developed a software able of gathering information onsocial networks from written texts. This software, the CHAracters and PLacesInteraction Network (CHAPLIN) tool, is implemented in Visual Basic. By means ofit, characters and places of a literary work can be extracted from a list ofraw words. The software interface helps users to select their names out of thislist. Setting some parameters, CHAPLIN creates a network where nodes representcharacters/places and edges give their interactions. Nodes and edges arelabelled by performances. In this paper, we propose to use CHAPLIN for theanalysis a William Shakespeare's play, the famous 'Tragedy of Hamlet, Prince ofDenmark'. Performances of characters in the play as a whole and in each act ofit are given by graphs.
arxiv-13800-279 | Non-Sentential Utterances in Dialogue: Experiments in Classification and Interpretation | http://arxiv.org/pdf/1511.06995v1.pdf | author:Paolo Dragone category:cs.CL cs.AI published:2015-11-22 summary:Non-sentential utterances (NSUs) are utterances that lack a completesentential form but whose meaning can be inferred from the dialogue context,such as "OK", "where?", "probably at his apartment". The interpretation ofnon-sentential utterances is an important problem in computational linguisticssince they constitute a frequent phenomena in dialogue and they areintrinsically context-dependent. The interpretation of NSUs is the task ofretrieving their full semantic content from their form and the dialoguecontext. The first half of this thesis is devoted to the NSU classificationtask. Our work builds upon Fern\'andez et al. (2007) which present a series ofmachine-learning experiments on the classification of NSUs. We extended theirapproach with a combination of new features and semi-supervised learningtechniques. The empirical results presented in this thesis show a modest butsignificant improvement over the state-of-the-art classification performance.The consecutive, yet independent, problem is how to infer an appropriatesemantic representation of such NSUs on the basis of the dialogue context.Fern\'andez (2006) formalizes this task in terms of "resolution rules" built ontop of the Type Theory with Records (TTR). Our work is focused on thereimplementation of the resolution rules from Fern\'andez (2006) with aprobabilistic account of the dialogue state. The probabilistic rules formalismLison (2014) is particularly suited for this task because, similarly to theframework developed by Ginzburg (2012) and Fern\'andez (2006), it involves thespecification of update rules on the variables of the dialogue state to capturethe dynamics of the conversation. However, the probabilistic rules can alsoencode probabilistic knowledge, thereby providing a principled account ofambiguities in the NSU resolution process.
arxiv-13800-280 | Learning High-level Prior with Convolutional Neural Networks for Semantic Segmentation | http://arxiv.org/pdf/1511.06988v1.pdf | author:Haitian Zheng, Yebin Liu, Mengqi Ji, Feng Wu, Lu Fang category:cs.CV published:2015-11-22 summary:This paper proposes a convolutional neural network that can fuse high-levelprior for semantic image segmentation. Motivated by humans' vision recognitionsystem, our key design is a three-layer generative structure consisting ofhigh-level coding, middle-level segmentation and low-level image to introduceglobal prior for semantic segmentation. Based on this structure, we proposed agenerative model called conditional variational auto-encoder (CVAE) that canbuild up the links behind these three layers. These important links include animage encoder that extracts high level info from image, a segmentation encoderthat extracts high level info from segmentation, and a hybrid decoder thatoutputs semantic segmentation from the high level prior and input image. Wetheoretically derive the semantic segmentation as an optimization problemparameterized by these links. Finally, the optimization problem enables us totake advantage of state-of-the-art fully convolutional network structure forthe implementation of the above encoders and decoder. Experimental results onseveral representative datasets demonstrate our supreme performance forsemantic segmentation.
arxiv-13800-281 | Evolutionary algorithms | http://arxiv.org/pdf/1511.06987v1.pdf | author:Anton V. Eremeev category:cs.NE published:2015-11-22 summary:This manuscript contains an outline of lectures course "EvolutionaryAlgorithms" read by the author in Omsk State University n.a. F.M.Dostoevsky.The course covers Canonic Genetic Algorithm and various other geneticalgorithms as well as evolutioanry algorithms in general. Some facts, such asthe Rotation Property of crossover, the Schemata Theorem, GA performance as alocal search and "almost surely" convergence of evolutionary algorithms aregiven with complete proofs. The text is in Russian.
arxiv-13800-282 | End-to-end Learning of Action Detection from Frame Glimpses in Videos | http://arxiv.org/pdf/1511.06984v1.pdf | author:Serena Yeung, Olga Russakovsky, Greg Mori, Li Fei-Fei category:cs.CV cs.LG published:2015-11-22 summary:In this work we introduce a fully end-to-end approach for action detection invideos that learns to directly predict the temporal bounds of actions. Ourintuition is that the process of detecting actions is naturally one ofobservation and refinement: observing moments in video, and refining hypothesesabout when an action is occurring. Based on this insight, we formulate ourmodel as a recurrent neural network-based agent that interacts with a videoover time. The agent observes video frames and decides both where to look nextand when to emit a prediction. Since backpropagation is not adequate in thisnon-differentiable setting, we use REINFORCE to learn the agent's decisionpolicy. Our model achieves state-of-the-art results on the THUMOS'14 andActivityNet datasets while observing only a fraction (2% or less) of the videoframes.
arxiv-13800-283 | On the Linear Algebraic Structure of Distributed Word Representations | http://arxiv.org/pdf/1511.06961v1.pdf | author:Lisa Seung-Yeon Lee category:cs.CL cs.LG published:2015-11-22 summary:In this work, we leverage the linear algebraic structure of distributed wordrepresentations to automatically extend knowledge bases and allow a machine tolearn new facts about the world. Our goal is to extract structured facts fromcorpora in a simpler manner, without applying classifiers or patterns, andusing only the co-occurrence statistics of words. We demonstrate that thelinear algebraic structure of word embeddings can be used to reduce datarequirements for methods of learning facts. In particular, we demonstrate thatwords belonging to a common category, or pairs of words satisfying a certainrelation, form a low-rank subspace in the projected space. We compute a basisfor this low-rank subspace using singular value decomposition (SVD), then usethis basis to discover new facts and to fit vectors for less frequent wordswhich we do not yet have vectors for.
arxiv-13800-284 | LooseCut: Interactive Image Segmentation with Loosely Bounded Boxes | http://arxiv.org/pdf/1507.03060v2.pdf | author:Hongkai Yu, Youjie Zhou, Hui Qian, Min Xian, Yuewei Lin, Dazhou Guo, Kang Zheng, Kareem Abdelfatah, Song Wang category:cs.CV published:2015-07-11 summary:One popular approach to interactively segment the foreground object ofinterest from an image is to annotate a bounding box that covers the foregroundobject. Then, a binary labeling is performed to achieve a refined segmentation.One major issue of the existing algorithms for such interactive imagesegmentation is their preference of an input bounding box that tightly enclosesthe foreground object. This increases the annotation burden, and prevents thesealgorithms from utilizing automatically detected bounding boxes. In this paper,we develop a new LooseCut algorithm that can handle cases where the inputbounding box only loosely covers the foreground object. We propose a new MarkovRandom Fields (MRF) model for segmentation with loosely bounded boxes,including a global similarity constraint to better distinguish the foregroundand background, and an additional energy term to encourage consistent labelingof similar-appearance pixels. This MRF model is then solved by an iteratedmax-flow algorithm. In the experiments, we evaluate LooseCut in threepublicly-available image datasets, and compare its performance against severalstate-of-the-art interactive image segmentation algorithms. We also show thatLooseCut can be used for enhancing the performance of unsupervised videosegmentation and image saliency detection.
arxiv-13800-285 | Gradual DropIn of Layers to Train Very Deep Neural Networks | http://arxiv.org/pdf/1511.06951v1.pdf | author:Leslie N. Smith, Emily M. Hand, Timothy Doster category:cs.NE cs.CV cs.LG published:2015-11-22 summary:We introduce the concept of dynamically growing a neural network duringtraining. In particular, an untrainable deep network starts as a trainableshallow network and newly added layers are slowly, organically added duringtraining, thereby increasing the network's depth. This is accomplished by a newlayer, which we call DropIn. The DropIn layer starts by passing the output froma previous layer (effectively skipping over the newly added layers), thenincreasingly including units from the new layers for both feedforward andbackpropagation. We show that deep networks, which are untrainable withconventional methods, will converge with DropIn layers interspersed in thearchitecture. In addition, we demonstrate that DropIn provides regularizationduring training in an analogous way as dropout. Experiments are described withthe MNIST dataset and various expanded LeNet architectures, CIFAR-10 datasetwith its architecture expanded from 3 to 11 layers, and on the ImageNet datasetwith the AlexNet architecture expanded to 13 layers and the VGG 16-layerarchitecture.
arxiv-13800-286 | Real-Time Anomaly Detection and Localization in Crowded Scenes | http://arxiv.org/pdf/1511.06936v1.pdf | author:Mohammad Sabokrou, Mahmood Fathy, Mojtaba Hosseini, Reinhard Klette category:cs.CV published:2015-11-21 summary:In this paper, we propose a method for real-time anomaly detection andlocalization in crowded scenes. Each video is defined as a set ofnon-overlapping cubic patches, and is described using two local and globaldescriptors. These descriptors capture the video properties from differentaspects. By incorporating simple and cost-effective Gaussian classifiers, wecan distinguish normal activities and anomalies in videos. The local and globalfeatures are based on structure similarity between adjacent patches and thefeatures learned in an unsupervised way, using a sparse auto- encoder.Experimental results show that our algorithm is comparable to astate-of-the-art procedure on UCSD ped2 and UMN benchmarks, but even moretime-efficient. The experiments confirm that our system can reliably detect andlocalize anomalies as soon as they happen in a video.
arxiv-13800-287 | Semantic Segmentation of Colon Glands with Deep Convolutional Neural Networks and Total Variation Segmentation | http://arxiv.org/pdf/1511.06919v1.pdf | author:Philipp Kainz, Michael Pfeiffer, Martin Urschler category:cs.CV published:2015-11-21 summary:Segmentation of histopathology sections is an ubiquitous requirement indigital pathology and due to the large variability of biological tissue,machine learning techniques have shown superior performance over standard imageprocessing methods. As part of the GlaS@MICCAI2015 colon gland segmentationchallenge, we present a learning-based algorithm to segment glands in tissue ofbenign and malignant colorectal cancer. Images are preprocessed according tothe Hematoxylin-Eosin staining protocol and two deep convolutional neuralnetworks (CNN) are trained as pixel classifiers. The CNN predictions are thenregularized using a figure-ground segmentation based on weighted totalvariation to produce the final segmentation result. On two test sets, ourapproach achieves a tissue classification accuracy of 98% and 94%, making useof the inherent capability of our system to distinguish between benign andmalignant tissue.
arxiv-13800-288 | Predicting online user behaviour using deep learning algorithms | http://arxiv.org/pdf/1511.06247v2.pdf | author:Armando Vieira category:cs.LG stat.ML published:2015-11-19 summary:We propose a robust classifier to predict buying intentions based on userbehaviour within a large e-commerce website. In this work we comparetraditional machine learning techniques with the most advanced deep learningapproaches. We show that both Deep Belief Networks and Stacked Denoisingauto-Encoders achieved a substantial improvement by extracting features fromhigh dimensional data during the pre-train phase. They prove also to be moreconvenient to deal with severe class imbalance.
arxiv-13800-289 | Screen Content Image Segmentation Using Sparse-Smooth Decomposition | http://arxiv.org/pdf/1511.06911v1.pdf | author:Shervin Minaee, Amirali Abdolrashidi, Yao Wang category:cs.CV published:2015-11-21 summary:Sparse decomposition has been extensively used for different applicationsincluding signal compression and denoising and document analysis. In thispaper, sparse decomposition is used for image segmentation. The proposedalgorithm separates the background and foreground using a sparse-smoothdecomposition technique such that the smooth and sparse components correspondto the background and foreground respectively. This algorithm is tested onseveral test images from HEVC test sequences and is shown to have superiorperformance over other methods, such as the hierarchical k-means clustering inDjVu. This segmentation algorithm can also be used for text extraction, videocompression and medical image segmentation.
arxiv-13800-290 | ICU Patient Deterioration prediction: a Data-Mining Approach | http://arxiv.org/pdf/1511.06910v1.pdf | author:Noura AlNuaimi, Mohammad M Masud, Farhan Mohammed category:cs.CY cs.LG published:2015-11-21 summary:A huge amount of medical data is generated every day, which presents achallenge in analysing these data. The obvious solution to this challenge is toreduce the amount of data without information loss. Dimension reduction isconsidered the most popular approach for reducing data size and also to reducenoise and redundancies in data. In this paper, we investigate the effect offeature selection in improving the prediction of patient deterioration in ICUs.We consider lab tests as features. Thus, choosing a subset of features wouldmean choosing the most important lab tests to perform. If the number of testscan be reduced by identifying the most important tests, then we could alsoidentify the redundant tests. By omitting the redundant tests, observation timecould be reduced and early treatment could be provided to avoid the risk.Additionally, unnecessary monetary cost would be avoided. Our approach usesstate-ofthe- art feature selection for predicting ICU patient deteriorationusing the medical lab results. We apply our technique on the publicly availableMIMIC-II database and show the effectiveness of the feature selection. We alsoprovide a detailed analysis of the best features identified by our approach.
arxiv-13800-291 | Gaussian Process Planning with Lipschitz Continuous Reward Functions: Towards Unifying Bayesian Optimization, Active Learning, and Beyond | http://arxiv.org/pdf/1511.06890v1.pdf | author:Chun Kai Ling, Kian Hsiang Low, Patrick Jaillet category:stat.ML cs.AI cs.LG cs.RO published:2015-11-21 summary:This paper presents a novel nonmyopic adaptive Gaussian process planning(GPP) framework endowed with a general class of Lipschitz continuous rewardfunctions that can unify some active learning/sensing and Bayesian optimizationcriteria and offer practitioners some flexibility to specify their desiredchoices for defining new tasks/problems. In particular, it utilizes aprincipled Bayesian sequential decision problem framework for jointly andnaturally optimizing the exploration-exploitation trade-off. In general, theresulting induced GPP policy cannot be derived exactly due to an uncountableset of candidate observations. A key contribution of our work here thus lies inexploiting the Lipschitz continuity of the reward functions to solve for anonmyopic adaptive epsilon-optimal GPP (epsilon-GPP) policy. To plan in realtime, we further propose an asymptotically optimal, branch-and-bound anytimevariant of epsilon-GPP with performance guarantee. We empirically demonstratethe effectiveness of our epsilon-GPP policy and its anytime variant in Bayesianoptimization and an energy harvesting task.
arxiv-13800-292 | Recurrent Polynomial Network for Dialogue State Tracking | http://arxiv.org/pdf/1507.03934v2.pdf | author:Kai Sun, Qizhe Xie, Kai Yu category:cs.CL published:2015-07-14 summary:Dialogue state tracking (DST) is a process to estimate the distribution ofthe dialogue states as a dialogue progresses. Recent studies on constrainedMarkov Bayesian polynomial (CMBP) framework take the first step towardsbridging the gap between rule-based and statistical approaches for DST. In thispaper, the gap is further bridged by a novel framework -- recurrent polynomialnetwork (RPN). RPN's unique structure enables the framework to have all theadvantages of CMBP including efficiency, portability and interpretability.Additionally, RPN achieves more properties of statistical approaches than CMBP.RPN was evaluated on the data corpora of the second and the third Dialog StateTracking Challenge (DSTC-2/3). Experiments showed that RPN can significantlyoutperform both traditional rule-based approaches and statistical approacheswith similar feature set. Compared with the state-of-the-art statistical DSTapproaches with a lot richer features, RPN is also competitive.
arxiv-13800-293 | TransCut: Transparent Object Segmentation from a Light-Field Image | http://arxiv.org/pdf/1511.06853v1.pdf | author:Yichao Xu, Hajime Nagahara, Atsushi Shimada, Rin-ichiro Taniguchi category:cs.CV published:2015-11-21 summary:The segmentation of transparent objects can be very useful in computer visionapplications. However, because they borrow texture from their background andhave a similar appearance to their surroundings, transparent objects are nothandled well by regular image segmentation methods. We propose a method thatovercomes these problems using the consistency and distortion properties of alight-field image. Graph-cut optimization is applied for the pixel labelingproblem. The light-field linearity is used to estimate the likelihood of apixel belonging to the transparent object or Lambertian background, and theocclusion detector is used to find the occlusion boundary. We acquire a lightfield dataset for the transparent object, and use this dataset to evaluate ourmethod. The results demonstrate that the proposed method successfully segmentstransparent objects from the background.
arxiv-13800-294 | Mapping Images to Sentiment Adjective Noun Pairs with Factorized Neural Nets | http://arxiv.org/pdf/1511.06838v1.pdf | author:Takuya Narihira, Damian Borth, Stella X. Yu, Karl Ni, Trevor Darrell category:cs.CV cs.CL published:2015-11-21 summary:We consider the visual sentiment task of mapping an image to an adjectivenoun pair (ANP) such as "cute baby". To capture the two-factor structure of ourANP semantics as well as to overcome annotation noise and ambiguity, we proposea novel factorized CNN model which learns separate representations foradjectives and nouns but optimizes the classification performance over theirproduct. Our experiments on the publicly available SentiBank dataset show thatour model significantly outperforms not only independent ANP classifiers onunseen ANPs and on retrieving images of novel ANPs, but also image captioningmodels which capture word semantics from co-occurrence of natural text; thelatter turn out to be surprisingly poor at capturing the sentiment evoked bypure visual experience. That is, our factorized ANP CNN not only trains betterfrom noisy labels, generalizes better to new images, but can also expands theANP vocabulary on its own.
arxiv-13800-295 | Fidelity-Naturalness Evaluation of Single Image Super Resolution | http://arxiv.org/pdf/1511.06834v1.pdf | author:Xuan Dong, Yu Zhu, Weixin Li, Lingxi Xie, Alex Wong, Alan Yuille category:cs.CV published:2015-11-21 summary:We study the problem of evaluating super resolution methods. Traditionalevaluation methods usually judge the quality of super resolved images based ona single measure of their difference with the original high resolution images.In this paper, we proposed to use both fidelity (the difference with originalimages) and naturalness (human visual perception of super resolved images) forevaluation. For fidelity evaluation, a new metric is proposed to solve the biasproblem of traditional evaluation. For naturalness evaluation, we let humanslabel preference of super resolution results using pair-wise comparison, andtest the correlation between human labeling results and image qualityassessment metrics' outputs. Experimental results show that ourfidelity-naturalness method is better than the traditional evaluation methodfor super resolution methods, which could help future research on single-imagesuper resolution.
arxiv-13800-296 | Semi-supervised Bootstrapping approach for Named Entity Recognition | http://arxiv.org/pdf/1511.06833v1.pdf | author:S. Thenmalar, J. Balaji, T. V. Geetha category:cs.CL cs.IR published:2015-11-21 summary:The aim of Named Entity Recognition (NER) is to identify references of namedentities in unstructured documents, and to classify them into pre-definedsemantic categories. NER often aids from added background knowledge in the formof gazetteers. However using such a collection does not deal with name variantsand cannot resolve ambiguities associated in identifying the entities incontext and associating them with predefined categories. We present asemi-supervised NER approach that starts with identifying named entities with asmall set of training data. Using the identified named entities, the word andthe context features are used to define the pattern. This pattern of each namedentity category is used as a seed pattern to identify the named entities in thetest set. Pattern scoring and tuple value score enables the generation of thenew patterns to identify the named entity categories. We have evaluated theproposed system for English language with the dataset of tagged (IEER) anduntagged (CoNLL 2003) named entity corpus and for Tamil language with thedocuments from the FIRE corpus and yield an average f-measure of 75% for boththe languages.
arxiv-13800-297 | GradNets: Dynamic Interpolation Between Neural Architectures | http://arxiv.org/pdf/1511.06827v1.pdf | author:Diogo Almeida, Nate Sauder category:cs.LG cs.NE published:2015-11-21 summary:In machine learning, there is a fundamental trade-off between ease ofoptimization and expressive power. Neural Networks, in particular, haveenormous expressive power and yet are notoriously challenging to train. Thenature of that optimization challenge changes over the course of learning.Traditionally in deep learning, one makes a static trade-off between the needsof early and late optimization. In this paper, we investigate a novelframework, GradNets, for dynamically adapting architectures during training toget the benefits of both. For example, we can gradually transition from linearto non-linear networks, deterministic to stochastic computation, shallow todeep architectures, or even simple downsampling to fully differentiableattention mechanisms. Benefits include increased accuracy, easier convergencewith more complex architectures, solutions to test-time execution of batchnormalization, and the ability to train networks of up to 200 layers.
arxiv-13800-298 | Kernel Additive Principal Components | http://arxiv.org/pdf/1511.06821v1.pdf | author:Xin Lu Tan, Andreas Buja, Zongming Ma category:stat.ME stat.ML published:2015-11-21 summary:Additive principal components (APCs for short) are a nonlinear generalizationof linear principal components. We focus on smallest APCs to describe additivenonlinear constraints that are approximately satisfied by the data. Thus APCsfit data with implicit equations that treat the variables symmetrically, asopposed to regression analyses which fit data with explicit equations thattreat the data asymmetrically by singling out a response variable. We propose aregularized data-analytic procedure for APC estimation using kernel methods. Incontrast to existing approaches to APCs that are based on regularizationthrough subspace restriction, kernel methods achieve regularization throughshrinkage and therefore grant distinctive flexibility in APC estimation byallowing the use of infinite-dimensional functions spaces for searching APCtransformation while retaining computational feasibility. To connect populationAPCs and kernelized finite-sample APCs, we study kernelized population APCs andtheir associated eigenproblems, which eventually lead to the establishment ofconsistency of the estimated APCs. Lastly, we discuss an iterative algorithmfor computing kernelized finite-sample APCs.
arxiv-13800-299 | An Immersive Telepresence System using RGB-D Sensors and Head Mounted Display | http://arxiv.org/pdf/1511.06815v1.pdf | author:Xinzhong Lu, Ju Shen, Saverio Perugini, Jianjun Yang category:cs.CV cs.HC cs.MM published:2015-11-21 summary:We present a tele-immersive system that enables people to interact with eachother in a virtual world using body gestures in addition to verbalcommunication. Beyond the obvious applications, including general onlineconversations and gaming, we hypothesize that our proposed system would beparticularly beneficial to education by offering rich visual contents andinteractivity. One distinct feature is the integration of egocentric poserecognition that allows participants to use their gestures to demonstrate andmanipulate virtual objects simultaneously. This functionality enables theinstructor to ef- fectively and efficiently explain and illustrate complexconcepts or sophisticated problems in an intuitive manner. The highlyinteractive and flexible environment can capture and sustain more studentattention than the traditional classroom setting and, thus, delivers acompelling experience to the students. Our main focus here is to investigatepossible solutions for the system design and implementation and devisestrategies for fast, efficient computation suitable for visual data processingand network transmission. We describe the technique and experiments in detailsand provide quantitative performance results, demonstrating our system can berun comfortably and reliably for different application scenarios. Ourpreliminary results are promising and demonstrate the potential for morecompelling directions in cyberlearning.
arxiv-13800-300 | Learning visual groups from co-occurrences in space and time | http://arxiv.org/pdf/1511.06811v1.pdf | author:Phillip Isola, Daniel Zoran, Dilip Krishnan, Edward H. Adelson category:cs.LG cs.CV published:2015-11-21 summary:We propose a self-supervised framework that learns to group visual entitiesbased on their rate of co-occurrence in space and time. To model statisticaldependencies between the entities, we set up a simple binary classificationproblem in which the goal is to predict if two visual primitives occur in thesame spatial or temporal context. We apply this framework to three domains:learning patch affinities from spatial adjacency in images, learning frameaffinities from temporal adjacency in videos, and learning photo affinitiesfrom geospatial proximity in image collections. We demonstrate that in eachcase the learned affinities uncover meaningful semantic groupings. From patchaffinities we generate object proposals that are competitive withstate-of-the-art supervised methods. From frame affinities we generate moviescene segmentations that correlate well with DVD chapter structure. Finally,from geospatial affinities we learn groups that relate well to semantic placecategories.
