arxiv-13500-1 | Hyper-Fisher Vectors for Action Recognition | http://arxiv.org/pdf/1509.08439v1.pdf | author:Sanath Narayan, Kalpathi R. Ramakrishnan category:cs.CV published:2015-09-28 summary:In this paper, a novel encoding scheme combining Fisher vector andbag-of-words encodings has been proposed for recognizing action in videos. Theproposed Hyper-Fisher vector encoding is sum of local Fisher vectors which arecomputed based on the traditional Bag-of-Words (BoW) encoding. Thus, theproposed encoding is simple and yet an effective representation over thetraditional Fisher Vector encoding. By extensive evaluation on challengingaction recognition datasets, viz., Youtube, Olympic Sports, UCF50 and HMDB51,we show that the proposed Hyper-Fisher Vector encoding improves the recognitionperformance by around 2-3% compared to the improved Fisher Vector encoding. Wealso perform experiments to show that the performance of the Hyper-FisherVector is robust to the dictionary size of the BoW encoding.
arxiv-13500-2 | Efficient Empowerment | http://arxiv.org/pdf/1509.08455v1.pdf | author:Maximilian Karl, Justin Bayer, Patrick van der Smagt category:stat.ML cs.LG published:2015-09-28 summary:Empowerment quantifies the influence an agent has on its environment. This isformally achieved by the maximum of the expected KL-divergence between thedistribution of the successor state conditioned on a specific action and adistribution where the actions are marginalised out. This is a naturalcandidate for an intrinsic reward signal in the context of reinforcementlearning: the agent will place itself in a situation where its action havemaximum stability and maximum influence on the future. The limiting factor sofar has been the computational complexity of the method: the only way ofcalculation has so far been a brute force algorithm, reducing the applicabilityof the method to environments with a small set discrete states. In this work,we propose to use an efficient approximation for marginalising out the actionsin the case of continuous environments. This allows fast evaluation ofempowerment, paving the way towards challenging environments such as real worldrobotics. The method is presented on a pendulum swing up problem.
arxiv-13500-3 | Encoding Reality: Prediction-Assisted Cortical Learning Algorithm in Hierarchical Temporal Memory | http://arxiv.org/pdf/1509.08255v2.pdf | author:Fergal Byrne category:cs.NE cs.AI published:2015-09-28 summary:In the decade since Jeff Hawkins proposed Hierarchical Temporal Memory (HTM)as a model of neocortical computation, the theory and the algorithms haveevolved dramatically. This paper presents a detailed description of HTM'sCortical Learning Algorithm (CLA), including for the first time a rigorousmathematical formulation of all aspects of the computations. PredictionAssisted CLA (paCLA), a refinement of the CLA is presented, which is bothcloser to the neuroscience and adds significantly to the computational power.Finally, we summarise the key functions of neocortex which are expressed inpaCLA implementations.
arxiv-13500-4 | Robust video object tracking using particle filter with likelihood based feature fusion and adaptive template updating | http://arxiv.org/pdf/1509.08182v1.pdf | author:Yi Dai, Bin Liu category:cs.CV 68T45 I.4.8; I.5.4 published:2015-09-28 summary:A robust algorithm solution is proposed for tracking an object in complexvideo scenes. In this solution, the bootstrap particle filter (PF) isinitialized by an object detector, which models the time-evolving background ofthe video signal by an adaptive Gaussian mixture. The motion of the object isexpressed by a Markov model, which defines the state transition prior. Thecolor and texture features are used to represent the object, and a marginallikelihood based feature fusion approach is proposed. A corresponding objecttemplate model updating procedure is developed to account for possible scalechanges of the object in the tracking process. Experimental results show thatour algorithm beats several existing alternatives in tackling challengingscenarios in video tracking tasks.
arxiv-13500-5 | High-dimensional Time Series Prediction with Missing Values | http://arxiv.org/pdf/1509.08333v3.pdf | author:Hsiang-Fu Yu, Nikhil Rao, Inderjit S. Dhillon category:cs.LG stat.ML published:2015-09-28 summary:High-dimensional time series prediction is needed in applications as diverseas demand forecasting and climatology. Often, such applications require methodsthat are both highly scalable, and deal with noisy data in terms of corruptionsor missing values. Classical time series methods usually fall short of handlingboth these issues. In this paper, we propose to adapt matrix matrix completionapproaches that have previously been successfully applied to large scale noisydata, but which fail to adequately model high-dimensional time series due totemporal dependencies. We present a novel temporal regularized matrixfactorization (TRMF) framework which supports data-driven temporal dependencylearning and enables forecasting ability to our new matrix factorizationapproach. TRMF is highly general, and subsumes many existing matrixfactorization approaches for time series data. We make interesting connectionsto graph regularized matrix factorization methods in the context of learningthe dependencies. Experiments on both real and synthetic data show that TRMFoutperforms several existing approaches for common time series tasks.
arxiv-13500-6 | Efficient Discriminative Nonorthogonal Binary Subspace with its Application to Visual Tracking | http://arxiv.org/pdf/1509.08383v1.pdf | author:Ang Li, Feng Tang, Yanwen Guo, Hai Tao category:cs.CV published:2015-09-28 summary:One of the crucial problems in visual tracking is how the object isrepresented. Conventional appearance-based trackers are using increasingly morecomplex features in order to be robust. However, complex representationstypically not only require more computation for feature extraction, but alsomake the state inference complicated. We show that with a careful featureselection scheme, extremely simple yet discriminative features can be used forrobust object tracking. The central component of the proposed method is asuccinct and discriminative representation of the object using discriminativenon-orthogonal binary subspace (DNBS) which is spanned by Haar-like features.The DNBS representation inherits the merits of the original NBS in that itefficiently describes the object. It also incorporates the discriminativeinformation to distinguish foreground from background. However, the problem offinding the DNBS bases from an over-complete dictionary is NP-hard. We proposea greedy algorithm called discriminative optimized orthogonal matching pursuit(D-OOMP) to solve this problem. An iterative formulation named iterative D-OOMPis further developed to drastically reduce the redundant computation betweeniterations and a hierarchical selection strategy is integrated for reducing thesearch space of features. The proposed DNBS representation is applied to objecttracking through SSD-based template matching. We validate the effectiveness ofour method through extensive experiments on challenging videos with comparisonsagainst several state-of-the-art trackers and demonstrate its capability totrack objects in clutter and moving background.
arxiv-13500-7 | Compressive spectral embedding: sidestepping the SVD | http://arxiv.org/pdf/1509.08360v1.pdf | author:Dinesh Ramasamy, Upamanyu Madhow category:stat.ML cs.LG published:2015-09-28 summary:Spectral embedding based on the Singular Value Decomposition (SVD) is awidely used "preprocessing" step in many learning tasks, typically leading todimensionality reduction by projecting onto a number of dominant singularvectors and rescaling the coordinate axes (by a predefined function of thesingular value). However, the number of such vectors required to captureproblem structure grows with problem size, and even partial SVD computationbecomes a bottleneck. In this paper, we propose a low-complexity it compressivespectral embedding algorithm, which employs random projections and finite orderpolynomial expansions to compute approximations to SVD-based embedding. For anm times n matrix with T non-zeros, its time complexity is O((T+m+n)log(m+n)),and the embedding dimension is O(log(m+n)), both of which are independent ofthe number of singular vectors whose effect we wish to capture. To the best ofour knowledge, this is the first work to circumvent this dependence on thenumber of singular vectors for general SVD-based embeddings. The key tosidestepping the SVD is the observation that, for downstream inference taskssuch as clustering and classification, we are only interested in using theresulting embedding to evaluate pairwise similarity metrics derived from theeuclidean norm, rather than capturing the effect of the underlying matrix onarbitrary vectors as a partial SVD tries to do. Our numerical results onnetwork datasets demonstrate the efficacy of the proposed method, and motivatefurther exploration of its application to large-scale inference tasks.
arxiv-13500-8 | Theoretical Analysis of the Optimal Free Responses of Graph-Based SFA for the Design of Training Graphs | http://arxiv.org/pdf/1509.08329v1.pdf | author:Alberto N. Escalante-B., Laurenz Wiskott category:cs.AI cs.CV stat.ML published:2015-09-28 summary:Slow feature analysis (SFA) is an unsupervised learning algorithm thatextracts slowly varying features from a time series. Graph-based SFA (GSFA) isa supervised extension that can solve regression problems if followed by apost-processing regression algorithm. A training graph specifies arbitraryconnections between the training samples. The connections in current graphs,however, only depend on the rank of the involved labels. Exploiting the exactlabel values makes further improvements in estimation accuracy possible. In this article, we propose the exact label learning (ELL) method to create agraph that codes the desired label explicitly, so that GSFA is able to extracta normalized version of it directly. The ELL method is used for three tasks:(1) We estimate gender from artificial images of human faces (regression) andshow the advantage of coding additional labels, particularly skin color. (2) Weanalyze two existing graphs for regression. (3) We extract compactdiscriminative features to classify traffic sign images. When the number ofoutput features is limited, a higher classification rate is obtained comparedto a graph equivalent to nonlinear Fisher discriminant analysis. The method isversatile, directly supports multiple labels, and provides higher accuracycompared to current graphs for the problems considered.
arxiv-13500-9 | Fast Non-local Stereo Matching based on Hierarchical Disparity Prediction | http://arxiv.org/pdf/1509.08197v1.pdf | author:Xuan Luo, Xuejiao Bai, Shuo Li, Hongtao Lu, Sei-ichiro Kamata category:cs.CV published:2015-09-28 summary:Stereo matching is the key step in estimating depth from two or more images.Recently, some tree-based non-local stereo matching methods have been proposed,which achieved state-of-the-art performance. The algorithms employed some treestructures to aggregate cost and thus improved the performance and reduced thecoputation load of the stereo matching. However, the computational complexityof these tree-based algorithms is still high because they search over theentire disparity range. In addition, the extreme greediness of the minimumspanning tree (MST) causes the poor performance in large areas with similarcolors but varying disparities. In this paper, we propose an efficient stereomatching method using a hierarchical disparity prediction (HDP) framework todramatically reduce the disparity search range so as to speed up the tree-basednon-local stereo methods. Our disparity prediction scheme works on a graphpyramid derived from an image whose disparity to be estimated. We utilize thedisparity of a upper graph to predict a small disparity range for the lowergraph. Some independent disparity trees (DT) are generated to form a disparityprediction forest (HDPF) over which the cost aggregation is made. When combinedwith the state-of-the-art tree-based methods, our scheme not only dramaticallyspeeds up the original methods but also improves their performance byalleviating the second drawback of the tree-based methods. This is partiallybecause our DTs overcome the extreme greediness of the MST. Extensiveexperimental results on some benchmark datasets demonstrate the effectivenessand efficiency of our framework. For example, the segment-tree based stereomatching becomes about 25.57 times faster and 2.2% more accurate over theMiddlebury 2006 full-size dataset.
arxiv-13500-10 | A Preliminary Study on the Learning Informativeness of Data Subsets | http://arxiv.org/pdf/1510.04104v1.pdf | author:Simon Kaltenbacher, Nicholas H. Kirk, Dongheui Lee category:cs.CL cs.RO published:2015-09-28 summary:Estimating the internal state of a robotic system is complex: this isperformed from multiple heterogeneous sensor inputs and knowledge sources.Discretization of such inputs is done to capture saliences, represented assymbolic information, which often presents structure and recurrence. As thesesequences are used to reason over complex scenarios, a more compactrepresentation would aid exactness of technical cognitive reasoningcapabilities, which are today constrained by computational complexity issuesand fallback to representational heuristics or human intervention. Suchproblems need to be addressed to ensure timely and meaningful human-robotinteraction. Our work is towards understanding the variability of learninginformativeness when training on subsets of a given input dataset. This is inview of reducing the training size while retaining the majority of the symboliclearning potential. We prove the concept on human-written texts, and conjecturethis work will reduce training data size of sequential instructions, whilepreserving semantic relations, when gathering information from large remotesources.
arxiv-13500-11 | Learning FRAME Models Using CNN Filters | http://arxiv.org/pdf/1509.08379v3.pdf | author:Yang Lu, Song-Chun Zhu, Ying Nian Wu category:cs.CV published:2015-09-28 summary:The convolutional neural network (ConvNet or CNN) has proven to be verysuccessful in many tasks such as those in computer vision. In this conceptualpaper, we study the generative perspective of the discriminative CNN. Inparticular, we propose to learn the generative FRAME (Filters, Random field,And Maximum Entropy) model using the highly expressive filters pre-learned bythe CNN at the convolutional layers. We show that the learning algorithm cangenerate realistic and rich object and texture patterns in natural scenes. Weexplain that each learned model corresponds to a new CNN unit at a layer abovethe layer of filters employed by the model. We further show that it is possibleto learn a new layer of CNN units using a generative CNN model, which is aproduct of experts model, and the learning algorithm admits an EMinterpretation with binary latent variables.
arxiv-13500-12 | Quantile Search: A Distance-Penalized Active Learning Algorithm for Spatial Sampling | http://arxiv.org/pdf/1509.08387v1.pdf | author:John Lipor, Laura Balzano, Branko Kerkez, Don Scavia category:stat.ML cs.LG 62L05 G.3; H.3.3 published:2015-09-28 summary:Adaptive sampling theory has shown that, with proper assumptions on thesignal class, algorithms exist to reconstruct a signal in $\mathbb{R}^{d}$ withan optimal number of samples. We generalize this problem to when the cost ofsampling is not only the number of samples but also the distance traveledbetween samples. This is motivated by our work studying regions of low oxygenconcentration in the Great Lakes. We show that for one-dimensional thresholdclassifiers, a tradeoff between number of samples and distance traveled can beachieved using a generalization of binary search, which we refer to as quantilesearch. We derive the expected total sampling time for noiseless measurementsand the expected number of samples for an extension to the noisy case. Weillustrate our results in simulations relevant to our sampling application.
arxiv-13500-13 | Analysis of Intelligent Classifiers and Enhancing the Detection Accuracy for Intrusion Detection System | http://arxiv.org/pdf/1509.08239v1.pdf | author:Mohanad Albayati, Biju Issac category:cs.CR cs.LG published:2015-09-28 summary:In this paper we discuss and analyze some of the intelligent classifierswhich allows for automatic detection and classification of networks attacks forany intrusion detection system. We will proceed initially with their analysisusing the WEKA software to work with the classifiers on a well-known IDS(Intrusion Detection Systems) dataset like NSL-KDD dataset. The NSL-KDD datasetof network attacks was created in a military network by MIT Lincoln Labs. Thenwe will discuss and experiment some of the hybrid AI (Artificial Intelligence)classifiers that can be used for IDS, and finally we developed a Java softwarewith three most efficient classifiers and compared it with other options. Theoutputs would show the detection accuracy and efficiency of the single andcombined classifiers used.
arxiv-13500-14 | Segment-Phrase Table for Semantic Segmentation, Visual Entailment and Paraphrasing | http://arxiv.org/pdf/1509.08075v1.pdf | author:Hamid Izadinia, Fereshteh Sadeghi, Santosh Kumar Divvala, Yejin Choi, Ali Farhadi category:cs.CV published:2015-09-27 summary:We introduce Segment-Phrase Table (SPT), a large collection of bijectiveassociations between textual phrases and their corresponding segmentations.Leveraging recent progress in object recognition and natural languagesemantics, we show how we can successfully build a high-quality segment-phrasetable using minimal human supervision. More importantly, we demonstrate theunique value unleashed by this rich bimodal resource, for both vision as wellas natural language understanding. First, we show that fine-grained textuallabels facilitate contextual reasoning that helps in satisfying semanticconstraints across image segments. This feature enables us to achievestate-of-the-art segmentation results on benchmark datasets. Next, we show thatthe association of high-quality segmentations to textual phrases aids in richersemantic understanding and reasoning of these textual phrases. Leveraging thisfeature, we motivate the problem of visual entailment and visual paraphrasing,and demonstrate its utility on a large dataset.
arxiv-13500-15 | Optimal Copula Transport for Clustering Multivariate Time Series | http://arxiv.org/pdf/1509.08144v2.pdf | author:Gautier Marti, Frank Nielsen, Philippe Donnat category:cs.LG stat.ML published:2015-09-27 summary:This paper presents a new methodology for clustering multivariate time seriesleveraging optimal transport between copulas. Copulas are used to encode both(i) intra-dependence of a multivariate time series, and (ii) inter-dependencebetween two time series. Then, optimal copula transport allows us to define twodistances between multivariate time series: (i) one for measuringintra-dependence dissimilarity, (ii) another one for measuring inter-dependencedissimilarity based on a new multivariate dependence coefficient which isrobust to noise, deterministic, and which can target specified dependencies.
arxiv-13500-16 | Non-asymptotic Analysis of $\ell_1$-norm Support Vector Machines | http://arxiv.org/pdf/1509.08083v1.pdf | author:Anton Kolleck, Jan Vybíral category:cs.IT cs.LG math.FA math.IT math.ST stat.TH published:2015-09-27 summary:Support Vector Machines (SVM) with $\ell_1$ penalty became a standard tool inanalysis of highdimensional classification problems with sparsity constraintsin many applications including bioinformatics and signal processing. AlthoughSVM have been studied intensively in the literature, this paper has to ourknowledge first non-asymptotic results on the performance of $\ell_1$-SVM inidentification of sparse classifiers. We show that a $d$-dimensional $s$-sparseclassification vector can be (with high probability) well approximated fromonly $O(s\log(d))$ Gaussian trials. The methods used in the proof includeconcentration of measure and probability in Banach spaces.
arxiv-13500-17 | Representation Benefits of Deep Feedforward Networks | http://arxiv.org/pdf/1509.08101v2.pdf | author:Matus Telgarsky category:cs.LG cs.NE published:2015-09-27 summary:This note provides a family of classification problems, indexed by a positiveinteger $k$, where all shallow networks with fewer than exponentially (in $k$)many nodes exhibit error at least $1/6$, whereas a deep network with 2 nodes ineach of $2k$ layers achieves zero error, as does a recurrent network with 3distinct nodes iterated $k$ times. The proof is elementary, and the networksare standard feedforward networks with ReLU (Rectified Linear Unit)nonlinearities.
arxiv-13500-18 | Amodal Completion and Size Constancy in Natural Scenes | http://arxiv.org/pdf/1509.08147v2.pdf | author:Abhishek Kar, Shubham Tulsiani, João Carreira, Jitendra Malik category:cs.CV published:2015-09-27 summary:We consider the problem of enriching current object detection systems withveridical object sizes and relative depth estimates from a single image. Thereare several technical challenges to this, such as occlusions, lack ofcalibration data and the scale ambiguity between object size and distance.These have not been addressed in full generality in previous work. Here wepropose to tackle these issues by building upon advances in object recognitionand using recently created large-scale datasets. We first introduce the task ofamodal bounding box completion, which aims to infer the the full extent of theobject instances in the image. We then propose a probabilistic framework forlearning category-specific object size distributions from available annotationsand leverage these in conjunction with amodal completion to infer veridicalsizes in novel images. Finally, we introduce a focal length prediction approachthat exploits scene recognition to overcome inherent scaling ambiguities and wedemonstrate qualitative results on challenging real-world scenes.
arxiv-13500-19 | Feature Selection for classification of hyperspectral data by minimizing a tight bound on the VC dimension | http://arxiv.org/pdf/1509.08112v1.pdf | author:Phool Preet, Sanjit Singh Batra, Jayadeva category:cs.LG published:2015-09-27 summary:Hyperspectral data consists of large number of features which requiresophisticated analysis to be extracted. A popular approach to reducecomputational cost, facilitate information representation and accelerateknowledge discovery is to eliminate bands that do not improve theclassification and analysis methods being applied. In particular, algorithmsthat perform band elimination should be designed to take advantage of thespecifics of the classification method being used. This paper employs arecently proposed filter-feature-selection algorithm based on minimizing atight bound on the VC dimension. We have successfully applied this algorithm todetermine a reasonable subset of bands without any user-defined stoppingcriteria on widely used hyperspectral images and demonstrate that this methodoutperforms state-of-the-art methods in terms of both sparsity of feature setas well as accuracy of classification.\end{abstract}
arxiv-13500-20 | Multivariate Median Filters and Partial Differential Equations | http://arxiv.org/pdf/1509.08082v2.pdf | author:Martin Welk category:cs.CV I.4.3; G.1.8 published:2015-09-27 summary:Multivariate median filters have been proposed as generalisations of thewell-established median filter for grey-value images to multi-channel images.As multivariate median, most of the recent approaches use the $L^1$ median,i.e.\ the minimiser of an objective function that is the sum of distances toall input points. Many properties of univariate median filters generalise tosuch a filter. However, the famous result by Guichard and Morel aboutapproximation of the mean curvature motion PDE by median filtering does nothave a comparably simple counterpart for $L^1$ multivariate median filtering.We discuss the affine equivariant Oja median and the affine equivarianttransformation--retransformation $L^1$ median as alternatives to $L^1$ medianfiltering. We analyse multivariate median filters in a space-continuoussetting, including the formulation of a space-continuous version of thetransformation--retransformation $L^1$ median, and derive PDEs approximated bythese filters in the cases of bivariate planar images, three-channel volumeimages and three-channel planar images. The PDEs for the affine equivariantfilters can be interpreted geometrically as combinations of a diffusion and aprincipal-component-wise curvature motion contribution with a cross-effect termbased on torsions of principal components. Numerical experiments are presentedthat demonstrate the validity of the approximation results.
arxiv-13500-21 | Discriminative Learning of the Prototype Set for Nearest Neighbor Classification | http://arxiv.org/pdf/1509.08102v4.pdf | author:Shin Ando category:cs.LG published:2015-09-27 summary:The nearest neighbor rule is one of the most widely used models forclassification and selecting a compact set of prototype instances is animportant problem for its applications. Many existing approaches on theprototype selection problem have relied on instance-based analyses of the classdistribution, which can be computationally expensive for large datasets. Inthis paper, we revisit this problem to explore a parametric approach, whichapproximates the violation of the nearest neighbor rule over the training setand learns the prioritization of prototypes that minimizes the violation. Weshow that our approach reduces the problem to large-margin learning anddemonstrate its advantage by empirical comparisons using public benchmark data.
arxiv-13500-22 | Online Object Tracking, Learning and Parsing with And-Or Graphs | http://arxiv.org/pdf/1509.08067v5.pdf | author:Tianfu Wu, Yang Lu, Song-Chun Zhu category:cs.CV cs.LG published:2015-09-27 summary:This paper presents a method, called AOGTracker, for simultaneously tracking,learning and parsing (TLP) unknown objects in video sequences with ahierarchical and compositional And-Or graph (AOG) representation. %The AOGcaptures both structural and appearance variations of a target object in aprincipled way. The TLP method is formulated in the Bayesian framework with aspatial and a temporal dynamic programming (DP) algorithms inferring objectbounding boxes on-the-fly. During online learning, the AOG is discriminativelylearned using latent SVM to account for appearance (e.g., lighting and partialocclusion) and structural (e.g., different poses and viewpoints) variations ofa tracked object, as well as distractors (e.g., similar objects) in background.Three key issues in online inference and learning are addressed: (i)maintaining purity of positive and negative examples collected online, (ii)controling model complexity in latent structure learning, and (iii) identifyingcritical moments to re-learn the structure of AOG based on its intrackability.The intrackability measures uncertainty of an AOG based on its score maps in aframe. In experiments, our AOGTracker is tested on two popular trackingbenchmarks with the same parameter setting: the TB-100/50/CVPR2013 benchmarks,and the VOT benchmarks --- VOT 2013, 2014, 2015 and TIR2015 (thermal imagerytracking). In the former, our AOGTracker outperforms state-of-the-art trackingalgorithms including two trackers based on deep convolutional network. In thelatter, our AOGTracker outperforms all other trackers in VOT2013 and iscomparable to the state-of-the-art methods in VOT2014, 2015 and TIR2015. Reproducibility: The source code is released with this paper for reproducingall results, which is available at https://github.com/tfwu/RGM-AOGTracker.
arxiv-13500-23 | End-to-End Text-Dependent Speaker Verification | http://arxiv.org/pdf/1509.08062v1.pdf | author:Georg Heigold, Ignacio Moreno, Samy Bengio, Noam Shazeer category:cs.LG cs.SD published:2015-09-27 summary:In this paper we present a data-driven, integrated approach to speakerverification, which maps a test utterance and a few reference utterancesdirectly to a single score for verification and jointly optimizes the system'scomponents using the same evaluation protocol and metric as at test time. Suchan approach will result in simple and efficient systems, requiring littledomain-specific knowledge and making few model assumptions. We implement theidea by formulating the problem as a single neural network architecture,including the estimation of a speaker model on only a few utterances, andevaluate it on our internal "Ok Google" benchmark for text-dependent speakerverification. The proposed approach appears to be very effective for big dataapplications like ours that require highly accurate, easy-to-maintain systemswith a small footprint.
arxiv-13500-24 | Deep Trans-layer Unsupervised Networks for Representation Learning | http://arxiv.org/pdf/1509.08038v1.pdf | author:Wentao Zhu, Jun Miao, Laiyun Qing, Xilin Chen category:cs.NE cs.CV cs.LG published:2015-09-27 summary:Learning features from massive unlabelled data is a vast prevalent topic forhigh-level tasks in many machine learning applications. The recent greatimprovements on benchmark data sets achieved by increasingly complexunsupervised learning methods and deep learning models with lots of parametersusually requires many tedious tricks and much expertise to tune. However,filters learned by these complex architectures are quite similar to standardhand-crafted features visually. In this paper, unsupervised learning methods,such as PCA or auto-encoder, are employed as the building block to learn filterbanks at each layer. The lower layer responses are transferred to the lastlayer (trans-layer) to form a more complete representation retaining moreinformation. In addition, some beneficial methods such as local contrastnormalization and whitening are added to the proposed deep trans-layer networksto further boost performance. The trans-layer representations are followed byblock histograms with binary encoder schema to learn translation and rotationinvariant representations, which are utilized to do high-level tasks such asrecognition and classification. Compared to traditional deep learning methods,the implemented feature learning method has much less parameters and isvalidated in several typical experiments, such as digit recognition on MNISTand MNIST variations, object recognition on Caltech 101 dataset and faceverification on LFW dataset. The deep trans-layer unsupervised learningachieves 99.45% accuracy on MNIST dataset, 67.11% accuracy on 15 samples perclass and 75.98% accuracy on 30 samples per class on Caltech 101 dataset,87.10% on LFW dataset.
arxiv-13500-25 | Super-Resolution Off the Grid | http://arxiv.org/pdf/1509.07943v1.pdf | author:Qingqing Huang, Sham M. Kakade category:cs.LG published:2015-09-26 summary:Super-resolution is the problem of recovering a superposition of pointsources using bandlimited measurements, which may be corrupted with noise. Thissignal processing problem arises in numerous imaging problems, ranging fromastronomy to biology to spectroscopy, where it is common to take (coarse)Fourier measurements of an object. Of particular interest is in obtainingestimation procedures which are robust to noise, with the following desirablestatistical and computational properties: we seek to use coarse Fouriermeasurements (bounded by some cutoff frequency); we hope to take a(quantifiably) small number of measurements; we desire our algorithm to runquickly. Suppose we have k point sources in d dimensions, where the points areseparated by at least \Delta from each other (in Euclidean distance). This workprovides an algorithm with the following favorable guarantees: - The algorithmuses Fourier measurements, whose frequencies are bounded by O(1/\Delta) (up tolog factors). Previous algorithms require a cutoff frequency which may be aslarge as {\Omega}( d/\Delta). - The number of measurements taken by and thecomputational complexity of our algorithm are bounded by a polynomial in boththe number of points k and the dimension d, with no dependence on theseparation \Delta. In contrast, previous algorithms depended inversepolynomially on the minimal separation and exponentially on the dimension forboth of these quantities. Our estimation procedure itself is simple: we take random bandlimitedmeasurements (as opposed to taking an exponential number of measurements on thehyper-grid). Furthermore, our analysis and algorithm are elementary (based onconcentration bounds for sampling and the singular value decomposition).
arxiv-13500-26 | Anomaly Detection in Unstructured Environments using Bayesian Nonparametric Scene Modeling | http://arxiv.org/pdf/1509.07979v2.pdf | author:Yogesh Girdhar, Walter Cho, Matthew Campbell, Jesus Pineda, Elizabeth Clarke, Hanumant Singh category:cs.CV cs.RO published:2015-09-26 summary:This paper explores the use of a Bayesian non-parametric topic modelingtechnique for the purpose of anomaly detection in video data. We presentresults from two experiments. The first experiment shows that the proposedtechnique is automatically able characterize the underlying terrain, and detectanomalous flora in image data collected by an underwater robot. The secondexperiment shows that the same technique can be used on images from a staticcamera in a dynamic unstructured environment. In the second dataset, consistingof video data from a static seafloor camera capturing images of a busy coralreef, the proposed technique was able to detect all three instances of anunderwater vehicle passing in front of the camera, amongst many otherobservations of fishes, debris, lighting changes due to surface waves, andbenthic flora.
arxiv-13500-27 | Targeted Fused Ridge Estimation of Inverse Covariance Matrices from Multiple High-Dimensional Data Classes | http://arxiv.org/pdf/1509.07982v1.pdf | author:Anders Ellern Bilgrau, Carel F. W. Peeters, Poul Svante Eriksen, Martin Bøgsted, Wessel N. van Wieringen category:stat.ME q-bio.MN stat.ML published:2015-09-26 summary:We consider the problem of jointly estimating multiple precision matricesfrom (aggregated) high-dimensional data consisting of distinct classes. An$\ell_2$-penalized maximum-likelihood approach is employed. The suggestedapproach is flexible and generic, incorporating several other$\ell_2$-penalized estimators as special cases. In addition, the approachallows for the specification of target matrices through which prior knowledgemay be incorporated and which can stabilize the estimation procedure inhigh-dimensional settings. The result is a targeted fused ridge estimator thatis of use when the precision matrices of the constituent classes are believedto chiefly share the same structure while potentially differing in a number oflocations of interest. It has many applications in (multi)factorial studydesigns. We focus on the graphical interpretation of precision matrices withthe proposed estimator then serving as a basis for integrative or meta-analyticGaussian graphical modeling. Situations are considered in which the classes aredefined by data sets and/or (subtypes of) diseases. The performance of theproposed estimator in the graphical modeling setting is assessed throughextensive simulation experiments. Its practical usability is illustrated by thedifferential network modeling of 11 large-scale diffuse large B-cell lymphomagene expression data sets. The estimator and its related procedures areincorporated into the R-package rags2ridges.
arxiv-13500-28 | Modeling Curiosity in a Mobile Robot for Long-Term Autonomous Exploration and Monitoring | http://arxiv.org/pdf/1509.07975v1.pdf | author:Yogesh Girdhar, Gregory Dudek category:cs.RO cs.CV cs.LG published:2015-09-26 summary:This paper presents a novel approach to modeling curiosity in a mobile robot,which is useful for monitoring and adaptive data collection tasks, especiallyin the context of long term autonomous missions where pre-programmed missionsare likely to have limited utility. We use a realtime topic modeling techniqueto build a semantic perception model of the environment, using which, we plan apath through the locations in the world with high semantic information content.The life-long learning behavior of the proposed perception model makes itsuitable for long-term exploration missions. We validate the approach usingsimulated exploration experiments using aerial and underwater data, anddemonstrate an implementation on the Aqua underwater robot in a variety ofscenarios. We find that the proposed exploration paths that are biased towardslocations with high topic perplexity, produce better terrain models with highdiscriminative power. Moreover, we show that the proposed algorithm implementedon Aqua robot is able to do tasks such as coral reef inspection, diverfollowing, and sea floor exploration, without any prior training orpreparation.
arxiv-13500-29 | Probably certifiably correct k-means clustering | http://arxiv.org/pdf/1509.07983v2.pdf | author:Takayuki Iguchi, Dustin G. Mixon, Jesse Peterson, Soledad Villar category:cs.IT cs.DS cs.LG math.IT math.ST stat.TH published:2015-09-26 summary:Recently, Bandeira [arXiv:1509.00824] introduced a new type of algorithm (theso-called probably certifiably correct algorithm) that combines fast solverswith the optimality certificates provided by convex relaxations. In this paper,we devise such an algorithm for the problem of k-means clustering. First, weprove that Peng and Wei's semidefinite relaxation of k-means is tight with highprobability under a distribution of planted clusters called the stochastic ballmodel. Our proof follows from a new dual certificate for integral solutions ofthis semidefinite program. Next, we show how to test the optimality of aproposed k-means solution using this dual certificate in quasilinear time.Finally, we analyze a version of spectral clustering from Peng and Wei that isdesigned to solve k-means in the case of two clusters. In particular, we showthat this quasilinear-time method typically recovers planted clusters under thestochastic ball model.
arxiv-13500-30 | A Revisit of Infinite Population Models for Evolutionary Algorithms on Continuous Optimization Problems | http://arxiv.org/pdf/1509.07946v1.pdf | author:Bo Song, Victor O. K. Li category:cs.NE math.OC published:2015-09-26 summary:Infinite population models are important tools for studying populationdynamics of evolutionary algorithms. They describe how the distributions ofpopulations change between consecutive generations. In general, infinitepopulation models are derived from Markov chains by exploiting symmetriesbetween individuals in the population and analyzing the limit as the populationsize goes to infinity. In this paper, we study the theoretical foundations ofinfinite population models of evolutionary algorithms on continuousoptimization problems. First, we show that the convergence proofs in a widelycited study were in fact problematic and incomplete. We further show that themodeling assumption of exchangeability of individuals cannot yield thetransition equation. Then, in order to analyze infinite population models, webuild an analytical framework based on convergence in distribution of randomelements which take values in the metric space of infinite sequences. Theframework is concise and mathematically rigorous. It also provides aninfrastructure for studying the convergence of the stacking of operators and ofiterating the algorithm which previous studies failed to address. Finally, weuse the framework to prove the convergence of infinite population models forthe mutation operator and the $k$-ary recombination operator. We show thatthese operators can provide accurate predictions for real population dynamicsas the population size goes to infinity, provided that the initial populationis identically and independently distributed.
arxiv-13500-31 | Algorithms for Linear Bandits on Polyhedral Sets | http://arxiv.org/pdf/1509.07927v1.pdf | author:Manjesh K. Hanawal, Amir Leshem, Venkatesh Saligrama category:cs.LG published:2015-09-26 summary:We study stochastic linear optimization problem with bandit feedback. The setof arms take values in an $N$-dimensional space and belong to a boundedpolyhedron described by finitely many linear inequalities. We provide a lowerbound for the expected regret that scales as $\Omega(N\log T)$. We then providea nearly optimal algorithm and show that its expected regret scales as$O(N\log^{1+\epsilon}(T))$ for an arbitrary small $\epsilon >0$. The algorithmalternates between exploration and exploitation intervals sequentially wheredeterministic set of arms are played in the exploration intervals and greedilyselected arm is played in the exploitation intervals. We also develop analgorithm that achieves the optimal regret when sub-Gaussianity parameter ofthe noise term is known. Our key insight is that for a polyhedron the optimalarm is robust to small perturbations in the reward function. Consequently, agreedily selected arm is guaranteed to be optimal when the estimation errorfalls below some suitable threshold. Our solution resolves a question posed byRusmevichientong and Tsitsiklis (2011) that left open the possibility ofefficient algorithms with asymptotic logarithmic regret bounds. We also showthat the regret upper bounds hold with probability $1$. Our numericalinvestigations show that while theoretical results are asymptotic theperformance of our algorithms compares favorably to state-of-the-art algorithmsin finite time as well.
arxiv-13500-32 | Sentiment of Emojis | http://arxiv.org/pdf/1509.07761v2.pdf | author:Petra Kralj Novak, Jasmina Smailović, Borut Sluban, Igor Mozetič category:cs.CL published:2015-09-25 summary:There is a new generation of emoticons, called emojis, that is increasinglybeing used in mobile communications and social media. In the past two years,over ten billion emojis were used on Twitter. Emojis are Unicode graphicsymbols, used as a shorthand to express concepts and ideas. In contrast to thesmall number of well-known emoticons that carry clear emotional contents, thereare hundreds of emojis. But what are their emotional contents? We provide thefirst emoji sentiment lexicon, called the Emoji Sentiment Ranking, and draw asentiment map of the 751 most frequently used emojis. The sentiment of theemojis is computed from the sentiment of the tweets in which they occur. Weengaged 83 human annotators to label over 1.6 million tweets in 13 Europeanlanguages by the sentiment polarity (negative, neutral, or positive). About 4%of the annotated tweets contain emojis. The sentiment analysis of the emojisallows us to draw several interesting conclusions. It turns out that most ofthe emojis are positive, especially the most popular ones. The sentimentdistribution of the tweets with and without emojis is significantly different.The inter-annotator agreement on the tweets with emojis is higher. Emojis tendto occur at the end of the tweets, and their sentiment polarity increases withthe distance. We observe no significant differences in the emoji rankingsbetween the 13 languages and the Emoji Sentiment Ranking. Consequently, wepropose our Emoji Sentiment Ranking as a European language-independent resourcefor automated sentiment analysis. Finally, the paper provides a formalizationof sentiment and a novel visualization in the form of a sentiment bar.
arxiv-13500-33 | A hybrid COA$ε$-constraint method for solving multi-objective problems | http://arxiv.org/pdf/1509.08302v1.pdf | author:Mahdi parvizi, Elham Shadkam, Niloofar Jahani category:cs.NE published:2015-09-25 summary:In this paper, a hybrid method for solving multi-objective problem has beenprovided. The proposed method is combining the {\epsilon}-Constraint and theCuckoo algorithm. First the multi objective problem transfers into asingle-objective problem using $\epsilon$-Constraint, then the Cuckoooptimization algorithm will optimize the problem in each task. At last theoptimized Pareto frontier will be drawn. The advantage of this method is thehigh accuracy and the dispersion of its Pareto frontier. In order to testingthe efficiency of the suggested method, a lot of test problems have been solvedusing this method. Comparing the results of this method with the results ofother similar methods shows that the Cuckoo algorithm is more suitable forsolving the multi-objective problems.
arxiv-13500-34 | Online Stochastic Linear Optimization under One-bit Feedback | http://arxiv.org/pdf/1509.07728v1.pdf | author:Lijun Zhang, Tianbao Yang, Rong Jin, Zhi-Hua Zhou category:cs.LG published:2015-09-25 summary:In this paper, we study a special bandit setting of online stochastic linearoptimization, where only one-bit of information is revealed to the learner ateach round. This problem has found many applications including onlineadvertisement and online recommendation. We assume the binary feedback is arandom variable generated from the logit model, and aim to minimize the regretdefined by the unknown linear function. Although the existing method forgeneralized linear bandit can be applied to our problem, the high computationalcost makes it impractical for real-world problems. To address this challenge,we develop an efficient online learning algorithm by exploiting particularstructures of the observation model. Specifically, we adopt online Newton stepto estimate the unknown parameter and derive a tight confidence region based onthe exponential concavity of the logistic loss. Our analysis shows that theproposed algorithm achieves a regret bound of $O(d\sqrt{T})$, which matches theoptimal result of stochastic linear bandits.
arxiv-13500-35 | Efficient Computation of the Quasi Likelihood function for Discretely Observed Diffusion Processes | http://arxiv.org/pdf/1509.07751v1.pdf | author:Lars Josef Höök, Erik Lindström category:stat.CO q-fin.ST stat.ML published:2015-09-25 summary:We introduce a simple method for nearly simultaneous computation of allmoments needed for quasi maximum likelihood estimation of parameters indiscretely observed stochastic differential equations commonly seen in finance.The method proposed in this papers is not restricted to any particular dynamicsof the differential equation and is virtually insensitive to the samplinginterval. The key contribution of the paper is that computational complexity issublinear in the number of observations as we compute all moments through asingle operation. Furthermore, that operation can be done offline. Thesimulations show that the method is unbiased for all practical purposes for anysampling design, including random sampling, and that the computational cost iscomparable (actually faster for moderate and large data sets) to the simple,often severely biased, Euler-Maruyama approximation.
arxiv-13500-36 | Information Limits for Recovering a Hidden Community | http://arxiv.org/pdf/1509.07859v2.pdf | author:Bruce Hajek, Yihong Wu, Jiaming Xu category:stat.ML cs.IT math.IT published:2015-09-25 summary:We study the problem of recovering a hidden community of cardinality $K$ froman $n \times n$ symmetric data matrix $A$, where for distinct indices $i,j$,$A_{ij} \sim P$ if $i, j$ both belong to the community and $A_{ij} \sim Q$otherwise, for two known probability distributions $P$ and $Q$ depending on$n$. If $P={\rm Bern}(p)$ and $Q={\rm Bern}(q)$ with $p>q$, it reduces to theproblem of finding a densely-connected $K$-subgraph planted in a largeErd\"os-R\'enyi graph; if $P=\mathcal{N}(\mu,1)$ and $Q=\mathcal{N}(0,1)$ with$\mu>0$, it corresponds to the problem of locating a $K \times K$ principalsubmatrix of elevated means in a large Gaussian random matrix. We focus on twotypes of asymptotic recovery guarantees as $n \to \infty$: (1) weak recovery:expected number of classification errors is $o(K)$; (2) exact recovery:probability of classifying all indices correctly converges to one. Under mildassumptions on $P$ and $Q$, and allowing the community size to scalesublinearly with $n$, we derive a set of sufficient conditions and a set ofnecessary conditions for recovery, which are asymptotically tight with sharpconstants. The results hold in particular for the Gaussian case, and for thecase of bounded log likelihood ratio, including the Bernoulli case whenever$\frac{p}{q}$ and $\frac{1-p}{1-q}$ are bounded away from zero and infinity. Animportant algorithmic implication is that, whenever exact recovery isinformation theoretically possible, any algorithm that provides weak recoverywhen the community size is concentrated near $K$ can be upgraded to achieveexact recovery in linear additional time by a simple voting procedure.
arxiv-13500-37 | A Mathematical Theory for Clustering in Metric Spaces | http://arxiv.org/pdf/1509.07755v1.pdf | author:Cheng-Shang Chang, Wanjiun Liao, Yu-Sheng Chen, Li-Heng Liou category:cs.LG published:2015-09-25 summary:Clustering is one of the most fundamental problems in data analysis and ithas been studied extensively in the literature. Though many clusteringalgorithms have been proposed, clustering theories that justify the use ofthese clustering algorithms are still unsatisfactory. In particular, one of thefundamental challenges is to address the following question: What is a cluster in a set of data points? In this paper, we make an attempt to address such a question by considering aset of data points associated with a distance measure (metric). We firstpropose a new cohesion measure in terms of the distance measure. Using thecohesion measure, we define a cluster as a set of points that are cohesive tothemselves. For such a definition, we show there are various equivalentstatements that have intuitive explanations. We then consider the secondquestion: How do we find clusters and good partitions of clusters under such adefinition? For such a question, we propose a hierarchical agglomerative algorithm and apartitional algorithm. Unlike standard hierarchical agglomerative algorithms,our hierarchical agglomerative algorithm has a specific stopping criterion andit stops with a partition of clusters. Our partitional algorithm, called theK-sets algorithm in the paper, appears to be a new iterative algorithm. Unlikethe Lloyd iteration that needs two-step minimization, our K-sets algorithm onlytakes one-step minimization. One of the most interesting findings of our paper is the duality resultbetween a distance measure and a cohesion measure. Such a duality result leadsto a dual K-sets algorithm for clustering a set of data points with a cohesionmeasure. The dual K-sets algorithm converges in the same way as a sequentialversion of the classical kernel K-means algorithm. The key difference is that acohesion measure does not need to be positive semi-definite.
arxiv-13500-38 | Feature Evaluation of Deep Convolutional Neural Networks for Object Recognition and Detection | http://arxiv.org/pdf/1509.07627v1.pdf | author:Hirokatsu Kataoka, Kenji Iwata, Yutaka Satoh category:cs.CV cs.AI cs.MM published:2015-09-25 summary:In this paper, we evaluate convolutional neural network (CNN) features usingthe AlexNet architecture and very deep convolutional network (VGGNet)architecture. To date, most CNN researchers have employed the last layersbefore output, which were extracted from the fully connected feature layers.However, since it is unlikely that feature representation effectiveness isdependent on the problem, this study evaluates additional convolutional layersthat are adjacent to fully connected layers, in addition to executing simpletuning for feature concatenation (e.g., layer 3 + layer 5 + layer 7) andtransformation, using tools such as principal component analysis. In ourexperiments, we carried out detection and classification tasks using theCaltech 101 and Daimler Pedestrian Benchmark Datasets.
arxiv-13500-39 | Self-localization Using Visual Experience Across Domains | http://arxiv.org/pdf/1509.07618v1.pdf | author:Taisho Tsukamoto, Kanji Tanaka category:cs.CV published:2015-09-25 summary:In this study, we aim to solve the single-view robot self-localizationproblem by using visual experience across domains. Although the bag-of-wordsmethod constitutes a popular approach to single-view localization, it failsbadly when it's visual vocabulary is learned and tested in different domains.Further, we are interested in using a cross-domain setting, in which the visualvocabulary is learned in different seasons and routes from the inputquery/database scenes. Our strategy is to mine a cross-domain visualexperience, a library of raw visual images collected in different domains, todiscover the relevant visual patterns that effectively explain the input scene,and use them for scene retrieval. In particular, we show that the appearanceand the pose of the mined visual patterns of a query scene can be efficientlyand discriminatively matched against those of the database scenes by employingimage-to-class distance and spatial pyramid matching. Experimental resultsobtained using a novel cross-domain dataset show that our system achievespromising results despite our visual vocabulary being learned and tested indifferent domains.
arxiv-13500-40 | Computational Intelligence Challenges and Applications on Large-Scale Astronomical Time Series Databases | http://arxiv.org/pdf/1509.07823v1.pdf | author:Pablo Huijse, Pablo A. Estevez, Pavlos Protopapas, Jose C. Principe, Pablo Zegers category:astro-ph.IM cs.LG published:2015-09-25 summary:Time-domain astronomy (TDA) is facing a paradigm shift caused by theexponential growth of the sample size, data complexity and data generationrates of new astronomical sky surveys. For example, the Large Synoptic SurveyTelescope (LSST), which will begin operations in northern Chile in 2022, willgenerate a nearly 150 Petabyte imaging dataset of the southern hemisphere sky.The LSST will stream data at rates of 2 Terabytes per hour, effectivelycapturing an unprecedented movie of the sky. The LSST is expected not only toimprove our understanding of time-varying astrophysical objects, but also toreveal a plethora of yet unknown faint and fast-varying phenomena. To cope witha change of paradigm to data-driven astronomy, the fields of astroinformaticsand astrostatistics have been created recently. The new data-oriented paradigmsfor astronomy combine statistics, data mining, knowledge discovery, machinelearning and computational intelligence, in order to provide the automated androbust methods needed for the rapid detection and classification of knownastrophysical objects as well as the unsupervised characterization of novelphenomena. In this article we present an overview of machine learning andcomputational intelligence applications to TDA. Future big data challenges andnew lines of research in TDA, focusing on the LSST, are identified anddiscussed from the viewpoint of computational intelligence/machine learning.Interdisciplinary collaboration will be required to cope with the challengesposed by the deluge of astronomical data coming from the LSST.
arxiv-13500-41 | Validity of time reversal for testing Granger causality | http://arxiv.org/pdf/1509.07636v2.pdf | author:Irene Winkler, Danny Panknin, Daniel Bartz, Klaus-Robert Müller, Stefan Haufe category:math.ST stat.ML stat.TH published:2015-09-25 summary:Inferring causal interactions from observed data is a challenging problem,especially in the presence of measurement noise. To alleviate the problem ofspurious causality, Haufe et al. (2013) proposed to contrast measures ofinformation flow obtained on the original data against the same measuresobtained on time-reversed data. They show that this procedure, time-reversedGranger causality (TRGC), robustly rejects causal interpretations on mixturesof independent signals. While promising results have been achieved insimulations, it was so far unknown whether time reversal leads to validmeasures of information flow in the presence of true interaction. Here we provethat, for linear finite-order autoregressive processes with unidirectionalinformation flow, the application of time reversal for testing Grangercausality indeed leads to correct estimates of information flow and itsdirectionality. Using simulations, we further show that TRGC is able to infercorrect directionality with similar statistical power as the net Grangercausality between two variables, while being much more robust to the presenceof measurement noise.
arxiv-13500-42 | Discriminative Map Retrieval Using View-Dependent Map Descriptor | http://arxiv.org/pdf/1509.07615v1.pdf | author:Enfu Liu, Kanji Tanaka category:cs.CV published:2015-09-25 summary:Map retrieval, the problem of similarity search over a large collection of 2Dpointset maps previously built by mobile robots, is crucial for autonomousnavigation in indoor and outdoor environments. Bag-of-words (BoW) methodsconstitute a popular approach to map retrieval; however, these methods haveextremely limited descriptive ability because they ignore the spatial layoutinformation of the local features. The main contribution of this paper is anextension of the bag-of-words map retrieval method to enable the use of spatialinformation from local features. Our strategy is to explicitly model a uniqueviewpoint of an input local map; the pose of the local feature is defined withrespect to this unique viewpoint, and can be viewed as an additional invariantfeature for discriminative map retrieval. Specifically, we wish to determine aunique viewpoint that is invariant to moving objects, clutter, occlusions, andactual viewpoints. Hence, we perform scene parsing to analyze the scenestructure, and consider the "center" of the scene structure to be the uniqueviewpoint. Our scene parsing is based on a Manhattan world grammar that imposesa quasi-Manhattan world constraint to enable the robust detection of a scenestructure that is invariant to clutter and moving objects. Experimental resultsusing the publicly available radish dataset validate the efficacy of theproposed approach.
arxiv-13500-43 | Deep Multimodal Embedding: Manipulating Novel Objects with Point-clouds, Language and Trajectories | http://arxiv.org/pdf/1509.07831v1.pdf | author:Jaeyong Sung, Ian Lenz, Ashutosh Saxena category:cs.RO cs.AI cs.CV cs.LG published:2015-09-25 summary:A robot operating in a real-world environment needs to perform reasoning witha variety of sensing modalities. However, manually designing features thatallow a learning algorithm to relate these different modalities can beextremely challenging. In this work, we consider the task of manipulating novelobjects and appliances. To this end, we learn to embed point-cloud, naturallanguage, and manipulation trajectory data into a shared embedding space usinga deep neural network. In order to learn semantically meaningful spacesthroughout our network, we introduce a method for pre-training its lower layersfor multimodal feature embedding and a method for fine-tuning this embeddingspace using a loss-based margin. We test our model on the Robobarista dataset[22], where we achieve significant improvements in both accuracy and inferencetime over the previous state of the art.
arxiv-13500-44 | Selecting Relevant Web Trained Concepts for Automated Event Retrieval | http://arxiv.org/pdf/1509.07845v1.pdf | author:Bharat Singh, Xintong Han, Zhe Wu, Vlad I. Morariu, Larry S. Davis category:cs.CV cs.CL cs.IR published:2015-09-25 summary:Complex event retrieval is a challenging research problem, especially when notraining videos are available. An alternative to collecting training videos isto train a large semantic concept bank a priori. Given a text description of anevent, event retrieval is performed by selecting concepts linguisticallyrelated to the event description and fusing the concept responses on unseenvideos. However, defining an exhaustive concept lexicon and pre-training itrequires vast computational resources. Therefore, recent approaches automateconcept discovery and training by leveraging large amounts of weakly annotatedweb data. Compact visually salient concepts are automatically obtained by theuse of concept pairs or, more generally, n-grams. However, not all visuallysalient n-grams are necessarily useful for an event query--some combinations ofconcepts may be visually compact but irrelevant--and this drastically affectsperformance. We propose an event retrieval algorithm that constructs pairs ofautomatically discovered concepts and then prunes those concepts that areunlikely to be helpful for retrieval. Pruning depends both on the query and onthe specific video instance being evaluated. Our approach also addressescalibration and domain adaptation issues that arise when applying conceptdetectors to unseen videos. We demonstrate large improvements over other visionbased systems on the TRECVID MED 13 dataset.
arxiv-13500-45 | Sentiment Uncertainty and Spam in Twitter Streams and Its Implications for General Purpose Realtime Sentiment Analysis | http://arxiv.org/pdf/1509.07612v1.pdf | author:Nils Haldenwang, Oliver Vornberger category:cs.CL published:2015-09-25 summary:State of the art benchmarks for Twitter Sentiment Analysis do not considerthe fact that for more than half of the tweets from the public stream adistinct sentiment cannot be chosen. This paper provides a new perspective onTwitter Sentiment Analysis by highlighting the necessity of explicitlyincorporating uncertainty. Moreover, a dataset of high quality to evaluatesolutions for this new problem is introduced and made publicly available.
arxiv-13500-46 | Training Deep Networks with Structured Layers by Matrix Backpropagation | http://arxiv.org/pdf/1509.07838v4.pdf | author:Catalin Ionescu, Orestis Vantzos, Cristian Sminchisescu category:cs.CV cs.AI published:2015-09-25 summary:Deep neural network architectures have recently produced excellent results ina variety of areas in artificial intelligence and visual recognition, wellsurpassing traditional shallow architectures trained using hand-designedfeatures. The power of deep networks stems both from their ability to performlocal computations followed by pointwise non-linearities over increasinglylarger receptive fields, and from the simplicity and scalability of thegradient-descent training procedure based on backpropagation. An open problemis the inclusion of layers that perform global, structured matrix computationslike segmentation (e.g. normalized cuts) or higher-order pooling (e.g.log-tangent space metrics defined over the manifold of symmetric positivedefinite matrices) while preserving the validity and efficiency of anend-to-end deep training framework. In this paper we propose a soundmathematical apparatus to formally integrate global structured computation intodeep computation architectures. At the heart of our methodology is thedevelopment of the theory and practice of backpropagation that generalizes tothe calculus of adjoint matrix variations. The proposed matrix backpropagationmethodology applies broadly to a variety of problems in machine learning orcomputational perception. Here we illustrate it by performing visualsegmentation experiments using the BSDS and MSCOCO benchmarks, where we showthat deep networks relying on second-order pooling and normalized cuts layers,trained end-to-end using matrix backpropagation, outperform counterparts thatdo not take advantage of such global layers.
arxiv-13500-47 | Incremental Loop Closure Verification by Guided Sampling | http://arxiv.org/pdf/1509.07611v1.pdf | author:Kanji Tanaka category:cs.CV published:2015-09-25 summary:Loop closure detection, the task of identifying locations revisited by arobot in a sequence of odometry and perceptual observations, is typicallyformulated as a combination of two subtasks: (1) bag-of-words image retrievaland (2) post-verification using RANSAC geometric verification. The maincontribution of this study is the proposal of a novel post-verificationframework that achieves good precision recall trade-off in loop closuredetection. This study is motivated by the fact that not all loop closurehypotheses are equally plausible (e.g., owing to mutual consistency betweenloop closure constraints) and that if we have evidence that one hypothesis ismore plausible than the others, then it should be verified more frequently. Wedemonstrate that the problem of loop closure detection can be viewed as aninstance of a multi-model hypothesize-and-verify framework and build guidedsampling strategies on the framework where loop closures proposed using imageretrieval are verified in a planned order (rather than in a conventionaluniform order) to operate in a constant time. Experimental results using astereo SLAM system confirm that the proposed strategy, the use of loop closureconstraints and robot trajectory hypotheses as a guide, achieves promisingresults despite the fact that there exists a significant number of falsepositive constraints and hypotheses.
arxiv-13500-48 | Evasion and Hardening of Tree Ensemble Classifiers | http://arxiv.org/pdf/1509.07892v1.pdf | author:Alex Kantchelian, J. D. Tygar, Anthony D. Joseph category:cs.LG cs.CR stat.ML published:2015-09-25 summary:Recent work has successfully constructed adversarial "evading" instances fordifferentiable prediction models. However generating adversarial instances fortree ensembles, a piecewise constant class of models, has remained an openproblem. In this paper, we construct both exact and approximate evasionalgorithms for tree ensembles: for a given instance x we find the "nearest"instance x' such that the classifier predictions of x and x' are different.First, we show that finding such instances is practically possible despite treeensemble models being non-differentiable and the optimal evasion problem beingNP-hard. In addition, we quantify the susceptibility of such models applied to thetask of recognizing handwritten digits by measuring the distance between theoriginal instance and the modified instance under the L0, L1, L2 and L-infinitynorms. We also analyze a wide variety of classifiers including linear andRBF-kernel models, max-ensemble of linear models, and neural networks forcomparison purposes. Our analysis shows that tree ensembles produced by astate-of-the-art gradient boosting method are consistently the least robustmodels notwithstanding their competitive accuracy. Finally, we show that asufficient number of retraining rounds with L0-adversarial instances makes thehardened model three times harder to evade. This retraining set also marginallyimproves classification accuracy, but simultaneously makes the model moresusceptible to L1, L2 and L-infinity evasions.
arxiv-13500-49 | Learning Concept Embeddings with Combined Human-Machine Expertise | http://arxiv.org/pdf/1509.07479v2.pdf | author:Michael J. Wilber, Iljung S. Kwak, David Kriegman, Serge Belongie category:cs.CV published:2015-09-24 summary:This paper presents our work on "SNaCK," a low-dimensional concept embeddingalgorithm that combines human expertise with automatic machine similaritykernels. Both parts are complimentary: human insight can capture relationshipsthat are not apparent from the object's visual similarity and the machine canhelp relieve the human from having to exhaustively specify many constraints. Weshow that our SNaCK embeddings are useful in several tasks: distinguishingprime and nonprime numbers on MNIST, discovering labeling mistakes in theCaltech UCSD Birds (CUB) dataset with the help of deep-learned features,creating training datasets for bird classifiers, capturing subjective humantaste on a new dataset of 10,000 foods, and qualitatively exploring anunstructured set of pictographic characters. Comparisons with thestate-of-the-art in these tasks show that SNaCK produces better conceptembeddings that require less human supervision than the leading methods.
arxiv-13500-50 | Noise-Robust ASR for the third 'CHiME' Challenge Exploiting Time-Frequency Masking based Multi-Channel Speech Enhancement and Recurrent Neural Network | http://arxiv.org/pdf/1509.07211v1.pdf | author:Zaihu Pang, Fengyun Zhu category:cs.SD cs.CL published:2015-09-24 summary:In this paper, the Lingban entry to the third 'CHiME' speech separation andrecognition challenge is presented. A time-frequency masking based speechenhancement front-end is proposed to suppress the environmental noise utilizingmulti-channel coherence and spatial cues. The state-of-the-art speechrecognition techniques, namely recurrent neural network based acoustic andlanguage modeling, state space minimum Bayes risk based discriminative acousticmodeling, and i-vector based acoustic condition modeling, are carefullyintegrated into the speech recognition back-end. To further improve the systemperformance by fully exploiting the advantages of different technologies, thefinal recognition results are obtained by lattice combination and rescoring.Evaluations carried out on the official dataset prove the effectiveness of theproposed systems. Comparing with the best baseline result, the proposed systemobtains consistent improvements with over 57% relative word error ratereduction on the real-data test set.
arxiv-13500-51 | Automatic Concept Discovery from Parallel Text and Visual Corpora | http://arxiv.org/pdf/1509.07225v1.pdf | author:Chen Sun, Chuang Gan, Ram Nevatia category:cs.CV published:2015-09-24 summary:Humans connect language and vision to perceive the world. How to build asimilar connection for computers? One possible way is via visual concepts,which are text terms that relate to visually discriminative entities. Wepropose an automatic visual concept discovery algorithm using parallel text andvisual corpora; it filters text terms based on the visual discriminative powerof the associated images, and groups them into concepts using visual andsemantic similarities. We illustrate the applications of the discoveredconcepts using bidirectional image and sentence retrieval task and imagetagging task, and show that the discovered concepts not only outperform severallarge sets of manually selected concepts significantly, but also achieves thestate-of-the-art performance in the retrieval task.
arxiv-13500-52 | Sparsity-based Correction of Exponential Artifacts | http://arxiv.org/pdf/1509.07234v1.pdf | author:Yin Ding, Ivan W. Selesnick category:cs.LG published:2015-09-24 summary:This paper describes an exponential transient excision algorithm (ETEA). Inbiomedical time series analysis, e.g., in vivo neural recording andelectrocorticography (ECoG), some measurement artifacts take the form ofpiecewise exponential transients. The proposed method is formulated as anunconstrained convex optimization problem, regularized by smoothed l1-normpenalty function, which can be solved by majorization-minimization (MM) method.With a slight modification of the regularizer, ETEA can also suppress moreirregular piecewise smooth artifacts, especially, ocular artifacts (OA) inelectroencephalog- raphy (EEG) data. Examples of synthetic signal, EEG data,and ECoG data are presented to illustrate the proposed algorithms.
arxiv-13500-53 | Opinion mining from twitter data using evolutionary multinomial mixture models | http://arxiv.org/pdf/1509.07344v1.pdf | author:Md. Abul Hasnat, Julien Velcin, Stéphane Bonnevay, Julien Jacques category:cs.IR stat.ML published:2015-09-24 summary:Image of an entity can be defined as a structured and dynamic representationwhich can be extracted from the opinions of a group of users or population.Automatic extraction of such an image has certain importance in politicalscience and sociology related studies, e.g., when an extended inquiry fromlarge-scale data is required. We study the images of two politicallysignificant entities of France. These images are constructed by analyzing theopinions collected from a well known social media called Twitter. Our goal isto build a system which can be used to automatically extract the image ofentities over time. In this paper, we propose a novel evolutionary clustering method based on theparametric link among Multinomial mixture models. First we propose theformulation of a generalized model that establishes parametric links among theMultinomial distributions. Afterward, we follow a model-based clusteringapproach to explore different parametric sub-models and select the best model.For the experiments, first we use synthetic temporal data. Next, we apply themethod to analyze the annotated social media data. Results show that theproposed method is better than the state-of-the-art based on the commonevaluation metrics. Additionally, our method can provide interpretation aboutthe temporal evolution of the clusters.
arxiv-13500-54 | Adaptive Sequential Optimization with Applications to Machine Learning | http://arxiv.org/pdf/1509.07422v1.pdf | author:Craig Wilson, Venugopal V. Veeravalli category:cs.LG cs.DS published:2015-09-24 summary:A framework is introduced for solving a sequence of slowly changingoptimization problems, including those arising in regression and classificationapplications, using optimization algorithms such as stochastic gradient descent(SGD). The optimization problems change slowly in the sense that the minimizerschange at either a fixed or bounded rate. A method based on estimates of thechange in the minimizers and properties of the optimization algorithm isintroduced for adaptively selecting the number of samples needed from thedistributions underlying each problem in order to ensure that the excess risk,i.e., the expected gap between the loss achieved by the approximate minimizerproduced by the optimization algorithm and the exact minimizer, does not exceeda target level. Experiments with synthetic and real data are used to confirmthat this approach performs well.
arxiv-13500-55 | Bilingual Distributed Word Representations from Document-Aligned Comparable Data | http://arxiv.org/pdf/1509.07308v2.pdf | author:Ivan Vulić, Marie-Francine Moens category:cs.CL published:2015-09-24 summary:We propose a new model for learning bilingual word representations fromnon-parallel document-aligned data. Following the recent advances in wordrepresentation learning, our model learns dense real-valued word vectors, thatis, bilingual word embeddings (BWEs). Unlike prior work on inducing BWEs whichheavily relied on parallel sentence-aligned corpora and/or readily availabletranslation resources such as dictionaries, the article reveals that BWEs maybe learned solely on the basis of document-aligned comparable data without anyadditional lexical resources nor syntactic information. We present a comparisonof our approach with previous state-of-the-art models for learning bilingualword representations from comparable data that rely on the framework ofmultilingual probabilistic topic modeling (MuPTM), as well as withdistributional local context-counting models. We demonstrate the utility of theinduced BWEs in two semantic tasks: (1) bilingual lexicon extraction, (2)suggesting word translations in context for polysemous words. Our simple yeteffective BWE-based models significantly outperform the MuPTM-based andcontext-counting representation models from comparable data as well as priorBWE-based models, and acquire the best reported results on both tasks for allthree tested language pairs.
arxiv-13500-56 | A Review of Feature Selection Methods Based on Mutual Information | http://arxiv.org/pdf/1509.07577v1.pdf | author:Jorge R. Vergara, Pablo A. Estévez category:cs.LG stat.ML published:2015-09-24 summary:In this work we present a review of the state of the art of informationtheoretic feature selection methods. The concepts of feature relevance,redundance and complementarity (synergy) are clearly defined, as well as Markovblanket. The problem of optimal feature selection is defined. A unifyingtheoretical framework is described, which can retrofit successful heuristiccriteria, indicating the approximations made by each method. A number of openproblems in the field are presented.
arxiv-13500-57 | Channel Vector Subspace Estimation from Low-Dimensional Projections | http://arxiv.org/pdf/1509.07469v1.pdf | author:Saeid Haghighatshoar, Giuseppe Caire category:cs.IT math.IT stat.ML published:2015-09-24 summary:In this paper, we propose efficient algorithms for estimating the signalsubspace of mobile users in a wireless communication environment with amulti-antenna base-station with $M$ antennas. We assume that, for reducing theRF front-end complexity and overall A/D conversion rate, the JSDMtransmitter/receiver is split into the product of a baseband linear projection(digital) and an RF reconfigurable beamforming network (analog) with only $m\ll M$ RF chains. This implies that only $m$ analog observations can beobtained for subspace estimation, and the standard sample covariance estimatoris not available. We develop efficient algorithms that estimate the dominant signal subspacefrom sampling only $m=O(2 \sqrt{M})$ specific array elements according to acoprime scheme, and for a given $p \leq M$, return a $p$-dimensional beamformerthat has a performance comparable with the best $p$-dim beamformer designed byknowing the exact covariance matrix of the received signal. We asses theperformance of our proposed estimators both analytically and empirically vianumerical simulations, and compare it with that of the other state-of-the-artmethods proposed in the literature, which are also reviewed and put in thecontext of estimating the subspace of the signal.
arxiv-13500-58 | Learning Visual Clothing Style with Heterogeneous Dyadic Co-occurrences | http://arxiv.org/pdf/1509.07473v1.pdf | author:Andreas Veit, Balazs Kovacs, Sean Bell, Julian McAuley, Kavita Bala, Serge Belongie category:cs.CV published:2015-09-24 summary:With the rapid proliferation of smart mobile devices, users now take millionsof photos every day. These include large numbers of clothing and accessoryimages. We would like to answer questions like `What outfit goes well with thispair of shoes?' To answer these types of questions, one has to go beyondlearning visual similarity and learn a visual notion of compatibility acrosscategories. In this paper, we propose a novel learning framework to help answerthese types of questions. The main idea of this framework is to learn a featuretransformation from images of items into a latent space that expressescompatibility. For the feature transformation, we use a Siamese ConvolutionalNeural Network (CNN) architecture, where training examples are pairs of itemsthat are either compatible or incompatible. We model compatibility based onco-occurrence in large-scale user behavior data; in particular co-purchase datafrom Amazon.com. To learn cross-category fit, we introduce a strategic methodto sample training data, where pairs of items are heterogeneous dyads, i.e.,the two elements of a pair belong to different high-level categories. Whilethis approach is applicable to a wide variety of settings, we focus on therepresentative problem of learning compatible clothing style. Our resultsindicate that the proposed framework is capable of learning semanticinformation about visual style and is able to generate outfits of clothes, withitems from different categories, that go well together.
arxiv-13500-59 | Spatially Encoding Temporal Correlations to Classify Temporal Data Using Convolutional Neural Networks | http://arxiv.org/pdf/1509.07481v1.pdf | author:Zhiguang Wang, Tim Oates category:cs.LG published:2015-09-24 summary:We propose an off-line approach to explicitly encode temporal patternsspatially as different types of images, namely, Gramian Angular Fields andMarkov Transition Fields. This enables the use of techniques from computervision for feature learning and classification. We used Tiled ConvolutionalNeural Networks to learn high-level features from individual GAF, MTF, andGAF-MTF images on 12 benchmark time series datasets and two realspatial-temporal trajectory datasets. The classification results of ourapproach are competitive with state-of-the-art approaches on both types ofdata. An analysis of the features and weights learned by the CNNs explains whythe approach works.
arxiv-13500-60 | Multi-Region Probabilistic Dice Similarity Coefficient using the Aitchison Distance and Bipartite Graph Matching | http://arxiv.org/pdf/1509.07244v3.pdf | author:Shawn Andrews, Ghassan Hamarneh category:cs.CV published:2015-09-24 summary:Validation of image segmentation methods is of critical importance.Probabilistic image segmentation is increasingly popular as it capturesuncertainty in the results. Image segmentation methods that supportmulti-region (as opposed to binary) delineation are more favourable as theycapture interactions between the different objects in the image. The Dicesimilarity coefficient (DSC) has been a popular metric for evaluating theaccuracy of automated or semi-automated segmentation methods by comparing theirresults to the ground truth. In this work, we develop an extension of the DSCto multi-region probabilistic segmentations (with unordered labels). We usebipartite graph matching to establish label correspondences and propose twofunctions that extend the DSC, one based on absolute probability differencesand one based on the Aitchison distance. These provide a robust and accuratemeasure of multi-region probabilistic segmentation accuracy.
arxiv-13500-61 | Description of the Odin Event Extraction Framework and Rule Language | http://arxiv.org/pdf/1509.07513v1.pdf | author:Marco A. Valenzuela-Escárcega, Gus Hahn-Powell, Mihai Surdeanu category:cs.CL published:2015-09-24 summary:This document describes the Odin framework, which is a domain-independentplatform for developing rule-based event extraction models. Odin aims to bepowerful (the rule language allows the modeling of complex syntacticstructures) and robust (to recover from syntactic parsing errors, syntacticpatterns can be freely mixed with surface, token-based patterns), whileremaining simple (some domain grammars can be up and running in minutes), andfast (Odin processes over 100 sentences/second in a real-world domain with over200 rules). Here we include a thorough definition of the Odin rule language,together with a description of the Odin API in the Scala language, which allowsone to apply these rules to arbitrary texts.
arxiv-13500-62 | Provable approximation properties for deep neural networks | http://arxiv.org/pdf/1509.07385v3.pdf | author:Uri Shaham, Alexander Cloninger, Ronald R. Coifman category:stat.ML cs.LG cs.NE published:2015-09-24 summary:We discuss approximation of functions using deep neural nets. Given afunction $f$ on a $d$-dimensional manifold $\Gamma \subset \mathbb{R}^m$, weconstruct a sparsely-connected depth-4 neural network and bound its error inapproximating $f$. The size of the network depends on dimension and curvatureof the manifold $\Gamma$, the complexity of $f$, in terms of its waveletdescription, and only weakly on the ambient dimension $m$. Essentially, ournetwork computes wavelet functions, which are computed from Rectified LinearUnits (ReLU)
arxiv-13500-63 | On Optimizing Human-Machine Task Assignments | http://arxiv.org/pdf/1509.07543v1.pdf | author:Andreas Veit, Michael Wilber, Rajan Vaish, Serge Belongie, James Davis, Vishal Anand, Anshu Aviral, Prithvijit Chakrabarty, Yash Chandak, Sidharth Chaturvedi, Chinmaya Devaraj, Ankit Dhall, Utkarsh Dwivedi, Sanket Gupte, Sharath N. Sridhar, Karthik Paga, Anuj Pahuja, Aditya Raisinghani, Ayush Sharma, Shweta Sharma, Darpana Sinha, Nisarg Thakkar, K. Bala Vignesh, Utkarsh Verma, Kanniganti Abhishek, Amod Agrawal, Arya Aishwarya, Aurgho Bhattacharjee, Sarveshwaran Dhanasekar, Venkata Karthik Gullapalli, Shuchita Gupta, Chandana G, Kinjal Jain, Simran Kapur, Meghana Kasula, Shashi Kumar, Parth Kundaliya, Utkarsh Mathur, Alankrit Mishra, Aayush Mudgal, Aditya Nadimpalli, Munakala Sree Nihit, Akanksha Periwal, Ayush Sagar, Ayush Shah, Vikas Sharma, Yashovardhan Sharma, Faizal Siddiqui, Virender Singh, Abhinav S., Anurag. D. Yadav category:cs.HC cs.CV published:2015-09-24 summary:When crowdsourcing systems are used in combination with machine inferencesystems in the real world, they benefit the most when the machine system isdeeply integrated with the crowd workers. However, if researchers wish tointegrate the crowd with "off-the-shelf" machine classifiers, this deepintegration is not always possible. This work explores two strategies toincrease accuracy and decrease cost under this setting. First, we show thatreordering tasks presented to the human can create a significant accuracyimprovement. Further, we show that greedily choosing parameters to maximizemachine accuracy is sub-optimal, and joint optimization of the combined systemimproves performance.
arxiv-13500-64 | Mapping Generative Models onto a Network of Digital Spiking Neurons | http://arxiv.org/pdf/1509.07302v2.pdf | author:Bruno U. Pedroni, Srinjoy Das, John V. Arthur, Paul A. Merolla, Bryan L. Jackson, Dharmendra S. Modha, Kenneth Kreutz-Delgado, Gert Cauwenberghs category:cs.NE q-bio.NC published:2015-09-24 summary:Stochastic neural networks such as Restricted Boltzmann Machines (RBMs) havebeen successfully used in applications ranging from speech recognition to imageclassification. Inference and learning in these algorithms use a Markov ChainMonte Carlo procedure called Gibbs sampling, where a logistic function formsthe kernel of this sampler. On the other side of the spectrum, neuromorphicsystems have shown great promise for low-power and parallelized cognitivecomputing, but lack well-suited applications and automation procedures. In thiswork, we propose a systematic method for bridging the RBM algorithm and digitalneuromorphic systems, with a generative pattern completion task as proof ofconcept. For this, we first propose a method of producing the Gibbs samplerusing bio-inspired digital noisy integrate-and-fire neurons. Next, we describethe process of mapping generative RBMs trained offline onto the IBM TrueNorthneurosynaptic processor -- a low-power digital neuromorphic VLSI substrate.Mapping these algorithms onto neuromorphic hardware presents unique challengesin network connectivity and weight and bias quantization, which, in turn,require architectural and design strategies for the physical realization.Generative performance metrics are analyzed to validate the neuromorphicrequirements and to best select the neuron parameters for the model. Lastly, wedescribe a design automation procedure which achieves optimal resource usage,accounting for the novel hardware adaptations. This work represents the firstimplementation of generative RBM inference on a neuromorphic VLSI substrate.
arxiv-13500-65 | Linear-time Learning on Distributions with Approximate Kernel Embeddings | http://arxiv.org/pdf/1509.07553v1.pdf | author:Dougal J. Sutherland, Junier B. Oliva, Barnabás Póczos, Jeff Schneider category:stat.ML cs.LG published:2015-09-24 summary:Many interesting machine learning problems are best posed by consideringinstances that are distributions, or sample sets drawn from distributions.Previous work devoted to machine learning tasks with distributional inputs hasdone so through pairwise kernel evaluations between pdfs (or sample sets).While such an approach is fine for smaller datasets, the computation of an $N\times N$ Gram matrix is prohibitive in large datasets. Recent scalableestimators that work over pdfs have done so only with kernels that useEuclidean metrics, like the $L_2$ distance. However, there are a myriad ofother useful metrics available, such as total variation, Hellinger distance,and the Jensen-Shannon divergence. This work develops the first random featuresfor pdfs whose dot product approximates kernels using these non-Euclideanmetrics, allowing estimators using such kernels to scale to large datasets byworking in a primal space, without computing large Gram matrices. We provide ananalysis of the approximation error in using our proposed random features andshow empirically the quality of our approximation both in estimating a Grammatrix and in solving learning tasks in real-world and synthetic data.
arxiv-13500-66 | High Dimensional Data Modeling Techniques for Detection of Chemical Plumes and Anomalies in Hyperspectral Images and Movies | http://arxiv.org/pdf/1509.07497v2.pdf | author:Yi, Wang, Guangliang Chen, Mauro Maggioni category:stat.ML published:2015-09-24 summary:We briefly review recent progress in techniques for modeling and analyzinghyperspectral images and movies, in particular for detecting plumes of bothknown and unknown chemicals. For detecting chemicals of known spectrum, weextend the technique of using a single subspace for modeling the background toa "mixture of subspaces" model to tackle more complicated background.Furthermore, we use partial least squares regression on a resampled trainingset to boost performance. For the detection of unknown chemicals we view theproblem as an anomaly detection problem, and use novel estimators withlow-sampled complexity for intrinsically low-dimensional data inhigh-dimensions that enable us to model the "normal" spectra and detectanomalies. We apply these algorithms to benchmark data sets made available bythe Automated Target Detection program co-funded by NSF, DTRA and NGA, andcompare, when applicable, to current state-of-the-art algorithms, withfavorable results.
arxiv-13500-67 | Model-based Reinforcement Learning with Parametrized Physical Models and Optimism-Driven Exploration | http://arxiv.org/pdf/1509.06824v2.pdf | author:Christopher Xie, Sachin Patil, Teodor Moldovan, Sergey Levine, Pieter Abbeel category:cs.LG cs.RO published:2015-09-23 summary:In this paper, we present a robotic model-based reinforcement learning methodthat combines ideas from model identification and model predictive control. Weuse a feature-based representation of the dynamics that allows the dynamicsmodel to be fitted with a simple least squares procedure, and the features areidentified from a high-level specification of the robot's morphology,consisting of the number and connectivity structure of its links. Modelpredictive control is then used to choose the actions under an optimistic modelof the dynamics, which produces an efficient and goal-directed explorationstrategy. We present real time experimental results on standard benchmarkproblems involving the pendulum, cartpole, and double pendulum systems.Experiments indicate that our method is able to learn a range of benchmarktasks substantially faster than the previous best methods. To evaluate ourapproach on a realistic robotic control task, we also demonstrate real timecontrol of a simulated 7 degree of freedom arm.
arxiv-13500-68 | One-Shot Learning of Manipulation Skills with Online Dynamics Adaptation and Neural Network Priors | http://arxiv.org/pdf/1509.06841v2.pdf | author:Justin Fu, Sergey Levine, Pieter Abbeel category:cs.LG cs.RO published:2015-09-23 summary:One of the key challenges in applying reinforcement learning to complexrobotic control tasks is the need to gather large amounts of experience inorder to find an effective policy for the task at hand. Model-basedreinforcement learning can achieve good sample efficiency, but requires theability to learn a model of the dynamics that is good enough to learn aneffective policy. In this work, we develop a modelbased reinforcement learningalgorithm that combines prior knowledge from previous tasks with onlineadaptation of the dynamics model. These two ingredients enable highly sampleefficient learning even in regimes where estimating the true dynamics is verydifficult, since the online model adaptation allows the method to locallycompensate for unmodeled variation in the dynamics. We encode the priorexperience into a neural network dynamics model, and adapt it online byprogressively refitting a local linear model of the dynamics. Our experimentalresults show that this approach can be used to solve a variety of complexrobotic manipulation tasks in just a single attempt, using prior data fromother manipulation behaviors.
arxiv-13500-69 | On The Direct Maximization of Quadratic Weighted Kappa | http://arxiv.org/pdf/1509.07107v3.pdf | author:David Vaughn, Derek Justice category:cs.LG published:2015-09-23 summary:In recent years, quadratic weighted kappa has been growing in popularity inthe machine learning community as an evaluation metric in domains where thetarget labels to be predicted are drawn from integer ratings, usually obtainedfrom human experts. For example, it was the metric of choice in several recent,high profile machine learning contests hosted on Kaggle :https://www.kaggle.com/c/asap-aes , https://www.kaggle.com/c/asap-sas ,https://www.kaggle.com/c/diabetic-retinopathy-detection . Yet, little isunderstood about the nature of this metric, its underlying mathematicalproperties, where it fits among other common evaluation metrics such as meansquared error (MSE) and correlation, or if it can be optimized analytically,and if so, how. Much of this is due to the cumbersome way that this metric iscommonly defined. In this paper we first derive an equivalent but much simpler,and more useful, definition for quadratic weighted kappa, and then employ thisalternate form to address the above issues.
arxiv-13500-70 | Is Image Super-resolution Helpful for Other Vision Tasks? | http://arxiv.org/pdf/1509.07009v2.pdf | author:Dengxin Dai, Yujian Wang, Yuhua Chen, Luc Van Gool category:cs.CV published:2015-09-23 summary:Despite the great advances made in the field of image super-resolution (ISR)during the last years, the performance has merely been evaluated perceptually.Thus, it is still unclear whether ISR is helpful for other vision tasks. Inthis paper, we present the first comprehensive study and analysis of theusefulness of ISR for other vision applications. In particular, six ISR methodsare evaluated on four popular vision tasks, namely edge detection, semanticimage segmentation, digit recognition, and scene recognition. We show thatapplying ISR to input images of other vision systems does improve theirperformance when the input images are of low-resolution. We also study thecorrelation between four standard perceptual evaluation criteria (namely PSNR,SSIM, IFC, and NQM) and the usefulness of ISR to the vision tasks. Experimentsshow that they correlate well with each other in general, but perceptualcriteria are still not accurate enough to be used as full proxies for theusefulness. We hope this work will inspire the community to evaluate ISRmethods also in real vision applications, and to adopt ISR as a pre-processingstep of other vision tasks if the resolution of their input images is low.
arxiv-13500-71 | A review of learning vector quantization classifiers | http://arxiv.org/pdf/1509.07093v1.pdf | author:David Nova, Pablo A. Estevez category:cs.LG astro-ph.IM cs.NE stat.ML published:2015-09-23 summary:In this work we present a review of the state of the art of Learning VectorQuantization (LVQ) classifiers. A taxonomy is proposed which integrates themost relevant LVQ approaches to date. The main concepts associated with modernLVQ approaches are defined. A comparison is made among eleven LVQ classifiersusing one real-world and two artificial datasets.
arxiv-13500-72 | Deep Temporal Sigmoid Belief Networks for Sequence Modeling | http://arxiv.org/pdf/1509.07087v1.pdf | author:Zhe Gan, Chunyuan Li, Ricardo Henao, David Carlson, Lawrence Carin category:stat.ML cs.LG published:2015-09-23 summary:Deep dynamic generative models are developed to learn sequential dependenciesin time-series data. The multi-layered model is designed by constructing ahierarchy of temporal sigmoid belief networks (TSBNs), defined as a sequentialstack of sigmoid belief networks (SBNs). Each SBN has a contextual hiddenstate, inherited from the previous SBNs in the sequence, and is used toregulate its hidden bias. Scalable learning and inference algorithms arederived by introducing a recognition model that yields fast sampling from thevariational posterior. This recognition model is trained jointly with thegenerative model, by maximizing its variational lower bound on thelog-likelihood. Experimental results on bouncing balls, polyphonic music,motion capture, and text streams show that the proposed approach achievesstate-of-the-art predictive performance, and has the capacity to synthesizevarious sequences.
arxiv-13500-73 | Well Tops Guided Prediction of Reservoir Properties using Modular Neural Network Concept A Case Study from Western Onshore, India | http://arxiv.org/pdf/1509.07079v1.pdf | author:Soumi Chaki, Akhilesh K Verma, Aurobinda Routray, William K Mohanty, Mamata Jenamani category:cs.NE cs.CE published:2015-09-23 summary:This paper proposes a complete framework consisting pre-processing, modeling,and post-processing stages to carry out well tops guided prediction of areservoir property (sand fraction) from three seismic attributes (seismicimpedance, instantaneous amplitude, and instantaneous frequency) using theconcept of modular artificial neural network (MANN). The data set used in thisstudy comprising three seismic attributes and well log data from eight wells,is acquired from a western onshore hydrocarbon field of India. Firstly, theacquired data set is integrated and normalized. Then, well log analysis andsegmentation of the total depth range into three different units (zones)separated by well tops are carried out. Secondly, three different networks aretrained corresponding to three different zones using combined data set of sevenwells and then trained networks are validated using the remaining test well.The target property of the test well is predicted using three different tunednetworks corresponding to three zones; and then the estimated values obtainedfrom three different networks are concatenated to represent the predicted logalong the complete depth range of the testing well. The application of multiplesimpler networks instead of a single one improves the prediction accuracy interms of performance metrics such as correlation coefficient, root mean squareerror, absolute error mean and program execution time.
arxiv-13500-74 | 3D Scan Registration using Curvelet Features in Planetary Environments | http://arxiv.org/pdf/1509.07075v1.pdf | author:Siddhant Ahuja, Peter Iles, Steven L. Waslander category:cs.CV cs.RO published:2015-09-23 summary:Topographic mapping in planetary environments relies on accurate 3D scanregistration methods. However, most global registration algorithms relying onfeatures such as FPFH and Harris-3D show poor alignment accuracy in thesesettings due to the poor structure of the Mars-like terrain and variableresolution, occluded, sparse range data that is hard to register without somea-priori knowledge of the environment. In this paper, we propose an alternativeapproach to 3D scan registration using the curvelet transform that performsmulti-resolution geometric analysis to obtain a set of coefficients indexed byscale (coarsest to finest), angle and spatial position. Features are detectedin the curvelet domain to take advantage of the directional selectivity of thetransform. A descriptor is computed for each feature by calculating the 3Dspatial histogram of the image gradients, and nearest neighbor based matchingis used to calculate the feature correspondences. Correspondence rejectionusing Random Sample Consensus identifies inliers, and a locally optimalSingular Value Decomposition-based estimation of the rigid-body transformationaligns the laser scans given the re-projected correspondences in the metricspace. Experimental results on a publicly available data-set of planetaryanalogue indoor facility, as well as simulated and real-world scans from NeptecDesign Group's IVIGMS 3D laser rangefinder at the outdoor CSA Mars yarddemonstrates improved performance over existing methods in the challengingsparse Mars-like terrain.
arxiv-13500-75 | A Novel Pre-processing Scheme to Improve the Prediction of Sand Fraction from Seismic Attributes using Neural Networks | http://arxiv.org/pdf/1509.07065v1.pdf | author:Soumi Chaki, Aurobinda Routray, William K. Mohanty category:cs.CE cs.LG published:2015-09-23 summary:This paper presents a novel pre-processing scheme to improve the predictionof sand fraction from multiple seismic attributes such as seismic impedance,amplitude and frequency using machine learning and information filtering. Theavailable well logs along with the 3-D seismic data have been used to benchmarkthe proposed pre-processing stage using a methodology which primarily consistsof three steps: pre-processing, training and post-processing. An ArtificialNeural Network (ANN) with conjugate-gradient learning algorithm has been usedto model the sand fraction. The available sand fraction data from the highresolution well logs has far more information content than the low resolutionseismic attributes. Therefore, regularization schemes based on FourierTransform (FT), Wavelet Decomposition (WD) and Empirical Mode Decomposition(EMD) have been proposed to shape the high resolution sand fraction data foreffective machine learning. The input data sets have been segregated intotraining, testing and validation sets. The test results are primarily used tocheck different network structures and activation function performances. Oncethe network passes the testing phase with an acceptable performance in terms ofthe selected evaluators, the validation phase follows. In the validation stage,the prediction model is tested against unseen data. The network yieldingsatisfactory performance in the validation stage is used to predictlithological properties from seismic attributes throughout a given volume.Finally, a post-processing scheme using 3-D spatial filtering is implementedfor smoothing the sand fraction in the volume. Prediction of lithologicalproperties using this framework is helpful for Reservoir Characterization.
arxiv-13500-76 | Fast k-NN search | http://arxiv.org/pdf/1509.06957v1.pdf | author:Ville Hyvönen, Teemu Pitkänen, Sotiris Tasoulis, Liang Wang, Teemu Roos, Jukka Corander category:stat.ML cs.DS cs.LG published:2015-09-23 summary:Random projection trees have proven to be effective for approximate nearestneighbor searches in high dimensional spaces where conventional methods are notapplicable due to excessive usage of memory and computational time. We showthat building multiple trees on the same data can improve the performance evenfurther, without significantly increasing the total computational cost ofqueries when executed in a modern parallel computing environment. Ourexperiments identify suitable parameter values to achieve accurate searcheswith extremely fast query times, while also retaining a feasible complexity forindex construction.
arxiv-13500-77 | Enabling Depth-driven Visual Attention on the iCub Humanoid Robot: Instructions for Use and New Perspectives | http://arxiv.org/pdf/1509.06939v1.pdf | author:Giulia Pasquale, Tanis Mar, Carlo Ciliberto, Lorenzo Rosasco, Lorenzo Natale category:cs.RO cs.CV published:2015-09-23 summary:The importance of depth perception in the interactions that humans havewithin their nearby space is a well established fact. Consequently, it is alsowell known that the possibility of exploiting good stereo information wouldease and, in many cases, enable, a large variety of attentional and interactivebehaviors on humanoid robotic platforms. However, the difficulty of computingreal-time and robust binocular disparity maps from moving stereo cameras oftenprevents from relying on this kind of cue to visually guide robots' attentionand actions in real-world scenarios. The contribution of this paper istwo-fold: first, we show that the Efficient Large-scale Stereo Matchingalgorithm (ELAS) by A. Geiger et al. 2010 for computation of the disparity mapis well suited to be used on a humanoid robotic platform as the iCub robot;second, we show how, provided with a fast and reliable stereo system,implementing relatively challenging visual behaviors in natural settings canrequire much less effort. As a case of study we consider the common situationwhere the robot is asked to focus the attention on one object close in thescene, showing how a simple but effective disparity-based segmentation solvesthe problem in this case. Indeed this example paves the way to a variety ofother similar applications.
arxiv-13500-78 | Fully automatic multi-language translation with a catalogue of phrases - successful employment for the Swiss avalanche bulletin | http://arxiv.org/pdf/1509.06937v1.pdf | author:Kurt Winkler, Tobias Kuhn category:cs.CL published:2015-09-23 summary:The Swiss avalanche bulletin is produced twice a day in four languages. Dueto the lack of time available for manual translation, a fully automatedtranslation system is employed, based on a catalogue of predefined phrases andpredetermined rules of how these phrases can be combined to produce sentences.Because this catalogue of phrases is limited to a small sublanguage, the systemis able to automatically translate such sentences from German into the targetlanguages French, Italian and English without subsequent proofreading orcorrection. Having been operational for two winter seasons, we assess here thequality of the produced texts based on two different surveys where participantsrated texts from real avalanche bulletins from both origins, the catalogue ofphrases versus manually written and translated texts. With a mean recognitionrate of 55%, users can hardly distinguish between thetwo types of texts, andgive very similar ratings with respect to their language quality. Overall, theoutput from the catalogue system can be considered virtually equivalent to atext written by avalanche forecasters and then manually translated byprofessional translators. Furthermore, forecasters declared that all relevantsituations were captured by the system with sufficient accuracy. Forecaster'sworking load did not change with the introduction of the catalogue: the extratime to find matching sentences is compensated by the fact that they no longerneed to double-check manually translated texts. The reduction of dailytranslation costs is expected to offset the initial development costs within afew years.
arxiv-13500-79 | Automatic Dialect Detection in Arabic Broadcast Speech | http://arxiv.org/pdf/1509.06928v1.pdf | author:Ahmed Ali, Peter Bell, Steve Renals category:cs.CL published:2015-09-23 summary:We investigate different approaches for dialect identification in Arabicbroadcast speech, using phonetic, lexical features obtained from a speechrecognition system, and acoustic features using the i-vector framework. Westudied both generative and discriminate classifiers, and we combined thesefeatures using a multi-class Support Vector Machine (SVM). We validated ourresults on an Arabic/English language identification task, with an accuracy of100%. We used these features in a binary classifier to discriminate betweenModern Standard Arabic (MSA) and Dialectal Arabic, with an accuracy of 100%. Wefurther report results using the proposed method to discriminate between thefive most widely used dialects of Arabic: namely Egyptian, Gulf, Levantine,North African, and MSA, with an accuracy of 52%. We discuss dialectidentification errors in the context of dialect code-switching betweenDialectal Arabic and MSA, and compare the error pattern between manuallylabeled data, and the output from our classifier. We also release the train andtest data as standard corpus for dialect identification.
arxiv-13500-80 | Robust Object Tracking with a Hierarchical Ensemble Framework | http://arxiv.org/pdf/1509.06925v1.pdf | author:Mengmeng Wang, Yong Liu category:cs.CV published:2015-09-23 summary:Autonomous robots enjoy a wide popularity nowadays and have been applied inmany applications, such as home security, entertainment, delivery, navigationand guidance. It is vital to robots to track objects accurately in theseapplications, so it is necessary to focus on tracking algorithms to improve therobustness and accuracy. In this paper, we propose a robust object trackingalgorithm based on a hierarchical ensemble framework which can incorporateinformation including individual pixel features, local patches and holistictarget models. The framework combines multiple ensemble models simultaneouslyinstead of using a single ensemble model individually. A discriminative modelwhich accounts for the matching degree of local patches is adopted via a bottomensemble layer, and a generative model which exploits holistic templates isused to search for the object through the middle ensemble layer as well as anadaptive Kalman filter. We test the proposed tracker on challenging benchmarkimage sequences. Both qualitative and quantitative evaluations demonstrate thatthe proposed tracker performs superiorly against several state-of-the-artalgorithms, especially when the appearance changes dramatically and theocclusions occur.
arxiv-13500-81 | Predicting Climate Variability over the Indian Region Using Data Mining Strategies | http://arxiv.org/pdf/1509.06920v1.pdf | author:Naresh Kumar Mallenahalli category:stat.ML physics.ao-ph published:2015-09-23 summary:In this paper an approach based on expectation maximization (EM) clusteringto find the climate regions and a support vector machine to build a predictivemodel for each of these regions is proposed. To minimize the biases in theestimations a ten cross fold validation is adopted both for obtaining clustersand building the predictive models. The EM clustering could identify all thezones as per the Koppen classification over Indian region. The proposedstrategy when employed for predicting temperature has resulted in an RMSE of$1.19$ in the Montane climate region and $0.89$ in the Humid Sub Tropicalregion as compared to $2.9$ and $0.95$ respectively predicted using k-means andlinear regression method.
arxiv-13500-82 | Designing Behaviour in Bio-inspired Robots Using Associative Topologies of Spiking-Neural-Networks | http://arxiv.org/pdf/1509.07035v2.pdf | author:Cristian Jimenez-Romero, David Sousa-Rodrigues, Jeffrey H. Johnson category:cs.RO cs.AI cs.NE published:2015-09-23 summary:This study explores the design and control of the behaviour of agents androbots using simple circuits of spiking neurons and Spike Timing DependentPlasticity (STDP) as a mechanism of associative and unsupervised learning.Based on a "reward and punishment" classical conditioning, it is demonstratedthat these robots learnt to identify and avoid obstacles as well as to identifyand look for rewarding stimuli. Using the simulation and programmingenvironment NetLogo, a software engine for the Integrate and Fire model wasdeveloped, which allowed us to monitor in discrete time steps the dynamics ofeach single neuron, synapse and spike in the proposed neural networks. Thesespiking neural networks (SNN) served as simple brains for the experimentalrobots. The Lego Mindstorms robot kit was used for the embodiment of thesimulated agents. In this paper the topological building blocks are presentedas well as the neural parameters required to reproduce the experiments. Thispaper summarizes the resulting behaviour as well as the observed dynamics ofthe neural circuits. The Internet-link to the NetLogo code is included in theannex.
arxiv-13500-83 | Efficient reconstruction of transmission probabilities in a spreading process from partial observations | http://arxiv.org/pdf/1509.06893v1.pdf | author:Andrey Y. Lokhov, Theodor Misiakiewicz category:physics.soc-ph cs.LG cs.SI stat.ML published:2015-09-23 summary:An important problem of reconstruction of diffusion network and transmissionprobabilities from the data has attracted a considerable attention in the pastseveral years. A number of recent papers introduced efficient algorithms forthe estimation of spreading parameters, based on the maximization of thelikelihood of observed cascades, assuming that the full information for all thenodes in the network is available. In this work, we focus on a more realisticand restricted scenario, in which only a partial information on the cascades isavailable: either the set of activation times for a limited number of nodes, orthe states of nodes for a subset of observation times. To tackle this problem,we first introduce a framework based on the maximization of the likelihood ofthe incomplete diffusion trace. However, we argue that the computation of thisincomplete likelihood is a computationally hard problem, and show that a fastand robust reconstruction of transmission probabilities in sparse networks canbe achieved with a new algorithm based on recently introduced dynamicmessage-passing equations for the spreading processes. The suggested approachcan be easily generalized to a large class of discrete and continuous dynamicmodels, as well as to the cases of dynamically-changing networks and noisyinformation.
arxiv-13500-84 | New Fuzzy LBP Features for Face Recognition | http://arxiv.org/pdf/1509.06853v1.pdf | author:Abdullah Gubbi, Mohammed Fazle Azeem, Zahid Ansari category:cs.CV published:2015-09-23 summary:There are many Local texture features each very in way they implement andeach of the Algorithm trying improve the performance. An attempt is made inthis paper to represent a theoretically very simple and computationallyeffective approach for face recognition. In our implementation the face imageis divided into 3x3 sub-regions from which the features are extracted using theLocal Binary Pattern (LBP) over a window, fuzzy membership function and at thecentral pixel. The LBP features possess the texture discriminative property andtheir computational cost is very low. By utilising the information from LBP,membership function, and central pixel, the limitations of traditional LBP iseliminated. The bench mark database like ORL and Sheffield Databases are usedfor the evaluation of proposed features with SVM classifier. For the proposedapproach K-fold and ROC curves are obtained and results are compared.
arxiv-13500-85 | Minimum Weight Perfect Matching via Blossom Belief Propagation | http://arxiv.org/pdf/1509.06849v1.pdf | author:Sungsoo Ahn, Sejun Park, Michael Chertkov, Jinwoo Shin category:cs.DS cs.AI stat.ML published:2015-09-23 summary:Max-product Belief Propagation (BP) is a popular message-passing algorithmfor computing a Maximum-A-Posteriori (MAP) assignment over a distributionrepresented by a Graphical Model (GM). It has been shown that BP can solve anumber of combinatorial optimization problems including minimum weightmatching, shortest path, network flow and vertex cover under the followingcommon assumption: the respective Linear Programming (LP) relaxation is tight,i.e., no integrality gap is present. However, when LP shows an integrality gap,no model has been known which can be solved systematically via sequentialapplications of BP. In this paper, we develop the first such algorithm, coinedBlossom-BP, for solving the minimum weight matching problem over arbitrarygraphs. Each step of the sequential algorithm requires applying BP over amodified graph constructed by contractions and expansions of blossoms, i.e.,odd sets of vertices. Our scheme guarantees termination in O(n^2) of BP runs,where n is the number of vertices in the original graph. In essence, theBlossom-BP offers a distributed version of the celebrated Edmonds' Blossomalgorithm by jumping at once over many sub-steps with a single BP. Moreover,our result provides an interpretation of the Edmonds' algorithm as a sequenceof LPs.
arxiv-13500-86 | A Feature-Based Comparison of Evolutionary Computing Techniques for Constrained Continuous Optimisation | http://arxiv.org/pdf/1509.06842v1.pdf | author:Shayan Poursoltan, Frank Neumann category:cs.AI cs.NE published:2015-09-23 summary:Evolutionary algorithms have been frequently applied to constrainedcontinuous optimisation problems. We carry out feature based comparisons ofdifferent types of evolutionary algorithms such as evolution strategies,differential evolution and particle swarm optimisation for constrainedcontinuous optimisation. In our study, we examine how sets of constraintsinfluence the difficulty of obtaining close to optimal solutions. Using amulti-objective approach, we evolve constrained continuous problems having aset of linear and/or quadratic constraints where the different evolutionaryapproaches show a significant difference in performance. Afterwards, we discussthe features of the constraints that exhibit a difference in performance of thedifferent evolutionary approaches under consideration.
arxiv-13500-87 | Density Estimation via Discrepancy | http://arxiv.org/pdf/1509.06831v1.pdf | author:Kun Yang, Hao Su, Wing Hung Wang category:stat.ML published:2015-09-23 summary:Given i.i.d samples from some unknown continuous density on hyper-rectangle$[0, 1]^d$, we attempt to learn a piecewise constant function that approximatesthis underlying density non-parametrically. Our density estimate is defined ona binary split of $[0, 1]^d$ and built up sequentially according to discrepancycriteria; the key ingredient is to control the discrepancy adaptively in eachsub-rectangle to achieve overall bound. We prove that the estimate, even thoughsimple as it appears, preserves most of the estimation power. By exploiting itsstructure, it can be directly applied to some important pattern recognitiontasks such as mode seeking and density landscape exploration. We demonstrateits applicability through simulations and examples.
arxiv-13500-88 | Supersizing Self-supervision: Learning to Grasp from 50K Tries and 700 Robot Hours | http://arxiv.org/pdf/1509.06825v1.pdf | author:Lerrel Pinto, Abhinav Gupta category:cs.LG cs.CV cs.RO published:2015-09-23 summary:Current learning-based robot grasping approaches exploit human-labeleddatasets for training the models. However, there are two problems with such amethodology: (a) since each object can be grasped in multiple ways, manuallylabeling grasp locations is not a trivial task; (b) human labeling is biased bysemantics. While there have been attempts to train robots using trial-and-errorexperiments, the amount of data used in such experiments remains substantiallylow and hence makes the learner prone to over-fitting. In this paper, we takethe leap of increasing the available training data to 40 times more than priorwork, leading to a dataset size of 50K data points collected over 700 hours ofrobot grasping attempts. This allows us to train a Convolutional Neural Network(CNN) for the task of predicting grasp locations without severe overfitting. Inour formulation, we recast the regression problem to an 18-way binaryclassification over image patches. We also present a multi-stage learningapproach where a CNN trained in one stage is used to collect hard negatives insubsequent stages. Our experiments clearly show the benefit of usinglarge-scale datasets (and multi-stage training) for the task of grasping. Wealso compare to several baselines and show state-of-the-art performance ongeneralization to unseen objects for grasping.
arxiv-13500-89 | IllinoisSL: A JAVA Library for Structured Prediction | http://arxiv.org/pdf/1509.07179v1.pdf | author:Kai-Wei Chang, Shyam Upadhyay, Ming-Wei Chang, Vivek Srikumar, Dan Roth category:cs.LG cs.CL stat.ML published:2015-09-23 summary:IllinoisSL is a Java library for learning structured prediction models. Itsupports structured Support Vector Machines and structured Perceptron. Thelibrary consists of a core learning module and several applications, which canbe executed from command-lines. Documentation is provided to guide users. InComparison to other structured learning libraries, IllinoisSL is efficient,general, and easy to use.
arxiv-13500-90 | Exploration and Exploitation of Victorian Science in Darwin's Reading Notebooks | http://arxiv.org/pdf/1509.07175v3.pdf | author:Jaimie Murdock, Colin Allen, Simon DeDeo category:cs.CL cs.AI cs.CY cs.DL physics.soc-ph published:2015-09-23 summary:Search in an environment with an uncertain distribution of resources involvesa trade-off between exploitation of past discoveries and further exploration.This extends to information foraging, where a knowledge-seeker shifts betweenreading in depth and studying new domains. We study this process in CharlesDarwin by modeling the full-text of books listed in hischronologically-organized reading journals. We use the information-theoreticKullback-Liebler Divergence, or relative surprise, between books for both hislocal (book-to-book) and global (book-to-past) reading decisions. Rather than apattern of surprise-minimization, corresponding to a pure exploitationstrategy, Darwin's behavior shifts from early exploitation to laterexploration, seeking unusually high levels of cognitive surprise relative toprevious eras. These shifts, detected by an unsupervised Bayesian model,correlate with major intellectual epochs of his career as identified both bytraditional, qualitative scholarship and Darwin's own self-commentary. Inaddition to quantifying Darwin's individual-level foraging, our methods allowus to compare his consumption of texts with their publication order. We findDarwin's consumption more exploratory than the culture's production, suggestingthat underneath gradual societal changes are the explorations of individualsynthesis and discovery.
arxiv-13500-91 | Bandit Label Inference for Weakly Supervised Learning | http://arxiv.org/pdf/1509.06807v1.pdf | author:Ke Li, Jitendra Malik category:cs.LG stat.ML published:2015-09-22 summary:The scarcity of data annotated at the desired level of granularity is arecurring issue in many applications. Significant amounts of effort have beendevoted to developing weakly supervised methods tailored to each individualsetting, which are often carefully designed to take advantage of the particularproperties of weak supervision regimes, form of available data and priorknowledge of the task at hand. Unfortunately, it is difficult to adapt thesemethods to new tasks and/or forms of data, which often require different weaksupervision regimes or models. We present a general-purpose method that cansolve any weakly supervised learning problem irrespective of the weaksupervision regime or the model. The proposed method turns any off-the-shelfstrongly supervised classifier into a weakly supervised classifier and allowsthe user to specify any arbitrary weakly supervision regime via a lossfunction. We apply the method to several different weak supervision regimes anddemonstrate competitive results compared to methods specifically engineered forthose settings.
arxiv-13500-92 | Invariants of objects and their images under surjective maps | http://arxiv.org/pdf/1509.06690v1.pdf | author:Irina A. Kogan, Peter J. Olver category:math.DG cs.CV I.2.10 published:2015-09-22 summary:We examine the relationships between the differential invariants of objectsand of their images under a surjective map. We analyze both the case when theunderlying transformation group is projectable and hence induces an action onthe image, and the case when only a proper subgroup of the entire group actsprojectably. In the former case, we establish a constructible isomorphismbetween the algebra of differential invariants of the images and the algebra offiber-wise constant (gauge) differential invariants of the objects. In thelatter case, we describe residual effects of the full transformation group onthe image invariants. Our motivation comes from the problem of reconstructionof an object from multiple-view images, with central and parallel projectionsof curves from three-dimensional space to the two-dimensional plane serving asour main examples.
arxiv-13500-93 | Classification error in multiclass discrimination from Markov data | http://arxiv.org/pdf/1509.06673v1.pdf | author:Sören Christensen, Albrecht Irle, Lars Willert category:stat.ML math.ST stat.TH published:2015-09-22 summary:As a model for an on-line classification setting we consider a stochasticprocess $(X_{-n},Y_{-n})_{n}$, the present time-point being denoted by 0, withobservables $ \ldots,X_{-n},X_{-n+1},\ldots, X_{-1}, X_0$ from which thepattern $Y_0$ is to be inferred. So in this classification setting, in additionto the present observation $X_0$ a number $l$ of preceding observations may beused for classification, thus taking a possible dependence structure intoaccount as it occurs e.g. in an ongoing classification of handwrittencharacters. We treat the question how the performance of classifiers isimproved by using such additional information. For our analysis, a hiddenMarkov model is used. Letting $R_l$ denote the minimal risk ofmisclassification using $l$ preceding observations we show that the difference$\sup_k R_l - R_{l+k}$ decreases exponentially fast as $l$ increases. Thissuggests that a small $l$ might already lead to a noticeable improvement. Tofollow this point we look at the use of past observations for kernelclassification rules. Our practical findings in simulated hidden Markov modelsand in the classification of handwritten characters indicate that using $l=1$,i.e. just the last preceding observation in addition to $X_0$, can lead to asubstantial reduction of the risk of misclassification. So, in the presence ofstochastic dependencies, we advocate to use $ X_{-1},X_0$ for finding thepattern $Y_0$ instead of only $X_0$ as one would in the independent situation.
arxiv-13500-94 | A Compositional Explanation of the Pet Fish Phenomenon | http://arxiv.org/pdf/1509.06594v1.pdf | author:Bob Coecke, Martha Lewis category:cs.AI cs.CL math.CT published:2015-09-22 summary:The `pet fish' phenomenon is often cited as a paradigm example of the`non-compositionality' of human concept use. We show here how this phenomenonis naturally accommodated within a compositional distributional model ofmeaning. This model describes the meaning of a composite concept by accountingfor interaction between its constituents via their grammatical roles. We givetwo illustrative examples to show how the qualitative phenomena are exhibited.We go on to apply the model to experimental data, and finally discussextensions of the formalism.
arxiv-13500-95 | Graph Kernels exploiting Weisfeiler-Lehman Graph Isomorphism Test Extensions | http://arxiv.org/pdf/1509.06589v1.pdf | author:Giovanni Da San Martino, Nicolò Navarin, Alessandro Sperduti category:cs.LG cs.AI published:2015-09-22 summary:In this paper we present a novel graph kernel framework inspired the by theWeisfeiler-Lehman (WL) isomorphism tests. Any WL test comprises a relabellingphase of the nodes based on test-specific information extracted from the graph,for example the set of neighbours of a node. We defined a novel relabelling andderived two kernels of the framework from it. The novel kernels are very fastto compute and achieve state-of-the-art results on five real-world datasets.
arxiv-13500-96 | A Review of Features for the Discrimination of Twitter Users: Application to the Prediction of Offline Influence | http://arxiv.org/pdf/1509.06585v1.pdf | author:Jean-Valère Cossu, Vincent Labatut, Nicolas Dugué category:cs.CL cs.SI published:2015-09-22 summary:Many works related to Twitter aim at characterizing its users in some way:role on the service (spammers, bots, organizations, etc.), nature of the user(socio-professional category, age, etc.), topics of interest, and others.However, for a given user classification problem, it is very difficult toselect a set of appropriate features, because the many features described inthe literature are very heterogeneous, with name overlaps and collisions, andnumerous very close variants. In this article, we review a wide range of suchfeatures. In order to present a clear state-of-the-art description, we unifytheir names, definitions and relationships, and we propose a new, neutral,typology. We then illustrate the interest of our review by applying a selectionof these features to the offline influence detection problem. This taskconsists in identifying users which are influential in real-life, based ontheir Twitter account and related data. We show that most features deemedefficient to predict online influence, such as the numbers of retweets andfollowers, are not relevant to this problem. However, We propose severalcontent-based approaches to label Twitter users as Influencers or not. We alsorank them according to a predicted influence level. Our proposals are evaluatedover the CLEF RepLab 2014 dataset, and outmatch state-of-the-art methods.
arxiv-13500-97 | Homotopy relations for digital images | http://arxiv.org/pdf/1509.06576v1.pdf | author:Laurence Boxer, P. Christopher Staecker category:math.GN cs.CV 55P10, 55Q05 I.4.m published:2015-09-22 summary:We introduce three generalizations of homotopy equivalence in digital images,to allow us to express whether a finite and an infinite digital image aresimilar with respect to homotopy. We show that these three generalizations are not equivalent to ordinaryhomotopy equivalence, and give several examples. We show that, like homotopyequivalence, our three generalizations imply isomorphism of fundamental groups,and are
arxiv-13500-98 | Local Multi-Grouped Binary Descriptor with Ring-based Pooling Configuration and Optimization | http://arxiv.org/pdf/1509.06557v1.pdf | author:Yongqiang Gao, Weilin Huang, Yu Qiao category:cs.CV published:2015-09-22 summary:Local binary descriptors are attracting increasingly attention due to theirgreat advantages in computational speed, which are able to achieve real-timeperformance in numerous image/vision applications. Various methods have beenproposed to learn data-dependent binary descriptors. However, most existingbinary descriptors aim overly at computational simplicity at the expense ofsignificant information loss which causes ambiguity in similarity measure usingHamming distance. In this paper, by considering multiple features might sharecomplementary information, we present a novel local binary descriptor, referredas Ring-based Multi-Grouped Descriptor (RMGD), to successfully bridge theperformance gap between current binary and floated-point descriptors. Ourcontributions are two-fold. Firstly, we introduce a new pooling configurationbased on spatial ring-region sampling, allowing for involving binary tests onthe full set of pairwise regions with different shapes, scales and distances.This leads to a more meaningful description than existing methods whichnormally apply a limited set of pooling configurations. Then, an extendedAdaboost is proposed for efficient bit selection by emphasizing high varianceand low correlation, achieving a highly compact representation. Secondly, theRMGD is computed from multiple image properties where binary strings areextracted. We cast multi-grouped features integration as rankSVM or sparse SVMlearning problem, so that different features can compensate strongly for eachother, which is the key to discriminativeness and robustness. The performanceof RMGD was evaluated on a number of publicly available benchmarks, where theRMGD outperforms the state-of-the-art binary descriptors significantly.
arxiv-13500-99 | Deep Boltzmann Machines in Estimation of Distribution Algorithms for Combinatorial Optimization | http://arxiv.org/pdf/1509.06535v1.pdf | author:Malte Probst, Franz Rothlauf category:cs.NE published:2015-09-22 summary:Estimation of Distribution Algorithms (EDAs) require flexible probabilitymodels that can be efficiently learned and sampled. Deep Boltzmann Machines(DBMs) are generative neural networks with these desired properties. Weintegrate a DBM into an EDA and evaluate the performance of this system insolving combinatorial optimization problems with a single objective. We comparethe results to the Bayesian Optimization Algorithm. The performance of DBM-EDAwas superior to BOA for difficult additively decomposable functions, i.e.,concatenated deceptive traps of higher order. For most other benchmarkproblems, DBM-EDA cannot clearly outperform BOA, or other neural network-basedEDAs. In particular, it often yields optimal solutions for a subset of the runs(with fewer evaluations than BOA), but is unable to provide reliableconvergence to the global optimum competitively. At the same time, the modelbuilding process is computationally more expensive than that of other EDAsusing probabilistic models from the neural network family, such as DAE-EDA.
arxiv-13500-100 | A survey on feature weighting based K-Means algorithms | http://arxiv.org/pdf/1601.03483v1.pdf | author:Renato Cordeiro de Amorim category:cs.LG published:2015-09-22 summary:In a real-world data set there is always the possibility, rather high in ouropinion, that different features may have different degrees of relevance. Mostmachine learning algorithms deal with this fact by either selecting ordeselecting features in the data preprocessing phase. However, we maintain thateven among relevant features there may be different degrees of relevance, andthis should be taken into account during the clustering process. With over 50years of history, K-Means is arguably the most popular partitional clusteringalgorithm there is. The first K-Means based clustering algorithm to computefeature weights was designed just over 30 years ago. Various such algorithmshave been designed since but there has not been, to our knowledge, a surveyintegrating empirical evidence of cluster recovery ability, common flaws, andpossible directions for future research. This paper elaborates on the conceptof feature weighting and addresses these issues by critically analysing some ofthe most popular, or innovative, feature weighting mechanisms based in K-Means.
arxiv-13500-101 | Modifying iterated Laplace approximations | http://arxiv.org/pdf/1509.06492v1.pdf | author:Tiep Mai, Simon Wilson category:stat.ME stat.ML published:2015-09-22 summary:In this paper, several modifications are introduced to the functionalapproximation method iterLap to reduce the approximation error, includingstopping rule adjustment, proposal of new residual function, starting pointselection for numerical optimisation, scaling of Hessian matrix. Illustrativeexamples are also provided to show the trade-off between running time andaccuracy of the original and modified methods.
arxiv-13500-102 | Learning Wake-Sleep Recurrent Attention Models | http://arxiv.org/pdf/1509.06812v1.pdf | author:Jimmy Ba, Roger Grosse, Ruslan Salakhutdinov, Brendan Frey category:cs.LG published:2015-09-22 summary:Despite their success, convolutional neural networks are computationallyexpensive because they must examine all image locations. Stochasticattention-based models have been shown to improve computational efficiency attest time, but they remain difficult to train because of intractable posteriorinference and high variance in the stochastic gradient estimates. Borrowingtechniques from the literature on training deep generative models, we presentthe Wake-Sleep Recurrent Attention Model, a method for training stochasticattention networks which improves posterior inference and which reduces thevariability in the stochastic gradients. We show that our method can greatlyspeed up the training time for stochastic attention networks in the domains ofimage classification and caption generation.
arxiv-13500-103 | Understand Scene Categories by Objects: A Semantic Regularized Scene Classifier Using Convolutional Neural Networks | http://arxiv.org/pdf/1509.06470v1.pdf | author:Yiyi Liao, Sarath Kodagoda, Yue Wang, Lei Shi, Yong Liu category:cs.CV published:2015-09-22 summary:Scene classification is a fundamental perception task for environmentalunderstanding in today's robotics. In this paper, we have attempted to exploitthe use of popular machine learning technique of deep learning to enhance sceneunderstanding, particularly in robotics applications. As scene images havelarger diversity than the iconic object images, it is more challenging for deeplearning methods to automatically learn features from scene images with lesssamples. Inspired by human scene understanding based on object knowledge, weaddress the problem of scene classification by encouraging deep neural networksto incorporate object-level information. This is implemented with aregularization of semantic segmentation. With only 5 thousand training images,as opposed to 2.5 million images, we show the proposed deep architectureachieves superior scene classification results to the state-of-the-art on apublicly available SUN RGB-D dataset. In addition, performance of semanticsegmentation, the regularizer, also reaches a new record with refinementderived from predicted scene labels. Finally, we apply our SUN RGB-D datasettrained model to a mobile robot captured images to classify scenes in ouruniversity demonstrating the generalization ability of the proposed algorithm.
arxiv-13500-104 | Stochastic gradient descent methods for estimation with large data sets | http://arxiv.org/pdf/1509.06459v1.pdf | author:Dustin Tran, Panos Toulis, Edoardo M. Airoldi category:stat.CO stat.ME stat.ML published:2015-09-22 summary:We develop methods for parameter estimation in settings with large-scale datasets, where traditional methods are no longer tenable. Our methods rely onstochastic approximations, which are computationally efficient as they maintainone iterate as a parameter estimate, and successively update that iterate basedon a single data point. When the update is based on a noisy gradient, thestochastic approximation is known as standard stochastic gradient descent,which has been fundamental in modern applications with large data sets.Additionally, our methods are numerically stable because they employ implicitupdates of the iterates. Intuitively, an implicit update is a shrinked versionof a standard one, where the shrinkage factor depends on the observed Fisherinformation at the corresponding data point. This shrinkage prevents numericaldivergence of the iterates, which can be caused either by excess noise oroutliers. Our sgd package in R offers the most extensive and robustimplementation of stochastic gradient descent methods. We demonstrate that sgddominates alternative software in runtime for several estimation problems withmassive data sets. Our applications include the wide class of generalizedlinear models as well as M-estimation for robust regression.
arxiv-13500-105 | Reasoning about Entailment with Neural Attention | http://arxiv.org/pdf/1509.06664v4.pdf | author:Tim Rocktäschel, Edward Grefenstette, Karl Moritz Hermann, Tomáš Kočiský, Phil Blunsom category:cs.CL cs.AI cs.LG cs.NE 68T50 I.2.6; I.2.7 published:2015-09-22 summary:While most approaches to automatically recognizing entailment relations haveused classifiers employing hand engineered features derived from complexnatural language processing pipelines, in practice their performance has beenonly slightly better than bag-of-word pair classifiers using only lexicalsimilarity. The only attempt so far to build an end-to-end differentiableneural network for entailment failed to outperform such a simple similarityclassifier. In this paper, we propose a neural model that reads two sentencesto determine entailment using long short-term memory units. We extend thismodel with a word-by-word neural attention mechanism that encourages reasoningover entailments of pairs of words and phrases. Furthermore, we present aqualitative analysis of attention weights produced by this model, demonstratingsuch reasoning capabilities. On a large entailment dataset this modeloutperforms the previous best neural model and a classifier with engineeredfeatures by a substantial margin. It is the first generic end-to-enddifferentiable system that achieves state-of-the-art accuracy on a textualentailment dataset.
arxiv-13500-106 | Harmonic Extension | http://arxiv.org/pdf/1509.06458v1.pdf | author:Zuoqiang Shi, Jian Sun, Minghao Tian category:cs.LG math.NA published:2015-09-22 summary:In this paper, we consider the harmonic extension problem, which is widelyused in many applications of machine learning. We find that the transitionalmethod of graph Laplacian fails to produce a good approximation of theclassical harmonic function. To tackle this problem, we propose a new methodcalled the point integral method (PIM). We consider the harmonic extensionproblem from the point of view of solving PDEs on manifolds. The basic idea ofthe PIM method is to approximate the harmonicity using an integral equation,which is easy to be discretized from points. Based on the integral equation, weexplain the reason why the transitional graph Laplacian may fail to approximatethe harmonicity in the classical sense and propose a different approach whichwe call the volume constraint method (VCM). Theoretically, both the PIM and theVCM computes a harmonic function with convergence guarantees, and practically,they are both simple, which amount to solve a linear system. One importantapplication of the harmonic extension in machine learning is semi-supervisedlearning. We run a popular semi-supervised learning algorithm by Zhu et al.over a couple of well-known datasets and compare the performance of theaforementioned approaches. Our experiments show the PIM performs the best.
arxiv-13500-107 | Identifying collusion groups using spectral clustering | http://arxiv.org/pdf/1509.06457v1.pdf | author:Suneel Sarswat, Kandathil Mathew Abraham, Subir Kumar Ghosh category:q-fin.TR cs.CE stat.ML published:2015-09-22 summary:In an illiquid stock, traders can collude and place orders on a predeterminedprice and quantity at a fixed schedule. This is usually done to manipulate theprice of the stock or to create artificial liquidity in the stock, which maymislead genuine investors. Here, the problem is to identify such group ofcolluding traders. We modeled the problem instance as a graph, where eachtrader corresponds to a vertex of the graph and trade corresponds to edges ofthe graph. Further, we assign weights on edges depending on total volume, totalnumber of trades, maximum change in the price and commonality between twovertices. Spectral clustering algorithms are used on the constructed graph toidentify colluding group(s). We have compared our results with simulated datato show the effectiveness of spectral clustering to detecting colluding groups.Moreover, we also have used parameters of real data to test the effectivenessof our algorithm.
arxiv-13500-108 | From Facial Parts Responses to Face Detection: A Deep Learning Approach | http://arxiv.org/pdf/1509.06451v1.pdf | author:Shuo Yang, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV published:2015-09-22 summary:In this paper, we propose a novel deep convolutional network (DCN) thatachieves outstanding performance on FDDB, PASCAL Face, and AFW. Specifically,our method achieves a high recall rate of 90.99% on the challenging FDDBbenchmark, outperforming the state-of-the-art method by a large margin of2.91%. Importantly, we consider finding faces from a new perspective throughscoring facial parts responses by their spatial structure and arrangement. Thescoring mechanism is carefully formulated considering challenging cases wherefaces are only partially visible. This consideration allows our network todetect faces under severe occlusion and unconstrained pose variation, which arethe main difficulty and bottleneck of most existing face detection approaches.We show that despite the use of DCN, our network can achieve practical runtimespeed.
arxiv-13500-109 | Attribute-Graph: A Graph based approach to Image Ranking | http://arxiv.org/pdf/1509.06658v2.pdf | author:Nikita Prabhu, R. Venkatesh Babu category:cs.CV published:2015-09-22 summary:We propose a novel image representation, termed Attribute-Graph, to rankimages by their semantic similarity to a given query image. An Attribute-Graphis an undirected fully connected graph, incorporating both local and globalimage characteristics. The graph nodes characterise objects as well as theoverall scene context using mid-level semantic attributes, while the edgescapture the object topology. We demonstrate the effectiveness ofAttribute-Graphs by applying them to the problem of image ranking. We benchmarkthe performance of our algorithm on the 'rPascal' and 'rImageNet' datasets,which we have created in order to evaluate the ranking performance on complexqueries containing multiple objects. Our experimental evaluation shows thatmodelling images as Attribute-Graphs results in improved ranking performanceover existing techniques.
arxiv-13500-110 | Efficient Neighborhood Selection for Gaussian Graphical Models | http://arxiv.org/pdf/1509.06449v1.pdf | author:Yingxiang Yang, Jalal Etesami, Negar Kiyavash category:stat.ML cs.IT cs.LG math.IT published:2015-09-22 summary:This paper addresses the problem of neighborhood selection for Gaussiangraphical models. We present two heuristic algorithms: a forward-backwardgreedy algorithm for general Gaussian graphical models based on mutualinformation test, and a threshold-based algorithm for walk summable Gaussiangraphical models. Both algorithms are shown to be structurally consistent, andefficient. Numerical results show that both algorithms work very well.
arxiv-13500-111 | Algebraic Clustering of Affine Subspaces | http://arxiv.org/pdf/1509.06729v2.pdf | author:Manolis C. Tsakiris, Rene Vidal category:cs.CV published:2015-09-22 summary:Subspace clustering is an important problem in machine learning with manyapplications in computer vision and pattern recognition. Prior work has studiedthis problem using algebraic, iterative, statistical, low-rank and sparserepresentation techniques. While these methods have been applied to both linearand affine subspaces, theoretical results have only been established in thecase of linear subspaces. For example, algebraic subspace clustering (ASC) isguaranteed to provide the correct clustering when the data points are ingeneral position and the union of subspaces is transversal. In this paper westudy in a rigorous fashion the properties of ASC in the case of affinesubspaces. Using notions from algebraic geometry, we prove that thehomogenization trick, which embeds points in a union of affine subspaces intopoints in a union of linear subspaces, preserves the general position of thepoints and the transversality of the union of subspaces in the embedded space,thus establishing the correctness of ASC for affine subpaces.
arxiv-13500-112 | Learning Deep Control Policies for Autonomous Aerial Vehicles with MPC-Guided Policy Search | http://arxiv.org/pdf/1509.06791v2.pdf | author:Tianhao Zhang, Gregory Kahn, Sergey Levine, Pieter Abbeel category:cs.LG cs.RO published:2015-09-22 summary:Model predictive control (MPC) is an effective method for controlling roboticsystems, particularly autonomous aerial vehicles such as quadcopters. However,application of MPC can be computationally demanding, and typically requiresestimating the state of the system, which can be challenging in complex,unstructured environments. Reinforcement learning can in principle forego theneed for explicit state estimation and acquire a policy that directly mapssensor readings to actions, but is difficult to apply to unstable systems thatare liable to fail catastrophically during training before an effective policyhas been found. We propose to combine MPC with reinforcement learning in theframework of guided policy search, where MPC is used to generate data attraining time, under full state observations provided by an instrumentedtraining environment. This data is used to train a deep neural network policy,which is allowed to access only the raw observations from the vehicle's onboardsensors. After training, the neural network policy can successfully control therobot without knowledge of the full state, and at a fraction of thecomputational cost of MPC. We evaluate our method by learning obstacleavoidance policies for a simulated quadrotor, using simulated onboard sensorsand no explicit state estimation at test time.
arxiv-13500-113 | Deep Reinforcement Learning with Double Q-learning | http://arxiv.org/pdf/1509.06461v3.pdf | author:Hado van Hasselt, Arthur Guez, David Silver category:cs.LG published:2015-09-22 summary:The popular Q-learning algorithm is known to overestimate action values undercertain conditions. It was not previously known whether, in practice, suchoverestimations are common, whether they harm performance, and whether they cangenerally be prevented. In this paper, we answer all these questionsaffirmatively. In particular, we first show that the recent DQN algorithm,which combines Q-learning with a deep neural network, suffers from substantialoverestimations in some games in the Atari 2600 domain. We then show that theidea behind the Double Q-learning algorithm, which was introduced in a tabularsetting, can be generalized to work with large-scale function approximation. Wepropose a specific adaptation to the DQN algorithm and show that the resultingalgorithm not only reduces the observed overestimations, as hypothesized, butthat this also leads to much better performance on several games.
arxiv-13500-114 | A 128 channel Extreme Learning Machine based Neural Decoder for Brain Machine Interfaces | http://arxiv.org/pdf/1509.07450v2.pdf | author:Yi Chen, Enyi Yao, Arindam Basu category:cs.LG cs.HC published:2015-09-22 summary:Currently, state-of-the-art motor intention decoding algorithms inbrain-machine interfaces are mostly implemented on a PC and consume significantamount of power. A machine learning co-processor in 0.35um CMOS for motorintention decoding in brain-machine interfaces is presented in this paper.Using Extreme Learning Machine algorithm and low-power analog processing, itachieves an energy efficiency of 290 GMACs/W at a classification rate of 50 Hz.The learning in second stage and corresponding digitally stored coefficientsare used to increase robustness of the core analog processor. The chip isverified with neural data recorded in monkey finger movements experiment,achieving a decoding accuracy of 99.3% for movement type. The same co-processoris also used to decode time of movement from asynchronous neural spikes. Withtime-delayed feature dimension enhancement, the classification accuracy can beincreased by 5% with limited number of input channels. Further, a sparsitypromoting training scheme enables reduction of number of programmable weightsby ~2X.
arxiv-13500-115 | A Dual-Source Approach for 3D Pose Estimation from a Single Image | http://arxiv.org/pdf/1509.06720v2.pdf | author:Hashim Yasin, Umar Iqbal, Björn Krüger, Andreas Weber, Juergen Gall category:cs.CV published:2015-09-22 summary:One major challenge for 3D pose estimation from a single RGB image is theacquisition of sufficient training data. In particular, collecting largeamounts of training data that contain unconstrained images and are annotatedwith accurate 3D poses is infeasible. We therefore propose to use twoindependent training sources. The first source consists of images withannotated 2D poses and the second source consists of accurate 3D motion capturedata. To integrate both sources, we propose a dual-source approach thatcombines 2D pose estimation with efficient and robust 3D pose retrieval. In ourexperiments, we show that our approach achieves state-of-the-art results and iseven competitive when the skeleton structure of the two sources differsubstantially.
arxiv-13500-116 | Tensorizing Neural Networks | http://arxiv.org/pdf/1509.06569v2.pdf | author:Alexander Novikov, Dmitry Podoprikhin, Anton Osokin, Dmitry Vetrov category:cs.LG cs.NE published:2015-09-22 summary:Deep neural networks currently demonstrate state-of-the-art performance inseveral domains. At the same time, models of this class are very demanding interms of computational resources. In particular, a large amount of memory isrequired by commonly used fully-connected layers, making it hard to use themodels on low-end devices and stopping the further increase of the model size.In this paper we convert the dense weight matrices of the fully-connectedlayers to the Tensor Train format such that the number of parameters is reducedby a huge factor and at the same time the expressive power of the layer ispreserved. In particular, for the Very Deep VGG networks we report thecompression factor of the dense weight matrix of a fully-connected layer up to200000 times leading to the compression factor of the whole network up to 7times.
arxiv-13500-117 | Vision System and Depth Processing for DRC-HUBO+ | http://arxiv.org/pdf/1509.06114v2.pdf | author:Inwook Shim, Seunghak Shin, Yunsu Bok, Kyungdon Joo, Dong-Geol Choi, Joon-Young Lee, Jaesik Park, Jun-Ho Oh, In So Kweon category:cs.CV cs.RO published:2015-09-21 summary:This paper presents a vision system and a depth processing algorithm forDRC-HUBO+, the winner of the DRC finals 2015. Our system is designed toreliably capture 3D information of a scene and objects robust to challengingenvironment conditions. We also propose a depth-map upsampling method thatproduces an outliers-free depth map by explicitly handling depth outliers. Oursystem is suitable for an interactive robot with real-world that requiresaccurate object detection and pose estimation. We evaluate our depth processingalgorithm over state-of-the-art algorithms on several synthetic and real-worlddatasets.
arxiv-13500-118 | Cascaded Regressor based 3D Face Reconstruction from a Single Arbitrary View Image | http://arxiv.org/pdf/1509.06161v1.pdf | author:Feng Liu, Dan Zeng, Jing Li, Qijun Zhao category:cs.CV published:2015-09-21 summary:State-of-the-art methods reconstruct three-dimensional (3D) face shapes froma single image by fitting 3D face models to input images or by directlylearning mapping functions between two-dimensional (2D) images and 3D faces.However, they are often difficult to use in real-world applications due toexpensive online optimization or to the requirement of frontal face images.This paper approaches the 3D face reconstruction problem as a regressionproblem rather than a model fitting problem. Given an input face image alongwith some pre-defined facial landmarks on it, a series of shape adjustments tothe initial 3D face shape are computed through cascaded regressors based on thedeviations between the input landmarks and the landmarks obtained from thereconstructed 3D faces. The cascaded regressors are offline learned from a setof 3D faces and their corresponding 2D face images in various views. Bytreating the landmarks that are invisible in large view angles as missing data,the proposed method can handle arbitrary view face images in a unified way withthe same regressors. Experiments on the BFM and Bosphorus databases demonstratethat the proposed method can reconstruct 3D faces from arbitrary view imagesmore efficiently and more accurately than existing methods.
arxiv-13500-119 | The Utility of Clustering in Prediction Tasks | http://arxiv.org/pdf/1509.06163v1.pdf | author:Shubhendu Trivedi, Zachary A. Pardos, Neil T. Heffernan category:cs.LG published:2015-09-21 summary:We explore the utility of clustering in reducing error in various predictiontasks. Previous work has hinted at the improvement in prediction accuracyattributed to clustering algorithms if used to pre-process the data. In thiswork we more deeply investigate the direct utility of using clustering toimprove prediction accuracy and provide explanations for why this may be so. Welook at a number of datasets, run k-means at different scales and for eachscale we train predictors. This produces k sets of predictions. Thesepredictions are then combined by a na\"ive ensemble. We observed that this useof a predictor in conjunction with clustering improved the prediction accuracyin most datasets. We believe this indicates the predictive utility ofexploiting structure in the data and the data compression handed over byclustering. We also found that using this method improves upon the predictionof even a Random Forests predictor which suggests this method is providing anovel, and useful source of variance in the prediction process.
arxiv-13500-120 | LEWIS: Latent Embeddings for Word Images and their Semantics | http://arxiv.org/pdf/1509.06243v1.pdf | author:Albert Gordo, Jon Almazan, Naila Murray, Florent Perronnin category:cs.CV published:2015-09-21 summary:The goal of this work is to bring semantics into the tasks of textrecognition and retrieval in natural images. Although text recognition andretrieval have received a lot of attention in recent years, previous works havefocused on recognizing or retrieving exactly the same word used as a query,without taking the semantics into consideration. In this paper, we ask the following question: \emph{can we predict semanticconcepts directly from a word image, without explicitly trying to transcribethe word image or its characters at any point?} For this goal we propose aconvolutional neural network (CNN) with a weighted ranking loss objective thatensures that the concepts relevant to the query image are ranked ahead of thosethat are not relevant. This can also be interpreted as learning a Euclideanspace where word images and concepts are jointly embedded. This model islearned in an end-to-end manner, from image pixels to semantic concepts, usinga dataset of synthetically generated word images and concepts mined from alexical database (WordNet). Our results show that, despite the complexity ofthe task, word images and concepts can indeed be associated with a high degreeof accuracy
arxiv-13500-121 | A Bayesian Compressed Sensing Kalman Filter for Direction of Arrival Estimation | http://arxiv.org/pdf/1509.06290v1.pdf | author:Matthew Hawes, Lyudmila Mihaylova, Francois Septier, Simon Godsill category:stat.ML cs.IT math.IT published:2015-09-21 summary:In this paper, we look to address the problem of estimating the dynamicdirection of arrival (DOA) of a narrowband signal impinging on a sensor arrayfrom the far field. The initial estimate is made using a Bayesian compressivesensing (BCS) framework and then tracked using a Bayesian compressed sensingKalman filter (BCSKF). The BCS framework splits the angular region into Npotential DOAs and enforces a belief that only a few of the DOAs will have anon-zero valued signal present. A BCSKF can then be used to track the change inthe DOA using the same framework. There can be an issue when the DOA approachesthe endfire of the array. In this angular region current methods can struggleto accurately estimate and track changes in the DOAs. To tackle this problem,we propose changing the traditional sparse belief associated with BCS to abelief that the estimated signals will match the predicted signals given aknown DOA change. This is done by modelling the difference between the expectedsparse received signals and the estimated sparse received signals as a Gaussiandistribution. Example test scenarios are provided and comparisons made with thetraditional BCS based estimation method. They show that an improvement inestimation accuracy is possible without a significant increase in computationalcomplexity.
arxiv-13500-122 | Evaluating the visualization of what a Deep Neural Network has learned | http://arxiv.org/pdf/1509.06321v1.pdf | author:Wojciech Samek, Alexander Binder, Grégoire Montavon, Sebastian Bach, Klaus-Robert Müller category:cs.CV published:2015-09-21 summary:Deep Neural Networks (DNNs) have demonstrated impressive performance incomplex machine learning tasks such as image classification or speechrecognition. However, due to their multi-layer nonlinear structure, they arenot transparent, i.e., it is hard to grasp what makes them arrive at aparticular classification or recognition decision given a new unseen datasample. Recently, several approaches have been proposed enabling one tounderstand and interpret the reasoning embodied in a DNN for a single testimage. These methods quantify the ''importance'' of individual pixels wrt theclassification decision and allow a visualization in terms of a heatmap inpixel/input space. While the usefulness of heatmaps can be judged subjectivelyby a human, an objective quality measure is missing. In this paper we present ageneral methodology based on region perturbation for evaluating orderedcollections of pixels such as heatmaps. We compare heatmaps computed by threedifferent methods on the SUN397, ILSVRC2012 and MIT Places data sets. Our mainresult is that the recently proposed Layer-wise Relevance Propagation (LRP)algorithm qualitatively and quantitatively provides a better explanation ofwhat made a DNN arrive at a particular classification decision than thesensitivity-based approach or the deconvolution method. We provide theoreticalarguments to explain this result and discuss its practical implications.Finally, we investigate the use of heatmaps for unsupervised assessment ofneural network performance.
arxiv-13500-123 | Noise Robust IOA/CAS Speech Separation and Recognition System For The Third 'CHIME' Challenge | http://arxiv.org/pdf/1509.06103v1.pdf | author:Xiaofei Wang, Chao Wu, Pengyuan Zhang, Ziteng Wang, Yong Liu, Xu Li, Qiang Fu, Yonghong Yan category:cs.SD cs.CL published:2015-09-21 summary:This paper presents the contribution to the third 'CHiME' speech separationand recognition challenge including both front-end signal processing andback-end speech recognition. In the front-end, Multi-channel Wiener filter(MWF) is designed to achieve background noise reduction. Different fromtraditional MWF, optimized parameter for the tradeoff between noise reductionand target signal distortion is built according to the desired noise reductionlevel. In the back-end, several techniques are taken advantage to improve thenoisy Automatic Speech Recognition (ASR) performance including Deep NeuralNetwork (DNN), Convolutional Neural Network (CNN) and Long short-term memory(LSTM) using medium vocabulary, Lattice rescoring with a big vocabularylanguage model finite state transducer, and ROVER scheme. Experimental resultsshow the proposed system combining front-end and back-end is effective toimprove the ASR performance.
arxiv-13500-124 | Multilayer bootstrap network for unsupervised speaker recognition | http://arxiv.org/pdf/1509.06095v1.pdf | author:Xiao-Lei Zhang category:cs.LG cs.SD published:2015-09-21 summary:We apply multilayer bootstrap network (MBN), a recent proposed unsupervisedlearning method, to unsupervised speaker recognition. The proposed method firstextracts supervectors from an unsupervised universal background model, thenreduces the dimension of the high-dimensional supervectors by multilayerbootstrap network, and finally conducts unsupervised speaker recognition byclustering the low-dimensional data. The comparison results with 2 unsupervisedand 1 supervised speaker recognition techniques demonstrate the effectivenessand robustness of the proposed method.
arxiv-13500-125 | Significance Analysis of High-Dimensional, Low-Sample Size Partially Labeled Data | http://arxiv.org/pdf/1509.06088v1.pdf | author:Qiyi Lu, Xingye Qiao category:stat.ML cs.LG stat.ME published:2015-09-21 summary:Classification and clustering are both important topics in statisticallearning. A natural question herein is whether predefined classes are reallydifferent from one another, or whether clusters are really there. Specifically,we may be interested in knowing whether the two classes defined by some classlabels (when they are provided), or the two clusters tagged by a clusteringalgorithm (where class labels are not provided), are from the same underlyingdistribution. Although both are challenging questions for the high-dimensional,low-sample size data, there has been some recent development for both. However,when it is costly to manually place labels on observations, it is often thatonly a small portion of the class labels is available. In this article, wepropose a significance analysis approach for such type of data, namelypartially labeled data. Our method makes use of the whole data and tries totest the class difference as if all the labels were observed. Compared to atesting method that ignores the label information, our method provides agreater power, meanwhile, maintaining the size, illustrated by a comprehensivesimulation study. Theoretical properties of the proposed method are studiedwith emphasis on the high-dimensional, low-sample size setting. Our simulatedexamples help to understand when and how the information extracted from thelabeled data can be effective. A real data example further illustrates theusefulness of the proposed method.
arxiv-13500-126 | Estimating Random Delays in Modbus Network Using Experiments and General Linear Regression Neural Networks with Genetic Algorithm Smoothing | http://arxiv.org/pdf/1509.06839v1.pdf | author:B. Sreram, F. Bounapane, B. Subathra, Seshadhri Srinivasan category:cs.SY cs.NE published:2015-09-21 summary:Time-varying delays adversely affect the performance of networked controlsys-tems (NCS) and in the worst-case can destabilize the entire system.Therefore, modelling network delays is important for designing NCS. However,modelling time-varying delays is challenging because of their dependence onmultiple pa-rameters such as length, contention, connected devices, protocolemployed, and channel loading. Further, these multiple parameters areinherently random and de-lays vary in a non-linear fashion with respect totime. This makes estimating ran-dom delays challenging. This investigationpresents a methodology to model de-lays in NCS using experiments and generalregression neural network (GRNN) due to their ability to capture non-linearrelationship. To compute the optimal smoothing parameter that computes the bestestimates, genetic algorithm is used. The objective of the genetic algorithm isto compute the optimal smoothing pa-rameter that minimizes the mean absolutepercentage error (MAPE). Our results illustrate that the resulting GRNN is ableto predict the delays with less than 3% error. The proposed delay model gives aframework to design compensation schemes for NCS subjected to time-varyingdelays.
arxiv-13500-127 | A Multi-Agent System Approach to Load-Balancing and Resource Allocation for Distributed Computing | http://arxiv.org/pdf/1509.06420v1.pdf | author:Soumya Banerjee, Joshua Hecker category:cs.NE cs.DC published:2015-09-21 summary:In this research we use a decentralized computing approach to allocate andschedule tasks on a massively distributed grid. Using emergent properties ofmulti-agent systems, the algorithm dynamically creates and dissociates clustersto serve the changing resource demands of a global task queue. The algorithm iscompared to a standard First-in First-out (FIFO) scheduling algorithm.Experiments done on a simulator show that the distributed resource allocationprotocol (dRAP) algorithm outperforms the FIFO scheduling algorithm on time toempty queue, average waiting time and CPU utilization. Such a decentralizedcomputing approach holds promise for massively distributed processing scenarioslike SETI@home and Google MapReduce.
arxiv-13500-128 | Fusing Multi-Stream Deep Networks for Video Classification | http://arxiv.org/pdf/1509.06086v2.pdf | author:Zuxuan Wu, Yu-Gang Jiang, Xi Wang, Hao Ye, Xiangyang Xue, Jun Wang category:cs.CV cs.MM published:2015-09-21 summary:This paper studies deep network architectures to address the problem of videoclassification. A multi-stream framework is proposed to fully utilize the richmultimodal information in videos. Specifically, we first train threeConvolutional Neural Networks to model spatial, short-term motion and audioclues respectively. Long Short Term Memory networks are then adopted to explorelong-term temporal dynamics. With the outputs of the individual streams, wepropose a simple and effective fusion method to generate the final predictions,where the optimal fusion weights are learned adaptively for each class, and thelearning process is regularized by automatically estimated class relationships.Our contributions are two-fold. First, the proposed multi-stream framework isable to exploit multimodal features that are more comprehensive than thosepreviously attempted. Second, we demonstrate that the adaptive fusion methodusing the class relationship as a regularizer outperforms traditionalalternatives that estimate the weights in a "free" fashion. Our frameworkproduces significantly better results than the state of the arts on two popularbenchmarks, 92.2\% on UCF-101 (without using audio) and 84.9\% on ColumbiaConsumer Videos.
arxiv-13500-129 | Deep Spatial Autoencoders for Visuomotor Learning | http://arxiv.org/pdf/1509.06113v3.pdf | author:Chelsea Finn, Xin Yu Tan, Yan Duan, Trevor Darrell, Sergey Levine, Pieter Abbeel category:cs.LG cs.CV cs.RO published:2015-09-21 summary:Reinforcement learning provides a powerful and flexible framework forautomated acquisition of robotic motion skills. However, applying reinforcementlearning requires a sufficiently detailed representation of the state,including the configuration of task-relevant objects. We present an approachthat automates state-space construction by learning a state representationdirectly from camera images. Our method uses a deep spatial autoencoder toacquire a set of feature points that describe the environment for the currenttask, such as the positions of objects, and then learns a motion skill withthese feature points using an efficient reinforcement learning method based onlocal linear models. The resulting controller reacts continuously to thelearned feature points, allowing the robot to dynamically manipulate objects inthe world with closed-loop control. We demonstrate our method with a PR2 roboton tasks that include pushing a free-standing toy block, picking up a bag ofrice using a spatula, and hanging a loop of rope on a hook at variouspositions. In each task, our method automatically learns to track task-relevantobjects and manipulate their configuration with the robot's arm.
arxiv-13500-130 | Robust Visual Tracking via Inverse Nonnegative Matrix Factorization | http://arxiv.org/pdf/1509.06003v3.pdf | author:Fanghui Liu, Tao Zhou, Keren Fu, Irene Y. H. Gu, Jie Yang category:cs.CV published:2015-09-20 summary:The establishment of robust target appearance model over time is anoverriding concern in visual tracking. In this paper, we propose an inversenonnegative matrix factorization (NMF) method for robust appearance modeling.Rather than using a linear combination of nonnegative basis matrices for eachtarget image patch in the conventional NMF, the proposed method is a reversethought to conventional NMF tracker. It utilizes both the foreground andbackground information, and imposes a local coordinate constraint, where thebasis matrix is sparse matrix from the linear combination of candidates withcorresponding nonnegative coefficient vectors. Inverse NMF is used as a featureencoder, where the resulting coefficient vectors are fed into a SVM classifierfor separating the target from the background. The proposed method is tested onseveral videos and compared with seven state-of-the-art methods. Our resultshave provided further support to the effectiveness and robustness of theproposed method.
arxiv-13500-131 | On Large-Scale Retrieval: Binary or n-ary Coding? | http://arxiv.org/pdf/1509.06066v1.pdf | author:Mahyar Najibi, Mohammad Rastegari, Larry S. Davis category:cs.CV published:2015-09-20 summary:The growing amount of data available in modern-day datasets makes the need toefficiently search and retrieve information. To make large-scale searchfeasible, Distance Estimation and Subset Indexing are the main approaches.Although binary coding has been popular for implementing both techniques, n-arycoding (known as Product Quantization) is also very effective for DistanceEstimation. However, their relative performance has not been studied for SubsetIndexing. We investigate whether binary or n-ary coding works better underdifferent retrieval strategies. This leads to the design of a new n-ary codingmethod, "Linear Subspace Quantization (LSQ)" which, unlike other n-aryencoders, can be used as a similarity-preserving embedding. Experiments onimage retrieval show that when Distance Estimation is used, n-ary LSQoutperforms other methods. However, when Subset Indexing is applied,interestingly, binary codings are more effective and binary LSQ achieves thebest accuracy.
arxiv-13500-132 | A Statistical Theory of Deep Learning via Proximal Splitting | http://arxiv.org/pdf/1509.06061v1.pdf | author:Nicholas G. Polson, Brandon T. Willard, Massoud Heidari category:stat.ML published:2015-09-20 summary:In this paper we develop a statistical theory and an implementation of deeplearning models. We show that an elegant variable splitting scheme for thealternating direction method of multipliers optimises a deep learningobjective. We allow for non-smooth non-convex regularisation penalties toinduce sparsity in parameter weights. We provide a link between traditionalshallow layer statistical models such as principal component and sliced inverseregression and deep layer models. We also define the degrees of freedom of adeep learning predictor and a predictive MSE criteria to perform modelselection for comparing architecture designs. We focus on deep multiclasslogistic learning although our methods apply more generally. Our resultssuggest an interesting and previously under-exploited relationship between deeplearning and proximal splitting techniques. To illustrate our methodology, weprovide a multi-class logit classification analysis of Fisher's Iris data wherewe illustrate the convergence of our algorithm. Finally, we conclude withdirections for future research.
arxiv-13500-133 | Impact of noise on a dynamical system: prediction and uncertainties from a swarm-optimized neural network | http://arxiv.org/pdf/1509.06057v1.pdf | author:C. H. López-Caraballo, J. A. Lazzús, I. Salfate, P. Rojas, M. Rivera, L. Palma-Chilla category:cs.NE published:2015-09-20 summary:In this study, an artificial neural network (ANN) based on particle swarmoptimization (PSO) was developed for the time series prediction. The hybridANN+PSO algorithm was applied on Mackey--Glass chaotic time series in theshort-term $x(t+6)$. The performance prediction was evaluated and compared withanother studies available in the literature. Also, we presented properties ofthe dynamical system via the study of chaotic behaviour obtained from thepredicted time series. Next, the hybrid ANN+PSO algorithm was complemented witha Gaussian stochastic procedure (called {\it stochastic} hybrid ANN+PSO) inorder to obtain a new estimator of the predictions, which also allowed us tocompute uncertainties of predictions for noisy Mackey--Glass chaotic timeseries. Thus, we studied the impact of noise for several cases with a whitenoise level ($\sigma_{N}$) from 0.01 to 0.1.
arxiv-13500-134 | Robust Image Sentiment Analysis Using Progressively Trained and Domain Transferred Deep Networks | http://arxiv.org/pdf/1509.06041v1.pdf | author:Quanzeng You, Jiebo Luo, Hailin Jin, Jianchao Yang category:cs.CV cs.IR cs.LG published:2015-09-20 summary:Sentiment analysis of online user generated content is important for manysocial media analytics tasks. Researchers have largely relied on textualsentiment analysis to develop systems to predict political elections, measureeconomic indicators, and so on. Recently, social media users are increasinglyusing images and videos to express their opinions and share their experiences.Sentiment analysis of such large scale visual content can help better extractuser sentiments toward events or topics, such as those in image tweets, so thatprediction of sentiment from visual content is complementary to textualsentiment analysis. Motivated by the needs in leveraging large scale yet noisytraining data to solve the extremely challenging problem of image sentimentanalysis, we employ Convolutional Neural Networks (CNN). We first design asuitable CNN architecture for image sentiment analysis. We obtain half amillion training samples by using a baseline sentiment algorithm to labelFlickr images. To make use of such noisy machine labeled data, we employ aprogressive strategy to fine-tune the deep network. Furthermore, we improve theperformance on Twitter images by inducing domain transfer with a small numberof manually labeled Twitter images. We have conducted extensive experiments onmanually labeled Twitter images. The results show that the proposed CNN canachieve better performance in image sentiment analysis than competingalgorithms.
arxiv-13500-135 | Early text classification: a Naive solution | http://arxiv.org/pdf/1509.06053v1.pdf | author:Hugo Jair Escalante, Manuel Montes-y-Gómez, Luis Villaseñor-Pineda, Marcelo Luis Errecalde category:cs.CL published:2015-09-20 summary:Text classification is a widely studied problem, and it can be consideredsolved for some domains and under certain circumstances. There are scenarios,however, that have received little or no attention at all, despite itsrelevance and applicability. One of such scenarios is early textclassification, where one needs to know the category of a document by usingpartial information only. A document is processed as a sequence of terms, andthe goal is to devise a method that can make predictions as fast as possible.The importance of this variant of the text classification problem is evident indomains like sexual predator detection, where one wants to identify an offenderas early as possible. This paper analyzes the suitability of the standard naiveBayes classifier for approaching this problem. Specifically, we assess itsperformance when classifying documents after seeing an increasingly number ofterms. A simple modification to the standard naive Bayes implementation allowsus to make predictions with partial information. To the best of our knowledgenaive Bayes has not been used for this purpose before. Throughout an extensiveexperimental evaluation we show the effectiveness of the classifier for earlytext classification. What is more, we show that this simple solution is verycompetitive when compared with state of the art methodologies that are moreelaborated. We foresee our work will pave the way for the development of moreeffective early text classification techniques based in the naive Bayesformulation.
arxiv-13500-136 | Denoising without access to clean data using a partitioned autoencoder | http://arxiv.org/pdf/1509.05982v2.pdf | author:Dan Stowell, Richard E. Turner category:cs.NE cs.LG published:2015-09-20 summary:Training a denoising autoencoder neural network requires access to trulyclean data, a requirement which is often impractical. To remedy this, weintroduce a method to train an autoencoder using only noisy data, havingexamples with and without the signal class of interest. The autoencoder learnsa partitioned representation of signal and noise, learning to reconstruct eachseparately. We illustrate the method by denoising birdsong audio (availableabundantly in uncontrolled noisy datasets) using a convolutional autoencoder.
arxiv-13500-137 | Image Retrieval Based on LBP Pyramidal Multiresolution using Reversible Watermarking | http://arxiv.org/pdf/1509.06035v1.pdf | author:H. Ouahi, K. Afdel, M. Machkour category:cs.CV published:2015-09-20 summary:In the medical field, images are increasingly used to facilitate diagnosis ofdiseases. These images are stored in multimedia databases accompanied by doctors prescriptions and other information related to patients.Search for medicalimages has become for clinical applications an essential tool to bringeffective aid in diagnosis. Content Based Image Retrieval (CBIR) is one of thepossible solutions to effectively manage these databases. Our contribution isto define a relevant descriptor to retrieve images based on multiresolutionanalysis of texture using Local Binary Pattern LBP. This descriptor oncecalculated and information s relating to the patient; will be placed in theimage using the technique of reversible watermarking. Thereby, the image,descriptor of its contents, the BFILE locator and patientrelated informationbecome a single entity, so even the administrator cannot have access to thepatient private data.
arxiv-13500-138 | Deep Convolutional Features for Image Based Retrieval and Scene Categorization | http://arxiv.org/pdf/1509.06033v1.pdf | author:Arsalan Mousavian, Jana Kosecka category:cs.CV published:2015-09-20 summary:Several recent approaches showed how the representations learned byConvolutional Neural Networks can be repurposed for novel tasks. Most commonlyit has been shown that the activation features of the last fully connectedlayers (fc7 or fc6) of the network, followed by a linear classifier outperformthe state-of-the-art on several recognition challenge datasets. Instead ofrecognition, this paper focuses on the image retrieval problem and proposes aexamines alternative pooling strategies derived for CNN features. The presentedscheme uses the features maps from an earlier layer 5 of the CNN architecture,which has been shown to preserve coarse spatial information and is semanticallymeaningful. We examine several pooling strategies and demonstrate superiorperformance on the image retrieval task (INRIA Holidays) at the fraction of thecomputational cost, while using a relatively small memory requirements. Inaddition to retrieval, we see similar efficiency gains on the SUN397 scenecategorization dataset, demonstrating wide applicability of this simplestrategy. We also introduce and evaluate a novel GeoPlaces5K dataset fromdifferent geographical locations in the world for image retrieval that stressesmore dramatic changes in appearance and viewpoint.
arxiv-13500-139 | Image Set Querying Based Localization | http://arxiv.org/pdf/1509.06016v1.pdf | author:Lei Deng, Siyuan Huang, Yueqi Duan, Baohua Chen, Jie Zhou category:cs.CV published:2015-09-20 summary:Conventional single image based localization methods usually fail to localizea querying image when there exist large variations between the querying imageand the pre-built scene. To address this, we propose an image-set queryingbased localization approach. When the localization by a single image fails towork, the system will ask the user to capture more auxiliary images. First, alocal 3D model is established for the querying image set. Then, the pose of thequerying image set is estimated by solving a nonlinear optimization problem,which aims to match the local 3D model against the pre-built scene. Experimentshave shown the effectiveness and feasibility of the proposed approach.
arxiv-13500-140 | A Parallel Framework for Parametric Maximum Flow Problems in Image Segmentation | http://arxiv.org/pdf/1509.06004v2.pdf | author:Vlad Olaru, Mihai Florea, Cristian Sminchisescu category:cs.CV published:2015-09-20 summary:This paper presents a framework that supports the implementation of parallelsolutions for the widespread parametric maximum flow computational routinesused in image segmentation algorithms. The framework is based on supergraphs, aspecial construction combining several image graphs into a larger one, andworks on various architectures (multi-core or GPU), either locally or remotelyin a cluster of computing nodes. The framework can also be used for performanceevaluation of parallel implementations of maximum flow algorithms. We presentthe case study of a state-of-the-art image segmentation algorithm based ongraph cuts, Constrained Parametric Min-Cut (CPMC), that uses the parallelframework to solve parametric maximum flow problems, based on a GPUimplementation of the well-known push-relabel algorithm. Our results indicatethat real-time implementations based on the proposed techniques are possible.
arxiv-13500-141 | Telugu OCR Framework using Deep Learning | http://arxiv.org/pdf/1509.05962v1.pdf | author:Rakesh Achanta, Trevor Hastie category:stat.ML cs.AI cs.CV cs.LG cs.NE published:2015-09-20 summary:In this paper, we address the task of Optical Character Recognition(OCR) forthe Telugu script. We present an end-to-end framework that segments the textimage, classifies the characters and extracts lines using a language model. Thesegmentation is based on mathematical morphology. The classification module,which is the most challenging task of the three, is a deep convolutional neuralnetwork. The language is modelled as a third degree markov chain at the glyphlevel. Telugu script is a complex abugida and the language is agglutinative,making the problem hard. In this paper we apply the latest advances in neuralnetworks to achieve acceptable error rates.
arxiv-13500-142 | STDP as presynaptic activity times rate of change of postsynaptic activity | http://arxiv.org/pdf/1509.05936v2.pdf | author:Yoshua Bengio, Thomas Mesnard, Asja Fischer, Saizheng Zhang, Yuhuai Wu category:cs.NE cs.LG q-bio.NC published:2015-09-19 summary:We introduce a weight update formula that is expressed only in terms offiring rates and their derivatives and that results in changes consistent withthose associated with spike-timing dependent plasticity (STDP) rules andbiological observations, even though the explicit timing of spikes is notneeded. The new rule changes a synaptic weight in proportion to the product ofthe presynaptic firing rate and the temporal rate of change of activity on thepostsynaptic side. These quantities are interesting for studying theoreticalexplanation for synaptic changes from a machine learning perspective. Inparticular, if neural dynamics moved neural activity towards reducing someobjective function, then this STDP rule would correspond to stochastic gradientdescent on that objective function.
arxiv-13500-143 | Face Photo Sketch Synthesis via Larger Patch and Multiresolution Spline | http://arxiv.org/pdf/1509.05897v1.pdf | author:Xu Yang category:cs.CV published:2015-09-19 summary:Face photo sketch synthesis has got some researchers' attention in recentyears because of its potential applications in digital entertainment and lawenforcement. Some patches based methods have been proposed to solve thisproblem. These methods usually focus more on how to get a sketch patch for agiven photo patch than how to blend these generated patches. However, withoutappropriately blending method, some jagged parts and mottled points will appearin the entire face sketch. In order to get a smoother sketch, we propose a newmethod to reduce such jagged parts and mottled points. In our system, we resortto an existed method, which is Markov Random Fields (MRF), to train a crudeface sketch firstly. Then this crude sketch face sketch will be divided intosome larger patches again and retrained by Non-Negative Matrix Factorization(NMF). At last, we use Multiresolution Spline and a blend trick namedfull-coverage trick to blend these retrained patches. The experiment resultsshow that compared with some previous method, we can get a smoother facesketch.
arxiv-13500-144 | A Fuzzy MLP Approach for Non-linear Pattern Classification | http://arxiv.org/pdf/1601.03481v1.pdf | author:Tirtharaj Dash, H. S. Behera category:cs.NE published:2015-09-19 summary:In case of decision making problems, classification of pattern is a complexand crucial task. Pattern classification using multilayer perceptron (MLP)trained with back propagation learning becomes much complex with increase innumber of layers, number of nodes and number of epochs and ultimate increasescomputational time [31]. In this paper, an attempt has been made to use fuzzyMLP and its learning algorithm for pattern classification. The time and spacecomplexities of the algorithm have been analyzed. A training performancecomparison has been carried out between MLP and the proposed fuzzy-MLP model byconsidering six cases. Results are noted against different learning ratesranging from 0 to 1. A new performance evaluation factor 'convergence gain' hasbeen introduced. It is observed that the number of epochs drastically reducedand performance increased compared to MLP. The average and minimum gain hasbeen found to be 93% and 75% respectively. The best gain is found to be 95% andis obtained by setting the learning rate to 0.55.
arxiv-13500-145 | Similar Handwritten Chinese Character Discrimination by Weakly Supervised Learning | http://arxiv.org/pdf/1509.05844v1.pdf | author:Zhibo Yang, Huanle Xu, Keda Fu, Yong Xia category:cs.CV published:2015-09-19 summary:Traditional approaches for handwritten Chinese character recognition sufferin classifying similar characters. In this paper, we propose to discriminatesimilar handwritten Chinese characters by using weakly supervised learning. Ourapproach learns a discriminative SVM for each similar pair which simultaneouslylocalizes the discriminative region of similar character and makes theclassification. For the first time, similar handwritten Chinese characterrecognition (SHCCR) is formulated as an optimization problem extended from SVM.We also propose a novel feature descriptor, Gradient Context, and applybag-of-words model to represent regions with different scales. In our method,we do not need to select a sized-fixed sub-window to differentiate similarcharacters. The unconstrained property makes our method well adapted to highvariance in the size and position of discriminative regions in similarhandwritten Chinese characters. We evaluate our proposed approach over theCASIA Chinese character data set and the results show that our methodoutperforms the state of the art.
arxiv-13500-146 | Modelling Uncertainty in Deep Learning for Camera Relocalization | http://arxiv.org/pdf/1509.05909v2.pdf | author:Alex Kendall, Roberto Cipolla category:cs.CV cs.RO published:2015-09-19 summary:We present a robust and real-time monocular six degree of freedom visualrelocalization system. We use a Bayesian convolutional neural network toregress the 6-DOF camera pose from a single RGB image. It is trained in anend-to-end manner with no need of additional engineering or graph optimisation.The algorithm can operate indoors and outdoors in real time, taking under 6msto compute. It obtains approximately 2m and 6 degrees accuracy for very largescale outdoor scenes and 0.5m and 10 degrees accuracy indoors. Using a Bayesianconvolutional neural network implementation we obtain an estimate of themodel's relocalization uncertainty and improve state of the art localizationaccuracy on a large scale outdoor dataset. We leverage the uncertainty measureto estimate metric relocalization error and to detect the presence or absenceof the scene in the input image. We show that the model's uncertainty is causedby images being dissimilar to the training dataset in either pose orappearance.
arxiv-13500-147 | "Oddball SGD": Novelty Driven Stochastic Gradient Descent for Training Deep Neural Networks | http://arxiv.org/pdf/1509.05765v1.pdf | author:Andrew J. R. Simpson category:cs.LG 68Txx published:2015-09-18 summary:Stochastic Gradient Descent (SGD) is arguably the most popular of the machinelearning methods applied to training deep neural networks (DNN) today. It hasrecently been demonstrated that SGD can be statistically biased so that certainelements of the training set are learned more rapidly than others. In thisarticle, we place SGD into a feedback loop whereby the probability of selectionis proportional to error magnitude. This provides a novelty-driven oddball SGDprocess that learns more rapidly than traditional SGD by prioritising thoseelements of the training set with the largest novelty (error). In our DNNexample, oddball SGD trains some 50x faster than regular SGD.
arxiv-13500-148 | Subdominant Dense Clusters Allow for Simple Learning and High Computational Performance in Neural Networks with Discrete Synapses | http://arxiv.org/pdf/1509.05753v1.pdf | author:Carlo Baldassi, Alessandro Ingrosso, Carlo Lucibello, Luca Saglietti, Riccardo Zecchina category:q-bio.NC stat.ML published:2015-09-18 summary:We show that discrete synaptic weights can be efficiently used for learningin large scale neural systems, and lead to unanticipated computationalperformance. We focus on the representative case of learning random patternswith binary synapses in single layer networks. The standard statisticalanalysis shows that this problem is exponentially dominated by isolatedsolutions that are extremely hard to find algorithmically. Here, we introduce anovel method that allows us to find analytical evidence for the existence ofsubdominant and extremely dense regions of solutions. Numerical experimentsconfirm these findings. We also show that the dense regions are surprisinglyaccessible by simple learning protocols, and that these synaptic configurationsare robust to perturbations and generalize better than typical solutions. Theseoutcomes extend to synapses with multiple states and to deeper neuralarchitectures. The large deviation measure also suggests how to design novelalgorithmic schemes for optimization based on local entropy maximization.
arxiv-13500-149 | Energy saving in smart homes based on consumer behaviour: A case study | http://arxiv.org/pdf/1509.05722v1.pdf | author:Michael Zehnder, Holger Wache, Hans-Friedrich Witschel, Danilo Zanatta, Miguel Rodriguez category:stat.ML cs.AI cs.MA cs.SY published:2015-09-18 summary:This paper presents a case study of a recommender system that can be used tosave energy in smart homes without lowering the comfort of the inhabitants. Wepresent an algorithm that uses consumer behavior data only and uses machinelearning to suggest actions for inhabitants to reduce the energy consumption oftheir homes. The system mines for frequent and periodic patterns in the eventdata provided by the Digitalstrom home automation system. These patterns areconverted into association rules, prioritized and compared with the currentbehavior of the inhabitants. If the system detects an opportunities to saveenergy without decreasing the comfort level it sends a recommendation to theresidents.
arxiv-13500-150 | Computational evolution of decision-making strategies | http://arxiv.org/pdf/1509.05646v1.pdf | author:Peter Kvam, Joseph Cesario, Jory Schossau, Heather Eisthen, Arend Hintze category:cs.NE q-bio.NC published:2015-09-18 summary:Most research on adaptive decision-making takes a strategy-first approach,proposing a method of solving a problem and then examining whether it can beimplemented in the brain and in what environments it succeeds. We present amethod for studying strategy development based on computational evolution thattakes the opposite approach, allowing strategies to develop in response to thedecision-making environment via Darwinian evolution. We apply this approach toa dynamic decision-making problem where artificial agents make decisions aboutthe source of incoming information. In doing so, we show that the complexity ofthe brains and strategies of evolved agents are a function of the environmentin which they develop. More difficult environments lead to larger brains andmore information use, resulting in strategies resembling a sequential samplingapproach. Less difficult environments drive evolution toward smaller brains andless information use, resulting in simpler heuristic-like strategies.
arxiv-13500-151 | Linearized Kernel Dictionary Learning | http://arxiv.org/pdf/1509.05634v1.pdf | author:Alona Golts, Michael Elad category:cs.CV published:2015-09-18 summary:In this paper we present a new approach of incorporating kernels intodictionary learning. The kernel K-SVD algorithm (KKSVD), which has beenintroduced recently, shows an improvement in classification performance, withrelation to its linear counterpart K-SVD. However, this algorithm requires thestorage and handling of a very large kernel matrix, which leads to highcomputational cost, while also limiting its use to setups with small number oftraining examples. We address these problems by combining two ideas: first weapproximate the kernel matrix using a cleverly sampled subset of its columnsusing the Nystr\"{o}m method; secondly, as we wish to avoid using this matrixaltogether, we decompose it by SVD to form new "virtual samples," on which anylinear dictionary learning can be employed. Our method, termed "LinearizedKernel Dictionary Learning" (LKDL) can be seamlessly applied as apre-processing stage on top of any efficient off-the-shelf dictionary learningscheme, effectively "kernelizing" it. We demonstrate the effectiveness of ourmethod on several tasks of both supervised and unsupervised classification andshow the efficiency of the proposed scheme, its easy integration andperformance boosting properties.
arxiv-13500-152 | Sports highlights generation based on acoustic events detection: A rugby case study | http://arxiv.org/pdf/1509.06279v1.pdf | author:Anant Baijal, Jaeyoun Cho, Woojung Lee, Byeong-Seob Ko category:cs.SD cs.AI cs.LG published:2015-09-18 summary:We approach the challenging problem of generating highlights from sportsbroadcasts utilizing audio information only. A language-independent,multi-stage classification approach is employed for detection of key acousticevents which then act as a platform for summarization of highlight scenes.Objective results and human experience indicate that our system is highlyefficient.
arxiv-13500-153 | Accelerating Optimization via Adaptive Prediction | http://arxiv.org/pdf/1509.05760v3.pdf | author:Mehryar Mohri, Scott Yang category:stat.ML cs.LG published:2015-09-18 summary:We present a powerful general framework for designing data-dependentoptimization algorithms, building upon and unifying recent techniques inadaptive regularization, optimistic gradient predictions, and problem-dependentrandomization. We first present a series of new regret guarantees that hold atany time and under very minimal assumptions, and then show how differentrelaxations recover existing algorithms, both basic as well as more recentsophisticated ones. Finally, we show how combining adaptivity, optimism, andproblem-dependent randomization can guide the design of algorithms that benefitfrom more favorable guarantees than recent state-of-the-art methods.
arxiv-13500-154 | MAGMA: Multi-level accelerated gradient mirror descent algorithm for large-scale convex composite minimization | http://arxiv.org/pdf/1509.05715v2.pdf | author:Vahan Hovhannisyan, Panos Parpas, Stefanos Zafeiriou category:math.OC cs.CV published:2015-09-18 summary:Composite convex optimization models arise in several applications, and areespecially prevalent in inverse problems with a sparsity inducing norm and ingeneral convex optimization with simple constraints. The most widely usedalgorithms for convex composite models are accelerated first order methods,however they can take a large number of iterations to compute an acceptablesolution for large-scale problems. In this paper we propose to speed up firstorder methods by taking advantage of the structure present in many applicationsand in image processing in particular. Our method is based on multi-leveloptimization methods and exploits the fact that many applications that giverise to large scale models can be modelled using varying degrees of fidelity.We use Nesterov's acceleration techniques together with the multi-levelapproach to achieve $\mathcal{O}(1/\sqrt{\epsilon})$ convergence rate, where$\epsilon$ denotes the desired accuracy. The proposed method has a betterconvergence rate than any other existing multi-level method for convexproblems, and in addition has the same rate as accelerated methods, which isknown to be optimal for first-order methods. Moreover, as our numericalexperiments show, on large-scale face recognition problems our algorithm isseveral times faster than the state of the art.
arxiv-13500-155 | Color-Stripe Structured Light Robust to Surface Color and Discontinuity | http://arxiv.org/pdf/1509.05592v1.pdf | author:Kwang Hee Lee, Changsoo Je, Sang Wook Lee category:cs.CV cs.GR physics.optics I.2.10; I.4.8 published:2015-09-18 summary:Multiple color stripes have been employed for structured light-based rapidrange imaging to increase the number of uniquely identifiable stripes. The useof multiple color stripes poses two problems: (1) object surface color maydisturb the stripe color and (2) the number of adjacent stripes required foridentifying a stripe may not be maintained near surface discontinuities such asoccluding boundaries. In this paper, we present methods to alleviate thoseproblems. Log-gradient filters are employed to reduce the influence of objectcolors, and color stripes in two and three directions are used to increase thechance of identifying correct stripes near surface discontinuities.Experimental results demonstrate the effectiveness of our methods.
arxiv-13500-156 | Word, graph and manifold embedding from Markov processes | http://arxiv.org/pdf/1509.05808v1.pdf | author:Tatsunori B. Hashimoto, David Alvarez-Melis, Tommi S. Jaakkola category:cs.CL cs.LG stat.ML published:2015-09-18 summary:Continuous vector representations of words and objects appear to carrysurprisingly rich semantic content. In this paper, we advance both theconceptual and theoretical understanding of word embeddings in three ways.First, we ground embeddings in semantic spaces studied incognitive-psychometric literature and introduce new evaluation tasks. Second,in contrast to prior work, we take metric recovery as the key object of study,unify existing algorithms as consistent metric recovery methods based onco-occurrence counts from simple Markov random walks, and propose a newrecovery algorithm. Third, we generalize metric recovery to graphs andmanifolds, relating co-occurence counts on random walks in graphs and randomprocesses on manifolds to the underlying metric to be recovered, therebyreconciling manifold estimation and embedding algorithms. We compare embeddingalgorithms across a range of tasks, from nonlinear dimensionality reduction tothree semantic language tasks, including analogies, sequence completion, andclassification.
arxiv-13500-157 | TransA: An Adaptive Approach for Knowledge Graph Embedding | http://arxiv.org/pdf/1509.05490v2.pdf | author:Han Xiao, Minlie Huang, Yu Hao, Xiaoyan Zhu category:cs.CL published:2015-09-18 summary:Knowledge representation is a major topic in AI, and many studies attempt torepresent entities and relations of knowledge base in a continuous vectorspace. Among these attempts, translation-based methods build entity andrelation vectors by minimizing the translation loss from a head entity to atail one. In spite of the success of these methods, translation-based methodsalso suffer from the oversimplified loss metric, and are not competitive enoughto model various and complex entities/relations in knowledge bases. To addressthis issue, we propose \textbf{TransA}, an adaptive metric approach forembedding, utilizing the metric learning ideas to provide a more flexibleembedding method. Experiments are conducted on the benchmark datasets and ourproposed method makes significant and consistent improvements over thestate-of-the-art baselines.
arxiv-13500-158 | TransG : A Generative Mixture Model for Knowledge Graph Embedding | http://arxiv.org/pdf/1509.05488v4.pdf | author:Han Xiao, Minlie Huang, Yu Hao, Xiaoyan Zhu category:cs.CL published:2015-09-18 summary:Recently, knowledge graph embedding, which projects symbolic entities andrelations into continuous vector space, has become a new, hot topic inartificial intelligence. This paper addresses a new issue of \textbf{multiplerelation semantics} that a relation may have multiple meanings revealed by theentity pairs associated with the corresponding triples, and proposes a novelGaussian mixture model for embedding, \textbf{TransG}. The new model candiscover latent semantics for a relation and leverage a mixture of relationcomponent vectors for embedding a fact triple. To the best of our knowledge,this is the first generative model for knowledge graph embedding, which is ableto deal with multiple relation semantics. Extensive experiments show that theproposed model achieves substantial improvements against the state-of-the-artbaselines.
arxiv-13500-159 | A Light Sliding-Window Part-of-Speech Tagger for the Apertium Free/Open-Source Machine Translation Platform | http://arxiv.org/pdf/1509.05517v1.pdf | author:Gang Chen, Mikel L. Forcada category:cs.CL published:2015-09-18 summary:This paper describes a free/open-source implementation of the lightsliding-window (LSW) part-of-speech tagger for the Apertium free/open-sourcemachine translation platform. Firstly, the mechanism and training process ofthe tagger are reviewed, and a new method for incorporating linguistic rules isproposed. Secondly, experiments are conducted to compare the performances ofthe tagger under different window settings, with or without Apertium-style"forbid" rules, with or without Constraint Grammar, and also with respect tothe traditional HMM tagger in Apertium.
arxiv-13500-160 | An Experimental Survey on Correlation Filter-based Tracking | http://arxiv.org/pdf/1509.05520v1.pdf | author:Zhe Chen, Zhibin Hong, Dacheng Tao category:cs.CV published:2015-09-18 summary:Over these years, Correlation Filter-based Trackers (CFTs) have arousedincreasing interests in the field of visual object tracking, and have achievedextremely compelling results in different competitions and benchmarks. In thispaper, our goal is to review the developments of CFTs with extensiveexperimental results. 11 trackers are surveyed in our work, based on which ageneral framework is summarized. Furthermore, we investigate different trainingschemes for correlation filters, and also discuss various effectiveimprovements that have been made recently. Comprehensive experiments have beenconducted to evaluate the effectiveness and efficiency of the surveyed CFTs,and comparisons have been made with other competing trackers. The experimentalresults have shown that state-of-art performance, in terms of robustness, speedand accuracy, can be achieved by several recent CFTs, such as MUSTer and SAMF.We find that further improvements for correlation filter-based tracking can bemade on estimating scales, applying part-based tracking strategy andcooperating with long-term tracking methods.
arxiv-13500-161 | Building a Pilot Software Quality-in-Use Benchmark Dataset | http://arxiv.org/pdf/1509.05736v1.pdf | author:Issa Atoum, Chih How Bong, Narayanan Kulathuramaiyer category:cs.SE cs.CL published:2015-09-18 summary:Prepared domain specific datasets plays an important role to supervisedlearning approaches. In this article a new sentence dataset for softwarequality-in-use is proposed. Three experts were chosen to annotate the datausing a proposed annotation scheme. Then the data were reconciled in a (nomatch eliminate) process to reduce bias. The Kappa, k statistics revealed anacceptable level of agreement; moderate to substantial agreement between theexperts. The built data can be used to evaluate software quality-in-use modelsin sentiment analysis models. Moreover, the annotation scheme can be used toextend the current dataset.
arxiv-13500-162 | BLC: Private Matrix Factorization Recommenders via Automatic Group Learning | http://arxiv.org/pdf/1509.05789v2.pdf | author:Alessandro Checco, Giuseppe Bianchi, Doug Leith category:cs.LG stat.ML published:2015-09-18 summary:We propose a privacy-enhanced matrix factorization recommender that exploitsthe fact that users can often be grouped together by interest. This allows aform of "hiding in the crowd" privacy. We introduce a novel matrixfactorization approach suited to making recommendations in a shared group (ornym) setting and the BLC algorithm for carrying out this matrix factorizationin a privacy-enhanced manner. We demonstrate that the increased privacy doesnot come at the cost of reduced recommendation accuracy.
arxiv-13500-163 | Efficient Clustering on Riemannian Manifolds: A Kernelised Random Projection Approach | http://arxiv.org/pdf/1509.05536v1.pdf | author:Kun Zhao, Azadeh Alavi, Arnold Wiliem, Brian C. Lovell category:cs.CV published:2015-09-18 summary:Reformulating computer vision problems over Riemannian manifolds hasdemonstrated superior performance in various computer vision applications. Thisis because visual data often forms a special structure lying on a lowerdimensional space embedded in a higher dimensional space. However, since thesemanifolds belong to non-Euclidean topological spaces, exploiting theirstructures is computationally expensive, especially when one considers theclustering analysis of massive amounts of data. To this end, we propose anefficient framework to address the clustering problem on Riemannian manifolds.This framework implements random projections for manifold points via kernelspace, which can preserve the geometric structure of the original space, but iscomputationally efficient. Here, we introduce three methods that follow ourframework. We then validate our framework on several computer visionapplications by comparing against popular clustering methods on Riemannianmanifolds. Experimental results demonstrate that our framework maintains theperformance of the clustering whilst massively reducing computationalcomplexity by over two orders of magnitude in some cases.
arxiv-13500-164 | Evaluation of Protein-protein Interaction Predictors with Noisy Partially Labeled Data Sets | http://arxiv.org/pdf/1509.05742v1.pdf | author:Haohan Wang, Madhavi K. Ganapathiraju category:cs.AI stat.ML published:2015-09-18 summary:Protein-protein interaction (PPI) prediction is an important problem inmachine learning and computational biology. However, there is no data set fortraining or evaluation purposes, where all the instances are accuratelylabeled. Instead, what is available are instances of positive class (withpossibly noisy labels) and no instances of negative class. The non-availabilityof negative class data is typically handled with the observation that randomlychosen protein-pairs have a nearly 100% chance of being negative class, as only1 in 1,500 protein pairs expected is expected to be an interacting pair. Inthis paper, we focused on the problem that non-availability of accuratelylabeled testing data sets in the domain of protein-protein interaction (PPI)prediction may lead to biased evaluation results. We first showed that notacknowledging the inherent skew in the interactome (i.e. rare occurrence ofpositive instances) leads to an over-estimated accuracy of the predictor. Thenwe show that, with the belief that positive interactions are a rare category,sampling random pairs of proteins excluding known interacting proteins set asthe negative testing data set could lead to an under-estimated evaluationresult. We formalized those two problems to validate the above claim, and basedon the formalization, we proposed a balancing method to cancel out theover-estimation with under-estimation. Finally, our experiments validated thetheoretical aspects and showed that this balancing evaluation could evaluatethe exact performance without availability of golden standard data sets.
arxiv-13500-165 | Fast and Simple PCA via Convex Optimization | http://arxiv.org/pdf/1509.05647v4.pdf | author:Dan Garber, Elad Hazan category:math.OC cs.LG cs.NA math.NA published:2015-09-18 summary:The problem of principle component analysis (PCA) is traditionally solved byspectral or algebraic methods. We show how computing the leading principalcomponent could be reduced to solving a \textit{small} number ofwell-conditioned {\it convex} optimization problems. This gives rise to a newefficient method for PCA based on recent advances in stochastic methods forconvex optimization. In particular we show that given a $d\times d$ matrix $\X =\frac{1}{n}\sum_{i=1}^n\x_i\x_i^{\top}$ with top eigenvector $\u$ and topeigenvalue $\lambda_1$ it is possible to: \begin{itemize} \item compute a unitvector $\w$ such that $(\w^{\top}\u)^2 \geq 1-\epsilon$ in$\tilde{O}\left({\frac{d}{\delta^2}+N}\right)$ time, where $\delta = \lambda_1- \lambda_2$ and $N$ is the total number of non-zero entries in$\x_1,...,\x_n$, \item compute a unit vector $\w$ such that $\w^{\top}\X\w \geq\lambda_1-\epsilon$ in $\tilde{O}(d/\epsilon^2)$ time. \end{itemize} To thebest of our knowledge, these bounds are the fastest to date for a wide regimeof parameters. These results could be further accelerated when $\delta$ (in thefirst case) and $\epsilon$ (in the second case) are smaller than $\sqrt{d/N}$.
arxiv-13500-166 | Decadal climate predictions using sequential learning algorithms | http://arxiv.org/pdf/1509.05285v1.pdf | author:Ehud Strobach, Golan Bel category:physics.ao-ph stat.ML 62C99 published:2015-09-17 summary:Ensembles of climate models are commonly used to improve climate predictionsand assess the uncertainties associated with them. Weighting the modelsaccording to their performances holds the promise of further improving theirpredictions. Here, we use an ensemble of decadal climate predictions todemonstrate the ability of sequential learning algorithms (SLAs) to reduce theforecast errors and reduce the uncertainties. Three different SLAs areconsidered, and their performances are compared with those of an equallyweighted ensemble, a linear regression and the climatology. Predictions of fourdifferent variables--the surface temperature, the zonal and meridional wind,and pressure--are considered. The spatial distributions of the performances arepresented, and the statistical significance of the improvements achieved by theSLAs is tested. Based on the performances of the SLAs, we propose one to behighly suitable for the improvement of decadal climate predictions.
arxiv-13500-167 | Humans Are Easily Fooled by Digital Images | http://arxiv.org/pdf/1509.05301v1.pdf | author:Victor Schetinger, Manuel M. Oliveira, Roberto da Silva, Tiago J. Carvalho category:cs.GR cs.CV cs.HC published:2015-09-17 summary:Digital images are ubiquitous in our modern lives, with uses ranging fromsocial media to news, and even scientific papers. For this reason, it iscrucial evaluate how accurate people are when performing the task of identifydoctored images. In this paper, we performed an extensive user study evaluatingsubjects capacity to detect fake images. After observing an image, users havebeen asked if it had been altered or not. If the user answered the image hasbeen altered, he had to provide evidence in the form of a click on the image.We collected 17,208 individual answers from 383 users, using 177 imagesselected from public forensic databases. Different from other previouslystudies, our method propose different ways to avoid lucky guess when evaluatingusers answers. Our results indicate that people show inaccurate skills atdifferentiating between altered and non-altered images, with an accuracy of58%, and only identifying the modified images 46.5% of the time. We also trackuser features such as age, answering time, confidence, providing deep analysisof how such variables influence on the users' performance.
arxiv-13500-168 | Recurrent Spatial Transformer Networks | http://arxiv.org/pdf/1509.05329v1.pdf | author:Søren Kaae Sønderby, Casper Kaae Sønderby, Lars Maaløe, Ole Winther category:cs.CV published:2015-09-17 summary:We integrate the recently proposed spatial transformer network (SPN)[Jaderberg et. al 2015] into a recurrent neural network (RNN) to form anRNN-SPN model. We use the RNN-SPN to classify digits in cluttered MNISTsequences. The proposed model achieves a single digit error of 1.5% compared to2.9% for a convolutional networks and 2.0% for convolutional networks with SPNlayers. The SPN outputs a zoomed, rotated and skewed version of the inputimage. We investigate different down-sampling factors (ratio of pixel in inputand output) for the SPN and show that the RNN-SPN model is able to down-samplethe input images without deteriorating performance. The down-sampling inRNN-SPN can be thought of as adaptive down-sampling that minimizes theinformation loss in the regions of interest. We attribute the superiorperformance of the RNN-SPN to the fact that it can attend to a sequence ofregions of interest.
arxiv-13500-169 | Facial Descriptors for Human Interaction Recognition In Still Images | http://arxiv.org/pdf/1509.05366v1.pdf | author:Gokhan Tanisik, Cemil Zalluhoglu, Nazli Ikizler-Cinbis category:cs.CV published:2015-09-17 summary:This paper presents a novel approach in a rarely studied area of computervision: Human interaction recognition in still images. We explore whether thefacial regions and their spatial configurations contribute to the recognitionof interactions. In this respect, our method involves extraction of severalvisual features from the facial regions, as well as incorporation of scenecharacteristics and deep features to the recognition. Extracted multiplefeatures are utilized within a discriminative learning framework forrecognizing interactions between people. Our designed facial descriptors arebased on the observation that relative positions, size and locations of thefaces are likely to be important for characterizing human interactions. Sincethere is no available dataset in this relatively new domain, a comprehensivenew dataset which includes several images of human interactions is collected.Our experimental results show that faces and scene characteristics containimportant information to recognize interactions between people.
arxiv-13500-170 | Network analysis of named entity interactions in written texts | http://arxiv.org/pdf/1509.05281v1.pdf | author:Diego R. Amancio category:cs.CL physics.soc-ph published:2015-09-17 summary:The use of methods borrowed from statistics and physics has allowed for thediscovery of unprecedent patterns of human behavior and cognition byestablishing links between models features and language structure. Whilecurrent models have been useful to identify patterns via analysis ofsyntactical and semantical networks, only a few works have probed the relevanceof investigating the structure arising from the relationship between relevantentities such as characters, locations and organizations. In this study, weintroduce a model that links entities appearing in the same context in order tocapture the complexity of entities organization through a networkedrepresentation. Computational simulations in books revealed that the proposedmodel displays interesting topological features, such as short typical shortestpath length, high values of clustering coefficient and modular organization.The effectiveness of the our model was verified in a practical patternrecognition task in real networks. When compared with the traditional wordadjacency networks, our model displayed optimized results in identifyingunknown references in texts. Because the proposed model plays a complementaryrole in characterizing unstructured documents via topological analysis of namedentities, we believe that it could be useful to improve the characterizationwritten texts when combined with other traditional approaches based onstatistical and deeper paradigms.
arxiv-13500-171 | Generalized Emphatic Temporal Difference Learning: Bias-Variance Analysis | http://arxiv.org/pdf/1509.05172v2.pdf | author:Assaf Hallak, Aviv Tamar, Remi Munos, Shie Mannor category:stat.ML cs.LG published:2015-09-17 summary:We consider the off-policy evaluation problem in Markov decision processeswith function approximation. We propose a generalization of the recentlyintroduced \emph{emphatic temporal differences} (ETD) algorithm\citep{SuttonMW15}, which encompasses the original ETD($\lambda$), as well asseveral other off-policy evaluation algorithms as special cases. We call thisframework \ETD, where our introduced parameter $\beta$ controls the decay rateof an importance-sampling term. We study conditions under which the projectedfixed-point equation underlying \ETD\ involves a contraction operator, allowingus to present the first asymptotic error bounds (bias) for \ETD. Our resultsshow that the original ETD algorithm always involves a contraction operator,and its bias is bounded. Moreover, by controlling $\beta$, our proposedgeneralization allows trading-off bias for variance reduction, therebyachieving a lower total error.
arxiv-13500-172 | Deep Multi-task Learning for Railway Track Inspection | http://arxiv.org/pdf/1509.05267v1.pdf | author:Xavier Gibert, Vishal M. Patel, Rama Chellappa category:cs.CV published:2015-09-17 summary:Railroad tracks need to be periodically inspected and monitored to ensuresafe transportation. Automated track inspection using computer vision andpattern recognition methods have recently shown the potential to improve safetyby allowing for more frequent inspections while reducing human errors.Achieving full automation is still very challenging due to the number ofdifferent possible failure modes as well as the broad range of image variationsthat can potentially trigger false alarms. Also, the number of defectivecomponents is very small, so not many training examples are available for themachine to learn a robust anomaly detector. In this paper, we show thatdetection performance can be improved by combining multiple detectors within amulti-task learning framework. We show that this approach results in betteraccuracy in detecting defects on railway ties and fasteners.
arxiv-13500-173 | Fast Gaussian Process Regression for Big Data | http://arxiv.org/pdf/1509.05142v4.pdf | author:Sourish Das, Sasanka Roy, Rajiv Sambasivan category:cs.LG stat.ML published:2015-09-17 summary:Gaussian Processes are widely used for regression tasks. A known limitationin the application of Gaussian Processes to regression tasks is that thecomputation of the solution requires performing a matrix inversion. Thesolution also requires the storage of a large matrix in memory. These factorsrestrict the application of Gaussian Process regression to small and moderatesize data sets. We present an algorithm based on empirically determined subsetselection that works well on both real world and synthetic datasets. We alsocompare the performance of this algorithm with two other methods that are usedto apply Gaussian Processes Regression on large datasets. On the synthetic andreal world datasets used in this study, the algorithm demonstrated sub-lineartime and space complexity. The accuracy obtained with this algorithm on thedatasets used for this study is comparable to what is achieved with the twoother methods commonly used to apply Gaussian Processes to large datasets.
arxiv-13500-174 | (Blue) Taxi Destination and Trip Time Prediction from Partial Trajectories | http://arxiv.org/pdf/1509.05257v1.pdf | author:Hoang Thanh Lam, Ernesto Diaz-Aviles, Alessandra Pascale, Yiannis Gkoufas, Bei Chen category:stat.ML cs.AI cs.CY cs.LG I.2.6; I.5.2 published:2015-09-17 summary:Real-time estimation of destination and travel time for taxis is of greatimportance for existing electronic dispatch systems. We present an approachbased on trip matching and ensemble learning, in which we leverage the patternsobserved in a dataset of roughly 1.7 million taxi journeys to predict thecorresponding final destination and travel time for ongoing taxi trips, as asolution for the ECML/PKDD Discovery Challenge 2015 competition. The results ofour empirical evaluation show that our approach is effective and very robust,which led our team -- BlueTaxi -- to the 3rd and 7th position of the finalrankings for the trip time and destination prediction tasks, respectively.Given the fact that the final rankings were computed using a very small testset (with only 320 trips) we believe that our approach is one of the mostrobust solutions for the challenge based on the consistency of our good resultsacross the test sets.
arxiv-13500-175 | Learning Preferences from Assortment Choices in a Heterogeneous Population | http://arxiv.org/pdf/1509.05113v1.pdf | author:Nathan Kallus, Madeleine Udell category:stat.ML cs.LG math.OC published:2015-09-17 summary:We consider the problem of learning the preferences of a heterogeneouscustomer population by observing their choices from an assortment of products,ads, or other offerings. Our observation model takes a form common inassortment planning: each arriving customer chooses from an assortment ofofferings consisting of a subset of all possibilities. One-size-fits-all choicemodeling can fit heterogeneous populations quite poorly, and misses theopportunity for assortment customization in online retail. On the other hand,time, revenue, and inventory targets rule out exploring the preferences ofevery customer or segment. In this paper we propose a mixture choice model witha natural underlying low-dimensional structure, and show how to estimate itsparameters. In our model, the preferences of each customer or segment follow aseparate parametric choice model, but the underlying structure of theseparameters over all the models has low dimension. We show that a nuclear-normregularized maximum likelihood estimator can learn the preferences of allcustomers using a number of observations much smaller than the number ofitem-customer combinations. This result shows the potential for structuralassumptions to speed up learning and improve revenues in assortment planningand customization.
arxiv-13500-176 | Hand-held Video Deblurring via Efficient Fourier Aggregation | http://arxiv.org/pdf/1509.05251v3.pdf | author:Mauricio Delbracio, Guillermo Sapiro category:cs.CV published:2015-09-17 summary:Videos captured with hand-held cameras often suffer from a significant amountof blur, mainly caused by the inevitable natural tremor of the photographer'shand. In this work, we present an algorithm that removes blur due to camerashake by combining information in the Fourier domain from nearby frames in avideo. The dynamic nature of typical videos with the presence of multiplemoving objects and occlusions makes this problem of camera shake removalextremely challenging, in particular when low complexity is needed. Given aninput video frame, we first create a consistent registered version oftemporally adjacent frames. Then, the set of consistently registered frames isblock-wise fused in the Fourier domain with weights depending on the Fourierspectrum magnitude. The method is motivated from the physiological fact thatcamera shake blur has a random nature and therefore, nearby video frames aregenerally blurred differently. Experiments with numerous videos recorded in thewild, along with extensive comparisons, show that the proposed algorithmachieves state-of-the-art results while at the same time being much faster thanits competitors.
arxiv-13500-177 | Extraction of evidence tables from abstracts of randomized clinical trials using a maximum entropy classifier and global constraints | http://arxiv.org/pdf/1509.05209v1.pdf | author:Antonio Trenta, Anthony Hunter, Sebastian Riedel category:cs.CL cs.AI published:2015-09-17 summary:Systematic use of the published results of randomized clinical trials isincreasingly important in evidence-based medicine. In order to collate andanalyze the results from potentially numerous trials, evidence tables are usedto represent trials concerning a set of interventions of interest. An evidencetable has columns for the patient group, for each of the interventions beingcompared, for the criterion for the comparison (e.g. proportion who survivedafter 5 years from treatment), and for each of the results. Currently, it is alabour-intensive activity to read each published paper and extract theinformation for each field in an evidence table. There have been some NLPstudies investigating how some of the features from papers can be extracted, orat least the relevant sentences identified. However, there is a lack of an NLPsystem for the systematic extraction of each item of information required foran evidence table. We address this need by a combination of a maximum entropyclassifier, and integer linear programming. We use the later to handleconstraints on what is an acceptable classification of the features to beextracted. With experimental results, we demonstrate substantial advantages inusing global constraints (such as the features describing the patient group,and the interventions, must occur before the features describing the results ofthe comparison).
arxiv-13500-178 | Learning from Synthetic Data Using a Stacked Multichannel Autoencoder | http://arxiv.org/pdf/1509.05463v2.pdf | author:Xi Zhang, Yanwei Fu, Shanshan Jiang, Leonid Sigal, Gady Agam category:cs.CV cs.AI published:2015-09-17 summary:Learning from synthetic data has many important and practical applications.An example of application is photo-sketch recognition. Using synthetic data ischallenging due to the differences in feature distributions between syntheticand real data, a phenomenon we term synthetic gap. In this paper, weinvestigate and formalize a general framework-Stacked Multichannel Autoencoder(SMCAE) that enables bridging the synthetic gap and learning from syntheticdata more efficiently. In particular, we show that our SMCAE can not onlytransform and use synthetic data on the challenging face-sketch recognitiontask, but that it can also help simulate real images, which can be used fortraining classifiers for recognition. Preliminary experiments validate theeffectiveness of the framework.
arxiv-13500-179 | Improved Residual Vector Quantization for High-dimensional Approximate Nearest Neighbor Search | http://arxiv.org/pdf/1509.05195v1.pdf | author:Shicong Liu, Hongtao Lu, Junru Shao category:cs.CV published:2015-09-17 summary:Quantization methods have been introduced to perform large scale approximatenearest search tasks. Residual Vector Quantization (RVQ) is one of theeffective quantization methods. RVQ uses a multi-stage codebook learning schemeto lower the quantization error stage by stage. However, there are two majorlimitations for RVQ when applied to on high-dimensional approximate nearestneighbor search: 1. The performance gain diminishes quickly with added stages.2. Encoding a vector with RVQ is actually NP-hard. In this paper, we propose animproved residual vector quantization (IRVQ) method, our IRVQ learns codebookwith a hybrid method of subspace clustering and warm-started k-means on eachstage to prevent performance gain from dropping, and uses a multi-path encodingscheme to encode a vector with lower distortion. Experimental results on thebenchmark datasets show that our method gives substantially improves RVQ anddelivers better performance compared to the state-of-the-art.
arxiv-13500-180 | Fast Sequence Component Analysis for Attack Detection in Synchrophasor Networks | http://arxiv.org/pdf/1509.05086v1.pdf | author:Jordan Landford, Rich Meier, Richard Barella, Xinghui Zhao, Eduardo Cotilla-Sanchez, Robert B. Bass, Scott Wallace category:cs.LG cs.CR published:2015-09-17 summary:Modern power systems have begun integrating synchrophasor technologies intopart of daily operations. Given the amount of solutions offered and thematurity rate of application development it is not a matter of "if" but amatter of "when" in regards to these technologies becoming ubiquitous incontrol centers around the world. While the benefits are numerous, thefunctionality of operator-level applications can easily be nullified byinjection of deceptive data signals disguised as genuine measurements. Suchdeceptive action is a common precursor to nefarious, often malicious activity.A correlation coefficient characterization and machine learning methodology areproposed to detect and identify injection of spoofed data signals. The proposedmethod utilizes statistical relationships intrinsic to power system parameters,which are quantified and presented. Several spoofing schemes have beendeveloped to qualitatively and quantitatively demonstrate detectioncapabilities.
arxiv-13500-181 | HCLAE: High Capacity Locally Aggregating Encodings for Approximate Nearest Neighbor Search | http://arxiv.org/pdf/1509.05194v1.pdf | author:Shicong Liu, Junru Shao, Hongtao Lu category:cs.CV published:2015-09-17 summary:Vector quantization-based approaches are successful to solve ApproximateNearest Neighbor (ANN) problems which are critical to many applications. Theidea is to generate effective encodings to allow fast distance approximation.We propose quantization-based methods should partition the data space finelyand exhibit locality of the dataset to allow efficient non-exhaustive search.In this paper, we introduce the concept of High Capacity Locality AggregatingEncodings (HCLAE) to this end, and propose Dictionary Annealing (DA) to learnHCLAE by a simulated annealing procedure. The quantization error is lower thanother state-of-the-art. The algorithms of DA can be easily extended to anonline learning scheme, allowing effective handle of large scale data. Further,we propose Aggregating-Tree (A-Tree), a non-exhaustive search method usingHCLAE to perform efficient ANN-Search. A-Tree achieves magnitudes of speed-upon ANN-Search tasks, compared to the state-of-the-art.
arxiv-13500-182 | Accelerated Distance Computation with Encoding Tree for High Dimensional Data | http://arxiv.org/pdf/1509.05186v2.pdf | author:Shicong Liu, Junru Shao, Hongtao Lu category:cs.CV published:2015-09-17 summary:We propose a novel distance to calculate distance between high dimensionalvector pairs, utilizing vector quantization generated encodings. Vectorquantization based methods are successful in handling large scale highdimensional data. These methods compress vectors into short encodings, andallow efficient distance computation between an uncompressed vector andcompressed dataset without decompressing explicitly. However for largedatasets, these distance computing methods perform excessive computations. Weavoid excessive computations by storing the encodings on an EncodingTree(E-Tree), interestingly the memory consumption is also lowered. We alsopropose Encoding Forest(E-Forest) to further lower the computation cost. E-Treeand E-Forest is compatible with various existing quantization-based methods. Weshow by experiments our methods speed-up distance computing for highdimensional data drastically, and various existing algorithms can benefit fromour methods.
arxiv-13500-183 | Algorithmic statistics, prediction and machine learning | http://arxiv.org/pdf/1509.05473v1.pdf | author:Alexey Milovanov category:cs.LG cs.IT math.IT published:2015-09-17 summary:Algorithmic statistics considers the following problem: given a binary string$x$ (e.g., some experimental data), find a "good" explanation of this data. Ituses algorithmic information theory to define formally what is a goodexplanation. In this paper we extend this framework in two directions. First, the explanations are not only interesting in themselves but also usedfor prediction: we want to know what kind of data we may reasonably expect insimilar situations (repeating the same experiment). We show that some kind ofhierarchy can be constructed both in terms of algorithmic statistics and usingthe notion of a priori probability, and these two approaches turn out to beequivalent. Second, a more realistic approach that goes back to machine learning theory,assumes that we have not a single data string $x$ but some set of "positiveexamples" $x_1,\ldots,x_l$ that all belong to some unknown set $A$, a propertythat we want to learn. We want this set $A$ to contain all positive examplesand to be as small and simple as possible. We show how algorithmic statisticcan be extended to cover this situation.
arxiv-13500-184 | Taming the ReLU with Parallel Dither in a Deep Neural Network | http://arxiv.org/pdf/1509.05173v1.pdf | author:Andrew J. R. Simpson category:cs.LG 68Txx published:2015-09-17 summary:Rectified Linear Units (ReLU) seem to have displaced traditional 'smooth'nonlinearities as activation-function-du-jour in many - but not all - deepneural network (DNN) applications. However, nobody seems to know why. In thisarticle, we argue that ReLU are useful because they are ideal demodulators -this helps them perform fast abstract learning. However, this fast learningcomes at the expense of serious nonlinear distortion products - decoy features.We show that Parallel Dither acts to suppress the decoy features, preventingoverfitting and leaving the true features cleanly demodulated for rapid,reliable learning.
arxiv-13500-185 | Learning to Hash for Indexing Big Data - A Survey | http://arxiv.org/pdf/1509.05472v1.pdf | author:Jun Wang, Wei Liu, Sanjiv Kumar, Shih-Fu Chang category:cs.LG published:2015-09-17 summary:The explosive growth in big data has attracted much attention in designingefficient indexing and search methods recently. In many critical applicationssuch as large-scale search and pattern matching, finding the nearest neighborsto a query is a fundamental research problem. However, the straightforwardsolution using exhaustive comparison is infeasible due to the prohibitivecomputational complexity and memory requirement. In response, ApproximateNearest Neighbor (ANN) search based on hashing techniques has become populardue to its promising performance in both efficiency and accuracy. Priorrandomized hashing methods, e.g., Locality-Sensitive Hashing (LSH), exploredata-independent hash functions with random projections or permutations.Although having elegant theoretic guarantees on the search quality in certainmetric spaces, performance of randomized hashing has been shown insufficient inmany real-world applications. As a remedy, new approaches incorporatingdata-driven learning methods in development of advanced hash functions haveemerged. Such learning to hash methods exploit information such as datadistributions or class labels when optimizing the hash codes or functions.Importantly, the learned hash codes are able to preserve the proximity ofneighboring data in the original feature spaces in the hash code spaces. Thegoal of this paper is to provide readers with systematic understanding ofinsights, pros and cons of the emerging techniques. We provide a comprehensivesurvey of the learning to hash framework and representative techniques ofvarious types, including unsupervised, semi-supervised, and supervised. Inaddition, we also summarize recent hashing approaches utilizing the deeplearning models. Finally, we discuss the future direction and trends ofresearch in this area.
arxiv-13500-186 | Optimal Subsampling Approaches for Large Sample Linear Regression | http://arxiv.org/pdf/1509.05111v2.pdf | author:Rong Zhu, Ping Ma, Michael W. Mahoney, Bin Yu category:stat.ME stat.ML published:2015-09-17 summary:A significant hurdle for analyzing large sample data is the lack of effectivestatistical computing and inference methods. An emerging powerful approach foranalyzing large sample data is subsampling, by which one takes a randomsubsample from the original full sample and uses it as a surrogate forsubsequent computation and estimation. In this paper, we study subsamplingmethods under two scenarios: approximating the full sample ordinaryleast-square (OLS) estimator and estimating the coefficients in linearregression. We present two algorithms, weighted estimation algorithm andunweighted estimation algorithm, and analyze asymptotic behaviors of theirresulting subsample estimators under general conditions. For the weightedestimation algorithm, we propose a criterion for selecting the optimal samplingprobability by making use of the asymptotic results. On the basis of thecriterion, we provide two novel subsampling methods, the optimal subsamplingand the predictor- length subsampling methods. The predictor-length subsamplingmethod is based on the L2 norm of predictors rather than leverage scores. Itscomputational cost is scalable. For unweighted estimation algorithm, we showthat its resulting subsample estimator is not consistent to the full sample OLSestimator. However, it has better performance than the weighted estimationalgorithm for estimating the coefficients. Simulation studies and a real dataexample are used to demonstrate the effectiveness of our proposed subsamplingmethods.
arxiv-13500-187 | Geometry-aware Deep Transform | http://arxiv.org/pdf/1509.05360v2.pdf | author:Jiaji Huang, Qiang Qiu, Robert Calderbank, Guillermo Sapiro category:cs.CV published:2015-09-17 summary:Many recent efforts have been devoted to designing sophisticated deeplearning structures, obtaining revolutionary results on benchmark datasets. Thesuccess of these deep learning methods mostly relies on an enormous volume oflabeled training samples to learn a huge number of parameters in a network;therefore, understanding the generalization ability of a learned deep networkcannot be overlooked, especially when restricted to a small training set, whichis the case for many applications. In this paper, we propose a novel deeplearning objective formulation that unifies both the classification and metriclearning criteria. We then introduce a geometry-aware deep transform to enablea non-linear discriminative and robust feature transform, which showscompetitive performance on small training sets for both synthetic andreal-world data. We further support the proposed framework with a formal$(K,\epsilon)$-robustness analysis.
arxiv-13500-188 | Sparse Fisher's Linear Discriminant Analysis for Partially Labeled Data | http://arxiv.org/pdf/1509.05438v1.pdf | author:Qiyi Lu, Xingye Qiao category:stat.ML stat.ME published:2015-09-17 summary:Classification is an important tool with many useful applications. Among themany classification methods, Fisher's Linear Discriminant Analysis (LDA) is atraditional model-based approach which makes use of the covariance information.However, in the high-dimensional, low-sample size setting, LDA cannot bedirectly deployed because the sample covariance is not invertible. While thereare modern methods designed to deal with high-dimensional data, they may notfully use the covariance information as LDA does. Hence in some situations, itis still desirable to use a model-based method such as LDA for classification.This article exploits the potential of LDA in more complicated data settings.In many real applications, it is costly to manually place labels onobservations; hence it is often that only a small portion of labeled data isavailable while a large number of observations are left without a label. It isa great challenge to obtain good classification performance through the labeleddata alone, especially when the dimension is greater than the size of thelabeled data. In order to overcome this issue, we propose a semi-supervisedsparse LDA classifier to take advantage of the seemingly useless unlabeleddata. They provide additional information which helps to boost theclassification performance in some situations. A direct estimation method isused to reconstruct LDA and achieve the sparsity; meanwhile we employ thedifference-convex algorithm to handle the non-convex loss function associatedwith the unlabeled data. Theoretical properties of the proposed classifier arestudied. Our simulated examples help to understand when and how the informationextracted from the unlabeled data can be useful. A real data example furtherillustrates the usefulness of the proposed method.
arxiv-13500-189 | Some Theorems for Feed Forward Neural Networks | http://arxiv.org/pdf/1509.05177v4.pdf | author:K. Eswaran, Vishwajeet Singh category:cs.NE 62M45 published:2015-09-17 summary:In this paper we introduce a new method which employs the concept of"Orientation Vectors" to train a feed forward neural network and suitable forproblems where large dimensions are involved and the clusters arecharacteristically sparse. The new method is not NP hard as the problem sizeincreases. We `derive' the method by starting from Kolmogrov's method and thenrelax some of the stringent conditions. We show for most classificationproblems three layers are sufficient and the network size depends on the numberof clusters. We prove as the number of clusters increase from N to N+dN thenumber of processing elements in the first layer only increases by d(logN), andare proportional to the number of classes, and the method is not NP hard. Many examples are solved to demonstrate that the method of OrientationVectors requires much less computational effort than Radial Basis Functionmethods and other techniques wherein distance computations are required, infact the present method increases logarithmically with problem size compared tothe Radial Basis Function method and the other methods which depend on distancecomputations e.g statistical methods where probabilistic distances arecalculated. A practical method of applying the concept of Occum's razor tochoose between two architectures which solve the same classification problemhas been described. The ramifications of the above findings on the field ofDeep Learning have also been briefly investigated and we have found that itdirectly leads to the existence of certain types of NN architectures which canbe used as a "mapping engine", which has the property of "invertibility", thusimproving the prospect of their deployment for solving problems involving DeepLearning and hierarchical classification. The latter possibility has a lot offuture scope in the areas of machine learning and cloud computing.
arxiv-13500-190 | DeXpression: Deep Convolutional Neural Network for Expression Recognition | http://arxiv.org/pdf/1509.05371v1.pdf | author:Peter Burkert, Felix Trier, Muhammad Zeshan Afzal, Andreas Dengel, Marcus Liwicki category:cs.CV cs.LG published:2015-09-17 summary:We propose a convolutional neural network (CNN) architecture for facialexpression recognition. The proposed architecture is independent of anyhand-crafted feature extraction and performs better than the earlier proposedconvolutional neural network based approaches. We visualize the automaticallyextracted features which have been learned by the network in order to provide abetter understanding. The standard datasets, i.e. Extended Cohn-Kanade (CKP)and MMI Facial Expression Databse are used for the quantitative evaluation. Onthe CKP set the current state of the art approach, using CNNs, achieves anaccuracy of 99.2%. For the MMI dataset, currently the best accuracy for emotionrecognition is 93.33%. The proposed architecture achieves 99.6% for CKP and98.63% for MMI, therefore performing better than the state of the art usingCNNs. Automatic facial expression recognition has a broad spectrum ofapplications such as human-computer interaction and safety systems. This is dueto the fact that non-verbal cues are important forms of communication and playa pivotal role in interpersonal communication. The performance of the proposedarchitecture endorses the efficacy and reliable usage of the proposed work forreal world applications.
arxiv-13500-191 | On the Expressive Power of Deep Learning: A Tensor Analysis | http://arxiv.org/pdf/1509.05009v2.pdf | author:Nadav Cohen, Or Sharir, Amnon Shashua category:cs.NE cs.LG cs.NA stat.ML published:2015-09-16 summary:It has long been conjectured that hypotheses spaces suitable for data that iscompositional in nature, such as text or images, may be more efficientlyrepresented with deep hierarchical networks than with shallow ones. Despite thevast empirical evidence supporting this belief, theoretical justifications todate are limited. In particular, they do not account for the locality, sharingand pooling constructs of convolutional networks, the most successful deeplearning architecture to date. In this work we derive a deep networkarchitecture based on arithmetic circuits that inherently employs locality,sharing and pooling. An equivalence between the networks and hierarchicaltensor factorizations is established. We show that a shallow networkcorresponds to CP (rank-1) decomposition, whereas a deep network corresponds toHierarchical Tucker decomposition. Using tools from measure theory and matrix algebra, we prove that besides anegligible set, all functions that can be implemented by a deep network ofpolynomial size, require exponential size in order to be realized (or evenapproximated) by a shallow network. Since log-space computation transforms ournetworks into SimNets, the result applies directly to a deep learningarchitecture demonstrating promising empirical performance. The constructionand theory developed in this paper shed new light on various practices andideas employed by the deep learning community.
arxiv-13500-192 | Exact simultaneous recovery of locations and structure from known orientations and corrupted point correspondences | http://arxiv.org/pdf/1509.05064v1.pdf | author:Paul Hand, Choongbum Lee, Vladislav Voroninski category:cs.CV cs.IT math.CO math.IT math.OC published:2015-09-16 summary:Let $t_1,\ldots,t_{n_l} \in \mathbb{R}^d$ and $p_1,\ldots,p_{n_s} \in\mathbb{R}^d$ and consider the bipartite location recovery problem: given asubset of pairwise direction observations $\{(t_i - p_j) / \t_i -p_j\_2\}_{i,j \in [n_l] \times [n_s]}$, where a constant fraction of theseobservations are arbitrarily corrupted, find $\{t_i\}_{i \in [n_ll]}$ and$\{p_j\}_{j \in [n_s]}$ up to a global translation and scale. We study therecently introduced ShapeFit algorithm as a method for solving this bipartitelocation recovery problem. In this case, ShapeFit consists of a simple convexprogram over $d(n_l + n_s)$ real variables. We prove that this program recoversa set of $n_l+n_s$ i.i.d. Gaussian locations exactly and with high probabilityif the observations are given by a bipartite Erd\H{o}s-R\'{e}nyi graph, $d$ islarge enough, and provided that at most a constant fraction of observationsinvolving any particular location are adversarially corrupted. This recoverytheorem is based on a set of deterministic conditions that we prove aresufficient for exact recovery. Finally, we propose a modified pipeline for theStructure for Motion problem, based on this bipartite location recoveryproblem.
arxiv-13500-193 | amLite: Amharic Transliteration Using Key Map Dictionary | http://arxiv.org/pdf/1509.04811v1.pdf | author:Tadele Tedla category:cs.CL cs.IR published:2015-09-16 summary:amLite is a framework developed to map ASCII transliterated Amharic textsback to the original Amharic letter texts. The aim of such a framework is tomake existing Amharic linguistic data consistent and interoperable amongresearchers. For achieving the objective, a key map dictionary is constructedusing the possible ASCII combinations actively in use for transliteratingAmharic letters; and a mapping of the combinations to the corresponding Amharicletters is done. The mapping is then used to replace the Amharic linguistictext back to form the original Amharic letters text. The framework indicated97.7, 99.7 and 98.4 percentage accuracy on converting the three sample randomtest data. It is; however, possible to improve the accuracy of the framework byadding an exception to the implementation of the algorithm, or by preprocessingthe input text prior to conversion. This paper outlined the rationales behindthe need for developing the framework and the processes undertaken in thedevelopment.
arxiv-13500-194 | An On-board Video Database of Human Drivers | http://arxiv.org/pdf/1509.04853v1.pdf | author:Anirban Dasgupta, Anjith George, SL Happy, Aurobinda Routray category:cs.CV published:2015-09-16 summary:Detection of fatigue due to drowsiness or loss of attention in human driversis an evolving area of research. Several algorithms have been implemented todetect the level of fatigue in human drivers by capturing videos of facialimage sequences and extracting facial features such as eye closure rates, eyegaze, head nodding, blink frequency etc. However, availability of standardvideo database to validate such algorithms is insufficient. This paperdiscusses the creation of such a database created under on-board conditionsduring the day as well as night. Passive Near Infra-red (NIR) illumination hasbeen used for illuminating the face during night driving since prolongedexposure to active Infra-Red lighting may lead to many health issues. Thedatabase contains videos of 30 subjects under actual driving conditions.Variation is ensured as the database contains different head orientations andwith different facial expressions, facial occlusions and illuminationvariation. This new database can be a very valuable resource for developmentand evaluation of algorithms for the video based detection of driver fatigue.
arxiv-13500-195 | Overcomplete Dictionary Learning with Jacobi Atom Updates | http://arxiv.org/pdf/1509.05054v1.pdf | author:Paul Irofti, Bogdan Dumitrescu category:cs.CV published:2015-09-16 summary:Dictionary learning for sparse representations is traditionally approachedwith sequential atom updates, in which an optimized atom is used immediatelyfor the optimization of the next atoms. We propose instead a Jacobi version, inwhich groups of atoms are updated independently, in parallel. Extensivenumerical evidence for sparse image representation shows that the parallelalgorithms, especially when all atoms are updated simultaneously, give betterdictionaries than their sequential counterparts.
arxiv-13500-196 | DenseBox: Unifying Landmark Localization with End to End Object Detection | http://arxiv.org/pdf/1509.04874v3.pdf | author:Lichao Huang, Yi Yang, Yafeng Deng, Yinan Yu category:cs.CV published:2015-09-16 summary:How can a single fully convolutional neural network (FCN) perform on objectdetection? We introduce DenseBox, a unified end-to-end FCN framework thatdirectly predicts bounding boxes and object class confidences through alllocations and scales of an image. Our contribution is two-fold. First, we showthat a single FCN, if designed and optimized carefully, can detect multipledifferent objects extremely accurately and efficiently. Second, we show thatwhen incorporating with landmark localization during multi-task learning,DenseBox further improves object detection accuray. We present experimentalresults on public benchmark datasets including MALF face detection and KITTIcar detection, that indicate our DenseBox is the state-of-the-art system fordetecting challenging objects such as faces and cars.
arxiv-13500-197 | Fast Template Matching by Subsampled Circulant Matrix | http://arxiv.org/pdf/1509.04863v1.pdf | author:Sung-Hsien Hsieh, Chun-Shien Lu, and Soo-Chang Pei category:cs.DS cs.CV published:2015-09-16 summary:Template matching is widely used for many applications in image and signalprocessing and usually is time-critical. Traditional methods usually focus onhow to reduce the search locations by coarse-to-fine strategy or full searchcombined with pruning strategy. However, the computation cost of those methodsis easily dominated by the size of signal N instead of that of template K. Thispaper proposes a probabilistic and fast matching scheme, which computationcosts requires O(N) additions and O(K \log K) multiplications, based oncross-correlation. The nuclear idea is to first downsample signal, which sizebecomes O(K), and then subsequent operations only involves downsampled signals.The probability of successful match depends on cross-correlation between signaland the template. We show the sufficient condition for successful match andprove that the probability is high for binary signals with K^2/log K >= O(N).The experiments shows this proposed scheme is fast and efficient and supportsthe theoretical results.
arxiv-13500-198 | Recurrent Neural Networks for Driver Activity Anticipation via Sensory-Fusion Architecture | http://arxiv.org/pdf/1509.05016v1.pdf | author:Ashesh Jain, Avi Singh, Hema S Koppula, Shane Soh, Ashutosh Saxena category:cs.CV cs.AI cs.RO published:2015-09-16 summary:Anticipating the future actions of a human is a widely studied problem inrobotics that requires spatio-temporal reasoning. In this work we propose adeep learning approach for anticipation in sensory-rich robotics applications.We introduce a sensory-fusion architecture which jointly learns to anticipateand fuse information from multiple sensory streams. Our architecture consistsof Recurrent Neural Networks (RNNs) that use Long Short-Term Memory (LSTM)units to capture long temporal dependencies. We train our architecture in asequence-to-sequence prediction manner, and it explicitly learns to predict thefuture given only a partial temporal context. We further introduce a novel losslayer for anticipation which prevents over-fitting and encourages earlyanticipation. We use our architecture to anticipate driving maneuvers severalseconds before they happen on a natural driving data set of 1180 miles. Thecontext for maneuver anticipation comes from multiple sensors installed on thevehicle. Our approach shows significant improvement over the state-of-the-artin maneuver anticipation by increasing the precision from 77.4% to 90.5% andrecall from 71.2% to 87.4%.
arxiv-13500-199 | Human and Sheep Facial Landmarks Localisation by Triplet Interpolated Features | http://arxiv.org/pdf/1509.04954v1.pdf | author:Heng Yang, Renqiao Zhang, Peter Robinson category:cs.CV published:2015-09-16 summary:In this paper we present a method for localisation of facial landmarks onhuman and sheep. We introduce a new feature extraction scheme calledtriplet-interpolated feature used at each iteration of the cascaded shaperegression framework. It is able to extract features from similar semanticlocation given an estimated shape, even when head pose variations are large andthe facial landmarks are very sparsely distributed. Furthermore, we study theimpact of training data imbalance on model performance and propose a trainingsample augmentation scheme that produces more initialisations for trainingsamples from the minority. More specifically, the augmentation number for atraining sample is made to be negatively correlated to the value of the fittedprobability density function at the sample's position. We evaluate the proposedscheme on both human and sheep facial landmarks localisation. On the benchmark300w human face dataset, we demonstrate the benefits of our proposed methodsand show very competitive performance when comparing to other methods. On anewly created sheep face dataset, we get very good performance despite the factthat we only have a limited number of training samples and a set of sparselandmarks are annotated.
arxiv-13500-200 | A Drowsiness Detection Scheme Based on Fusion of Voice and Vision Cues | http://arxiv.org/pdf/1509.04887v1.pdf | author:Anirban Dasgupta, Bibek Kabi, Anjith George, SL Happy, Aurobinda Routray category:cs.CV published:2015-09-16 summary:Drowsiness level detection of an individual is very important in many safetycritical applications such as driving. There are several invasive and contactbased methods such as use of blood biochemical, brain signals etc. which canestimate the level of drowsiness very accurately. However, these methods arevery difficult to implement in practical scenarios, as they cause discomfort tothe user. This paper presents a combined voice and vision based drowsinessdetection system well suited to detect the drowsiness level of an automotivedriver. The vision and voice based detection, being non-contact methods, hasthe advantage of their feasibility of implementation. The authenticity of thesemethods have been cross-validated using brain signals.
arxiv-13500-201 | Group Membership Prediction | http://arxiv.org/pdf/1509.04783v1.pdf | author:Ziming Zhang, Yuting Chen, Venkatesh Saligrama category:cs.CV stat.ML published:2015-09-16 summary:The group membership prediction (GMP) problem involves predicting whether ornot a collection of instances share a certain semantic property. For instance,in kinship verification given a collection of images, the goal is to predictwhether or not they share a {\it familial} relationship. In this context wepropose a novel probability model and introduce latent {\em view-specific} and{\em view-shared} random variables to jointly account for the view-specificappearance and cross-view similarities among data instances. Our model positsthat data from each view is independent conditioned on the shared variables.This postulate leads to a parametric probability model that decomposes groupmembership likelihood into a tensor product of data-independent parameters anddata-dependent factors. We propose learning the data-independent parameters ina discriminative way with bilinear classifiers, and test our predictionalgorithm on challenging visual recognition tasks such as multi-camera personre-identification and kinship verification. On most benchmark datasets, ourmethod can significantly outperform the current state-of-the-art.
arxiv-13500-202 | Projection Bank: From High-dimensional Data to Medium-length Binary Codes | http://arxiv.org/pdf/1509.04916v1.pdf | author:Li Liu, Mengyang Yu, Ling Shao category:cs.CV published:2015-09-16 summary:Recently, very high-dimensional feature representations, e.g., Fisher Vector,have achieved excellent performance for visual recognition and retrieval.However, these lengthy representations always cause extremely heavycomputational and storage costs and even become unfeasible in some large-scaleapplications. A few existing techniques can transfer very high-dimensional datainto binary codes, but they still require the reduced code length to berelatively long to maintain acceptable accuracies. To target a better balancebetween computational efficiency and accuracies, in this paper, we propose anovel embedding method called Binary Projection Bank (BPB), which caneffectively reduce the very high-dimensional representations tomedium-dimensional binary codes without sacrificing accuracies. Instead ofusing conventional single linear or bilinear projections, the proposed methodlearns a bank of small projections via the max-margin constraint to optimallypreserve the intrinsic data similarity. We have systematically evaluated theproposed method on three datasets: Flickr 1M, ILSVR2010 and UCF101, showingcompetitive retrieval and recognition accuracies compared with state-of-the-artapproaches, but with a significantly smaller memory footprint and lower codingcomplexity.
arxiv-13500-203 | Guiding Long-Short Term Memory for Image Caption Generation | http://arxiv.org/pdf/1509.04942v1.pdf | author:Xu Jia, Efstratios Gavves, Basura Fernando, Tinne Tuytelaars category:cs.CV published:2015-09-16 summary:In this work we focus on the problem of image caption generation. We proposean extension of the long short term memory (LSTM) model, which we coin gLSTMfor short. In particular, we add semantic information extracted from the imageas extra input to each unit of the LSTM block, with the aim of guiding themodel towards solutions that are more tightly coupled to the image content.Additionally, we explore different length normalization strategies for beamsearch in order to prevent from favoring short sentences. On various benchmarkdatasets such as Flickr8K, Flickr30K and MS COCO, we obtain results that are onpar with or even outperform the current state-of-the-art.
arxiv-13500-204 | Dirichlet Fragmentation Processes | http://arxiv.org/pdf/1509.04781v1.pdf | author:Hong Ge, Yarin Gal, Zoubin Ghahramani category:stat.ML published:2015-09-16 summary:Tree structures are ubiquitous in data across many domains, and many datasetsare naturally modelled by unobserved tree structures. In this paper, first wereview the theory of random fragmentation processes [Bertoin, 2006], and anumber of existing methods for modelling trees, including the popular nestedChinese restaurant process (nCRP). Then we define a general class ofprobability distributions over trees: the Dirichlet fragmentation process (DFP)through a novel combination of the theory of Dirichlet processes and randomfragmentation processes. This DFP presents a stick-breaking construction, andrelates to the nCRP in the same way the Dirichlet process relates to theChinese restaurant process. Furthermore, we develop a novel hierarchicalmixture model with the DFP, and empirically compare the new model to similarmodels in machine learning. Experiments show the DFP mixture model to beconvincingly better than existing state-of-the-art approaches for hierarchicalclustering and density modelling.
arxiv-13500-205 | Sparse Multinomial Logistic Regression via Approximate Message Passing | http://arxiv.org/pdf/1509.04491v1.pdf | author:Evan Byrne, Philip Schniter category:cs.IT math.IT stat.ML published:2015-09-15 summary:For the problem of multi-class linear classification and feature selection,we propose approximate message passing approaches to sparse multinomiallogistic regression. First, we propose two algorithms based on the HybridGeneralized Approximate Message Passing (HyGAMP) framework: one finds themaximum a posteriori (MAP) linear classifier and the other finds anapproximation of the test-error-rate minimizing linear classifier. Then wedesign computationally simplified variants of these two algorithms. Next, wedetail methods to tune the hyperparameters of their assumed statistical modelsusing Stein's unbiased risk estimate (SURE) and expectation-maximization (EM),respectively. Finally, using both synthetic and real-world datasets, wedemonstrate improved error-rate and runtime performance relative tostate-of-the-art existing approaches.
arxiv-13500-206 | Splitting Compounds by Semantic Analogy | http://arxiv.org/pdf/1509.04473v1.pdf | author:Joachim Daiber, Lautaro Quiroz, Roger Wechsler, Stella Frank category:cs.CL published:2015-09-15 summary:Compounding is a highly productive word-formation process in some languagesthat is often problematic for natural language processing applications. In thispaper, we investigate whether distributional semantics in the form of wordembeddings can enable a deeper, i.e., more knowledge-rich, processing ofcompounds than the standard string-based methods. We present an unsupervisedapproach that exploits regularities in the semantic vector space (based onanalogies such as "bookshop is to shop as bookshelf is to shelf") to producecompound analyses of high quality. A subsequent compound splitting algorithmbased on these analyses is highly effective, particularly for ambiguouscompounds. German to English machine translation experiments show that thissemantic analogy-based compound splitter leads to better translations than acommonly used frequency-based method.
arxiv-13500-207 | Regular expressions for decoding of neural network outputs | http://arxiv.org/pdf/1509.04438v2.pdf | author:Tobias Strauß, Gundram Leifert, Tobias Grüning, Roger Labahn category:cs.NE published:2015-09-15 summary:This article proposes a convenient tool for decoding the output of neuralnetworks trained by Connectionist Temporal Classification (CTC) for handwrittentext recognition. We use regular expressions to describe the complex structuresexpected in the writing. The corresponding finite automata are employed tobuild a decoder. We analyze theoretically which calculations are relevant andwhich can be avoided. A great speed-up results from an approximation. Weconclude that the approximation most likely fails if the regular expressiondoes not match the ground truth which is not harmful for many applicationssince the low probability will be even underestimated. The proposed decoder isvery efficient compared to other decoding methods. The variety of applicationsreaches from information retrieval to full text recognition. We refer toapplications where we integrated the proposed decoder successfully.
arxiv-13500-208 | Kernelized Deep Convolutional Neural Network for Describing Complex Images | http://arxiv.org/pdf/1509.04581v1.pdf | author:Zhen Liu category:cs.CV cs.AI cs.IR cs.MM published:2015-09-15 summary:With the impressive capability to capture visual content, deep convolutionalneural networks (CNN) have demon- strated promising performance in variousvision-based ap- plications, such as classification, recognition, and objec- tdetection. However, due to the intrinsic structure design of CNN, for imageswith complex content, it achieves lim- ited capability on invariance totranslation, rotation, and re-sizing changes, which is strongly emphasized inthe s- cenario of content-based image retrieval. In this paper, to address thisproblem, we proposed a new kernelized deep convolutional neural network. Wefirst discuss our motiva- tion by an experimental study to demonstrate thesensitivi- ty of the global CNN feature to the basic geometric trans-formations. Then, we propose to represent visual content with approximateinvariance to the above geometric trans- formations from a kernelizedperspective. We extract CNN features on the detected object-like patches andaggregate these patch-level CNN features to form a vectorial repre- sentationwith the Fisher vector model. The effectiveness of our proposed algorithm isdemonstrated on image search application with three benchmark datasets.
arxiv-13500-209 | A Low Complexity VLSI Architecture for Multi-Focus Image Fusion in DCT Domain | http://arxiv.org/pdf/1602.07620v1.pdf | author:Ashutosh Mishra, Sudipta Mahapatra, Swapna Banerjee category:cs.CV published:2015-09-15 summary:Due to the confined focal length of optical sensors, focusing all objects ina scene with a single sensor is a difficult task. To handle such a situation,image fusion methods are used in multi-focus environment. Discrete CosineTransform (DCT) is a widely used image compression transform, image fusion inDCT domain is an efficient method. This paper presents a low complexityapproach for multi-focus image fusion and its VLSI implementation using DCT.The proposed method is evaluated using reference/non-reference fusion measurecriteria and the obtained results asserts it's effectiveness. The maximumsynthesized frequency on FPGA is found to be 221 MHz and consumes 42% of FPGAresources. The proposed method consumes very less power and can process 4Kresolution images at the rate of 60 frames per second which makes the hardwaresuitable for handheld portable devices such as camera module and wireless imagesensors.
arxiv-13500-210 | Neuron detection in stack images: a persistent homology interpretation | http://arxiv.org/pdf/1509.04420v1.pdf | author:Jónathan Heras, Gadea Mata, Germán Cuesto, Julio Rubio, Miguel Morales category:cs.CV q-bio.NC published:2015-09-15 summary:Automation and reliability are the two main requirements when computers areapplied in Life Sciences. In this paper we report on an application to neuronrecognition, an important step in our long-term project of providing softwaresystems to the study of neural morphology and functionality from biomedicalimages. Our algorithms have been implemented in an ImageJ plugin calledNeuronPersistentJ, which has been validated experimentally. The soundness andreliability of our approach are based on the interpretation of our processingmethods with respect to persistent homology, a well-known tool in computationalmathematics.
arxiv-13500-211 | When are Kalman-filter restless bandits indexable? | http://arxiv.org/pdf/1509.04541v1.pdf | author:Christopher R. Dance, Tomi Silander category:stat.ML published:2015-09-15 summary:We study the restless bandit associated with an extremely simple scalarKalman filter model in discrete time. Under certain assumptions, we prove thatthe problem is indexable in the sense that the Whittle index is anon-decreasing function of the relevant belief state. In spite of the longhistory of this problem, this appears to be the first such proof. We useresults about Schur-convexity and mechanical words, which are particular binarystrings intimately related to palindromes.
arxiv-13500-212 | Modeling and interpolation of the ambient magnetic field by Gaussian processes | http://arxiv.org/pdf/1509.04634v1.pdf | author:Arno Solin, Manon Kok, Niklas Wahlström, Thomas B. Schön, Simo Särkkä category:cs.RO stat.ML published:2015-09-15 summary:Anomalies in the ambient magnetic field can be used as features in indoorpositioning and navigation. By using Maxwell's equations, we derive and presenta Bayesian non-parametric probabilistic modeling approach for interpolation andextrapolation of the magnetic field. We model the magnetic field componentsjointly by imposing a Gaussian process (GP) prior on the latent scalarpotential of the magnetic field. By rewriting the GP model in terms of aHilbert space representation, we circumvent the computational pitfallsassociated with GP modeling and provide a computationally efficient andphysically justified modeling tool for the ambient magnetic field. The modelallows for sequential updating of the estimate and time-dependent changes inthe magnetic field. The model is shown to work well in practice in differentapplications: we demonstrate mapping of the magnetic field both with aninexpensive Raspberry Pi powered robot and on foot using a standard smartphone.
arxiv-13500-213 | The Shape of Data and Probability Measures | http://arxiv.org/pdf/1509.04632v1.pdf | author:Diego Hernán Díaz Martínez, Facundo Mémoli, Washington Mio category:stat.ML math.MG math.ST stat.TH published:2015-09-15 summary:We introduce the notion of multiscale covariance tensor fields (CTF)associated with Euclidean random variables as a gateway to the shape of theirdistributions. Multiscale CTFs quantify variation of the data about every pointin the data landscape at all spatial scales, unlike the usual covariance tensorthat only quantifies global variation about the mean. Empirical forms oflocalized covariance previously have been used in data analysis andvisualization, but we develop a framework for the systematic treatment oftheoretical questions and computational models based on localized covariance.We prove strong stability theorems with respect to the Wasserstein distancebetween probability measures, obtain consistency results, as well as estimatesfor the rate of convergence of empirical CTFs. These results ensure that CTFsare robust to sampling, noise and outliers. We provide numerous illustrationsof how CTFs let us extract shape from data and also apply CTFs to manifoldclustering, the problem of categorizing data points according to their noisymembership in a collection of possibly intersecting, smooth submanifolds ofEuclidean space. We prove that the proposed manifold clustering method isstable and carry out several experiments to validate the method.
arxiv-13500-214 | Analyzing structural characteristics of object category representations from their semantic-part distributions | http://arxiv.org/pdf/1509.04399v1.pdf | author:Ravi Kiran Sarvadevabhatla, Venkatesh Babu R category:cs.CV published:2015-09-15 summary:Studies from neuroscience show that part-mapping computations are employed byhuman visual system in the process of object recognition. In this work, wepresent an approach for analyzing semantic-part characteristics of objectcategory representations. For our experiments, we use category-epitome, arecently proposed sketch-based spatial representation for objects. To enablepart-importance analysis, we first obtain semantic-part annotations ofhand-drawn sketches originally used to construct the corresponding epitomes. Wethen examine the extent to which the semantic-parts are present in the epitomesof a category and visualize the relative importance of parts as a word cloud.Finally, we show how such word cloud visualizations provide an intuitiveunderstanding of category-level structural trends that exist in thecategory-epitome object representations.
arxiv-13500-215 | Dynamic Poisson Factorization | http://arxiv.org/pdf/1509.04640v1.pdf | author:Laurent Charlin, Rajesh Ranganath, James McInerney, David M. Blei category:cs.LG cs.IR stat.ML published:2015-09-15 summary:Models for recommender systems use latent factors to explain the preferencesand behaviors of users with respect to a set of items (e.g., movies, books,academic papers). Typically, the latent factors are assumed to be static and,given these factors, the observed preferences and behaviors of users areassumed to be generated without order. These assumptions limit the explorativeand predictive capabilities of such models, since users' interests and itempopularity may evolve over time. To address this, we propose dPF, a dynamicmatrix factorization model based on the recent Poisson factorization model forrecommendations. dPF models the time evolving latent factors with a Kalmanfilter and the actions with Poisson distributions. We derive a scalablevariational inference algorithm to infer the latent factors. Finally, wedemonstrate dPF on 10 years of user click data from arXiv.org, one of thelargest repository of scientific papers and a formidable source of informationabout the behavior of scientists. Empirically we show performance improvementover both static and, more recently proposed, dynamic recommendation models. Wealso provide a thorough exploration of the inferred posteriors over the latentvariables.
arxiv-13500-216 | Exponential Family Matrix Completion under Structural Constraints | http://arxiv.org/pdf/1509.04397v1.pdf | author:Suriya Gunasekar, Pradeep Ravikumar, Joydeep Ghosh category:stat.ML cs.LG published:2015-09-15 summary:We consider the matrix completion problem of recovering a structured matrixfrom noisy and partial measurements. Recent works have proposed tractableestimators with strong statistical guarantees for the case where the underlyingmatrix is low--rank, and the measurements consist of a subset, either of theexact individual entries, or of the entries perturbed by additive Gaussiannoise, which is thus implicitly suited for thin--tailed continuous data.Arguably, common applications of matrix completion require estimators for (a)heterogeneous data--types, such as skewed--continuous, count, binary, etc., (b)for heterogeneous noise models (beyond Gaussian), which capture varieduncertainty in the measurements, and (c) heterogeneous structural constraintsbeyond low--rank, such as block--sparsity, or a superposition structure oflow--rank plus elementwise sparseness, among others. In this paper, we providea vastly unified framework for generalized matrix completion by considering amatrix completion setting wherein the matrix entries are sampled from anymember of the rich family of exponential family distributions; and imposegeneral structural constraints on the underlying matrix, as captured by ageneral regularizer $\mathcal{R}(.)$. We propose a simple convex regularized$M$--estimator for the generalized framework, and provide a unified and novelstatistical analysis for this general class of estimators. We finallycorroborate our theoretical results on simulated datasets.
arxiv-13500-217 | Macau: Scalable Bayesian Multi-relational Factorization with Side Information using MCMC | http://arxiv.org/pdf/1509.04610v2.pdf | author:Jaak Simm, Adam Arany, Pooya Zakeri, Tom Haber, Jörg K. Wegner, Vladimir Chupakhin, Hugo Ceulemans, Yves Moreau category:stat.ML published:2015-09-15 summary:We propose Macau, a powerful and flexible Bayesian factorization method forheterogeneous data. Our model can factorize any set of entities and relationsthat can be represented by a relational model, including tensors and alsomultiple relations for each entity. Macau can also incorporate sideinformation, specifically entity and relation features, which are crucial forpredicting sparsely observed relations. Macau scales to millions of entityinstances, hundred millions of observations, and sparse entity features withmillions of dimensions. To achieve the scale up, we specially designed samplingprocedure for entity and relation features that relies primarily on noiseinjection in linear regressions. We show performance and advanced features ofMacau in a set of experiments, including challenging drug-protein activityprediction task.
arxiv-13500-218 | Dependency length minimization: Puzzles and Promises | http://arxiv.org/pdf/1509.04393v1.pdf | author:Haitao Liu, Chunshan Xu, Junying Liang category:cs.CL published:2015-09-15 summary:In the recent issue of PNAS, Futrell et al. claims that their study of 37languages gives the first large scale cross-language evidence for DependencyLength Minimization, which is an overstatement that ignores similar previousresearches. In addition,this study seems to pay no attention to factors likethe uniformity of genres,which weakens the validity of the argument that DLM isuniversal. Another problem is that this study sets the baseline random languageas projective, which fails to truly uncover the difference between naturallanguage and random language, since projectivity is an important feature ofmany natural languages. Finally, the paper contends an "apparent relationshipbetween head finality and dependency length" despite the lack of an explicitstatistical comparison, which renders this conclusion rather hasty andimproper.
arxiv-13500-219 | Comparative Design Space Exploration of Dense and Semi-Dense SLAM | http://arxiv.org/pdf/1509.04648v3.pdf | author:M. Zeeshan Zia, Luigi Nardi, Andrew Jack, Emanuele Vespa, Bruno Bodin, Paul H. J. Kelly, Andrew J. Davison category:cs.RO cs.CV published:2015-09-15 summary:SLAM has matured significantly over the past few years, and is beginning toappear in serious commercial products. While new SLAM systems are beingproposed at every conference, evaluation is often restricted to qualitativevisualizations or accuracy estimation against a ground truth. This is due tothe lack of benchmarking methodologies which can holistically andquantitatively evaluate these systems. Further investigation at the level ofindividual kernels and parameter spaces of SLAM pipelines is non-existent,which is absolutely essential for systems research and integration. We extendthe recently introduced SLAMBench framework to allow comparing twostate-of-the-art SLAM pipelines, namely KinectFusion and LSD-SLAM, along themetrics of accuracy, energy consumption, and processing frame rate on twodifferent hardware platforms, namely a desktop and an embedded device. We alsoanalyze the pipelines at the level of individual kernels and explore theiralgorithmic and hardware design spaces for the first time, yielding valuableinsights.
arxiv-13500-220 | Precise Phase Transition of Total Variation Minimization | http://arxiv.org/pdf/1509.04376v1.pdf | author:Bingwen Zhang, Weiyu Xu, Jian-Feng Cai, Lifeng Lai category:cs.IT cs.LG math.IT math.OC stat.ML published:2015-09-15 summary:Characterizing the phase transitions of convex optimizations in recoveringstructured signals or data is of central importance in compressed sensing,machine learning and statistics. The phase transitions of many convexoptimization signal recovery methods such as $\ell_1$ minimization and nuclearnorm minimization are well understood through recent years' research. However,rigorously characterizing the phase transition of total variation (TV)minimization in recovering sparse-gradient signal is still open. In this paper,we fully characterize the phase transition curve of the TV minimization. Ourproof builds on Donoho, Johnstone and Montanari's conjectured phase transitioncurve for the TV approximate message passing algorithm (AMP), together with thelinkage between the minmax Mean Square Error of a denoising problem and thehigh-dimensional convex geometry for TV minimization.
arxiv-13500-221 | Forecasting Method for Grouped Time Series with the Use of k-Means Algorithm | http://arxiv.org/pdf/1509.04705v1.pdf | author:N. N. Astakhova, L. A. Demidova, E. V. Nikulchev category:cs.LG published:2015-09-15 summary:The paper is focused on the forecasting method for time series groups withthe use of algorithms for cluster analysis. $K$-means algorithm is suggested tobe a basic one for clustering. The coordinates of the centers of clusters havebeen put in correspondence with summarizing time series data the centroids ofthe clusters. A description of time series, the centroids of the clusters, isimplemented with the use of forecasting models. They are based on strict binarytrees and a modified clonal selection algorithm. With the help of suchforecasting models, the possibility of forming analytic dependences is shown.It is suggested to use a common forecasting model, which is constructed fortime series the centroid of the cluster, in forecasting the private(individual) time series in the cluster. The promising application of thesuggested method for grouped time series forecasting is demonstrated.
arxiv-13500-222 | Maximum Correntropy Kalman Filter | http://arxiv.org/pdf/1509.04580v1.pdf | author:Badong Chen, Xi Liu, Haiquan Zhao, José C. Príncipe category:stat.ML cs.SY published:2015-09-15 summary:Traditional Kalman filter (KF) is derived under the well-known minimum meansquare error (MMSE) criterion, which is optimal under Gaussian assumption.However, when the signals are non-Gaussian, especially when the system isdisturbed by some heavy-tailed impulsive noises, the performance of KF willdeteriorate seriously. To improve the robustness of KF against impulsivenoises, we propose in this work a new Kalman filter, called the maximumcorrentropy Kalman filter (MCKF), which adopts the robust maximum correntropycriterion (MCC) as the optimality criterion, instead of using the MMSE. Similarto the traditional KF, the state mean and covariance matrix propagationequations are used to give prior estimations of the state and covariance matrixin MCKF. A novel fixed-point algorithm is then used to update the posteriorestimations. A sufficient condition that guarantees the convergence of thefixed-point algorithm is given. Illustration examples are presented todemonstrate the effectiveness and robustness of the new algorithm.
arxiv-13500-223 | Medical Image Classification via SVM using LBP Features from Saliency-Based Folded Data | http://arxiv.org/pdf/1509.04619v1.pdf | author:Zehra Camlica, H. R. Tizhoosh, Farzad Khalvati category:cs.CV published:2015-09-15 summary:Good results on image classification and retrieval using support vectormachines (SVM) with local binary patterns (LBPs) as features have beenextensively reported in the literature where an entire image is retrieved orclassified. In contrast, in medical imaging, not all parts of the image may beequally significant or relevant to the image retrieval application at hand. Forinstance, in lung x-ray image, the lung region may contain a tumour, hencebeing highly significant whereas the surrounding area does not containsignificant information from medical diagnosis perspective. In this paper, wepropose to detect salient regions of images during training and fold the datato reduce the effect of irrelevant regions. As a result, smaller image areaswill be used for LBP features calculation and consequently classification bySVM. We use IRMA 2009 dataset with 14,410 x-ray images to verify theperformance of the proposed approach. The results demonstrate the benefits ofsaliency-based folding approach that delivers comparable classificationaccuracies with state-of-the-art but exhibits lower computational cost andstorage requirements, factors highly important for big data analytics.
arxiv-13500-224 | Self-Configuring and Evolving Fuzzy Image Thresholding | http://arxiv.org/pdf/1509.04664v1.pdf | author:A. Othman, H. R. Tizhoosh, F. Khalvati category:cs.CV published:2015-09-15 summary:Every segmentation algorithm has parameters that need to be adjusted in orderto achieve good results. Evolving fuzzy systems for adjustment of segmentationparameters have been proposed recently (Evolving fuzzy image segmentation --EFIS [1]. However, similar to any other algorithm, EFIS too suffers from a fewlimitations when used in practice. As a major drawback, EFIS depends ondetection of the object of interest for feature calculation, a task that ishighly application-dependent. In this paper, a new version of EFIS is proposedto overcome these limitations. The new EFIS, called self-configuring EFIS(SC-EFIS), uses available training data to auto-configure the parameters thatare fixed in EFIS. As well, the proposed SC-EFIS relies on a feature selectionprocess that does not require the detection of a region of interest (ROI).
arxiv-13500-225 | Large-Scale Optimization Algorithms for Sparse Conditional Gaussian Graphical Models | http://arxiv.org/pdf/1509.04681v2.pdf | author:Calvin McCarter, Seyoung Kim category:stat.ML published:2015-09-15 summary:This paper addresses the problem of scalable optimization for L1-regularizedconditional Gaussian graphical models. Conditional Gaussian graphical modelsgeneralize the well-known Gaussian graphical models to conditionaldistributions to model the output network influenced by conditioning inputvariables. While highly scalable optimization methods exist for sparse Gaussiangraphical model estimation, state-of-the-art methods for conditional Gaussiangraphical models are not efficient enough and more importantly, fail due tomemory constraints for very large problems. In this paper, we propose a newoptimization procedure based on a Newton method that efficiently iterates overtwo sub-problems, leading to drastic improvement in computation time comparedto the previous methods. We then extend our method to scale to large problemsunder memory constraints, using block coordinate descent to limit memory usagewhile achieving fast convergence. Using synthetic and genomic data, we showthat our methods can solve one million dimensional problems to high accuracy ina little over a day on a single machine.
arxiv-13500-226 | Direct high-order edge-preserving regularization for tomographic image reconstruction | http://arxiv.org/pdf/1509.04706v1.pdf | author:Daniil Kazantsev, Evgueni Ovtchinnikov, William R. B. Lionheart, Philip J. Withers, Peter D. Lee category:cs.CV cs.MS cs.NA math.NA published:2015-09-15 summary:In this paper we present a new two-level iterative algorithm for tomographicimage reconstruction. The algorithm uses a regularization technique, which wecall edge-preserving Laplacian, that preserves sharp edges between objectswhile damping spurious oscillations in the areas where the reconstructed imageis smooth. Our numerical simulations demonstrate that the proposed methodoutperforms total variation (TV) regularization and it is competitive with thecombined TV-L2 penalty. Obtained reconstructed images show increasedsignal-to-noise ratio and visually appealing structural features. Computerimplementation and parameter control of the proposed technique isstraightforward, which increases the feasibility of it across many tomographicapplications. In this paper, we applied our method to the under-sampledcomputed tomography (CT) projection data and also considered a case ofreconstruction in emission tomography The MATLAB code is provided to supportobtained results.
arxiv-13500-227 | Towards Making High Dimensional Distance Metric Learning Practical | http://arxiv.org/pdf/1509.04355v1.pdf | author:Qi Qian, Rong Jin, Lijun Zhang, Shenghuo Zhu category:cs.LG published:2015-09-15 summary:In this work, we study distance metric learning (DML) for high dimensionaldata. A typical approach for DML with high dimensional data is to perform thedimensionality reduction first before learning the distance metric. The mainshortcoming of this approach is that it may result in a suboptimal solution dueto the subspace removed by the dimensionality reduction method. In this work,we present a dual random projection frame for DML with high dimensional datathat explicitly addresses the limitation of dimensionality reduction for DML.The key idea is to first project all the data points into a low dimensionalspace by random projection, and compute the dual variables using the projectedvectors. It then reconstructs the distance metric in the original space usingthe estimated dual variables. The proposed method, on one hand, enjoys thelight computation of random projection, and on the other hand, alleviates thelimitation of most dimensionality reduction methods. We verify both empiricallyand theoretically the effectiveness of the proposed algorithm for highdimensional DML.
arxiv-13500-228 | Modeling sequences and temporal networks with dynamic community structures | http://arxiv.org/pdf/1509.04740v1.pdf | author:Tiago P. Peixoto, Martin Rosvall category:cs.SI physics.soc-ph stat.ML published:2015-09-15 summary:Community-detection methods that describe large-scale patterns in thedynamics on and of networks suffer from effects of limited memory and arbitrarytime binning. We develop a variable-order Markov chain model that generalizesthe stochastic block model for discrete time-series as well as temporalnetworks. The temporal model does not use time binning but takes full advantageof the time-ordering of the tokens or edges. When the edge ordering is random,we recover the traditional static block model as a special case. Based onstatistical evidence and without overfitting, we show how a Bayesianformulation of the model allows us to select the most appropriate Markov orderand number of communities.
arxiv-13500-229 | Adapting Resilient Propagation for Deep Learning | http://arxiv.org/pdf/1509.04612v2.pdf | author:Alan Mosca, George D. Magoulas category:cs.NE cs.CV cs.LG stat.ML published:2015-09-15 summary:The Resilient Propagation (Rprop) algorithm has been very popular forbackpropagation training of multilayer feed-forward neural networks in variousapplications. The standard Rprop however encounters difficulties in the contextof deep neural networks as typically happens with gradient-based learningalgorithms. In this paper, we propose a modification of the Rprop that combinesstandard Rprop steps with a special drop out technique. We apply the method fortraining Deep Neural Networks as standalone components and in ensembleformulations. Results on the MNIST dataset show that the proposed modificationalleviates standard Rprop's problems demonstrating improved learning speed andaccuracy.
arxiv-13500-230 | Free-body Gesture Tracking and Augmented Reality Improvisation for Floor and Aerial Dance | http://arxiv.org/pdf/1509.04751v1.pdf | author:Tammuz Dubnov, Cheng-i Wang category:cs.MM cs.CV cs.HC published:2015-09-15 summary:This paper describes an updated interactive performance system for floor andAerial Dance that controls visual and sonic aspects of the presentation via adepth sensing camera (MS Kinect). In order to detect, measure and track freemovement in space, 3 degree of freedom (3-DOF) tracking in space (on the groundand in the air) is performed using IR markers with a method for multi targettracking capabilities added and described in detail. An improved gesturetracking and recognition system, called Action Graph (AG), is described in thepaper. Action Graph uses an efficient incremental construction from a singlelong sequence of movement features and automatically captures repeatedsub-segments in the movement from start to finish with no manual interactionneeded with other advanced capabilities discussed as well. By using the newmodel for the gesture we can unify an entire choreography piece by dynamicallytracking and recognizing gestures and sub-portions of the piece. This gives theperformer the freedom to improvise based on a set of recorded gestures/portionsof the choreography and have the system dynamically respond in relation to theperformer within a set of related rehearsed actions, an ability that has notbeen seen in any other system to date.
arxiv-13500-231 | Zero-Shot Learning via Semantic Similarity Embedding | http://arxiv.org/pdf/1509.04767v2.pdf | author:Ziming Zhang, Venkatesh Saligrama category:cs.CV stat.ML published:2015-09-15 summary:In this paper we consider a version of the zero-shot learning problem whereseen class source and target domain data are provided. The goal duringtest-time is to accurately predict the class label of an unseen target domaininstance based on revealed source domain side information (\eg attributes) forunseen classes. Our method is based on viewing each source or target data as amixture of seen class proportions and we postulate that the mixture patternshave to be similar if the two instances belong to the same unseen class. Thisperspective leads us to learning source/target embedding functions that map anarbitrary source/target domain data into a same semantic space where similaritycan be readily measured. We develop a max-margin framework to learn thesesimilarity functions and jointly optimize parameters by means of crossvalidation. Our test results are compelling, leading to significant improvementin terms of accuracy on most benchmark datasets for zero-shot recognition.
arxiv-13500-232 | Linear Embedding of Large-Scale Brain Networks for Twin fMRI | http://arxiv.org/pdf/1509.04771v1.pdf | author:Moo K. Chung, Victoria G. Vilalta, Paul J. Rathouz, Benjamin B. Lahey, David H. Zald category:cs.AI q-bio.NC stat.ML published:2015-09-15 summary:In many human brain network studies, we do not have sufficient number (n) ofimages relative to the number (p) of voxels due to the prohibitively expensivecost of scanning enough subjects. Thus, brain network models usually suffer thesmall-n large-p problem. Such a problem is often remedied by sparse networkmodels, which are usually solved numerically by optimizing L1-penalties.Unfortunately, due to the computational bottleneck associated with optimizingL1-penalties, it is not practical to apply such methods to learn large-scalebrain networks. In this paper, we introduce a new sparse network model based oncross-correlations that bypass the computational bottleneck. Our model canbuild the sparse brain networks at voxel level with p > 25000. Instead of usinga single sparse parameter that may not be optimal in other studies anddatasets, we propose to analyze the collection of networks at every possiblesparse parameter in a coherent mathematical framework using graph filtrations.The method is subsequently applied in determining the extend of genetic effectson functional brain networks at voxel-level for the first time using twin fMRI.
arxiv-13500-233 | Bayesian inference for spatio-temporal spike and slab priors | http://arxiv.org/pdf/1509.04752v2.pdf | author:Michael Riis Andersen, Aki Vehtari, Ole Winther, Lars Kai Hansen category:stat.ML stat.CO stat.ME published:2015-09-15 summary:In this work we address the problem of solving a series of underdeterminedlinear inverse problems subject to a sparsity constraint. We generalize thespike and slab prior distribution to encode a priori correlation of the supportof the solution in both space and time by imposing a transformed Gaussianprocess on the spike and slab probabilities. An expectation propagation (EP)algorithm for posterior inference under the proposed model is derived. Forlarge scale problems, the standard EP algorithm can be prohibitively slow. Wetherefore introduce three different approximation schemes to reduce thecomputational complexity. Finally, we demonstrate the proposed model usingnumerical experiments based on both synthetic and real data sets.
arxiv-13500-234 | Dropping Convexity for Faster Semi-definite Optimization | http://arxiv.org/pdf/1509.03917v3.pdf | author:Srinadh Bhojanapalli, Anastasios Kyrillidis, Sujay Sanghavi category:stat.ML cs.DS cs.IT cs.LG cs.NA math.IT math.OC published:2015-09-14 summary:We study the minimization of a convex function $f(X)$ over the set of$n\times n$ positive semi-definite matrices, but when the problem is recast as$\min_U g(U) := f(UU^\top)$, with $U \in \mathbb{R}^{n \times r}$ and $r \leqn$. We study the performance of gradient descent on $g$---which we refer to asFactored Gradient Descent (FGD)---under standard assumptions on the originalfunction $f$. We provide a rule for selecting the step size and, with this choice, showthat the local convergence rate of FGD mirrors that of standard gradientdescent on the original $f$: i.e., after $k$ steps, the error is $O(1/k)$ forsmooth $f$, and exponentially small in $k$ when $f$ is (restricted) stronglyconvex. In addition, we provide a procedure to initialize FGD for (restricted)strongly convex objectives and when one only has access to $f$ via afirst-order oracle; for several problem instances, such proper initializationleads to global convergence guarantees. FGD and similar procedures are widely used in practice for problems that canbe posed as matrix factorization. To the best of our knowledge, this is thefirst paper to provide precise convergence rate guarantees for general convexfunctions under standard convex assumptions.
arxiv-13500-235 | Expanded Parts Model for Semantic Description of Humans in Still Images | http://arxiv.org/pdf/1509.04186v2.pdf | author:Gaurav Sharma, Frederic Jurie, Cordelia Schmid category:cs.CV published:2015-09-14 summary:We introduce an Expanded Parts Model (EPM) for recognizing human attributes(e.g. young, short hair, wearing suit) and actions (e.g. running, jumping) instill images. An EPM is a collection of part templates which are learntdiscriminatively to explain specific scale-space regions in the images (inhuman centric coordinates). This is in contrast to current models which consistof a relatively few (i.e. a mixture of) 'average' templates. EPM uses only asubset of the parts to score an image and scores the image sparsely in space,i.e. it ignores redundant and random background in an image. To learn ourmodel, we propose an algorithm which automatically mines parts and learnscorresponding discriminative templates together with their respective locationsfrom a large number of candidate parts. We validate our method on three recentchallenging datasets of human attributes and actions. We obtain convincingqualitative and state-of-the-art quantitative results on the three datasets.
arxiv-13500-236 | Sparse Representation for 3D Shape Estimation: A Convex Relaxation Approach | http://arxiv.org/pdf/1509.04309v2.pdf | author:Xiaowei Zhou, Menglong Zhu, Spyridon Leonardos, Kostas Daniilidis category:cs.CV published:2015-09-14 summary:We investigate the problem of estimating the 3D shape of an object defined bya set of 3D landmarks, given their 2D correspondences in a single image. Asuccessful approach to alleviating the reconstruction ambiguity is the 3Ddeformable shape model and a sparse representation is often used to capturecomplex shape variability. But the model inference is still a challenge due tothe nonconvexity in optimization resulted from joint estimation of shape andviewpoint. In contrast to prior work that relies on a alternating scheme withsolutions depending on initialization, we propose a convex approach toaddressing this challenge and develop an efficient algorithm to solve theproposed convex program. Moreover, we propose a robust model to handle grosserrors in the 2D correspondences. We demonstrate the exact recovery property ofthe proposed method, the advantage compared to the nonconvex baseline methodsand the applicability to recover 3D human poses and car models from singleimages.
arxiv-13500-237 | Voted Kernel Regularization | http://arxiv.org/pdf/1509.04340v1.pdf | author:Corinna Cortes, Prasoon Goyal, Vitaly Kuznetsov, Mehryar Mohri category:cs.LG published:2015-09-14 summary:This paper presents an algorithm, Voted Kernel Regularization , that providesthe flexibility of using potentially very complex kernel functions such aspredictors based on much higher-degree polynomial kernels, while benefittingfrom strong learning guarantees. The success of our algorithm arises fromderived bounds that suggest a new regularization penalty in terms of theRademacher complexities of the corresponding families of kernel maps. In aseries of experiments we demonstrate the improved performance of our algorithmas compared to baselines. Furthermore, the algorithm enjoys several favorableproperties. The optimization problem is convex, it allows for learning withnon-PDS kernels, and the solutions are highly sparse, resulting in improvedclassification speed and memory requirements.
arxiv-13500-238 | Markov Boundary Discovery with Ridge Regularized Linear Models | http://arxiv.org/pdf/1509.03935v1.pdf | author:Eric V. Strobl, Shyam Visweswaran category:math.ST stat.ME stat.ML stat.TH published:2015-09-14 summary:Ridge regularized linear models (RRLMs), such as ridge regression and theSVM, are a popular group of methods that are used in conjunction withcoefficient hypothesis testing to discover explanatory variables with asignificant multivariate association to a response. However, many investigatorsare reluctant to draw causal interpretations of the selected variables due tothe incomplete knowledge of the capabilities of RRLMs in causal inference.Under reasonable assumptions, we show that a modified form of RRLMs can getvery close to identifying a subset of the Markov boundary by providing aworst-case bound on the space of possible solutions. The results hold for anyconvex loss, even when the underlying functional relationship is nonlinear, andthe solution is not unique. Our approach combines ideas in Markov boundary andsufficient dimension reduction theory. Experimental results show that themodified RRLMs are competitive against state-of-the-art algorithms indiscovering part of the Markov boundary from gene expression data.
arxiv-13500-239 | Learning without Recall by Random Walks on Directed Graphs | http://arxiv.org/pdf/1509.04332v1.pdf | author:Mohammad Amin Rahimian, Shahin Shahrampour, Ali Jadbabaie category:cs.SY math.OC stat.ML published:2015-09-14 summary:We consider a network of agents that aim to learn some unknown state of theworld using private observations and exchange of beliefs. At each time, agentsobserve private signals generated based on the true unknown state. Each agentmight not be able to distinguish the true state based only on her privateobservations. This occurs when some other states are observationally equivalentto the true state from the agent's perspective. To overcome this shortcoming,agents must communicate with each other to benefit from local observations. Wepropose a model where each agent selects one of her neighbors randomly at eachtime. Then, she refines her opinion using her private signal and the prior ofthat particular neighbor. The proposed rule can be thought of as a Bayesianagent who cannot recall the priors based on which other agents make inferences.This learning without recall approach preserves some aspects of the Bayesianinference while being computationally tractable. By establishing acorrespondence with a random walk on the network graph, we prove that under thedescribed protocol, agents learn the truth exponentially fast in the almostsure sense. The asymptotic rate is expressed as the sum of the relativeentropies between the signal structures of every agent weighted by thestationary distribution of the random walk.
arxiv-13500-240 | A Practioner's Guide to Evaluating Entity Resolution Results | http://arxiv.org/pdf/1509.04238v1.pdf | author:Matt Barnes category:cs.DB stat.ML published:2015-09-14 summary:Entity resolution (ER) is the task of identifying records belonging to thesame entity (e.g. individual, group) across one or multiple databases.Ironically, it has multiple names: deduplication and record linkage, amongothers. In this paper we survey metrics used to evaluate ER results in order toiteratively improve performance and guarantee sufficient quality prior todeployment. Some of these metrics are borrowed from multi-class classificationand clustering domains, though some key differences exist differentiatingentity resolution from general clustering. Menestrina et al. empirically showedrankings from these metrics often conflict with each other, thus our primarymotivation for studying them. This paper provides practitioners the basicknowledge to begin evaluating their entity resolution results.
arxiv-13500-241 | Model Accuracy and Runtime Tradeoff in Distributed Deep Learning | http://arxiv.org/pdf/1509.04210v2.pdf | author:Suyog Gupta, Wei Zhang, Josh Milthorpe category:stat.ML cs.DC cs.LG cs.NE published:2015-09-14 summary:This paper presents Rudra, a parameter server based distributed computingframework tuned for training large-scale deep neural networks. Using variantsof the asynchronous stochastic gradient descent algorithm we study the impactof synchronization protocol, stale gradient updates, minibatch size, learningrates, and number of learners on runtime performance and model accuracy. Weintroduce a new learning rate modulation strategy to counter the effect ofstale gradients and propose a new synchronization protocol that can effectivelybound the staleness in gradients, improve runtime performance and achieve goodmodel accuracy. Our empirical investigation reveals a principled approach fordistributed training of neural networks: the mini-batch size per learner shouldbe reduced as more learners are added to the system to preserve the modelaccuracy. We validate this approach using commonly-used image classificationbenchmarks: CIFAR10 and ImageNet.
arxiv-13500-242 | gSLICr: SLIC superpixels at over 250Hz | http://arxiv.org/pdf/1509.04232v1.pdf | author:Carl Yuheng Ren, Victor Adrian Prisacariu, Ian D Reid category:cs.CV published:2015-09-14 summary:We introduce a parallel GPU implementation of the Simple Linear IterativeClustering (SLIC) superpixel segmentation. Using a single graphic card, ourimplementation achieves speedups of up to $83\times$ from the standardsequential implementation. Our implementation is fully compatible with thestandard sequential implementation and the software is now available online andis open source.
arxiv-13500-243 | Parametric Maxflows for Structured Sparse Learning with Convex Relaxations of Submodular Functions | http://arxiv.org/pdf/1509.03946v1.pdf | author:Yoshinobu Kawahara, Yutaro Yamaguchi category:cs.LG cs.NA published:2015-09-14 summary:The proximal problem for structured penalties obtained via convex relaxationsof submodular functions is known to be equivalent to minimizing separableconvex functions over the corresponding submodular polyhedra. In this paper, wereveal a comprehensive class of structured penalties for which penalties thisproblem can be solved via an efficiently solvable class of parametric maxflowoptimization. We then show that the parametric maxflow algorithm proposed byGallo et al. and its variants, which runs, in the worst-case, at the cost ofonly a constant factor of a single computation of the corresponding maxflowoptimization, can be adapted to solve the proximal problems for thosepenalties. Several existing structured penalties satisfy these conditions;thus, regularized learning with these penalties is solvable quickly using theparametric maxflow algorithm. We also investigate the empirical runtimeperformance of the proposed framework.
arxiv-13500-244 | Robust Gaussian Filtering | http://arxiv.org/pdf/1509.04072v2.pdf | author:Manuel Wüthrich, Cristina Garcia Cifuentes, Sebastian Trimpe, Franziska Meier, Jeannette Bohg, Jan Issac, Stefan Schaal category:stat.ML cs.SY published:2015-09-14 summary:Most widely-used state estimation algorithms, such as the Extended KalmanFilter and the Unscented Kalman Filter, belong to the family of GaussianFilters (GF). Unfortunately, GFs fail if the measurement process is modelled bya fat-tailed distribution. This is a severe limitation, because thin-tailedmeasurement models, such as the analytically-convenient and thereforewidely-used Gaussian distribution, are sensitive to outliers. In this paper, weshow that mapping the measurements into a specific feature space enables anyexisting GF algorithm to work with fat-tailed measurement models. We find afeature function which is optimal under certain conditions. Simulation resultsshow that the proposed method allows for robust filtering in both linear andnonlinear systems with measurements contaminated by fat-tailed noise.
arxiv-13500-245 | Fame for sale: efficient detection of fake Twitter followers | http://arxiv.org/pdf/1509.04098v2.pdf | author:Stefano Cresci, Roberto Di Pietro, Marinella Petrocchi, Angelo Spognardi, Maurizio Tesconi category:cs.SI cs.CR cs.LG H.2.8 published:2015-09-14 summary:$\textit{Fake followers}$ are those Twitter accounts specifically created toinflate the number of followers of a target account. Fake followers aredangerous for the social platform and beyond, since they may alter conceptslike popularity and influence in the Twittersphere - hence impacting oneconomy, politics, and society. In this paper, we contribute along differentdimensions. First, we review some of the most relevant existing features andrules (proposed by Academia and Media) for anomalous Twitter accountsdetection. Second, we create a baseline dataset of verified human and fakefollower accounts. Such baseline dataset is publicly available to thescientific community. Then, we exploit the baseline dataset to train a set ofmachine-learning classifiers built over the reviewed rules and features. Ourresults show that most of the rules proposed by Media provide unsatisfactoryperformance in revealing fake followers, while features proposed in the past byAcademia for spam detection provide good results. Building on the mostpromising features, we revise the classifiers both in terms of reduction ofoverfitting and cost for gathering the data needed to compute the features. Thefinal result is a novel $\textit{Class A}$ classifier, general enough to thwartoverfitting, lightweight thanks to the usage of the less costly features, andstill able to correctly classify more than 95% of the accounts of the originaltraining set. We ultimately perform an information fusion-based sensitivityanalysis, to assess the global sensitivity of each of the features employed bythe classifier. The findings reported in this paper, other than being supportedby a thorough experimental methodology and interesting on their own, also pavethe way for further investigation on the novel issue of fake Twitter followers.
arxiv-13500-246 | Twitter Sentiment Analysis | http://arxiv.org/pdf/1509.04219v1.pdf | author:Afroze Ibrahim Baqapuri category:cs.CL cs.IR cs.SI published:2015-09-14 summary:This project addresses the problem of sentiment analysis in twitter; that isclassifying tweets according to the sentiment expressed in them: positive,negative or neutral. Twitter is an online micro-blogging and social-networkingplatform which allows users to write short status updates of maximum length 140characters. It is a rapidly expanding service with over 200 million registeredusers - out of which 100 million are active users and half of them log ontwitter on a daily basis - generating nearly 250 million tweets per day. Due tothis large amount of usage we hope to achieve a reflection of public sentimentby analysing the sentiments expressed in the tweets. Analysing the publicsentiment is important for many applications such as firms trying to find outthe response of their products in the market, predicting political electionsand predicting socioeconomic phenomena like stock exchange. The aim of thisproject is to develop a functional classifier for accurate and automaticsentiment classification of an unknown tweet stream.
arxiv-13500-247 | Deep Learning Applied to Image and Text Matching | http://arxiv.org/pdf/1601.03478v1.pdf | author:Afroze Ibrahim Baqapuri category:cs.LG cs.CL cs.CV published:2015-09-14 summary:The ability to describe images with natural language sentences is thehallmark for image and language understanding. Such a system has wide rangingapplications such as annotating images and using natural sentences to searchfor images.In this project we focus on the task of bidirectional imageretrieval: such asystem is capable of retrieving an image based on a sentence(image search) andretrieve sentence based on an image query (image annotation).We present asystem based on a global ranking objective function which uses acombinationof convolutional neural networks (CNN) and multi layer perceptrons(MLP).It takes a pair of image and sentence and processes them in differentchannels,finally embedding it into a common multimodal vector space. Theseembeddingsencode abstract semantic information about the two inputs and can becomparedusing traditional information retrieval approaches. For each such pair,the modelreturns a score which is interpretted as a similarity metric. If thisscore is high,the image and sentence are likely to convey similar meaning, andif the score is low then they are likely not to. The visual input is modeled via deep convolutional neural network. Ontheother hand we explore three models for the textual module. The first oneisbag of words with an MLP. The second one uses n-grams (bigram, trigrams,and acombination of trigram & skip-grams) with an MLP. The third is morespecializeddeep network specific for modeling variable length sequences (SSE).We reportcomparable performance to recent work in the field, even though ouroverallmodel is simpler. We also show that the training time choice of how wecangenerate our negative samples has a significant impact on performance, and canbe used to specialize the bi-directional system in one particular task.
arxiv-13500-248 | Geometry and dimensionality reduction of feature spaces in primary visual cortex | http://arxiv.org/pdf/1509.03942v1.pdf | author:Davide Barbieri category:q-bio.NC cs.CV math.GR published:2015-09-14 summary:Some geometric properties of the wavelet analysis performed by visual neuronsare discussed and compared with experimental data. In particular, severalrelationships between the cortical morphologies and the parametric dependenciesof extracted features are formalized and considered from a harmonic analysispoint of view.
arxiv-13500-249 | Learning Social Relation Traits from Face Images | http://arxiv.org/pdf/1509.03936v1.pdf | author:Zhanpeng Zhang, Ping Luo, Chen Change Loy, Xiaoou Tang category:cs.CV cs.CY published:2015-09-14 summary:Social relation defines the association, e.g, warm, friendliness, anddominance, between two or more people. Motivated by psychological studies, weinvestigate if such fine-grained and high-level relation traits can becharacterised and quantified from face images in the wild. To address thischallenging problem we propose a deep model that learns a rich facerepresentation to capture gender, expression, head pose, and age-relatedattributes, and then performs pairwise-face reasoning for relation prediction.To learn from heterogeneous attribute sources, we formulate a new networkarchitecture with a bridging layer to leverage the inherent correspondencesamong these datasets. It can also cope with missing target attribute labels.Extensive experiments show that our approach is effective for fine-grainedsocial relation learning in images and videos.
arxiv-13500-250 | Color-Phase Analysis for Sinusoidal Structured Light in Rapid Range Imaging | http://arxiv.org/pdf/1509.04115v1.pdf | author:Changsoo Je, Sang Wook Lee, Rae-Hong Park category:cs.CV cs.GR physics.optics I.2.10; I.4.8 published:2015-09-14 summary:Active range sensing using structured-light is the most accurate and reliablemethod for obtaining 3D information. However, most of the work has been limitedto range sensing of static objects, and range sensing of dynamic (moving ordeforming) objects has been investigated recently only by a few researchers.Sinusoidal structured-light is one of the well-known optical methods for 3Dmeasurement. In this paper, we present a novel method for rapid high-resolutionrange imaging using color sinusoidal pattern. We consider the real-worldproblem of nonlinearity and color-band crosstalk in the color light projectorand color camera, and present methods for accurate recovery of color-phase. Forhigh-resolution ranging, we use high-frequency patterns and describe newunwrapping algorithms for reliable range recovery. The experimental resultsdemonstrate the effectiveness of our methods.
arxiv-13500-251 | Optimization of anemia treatment in hemodialysis patients via reinforcement learning | http://arxiv.org/pdf/1509.03977v1.pdf | author:Pablo Escandell-Montero, Milena Chermisi, José M. Martínez-Martínez, Juan Gómez-Sanchis, Carlo Barbieri, Emilio Soria-Olivas, Flavio Mari, Joan Vila-Francés, Andrea Stopper, Emanuele Gatti, José D. Martín-Guerrero category:stat.ML cs.AI cs.LG published:2015-09-14 summary:Objective: Anemia is a frequent comorbidity in hemodialysis patients that canbe successfully treated by administering erythropoiesis-stimulating agents(ESAs). ESAs dosing is currently based on clinical protocols that often do notaccount for the high inter- and intra-individual variability in the patient'sresponse. As a result, the hemoglobin level of some patients oscillates aroundthe target range, which is associated with multiple risks and side-effects.This work proposes a methodology based on reinforcement learning (RL) tooptimize ESA therapy. Methods: RL is a data-driven approach for solving sequential decision-makingproblems that are formulated as Markov decision processes (MDPs). Computingoptimal drug administration strategies for chronic diseases is a sequentialdecision-making problem in which the goal is to find the best sequence of drugdoses. MDPs are particularly suitable for modeling these problems due to theirability to capture the uncertainty associated with the outcome of the treatmentand the stochastic nature of the underlying process. The RL algorithm employedin the proposed methodology is fitted Q iteration, which stands out for itsability to make an efficient use of data. Results: The experiments reported here are based on a computational modelthat describes the effect of ESAs on the hemoglobin level. The performance ofthe proposed method is evaluated and compared with the well-known Q-learningalgorithm and with a standard protocol. Simulation results show that theperformance of Q-learning is substantially lower than FQI and the protocol. Conclusion: Although prospective validation is required, promising resultsdemonstrate the potential of RL to become an alternative to current protocols.
arxiv-13500-252 | Learning to Divide and Conquer for Online Multi-Target Tracking | http://arxiv.org/pdf/1509.03956v1.pdf | author:Francesco Solera, Simone Calderara, Rita Cucchiara category:cs.CV published:2015-09-14 summary:Online Multiple Target Tracking (MTT) is often addressed within thetracking-by-detection paradigm. Detections are previously extractedindependently in each frame and then objects trajectories are built bymaximizing specifically designed coherence functions. Nevertheless, ambiguitiesarise in presence of occlusions or detection errors. In this paper we claimthat the ambiguities in tracking could be solved by a selective use of thefeatures, by working with more reliable features if possible and exploiting adeeper representation of the target only if necessary. To this end, we proposean online divide and conquer tracker for static camera scenes, which partitionsthe assignment problem in local subproblems and solves them by selectivelychoosing and combining the best features. The complete framework is cast as astructural learning task that unifies these phases and learns trackerparameters from examples. Experiments on two different datasets highlights asignificant improvement of tracking performances (MOTA +10%) over the state ofthe art.
arxiv-13500-253 | Natural scene statistics mediate the perception of image complexity | http://arxiv.org/pdf/1509.03970v1.pdf | author:Nicolas Gauvrit, Fernando Soler-Toscano, Hector Zenil category:cs.AI cs.CV published:2015-09-14 summary:Humans are sensitive to complexity and regularity in patterns. The subjectiveperception of pattern complexity is correlated to algorithmic(Kolmogorov-Chaitin) complexity as defined in computer science, but also to thefrequency of naturally occurring patterns. However, the possible mediationalrole of natural frequencies in the perception of algorithmic complexity remainsunclear. Here we reanalyze Hsu et al. (2010) through a mediational analysis,and complement their results in a new experiment. We conclude that humanperception of complexity seems partly shaped by natural scenes statistics,thereby establishing a link between the perception of complexity and the effectof natural scene statistics.
arxiv-13500-254 | The USFD Spoken Language Translation System for IWSLT 2014 | http://arxiv.org/pdf/1509.03870v1.pdf | author:Raymond W. M. Ng, Mortaza Doulaty, Rama Doddipatla, Wilker Aziz, Kashif Shah, Oscar Saz, Madina Hasan, Ghada AlHarbi, Lucia Specia, Thomas Hain category:cs.CL published:2015-09-13 summary:The University of Sheffield (USFD) participated in the International Workshopfor Spoken Language Translation (IWSLT) in 2014. In this paper, we willintroduce the USFD SLT system for IWSLT. Automatic speech recognition (ASR) isachieved by two multi-pass deep neural network systems with adaptation andrescoring techniques. Machine translation (MT) is achieved by a phrase-basedsystem. The USFD primary system incorporates state-of-the-art ASR and MTtechniques and gives a BLEU score of 23.45 and 14.75 on the English-to-Frenchand English-to-German speech-to-text translation task with the IWSLT 2014 data.The USFD contrastive systems explore the integration of ASR and MT by using aquality estimation system to rescore the ASR outputs, optimising towards bettertranslation. This gives a further 0.54 and 0.26 BLEU improvement respectivelyon the IWSLT 2012 and 2014 evaluation data.
arxiv-13500-255 | On Binary Classification with Single-Layer Convolutional Neural Networks | http://arxiv.org/pdf/1509.03891v1.pdf | author:Soroush Mehri category:cs.CV published:2015-09-13 summary:Convolutional neural networks are becoming standard tools for solving objectrecognition and visual tasks. However, most of the design and implementation ofthese complex models are based on trail-and-error. In this report, the mainfocus is to consider some of the important factors in designing convolutionalnetworks to perform better. Specifically, classification with wide single-layernetworks with large kernels as a general framework is considered. Particularly,we will show that pre-training using unsupervised schemes is vital, reasonableregularization is beneficial and applying of strong regularizers like dropoutcould be devastating. Pool size is also could be as important as learningprocedure itself. In addition, it has been presented that using such a simpleand relatively fast model for classifying cats and dogs, performance is closeto state-of-the-art achievable by a combination of SVM models on color andtexture features.
arxiv-13500-256 | A Markov Jump Process for More Efficient Hamiltonian Monte Carlo | http://arxiv.org/pdf/1509.03808v3.pdf | author:Andrew B. Berger, Mayur Mudigonda, Michael R. DeWeese, Jascha Sohl-Dickstein category:stat.ML stat.CO published:2015-09-13 summary:In most sampling algorithms, including Hamiltonian Monte Carlo, transitionrates between states correspond to the probability of making a transition in asingle time step, and are constrained to be less than or equal to 1. We derivea Hamiltonian Monte Carlo algorithm using a continuous time Markov jumpprocess, and are thus able to escape this constraint. Transition rates in aMarkov jump process need only be non-negative. We demonstrate that the newalgorithm leads to improved mixing for several example problems, both byevaluating the spectral gap of the Markov operator, and by computingautocorrelation as a function of compute time. We release the algorithm as anopen source Python package.
arxiv-13500-257 | Vectors of Locally Aggregated Centers for Compact Video Representation | http://arxiv.org/pdf/1509.03844v1.pdf | author:Alhabib Abbas, Nikos Deligiannis, Yiannis Andreopoulos category:cs.MM cs.CV cs.IR published:2015-09-13 summary:We propose a novel vector aggregation technique for compact videorepresentation, with application in accurate similarity detection within largevideo datasets. The current state-of-the-art in visual search is formed by thevector of locally aggregated descriptors (VLAD) of Jegou et. al. VLAD generatescompact video representations based on scale-invariant feature transform (SIFT)vectors (extracted per frame) and local feature centers computed over atraining set. With the aim to increase robustness to visual distortions, wepropose a new approach that operates at a coarser level in the featurerepresentation. We create vectors of locally aggregated centers (VLAC) by firstclustering SIFT features to obtain local feature centers (LFCs) and thenencoding the latter with respect to given centers of local feature centers(CLFCs), extracted from a training set. The sum-of-differences between the LFCsand the CLFCs are aggregated to generate an extremely-compact video descriptionused for accurate video segment similarity detection. Experimentation using avideo dataset, comprising more than 1000 minutes of content from the Open VideoProject, shows that VLAC obtains substantial gains in terms of mean AveragePrecision (mAP) against VLAD and the hyper-pooling method of Douze et. al.,under the same compaction factor and the same set of distortions.
arxiv-13500-258 | Learning Contextual Dependencies with Convolutional Hierarchical Recurrent Neural Networks | http://arxiv.org/pdf/1509.03877v2.pdf | author:Zhen Zuo, Bing Shuai, Gang Wang, Xiao Liu, Xingxing Wang, Bing Wang category:cs.CV published:2015-09-13 summary:Existing deep convolutional neural networks (CNNs) have shown their greatsuccess on image classification. CNNs mainly consist of convolutional andpooling layers, both of which are performed on local image areas withoutconsidering the dependencies among different image regions. However, suchdependencies are very important for generating explicit image representation.In contrast, recurrent neural networks (RNNs) are well known for their abilityof encoding contextual information among sequential data, and they only requirea limited number of network parameters. General RNNs can hardly be directlyapplied on non-sequential data. Thus, we proposed the hierarchical RNNs(HRNNs). In HRNNs, each RNN layer focuses on modeling spatial dependenciesamong image regions from the same scale but different locations. While thecross RNN scale connections target on modeling scale dependencies among regionsfrom the same location but different scales. Specifically, we propose tworecurrent neural network models: 1) hierarchical simple recurrent network(HSRN), which is fast and has low computational cost; and 2) hierarchicallong-short term memory recurrent network (HLSTM), which performs better thanHSRN with the price of more computational cost. In this manuscript, we integrate CNNs with HRNNs, and develop end-to-endconvolutional hierarchical recurrent neural networks (C-HRNNs). C-HRNNs notonly make use of the representation power of CNNs, but also efficiently encodesspatial and scale dependencies among different image regions. On four of themost challenging object/scene image classification benchmarks, our C-HRNNsachieve state-of-the-art results on Places 205, SUN 397, MIT indoor, andcompetitive results on ILSVRC 2012.
arxiv-13500-259 | Bio-Inspired Human Action Recognition using Hybrid Max-Product Neuro-Fuzzy Classifier and Quantum-Behaved PSO | http://arxiv.org/pdf/1509.03789v2.pdf | author:Bardia Yousefi, Chu Kiong Loo category:cs.AI cs.CV published:2015-09-13 summary:Studies on computational neuroscience through functional magnetic resonanceimaging (fMRI) and following biological inspired system stated that humanaction recognition in the brain of mammalian leads two distinct pathways in themodel, which are specialized for analysis of motion (optic flow) and forminformation. Principally, we have defined a novel and robust form featuresapplying active basis model as form extractor in form pathway in the biologicalinspired model. An unbalanced synergetic neural net-work classifies shapes andstructures of human objects along with tuning its attention parameter byquantum particle swarm optimization (QPSO) via initiation of Centroidal VoronoiTessellations. These tools utilized and justified as strong tools for followingbiological system model in form pathway. But the final decision has done bycombination of ultimate outcomes of both pathways via fuzzy inference whichincreases novality of proposed model. Combination of these two brain pathwaysis done by considering each feature sets in Gaussian membership functions withfuzzy product inference method. Two configurations have been proposed for formpathway: applying multi-prototype human action templates using two timesynergetic neural network for obtaining uniform template regarding eachactions, and second scenario that it uses abstracting human action in fourkey-frames. Experimental results showed promising accuracy performance ondifferent datasets (KTH and Weizmann).
arxiv-13500-260 | Double Relief with progressive weighting function | http://arxiv.org/pdf/1509.04265v2.pdf | author:Gabriel Prat Masramon, Lluís A. Belanche Muñoz category:cs.LG cs.AI published:2015-09-12 summary:Feature weighting algorithms try to solve a problem of great importancenowadays in machine learning: The search of a relevance measure for thefeatures of a given domain. This relevance is primarily used for featureselection as feature weighting can be seen as a generalization of it, but it isalso useful to better understand a problem's domain or to guide an inductor inits learning process. Relief family of algorithms are proven to be veryeffective in this task. On previous work, a new extension was proposed that aimed for improving thealgorithm's performance and it was shown that in certain cases it improved theweights' estimation accuracy. However, it also seemed to be sensible to somecharacteristics of the data. An improvement of that previously presentedextension is presented in this work that aims to make it more robust to problemspecific characteristics. An experimental design is proposed to test itsperformance. Results of the tests prove that it indeed increase the robustnessof the previously proposed extension.
arxiv-13500-261 | Toward better feature weighting algorithms: a focus on Relief | http://arxiv.org/pdf/1509.03755v2.pdf | author:Gabriel Prat Masramon, Lluís A. Belanche Muñoz category:cs.LG published:2015-09-12 summary:Feature weighting algorithms try to solve a problem of great importancenowadays in machine learning: The search of a relevance measure for thefeatures of a given domain. This relevance is primarily used for featureselection as feature weighting can be seen as a generalization of it, but it isalso useful to better understand a problem's domain or to guide an inductor inits learning process. Relief family of algorithms are proven to be veryeffective in this task. Some other feature weighting methods are reviewed inorder to give some context and then the different existing extensions to theoriginal algorithm are explained. One of Relief's known issues is the performance degradation of its estimateswhen redundant features are present. A novel theoretical definition ofredundancy level is given in order to guide the work towards an extension ofthe algorithm that is more robust against redundancy. A new extension ispresented that aims for improving the algorithms performance. Some experimentswere driven to test this new extension against the existing ones with a set ofartificial and real datasets and denoted that in certain cases it improves theweight's estimation accuracy.
arxiv-13500-262 | Improving distant supervision using inference learning | http://arxiv.org/pdf/1509.03739v1.pdf | author:Roland Roller, Eneko Agirre, Aitor Soroa, Mark Stevenson category:cs.CL published:2015-09-12 summary:Distant supervision is a widely applied approach to automatic training ofrelation extraction systems and has the advantage that it can generate largeamounts of labelled data with minimal effort. However, this data may containerrors and consequently systems trained using distant supervision tend not toperform as well as those based on manually labelled data. This work proposes anovel method for detecting potential false negative training examples using aknowledge inference method. Results show that our approach improves theperformance of relation extraction systems trained using distantly superviseddata.
arxiv-13500-263 | Kannada named entity recognition and classification (nerc) based on multinomial naïve bayes (mnb) classifier | http://arxiv.org/pdf/1509.04385v1.pdf | author:S. Amarappa, S. V. Sathyanarayana category:cs.CL published:2015-09-12 summary:Named Entity Recognition and Classification (NERC) is a process ofidentification of proper nouns in the text and classification of those nounsinto certain predefined categories like person name, location, organization,date, and time etc. NERC in Kannada is an essential and challenging task. Theaim of this work is to develop a novel model for NERC, based on MultinomialNa\"ive Bayes (MNB) Classifier. The Methodology adopted in this paper is basedon feature extraction of training corpus, by using term frequency, inversedocument frequency and fitting them to a tf-idf-vectorizer. The paper discussesthe various issues in developing the proposed model. The details ofimplementation and performance evaluation are discussed. The experiments areconducted on a training corpus of size 95,170 tokens and test corpus of 5,000tokens. It is observed that the model works with Precision, Recall andF1-measure of 83%, 79% and 81% respectively.
arxiv-13500-264 | Hessian-free Optimization for Learning Deep Multidimensional Recurrent Neural Networks | http://arxiv.org/pdf/1509.03475v2.pdf | author:Minhyung Cho, Chandra Shekhar Dhir, Jaehyung Lee category:cs.LG cs.NE stat.ML published:2015-09-11 summary:Multidimensional recurrent neural networks (MDRNNs) have shown a remarkableperformance in the area of speech and handwriting recognition. The performanceof an MDRNN is improved by further increasing its depth, and the difficulty oflearning the deeper network is overcome by using Hessian-free (HF)optimization. Given that connectionist temporal classification (CTC) isutilized as an objective of learning an MDRNN for sequence labeling, thenon-convexity of CTC poses a problem when applying HF to the network. As asolution, a convex approximation of CTC is formulated and its relationship withthe EM algorithm and the Fisher information matrix is discussed. An MDRNN up toa depth of 15 layers is successfully trained using HF, resulting in an improvedperformance for sequence labeling.
arxiv-13500-265 | Inferring and evaluating semantic classes of verbs signaling modality | http://arxiv.org/pdf/1509.03488v1.pdf | author:Judith Eckle-Kohler category:cs.CL published:2015-09-11 summary:We infer semantic classes of verbs signaling modality from a purely syntacticclassification of 637 German verbs by applying findings from linguistics aboutcorrespondences between verb meaning and syntax. Our extensive evaluation ofthe semantic classification is based on a linking to three other lexicalresources at the word sense level: to the German wordnet GermaNet and to theEnglish resources VerbNet and FrameNet. This way, we are able to perform areproducible semantic characterization of the inferred German classes. We alsoperform a corpus-based evaluation revealing that the frequencies of the classesin corpora of different genres are significantly different. We will make theresulting bilingual resource of German-English semantically categorized verbclasses publicly available.
arxiv-13500-266 | DeepSat - A Learning framework for Satellite Imagery | http://arxiv.org/pdf/1509.03602v1.pdf | author:Saikat Basu, Sangram Ganguly, Supratik Mukhopadhyay, Robert DiBiano, Manohar Karki, Ramakrishna Nemani category:cs.CV published:2015-09-11 summary:Satellite image classification is a challenging problem that lies at thecrossroads of remote sensing, computer vision, and machine learning. Due to thehigh variability inherent in satellite data, most of the current objectclassification approaches are not suitable for handling satellite datasets. Theprogress of satellite image analytics has also been inhibited by the lack of asingle labeled high-resolution dataset with multiple class labels. Thecontributions of this paper are twofold - (1) first, we present two newsatellite datasets called SAT-4 and SAT-6, and (2) then, we propose aclassification framework that extracts features from an input image, normalizesthem and feeds the normalized feature vectors to a Deep Belief Network forclassification. On the SAT-4 dataset, our best network produces aclassification accuracy of 97.95% and outperforms three state-of-the-art objectrecognition algorithms, namely - Deep Belief Networks, Convolutional NeuralNetworks and Stacked Denoising Autoencoders by ~11%. On SAT-6, it produces aclassification accuracy of 93.9% and outperforms the other algorithms by ~15%.Comparative studies with a Random Forest classifier show the advantage of anunsupervised learning approach over traditional supervised learning techniques.A statistical analysis based on Distribution Separability Criterion andIntrinsic Dimensionality Estimation substantiates the effectiveness of ourapproach in learning better representations for satellite imagery.
arxiv-13500-267 | Hardness of Online Sleeping Combinatorial Optimization Problems | http://arxiv.org/pdf/1509.03600v2.pdf | author:Satyen Kale, Chansoo Lee, Dávid Pál category:cs.LG cs.DS published:2015-09-11 summary:We show that several online combinatorial optimization problems that admitefficient no-regret algorithms become computationally hard in the sleepingsetting where a subset of actions becomes unavailable in each round.Specifically, we show that the sleeping versions of these problems, usingper-action regret as the performance measure, are at least as hard as PAClearning DNF expressions, a long standing open problem. We show hardness forthe sleeping versions of Online Shortest Paths, Online Minimum Spanning Tree,Online $k$-Subsets, Online $k$-Truncated Permutations, Online Minimum Cut, andOnline Bipartite Matching. The hardness result for the sleeping version of theOnline Shortest Paths problem resolves an open problem presented at COLT 2015(Koolen et al., 2015). We also give an efficient reduction of the task ofminimizing per-action regret to the task of minimizing ranking regret, adifferent performance measure. Thus, existing efficient algorithms forminimizing ranking regret under various restrictions of the adversary can beused to efficiently minimize per-action regret as well.
arxiv-13500-268 | A Parallel Corpus of Translationese | http://arxiv.org/pdf/1509.03611v2.pdf | author:Ella Rabinovich, Shuly Wintner, Ofek Luis Lewinsohn category:cs.CL published:2015-09-11 summary:We describe a set of bilingual English--French and English--German parallelcorpora in which the direction of translation is accurately and reliablyannotated. The corpora are diverse, consisting of parliamentary proceedings,literary works, transcriptions of TED talks and political commentary. They willbe instrumental for research of translationese and its applications to (humanand machine) translation; specifically, they can be used for the task oftranslationese identification, a research direction that enjoys a growinginterest in recent years. To validate the quality and reliability of thecorpora, we replicated previous results of supervised and unsupervisedidentification of translationese, and further extended the experiments toadditional datasets and languages.
arxiv-13500-269 | A reliable order-statistics-based approximate nearest neighbor search algorithm | http://arxiv.org/pdf/1509.03453v1.pdf | author:Luisa Verdoliva, Davide Cozzolino, Giovanni Poggi category:cs.CV published:2015-09-11 summary:We propose a new algorithm for fast approximate nearest neighbor search basedon the properties of ordered vectors. Data vectors are classified based on theindex and sign of their largest components, thereby partitioning the space in anumber of cones centered in the origin. The query is itself classified, and thesearch starts from the selected cone and proceeds to neighboring ones. Overall,the proposed algorithm corresponds to locality sensitive hashing in the spaceof directions, with hashing based on the order of components. Thanks to thestatistical features emerging through ordering, it deals very well with thechallenging case of unstructured data, and is a valuable building block formore complex techniques dealing with structured data. Experiments on bothsimulated and real-world data prove the proposed algorithm to provide astate-of-the-art performance.
arxiv-13500-270 | Learning Sparse Feature Representations using Probabilistic Quadtrees and Deep Belief Nets | http://arxiv.org/pdf/1509.03413v1.pdf | author:Saikat Basu, Manohar Karki, Sangram Ganguly, Robert DiBiano, Supratik Mukhopadhyay, Ramakrishna Nemani category:cs.CV published:2015-09-11 summary:Learning sparse feature representations is a useful instrument for solving anunsupervised learning problem. In this paper, we present three labeledhandwritten digit datasets, collectively called n-MNIST. Then, we propose anovel framework for the classification of handwritten digits that learns sparserepresentations using probabilistic quadtrees and Deep Belief Nets. On theMNIST and n-MNIST datasets, our framework shows promising results andsignificantly outperforms traditional Deep Belief Networks.
arxiv-13500-271 | Person Recognition in Personal Photo Collections | http://arxiv.org/pdf/1509.03502v2.pdf | author:Seong Joon Oh, Rodrigo Benenson, Mario Fritz, Bernt Schiele category:cs.CV published:2015-09-11 summary:Recognising persons in everyday photos presents major challenges (occludedfaces, different clothing, locations, etc.) for machine vision. We propose aconvnet based person recognition system on which we provide an in-depthanalysis of informativeness of different body cues, impact of training data,and the common failure modes of the system. In addition, we discuss thelimitations of existing benchmarks and propose more challenging ones. Ourmethod is simple and is built on open source and open data, yet it improves thestate of the art results on a large dataset of social media photos (PIPA).
arxiv-13500-272 | OCR accuracy improvement on document images through a novel pre-processing approach | http://arxiv.org/pdf/1509.03456v1.pdf | author:Abdeslam El Harraj, Naoufal Raissouni category:cs.CV published:2015-09-11 summary:Digital camera and mobile document image acquisition are new trends arisingin the world of Optical Character Recognition and text detection. In somecases, such process integrates many distortions and produces poorly scannedtext or text-photo images and natural images, leading to an unreliable OCRdigitization. In this paper, we present a novel nonparametric and unsupervisedmethod to compensate for undesirable document image distortions aiming tooptimally improve OCR accuracy. Our approach relies on a very efficient stackof document image enhancing techniques to recover deformation of the entiredocument image. First, we propose a local brightness and contrast adjustmentmethod to effectively handle lighting variations and the irregular distributionof image illumination. Second, we use an optimized greyscale conversionalgorithm to transform our document image to greyscale level. Third, we sharpenthe useful information in the resulting greyscale image using Un-sharp Maskingmethod. Finally, an optimal global binarization approach is used to prepare thefinal document image to OCR recognition. The proposed approach cansignificantly improve text detection rate and optical character recognitionaccuracy. To demonstrate the efficiency of our approach, an exhaustiveexperimentation on a standard dataset is presented.
arxiv-13500-273 | Fingerprint Recognition Using Translation Invariant Scattering Network | http://arxiv.org/pdf/1509.03542v3.pdf | author:Shervin Minaee, Yao Wang category:cs.CV published:2015-09-11 summary:Fingerprint recognition has drawn a lot of attention during last decades.Different features and algorithms have been used for fingerprint recognition inthe past. In this paper, a powerful image representation called scatteringtransform/network, is used for recognition. Scattering network is aconvolutional network where its architecture and filters are predefined wavelettransforms. The first layer of scattering representation is similar to siftdescriptors and the higher layers capture higher frequency content of thesignal. After extraction of scattering features, their dimensionality isreduced by applying principal component analysis (PCA). At the end, multi-classSVM is used to perform template matching for the recognition task. The proposedscheme is tested on a well-known fingerprint database and has shown promisingresults with the best accuracy rate of 98\%.
arxiv-13500-274 | Learning the Number of Autoregressive Mixtures in Time Series Using the Gap Statistics | http://arxiv.org/pdf/1509.03381v1.pdf | author:Jie Ding, Mohammad Noshad, Vahid Tarokh category:stat.ML published:2015-09-11 summary:Using a proper model to characterize a time series is crucial in makingaccurate predictions. In this work we use time-varying autoregressive process(TVAR) to describe non-stationary time series and model it as a mixture ofmultiple stable autoregressive (AR) processes. We introduce a new modelselection technique based on Gap statistics to learn the appropriate number ofAR filters needed to model a time series. We define a new distance measurebetween stable AR filters and draw a reference curve that is used to measurehow much adding a new AR filter improves the performance of the model, and thenchoose the number of AR filters that has the maximum gap with the referencecurve. To that end, we propose a new method in order to generate uniform randomstable AR filters in root domain. Numerical results are provided demonstratingthe performance of the proposed approach.
arxiv-13500-275 | Efficient Convolutional Neural Networks for Pixelwise Classification on Heterogeneous Hardware Systems | http://arxiv.org/pdf/1509.03371v1.pdf | author:Fabian Tschopp category:cs.CV cs.AI I.2.6; I.5.1 published:2015-09-11 summary:This work presents and analyzes three convolutional neural network (CNN)models for efficient pixelwise classification of images. When usingconvolutional neural networks to classify single pixels in patches of a wholeimage, a lot of redundant computations are carried out when using slidingwindow networks. This set of new architectures solve this issue by eitherremoving redundant computations or using fully convolutional architectures thatinherently predict many pixels at once. The implementations of the three models are accessible through a new utilityon top of the Caffe library. The utility provides support for a wide range ofimage input and output formats, pre-processing parameters and methods toequalize the label histogram during training. The Caffe library has beenextended by new layers and a new backend for availability on a wider range ofhardware such as CPUs and GPUs through OpenCL. On AMD GPUs, speedups of $54\times$ (SK-Net), $437\times$ (U-Net) and$320\times$ (USK-Net) have been observed, taking the SK equivalent SW (slidingwindow) network as the baseline. The label throughput is up to one megapixelper second. The analyzed neural networks have distinctive characteristics that applyduring training or processing, and not every data set is suitable to everyarchitecture. The quality of the predictions is assessed on two neural tissuedata sets, of which one is the ISBI 2012 challenge data set. Two different lossfunctions, Malis loss and Softmax loss, were used during training. The whole pipeline, consisting of models, interface and modified Caffelibrary, is available as Open Source software under the working title ProjectGreentea.
arxiv-13500-276 | A deep matrix factorization method for learning attribute representations | http://arxiv.org/pdf/1509.03248v1.pdf | author:George Trigeorgis, Konstantinos Bousmalis, Stefanos Zafeiriou, Bjoern W. Schuller category:cs.CV cs.LG stat.ML published:2015-09-10 summary:Semi-Non-negative Matrix Factorization is a technique that learns alow-dimensional representation of a dataset that lends itself to a clusteringinterpretation. It is possible that the mapping between this new representationand our original data matrix contains rather complex hierarchical informationwith implicit lower-level hidden attributes, that classical one levelclustering methodologies can not interpret. In this work we propose a novelmodel, Deep Semi-NMF, that is able to learn such hidden representations thatallow themselves to an interpretation of clustering according to different,unknown attributes of a given dataset. We also present a semi-supervisedversion of the algorithm, named Deep WSF, that allows the use of (partial)prior information for each of the known attributes of a dataset, that allowsthe model to be used on datasets with mixed attribute knowledge. Finally, weshow that our models are able to learn low-dimensional representations that arebetter suited for clustering, but also classification, outperformingSemi-Non-negative Matrix Factorization, but also other state-of-the-artmethodologies variants.
arxiv-13500-277 | Rigid Multiview Varieties | http://arxiv.org/pdf/1509.03257v1.pdf | author:Michael Joswig, Joe Kileel, Bernd Sturmfels, André Wagner category:math.AG cs.CV math.AC 14M99, 68T45 published:2015-09-10 summary:The multiview variety from computer vision is generalized to images by $n$cameras of points linked by a distance constraint. The resultingfive-dimensional variety lives in a product of $2n$ projective planes. Wedetermine defining polynomial equations, and we explore generalizations of thisvariety to scenarios of interest in applications.
arxiv-13500-278 | Gibbs Sampling Strategies for Semantic Perception of Streaming Video Data | http://arxiv.org/pdf/1509.03242v1.pdf | author:Yogesh Girdhar, Gregory Dudek category:cs.RO cs.LG published:2015-09-10 summary:Topic modeling of streaming sensor data can be used for high level perceptionof the environment by a mobile robot. In this paper we compare various Gibbssampling strategies for topic modeling of streaming spatiotemporal data, suchas video captured by a mobile robot. Compared to previous work on online topicmodeling, such as o-LDA and incremental LDA, we show that the proposedtechnique results in lower online and final perplexity, given the realtimeconstraints.
arxiv-13500-279 | Real-time Sign Language Fingerspelling Recognition using Convolutional Neural Networks from Depth map | http://arxiv.org/pdf/1509.03001v3.pdf | author:Byeongkeun Kang, Subarna Tripathi, Truong Q. Nguyen category:cs.CV published:2015-09-10 summary:Sign language recognition is important for natural and convenientcommunication between deaf community and hearing majority. We take the highlyefficient initial step of automatic fingerspelling recognition system usingconvolutional neural networks (CNNs) from depth maps. In this work, we considerrelatively larger number of classes compared with the previous literature. Wetrain CNNs for the classification of 31 alphabets and numbers using a subset ofcollected depth data from multiple subjects. While using different learningconfigurations, such as hyper-parameter selection with and without validation,we achieve 99.99% accuracy for observed signers and 83.58% to 85.49% accuracyfor new signers. The result shows that accuracy improves as we include moredata from different subjects during training. The processing time is 3 ms forthe prediction of a single image. To the best of our knowledge, the systemachieves the highest accuracy and speed. The trained model and dataset isavailable on our repository.
arxiv-13500-280 | Recurrent Reinforcement Learning: A Hybrid Approach | http://arxiv.org/pdf/1509.03044v2.pdf | author:Xiujun Li, Lihong Li, Jianfeng Gao, Xiaodong He, Jianshu Chen, Li Deng, Ji He category:cs.LG cs.AI cs.SY published:2015-09-10 summary:Successful applications of reinforcement learning in real-world problemsoften require dealing with partially observable states. It is in general verychallenging to construct and infer hidden states as they often depend on theagent's entire interaction history and may require substantial domainknowledge. In this work, we investigate a deep-learning approach to learningthe representation of states in partially observable tasks, with minimal priorknowledge of the domain. In particular, we propose a new family of hybridmodels that combines the strength of both supervised learning (SL) andreinforcement learning (RL), trained in a joint fashion: The SL component canbe a recurrent neural networks (RNN) or its long short-term memory (LSTM)version, which is equipped with the desired property of being able to capturelong-term dependency on history, thus providing an effective way of learningthe representation of hidden states. The RL component is a deep Q-network (DQN)that learns to optimize the control for maximizing long-term rewards. Extensiveexperiments in a direct mailing campaign problem demonstrate the effectivenessand advantages of the proposed approach, which performs the best among a set ofprevious state-of-the-art methods.
arxiv-13500-281 | Performance Bounds for Pairwise Entity Resolution | http://arxiv.org/pdf/1509.03302v1.pdf | author:Matt Barnes, Kyle Miller, Artur Dubrawski category:stat.ML cs.CY cs.DB cs.LG published:2015-09-10 summary:One significant challenge to scaling entity resolution algorithms to massivedatasets is understanding how performance changes after moving beyond the realmof small, manually labeled reference datasets. Unlike traditional machinelearning tasks, when an entity resolution algorithm performs well on smallhold-out datasets, there is no guarantee this performance holds on largerhold-out datasets. We prove simple bounding properties between the performanceof a match function on a small validation set and the performance of a pairwiseentity resolution algorithm on arbitrarily sized datasets. Thus, our approachenables optimization of pairwise entity resolution algorithms for largedatasets, using a small set of labeled data.
arxiv-13500-282 | Fast low-rank estimation by projected gradient descent: General statistical and algorithmic guarantees | http://arxiv.org/pdf/1509.03025v1.pdf | author:Yudong Chen, Martin J. Wainwright category:math.ST cs.LG stat.ML stat.TH published:2015-09-10 summary:Optimization problems with rank constraints arise in many applications,including matrix regression, structured PCA, matrix completion and matrixdecomposition problems. An attractive heuristic for solving such problems is tofactorize the low-rank matrix, and to run projected gradient descent on thenonconvex factorized optimization problem. The goal of this problem is toprovide a general theoretical framework for understanding when such methodswork well, and to characterize the nature of the resulting fixed point. Weprovide a simple set of conditions under which projected gradient descent, whengiven a suitable initialization, converges geometrically to a statisticallyuseful solution. Our results are applicable even when the initial solution isoutside any region of local convexity, and even when the problem is globallyconcave. Working in a non-asymptotic framework, we show that our conditions aresatisfied for a wide range of concrete models, including matrix regression,structured PCA, matrix completion with real and quantized observations, matrixdecomposition, and graph clustering problems. Simulation results show excellentagreement with the theoretical predictions.
arxiv-13500-283 | Compatible Value Gradients for Reinforcement Learning of Continuous Deep Policies | http://arxiv.org/pdf/1509.03005v1.pdf | author:David Balduzzi, Muhammad Ghifary category:cs.LG cs.AI cs.NE stat.ML published:2015-09-10 summary:This paper proposes GProp, a deep reinforcement learning algorithm forcontinuous policies with compatible function approximation. The algorithm isbased on two innovations. Firstly, we present a temporal-difference basedmethod for learning the gradient of the value-function. Secondly, we presentthe deviator-actor-critic (DAC) model, which comprises three neural networksthat estimate the value function, its gradient, and determine the actor'spolicy respectively. We evaluate GProp on two challenging tasks: a contextualbandit problem constructed from nonparametric regression datasets that isdesigned to probe the ability of reinforcement learning algorithms toaccurately estimate gradients; and the octopus arm, a challenging reinforcementlearning benchmark. GProp is competitive with fully supervised methods on thebandit task and achieves the best performance to date on the octopus arm.
arxiv-13500-284 | Use it or Lose it: Selective Memory and Forgetting in a Perpetual Learning Machine | http://arxiv.org/pdf/1509.03185v1.pdf | author:Andrew J. R. Simpson category:cs.LG 68Txx published:2015-09-10 summary:In a recent article we described a new type of deep neural network - aPerpetual Learning Machine (PLM) - which is capable of learning 'on the fly'like a brain by existing in a state of Perpetual Stochastic Gradient Descent(PSGD). Here, by simulating the process of practice, we demonstrate bothselective memory and selective forgetting when we introduce statistical recallbiases during PSGD. Frequently recalled memories are remembered, whilstmemories recalled rarely are forgotten. This results in a 'use it or lose it'stimulus driven memory process that is similar to human memory.
arxiv-13500-285 | Density Evolution in the Degree-correlated Stochastic Block Model | http://arxiv.org/pdf/1509.03281v1.pdf | author:Elchanan Mossel, Jiaming Xu category:stat.ML cs.IT math.IT math.PR published:2015-09-10 summary:There is a recent surge of interest in identifying the sharp recoverythresholds for cluster recovery under the stochastic block model. In thispaper, we address the more refined question of how many vertices that will bemisclassified on average. We consider the binary form of the stochastic blockmodel, where $n$ vertices are partitioned into two clusters with edgeprobability $a/n$ within the first cluster, $c/n$ within the second cluster,and $b/n$ across clusters. Suppose that as $n \to \infty$, $a= b+ \mu \sqrt{ b}$, $c=b+ \nu \sqrt{ b} $ for two fixed constants $\mu, \nu$, and $b \to \infty$with $b=n^{o(1)}$. When the cluster sizes are balanced and $\mu \neq \nu$, weshow that the minimum fraction of misclassified vertices on average is given by$Q(\sqrt{v^*})$, where $Q(x)$ is the Q-function for standard normal, $v^*$ isthe unique fixed point of $v= \frac{(\mu-\nu)^2}{16} + \frac{ (\mu+\nu)^2 }{16}\mathbb{E}[ \tanh(v+ \sqrt{v} Z)],$ and $Z$ is standard normal. Moreover, theminimum misclassified fraction on average is attained by a local algorithm,namely belief propagation, in time linear in the number of edges. Our prooftechniques are based on connecting the cluster recovery problem to treereconstruction problems, and analyzing the density evolution of beliefpropagation on trees with Gaussian approximations.
arxiv-13500-286 | STC: A Simple to Complex Framework for Weakly-supervised Semantic Segmentation | http://arxiv.org/pdf/1509.03150v1.pdf | author:Yunchao Wei, Xiaodan Liang, Yunpeng Chen, Xiaohui Shen, Ming-Ming Cheng, Yao Zhao, Shuicheng Yan category:cs.CV published:2015-09-10 summary:Recently, significant improvement has been made on semantic objectsegmentation due to the development of deep convolutional neural networks(DCNNs). Training such a DCNN usually relies on a large number of images withpixel-level segmentation masks, and annotating these images is very costly interms of both finance and human effort. In this paper, we propose a simple tocomplex (STC) framework in which only image-level annotations are utilized tolearn DCNNs for semantic segmentation. Specifically, we first train an initialsegmentation network called Initial-DCNN with the saliency maps of simpleimages (i.e., those with a single category of major object(s) and cleanbackground). These saliency maps can be automatically obtained by existingbottom-up salient object detection techniques, where no supervision informationis needed. Then, a better network called Enhanced-DCNN is learned withsupervision from the predicted segmentation masks of simple images based on theInitial-DCNN as well as the image-level annotations. Finally, more pixel-levelsegmentation masks of complex images (two or more categories of objects withcluttered background), which are inferred by using Enhanced-DCNN andimage-level annotations, are utilized as the supervision information to learnthe Powerful-DCNN for semantic segmentation. Our method utilizes $40$K simpleimages from Flickr.com and 10K complex images from PASCAL VOC for step-wiselyboosting the segmentation network. Extensive experimental results on PASCAL VOC2012 segmentation benchmark demonstrate that the proposed STC frameworkoutperforms the state-of-the-art algorithms for weakly-supervised semanticsegmentation by a large margin (e.g., 10.6% over MIL-ILP-seg [1]).
arxiv-13500-287 | On the evolution of word usage of classical Chinese poetry | http://arxiv.org/pdf/1509.04556v2.pdf | author:Liang Liu category:physics.soc-ph cs.CL published:2015-09-10 summary:The hierarchy of classical Chinese poetry has been broadly acknowledged by anumber of studies in Chinese literature. However, quantitative investigationsabout the evolution of classical Chinese poetry are limited. The primary goalof this study is to provide quantitative evidence of the evolutionary linkages,with emphasis on word usage, among different period genres for classicalChinese poetry. Specifically, various statistical analyses were performed tofind and compare the patterns of word usage in the poems of nine period genres,including shi jing, chu ci, Han shi , Jin shi, Tang shi, Song shi, Yuan shi,Ming shi, and Qing shi. The result of analysis indicates that each of nineperiod genres has unique patterns of word usage, with some Chinese charactersbeing preferably used by the poems of a particular period genre. The analysison the general pattern of word preference implies a decreasing trend in the useof ancient Chinese characters along the timeline of dynastic types of classicalChinese poetry. The phylogenetic analysis based on the distance matrix suggeststhat the evolution of different types of classical Chinese poetry is congruentwith their chronological order, suggesting that word frequencies contain usefulphylogenetic information and thus can be used to infer evolutionary linkagesamong various types of classical Chinese poetry. The statistical analysesconducted in this study can be applied to the data sets of general Chineseliterature. Such analyses can provide quantitative insights about the evolutionof general Chinese literature.
arxiv-13500-288 | A Dual Fast and Slow Feature Interaction in Biologically Inspired Visual Recognition of Human Action | http://arxiv.org/pdf/1509.02587v2.pdf | author:Bardia Yousefi, C. K. Loo category:cs.CV published:2015-09-09 summary:Computational neuroscience studies that have examined human visual systemthrough functional magnetic resonance imaging (fMRI) have identified a modelwhere the mammalian brain pursues two distinct pathways (for recognition ofbiological movement tasks). In the brain, dorsal stream analyzes theinformation of motion (optical flow), which is the fast features, and ventralstream (form pathway) analyzes form information (through active basis modelbased incremental slow feature analysis ) as slow features. The proposedapproach suggests the motion perception of the human visual system composes offast and slow feature interactions that identifies biological movements. Formfeatures in the visual system biologically follows the application of activebasis model with incremental slow feature analysis for the extraction of theslowest form features of human objects movements in the ventral stream.Applying incremental slow feature analysis provides an opportunity to use theaction prototypes. To extract the slowest features episodic observation isrequired but the fast features updates the processing of motion information inevery frames. Experimental results have shown promising accuracy for theproposed model and good performance with two datasets (KTH and Weizmann).
arxiv-13500-289 | Asymptotically Optimal Multi-Armed Bandit Policies under a Cost Constraint | http://arxiv.org/pdf/1509.02857v3.pdf | author:Apostolos N. Burnetas, Odysseas Kanavetas, Michael N. Katehakis category:stat.ML math.OC published:2015-09-09 summary:We develop asymptotically optimal policies for the multi armed bandit (MAB),problem, under a cost constraint. This model is applicable in situations whereeach sample (or activation) from a population (bandit) incurs a known banditdependent cost. Successive samples from each population are iid randomvariables with unknown distribution. The objective is to design a feasiblepolicy for deciding from which population to sample from, so as to maximize theexpected sum of outcomes of $n$ total samples or equivalently to minimize theregret due to lack on information on sample distributions, For this problem weconsider the class of feasible uniformly fast (f-UF) convergent policies, thatsatisfy the cost constraint sample-path wise. We first establish a necessaryasymptotic lower bound for the rate of increase of the regret function of f-UFpolicies. Then we construct a class of f-UF policies and provide conditionsunder which they are asymptotically optimal within the class of f-UF policies,achieving this asymptotic lower bound. At the end we provide the explicit formof such policies for the case in which the unknown distributions are Normalwith unknown means and known variances.
arxiv-13500-290 | Finite Dictionary Variants of the Diffusion KLMS Algorithm | http://arxiv.org/pdf/1509.02730v1.pdf | author:Rangeet Mitra, Vimal Bhatia category:cs.SY cs.DC cs.IT cs.LG math.IT published:2015-09-09 summary:The diffusion based distributed learning approaches have been found to be aviable solution for learning over linearly separable datasets over a network.However, approaches till date are suitable for linearly separable datasets andneed to be extended to scenarios in which we need to learn a non-linearity. Insuch scenarios, the recently proposed diffusion kernel least mean squares(KLMS) has been found to be performing better than diffusion least mean squares(LMS). The drawback of diffusion KLMS is that it requires infinite storage forobservations (also called dictionary). This paper formulates the diffusion KLMSin a fixed budget setting such that the storage requirement is curtailed whilemaintaining appreciable performance in terms of convergence. Simulations havebeen carried out to validate the two newly proposed algorithms named asquantised diffusion KLMS (QDKLMS) and fixed budget diffusion KLMS (FBDKLMS)against KLMS, which indicate that both the proposed algorithms deliver betterperformance as compared to the KLMS while reducing the dictionary size storagerequirement.
arxiv-13500-291 | Semismooth Newton Coordinate Descent Algorithm for Elastic-Net Penalized Huber Loss and Quantile Regression | http://arxiv.org/pdf/1509.02957v1.pdf | author:Congrui Yi, Jian Huang category:stat.CO stat.ML published:2015-09-09 summary:We propose a semismooth Newton coordinate descent (SNCD) algorithm forelastic-net penalized robust regression with Huber loss and quantileregression. The SNCD is a novel combination of the semismooth Newton andcoordinate descent algorithms. It is designed for loss functions with onlyfirst order derivatives and is scalable to high-dimensional models. Unlike thestandard coordinate descent method, the SNCD updates the regression parametersand the corresponding subdifferentials based on the concept of Newtonderivatives. In addition, an adaptive version of the "strong rule" forscreening predictors is incorporated to gain extra efficiency. As an importantapplication of the proposed algorithm, we show that the SNCD can be used tocompute the solution paths for penalized quantile regression. We establish theconvergence properties of the algorithm. Through numerical experiments, wedemonstrate that the proposed algorithm works well for high-dimensional datawith heavy-tailed errors, and that for quantile regression SNCD is considerablyfaster than the existing method and has better optimization performance. Abreast cancer gene expression data set is used to illustrate the proposedalgorithm.
arxiv-13500-292 | Proposal-free Network for Instance-level Object Segmentation | http://arxiv.org/pdf/1509.02636v2.pdf | author:Xiaodan Liang, Yunchao Wei, Xiaohui Shen, Jianchao Yang, Liang Lin, Shuicheng Yan category:cs.CV published:2015-09-09 summary:Instance-level object segmentation is an important yet under-explored task.The few existing studies are almost all based on region proposal methods toextract candidate segments and then utilize object classification to producefinal results. Nonetheless, generating accurate region proposals itself isquite challenging. In this work, we propose a Proposal-Free Network (PFN ) toaddress the instance-level object segmentation problem, which outputs theinstance numbers of different categories and the pixel-level information on 1)the coordinates of the instance bounding box each pixel belongs to, and 2) theconfidences of different categories for each pixel, based on pixel-to-pixeldeep convolutional neural network. All the outputs together, by using anyoff-the-shelf clustering method for simple post-processing, can naturallygenerate the ultimate instance-level object segmentation results. The whole PFNcan be easily trained in an end-to-end way without the requirement of aproposal generation stage. Extensive evaluations on the challenging PASCAL VOC2012 semantic segmentation benchmark demonstrate that the proposed PFN solutionwell beats the state-of-the-arts for instance-level object segmentation. Inparticular, the $AP^r$ over 20 classes at 0.5 IoU reaches 58.7% by PFN,significantly higher than 43.8% and 46.3% by the state-of-the-art algorithms,SDS [9] and [16], respectively.
arxiv-13500-293 | Shape Interaction Matrix Revisited and Robustified: Efficient Subspace Clustering with Corrupted and Incomplete Data | http://arxiv.org/pdf/1509.02649v1.pdf | author:Pan Ji, Mathieu Salzmann, Hongdong Li category:cs.CV published:2015-09-09 summary:The Shape Interaction Matrix (SIM) is one of the earliest approaches toperforming subspace clustering (i.e., separating points drawn from a union ofsubspaces). In this paper, we revisit the SIM and reveal its connections toseveral recent subspace clustering methods. Our analysis lets us derive asimple, yet effective algorithm to robustify the SIM and make it applicable torealistic scenarios where the data is corrupted by noise. We justify our methodby intuitive examples and the matrix perturbation theory. We then show how thisapproach can be extended to handle missing data, thus yielding an efficient andgeneral subspace clustering algorithm. We demonstrate the benefits of ourapproach over state-of-the-art subspace clustering methods on severalchallenging motion segmentation and face clustering problems, where the dataincludes corrupted and missing measurements.
arxiv-13500-294 | Dictionary Learning and Sparse Coding for Third-order Super-symmetric Tensors | http://arxiv.org/pdf/1509.02970v1.pdf | author:Piotr Koniusz, Anoop Cherian category:cs.CV published:2015-09-09 summary:Super-symmetric tensors - a higher-order extension of scatter matrices - arebecoming increasingly popular in machine learning and computer vision formodelling data statistics, co-occurrences, or even as visual descriptors.However, the size of these tensors are exponential in the data dimensionality,which is a significant concern. In this paper, we study third-ordersuper-symmetric tensor descriptors in the context of dictionary learning andsparse coding. Our goal is to approximate these tensors as sparse coniccombinations of atoms from a learned dictionary, where each atom is a symmetricpositive semi-definite matrix. Apart from the significant benefits to tensorcompression that this framework provides, our experiments demonstrate that thesparse coefficients produced by the scheme lead to better aggregation ofhigh-dimensional data, and showcases superior performance on two commoncomputer vision tasks compared to the state-of-the-art.
arxiv-13500-295 | Clustering by Hierarchical Nearest Neighbor Descent (H-NND) | http://arxiv.org/pdf/1509.02805v3.pdf | author:Teng Qiu, Yongjie Li category:stat.ML cs.CV cs.LG stat.ME published:2015-09-09 summary:Previously in 2014, we proposed the Nearest Descent (ND) method, capable ofgenerating an efficient Graph, called the in-tree (IT). Due to some beautifuland effective features, this IT structure proves well suited for dataclustering. Although there exist some redundant edges in IT, they usually havesalient features and thus it is not hard to remove them. Subsequently, in order to prevent the seemingly redundant edges fromoccurring, we proposed the Nearest Neighbor Descent (NND) by adding the"Neighborhood" constraint on ND. Consequently, clusters automatically emerged,without the additional requirement of removing the redundant edges. However,NND proved still not perfect, since it brought in a new yet worse problem, the"over-partitioning" problem. Now, in this paper, we propose a method, called the Hierarchical NearestNeighbor Descent (H-NND), which overcomes the over-partitioning problem of NNDvia using the hierarchical strategy. Specifically, H-NND uses ND to effectivelymerge the over-segmented sub-graphs or clusters that NND produces. Like ND,H-NND also generates the IT structure, in which the redundant edges once againappear. This seemingly comes back to the situation that ND faces. However,compared with ND, the redundant edges in the IT structure generated by H-NNDgenerally become more salient, thus being much easier and more reliable to beidentified even by the simplest edge-removing method which takes the edgelength as the only measure. In other words, the IT structure constructed byH-NND becomes more fitted for data clustering. We prove this on severalclustering datasets of varying shapes, dimensions and attributes. Besides,compared with ND, H-NND generally takes less computation time to construct theIT data structure for the input data.
arxiv-13500-296 | Coarse-to-Fine Sequential Monte Carlo for Probabilistic Programs | http://arxiv.org/pdf/1509.02962v1.pdf | author:Andreas Stuhlmüller, Robert X. D. Hawkins, N. Siddharth, Noah D. Goodman category:cs.AI stat.ML published:2015-09-09 summary:Many practical techniques for probabilistic inference require a sequence ofdistributions that interpolate between a tractable distribution and anintractable distribution of interest. Usually, the sequences used are simple,e.g., based on geometric averages between distributions. When models areexpressed as probabilistic programs, the models themselves are highlystructured objects that can be used to derive annealing sequences that are moresensitive to domain structure. We propose an algorithm for transformingprobabilistic programs to coarse-to-fine programs which have the same marginaldistribution as the original programs, but generate the data at increasinglevels of detail, from coarse to fine. We apply this algorithm to an Isingmodel, its depth-from-disparity variation, and a factorial hidden Markov model.We show preliminary evidence that the use of coarse-to-fine models can makeexisting generic inference algorithms more efficient.
arxiv-13500-297 | Asynchronous Distributed ADMM for Large-Scale Optimization- Part II: Linear Convergence Analysis and Numerical Performance | http://arxiv.org/pdf/1509.02604v1.pdf | author:Tsung-Hui Chang, Wei-Cheng Liao, Mingyi Hong, Xiangfeng Wang category:cs.DC cs.LG cs.SY published:2015-09-09 summary:The alternating direction method of multipliers (ADMM) has been recognized asa versatile approach for solving modern large-scale machine learning and signalprocessing problems efficiently. When the data size and/or the problemdimension is large, a distributed version of ADMM can be used, which is capableof distributing the computation load and the data set to a network of computingnodes. Unfortunately, a direct synchronous implementation of such algorithmdoes not scale well with the problem size, as the algorithm speed is limited bythe slowest computing nodes. To address this issue, in a companion paper, wehave proposed an asynchronous distributed ADMM (AD-ADMM) and studied itsworst-case convergence conditions. In this paper, we further the study bycharacterizing the conditions under which the AD-ADMM achieves linearconvergence. Our conditions as well as the resulting linear rates reveal theimpact that various algorithm parameters, network delay and network size haveon the algorithm performance. To demonstrate the superior time efficiency ofthe proposed AD-ADMM, we test the AD-ADMM on a high-performance computercluster by solving a large-scale logistic regression problem.
arxiv-13500-298 | Statistical Inference, Learning and Models in Big Data | http://arxiv.org/pdf/1509.02900v2.pdf | author:Beate Franke, Jean-François Plante, Ribana Roscher, Annie Lee, Cathal Smyth, Armin Hatefi, Fuqi Chen, Einat Gil, Alexander Schwing, Alessandro Selvitella, Michael M. Hoffman, Roger Grosse, Dieter Hendricks, Nancy Reid category:stat.ML cs.LG 62-07 published:2015-09-09 summary:The need for new methods to deal with big data is a common theme in mostscientific fields, although its definition tends to vary with the context.Statistical ideas are an essential part of this, and as a partial response, athematic program on statistical inference, learning, and models in big data washeld in 2015 in Canada, under the general direction of the Canadian StatisticalSciences Institute, with major funding from, and most activities located at,the Fields Institute for Research in Mathematical Sciences. This paper gives anoverview of the topics covered, describing challenges and strategies that seemcommon to many different areas of application, and including some examples ofapplications to make these challenges and strategies more concrete.
arxiv-13500-299 | Liberating language research from dogmas of the 20th century | http://arxiv.org/pdf/1509.03295v3.pdf | author:Ramon Ferrer-i-Cancho, Carlos Gómez-Rodríguez category:cs.CL cs.SI physics.soc-ph published:2015-09-09 summary:A commentary on the article "Large-scale evidence of dependency lengthminimization in 37 languages" by Futrell, Mahowald & Gibson (PNAS 2015 112 (33)10336-10341).
arxiv-13500-300 | Asynchronous Distributed ADMM for Large-Scale Optimization- Part I: Algorithm and Convergence Analysis | http://arxiv.org/pdf/1509.02597v2.pdf | author:Tsung-Hui Chang, Mingyi Hong, Wei-Cheng Liao, Xiangfeng Wang category:cs.DC cs.LG cs.SY published:2015-09-09 summary:Aiming at solving large-scale learning problems, this paper studiesdistributed optimization methods based on the alternating direction method ofmultipliers (ADMM). By formulating the learning problem as a consensus problem,the ADMM can be used to solve the consensus problem in a fully parallel fashionover a computer network with a star topology. However, traditional synchronizedcomputation does not scale well with the problem size, as the speed of thealgorithm is limited by the slowest workers. This is particularly true in aheterogeneous network where the computing nodes experience differentcomputation and communication delays. In this paper, we propose an asynchronousdistributed ADMM (AD-AMM) which can effectively improve the time efficiency ofdistributed optimization. Our main interest lies in analyzing the convergenceconditions of the AD-ADMM, under the popular partially asynchronous model,which is defined based on a maximum tolerable delay of the network.Specifically, by considering general and possibly non-convex cost functions, weshow that the AD-ADMM is guaranteed to converge to the set ofKarush-Kuhn-Tucker (KKT) points as long as the algorithm parameters are chosenappropriately according to the network delay. We further illustrate that theasynchrony of the ADMM has to be handled with care, as slightly modifying theimplementation of the AD-ADMM can jeopardize the algorithm convergence, evenunder a standard convex setting.
