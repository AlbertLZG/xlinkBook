LTI11344 | Machine Learning in Practice | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11344&SEMESTER=S15 | instructors:Rose, Carolyn description:Machine Learning is concerned with computer programs that enable the behavior of a computer to be learned from examples or experience rather than dictated through rules written by hand.  It has practical value in many application areas of computer science such as on-line communities and digital libraries.  This class is meant to teach the practical side of machine learning for applications, such as mining newsgroup data or building adaptive user interfaces.  The emphasis will be on learning the process of applying machine learning effectively to a variety of problems rather than emphasizing an understanding of the theory behind what makes machine learning work.  This course does not assume any prior exposure to machine learning theory or practice. In the first 2/3 of the course, we will cover a wide range of learning algorithms that can be applied to a variety of problems.  In particular, we will cover topics such as decision trees, rule based classification, support vector machines, Bayesian networks, and clustering. In the final third of the class, we will go into more depth on one application area, namely the application of machine learning to problems involving text processing, such as information retrieval or text categorization.
LTI11345 | Undergrad Independent Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11345&SEMESTER=S15 | description:None
LTI11390 | LTI Minor Project - Juniors | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11390&SEMESTER=S15 | instructors:Black, Alan description:None
LTI11411 | Natural Language Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11411&SEMESTER=S15 | prereq:15122 instructors:Black, Alan description:This course will introduce students to the highly interdisciplinary area of Artificial Intelligence known alternately as Natural Language Processing (NLP) and Computational Linguistics. The course aims to cover the techniques used today in software that does useful things with text in human languages like English and Chinese. Applications of NLP include automatic translation between languages, extraction and summarization of information in documents, question answering and dialog systems, and conversational agents. This course will focus on core representations and algorithms, with some time spent on real-world applications. Because modern NLP relies so heavily on Machine Learning, we'll cover the basics of discrete classification and probabilistic modeling as we go. Good computational linguists also know about Linguistics, so topics in linguistics (phonology, morphology, and syntax) will be covered when fitting. From a software engineering perspective, there will be an emphasis on rapid prototyping, a useful skill in many other areas of Computer Science. In particular, we will introduce some high-level languages (e.g., regular expressions and Dyna) and some scripting languages (e.g., Python and Perl) that can greatly simplify prototype implementation.
LTI11441 | Machine Learning for Text Mining | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11441&SEMESTER=S15 | instructors:Yang, Yiming description:This course provides a comprehensive introduction to the theory and implementation of algorithms for organizing and searching large text collections. The first half of the course studies text search engines for enterprise and Web environments; the open-source Indri search engine is used as a working example. The second half studies text mining techniques such as clustering, categorization, and information extraction. Programming assignments give hands-on experience with document ranking algorithms, categorizing documents into browsing hierarchies, and related topics.
LTI11442 | Search Engines | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11442&SEMESTER=S15 | instructors:Callan, James description:This course studies the theory, design, and implementation of text-based search engines. The core components include statistical characteristics of text, representation of information needs and documents, several important retrieval models, and experimental evaluation. The course also covers common elements of commercial search engines, for example, integration of diverse search engines into a single search service ("federated search", "vertical search"), personalized search results, diverse search results, and sponsored search. The software architecture components include design and implementation of large-scale, distributed search engines.
LTI11465 | Special Topics: Digital Signal Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11465&SEMESTER=S15 | instructors:Ramakrishnan, Bhiksha description:None
LTI11490 | LTI Minor Project - Seniors | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11490&SEMESTER=S15 | instructors:Black, Alan description:None
LTI11590 | LTI Minor Project - Advanced | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11590&SEMESTER=S15 | instructors:Black, Alan description:None
LTI11601 | Coding Boot-Camp | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11601&SEMESTER=S15 | instructors:Starzl, Ravi description:This is a masters-level course for students who have a CS undergraduate background but want to solidify their coding and algorithm skills. The course will be taught in Java, and will take a stratified approach to teaching material including fundamental coding, algorithms, coding/algorithmic problem solving, and agile development methodology.
LTI11611 | Natural Language Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11611&SEMESTER=S15 | instructors:Black, Alan description:None
LTI11631 | Seminar in Data Science: Seminar in Data Science | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11631&SEMESTER=S15 | instructors:Nyberg, Eric description:This course provides the student with a basic understanding of Data Science as an emerging scientific discipline, with interdisciplinary perspectives from computer science, business, and information policy / security. Students will read and discuss relevant publications, and attend presentations by guest speakers. Grading will be based on homework assignments related to the material covered in class sessions.
LTI11633 | MCDS Independent Study: MCDS Independent Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11633&SEMESTER=S15 | instructors:Nyberg, Eric description:An independent study course is designed by the student to cover study of a particular area of interest too the student and is used when there is no formal course available in that subject area.
LTI11641 | Machine Learning for Text Mining | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11641&SEMESTER=S15 | instructors:Yang, Yiming description:TBA
LTI11642 | Search Engines | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11642&SEMESTER=S15 | instructors:Callan, James description:This course studies the theory, design, and implementation of text-based search engines. The core components include statistical characteristics of text, representation of information needs and documents, several important retrieval models, and experimental evaluation. The course also covers common elements of commercial search engines, for example, integration of diverse search engines into a single search service ("federated search", "vertical search"), personalized search results, diverse search results, and sponsored search. The software architecture components include design and implementation of large-scale, distributed search engines.
LTI11661 | Language and Statistics | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11661&SEMESTER=S15 | instructors:Rosenfeld, Ronald description:Language technologies (search, text mining, information retrieval, speech recognition, machine translation, question answering, biological sequence analysis...) are at the forefront of this century's information revolution.  In addition to their use of machine learning, these technologies rely centrally on classic statistical estimation techniques.   Yet most CS and engineering undergraduate programs do not prepare students in this area beyond an introductory prob&stats course.  This course is designed to plug this hole.  The goal of "Language and Statistics" is to ground the data-driven techniques used in language technologies in sound statistical methodology.   We start by formulating various language technology problems in both an information theoretic framework (the source-channel paradigm) and a Bayesian framework (the Bayes classifier).  We then discuss the statistical properties of words, sentences, documents and whole languages, and the computational formalisms used to represent language.  These discussions naturally lead to specific concepts in statistical estimation.  Topics include: Zipf's distribution and type-token curves; point estimators, Maximum Likelihood estimation, bias and variance, sparseness, smoothing and clustering; interpolation, shrinkage, and backoff; entropy, cross entropy and mutual information;  decision tree models applied to language; latent variable models and the EM algorithm; hidden Markov models; exponential models and maximum entropy; semantic modeling and dimensionality reduction; probabilistic context-free grammars and syntactic language models.  The course is designed for LTI & SCS graduate students, but others are welcome.  CS UG upperclassmen who've taken it have done well, though they found it challenging.  The 11-661 version does not require the course project.  Prerequisites: Strong quantitative aptitude.  Comfort with basic UG-level probability.  Some programming skill.
LTI11663 | Applied Machine Learning | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11663&SEMESTER=S15 | instructors:Rose, Carolyn description:Machine Learning is concerned with computer programs that enable the behavior of a computer to be learned from examples or experience rather than dictated through rules written by hand.  It has practical value in many application areas of computer science such as on-line communities and digital libraries.  This class is meant to teach the practical side of machine learning for applications, such as mining newsgroup data or building adaptive user interfaces.  The emphasis will be on learning the process of applying machine learning effectively to a variety of problems rather than emphasizing an understanding of the theory behind what makes machine learning work.  This course does not assume any prior exposure to machine learning theory or practice. In the first 2/3 of the course, we will cover a wide range of learning algorithms that can be applied to a variety of problems.  In particular, we will cover topics such as decision trees, rule based classification, support vector machines, Bayesian networks, and clustering. In the final third of the class, we will go into more depth on one application area, namely the application of machine learning to problems involving text processing, such as information retrieval or text categorization.
LTI11675 | Big Data Systems in Practice | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11675&SEMESTER=S15 | instructors:Starzl, Ravi description:To be determined
LTI11690 | MIIS Directed Study | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11690&SEMESTER=S15 | instructors:Frederking, Robert description:to be determined by the department
LTI11695 | Competitive Engineering | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11695&SEMESTER=S15 | instructors:Starzl, Ravi description:In the second core course, students will be tasked with building a software application prototype for a biotech/pharmaceutical firm. Students will be introduced to a particular firm (through one of the program advisors) and will learn how to conduct and develop requirements analysis and convert that into feature definition. The customer requirements are often a moving target: they're influenced by the emergence of competitive alternatives (e.g. internal consultants, off-the-shelf software) and also by the team interaction with each others. Students will learn to create a product that best captures the best balance of the customer priorities and feasibility and distinguishing it from competitive alternatives. They will then use this learning to develop their respective prototypes. At the conclusion of the term, teams will compete with each other to determine which team's product is superior. In addition to having to apply various aspects of software development and computational learning, the course will help to provide students with some key insights into how biotech/pharmaceutical businesses operate.        In addition to concepts regarding market demand, students will learn how to aggregate and synthesize information related to demand, pricing and competition. They will then apply this learning to define and prioritize market driven requirements as it relates to a product. This information will then be used to build a product development plan. Students will utilize methods to enhance product quality and customer satisfaction: benchmarking; industry and customer analyses; project metrics, and a range of customer relationship management tools.
LTI11696 | MIIS Capstone Planning Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11696&SEMESTER=S15 | instructors:Nyberg, Eric description:The MIIS Capstone Planning Seminar prepares students to complete the MIIS Capstone Project in the following semester.  Students are organized into teams that will work together to complete the capstone project.  They define project goals, requirements, success metrics, and deliverables; and they identify and acquires data, software, and other resources required for successful completion of the project. The planning seminar must be completed in the semester prior to taking the capstone project.
LTI11699 | MSBIC Program Capstone | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11699&SEMESTER=S15 | instructors:Vu, Du (John) description:The final term will integrate all of the acquired learning in the program towards the development of a formal business plan and software product beta. The effort involved in the capstone project is quite intense and will consist of approximately three months of full time work for each student. The expected deliverables (features to be developed, business plan, technical documentation, etc.) must be agreed to by the course instructor at the outset of the course.    The capstone can either encompass the development of an industry sponsored software project or a software product intended for entrepreneurial startup. Students are expected to showcase their business and software projects and elicit feedback from academics, industry professionals, investors, and business executives. This phase also acts as an incubation period for companies that will be launched from the program.
LTI11700 | LTI Colloquium | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11700&SEMESTER=S15 | instructors:Lavie, Alon description:The LTI colloquium is a series of talks related to language technologies. The topics include but are not restricted to Computational Linguistics, Machine Translation, Speech Recognition and Synthesis, Information Retrieval, Computational Biology, Machine Learning, Text Mining, Knowledge Representation, Computer-Assisted Language Learning and Intelligent Language Tutoring. To get credit of the course, students are required to write either a short critique of one of the presentations or a comparison of two.
LTI11712 | Lab in NLP | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11712&SEMESTER=S15 | instructors:Lavie, Alon description:The Self-Paced Lab in NLP Algorithms is intended to complement the 11-711 lecture course by providing a chance for hands-on, in-depth exploration of various NLP paradigms. Students will study a set of on-line course materials and complete a set of programming assignments illustrating the concepts taught in the lecture course. Timing of individual assignments is left up to the student, although all assignments must be successfully completed and turned in before the end of the semester for the student to receive credit for the course.
LTI11719 | Computational Models of Discourse Analysis | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11719&SEMESTER=S15 | instructors:Rose, Carolyn description:Discourse analysis is the area of linguistics that focuses on the structure of language above the clause level.  It is interesting both in the complexity of structures that operate at that level and in the insights it offers about how personality, relationships, and community identification are revealed through patterns of language use.  A resurgence of interest in topics related to modeling language at the discourse level is in evidence at recent language technologies conferences.  This course is designed to help students get up to speed with foundational linguistic work in the area of discourse analysis, and to use these concepts to challenge the state-of-the-art in language technologies for problems that have a strong connection with those concepts, such as dialogue act tagging, sentiment analysis, and bias detection.  This is meant to be a hands on and intensely interactive course with a heavy programming component.  The course is structured around 3 week units, all but the first of which have a substantial programming assignment structured as a competition (although grades will not be assigned based on ranking within the competition, rather grades will be assigned based on demonstrated comprehension of course materials and methodology).
LTI11723 | Linguistics Lab | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11723&SEMESTER=S15 | instructors:Levin, Lorraine description:Formal Semantics is an introductory graduate course on formal linguistic semantics: Given a syntactic analysis of a natural language utterance, how can one assign the correct meaning representation to it, using a formal logical system? More details TBA.
LTI11726 | Meaning in Language Lab (Self Paced) | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11726&SEMESTER=S15 | instructors:Rose, Carolyn description:The self-paced Meaning in Language Lab is intended to follow-up on the 11-725 lecture course (Meaning in Language) by providing a chance for hands-on, in-depth, computational exploration of various semantics and pragmatics research topics. The course is self-paced and there will be no scheduled lecture times, however, students are welcome to set up meetings with the instructor as desired, and students who prefer to have a weekly or bi-monthly regularly scheduled meeting with the instructor are welcome to arrange for that. If there is sufficient interest, an informal reading group may be formed to supplement the lab work.    Students will design their own project, which they will discuss with the instructor for approval. Students are encouraged to select a topic from semantics, pragmatics, or discourse analysis, such as entailment, evidentiality, implicature, information status, or rhetorical structure, and a topic from language technologies, such as sentiment analysis or summarization, and explore how the linguistic topic applies to some aspect of the chosen language technology. Students are encouraged to contrast symbolic, formal, and knowledge based approaches with empirical approaches.    Each student will work independently. If multiple students work as a team on a particular topic, each should choose an approach that is different from the approaches used by the other students working on the same problem. Students will be responsible to set up a web page, blog, or wiki to post progress reports and other supporting documents, data, and analyses. The web space will be checked by the instructor periodically , and thus should be kept updated in order to reflect on-going progress. The web space will also serve as a shared project space in the case that students are working in a team for the project.
LTI11727 | Computational Semantics for NLP | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11727&SEMESTER=S15 | instructors:Hovy, Eduard description:This course surveys semantics from a language processing perspective.  It is divided into three main sections supplemented with a substantive semester-long computational project.  The first section addresses traditional topics of computational semantics and semantic processing and representation systems.  The second focuses on computational lexical semantics, including resources such as WordNet, Framenet, and some word-based ontologies, and their computational applications, such as word sense disambiguation, entailment, etc., and briefly the semantic web.  The third section covers modern statistics-based distributional models of semantics.  Each week focuses on one topic, covered by the lecturers, and will include one or two core introductory readings plus several optional more advanced readings.  All students will read and discuss the introductory readings while each student will be expected to read advanced papers on at least two topics.
LTI11728 | Advanced Seminar in SemanticsThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11728&SEMESTER=S15 | instructors:Mitamura, Teruko description:This course is an introductory survey of computational semantics from a language processing perspective. The first section is devoted to traditional topics of computational semantics and semantic processing and representation systems.  The second focuses on lexical semantics, including resources such as WordNet, Framenet, and some word-based ontologies.  In the third month we consider computational applications of semantics, such as word sense disambiguation, entailment, etc., and also look at the semantic web.  The fourth month ends with modern statistics-based distributional models of semantics.  Each week, we cover one topic, which will be introduced by the faculty and will include one or more appropriate readings that will be reviewed by students and discussed in class.  This is a 6-unit reading seminar that meets once a week.
LTI11731 | Machine Translation | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11731&SEMESTER=S15 | instructors:Dyer, Christopher description:Instructors: Chris Dyer (leader), Alon Lavie.  Prerequisites: 11-711 "Algorithms for NLP" or equivalent background is recommended. Course   Machine Translation is an introductory graduate-level course surveying the primary approaches and methods for developing modern state-of-the-art automated language translation systems.  The main objectives of the course are: Obtain a basic understanding of modern MT systems and MT-related issues. Learn about theory and approaches in Machine Translation and implement the main components of statistical MT systems.
LTI11734 | Advanced Machine Translation SeminarThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11734&SEMESTER=S15 | prereq:11731 instructors:Lavie, Alon description:The Advanced Machine Translation Seminar is a graduate-level seminar on current research topics in Machine Translation. The seminar will cover recent research on different approaches to Machine Translation (Statistical MT, Example-based MT, Interlingua and rule-based approaches, hybrid approaches, etc.). Related problems that are common to many of the various approaches will also be discussed, including the acquisition and construction of language resources for MT (translation lexicons, language models, etc.), methods for building large sentence-aligned bilingual corpora, automatic word alignment of sentence-parallel data, etc. The material covered will be mostly drawn from recent conference and journal publications on the topics of interest and will vary from year to year. The course will be run in a seminar format, where the students prepare presentations of selected research papers and lead in class discussion about the presented papers.   Prerequisites & corequisites:     11-731: Machine Translation, or instructor approval.
LTI11741 | Machine Learning for Text Mining | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11741&SEMESTER=S15 | instructors:Yang, Yiming description:This course studies the theory, design, and implementation of text-based information systems. The Information Retrieval core components of the course include statistical characteristics of text, representation of information needs and documents, several important retrieval models (Boolean, vector space, probabilistic, inference net, language modeling), clustering algorithms, automatic text categorization, and experimental evaluation. The software architecture components include design and implementation of high-capacity text retrieval and text filtering systems. A variety of current research topics are also covered, including cross-lingual retrieval, document summarization, machine learning, topic detection and tracking, and multi-media retrieval.      Prerequisites:      Programming and data-structures at the level of 15-212 or higher.  Algorithms comparable to the undergraduate CS algorithms course (15-451) or higher.  Basic linear algebra (21-241 or 21-341).   Basic statistics (36-202) or higher.
LTI11743 | Self-Paced Lab: IR | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11743&SEMESTER=S15 | prereq:11741 or 15886 instructors:Yang, Yiming description:Advanced Information Retrieval Seminar and Lab is a seminar that focuses on current research in Information Retrieval. The seminar covers recent research on subjects such as retrieval models, text classification, information gathering, fact extraction, information visualization, summarization, text data mining, information filtering, collaborative filtering, question answering systems, and portable information systems. Other topics are drawn from recent SIGIR, Digital Libraries, TREC, Machine Learning, and AAAI conferences. Course content varies from year to year.  Students not taking the course for credit are welcome to audit or sit in on the course, subject to availability of space.
LTI11745 | Advanced Statistical Learning Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11745&SEMESTER=S15 | instructors:Yang, Yiming description:This seminar aims to deepen the participants' understanding of the theoretical foundation of statistical learning and applications, to broaden their knowledge of new techniques, directions and challenges in the field, and to inspire research ideas through class-room discussions.  In the past years, this seminar was structured as a 12-unit course in the form of group-reading, presenting and discussing the book (chapter by chapter) of The Elements of Statistical Learning: Data Mining, Inference, and Prediction by Trevor Hastie et al. In the fall of 2014, we will have a 6-unit seminar, focusing on New Methods in Large-scale Structured Learning, with selected papers from the past 2-3 years of ICML, NIPS, KDD, JMLR or the like, plus related background reading. We will meet once a week, one topic per week (1-2 papers), with presentations rotating among participants. In each week, the assigned presenter starts with the questions from all the participants (collected by email) about the current topic, followed by a presentation on that topic and leads the discussion. All the students are required to read the assigned paper(s) of the week before the class, and email their questions to the presenter (CC to everybody). By the end of the semester, each student will individually write a short 3-4-page white paper outlining a research proposal for new work extending one of the research areas discussed in class.  There will be no exams or homework; the grading is based on class participation, quality of the seminar presentation(s), questions submitted for each class and discussions, and the final brief paper. Prerequisites: Intro machine learning and related courses
LTI11752 | Speech II: Phonetics, Prosody, Perception and SynthesisThis Section Cancelled | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11752&SEMESTER=S15 | instructors:Eskenazi, Maxine description:The goal of the course is to give the student basic knowledge from several fields that is necessary in order to pursue research in automatic speech processing. The course will begin with a study of the acoustic content of the speech signal. The students will use the spectrographic display to examine the signal and discover its variable properties. Phones in increasingly larger contexts will be studied with the goal of understanding coarticulation. Phonological rules will be studied as a contextual aid in understanding the spectrographic display. The spectrogram will then serve as a first introduction to the basic elements of prosody. Other displays will then be used to study the three parts of prosody: amplitude, duration, and pitch. Building on these three elements, the student will then examine how the three interact in careful and spontaneous speech.     Next, the students will explore perception. Topics covered will be:   physical aspects of perception, psychological aspects of perception, testing perception processes, practical applications of knowledge about perception.   The second part of this course will cover all aspects of speech synthesis.     Students need only have a basic knoweldge of speech and language processing. Some degree of programming and statistical modelling will be beneficial, but not required.    Taught every other year
LTI11753 | Advanced Laboratory in Speech Recognition | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11753&SEMESTER=S15 | instructors:Metze, Florian description:The technology to allow humans to communicate by speech with machines or by which machines can understand when humans communicate with each other is rapidly maturing. While the 11-751 speech course focussed on an introduction to the theoretical foundations, essential algorithms, major approaches, and strategies for current state-of-the-art systems, the 11-753 speech lab complements the education by concentrating on the experimental practice in developing speech recognition and understanding speech-based systems, and by getting hands-on experience on relevant research questions using state-of-the art tools. Possible problem sets include both core speech recognition technology, and the integration of speech-based components into multi-modal, semantic, learning, or otherwise complex systems and interfaces.
LTI11754 | Project Course: Dialogue Systems | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11754&SEMESTER=S15 | instructors:Black, Alan description:This course will teach participants how to implement a complete spoken language system while providing opportunities to explore research topics of interest in the context of a functioning system. The course will produce a complete implementation of a system to access and manipulate email through voice only, for example to allow users to interact with the mail system over a telephone while away from their computer. In doing so the class will address the component activities of spoken language system building. These include, but are not limited to, task analysis and language design, application-specific acoustic and language modeling, grammar design, task design, dialog management, language generation and synthesis. The course will place particular emphasis on issues in task design and dialog management and on issues in language generation and synthesis.     For Fall, we will implement a simple telephone-based information access application. The domain is bus schedules (see http://www.speech.cs.cmu.edu/BusLine for a web-based interface to this domain) and the goal will be to create one or more usable applications that can provide a real service and can be deployed for actual use by the University community. Participants will chose individual components of the system to concentrate on and will collaborate to put together the entire system. It is perfectly acceptable for several individuals to concentrate on a single component, particularly if their work will exemplify alternative approaches to the same problem.
LTI11755 | Machine Learning for Signal Processing | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11755&SEMESTER=S15 | instructors:Ramakrishnan, Bhiksha description:Signal Processing is the science that deals with extraction of information from signals of various kinds. This has two distinct aspects -- characterization and categorization. Traditionally, signal characterization has been performed with mathematically-driven transforms, while categorization and classification are achieved using statistical tools.     Machine learning aims to design algorithms that learn about the state of the world directly from data.     A increasingly popular trend has been to develop and apply machine learning techniques to both aspects of signal processing, often blurring the distinction between the two.     This course discusses the use of machine learning techniques to process signals. We cover a variety of topics, from data driven approaches for characterization of signals such as audio including speech, images and video, and machine learning methods for a variety of speech and image processing problems.
LTI11756 | Design and Implementation of Speech Recognition Systems | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11756&SEMESTER=S15 | instructors:Ramakrishnan, Bhiksha description:Voice recognition systems invoke concepts from a variety of fields including speech production, algebra, probability and statistics, information theory, linguistics, and various aspects of computer science. Voice recognition has therefore largely been viewed as an advanced science, typically meant for students and researchers who possess the requisite background and motivation.  In this course we take an alternative approach. We present voice recognition systems through the perspective of a novice. Beginning from the very simple problem of matching two strings, we present the algorithms and techniques as a series of intuitive and logical increments, until we arrive at a fully functional continuous speech recognition system.  Following the philosophy that the best way to understand a topic is to work on it, the course will be project oriented, combining formal lectures with required hands-on work. Students will be required to work on a series of projects of increasing complexity. Each project will build on the previous project, such that the incremental complexity of projects will be minimal and eminently doable. At the end of the course, merely by completing the series of projects students would have built their own fully-functional speech recognition systems.  Grading will be based on project completion and presentation.
LTI11761 | Language and Statistics | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11761&SEMESTER=S15 | instructors:Rosenfeld, Ronald description:Language technologies (search, text mining, information retrieval, speech recognition, machine translation, question answering, biological sequence analysis...) are at the forefront of this century's information revolution.  In addition to their use of machine learning, these technologies rely centrally on classic statistical estimation techniques.   Yet most CS and engineering undergraduate programs do not prepare students in this area beyond an introductory prob&stats course.  This course is designed to plug this hole.  The goal of "Language and Statistics" is to ground the data-driven techniques used in language technologies in sound statistical methodology.   We start by formulating various language technology problems in both an information theoretic framework (the source-channel paradigm) and a Bayesian framework (the Bayes classifier).  We then discuss the statistical properties of words, sentences, documents and whole languages, and the computational formalisms used to represent language.  These discussions naturally lead to specific concepts in statistical estimation.  Topics include: Zipf's distribution and type-token curves; point estimators, Maximum Likelihood estimation, bias and variance, sparseness, smoothing and clustering; interpolation, shrinkage, and backoff; entropy, cross entropy and mutual information;  decision tree models applied to language; latent variable models and the EM algorithm; hidden Markov models; exponential models and maximum entropy; semantic modeling and dimensionality reduction; probabilistic context-free grammars and syntactic language models.  The course is designed for LTI & SCS graduate students, but others are welcome.  CS UG upperclassmen who've taken it have done well, though they found it challenging.  The 11-661 version does not require the course project.  Prerequisites: Strong quantitative aptitude.  Comfort with basic UG-level probability.  Some programming skill.
LTI11775 | Large-Scale Multi-media Analysis | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11775&SEMESTER=S15 | instructors:Hauptmann, Alexander description:TBA
LTI11782 | Self-Paced Lab for Computational Biology | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11782&SEMESTER=S15 | prereq:10810 instructors:Xing, Poe description:Students will choose from a set of projects designed by the instructor. Students will also have the option of designing their own projects, subject to instructor approval. For the students who had completed a project in the 10-810 course, they can either switch to another project, or continue working on the previous project by aiming a significant progress (subject to instructor approval). Each student will work independently. If more than one student work on a particular topic, each should choose an approach that is different from the approaches used by the other students working on the same problem. The students need to begin with a project proposal to outline the high-level ideas, tasks, and goals of the problem, and plan of experiments and/or analysis. The instructor will consult with you on your ideas , but the final responsibility to define and execute an interesting piece of work is yours. Your project will have two final deliverables: 1. a writeup in the form of a NIPS paper (8 pages maximum in NIPS format, including references), worth 60% of the project grade, and 2. a research seminar presentation of your work at the end of the semester, worth 20% of the project grade. In addition, you must turn in a midway progress report (5 pages maximum in NIPS format, including references) describing the results of your first experiments, worth 20% of the project grade. Note that, as with any conference, the page limits are strict! Papers over the limit will not be considered. The grading of your project are based on overall scientific quality, novelty, writing, and clarity of presentation. We expect your final report to be of conference-paper quality, and you are expected to also deliver software implementation of your algorithmic results.
LTI11783 | Self-Paced Lab: Rich Interaction in Virtual World | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11783&SEMESTER=S15 | prereq:11751 and 18781 and 18799 instructors:Metze, Florian description:Massively Multi-player Online Role-Playing Games have evolved into Virtual Worlds (VWs), and are creating ever richer environments for experimentation on all aspects of human to human, or human to machine communication, as well as for information discovery and access. So far, interaction has been constrained by the limited capabilities of keyboards, joysticks, or computer mice. This creates an exciting opportunity for explorative research on speech input and output, speech-to-speech translation, or any aspect of language technology. Of particular interest will be a combination with other novel "real world" (RW) input, or output devices, such as mobile phones or portable games consoles, because they can be used to control the VW, or make it accessible everywhere in RW. Language technologies in particular profit from "context awareness", because domain adaptation can be performed. For scientific experimentation in that area, Virtual Worlds offer the opportunity to concentrate on algorithms, because context sensors can be written with a few lines of code, without the need for extra hardware sensors. Algorithms can also run "continuously", without the need for specific data collection times or places, because the VW is "always on".    In this lab, we will enhance existing clients to virtual worlds so that they can connect to various speech and language related research systems developed at LTI and CMU's Silicon Valley campus. The lab will be held jointly at the CMU's Pittsburgh and Silicon Valley Campuses. We will "eat our own dog food", so the goal will be to hold the last session entirely in a virtual class room, which will by that time include speech control of virtual equipment, speech-to-speech translation, and some devices that can be controlled using non-PC type equipment, like mobile phones. Eventually, this virtual room or the know-how gathered
LTI11792 | Intelligent Information Systems Project | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11792&SEMESTER=S15 | prereq:11791 or 15393 instructors:Nyberg, Eric description:The Software Engineering for IS sequence combines classroom material and assignments in the fundamentals of software engineering (11-791) with a self-paced, faculty-supervised directed project (11-792). The two courses cover all elements of project design, implementation, evaluation, and  documentation. Students may elect to take only 11-791; however, if both parts are taken, they should be taken in proper sequence. Prerequisite: 11-791. The course is required for VLIS students.
LTI11796 | Question Answering Lab | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11796&SEMESTER=S15 | prereq:11791 instructors:Mitamura, Teruko description:The Question Answering Lab provides a hands-on introduction to existing approaches to question answering (QA). Students will define their own project, with approval from the instructor. Each student will work independently. If multiple students work as a team on a particular topic, each should choose an approach that is different from the approaches used by the other students working on the same problem. Students will document their approach and progress on a wiki page that is shared with the instructor. Grading will be based on periodic and final review of the student progress as documented on the wiki.
LTI11797 | Question Answering | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11797&SEMESTER=S15 | instructors:Nyberg, Eric description:The Question Answering course provides a chance for hands-on, in-depth exploration of core algorithmic approaches to question answering (QA). Students will work independently or in small teams to extend or adapt existing QA modules and systems to improve overall performance on known QA datasets (e.g. TREC, CLEF, NTCIR), using best practices associated with the Open Advancement of Question Answering initiative. Each student project will evaluate one or more component algorithms on a given QA dataset and produce a conference-style paper describing the system design, experimental setup and results.
LTI11805 | Machine Learning with Large Datasets | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11805&SEMESTER=S15 | instructors:Cohen, William description:Large datasets are difficult to work with for several reasons. They are difficult to visualize, and it is difficult to understand what sort of errors and biases are present in them. They are computationally expensive to process, and often the cost of learning is hard to predict - for instance, and algorithm that runs quickly in a dataset that fits in memory may be exorbitantly expensive when the dataset is too large for memory. Large datasets may also display qualitatively different behavior in terms of which learning methods produce the most accurate predictions.This course is intended to provide a student practical knowledge of, and experience with, the issues involving large datasets. Among the issues considered are: scalable learning techniques, such as streaming machine learning techniques; parallel infrastructures such as map-reduce; practical techniques for reducing the memory requirements for learning methods, such as feature hashing and Bloom filters; and techniques for analysis of programs in terms of memory, disk usage, and (for parallel methods) communication complexity.
LTI11821 | Advanced Linguistics Seminar | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11821&SEMESTER=S15 | instructors:Levin, Lorraine description:None
LTI11823 | ConLanging: Lrng. Ling. &amp; Lang Tech via Constru Artif. Lang. | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11823&SEMESTER=S15 | instructors:Black, Alan description:TBD
LTI11910 | Directed Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11910&SEMESTER=S15 | instructors:Frederking, Robert description:This course number documents the research being done by Masters and pre-proposal PhD students. Beginning in Fall 2001, every LTI graduate student will register for at least 24 units of 11-910 each semester, unless they are ABD (i.e., they have had a thesis proposal accepted), in which case they should register for 48 units of 11-930. The student will be expected to write a report and give a presentation at the end of the semester, documenting the research done. The report will be filed by either the faculty member or the LTI graduate program administrator.   (Until Fall 2001 this course number was used for individual study in connection with LTI project research work and was a Pass/Fail course.)
LTI11920 | Independent Study: Breadth | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11920&SEMESTER=S15 | instructors:Frederking, Robert description:This course number is intended for individual study with faculty other than a student's intended thesis advisor.
LTI11925 | Independent Study: Area | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11925&SEMESTER=S15 | instructors:Frederking, Robert description:This course number is intended for individual study with the intended thesis advisor prior to acceptance of a student's thesis proposal.
LTI11929 | Masters Thesis II | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11929&SEMESTER=S15 | instructors:Frederking, Robert description:This course number is intended for last semester Masters students who wish to do an optional Masters Thesis. The student will normally have taken 11-925 Independent Study: Area of Concentration for 12 units in the preceding semester, to produce an MS Thesis Proposal.
LTI11930 | Dissertation Research | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11930&SEMESTER=S15 | instructors:Frederking, Robert description:This course number is intended for PhD dissertation research after acceptance of a student's PhD thesis proposal.
LTI11935 | LTI Practicum | https://enr-apps.as.cmu.edu/open/SOC/SOCServlet/courseDetails?COURSE=11935&SEMESTER=S15 | instructors:Frederking, Robert description:This course is intended as an internship course for students who are doing Curricular Practical Training (CPT) as part of their graduate degree.
