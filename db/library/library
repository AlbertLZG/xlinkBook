CS229 | Machine Learning | http://cs229.Stanford.EDU | instructors:Ng videourl:https://itunes.apple.com/us/course/machine-learning/id495053006 description:Topics: statistical pattern recognition, linear and non-linear regression, non-parametric methods, exponential family, GLMs, support vector machines, kernel methods, model/feature selection, learning theory, VC dimension, clustering, density estimation, EM, dimensionality reduction, ICA, PCA, reinforcement learning and adaptive control, Markov decision processes, approximate dynamic programming, and policy search. Prerequisites: linear algebra, and basic probability and statistics. path:db/eecs/cs-stanford2016
COMPGI13 |  Advanced Topics in Machine Learning | http://www.cs.ucl.ac.uk/students/syllabus/mscml/gi13_advanced_topics_in_machine_learning/ | path:db/eecs/computer-science-ucl2016
CS224D | Deep Learning for Natural Language Processing | http://cs224D.Stanford.EDU | instructors:Socher description:Deep learning approaches have obtained very high performance across many different natural language processing tasks. In this class, students will learn to understand, implement, train, debug, visualize and potentially invent their own neural network models for a variety of language understanding tasks. The course provides a deep excursion from early models to cutting-edge research. Applications will range across a broad spectrum: from simple tasks like part of speech tagging, over sentiment analysis to question answering and machine translation. The final project will involve implementing a complex neural network model and applying it to a large scale NLP problem. We will introduce a common programming framework for deep learning for the problem sets.Prerequisites: programming abilities (python), linear algebra, Math 21 or equivalent, machine learning background (CS 229 or similar) Recommended: CS 224N, EE364a (convex optimization), CS 231N path:db/eecs/cs-stanford2016
CS231N | Convolutional Neural Networks for Visual Recognition | http://cs231N.Stanford.EDU | instructors:Li/Karpathy description:Computer Vision has become ubiquitous in our society, with applications innsearch, image understanding, apps, mapping, medicine, drones, andnself-driving cars. Core to many of these applications are the tasks of image classification, localization and detection. This course is a deep dive into details of neural network architectures with a focus on learning end-to-end models for these tasks, particularly image classification. During the 10-week course, students will learn to implement, train and debug their own neural networks and gain a detailed understanding of cutting-edge research in computer vision. The final assignment will involve training a multi-million parameter convolutional neural network and applying it on the largest image classification dataset (ImageNet). We will focus on teaching how to set up the problem of image recognition, the learning algorithms (e.g. backpropagation), practical engineering tricks for training and fine-tuning the networks and guide the students through hands-on assignments and a final course project. Much of the background and materials of this course will be drawn from the ImageNet Challenge: http://image-net.org/challenges/LSVRC/2014/index. Prerequisites: Proficiency in Python; familiarity with C/C++; CS 131 and CS 229 or equivalents; Math 21 or equivalent, linear algebra. path:db/eecs/cs-stanford2016
